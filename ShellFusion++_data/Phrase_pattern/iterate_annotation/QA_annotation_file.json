{
  "0": [
    {
      "id": "au_1176076",
      "task": "How to show only 1 window of an application when the application icon in dash-to-dock is pressed?",
      "P-task": "show 1 window applic applic icon dash-to-dock press",
      "F_verb": "show",
      "P-body": "On the terminal, I discovered that I can use the below cmd to do what @mondjunge described for gnome-tweaks: .  Thus when I middle-click an App icon in dash-to-dock, a preview of opened App windows appears, and I can select the window I want to maximize from the preview. .  ",
      "P-tags": "window ubuntu-dock dash-to-dock gnome-shell-extens 18 04",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP when S"
    },
    {
      "id": "au_485800",
      "task": "How to paste text from an external source into the xterm edited file?",
      "P-task": "past text extern sourc xterm edit file",
      "F_verb": "paste",
      "P-body": "In \"xterm\" middle click works for me, as does Shift+Insert. There possibly are other methods, but those are the ones I just tested. .  ",
      "P-tags": "xterm past",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP from NP into NP"
    },
    {
      "id": "au_2199",
      "task": "Customize software sources for Ubuntu Desktop updater to manage?",
      "P-task": "custom softwar sourc ubuntu desktop updat manag",
      "F_verb": "customize",
      "P-body": "Basically the updater program (update-manager) needs an APT source url, which can be an ftp-server or http-server. But the files on the server needs to be structured in a special way for the updater to work and you can't just add anything to it. These servers are often referred to as repositories (or repos). .  A lot of 3rd party applications are available in their own repositories, often you will encounter instructions to add some lines to \"/etc/apt/sources.list\" but you can instead add them through the GUI by going to System > Administration > Software Sources and in the Other Software tab clicking Add... These lines will always start with \"deb\" and can look like this one for Oracle VirtualBox .  PPA's (Personal Package Archives) is a shortcut (of sorts) to doing this for some programs, but only the ones that are hosted at launchpad.net there is a bit of information on PPA's on this page. Afaik the only way to add PPA's is through the command line (terminal) with this command: .  launchpad-user-name and name-of-repos will be differnt in the real world! You will find the names of the different PPA's on launchpad or you might find people that refers to them on 3rd party sites. .  After adding a new source the programs from the new source will appear in the software management tools like Ubuntu Software Centre (or what it's called, I use \"aptitude\" on a command line ;) .  ",
      "P-tags": "dpkg apt updat package-manag update-manag",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_219427",
      "task": "yum install http://www.example.com/package.rpm vs. rpm -ivh http://www.example.com/package.rpm",
      "P-task": "yum instal http : www exampl com packag rpm vs rpm -ivh http : www exampl com packag rpm",
      "F_verb": "install",
      "P-body": "\"yum\" is a high-level package manager, able to solve dependencies. This means that should \"cf-cli_amd64.rpm\" need other packages to be installed (as it happens in most cases), \"yum\" will automatically retrieve and install them without any hassle for the user. .  ",
      "P-tags": "rhel rpm package-manag cento yum",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_10513367",
      "task": "Xlib - draw only set bits of a bitmap on a window",
      "P-task": "xlib - draw set bit bitmap window",
      "F_verb": "set",
      "P-body": "First, for non-transparent bitmaps you don't need to create a full-depth image from bitmap data. Create one-bit pixmap and use \"XCopyPlane\".  .  For transparent bitmaps you need to manipulate your GC's clip mask.  .  ",
      "P-tags": "linux xlib c x11",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP on NP"
    },
    {
      "id": "ul_453424",
      "task": "Shell: aggregate several results (md5sum) into a single file",
      "P-task": "shell : aggreg sever result md5sum singl file",
      "F_verb": "aggregate",
      "P-body": "Moving the redirection should do the trick: .  To keep \"basename\" output, here is a more useful version: .  ",
      "P-tags": "shell",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP into NP"
    },
    {
      "id": "ul_31145",
      "task": "Is there a more elegant way to count words and assign that count to variables?",
      "P-task": "eleg way count word assign count variabl",
      "F_verb": "assign",
      "P-body": "\"awk\" can replace the entire script pretty easily: .  The \"(+var)\" is to force \"awk\" to treat the variable as a number (so it will output \"0\" if the variable was unset). You can also use a \"BEGIN\" block to set all the variables to \"0\" initially: .   Stick that in a file and run \"awk -f /path/to/the/script.awk xiostatus.tmp\". If you don't need the temporary file, you can even do \"/root/xiotech status | awk -f /path/to/the/script.awk\". .  If you set the execution bit on the \"awk\" script, you can call it as a standalone executable: \"/path/to/the/script.awk xiostatus.tmp\", or \"/root/xiotech status | /path/to/the/script.awk\". .  ",
      "P-tags": "awk shell-script bash",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "so_27492110",
      "task": "Convert multi PDF document to several Image files",
      "P-task": "convert multi pdf document sever imag file",
      "F_verb": "convert",
      "P-body": "You should be able to convert multipage PDF files into multiple JPEGs (one file per page) easily when using \"convert\". .  Here is a command to process just pages 1--5: .  (\"[0-4]\" means pages 1--5. The page indexing is 0-based!) .  However, this does not give you much control about the resulting quality. The only thing you can add is \"-density 150\" or \"-density 300\" to increase the resolution of your images. \"convert\" by default uses \"-density 72\" which is 72 PPI.) .  Also, be aware that ImageMagick is not able to process PDFs all by itself. It employs Ghostscript as its 'delegate' to handle PDF files. You can see this if you add \"-verbose\" to your command line: .  So in many cases where you want to convert PDF pages to images it has advantages to run Ghostscript directly... .  ",
      "P-tags": "linux pdf imagemagick-convert",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_51782834",
      "task": "timerfd mysteriously set int to 0 when read()",
      "P-task": "timerfd mysteri set int 0 read",
      "F_verb": "set",
      "P-body": " Unless your \"int\" and \"uint64_t\" types are the same size, this is a very bad idea. What's most likely happening is that the 64 bits you're reading are overwriting \"exp\" and whatever else happens to be next to it on the stack. .  Actually, even if they are the same size, it's a bad idea. What you should have is something like: .  That way, you're guaranteed to never overwrite the data and your next line would catch the problem for you: .  It won't solve the problem that an unsigned integral type and an integral type will be treated differently but you can fix that just by using the right type for \"exp\". .  ",
      "P-tags": "timer unix",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP when S"
    },
    {
      "id": "au_155484",
      "task": "How to execute an arbitrary command when open a new gnome profile terminal?",
      "P-task": "execut arbitrari command open new gnome profil termin",
      "F_verb": "execute",
      "P-body": "You can put that command in \"~/.bashrc\" but it'll be invoked each time you open a new terminal (not for login terminals though). .  ",
      "P-tags": "gnome-termin command-lin",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "au_73068",
      "task": "Instructions to mount an internal hard drive?",
      "P-task": "instruct mount intern hard drive",
      "F_verb": "mount",
      "P-body": "The Windows partition should be visible in the left panel of Ubuntu file browser. Clicking on it should mount the drive and show you the files. .  If you prefer to mount the partition from command line, something like this would work: .  It's not clear why you're asking about fdisk and gparted - you definitely don't need those to access your files. .  ",
      "P-tags": "fdisk gnome gpart command-lin",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_54617341",
      "task": "ls sort order inside container",
      "P-task": "ls sort order insid contain",
      "F_verb": "sort",
      "P-body": "I found out I get the same behavior using \"sort\" command .  But the sorting order changes when using \"sort -d\" .  Thanks to David for pointing me in the right direction, this is caused by the locale settings as described here .  On bare ubuntu container, POSIX locale is used which has different sorting rules then en_US. I solved my problem by installing en_US locale in the docker image, and sorting works as expected again. .  ",
      "P-tags": "ls linux docker bash",
      "cate": "sort",
      "pat": "V NP inside S"
    },
    {
      "id": "so_18820197",
      "task": "curl usage to get header",
      "P-task": "curl usag get header",
      "F_verb": "get",
      "P-body": "You need to add the -i flag to the first command, to include the HTTP header in the output. This is required to print headers. .  More here: https://serverfault.com/questions/140149/difference-between-curl-i-and-curl-x-head .  ",
      "P-tags": "linux curl",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_18741181",
      "task": "Remove nils from a list - Erlang",
      "P-task": "remov nil list - erlang",
      "F_verb": "remove",
      "P-body": "You can remove nils from the list using function like that: .  This function does not remove nils within tuples though. .  And you can use a couple of functions to extract every first non tuple element in you list (like strings \"some\" and more): .  Function \"extract_first_non_tuple_element\" is recursive, because in your example tuple can be nested. .  So to test this functions: .  Update. To remove nils from nested tuples we can use function like that: .  ",
      "P-tags": "erlang-shel erlang ejabberd erlang-otp functional-program",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from S"
    },
    {
      "id": "ul_453595",
      "task": "Using 'read' for more than one variable",
      "P-task": "use read one variabl",
      "F_verb": "read",
      "P-body": "I'm not sure how much cleaner this is than your existing function but using an associative array (requires bash v4.0 or later) combined with a for loop you could use read once.  .  ",
      "P-tags": "docker read bash",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V for S"
    },
    {
      "id": "so_65634626",
      "task": "How to automatically stop a program.c and input a command in Linux?",
      "P-task": "automat stop program c input command linux",
      "F_verb": "stop",
      "P-body": "Probably an XY-problem here -- why would you want to do this? .  The basic issue is that this presupposes your server program is run from a shell and you want to return to the shell to do stuff. But what is the server going to be doing in the meantime? The shell will have (need) control of the input and output so the server pretty much just needs to wait. .  You can get the same effect as ^z by calling kill: .  will have the server send a STOP signal to itself. The shell (which is monitoring progress of the program), will notice this and print the \"Stopped\" message and then prompt for what to do. The server will be stopped, and you can resume it with the shell's \"fg\" command (or put it into the background with \"bg\"). However, if your server program is not run from a shell (it is just running directly in a terminal), this will simply stop the server and nothing else will happen. .  More commonly what you want to do here is run a subshell: .  which will start a new shell and will wait for it to complete. When the shell exits (use the \"exit\" command or type ^d at the shell prompt) the server will resume. .  If you want the server to continue to run while the shell runs, you can use fork+exec to run the shell in the child and continue running the server in the parent, or you can use fork+_exit to run the server as a grandchild and have the parent shell continue, but you need to be careful about using the terminal input and output (the server and shell will be fighting for it). .  ",
      "P-tags": "linux c server unix",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "so_39723726",
      "task": "How to Skip 1st line of file - awk",
      "P-task": "skip 1st line file - awk",
      "F_verb": "skip",
      "P-body": "Use GNU printf for proper tab-spaced formatting  .  You can use \"printf\" with \"width\" options as below example if \"printf \"%3s\"\" .   \"3\": meaning output will be padded to 3 characters.   From \"man awk\", you can see more details: .  You can add the padding count as you need. For the input file you specified .  ",
      "P-tags": "awk unix",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP"
    },
    {
      "id": "so_41506068",
      "task": "Find top folder only with NTFS Everyone",
      "P-task": "find top folder ntf everyon",
      "F_verb": "find",
      "P-body": "Simply check for ACEs that are not inherited. I would also recommend checking \"$_.PSIsContainer\" instead of \"$_.Mode\", and doing this before checking ACLs. On PowerShell v3 or newer use the \"-Directory\" switch of \"Get-ChildItem\" for limiting the results to directories only. .  Note that this does not take care of paths longer than 260 characters. That's a limitation of the Win32 API, and you need different tools to handle longer paths. .  ",
      "P-tags": "powershel",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "au_754958",
      "task": "How to prevent users from changing their password to one of the last X passwords?",
      "P-task": "prevent user chang password one last x password",
      "F_verb": "prevent",
      "P-body": "You can configure PAM to do this for you. Just open \"/etc/pam.d/common-password\" and append \"use_authtok\" to the first \"password\" line (the one which calls the pam_unix module) so that it looks somewhat like this: .  Now add this line above the previously modified line: .  where \"X\" is the number of previous passwords against which you want to check for a repeating password.  .  Here the previous \"X\" passwords will be stored in hashed form at the location \"/etc/security/opasswd\" .  So you need to create the file if and only if it does not exist and assign it permission 600 (\"-rw-------\"): .  ",
      "P-tags": "password gnome secur",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING"
    },
    {
      "id": "so_20523393",
      "task": "In bash readline, how do I make the incremental search case insensitive",
      "P-task": "bash readlin make increment search case insensit",
      "F_verb": "make",
      "P-body": "Short Answer: No you can't get this feature in BASH at present because this feature hasn't been built yet into \"vi or emacs mode\". As I commented above \"completion-ignore-case\" only applies to completion, not to \"isearch\". .  ",
      "P-tags": "readlin bash",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_37976225",
      "task": "Regex: Get a month of each line",
      "P-task": "regex : get month line",
      "F_verb": "get",
      "P-body": "You can use \"awk\" instead of \"cut\" and use \"split\" to parse \"month\": .  ",
      "P-tags": "linux cut regex",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_1214388",
      "task": "vim: E212: Can't open file for writing (even when using sudo)",
      "P-task": "vim : e212 : open file write even use sudo",
      "F_verb": "open",
      "P-body": "There's no such directory \"/usr/share/application/\". .  It is: .  You are missing the final \"s\". .  ",
      "P-tags": "18 04 vim",
      "cate": "open",
      "pat": "V NP for S_ING"
    },
    {
      "id": "au_639014",
      "task": "Another password prompt when waking from suspend",
      "P-task": "anoth password prompt wake suspend",
      "F_verb": "prompt",
      "P-body": "I found this solution: .  First: .  Then: .  Suspend, resume and you will be direct on the Unity's password promt. .  ",
      "P-tags": "login-screen",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V when S"
    },
    {
      "id": "ul_597456",
      "task": "Remove all files from (sometimes empty) directory",
      "P-task": "remov file sometim empti directori",
      "F_verb": "remove",
      "P-body": "With the POSIX \"find\": .  By design, find does not fail if no argument is provided. See example 8 in the specification which makes that clear. .  Meaning of the options: .   \"-path\" specifies that we only look for paths that begin in \"www/\" and do not have a dot immediately following (so it excludes hidden files from the removal list). .   \"-prune\" prevents find from trying to descend in directories (you are already using \"rm -r\", which does that). .   \"--\" in \"rm -r -- {} +\" allows processing of found files even though they start with a hyphen. .    ",
      "P-tags": "rm bash",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "su_684406",
      "task": "Batch file rename script swapping substrings in filename?",
      "P-task": "batch file renam script swap substr filenam",
      "F_verb": "rename",
      "P-body": "In bash, it can be done as follows: .  This command first finds all files in the current directory, then feeds these names (it assumes without checking that there are three underscores and a . in these file names) to awk, which rearranges them in the order you wish.  .  The only tricky part is \"-F'[_.]'\" The option \"-F' '\" is used to identify the delimiter between different fields, and in this last case the delimiter takes on its default value, a space. But the option \"-F'[_.]'\" defines a character class of interchangeable elements, in this case underscore and dot, which can be used at will as delimiters.  .  Edit: .  Ok, since this works, without actually moving anything, we can now implement the actual act of renaming the files:  .  ",
      "P-tags": "python shell-script batch maco",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_436647",
      "task": "AWK one-liner to process a file having different number of fields",
      "P-task": "awk one-lin process file differ number field",
      "F_verb": "process",
      "P-body": "To sum the last fields that have a decimal comma (dot) in them: .  That is, if the data in the last field (\"$NF\") has a dot in it, assume that it's a number and add it to \"sum\". At the end, print the sum with the format specified in the question. .  Note that this will skip any integers in the last field. .  The following will allow \"awk\" to try to use the last field as a number regardless of what it actually is. This means that \"1\" will be interpreted as 1 and that \"1.2\" will be interpreted as 1.2. The strings \"hello\" and \"boo\" will be zero while \"123abc\" will be taken as 123. .  The following will not sum fields that contain anything other than digits, dots, pluses and minuses: .  It will still accept \"09+99...\" (as 9), but matching floating point numbers is non-trivial and depends on the format you would need to match. See e.g. these examples at RegExLib site for more useful patterns. .  ",
      "P-tags": "awk linux",
      "cate": "handle/process/preprocess",
      "pat": "V NP"
    },
    {
      "id": "so_23962825",
      "task": "Powershell won't preserve the type cast when updating an object's property",
      "P-task": "powershel preserv type cast updat object properti",
      "F_verb": "preserve",
      "P-body": "You didn't mention what type of object $row is, but it appears that $row is a native .NET object with Device exposed as a System.String. If you don't have access to the source code of the $row type, you can use Select-Object to replace each $row object with a PSCustomType object that has the same properties: .  And if you didn't want to rely on exception handling, which is a little bit costlier, you could use the TryParse method of System.Net.IPAddress: .  ",
      "P-tags": "powershel net",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP when S"
    },
    {
      "id": "ul_82024",
      "task": "Get latest Rekonq developmental source code",
      "P-task": "get latest rekonq development sourc code",
      "F_verb": "get",
      "P-body": "Looks like you can get it here: .  Page on installing and compiling it is here: .   https://techbase.kde.org/Projects/rekonq/Compiling_rekonq  ",
      "P-tags": "browser develop compil kde",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_57098902",
      "task": "Add items to ant's PATH without breaking stuff",
      "P-task": "add item ant path without break stuff",
      "F_verb": "add",
      "P-body": "Found it.. Apache Ant documentation assumes somewhere in your code you've called the following: .  Without this, \"PATH\" will be set to the literal string \"${env.PATH}\", thus clobbering the \"PATH\" value. This can be observed by echoing the value of \"$PATH\" in the shell script. .  Their documentation has this in the examples, but it was missed in the above example causing the issue. .  ",
      "P-tags": "unix linux ant maco java",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP without S_ING"
    },
    {
      "id": "so_45069991",
      "task": "After doing update and upgrade, now get tensorflow ImportError: libcublas.so.8.0 cannot",
      "P-task": "updat upgrad get tensorflow importerror : libcubla 8 0",
      "F_verb": "get",
      "P-body": "I was able to resolve this by only reinstalling Cuda 8.0. I did not have to reinstall CudNN or Nvidia drivers or tensorflow. Since my previous install was a deb install, I did not have to remove anything. I followed instructions at cuda install. I believe that the update/upgrade and subsequent autoremove deleted the files in \"/usr/local/cuda-8.0/targets/x86_64-linux/lib\". During the problem, this folder only had a few files in it and now there are many including the missing ones.  .  ",
      "P-tags": "linux python tensorflow",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_637360",
      "task": "How do you upgrade a Dell XPS 13 Developer Edition from Ubuntu 14.04 to 15.04?",
      "P-task": "upgrad dell xp 13 develop edit ubuntu 14 04 15 04",
      "F_verb": "upgrade",
      "P-body": "First, be sure you've done all the 14.04 updates (I had issues just doing this, but after a bunch of reboots and upgrade attempts, you'll eventually get it done).  .  Second, go into Update Manager and tell Ubuntu to show you all available version updates, the default with the pre-installed 14.04 is to show you nothing, not even LTSes.  .  Then you have to remove some things that cause issues with the upgrade, install a newer kernel, and update grub: (src) .  Do NOT REBOOT YET! .  Now upgrade to 14.10 with: .  This should bring you up to 14.10. After the reboot into 14.10, check it with \"lsb_release -a\", it should say 14.10.  .  Now run \"sudo do-release-upgrade\" again to upgrade to 15.04 or run \"Software Updater\" and it should say 15.04 is available and ask you to upgrade (assuming you've set it to notify you of non LTS versions).  .  Boom, that should be it. I had no issues going this route.  .  If you lose wireless, apparently you can do a usb tether. Plug your phone into the usb port and turn on usb tethering, then \"sudo apt-get update && sudo apt-get upgrade\". Did not test this.  .  ",
      "P-tags": "upgrad 15 04 dell xp",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "ul_128379",
      "task": "find: missing argument to -exec",
      "P-task": "find : miss argument -exec",
      "F_verb": "find",
      "P-body": "There was several issues with your attempts, including backticks used instead of quotes (removed in later edits to the question), missing quotes where they are required, extra quotes where they are useless, missing parentheses to group \"-o\" clauses, and different implementations of \"find\"used (see the comments and chat for details). .  Anyway, the command can be simplified like this: .  or, should you use an archaic GNU find version, this should always work: .  ",
      "P-tags": "find",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_123634",
      "task": "How to show the CUPS printer jobs history?",
      "P-task": "show cup printer job histori",
      "F_verb": "show",
      "P-body": "Yes a program exists: \"lpstat\" - print cups status information .    Or if you prefer via the following web pages: .  Kind regards .  ",
      "P-tags": "lpr cup",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "ul_533500",
      "task": "systemd-boot cannot find my root",
      "P-task": "systemd-boot find root",
      "F_verb": "find",
      "P-body": "On giving this another look, it seems you have a mismatch between PARTUUID=... and UUID=... and that's what's causing this problem. .  You mentioned bootloader is configured with: .  But when you manage to boot it, you actually find this UUID under \"/dev/disk/by-uuid\": .  Furthermore, that's even listed in \"/proc/cmdline\" of the successful boot (I'm assuming it's the one with SuperGrub USB): .   \"/proc/cmdline\" output .   The two UUIDs are different. PARTUUID= is the UUID that will be found in the GPT partition table (that's why it's called \"PART\", because it's a property of the partition, recorded in the partition table), while UUID= is a UUID recorded in the filesystem (ext4, or xfs, or whichever filesystem you formatted the partition with) and Linux is able to read those while scanning the disks. .  So, it looks like you need to fix your boot options to use UUID= instead of PARTUUID=, since the UUID you have is a filesystem UUID and not a partition UUID. .  Edit file \"/boot/efi/loader/entries/debian.conf\" and replace the last line with: .  That should fix your issue! .  Make sure your \"/etc/fstab\" in the system also matches the correct tag. .  You can also use the \"blkid\" command to inspect the UUIDs present in your partitions and filesystems. This might help you confirm that you have the correct kind of UUID. .  For instance, using \"blkid -o export\" should display something like: .  That should help you see all UUIDs with a tag that is recognized by Linux. .  ",
      "P-tags": "systemd-boot linux systemd debian boot",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_257039",
      "task": "Breaking out of a loop, return to start of loop with correct value of variable",
      "P-task": "break loop return start loop correct valu variabl",
      "F_verb": "return",
      "P-body": "A simple solution is to change your logic slightly: .  This way, \"$i\" will only be incremented when a job was submitted. If the server is full, the script will wait 10 minutes and repeat with the same value of \"$i\".  .  ",
      "P-tags": "shell-script shell bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V to NP of NP with NP of NP"
    },
    {
      "id": "au_995223",
      "task": "Ubuntu 16.04 not detecting external HDMI monitor",
      "P-task": "ubuntu 16 04 detect extern hdmi monitor",
      "F_verb": "monitor",
      "P-body": "Annoyingly, I stumbled to the solution while trying to fix the problem. I run gnome3 on this machine, and in and attempt to fix the problem with this:  .  \"sudo apt-get install xserver-xorg-video-intel xorg-video-abi-20 xserver-xorg-core\" .  and it removed \"ubuntu-gnome-desktop\" and many \"xorg\" drivers... so when I rebooted, the keyboard and mouse did not work. I booted into a live CD, mounted and \"chroot\" to the main partition and removed \"xserver-xorg-video-intel\" and reinstalled \"ubuntu-gnome-desktop\" and all the \"xorg\" drivers came along with it.  .  When I rebooted, back to the main partition, I had return functionality to the keyboard and mouse and the external monitor worked too. .  ",
      "P-tags": "intel-graph 16 04",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V"
    },
    {
      "id": "ul_61390",
      "task": "How to write a systemd .service file running systemd-tmpfiles",
      "P-task": "write systemd servic file run systemd-tmpfil",
      "F_verb": "write",
      "P-body": "[This does not directly address the issue of systemd-tmpfiles but I think you have already recognized that in this particular case you are better off just using echo.] .  First up, \"multi-user.target\" may or may not be what you want to use. If you are familiar with the concept of runlevels from SysV style init stuff, multi-user is the systemd equivalent of runlevel 3, which is a multi-user system that boots to a console, not a GUI. The equivalent of runlevel 5, which boots to X, is graphical.target. The default is determined by a symlink in \"/etc/systemd/system\" (and/or \"/lib/systemd/system\"; the one in \"/etc\" will overrule the one in \"/lib\") called default.target, use ls to find where it points: .  \"systemctl get-default\" will tell you \"multi-user.target\" in this case. For normal linux desktops it will be graphical.target. This is actually not important if you want the boot service you are creating to start regardless of what the default runlevel/target is -- in that case, we can just use default.target, and not worry what it is an alias for. If you use multi-user, however, and your default is graphical, your service won't happen. .  Depending on the service, there may be more appropriate and specific targets or services that you want to start this one in relation to. Based on your other question, default.target is probably fine. As a note, the difference between a \"target\" and a \"service\" is that a service contains a \"[Service]\" section which actually runs a process; a target is just a way of grouping services together via the various \"depends\" and \"requires\" directives; it doesn't do anything of its own beyond triggering other targets or services. .  When a service starts is determined by what other services explicitly depend on it. In the case of a simple, stand-alone event like this that we want run late in the boot process, we can use this combination of directives: .  The \"Install\" section is used when the service is installed. \"WantedBy=\" specifies a target we want this service to be included with, meaning it will run if that target does. If you don't have specific dependencies, getting the unit to run later rather than sooner may be a matter of looking at what's going on normally and picking something to use as a dependency or prerequisite.  .  To distinguish: By dependency I mean something which your unit requires to also be activated, and by prerequisite I mean something that should run before your unit if it is being used, but it is not required. Those terms are mine, but this is an important distinction used in the systemd documentation, particularly in the sense that a required dependency is guaranteed to be started if your unit is, but this requirement does not influence the order in which they are started, meaning, something that is just a dependency may actually be started afterwards (and yes, since that means your unit may be started first, the dependency is not guaranteed to succeed).  .  Above, \"Requires\" on \"local-fs.target\" may be a bit pointless unless you think your unit is going to be used on a system where it might not be included otherwise, but combining it with \"After\" means your unit is guaranteed to be started after it is -- so you could do without the \"Requires\" (you can set a unit to start after a unit that it doesn't depend on). The example here is just to introduce the concepts and the distinction between dependency and order of execution: One does not determine the other. .  Note that \"started after\" still doesn't mean the prereq will have reached any particular point it its own execution. Eg., if it is about mounting remote filesystems and you this is important to your unit, you will want to use \"Requires\" and probably \"After\" the service that establishes that but you still need the actual process you are executing to do proper error handling in case the remote filesystems are not yet accessible (eg., by sleeping in a loop until they are). .  For the example, I'll just echo \"hello world\" to the console. The service itself is described in the \"[Service]\" section: .  The command needs a full path. The reason I did not just use \"/usr/bin/echo \"hello world\"\" is that it won't work (the output goes to /dev/null, I think), and while a service that does an \"echo \"hello world\" > /dev/console\" will, experimentation demonstrates that using shell redirection in an ExecStart directive won't, because the \"ExecStart\" command isn't run by a shell. But you can make so: /usr/local/bin/helloworld is a shell script with that one line, \"echo \"hello world\" > /dev/console\".1 .  Note the \"Type=simple\". This is fine for what \"helloworld\" does, but if you have something that is going to take more than a second or so, you should fork it to the background first (eg., via \"&\" in a start-up script) and use \"Type=forking\". The \"Type\" param is covered in detail in \"man systemd.service\" and you should read that part regardless of what you are trying to do. .  Our complete, minimal service file is just those three sections (\"[Unit]\", \"[Service]\", and \"[Install]\"). To install, place the file or a symlink to it in either /etc/systemd/system or /usr/lib/systemd/system, and: .  It should print \"ln -s ...\". This does not run the service, it just configures it to run at boot as discussed above. .  That's it in a nutshell. \"man systemd.unit\" and \"man systemd.service\" have more details (BTW, there's an index for all these things in \"man systemd.directives\"). .    You can redirect output using \"StandardOutput\" and \"StandardError\" parameters in the \"[Service]\" block, see \"man systemd.exec\".   ",
      "P-tags": "arch-linux systemd",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_1425706",
      "task": "How to obtain motherboard and processor unique identifiers in Mono under Linux?",
      "P-task": "obtain motherboard processor uniqu identifi mono linux",
      "F_verb": "obtain",
      "P-body": "The typical approach from the command line is using dmidecode or lshw, which read the BIOS DMI area, and parse the serial numbers. However, this won't work if your application doesn't run as root, since it needs to be able to read /dev/mem. .  You can get some of this information through HAL. I'm not entirely sure how to do this through HAL directly, but you can do it through the lshal command. Under one of the devices shown, you should see an entry for \"system.hardware.serial\" and \"system.hardware.uuid\" - those are the motherboard's serial number and UUID. .  You can query HAL from Bash like this: .  On older machines, those keys might be \"smbios.system.uuid\" and \"smbios.system.serial\" instead. Also, be aware that this information may not exist on all machines, or make be entirely fake. I have at least one motherboard here with a UUID consisting entirely of 1's, and another with a CPU serial number that's almost entirely zeroes. .  ",
      "P-tags": "linux c mono",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_695510",
      "task": "How to permanently start kodi with ALSA?",
      "P-task": "perman start kodi alsa",
      "F_verb": "start",
      "P-body": "First we will add your command to a bash script .  Open gedit and paste this into a new document .  Now save this to your /home as \"kodi.sh\". .  Now right click this file and go to properties then permissions and check allow executing file as a program .  Now make another new text file and paste this in to it YOU MUST CHANGE USER IN THE \"EXEC\"LINE TO YOUR USER NAME or it wont work .  Save it as whatever and where ever you like but end it with \".desktop\". .  Now right click this file and go to \"properties\" then \"permissions\" and check \"allow executing file as a program\".  .  You can add a comment in the \"comment\" section of the script or an custom icon via the \"icon\" parameter. .  When you click the .desktop file, the command in \"kodi.sh\" will be executed.  .  You can add the .desktop file to the launcher by simply dragging and draping it on there. .  ",
      "P-tags": "kodi alsa pulseaudio",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP with NP"
    },
    {
      "id": "au_1280039",
      "task": "Which install or configuration changes into LTS make it lose its LTS essence?",
      "P-task": "instal configur chang lt make lose lt essenc",
      "F_verb": "make",
      "P-body": "Don't confuse support and stability. .  LTS releases offer \"stability\" in the sense that the software does not change for 5 years, not the sense that it crashes less often. The latter coincidentally does happen to be somewhat true also, but that's due to the large user base discovering and filing bugs. .   The best way to keep any release of Ubuntu operating stably (less likely to crash) is to stick to the Ubuntu repositories and Snaps when installing software. .  The easy way to make an LTS install unstable (more likely to crash) is to install a lot of non-Ubuntu, PPA, and/or wrong-version software onto it. These are, of course, exactly the same ways that you get dependency problems. .  A common problem occurs when folks mistakenly consider an LTS to be a \"stable base system\" that they can bolt newer software onto. This is precisely the opposite of what an LTS is designed for. If you want newer software, use a newer release of Ubuntu. The Interim (6-month) releases are just as stable for most users as LTS... AND have newer kernel and software. .   For a command that details how far from any release (including LTS) that you have drifted, try \"ubuntu-security-status\" .  Here you can see that I have 14 packages to investigate out of 2258 packages on the system (0.6%). Try it: The output includes instructions on how to get more detail on each category. .  ",
      "P-tags": "support configur package-manag software-instal lt",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_1170395",
      "task": "Virtual box not install on UBUNTU 16/18 with i686 cpu",
      "P-task": "virtual box instal ubuntu 16 18 i686 cpu",
      "F_verb": "install",
      "P-body": "Finally I solve the problem with .   Remove old virtual box: \"sudo apt remove virtualbox\" .   Download virtualBox 5 from this link .   run in terminal \"sudo dpkg -i virtualbox-5.2_5.2.32-132073~Ubuntu~xenial_i386.deb\" .    Thank you \"ajgringo619\" for helpful comment. .  ",
      "P-tags": "kernel virtualbox intel",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V on NP with NP"
    },
    {
      "id": "so_30567791",
      "task": "How to count files in FTP directory",
      "P-task": "count file ftp directori",
      "F_verb": "count",
      "P-body": "The \"$list\" contains: .  If you split the string by \"`n\", you (correctly) get four parts, with the last one being empty. .  You can use an overload of \"String.Split\" that takes \"StringSplitOptions\" and use \"RemoveEmptyEntries\": .  ",
      "P-tags": "ftpwebrequest powershel string-split ftp",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP"
    },
    {
      "id": "so_17959193",
      "task": "Match and replace digits with sed in specific lines",
      "P-task": "match replac digit sed specif line",
      "F_verb": "replace",
      "P-body": "You cannot use sed like that. You need to use multiple sed replacements with \"-e\" switch like this: .  Update: Though awk doesn't support inline editing I believe using awk will be much cleaner for this task. Consider below awk command: .  ",
      "P-tags": "awk replac pattern-match bash sed",
      "cate": "replace",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_8598525",
      "task": "Can anyone help me in find the number of xml tag occurences using awk or sed",
      "P-task": "anyon help find number xml tag occur use awk sed",
      "F_verb": "find",
      "P-body": "Regular expressions are a bad way to parse XML, using some sort of XML parser is better. .  If you really want to use sed/awk/shell/grep etc, the first thing I can think of is: .  I don't know awk very well, but I'm sure there are awk ninjas out there who can do it more elegantly than this.  .  It only counts occurences of \"<Code>\" (& variations) but not the closing tag, so if you have (for example) 10 \"<Code>\" in your file but only 9 \"</Code>\", it will return 10 and not 9. .  Basically:  .   \"cat tst | xargs\" cats 'tst' to the shell all on one line (so I don't have to worry about new lines); \"grep -o '<\\s*C\\s*o\\s*d\\s*e[^>]*>'\" prints all matches of \"<Code{optional other stuff}>\" where you can have newlines/spaces in between all letters of \"Code\" (the \"-o\" prints just the matches to the regex, one per line); \"wc -l\" counts the lines.  Try each bit successively to see what I mean. .  For me \"tst\" was just a copy-paste of what you have above. .  ",
      "P-tags": "sed awk shell",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP using NP"
    },
    {
      "id": "so_26680901",
      "task": "Run a script on multiple files using numbers in their names",
      "P-task": "run script multipl file use number name",
      "F_verb": "run",
      "P-body": "You might do this: .  ",
      "P-tags": "file sh shell",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP using NP in NP"
    },
    {
      "id": "ul_467055",
      "task": "Bad IP route after restart network",
      "P-task": "bad ip rout restart network",
      "F_verb": "restart",
      "P-body": "Check your \"eth0:23\" configuration.  .  Its address overlaps with \"10.128.0.0/9\" so it looks to the system as directly connected. That's why the system won't let you add a route through the default gateway! .  You can see by \"route -n\" that the gateway is \"0.0.0.0\", which means directly connected, so the line .  cannot be execute (it probably gives an error in some log file, too). .  Obviously, when you explicitly delete the route, then the system lets you add a route via the default gateway as it no more have another route (the directly connected one) in its tables. .  To fix this, you have to delete the \"eth0:23\" interface, as 10.128.0.0/9 it's not a connected network and you shouldn't have an IP address on that machine. .  ",
      "P-tags": "iprout linux rhel network network-interfac",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "ul_20400",
      "task": "Change the order of displayed fields of arbitrary command output",
      "P-task": "chang order display field arbitrari command output",
      "F_verb": "change",
      "P-body": "For a fixed number of fields you can use \"awk\", for example to exchage second and fourth field: .  But unfortunately \"ls -l\" does not have a fixed number of field (separated by spaces) because also filenames can contain spaces: this is the reason why parsing \"ls -l\" output is discouraged. .  ",
      "P-tags": "text-process",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP of NP"
    },
    {
      "id": "su_1305704",
      "task": "Find and copy folders recursively but keep the structure",
      "P-task": "find copi folder recurs keep structur",
      "F_verb": "find",
      "P-body": "\"cd\" into \"foo\" and run .  It will invoke the \"echo\" command for each \".svn\" directory under \"foo\" and produce output like this: .  Verify that this is correct \u2014 you can replace \"../bar\" with \"~/bar\" if you want \u2014 and then run the \"find\" command again without the \"echo\": .  This will actually copy the directories. .  ",
      "P-tags": "shell linux command-lin bash",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_619814",
      "task": "Why do bind mounts of device nodes break with EACCES in root of a tmpfs?",
      "P-task": "bind mount devic node break eacc root tmpf",
      "F_verb": "bind",
      "P-body": "Well, this seems to be a very interesting effect, which is a consequence of three mechanisms combined together. .  The first (trivial) point is that when you redirect something to the file, the shell opens the target file with the \"O_CREAT\" option to be sure that the file will be created if it does not yet exist. .  The second thing to consider is the fact that \"/tmp/x\" is a \"tmpfs\" mountpoint, while \"/tmp/x/y\" is an ordinary directory. Given that you mount \"tmpfs\" with no options, the mountpoint's permissions automagically change so that it becomes world-writable and has a sticky bit (\"1777\", which is a usual set of permissions for \"/tmp\", so this feels like a sane default), while the permissions for \"/tmp/x/y\" are probably \"0755\" (depends on your \"umask\"). .  Finally, the third part of the puzzle is the way you set up the user namespace: you instruct \"unshare(1)\" to map UID/GID of your host user to the same UID/GID in the new namespace. This is the only mapping in new namespace, so trying to translate any other UID between the parent/child namespaces will result in so-called overflow UID, which by default is \"65534\" \u2014 a \"nobody\" user (see \"user_namespaces(7)\", section \"Unmapped user and group IDs\"). This makes \"/dev/null\" (and its bind-mounts) be owned by \"nobody\" inside the child user namespace (as there is no mapping for host's \"root\" user in the child user namespace): .  Combining all the facts together we come to the following: \"echo > /tmp/x/null\" tries to open an existing file with \"O_CREAT\" option, while this file resides inside the world-writable sticky directory and is owned by \"nobody\", who is not the owner of the directory containing it. .  Now, read \"openat(2)\" carefully, word by word: .   EACCES .  Where O_CREAT is specified, the protected_fifos or protected_regular sysctl is enabled, the file already exists and is a FIFO or regular file, the owner of the file is neither the current user nor the owner of the containing directory, and the containing directory is both world- or group-writable and sticky. For details, see the descriptions of /proc/sys/fs/protected_fifos and /proc/sys/fs/protected_regular in proc(5). .   Isn't this brilliant? This seems almost like our case... Except the fact that the man page tells only about ordinary files and FIFOs and tells nothing about device nodes. .  Well, let's take a look at the code which actually implements this. We can see that, essentially, it first checks for exceptional cases which must succeed (the first \"if\"), and then it just denies the access for any other case if the sticky directory is world-writable (the second \"if\", first condition): .  So, if the target file is a char device (not a regular file or a FIFO), the kernel still denies opening it with \"O_CREAT\" when this file is in the world-writable sticky directory. .  To prove that I found the reason correctly, we may check that the problem disappears in any of the following cases: .   mount \"tmpfs\" with \"-o mode=777\" \u2014 this will not make the mountpoint have a sticky bit; open \"/tmp/x/null\" as \"O_WRONLY\", but without \"O_CREAT\" option (to test this, write a program calling \"open(\"/tmp/x/null\", O_WRONLY | O_CREAT)\" and \"open(\"/tmp/x/null\", O_WRONLY)\", then compile and run it under \"strace -e trace=openat\" to see the returned values for each call).  I'm not sure whether this behavior should be considered a kernel bug or not, but the documentation for \"openat(2)\" clearly does not cover all the cases when this syscall actually fails with \"EACCES\". .  ",
      "P-tags": "mount linux namespac bind-mount",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP of NP with NP in NP of NP"
    },
    {
      "id": "su_162018",
      "task": "How to stop redirection to /dev/pts/x",
      "P-task": "stop redirect dev pt x",
      "F_verb": "stop",
      "P-body": "I'm not sure whether this would have unintended consequences, but what about \"chmod a-w /dev/pts/*\"? I ran a little test on my computer and it seemed to have the desired effect of preventing writes to the device, without disabling the terminal window. Your mileage may vary. .  Alternatively, assuming each user is logged in under a different username, \"chmod go-w /dev/pts/*\" should do it and that's probably safer. Or equivalently, \"chmod 0600 /dev/pts/*\") .  P.S. At first I was tempted to suggest \"cat /dev/urandom > /dev/pts/x\" but that'd just make a mess ;-) .  ",
      "P-tags": "redirect linux redhat-enterprise-linux bash",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP to NP"
    },
    {
      "id": "so_19223963",
      "task": "SELinux: cannot restore segment prot after reloc: Permission denied",
      "P-task": "selinux : restor segment prot reloc : permiss deni",
      "F_verb": "restore",
      "P-body": "I have found this: http://akkadia.org/drepper/textrelocs.html, which basically boils down to a suggestion to use \"eu-findtextrel\" to see what text relocations do exist. Recompiling affected libraries with \"-fPIC\" then fixes the problem. .  ",
      "P-tags": "c++ linux reloc selinux",
      "cate": "restore/recover/resume",
      "pat": "V NP after NP"
    },
    {
      "id": "so_41074669",
      "task": "How to count lines if only the first 6 characters is different?",
      "P-task": "count line first 6 charact differ",
      "F_verb": "count",
      "P-body": "You can use a \"Select-Sting\" to extract your text and then a \"Group-Object\" to do the counting. Something like this: .  ",
      "P-tags": "array powershel count line",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP if S"
    },
    {
      "id": "so_21164334",
      "task": "Calling to restart a \"service\" in Linux from Python script not working from within crontab entry",
      "P-task": "call restart servic linux python script work within crontab entri",
      "F_verb": "restart",
      "P-body": "It turns out that it is indeed path related. .  Path Information for Cronjobs  Commands in submodules .  To solve it I provided the following entries via \"crontab -e\" .  Now my service restarts as expected. Yay! .  ",
      "P-tags": "linux python crontab",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP from NP from NP"
    },
    {
      "id": "so_30214560",
      "task": "How to insert a BASH variable into a PERL regex replacement?",
      "P-task": "insert bash variabl perl regex replac",
      "F_verb": "insert",
      "P-body": "Just replace the single quotes around the regexp with double quotes. .  Single quotes do not expand the variable. .  ",
      "P-tags": "bash perl shell regex",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_50745977",
      "task": "How to pipe the each output of grep to another command?",
      "P-task": "pipe output grep anoth command",
      "F_verb": "grep",
      "P-body": "\"xargs\" has \"-I<STRING>\" that will be replaced before running the command, in your case would be e.g.: .  ",
      "P-tags": "xarg grep shell",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V to NP"
    },
    {
      "id": "ul_390716",
      "task": "Spacewalk Install failed selinux",
      "P-task": "spacewalk instal fail selinux",
      "F_verb": "install",
      "P-body": "I have ignored the SeLinux errors, downgraded c3p0 from version 9.5 to 9.1, ran \"rhn-satellite restart\" and have now logged in to spacewalk. I also went in to vi \"/etc/sysconfig/network\" and added a \"HOSTNAME=my.spacewalk.server\" entry. .  ",
      "P-tags": "cento spacewalk selinux",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_6115544",
      "task": "Interpret a Hudson job as successful even though one of the invoked programs fails",
      "P-task": "interpret hudson job success even though one invok program fail",
      "F_verb": "interpret",
      "P-body": "You were very close! Here's the corrected version of what you were trying: .  This now does what you asked for, but isn't perfect. I'll get to that later. .  Note the tiny important change from your version - we are now being explicit that we should exit with code 0 (success), if the bzr command does not do so. In your version, exit (with no argument) will terminate your script but return the exit code of the last command executed - in this case the bzr commit. .  More about exit .  How do we find out about this behaviour of exit? The \"exit\" command is a shell built-in - to find documentation on it we use the help command: .  Which on my machine tells me: .  Here's a decent tutorial on exit and exit codes in the bash shell .  Hudson and exit codes .  Hudson follows this common convention of interpreting exit code 0 as success, and any other code as failure. It will flag your build as a failure if the build script it executes exits with a non-zero code. .  Why your script is stopping after the bzr commit .  If, as you say, you have the following and your script is stopping after the bzr commit... .  ... I suspect your script has an instruction such as \"set -e\" or is being invoked with something like \"bash -e build_script.sh\" .  Either of these tells the shell to exit immediately if a command exits with a non-zero status, and to pass along that same \"failure\" exit code. There are subtleties - see footnote 1). .  Disabling exit-on-error .  While this behaviour of exiting on error is extremely useful, sometimes we'd like to disable it temporarily. You've found one way, in  .  We can also disable the error-checking with set +e.  .  Here's a pattern you may find useful. In it we will: .   Disable exit-on-error (with \"set +e\") run the command which may error \"bzr commit whatever\" capture its exit code ($?) for later inspection Re-enable exit-on-error (with \"set -e\") Test and act upon the exit code of any commands  Let's implement that. Again we'll exit 0 (success) if the bzr command failed. .  Note that we bracket as little as possible with set +e / set -e. If we have typos in our script in that section, they won't stop the script and there'll be chaos. Read the section \"Avoiding set -e\" in the post \"Insufficiently known POSIX shell features\" for more ideas. .  What's wrong with \"foo || exit 0\" ? .  As I mentioned earlier, there's a problem with our first proposed solution. We've said that when \"bzr commit\" is non-zero (i.e. it doesn't commit normally) we'll always stop and indicate success. This will happen even if \"bzr commit\" fails for some other reason (and with some other non-zero exit code): perhaps you've made a typo in your command invocation, or bzr can't connect to the repo. .  In at least some of these cases, you'd probably want the build to be flagged as a failure so you can do something about it. .  Towards a better solution .  We want to be specific about which non-zero exit codes we expect from bzr, and what we'll do about each. .  If you look back at the set +e / set -e pattern above, it shouldn't be difficult to expand the conditional logic (if) above into something that can deal with a number of specific exit codes from bzr, and with a catch-all for unanticipated exit codes which (I suggest) fails the build and reports the offending code and command. .  To find out the exit codes for any command, read the docs or run the command and then run \"echo $?\" as the next command. $? holds the exit code of the previous command. .  Footnote 1: The exit-on-error behaviour switched with set -e has some subtleties you'll need to read up on, concerning behaviour when commands are in pipelines, conditional statements and other constructs. .  ",
      "P-tags": "hudson bazaar bash",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP as NP of NP"
    },
    {
      "id": "su_1564615",
      "task": "gvim 8.2 doesn't paste on windows 10 in powershell",
      "P-task": "gvim 8 2 past window 10 powershel",
      "F_verb": "paste",
      "P-body": "https://n3wjack.net/2014/08/25/setting-up-vim-on-windows/ has the answers. .  Open \"vim\" and type the following: .  This will edit your \".vimrc\" file wherever it might live. On my system, it was in \"c:\\Users\\<my_username>\\.vimrc\", but you might have weird configuration issues, so just let \"vim\" find the file for you. .  Then, copy+paste the following into the file: .  Then save the file. .  ",
      "P-tags": "gvim powershell-5 0 vim windows-10",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V on NP in NP"
    },
    {
      "id": "so_5052345",
      "task": "How to improve performance of File::Find::Rule calls?",
      "P-task": "improv perform file : :find : :rule call",
      "F_verb": "find",
      "P-body": "I suspect that the delay you are seeing is due to the length of time it takes to produce all the results. Sure, if you pipe your \"find\" command into \"less\", you get results immediately, but if you pipe it into \"tail\" you might see a delay similar to what you see with your Perl script. .  In both your alternative implementations, you are creating an array with a list of all matching files - your code will not continue on until the file matching process is complete. .  You could alternatively use an iterator approach like this: .  For completeness, you could achieve a similar result with the find command. Instead of using backticks, you could explicitly use a pipe and read results one at a time: .  Note that with both these examples, your code can start processing results as soon as the first match is found. However, the total time taken until the last result is processed shouldn't be much different to your original code. .  ",
      "P-tags": "posix unix file perl find",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "su_977693",
      "task": "How can I make unix sort work properly using the underscore as a field separator?",
      "P-task": "make unix sort work properli use underscor field separ",
      "F_verb": "make",
      "P-body": "Use .  As the sort manual states: .  ",
      "P-tags": "sort unix",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_21368438",
      "task": "Linux utility program to write a matlab .mat file",
      "P-task": "linux util program write matlab mat file",
      "F_verb": "write",
      "P-body": "This is not exactly what you want, but it may be equivalent: In Matlab you can load an ASCII file (like that in your example) using .  where \"name\" is a string containing the file name. The file contents are read into a Matlab variable with the same name as the file. .   If you need several variables in the same file, you could write the ASCII file as .  (that is, add variable names and \"[\", \"]\", \";\" signs), and then run it from Matlab. .  ",
      "P-tags": "matlab linux",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_23032296",
      "task": "Kill bash and child process",
      "P-task": "kill bash child process",
      "F_verb": "kill",
      "P-body": "It will send a SIGTERM to the Process Group ID passed in parameter and to all children. .  Also, more answers on this post : Best way to kill all child processes .  ",
      "P-tags": "linux signal c bash",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "so_43984676",
      "task": "Turn file of 3 columns into a matrix",
      "P-task": "turn file 3 column matrix",
      "F_verb": "turn",
      "P-body": "\"awk\" to the rescue! .  ",
      "P-tags": "awk matrix shell bash",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP"
    },
    {
      "id": "so_47703369",
      "task": "Delete line containing pattern found anywhere in another file",
      "P-task": "delet line contain pattern found anywher anoth file",
      "F_verb": "delete",
      "P-body": "If I understand correctly, you want to exclude from the first file lines that would match any IP address in the second file. .  This simple and admittedly a bit lazy solution might be good enough for your purpose: .  The Awk extracts the 3rd column with IP addresses, and \"grep\" will use those as fixed patterns (\"-F\") and only match complete words (\"-w\"). .  If the IP address is not always the 3rd column, then you could extract them by using pattern matching with \"grep\", as @tripleee suggested: .  ",
      "P-tags": "awk grep linux bash sed",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "so_7613202",
      "task": "How to strip the & symbol from only the URLs in a file?",
      "P-task": "strip symbol url file",
      "F_verb": "strip",
      "P-body": "If you're happy to install BeautifulSoup, this simple Python script may do what you want: .  Example usage: .  Caveat: Since we're regenerating the output HTML based on a parsed representation of it, the formatting may change. Other possible changes include the explicit closing of tags if your markup is not well formed. .  I may be wrong, but I suspect most solutions that use a proper XML/HTML parser will result in similar issues. To maintain the file exactly as it is and only remove the offending chars, you will have to end up using regex-based search and remove/replace. Many will advice against parsing XML/HTML with regex except for really trivial patterns. In your case, that may be true, but I'm yet to be convinced. .  ",
      "P-tags": "awk linux sed",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_40666457",
      "task": "Add Text to an XML element",
      "P-task": "add text xml element",
      "F_verb": "add",
      "P-body": " to work with files: .  UPD01: If you want to import one XML to another XML, both must be XMLs .  ",
      "P-tags": "powershel xml",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "au_937731",
      "task": "Rsync don't copy .BAK files",
      "P-task": "rsync copi bak file",
      "F_verb": "copy",
      "P-body": "If you use \"-C\" option with \"rsync\" then it initializes an exclude list which contains \".BAK\" files along with many others. You can use \"man rsync\" and look at what all is excluded by the \"-C\" option. .  If you want to copy the \".BAK\" files remove the above mentioned option from your command. Although, Note that this will mean that anything which was previously excluded due to this option will also be copied. .  Thus your new command would be : .  \"sudo rsync -ravp --delete /home/administrador/ArquivosAL/ /media/administrador/Seagate\\ Expansion\\ Drive/Backup\" .  ",
      "P-tags": "rsync",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP"
    },
    {
      "id": "so_21099041",
      "task": "Why do we cast sockaddr_in to sockaddr when calling bind()?",
      "P-task": "cast sockaddr_in sockaddr call bind",
      "F_verb": "cast",
      "P-body": "No, it's not just convention. .  \"sockaddr\" is a generic descriptor for any kind of socket operation, whereas \"sockaddr_in\" is a struct specific to IP-based communication (IIRC, \"in\" stands for \"InterNet\"). As far as I know, this is a kind of \"polymorphism\" : the \"bind()\" function pretends to take a \"struct sockaddr *\", but in fact, it will assume that the appropriate type of structure is passed in; i. e. one that corresponds to the type of socket you give it as the first argument. .  ",
      "P-tags": "linux c socket",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP when S"
    },
    {
      "id": "ul_343211",
      "task": "Add another sub-level to KDE-Submenu in Dolphin actions/services?",
      "P-task": "add anoth sub-level kde-submenu dolphin action servic",
      "F_verb": "add",
      "P-body": "After investigating a bit more I dare say the answer is probably NO. .  The Nautilus sub-menus created through settings in nautilus action configuration tool are based on \".desktop\" files created in \"/.local/share/file-manager/actions\". But while the lowest levels (the actions themselves) are normal desktop actions, the intermediary sub-menus (that can go on numerous levels and can be multiplied many times through the nautilus action configuration tool) are not such normal desktop files, but contain Gconf settings. .  A Nautilus normal action is a desktop file that contains the line \"Type=Action\"; the multipliable menus are desktop files that contain the line \"Type=Menu\", but also a line like \"ItemsList=495e5ac1-e34b-4570-b7e2-fb2188410dff;034e7ec6-32f8-4538-956b-624e421593ac;c2ee726a-bda0-4e36-96db-e8cfaa7c83d6;f519ea3d-6937-457e-baf9-4a9dcd586062;\", which is the Gconf setting. .  I guess that is not doable in KDE and Dolphin. .  ",
      "P-tags": "dolphin desktop servicemenu kde5",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "ul_152479",
      "task": "How can I parse my String using regular expression to get only certain number of matches?",
      "P-task": "pars string use regular express get certain number match",
      "F_verb": "get",
      "P-body": "You don't specify any tools, so I use \"perl\" as example: .  With regular expression capture group, you can use backreferences to get the previous matches. In \"perl\", you can use \"$1\", \"$2\",...,\"$n\". .  In your case, you can use a non-capturing group to prevent \"[R=4]\" from being captured: .  As you mentioned \"php\" in your comment, you can use php backreference syntax \"\\1\" or \"\\g1\" or \"\\g{1}\". .  ",
      "P-tags": "regular-express",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_251392",
      "task": "dump with old 43BSD,question about tape size",
      "P-task": "dump old 43bsd question tape size",
      "F_verb": "dump",
      "P-body": "Solution found First rewind tape .  then pass arguments as this .  for 2GB 4mm tape .  ",
      "P-tags": "dump bsd",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V with NP about NP"
    },
    {
      "id": "ul_463708",
      "task": "Uninstall a Steam game with the console",
      "P-task": "uninstal steam game consol",
      "F_verb": "uninstall",
      "P-body": "You can use \"steamcmd\" for this (it\u2019s packaged in Debian\u2019s non-free repositories and in Ubuntu\u2019s multiverse): .  will list all installed applications with their id, and .  will uninstall the application matching the given id; add \"-complete\" before the id for a complete uninstall. .  ",
      "P-tags": "termin ubuntu shell-script steam",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_52590",
      "task": "Re-installing Windows 7 on a dual boot system with Fedora",
      "P-task": "re-instal window 7 dual boot system fedora",
      "F_verb": "boot",
      "P-body": "Simply reinstall Windows 7 and recover the GRUB. Technique for recovering of GRUB bootloader is Luckily covered in Fedora Manual: .   In many cases, the GRUB boot loader can mistakenly be deleted, corrupted, or replaced by other operating systems. .  The following steps detail the process on how GRUB is reinstalled on the master boot record: .   Boot the system from an installation boot medium. Type \"linux rescue\" at the installation boot prompt to enter the rescue environment. Type \"chroot /mnt/sysimage\" to mount the root partition. Type \"/sbin/grub-install *bootpart*\" to reinstall the GRUB boot loader, where \"*bootpart*\" is the boot partition (typically, \"/dev/sda\"). Review the \"/boot/grub/grub.conf\" file, as additional entries may be needed for GRUB to control additional operating systems. Reboot the system.   ",
      "P-tags": "dual-boot window fedora system-instal",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP with NP"
    },
    {
      "id": "so_26555814",
      "task": "Using os.system() in python to execute linux command",
      "P-task": "use os system python execut linux command",
      "F_verb": "execute",
      "P-body": "You've already identified the problem: the emails have ^M characters in them that you're not expecting. CR LF is a common line ending convention; Unix usually does not like the CR). .  Try removing \"\\r\" from your command: \"command = command.translate(None, \"\\r\")\". .  I also urge you to carefully consider the security implications of running whatever commands are delivered by email. There is likely a much safer way to do what you're trying to accomplish. .  ",
      "P-tags": "linux os system imap ls python",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_483335",
      "task": "find and replace a substring and change to uppercase",
      "P-task": "find replac substr chang uppercas",
      "F_verb": "change",
      "P-body": " ",
      "P-tags": "string replac find",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V to NP"
    },
    {
      "id": "so_18553962",
      "task": "How do I verify SSL connection with a server through bash?",
      "P-task": "verifi ssl connect server bash",
      "F_verb": "verify",
      "P-body": "I'd suggest using the \"openssl s_client\" SSL client, which is intended for SSL debugging and has a large number of relevant command line flags (which you can probably read about by typing \"man s_client\", but that's somewhat distro-specific). In particular, look at the \"-verify\" and \"-showcerts\" options. .  ",
      "P-tags": "ssl bash",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP with NP through NP"
    },
    {
      "id": "so_29721383",
      "task": "iNotify how to detect move-out",
      "P-task": "inotifi detect move-out",
      "F_verb": "detect",
      "P-body": "You need to check for the \"IN_MOVED_FROM\" event and a following \"IN_MOVED_TO\" event. If the cookie is the same, the file has been renamed in the same folder. If you don't receive a \"IN_MOVED_TO\" event with the same cookie, the file has been moved outside of the watched folder. .  ",
      "P-tags": "linux c inotifi linux-kernel",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_2857629",
      "task": "An agenda in Korn Shell: New / Edit / Delete / View appointment",
      "P-task": "agenda korn shell : new edit delet view appoint",
      "F_verb": "edit",
      "P-body": "Here's some code that adds a script that runs at 7:30 AM to your crontab: .  Yours, Tom .  ",
      "P-tags": "ksh crontab shell",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "su_609387",
      "task": "pipe command's output to dialog and allow to scroll up",
      "P-task": "pipe command output dialog allow scroll",
      "F_verb": "scroll",
      "P-body": " \"--tailbox\" and \"--progressbox\" handle this well, except that if the output becomes too much, you can only see as much as the screen fits. .   That is not entirely correct. A \"--tailbox\" allows you to scroll left and right. But it does not allow you to scroll up and down, which is a pity. .  To work around this, you can provide the \"--tailbox\" with an \"--extra-button\" that triggers, e.g., a \"--textbox\". Then the \u201cExit\u201d button becomes an \u201cOK\u201d button, so you have to use \"--ok-label\" if you want to change its caption.) .  Closing the \"--textbox\" can either abort or return to the \"--tailbox\". In the following, it returns to the \"--tailbox\": .   Edit: I have found an example that purports to do this, but I honestly don't understand how it works or how to translate it to the example of \"find / -name \"a*\"\". see the last example on http://mywiki.wooledge.org/BashFAQ/040 .   Thank you very much for referring to that example. Finally I understand how \"--tailboxbg\" is supposed to work. .  However, by contrast to my approach, this example \u201cas is\u201d would not allow you to scroll the output (nor does it purport to do this). Also, here (dialog 1.3-20160828), no button is displayed in the \"--tailbox\", which by comparison is not user-friendly. .  The way it \"works\" is as follows: .  \u201cCreate an empty file \"dialog-tail.log\" so that the \"dialog\" below can display the file even if nothing has been written into it yet.\u201d .  \u201cWrite the numbers from 1 to 3 into the file \"dialog-tail.log\", each on its own line (\"\\n\"), one number per second (\"sleep 1\"), and do that in the background (\"&\").\u201d .  In your case, you would replace \"{ \u2026 }\" with \"find / -name 'a*'\". You might also want to redirect \"find\"\u2019s standard error stream. .  \u201cDisplay the file in a box at line 10, column 10, with title \u2018TAIL BOXES\u2019 as if by \"tail\"(1), but run that box in the background (\"--tailboxbg\" instead of \"--tailbox\"), so that an additional widget (\"--and-widget\") can be immediately displayed starting at line 3, column 10 (\"--begin 3 10\"; above the tail box). That widget is a \"--msgbox\" with text \u2018Press OK \u2019, height 5, and width 30.\u201d .  \u201cDo not execute the following commands until all child processes in the background have exited (here: the process that writes to the file, and \"dialog\").\u201d (RTFM, respectively) .  ",
      "P-tags": "bash",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP"
    },
    {
      "id": "ul_372749",
      "task": "Don't allow multiple keypresses after prefix in tmux",
      "P-task": "allow multipl keypress prefix tmux",
      "F_verb": "allow",
      "P-body": "The \"repeat-time\" option, at 500 milliseconds by default, controls how long to wait for the same command key, provided that key has been bound with \"bind-key -r\" option, which is the case for things like \"Down\": .  So you can either reduce the time or redo the bindings without \"-r\" .  ",
      "P-tags": "keyboard-shortcut tmux",
      "cate": "request/ask/allow",
      "pat": "V NP after NP in NP"
    },
    {
      "id": "au_374838",
      "task": "Is it recommended to install \"LTS Hardware Enablement Stack\" for Intel GMA-500 Issues?",
      "P-task": "recommend instal lt hardwar enabl stack intel gma-500 issu",
      "F_verb": "install",
      "P-body": "Since nobody answered, the only way to find out was to test the \"LTS Hardware Enablement Stack\" and see if it works or breaks ... .  I installed Raring's stack (kernal + Xorg) with the following command: .  And reboot ... .  The system booted fine and almost everything worked, even some-things that didn't work before, such as brightness controls. But one major problem showed up: with every other boot, Xorg consumed a lot of CPU capacity (about %25), and the system was super slow and laggy! I don't know what was the cause, but it was either a bug in Xorg or a bug in the kernel module for Intel GMA-500 graphics. .  So I thought to try Saucy's stack in hope of solving the problem, since it has a newer version of the Linux kernel. The thing is that the kernel-package of Saucy is available but not its X-stack. According to this link, it is not a good idea to use a kernel with a different X-stack but in my situation I had no other choice, so I gave it a try ... I installed Saucy's kernel with the following command, and Raring's X-stack remained: .  And reboot ... .  Everything worked fine! \":)\" Now all the problems of my Xubuntu-12.04 installation on the Sony VAIO P with Intel GMA-500 graphics are solved without the need for any tweaking: .   The screen works fine with the standard resolution and adequate performance; External VGA port works and secondary monitors are handled fine; Brightness controls work; Suspend/Resume works;  Now I'm a happy Xubuntu user on my Sony VAIO P which is way more faster and responsive than the standard Windows-7 which came pre-installed on it! .  Of course there is one limitation: the graphics performance on Linux is much lower than the performance on Windows. For example, I almost can't watch any kind of video format on Xubuntu, while all video files with resolutions below HD (720p) play fine in Windows ... Although this is a problem I can live with, it would be really great to sea this fixed in Ubuntu-14.04 LTS. .  Finally, my general recommendation is that if practical, do a fresh installation of the latest version of Xubuntu (which currently is 13.10 Saucy). When the next LTS version is released (14.04 Trusty) perform an upgrade or again do a fresh installation. But if your situation is like mine and you can't afford a fresh installation right now, installing Suacy's kernel with Raring's X-stack can fix a lot of problems. .  Update: Since the release of the 14.04 Trusty, the most recent LTS release, it is recommended to use its HES: .  ",
      "P-tags": "multiple-monitor kernel gma500 video-driv poulsbo",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP"
    },
    {
      "id": "au_1238924",
      "task": "Assign an icon to a custom mimetype",
      "P-task": "assign icon custom mimetyp",
      "F_verb": "assign",
      "P-body": "Nathaniel M. Beaver is right - this is the same question he already answered in Assign an icon to a custom mimetype - Unix & Linux .   The fix Use this XML file instead: .  and make sure you run \"xdg-icon-resource\" with .  not .  otherwise they'll go in the wrong folder. .  For example, if the icon is 48x48, the installation commands will look like this: .  Attempt at an explanation This is a strange one. It appears the difficulty is that when the mimetype is .  instead of .  it defaults to the generic text icon. This seems to depend on the file manager and desktop, though. .   ",
      "P-tags": "icon desktop-icon configuration-manag mime-typ gnome",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "so_27037854",
      "task": "lua c read nested tables",
      "P-task": "lua c read nest tabl",
      "F_verb": "read",
      "P-body": "You are not too far. The key here is to understand how the Lua API use the stack for everything. .  Here is an untested code sample which should get you going: .  I suggest you use those documentations: Lua API table Lua API ref .  ",
      "P-tags": "lua linux lua-tabl lua-api c",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_33638789",
      "task": "In a bash script, print command (as a suggestion) on the prompt after the script exit",
      "P-task": "bash script print command suggest prompt script exit",
      "F_verb": "prompt",
      "P-body": "Following the suggestion of Landen in the comments (thanks a lot!), I've been able to produce a workaround for my problem. .  This workaround needs the xautomation package (\"xte\" command, emulating key pressed), is not very robust, and may depends on the keyboard layout handling of xautomation, and system shortcuts. For example, I had to change the shortcut for the unity HUD. .  But given that my command is very fast, and that is is mostly for personal use, this solution fits perfeclty my needs: .  \"sleep 0.1\" and \"tput cub ${#COMMAND_PASSED}\" commands are needed to prevent the keys from being also displayed before the command prompt. .  \"sleep 0.1\" makes the whole command to be printed before the prompt.  .  \"tput cub ${#COMMAND_PASSED}\" move the cursor backward to make sure that all unnecessary prints are erased. .  Thanks everyone! .  ",
      "P-tags": "prompt linux command-lin bash",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V after S"
    },
    {
      "id": "so_36895479",
      "task": "Powershell - Trying to get a blank line when an error is present",
      "P-task": "powershel - tri get blank line error present",
      "F_verb": "get",
      "P-body": "Since you're saving to a variable you can't use \"Write-Host\", but you could return an empty string. \"Select primarysmptpaddress\" returns a \"pscustomobject\" with a \"primarysmtpaddress\"-property. Since we return a blank string on error, I would use \"-ExpandProperty primar...\" to only get the string value inside so we have the same type of object on success and failure. .  ",
      "P-tags": "powershel",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "so_44738396",
      "task": "awk: copy from A to B and output..?",
      "P-task": "awk : copi b output",
      "F_verb": "copy",
      "P-body": "With GNU awk for multi-char RS and RT: .  ",
      "P-tags": "awk sed bash",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V from NP to NP"
    },
    {
      "id": "ul_330579",
      "task": "How to get a name of older package?",
      "P-task": "get name older packag",
      "F_verb": "get",
      "P-body": "I'm not quite sure how you managed to install two versions of the same package, but this should do the job: .  The first line queries the RPM database for my-package-name, asking RPM to provide the results in a specific format -- the VERSION followed by the default \"rpm -qa\" fields. This is piped to \"sort -V\" to (attempt) to sort the version numbers, followed by a pipe to \"awk\" to print only the first line, stripping off the additional VERSION field, resulting in the \"rpm -qa\" default output. .  This makes the hopefully-safe assumption that you're running this on a RHEL system that has a \"-V\" flag for sort. .  ",
      "P-tags": "rpm rhel package-manag",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_147203",
      "task": "Ping multiple hosts and execute command",
      "P-task": "ping multipl host execut command",
      "F_verb": "execute",
      "P-body": "I've made some comments in line to explain what different parts of the script are doing. I've then made a concise version of the script below. .  If you need a parameter for each server, create an array of parameters and an index variable in the for-loop. Access the parameter via the index: .  ",
      "P-tags": "host shell ping",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_318962",
      "task": "How can I disable the \"No mail\" notice on text-based login sessions?",
      "P-task": "disabl mail notic text-bas login session",
      "F_verb": "disable",
      "P-body": "Edit the \"pam_mail\" line in the appropriate PAM configuration file. For local logins, this is \"/etc/pam.d/login\". For ssh, it is \"/etc/pam.d/sshd\". Note that this affects all users. By default it uses \"standard\", which does print a message if you have no mail. You can change it to \"quiet\" to only print if you do have mail. See the pam_mail manpage for full details. .  ",
      "P-tags": "12 04 email server",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP on NP"
    },
    {
      "id": "so_21198124",
      "task": "Emacs: How to use shell command prompt with emacs?",
      "P-task": "emac : use shell command prompt emac",
      "F_verb": "use",
      "P-body": "Sounds like you need to make sure that variable \"exec-path\" includes the directories where those commands (\"ls\" etc.) are located. .  That error message does not appear to be an Emacs error message (from the Emacs Lisp or C source code), but rather it seems to come from the shell that tries to execute your command. .  ",
      "P-tags": "emac shell",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_388039",
      "task": "How to install virtualbox on Antergos",
      "P-task": "instal virtualbox antergo",
      "F_verb": "install",
      "P-body": "The problem with the modules here is the running kernel. .  \"uname -r\" shows .  \"4.12.6-1\" .  and the installed kernel is  .  \"4.12.8-2\" so given the update, some modules have been erased from the system and it is necessary to reload them, the easiest way is to restart the system. .  ",
      "P-tags": "antergo virtualbox dkm",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_1729824",
      "task": "An efficient way to transpose a file in Bash",
      "P-task": "effici way transpos file bash",
      "F_verb": "transpose",
      "P-body": " output .  Performance against Perl solution by Jonathan on a 10000 lines file .  EDIT by Ed Morton (@ghostdog74 feel free to delete if you disapprove). .  Maybe this version with some more explicit variable names will help answer some of the questions below and generally clarify what the script is doing. It also uses tabs as the separator which the OP had originally asked for so it'd handle empty fields and it coincidentally pretties-up the output a bit for this particular case. .  The above solutions will work in any awk (except old, broken awk of course - there YMMV). .  The above solutions do read the whole file into memory though - if the input files are too large for that then you can do this: .  which uses almost no memory but reads the input file once per number of fields on a line so it will be much slower than the version that reads the whole file into memory. It also assumes the number of fields is the same on each line and it uses GNU awk for \"ENDFILE\" and \"ARGIND\" but any awk can do the same with tests on \"FNR==1\" and \"END\". .  ",
      "P-tags": "transpos pars unix bash",
      "cate": "flip/rotate/permute/swap/transpose/reverse/shuffle",
      "pat": "V NP in NP"
    },
    {
      "id": "so_18814825",
      "task": "Trying to obtain memberof detail from linux ldapsearch command",
      "P-task": "tri obtain memberof detail linux ldapsearch command",
      "F_verb": "obtain",
      "P-body": "The syntax looks OK, you need to use the full DN syntax for the \"memberOf\" query, and it's still \"memberOf=\", not \"memberOf:\" - if you use the colon syntax then you'll get the bad search filter error. .  The next thing is that you must escape the search string according to the specifications of RFC4515. This generally means that the following characters in the search string terms: \"\\\", \"*\", \"(\", and \")\" must be escaped using \"\\5c\", \"\\2a\", \"\\28\", \"\\29\" respectively, otherwise you get the same error - bad search term. This is on top of the escaping that the ldap server may have applied to the DN already. .  ",
      "P-tags": "ldap linux openldap active-directori",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_51130649",
      "task": "jq shell script: aggregate iteration content into json body",
      "P-task": "jq shell script : aggreg iter content json bodi",
      "F_verb": "aggregate",
      "P-body": "You don't need an \"awk\" statement inside the while loop, but just read the key value pairs inside the \"read\" command itself. .  Also storing \"awk\" output in a variable and later parsing is an anti-pattern. You could use the process substitution feature provided by the shell, the \"< <()\" part will slurp the output of a command as if it were appearing on a file (or) use the here-strings .  You could now use the variable \"\"$json\"\" in the \"curl\" as  .  ",
      "P-tags": "jq shell",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP into NP"
    },
    {
      "id": "so_11876657",
      "task": "Create files based on user input",
      "P-task": "creat file base user input",
      "F_verb": "create",
      "P-body": "You could use the command \"fold\" which will split your string by character. Example: .  To check if they are unique just use the \"if\" statement, because in your case you allow only three one digit numbers. .  ",
      "P-tags": "linux bash",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "so_39406998",
      "task": "bash execute whole script but return exit code > 0 if any intermediate job has failed",
      "P-task": "bash execut whole script return exit code 0 intermedi job fail",
      "F_verb": "execute",
      "P-body": "You can trap errors: .  For more information on how traps work, see trap. .  ",
      "P-tags": "linux shell bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP if S"
    },
    {
      "id": "au_280323",
      "task": "How to monitor udp connections request time/duration?",
      "P-task": "monitor udp connect request time durat",
      "F_verb": "monitor",
      "P-body": "I think you can use Wireshark to capture segment for some period and analyze it for tcp/udp for \"SYN\" and \"SYN-ACK\" responses. Plus it has nice UI. And though I have not tried but I think Wireshark dump should be compatible with cross platform usage, so you can use it in Windows for analysis too. .  ",
      "P-tags": "network internet",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "ul_241178",
      "task": "How can I get this script to error exit based on result of for loop?",
      "P-task": "get script error exit base result loop",
      "F_verb": "get",
      "P-body": "Replace: .  with: .  This will cause the code to exit if the \"for\" loop exits with a non-zero exit code. .  As a point of trivia, the \"1\" in \"exit 1\" is not needed. A plain \"exit\" command would exit with the exit status of the last executed command which would be \"false\" (code=1) if the download fails. If the download succeeds, the exit code of the loop is the exit code of the \"echo\" command. \"echo\" normally exits with code=0, signally success. In that case, the \"||\" does not trigger and the \"exit\" command is not executed. .  Lastly, note that \"set -o errexit\" can be full of surprises. For a discussion of its pros and cons, see Greg's FAQ #105. .  Documentation From \"man bash\": .   for (( expr1 ; expr2 ; expr3 )) ; do list ; done First, the arithmetic expression expr1 is evaluated according the rules described below under ARITHMETIC EVALUATION. The arithmetic expression expr2 is then evaluated repeatedly until it evaluates to zero. Each time expr2 evaluates to a non-zero value, list is executed and the arithmetic expression expr3 is evaluated. If any expression is omitted, it behaves as if it evaluates to 1. The return value is the exit status of the last command in list that is executed, or false if any of the expressions is invalid. [Emphasis added] .   ",
      "P-tags": "shell-script bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF on NP of NP"
    },
    {
      "id": "so_10498433",
      "task": "How to correctly ignore Import-Module errors in PowerShell",
      "P-task": "correctli ignor import-modul error powershel",
      "F_verb": "ignore",
      "P-body": " ",
      "P-tags": "powershel import-modul",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_347280",
      "task": "How to perform full check of ext4 file system structure?",
      "P-task": "perform full check ext4 file system structur",
      "F_verb": "perform",
      "P-body": "As mentioned by Sat\u014d Katsura, run \"e2fsck\" in \"force\" mode: .  This will force a check even if the system thinks the file system is clean. The \"verbose\" option is helpful too: .  As a side-note, and not applicable in your case, but if you use LVM for your storage you can use the neat little \"lvcheck\" tool to run an \"offline\" file system check on a mounted file system (it uses an LVM snapshot and updates the file system metadata if the check doesn't find any errors). .  ",
      "P-tags": "fsck partit debian",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of NP"
    },
    {
      "id": "so_34063228",
      "task": "I need to find .c files a specified directory",
      "P-task": "need find c file specifi directori",
      "F_verb": "find",
      "P-body": "You can use \"find\" or any other utility that provides a usable return based on whether any files matching \"'*.c'\" are found. \"ls\" works equally well: .  where \"$dir\" contains the desired path. As a one-liner: .   A Generalized Version For Any Dir/Any Extension .  You can easily make the script a general extension search by allowing user input of the directory to be searched and the extension to be found. The script below is a generalized version that by default searches the present directory for \".c\" files, but will search for any directory entered as the first argument and any extension entered as the second argument: .  Examples .  (there are no \".foo\" files) .   Detect if Non \".c\" Extensions Also Present .  That changes things a bit, but to determine if a directory has files other than files with the \".c\" extensions, you will have to check each file. In POSIX shell, you have the \"expr string : regex\" feature available to check patterns. In bash there are a couple of different ways to do this). The following will do what you are looking for: .   Using Bash Parameter Expansion .  This will be faster than the POSIX use of \"expr\". .   Prompting for Search Directory .  Your code you posted did not make much sense. and there were numerous missing \"';'\" and \"done\" statements, and you never used \"path\") There is no need to change to the directory that the user enters. If you do, as you did in your code, you must change the second loop. Here is an update that prompts for the search directory and will exit if a sub-directory is present in the search path: .  You can tailor that as you like. .  ",
      "P-tags": "shell",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_21284163",
      "task": "When to use shellout?",
      "P-task": "use shellout",
      "F_verb": "use",
      "P-body": "Use Shellout When you need to get the result of the command to use elsewhere .  Use \"script\" and children When you want Chef to execute the code for you. .  Shellout is not a replacement to \"script\"/\"execute\" blocks. They also execute at different times during the Chef Client run. Shellout is a Ruby thing, whereas \"script\"/\"execute\" are Chef resources like \"template\". There is a lot of safety and cross-platform support wrapped in these resources that you won't get with Shellout. .  ",
      "P-tags": "mixlib-shellout chef-infra",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_237008",
      "task": "Upstart and multi-signal shutdown process",
      "P-task": "upstart multi-sign shutdown process",
      "F_verb": "process",
      "P-body": "There are two ways that I found to tackle the problem, neither is perfect: .   Upstart has the \"kill signal\" stanza. If you set \"kill signal QUIT\" and also \"kill timeout 600\", Upstart will send \"SIGQUIT\" to the process, then wait 600 seconds before sending \"SIGKILL\". If the process terminates before \"SIGKILL\" is sent, then we're good. There are issues with that approach: (a) it sends \"SIGKILL\" and not \"SIGTERM\" after the timeout which doesn't allow the resque worker to close nicely, but that's a no biggie. b) A worse problem that I found is that upstart sends the \"kill signal\" (in our case \"SIGQUIT\") to all processes in the session, which will likely interfere with the operation of child processes of the resque worker (\"SIGQUIT\" default action is to terminate with a core dump). Implement your own wrapper that traps whatever signal your configured upstart to send (or just assume the default \"SIGTERM\") and handle all the graceful shutdown yourself. In that case its important to set the Upstart \"kill timeout\" to a sufficient time to let your wrapper do a graceful shutdown and either force the abort with the time is up (in which case make sure to have the timeout slightly less than Upstart's) or just rely on Upstart's \"SIGKILL\" for the cleanup (which may or may not be a good idea depending on your requirements). Cons: its rather complicated to get this right, and the reason Upstart exists is so you won't have to write a process manager yourself for every service.  If you don't want to go either way, there are other process managers out there that may implement a more complex signal regime than Upstart support, and these are usually easy to implement under Upstart to manage just the process you are having a problem with. Unfortunately, its hard to find one that works correctly in all cases. For example I've tried Bluepill, which looks great on paper but at the time of writing has a glaring bug where if you try a complex signal regime with multiple signals and multiple timeouts, it just sends all the signals at once (not necessarily in the correct order) and crashes the child process. .  If someone else has more information to add, feel free to add more answers and I may even mark it as \"answered\" (instead of my self answer) if its good. .  ",
      "P-tags": "upstart",
      "cate": "handle/process/preprocess",
      "pat": "V"
    },
    {
      "id": "ul_66461",
      "task": "How to make SLiM not render anything at login prompt?",
      "P-task": "make slim render anyth login prompt",
      "F_verb": "make",
      "P-body": "There is no way to turn if off using config files. It is hardcoded in sources (with names of files), so only way to remove background will be to modify sources. .   My background is about 150KB, panel about 15 KB, so it lot smaller that \"few megabytes\".  .  You can set in your \"slim.theme\": .  so if its 1x1 px there will be only one stretched file and there will be only one copy of this file. .  BTW, turning off shouldn't make any visible difference in used resources of modern computer. If you want to run X applications there will be apps that are using many more megabytes of graphics... .  ",
      "P-tags": "slim",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF at NP"
    },
    {
      "id": "ul_113588",
      "task": "why does the dollar sign cause this command to be executed?",
      "P-task": "dollar sign caus command execut",
      "F_verb": "cause",
      "P-body": "A trivial search for \"$(\" in the shell man page gives the answer. .  As \"$name\" causes parameter expansion \"$(command)\" causes command substitution i.e. it is replaced by the output of the command (with trailing newline(s) removed). \"$(command)\" causes word splitting after the expansion, \"\"$(command)\"\" avoids it (like \"$name\" vs. \"\"$name\"\"). .  \"\"(dirname)\"\" on the other hand is just a literal string to the shell. .  ",
      "P-tags": "script variable-substitut shell-script variabl subshel",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_50643479",
      "task": "Video4Linux ioctl error (#25) when attempting to read device information from /dev/video0",
      "P-task": "video4linux ioctl error 25 attempt read devic inform dev video0",
      "F_verb": "read",
      "P-body": "It seems that the \"/dev/video*\" devices may be bound to separate \"/dev/media*\" devices, and you need to issue your \"MEDIA_IOC_DEVICE_INFO\" ioctl against the corresponding \"/dev/media*\" device for your \"/dev/video*\" device. .  As to how to locate that corresponding device id, the best I have come up with is to search for \"media*\" files within the \"/sys/class/video4linux/video{N}/device\" directory. .  For example, for a given device \"/dev/video0\" on my system (kernel 4.15.0-34-generic), searching for \"media*\" files under \"/sys/class/video4linux/video0/device\" turned up \"media10\", which I was then able to use to recover the serial number (open \"/dev/media10\", issue the ioctl command). .  I don't know whether this method of finding the corresponding media devices is consistent across distros/versions/kernels/etc. .  ",
      "P-tags": "linux c linux-kernel video4linux",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "au_958013",
      "task": "I want to deinstall and clean up after a partial Anaconda install",
      "P-task": "want deinstal clean partial anaconda instal",
      "F_verb": "install",
      "P-body": "Yes you need to remove the old install, check in two places: .   In your home directory for the \"anaconda\" folder, delete that Look in the \"/home/$USER/.bashrc\" for the \"anaconda\" \"export\" line and delete that. If in \"step 2\" that line is absent then go ahead with the new install.  Now your good to go with the new install. .  ",
      "P-tags": "python-2 7 64-bit 32-bit anaconda uninstal",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_47538235",
      "task": "Decrease a date correctly by each month",
      "P-task": "decreas date correctli month",
      "F_verb": "decrease",
      "P-body": "It's easier to generate the beginning of the month and do little trick to get the end of month without checking dates .  ",
      "P-tags": "linux shell bash datetim date",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP by NP"
    },
    {
      "id": "ul_422101",
      "task": "SMBus/IPMI/GenericSerialBus write requires Buffer of length 66, found length 32",
      "P-task": "smbu ipmi genericserialbu write requir buffer length 66 found length 32",
      "F_verb": "require",
      "P-body": "ACPI is the subsystem that uses information from the BIOS to control hardware, mostly for power management, temperature sensing, and related issues. SMBus is a simple two-wire communications protocol, used as side channel to access temperature sensors and other hardware. .  So your BIOS contains sloppy ACPI data that specifies the wrong buffer size for a write action on that channel. \"_PMM\" seems to indicate that it is related to some chip that measures something power related. Which means it probably fails to initialize some chip that monitors voltage levels somewhere. Which is usually not a problem (unless you want to measure voltage levels, and shut down your computer if there's something odd, which is a feature you have to install and set up, and is usually only used on servers). .  You can investigate that by looking at the ACPI data, but that requires a bit of expertise. Sloppy BIOS data is nothing unusual (unfortunately), vendors suck at setting up the BIOS properly, as they only test with the pre-installed Windows drivers which may work even with faulty data. .  ",
      "P-tags": "acpi raid linux acpid debian",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP"
    },
    {
      "id": "so_57665430",
      "task": "Unable to run python code on shinyapps.io",
      "P-task": "unabl run python code shinyapp io",
      "F_verb": "run",
      "P-body": "This syntax only works for python >=3.7  .  Otherwise use >=2.7 .  I would check this. .  ",
      "P-tags": "ubuntu python shinyapp python-3 x",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1030345",
      "task": "Get network usage from specific date on terminal",
      "P-task": "get network usag specif date termin",
      "F_verb": "get",
      "P-body": "vnStat supports date and time range specific queries for all list outputs starting from version 2.0 (currently available as beta). That version also allows free configuration of data retention durations so there's no more hardcoded 30 day limit for daily data. See the change notes and the GitHub repository for more details. .  ",
      "P-tags": "vnstat network network-monitor",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP on NP"
    },
    {
      "id": "so_18333070",
      "task": "bash: get literal parameters passed to a script and execute them as a command",
      "P-task": "bash : get liter paramet pass script execut command",
      "F_verb": "get",
      "P-body": "You are on the right track, and almost got it. You just need to use \"\"$@\"\" instead of \"$@\". .  Here's a summary of what \"$*\" and \"$@\" do, with and without quotes: .   \"$*\" and \"$@\" paste in the positional arguments, then tokenise them (using \"$IFS\") into separate strings. \"\"$*\"\" pastes in the positional arguments as one string, with the first character of \"$IFS\" (usually a space) inserted between each. \"\"$@\"\" pastes in the positional arguments, as a string for each argument.  Examples: .  Here's what changes when you set \"$IFS\": .  ",
      "P-tags": "mercuri shell bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_38333285",
      "task": "Increase ulimit in cygwin",
      "P-task": "increas ulimit cygwin",
      "F_verb": "increase",
      "P-body": "To debug a php script one way is to run .  http://linux.die.net/man/1/php .  ",
      "P-tags": "php cygwin shell powershel window",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP"
    },
    {
      "id": "su_1236600",
      "task": "Keeps detecting SELinux as enabled even though I disabled it (When trying to install FreePBX)",
      "P-task": "keep detect selinux enabl even though disabl tri instal freepbx",
      "F_verb": "install",
      "P-body": "I have faced this problem before: A quick search made me realise that in order to disable SELinux I have to modify \"/etc/selinux/config\" instead, doing that gave for \"sestatus\": .  ",
      "P-tags": "centos-6 selinux sip cento asterisk",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_55928332",
      "task": "How do I use Powershell regex to convert \"\" into \\\"?",
      "P-task": "use powershel regex convert",
      "F_verb": "convert",
      "P-body": "Use a Regular Expression with a positive lookahead zerolength assertion. .  yields: .  ",
      "P-tags": "powershel csv escap",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP"
    },
    {
      "id": "su_1337066",
      "task": "How to use a disk to system and a disk to storage CentOS?",
      "P-task": "use disk system disk storag cento",
      "F_verb": "use",
      "P-body": "You mount the VD 1 which is for the system on the mountpoint \"/\" (the root filesystem). That way, you ensure that your system is using the first virtual drive. .  Then mount the VD 2 which is for the user files on the mountpoint \"/home\" directory, where all users will save their files. .  EDIT: As you edited your post with the output of \"lsblk\" now, I see that you've actually had a virtual partition from VD1 mounted on \"/home\" as well. If you don't mind losing the files, you can simply \"umount /home\" till no partitions are mounted there, then \"mount /dev/sdb /home\". After that, \"/home\" will be on \"sdb\" and \"sda\" won't have anything on \"/home\" anymore. .  If you want to save your old files in \"home\": Just \"umount /dev/sdb\" so only \"sda\" is on \"/home\", then \"cp -R /home /tmp\". make sure \"/tmp\" dir exists before that) .  After that \"umount /home\", \"mount /dev/sdb /home\". .  ",
      "P-tags": "cento linux raid",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_536721",
      "task": "Can't install Mayavi on Anaconda distribution",
      "P-task": "instal mayavi anaconda distribut",
      "F_verb": "install",
      "P-body": "I've always found that when installing Mayavi with Anaconda, it's best to use \"conda\" rather than \"pip\" no matter the distribution. This will install it via the Anaconda repos. .  That's assuming you have the \"bin\" directory of Anaconda prepended to your path. The \"-c anaconda\" switch tells it to install Mayavi from the Anaconda repo. The installation will also be successful with .  I simply prefer the first but it's up to you. It will install Mayavi and it will be usable just the same.  .  Afterwards, you can see it installed with any of the following commands: .  ",
      "P-tags": "python3 manjaro",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_676246",
      "task": "When an SSH authorized key is restricted to command how can the command read the parameters in the call?",
      "P-task": "ssh author key restrict command command read paramet call",
      "F_verb": "read",
      "P-body": "The additional parameters passed to \"ssh\" appear in the environment variable \"SSH_ORIGINAL_COMMAND\": .  ",
      "P-tags": "openssh command ssh",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "so_11697076",
      "task": "Determine interpreter from inside script",
      "P-task": "determin interpret insid script",
      "F_verb": "determine",
      "P-body": "You can check which interpreter is used by looking at \"$SHELL\", which contains the full path to the shell executable (ex. \"/bin/bash\") .  Then, if it is Bash, you can check the Bash version in various ways: .   \"${BASH_VERSINFO[*]}\" -- an array of version components, e.g. \"(4 1 5 1 release x86_64-pc-linux-gnu)\" \"${BASH_VERSION}\" -- a string version, e.g. \"4.1.5(1)-release\" And of course, \"\"$0\" --version\"  ",
      "P-tags": "linux interpret bash",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP from NP"
    },
    {
      "id": "au_205672",
      "task": "How to fix this where it can not ping any DNS names but only IP, as a result apt-get update is failing",
      "P-task": "fix ping dn name ip result apt-get updat fail",
      "F_verb": "fix",
      "P-body": "What DNS servers are you using? Open \"System Settings\" and go to \"Network\". You can change DNS servers from there. Your ISP should have servers that you can use, but you can also try something else. I know that Google has two servers at \"8.8.8.8\" and \"8.8.4.4\" that work for me. .  To debug DNS issues you can use dig and ping. Try these commands: .  The values could be, for example: .  If changing DNS servers doesn't work, post the output of the above commands here. .  ",
      "P-tags": "updat 12 10 package-manag repositori 12 04",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP where S"
    },
    {
      "id": "so_22640210",
      "task": "Powershell script compare to lists foreach for Robocopy",
      "P-task": "powershel script compar list foreach robocopi",
      "F_verb": "compare",
      "P-body": "If you have a CSV with 2 columns, headers of OldName and NewName you could do this: .  That will load a CSV, pull a folder listing of the old servers profiles, and for each one move it to the new server with the new profile name. .  Without the CSV it gets a lot more complicated, and prone to errors because we have to make assumptions. You could do it manually I suppose, assuming that all old names are last name followed by first initial and the new name is first name (dot) last name. This will load the lists, iterate through the new names and create a hashtable associating the new names to the old names (based on the previous assumptions). Then it pulls a folder listing of the old profiles and moves them to the new server with the new profile name provided by the hashtable. .  Edit: Ok, if you really feel that you need to use RoboCopy, once you have the mapping CSV loaded you can do: .  Or if you use the Make-Your-Own_Hashtable method you could do something like: .  ",
      "P-tags": "powershel robocopi",
      "cate": "compare",
      "pat": "V to NP for NP"
    },
    {
      "id": "au_109147",
      "task": "Can see the nautilus menu in Desktop when using Gnome Shell",
      "P-task": "see nautilu menu desktop use gnome shell",
      "F_verb": "see",
      "P-body": "Yes, you should do ONE of the following (the one that you prefer): .  1) Set from Gnome Tweak Tool that the file manager should NOT handle the desktop (this will also get rid of the icons on the desktop) .  2) Remove the packages \"appmenu-gtk appmenu-gtk3 appmenu-qt\". .  ",
      "P-tags": "nautilu gnome",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP when S"
    },
    {
      "id": "au_166268",
      "task": "when setting up a webserver on linux , is it a good practice to make a new user and install everything under that user?",
      "P-task": "set webserv linux good practic make new user instal everyth user",
      "F_verb": "make",
      "P-body": "When using Linux you should not run things as \"root\" unless it's essential. This means that most installations will actually be done as \"root\", normally by using the \"sudo\" command (or the GUI equivalent) as this ensures that all the files can be put in the right locations, with most files being below the \"/usr\" directory. .  The Apache developers are well aware of security concerns and, by default, will install the webserver to run as a specially created user; on my system, most of the apache2 instances are running under the user \"www-data\" which I believe is the default (it's a long time since I installed it). .  I think you can override the default locations for the actual web files during installation, but normal practice is to use the default (\"/var/www\" as I recall) and then link subfolders to there. .  In summary, taking the defaults of the installation (run as \"root\" or using \"sudo\") will give you a reasonably safe setup and you don't need to take any special action. .  ",
      "P-tags": "webserv user",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "ul_1752",
      "task": "bash PS1 setup",
      "P-task": "bash ps1 setup",
      "F_verb": "setup",
      "P-body": "I have a helper function to set prompt, and because I don't want to spend more time for looking for escape code references, I've coded all text color values into it. .  You can then do: .  Here is the link that explains VT100 terminal codes: http://www.termsys.demon.co.uk/vtansi.htm .  \"\\[\" - begin sequence of non-printing characters \"\\]\" - end sequence of non-printing characters .    What's the difference between \"[\\e[32;1m]\" and \\e[32;1m\"? Are they the same?   Not the same, and it should be \"\\[\\e[32;1m\\]'. Without\"[]` it would try to print the sequence in console. .    What's the meaning of STARTCOLOR(\\e[40m)/ENDCOLOR(\\e[0m)?   STARTCOLOR, means set background to black, ENDCOLOR means reset all text attributes, meaning 'give me default console color' .  ",
      "P-tags": "prompt bash",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V"
    },
    {
      "id": "so_35522738",
      "task": "Need to convert single text column to a single row and then split the row based on the pattern",
      "P-task": "need convert singl text column singl row split row base pattern",
      "F_verb": "convert",
      "P-body": "Another approach:  .  sed adds the single quotes at the beginning and end of each line, and paste joins the line together with commas .  Or, print a comma for each line, and when you're done back up 1 character and overwrite the last comma with a space: .  ",
      "P-tags": "bash",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "au_171759",
      "task": "How can I install Ubuntu on a second hard drive with Windows being on the first?",
      "P-task": "instal ubuntu second hard drive window first",
      "F_verb": "install",
      "P-body": "That's simple: .   First download the ISO file then burn it to a CD/DVD or use Unetbootin to get a bootable USB, select the Installation media to boot first from your BIOS. Once you're in the Live Session, choose Install Ubuntu. When you get to the Choose an Option screen, select Do Something Else. Locate the Second drive and choose to Install the System on the second drive. Choose to also install the bootloader on the 2nd drive, make sure it's the drive and not a partition (i.e. \"/dev/sda\" and not \"/dev/sda1\")  ",
      "P-tags": "11 10 dual-boot system-instal",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP with NP S_ING on NP"
    },
    {
      "id": "ul_111256",
      "task": "How to permanently disable a network interface?",
      "P-task": "perman disabl network interfac",
      "F_verb": "disable",
      "P-body": "Method #1 - from NetworkManager's Applet Try disabling the wireless networking under the Network Applet that's accessible from under the icons in the upper right of your desktop. .  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 .  NOTE: The networking applet's icon looks like a triangle wedge. The image above is pointing to is as arrow #1. If you click it you should see a menu slide out from where you can disable wireless permanently, arrow #2. .  Method #2 - /etc/network/interfaces From the file \"/etc/network/interfaces\" you can specify that NetworkManager shouldn't control the \"wlan0\" interface. To do so simply add this line to the above mentioned file: .  Then restart NetworkManager: .  References  How to disable built-in wifi and use only USB wifi card?  ",
      "P-tags": "ubuntu network",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "au_1068247",
      "task": "Bash script to Run a command to X files at a time",
      "P-task": "bash script run command x file time",
      "F_verb": "run",
      "P-body": "Your script is not running all your files at once but one by one. And you are running the command recon-all in background wihtout waiting to its response, so in next run it picks the next file to run and still in background.  .  Use \"find\" with \"xargs\" and it will run for next file after the previous finished one by one.  .  to run in 10 batches, do .  note that the \"-s\"ubject is taking from first filename above.  .  ",
      "P-tags": "script command-lin bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP to NP at NP"
    },
    {
      "id": "so_55879144",
      "task": "Double quotes is not helping me to pass a string argument with spaces",
      "P-task": "doubl quot help pass string argument space",
      "F_verb": "pass",
      "P-body": "Oguz ismail's advise in this comment is perfectly correct. However, if the value of the other positional parameter, \"$1\", might also contain some spaces, you should quote it as well. And since these quotes do no harm otherwise, quote it in any case: .  Please note: The calling shell expands this to something like .  where \"GPU = 'blah blah'\" and \"nodes=1,walltime='foo bar'\" are treated as single words that are passed as single arguments to \"oarsub\" as it should be. .  Apart from that, in general, it is not necessary to hierarchically nest the quoted parts of a command line: You may simply concatenate them, basically like so: .  In this way you have full control of what parts are expanded and what parts are subject to word splitting. However, this is not necessary in your case. So you can just follow the suggestion above, which are by far easier to read and therefore clearer. .  ",
      "P-tags": "quot bash",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_643790",
      "task": "How to copy an entire line which matches the string and paste right after it with prefix?",
      "P-task": "copi entir line match string past right prefix",
      "F_verb": "copy",
      "P-body": "You could do this using \"awk\". .  Using your example here is one way to do it. .  Breaking down the statement for you: \"{print $0}\" is to print the entire line .  \"/Samsung/ {print \"prefix \" $0}\" says to print \"prefix \" followed by the entire line, but only if the line contains Samsung. .  ",
      "P-tags": "shell text-process",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP which S"
    },
    {
      "id": "so_36765882",
      "task": "How do I copy the beginning of multiple files in Linux?",
      "P-task": "copi begin multipl file linux",
      "F_verb": "copy",
      "P-body": "Try .  ",
      "P-tags": "file linux ubuntu unix-head",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_25779761",
      "task": "reduce vagrant box storage (vmdk) size",
      "P-task": "reduc vagrant box storag vmdk size",
      "F_verb": "reduce",
      "P-body": "You can try to do it by .   zero-out disk space within the vm by running  \"cat /dev/zero > /path/to/fill/z; sync; sleep 3; sync; rm -rf z\" .   NOTE: Delete unwanted files within the VM before running the command above. If you have multiple partitions, logical volumes, do it on each of them. .    compact / shrink the virtual disk (this works fine with VDI format, but not sure about VMDK, you can try)  \"VBoxManage modifyhd --compact /path/to/vdisk.vmdk\" .  You'll see the progress, once finished, check its size. .  Update: If you want to resize the virtual disk, you should use \"VBoxManage modifyhd --resize <megabytes> /path/to/vdisk.vmdk\". .   NOTE: The size of the virtual disk doesn't matter too much, it is just like a cap (max size) of the virtual disk image it can grow up to. By default the VMDK should be dynamically allocated, which mean the vmdk size will be close to the amount of data within the VM. The above method will help to reclaim spaces that has been freed up within the guest. .   IMPORTANT: Growing the size of the vdisk is OK, but when reducing/shrinking you should be very careful, there is risk of losing data the new size < the actual data size within the vdisk. .  ",
      "P-tags": "ubuntu virtualbox vagrant",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_81916",
      "task": "How to find a space in a text. using grep?",
      "P-task": "find space text\nuse grep",
      "F_verb": "find",
      "P-body": "I think I found it: .  ",
      "P-tags": "grep",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "so_48428007",
      "task": "Powershell script to copy publish files from build machine to posting server",
      "P-task": "powershel script copi publish file build machin post server",
      "F_verb": "build",
      "P-body": "Copy a file to a remote computer: .  Once you type a user name, you will be prompted for a password. .  ",
      "P-tags": "powershel msbuild tfsbuild",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP to NP"
    },
    {
      "id": "so_55144436",
      "task": "PowerShell foreach loop with same date for all iterations",
      "P-task": "powershel foreach loop date iter",
      "F_verb": "loop",
      "P-body": "Now that you have given us an example to work with, I think this will help you. .  The code parses the file and exports a CSV file with four columns: \"Serial\", \"Date\", \"Model\" and a 4th column to show if the 'Sonde' passed or failed the calibration test called \"Status\". you may leave that one out of course, but then you might think all equipment worked ok..) .  Using your example file, the resulting CSV file would contain: .    Hope that answers your question .  ",
      "P-tags": "powershel csv foreach",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V with NP for NP"
    },
    {
      "id": "so_18442224",
      "task": "Wait for all jobs of a user to finish before submitting subsequent jobs to a PBS cluster",
      "P-task": "wait job user finish submit subsequ job pb cluster",
      "F_verb": "finish",
      "P-body": "Filling in following the solution suggested by Jonathan in the comments. .  There are several resource managers based on the original Portable Batch System: OpenPBS, TORQUE and PBS Professional. The systems had diverged significantly and use different command syntax for newer features such as job arrays. .  Job arrays are a convenient way to submit multiple similar jobs based on the same job script. Quoting from the manual:  .   Sometimes users will want to submit large numbers of jobs based on the same job script. Rather than using a script to repeatedly call qsub, a feature known as job arrays now exists to allow the creation of multiple jobs with one qsub command. .   To submit a job array PBS provides the following syntax: .  this submits jobs with ids from 0,1,2,...,10,13,15. .  Within the script the variable \"PBS_ARRAYID\" carries the id of the job within the array and can be used to pick the necessary configuration. .  Job array have their specific dependency options.  .  TORQUE TORQUE resource manager that is probably used in the OP. There additional dependency options are provided that can be seen in the following example: .  This will result in the following \"qstat\" output .  Tested on torque version 3.0.4 .  The full afterokarray syntax is in the \"qsub(1)\" manual. .  PBS Professional In PBS Professional dependencies can work uniformly on ordinary jobs and array jobs. Here is an example: .  This will result in the following \"qstat\" output .  Update on Torque versions Array dependencies became available in Torque since version 2.5.3. Job arrays from version 2.5 are not compatible with job arrays in versions 2.3 or 2.4. In particular the \"[]\" syntax was introduced in Torque since version 2.5. .  Update on using a delimeter job For torque versions prior to 2.5 a different solution may work that is based on submitting dummy delimeter jobs between batches of jobs to be separated. It uses three dependency types: \"on\",\"before\", and \"after\". .  Consider the following example .  This will result in the queue state like this .  That is the job #2001 will run only after the previous 1000 jobs terminate. Probably the rudimentary job array facilities available in TORQUE 2.4 can be used as well to submit the script job. .  This solution will also work for TORQUE version 2.5 and higher. .  ",
      "P-tags": "cluster-comput wait qsub shell pb",
      "cate": "finish/complete/finalize/complement",
      "pat": "V before S_ING NP to NP"
    },
    {
      "id": "so_9473962",
      "task": "Redirect domain names from linux dns server",
      "P-task": "redirect domain name linux dn server",
      "F_verb": "redirect",
      "P-body": "here are some relevant quotes from this tutorial: .   Examples Corporation has been assigned the network 192.0.2.0/24 and internally we are using 10.0.0.0/24. .  Let's start serving the external names and IPs, we edit /etc/bind/named.conf.local4 and add: .    and then we create /etc/bind/db.example.com with the following contents: .   So what you want to do is replace \"example.com\" with whatever domain your programs access, replace \"192.0.2.whatever\" with your destination ip and remove the \"ns1\", \"mail\", \"www\", \"clien1\" lines and replace it with .  ",
      "P-tags": "linux dn",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_211173",
      "task": "In bash, how to call a variable and wrap quotes around its value as part of a command without causing the variable name to become a string literal?",
      "P-task": "bash call variabl wrap quot around valu part command without caus variabl name becom string liter",
      "F_verb": "call",
      "P-body": "Just for completeness, you don't need all those (\") nor the final \"$(echo ...)\". Here's the simplified version of your assignments that produce the same effect: .  Note how you don't need to quote when doing var=$(...) but you do usually with var=\"many words\": .  Inside (\") a (') has no special significance, and vice-versa, eg: .  ",
      "P-tags": "quot date shell-script bash",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP as NP of NP without S_ING"
    },
    {
      "id": "so_5589035",
      "task": "Powershell update for com plus application",
      "P-task": "powershel updat com plu applic",
      "F_verb": "update",
      "P-body": "It seems that you have already set the pool size using \"$app.Value(\"ConcurrentApps\") = 1\". Might be you are missing something (for example you are not checking that the your set is successful). Look at this example Configuring COM+ Application Pooling Values.  .  ",
      "P-tags": "powershel powershell-2 0 com+",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V for NP"
    },
    {
      "id": "ul_545946",
      "task": "Trim an audio file into multiple segments using `ffmpeg` with a single command",
      "P-task": "trim audio file multipl segment use ffmpeg singl command",
      "F_verb": "trim",
      "P-body": "Sure, just give it more output files: .  Options after the input file actually pertain to the output file (so the \"-c\", \"-ss\" and \"-to\" options are for the output file). And you can have multiple output files. .  (Unlike the segments muxer, you can have overlapping output this way if you want. Or different codecs, or metadata. But @Gyan's answer with the segment muxer is easier if its restrictions are OK for you). .  ",
      "P-tags": "ffmpeg audio trim",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP into NP using NP with NP"
    },
    {
      "id": "ul_358587",
      "task": "gzip: unexpected end of file with - how to read file anyway",
      "P-task": "gzip : unexpect end file - read file anyway",
      "F_verb": "read",
      "P-body": "Apart from the very end of the file, you will be able to see the uncompressed data with \"zcat\" (or \"gzip -dc\", or \"gunzip -c\"): .  or .  or .  \"gzip\" will do buffering for obvious reasons (it needs to compress the data in chunks), so even though the program may have outputted some data, that data may not yet be in the \"log.gz\" file. .  You may also store the uncompressed log with .  ... but that would be silly since there's obviously a reason why you compress the output in the first place. .  ",
      "P-tags": "gzip",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_1344650",
      "task": "Can't open snap-store",
      "P-task": "open snap-stor",
      "F_verb": "open",
      "P-body": "The problem is in the internals of the latest \"snap-store\" version 3.38.0-59-g494f078 2021-04-20 (518) from default channel. To fix it you can upgrade it to newer version by using command below .  Then you can use it as before. .   Notes: .   this method is universal for all current Ubuntu releases - 18.04 LTS, 20.04 LTS, 20.10 and 21.04. we need to get official fix from Snap Store developers and switch then to default channel, bug 1931380 was reported to launchpad. if one is not happy with above solution, then one can use GNOME Software with snap plugin instead - \"sudo add-apt-repository universe; sudo apt-get update; sudo apt-get install gnome-software gnome-software-plugin-snap\" .  Update: The bug has been fixed. If you switched to the beta channel, you should switch back to stable with the following command: .  ",
      "P-tags": "20 04 snap-stor",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "so_16464705",
      "task": "'tee' in makefile, can we copy stderr as well?",
      "P-task": "tee makefil copi stderr well",
      "F_verb": "copy",
      "P-body": "In order to use this syntax in your \"Makefile\" you need to change the shell that make uses for running commands by setting the \"SHELL\" variable. .  By invoking make using: \"make SHELL=/bin/bash\", or putting \"SHELL:=/bin/bash\" at the start of the \"Makefile\" it should accomplish this. .  ",
      "P-tags": "makefil shell tee",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP"
    },
    {
      "id": "su_1352746",
      "task": "How to copy all installed libraries to another Linux machine?",
      "P-task": "copi instal librari anoth linux machin",
      "F_verb": "copy",
      "P-body": "Managing a packages like rpm and libraries is very important in all the distribution of Linux. There are two ways to copy the packages from one System to another. .   You can create File of current list of Softwares as below: \"rpm -qa > installed-software.txt\" Copy the above file into new Server: If the both machines are of Same Distros: we can do the below in Ubuntu Distros: \"apt-get -y install $(cat /home/user/installed-software.txt)\" .  On Systems using apt or Debian and derivatives like ubuntu, mint... \"sudo apt-get install apt-clone\" \"apt-clone clone installedsoftware\" .   tar that file using \"tar -cvzf installedsoftware.tar.gz installedsoftware\" and copy this installedsoftware to new machine. .  Enjoy....!!! .  Thanks Santosh G. .  ",
      "P-tags": "apt-get linux ubuntu instal package-manag",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP to NP"
    },
    {
      "id": "au_180128",
      "task": "how can I recursively set pemission to all sub directories of a directory specified?",
      "P-task": "recurs set pemiss sub directori directori specifi",
      "F_verb": "set",
      "P-body": "Use the \"-R\" flag.  .  so the command would be \"sudo chmod -R 777 /var/www/\". .  This is, however a bad idea and you should normally do it one at a time. .  ",
      "P-tags": "12 04 command-lin",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "au_788884",
      "task": "Change window animations in Ubuntu 16.04 without additional tools",
      "P-task": "chang window anim ubuntu 16 04 without addit tool",
      "F_verb": "change",
      "P-body": "Use one of the following commands to change the minimize and restore/unminimize animation, respectively: .  And replace \"NEWANIMATION\" by one of the following strings: .  It seems like an invalid string is equivalent to \"None\". The default value for \"minimize-effects\" is \"Zoom\", for \"unminimize-effects\" it's \"Glide 2\". .  I extracted this information from the file \"UnityTweakTool/section/windowmanager.py\" from the Unity Tweak Tool source code. .  ",
      "P-tags": "16 04 uniti",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP without NP"
    },
    {
      "id": "so_6804353",
      "task": "How do I check to see if a file exists within a directory",
      "P-task": "check see file exist within directori",
      "F_verb": "see",
      "P-body": "You know already how to read user input, here's the new part: .  It's done with test(1): .  It also has the alternate name \"[\" which is most often used in \"if\" or \"while\" expressions: .  Please refer to the above link (or alternatively the manual page). .  ",
      "P-tags": "ksh script linux unix",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V if S"
    },
    {
      "id": "so_48891012",
      "task": "Segfault during fclose() despite correct file pointer",
      "P-task": "segfault fclose despit correct file pointer",
      "F_verb": "correct",
      "P-body": "A crash in fclose like this indicates that the \"FILE\" data structure involved has been corrupted, probably by an invalid pointer use elsewhere in the program. .  Your best bet is probably a memory checking tool like valgrind .  ",
      "P-tags": "memori linux segmentation-fault c++ gcc",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_389015",
      "task": "how to combine partitions",
      "P-task": "combin partit",
      "F_verb": "combine",
      "P-body": "You can think of the root filesystem (\"/\") as the \"C:\" drive in windows. It contains (unless you tell it otherwise) nearly all of the operating system files. In order to do any operations on the partition mounted on \"/\" you need to unmount the partition. To unmount the partition you have to stop using all the files on the partition. To stop using your operating system files you need to shut down your computer. .  So how might one do this? Well, we could use a different operating system. A Linux live CD is an entire copy of Linux compressed onto a CD. When you boot it, it creates a root partition in your RAM, instead of your hard drive. This allows you to play with your hard drives partitions (including \"/dev/sda1\") unencumbered.  .  There are of course other methods as well, for example you could install Linux on a second hard drive and attach that to your computer. Or you could network boot your computer, which works much like the CD but instead it uses a \"TFTP\" server. .  However there is one other thing that is going to get in your way, even if you use a Linux live disk: your swap space. The partition \"/dev/sda2\" (and the swap partition \"/dev/sda5\" that it contains) will prevent you from expanding \"/dev/sda1\" into the unallocated space. Thankfully, it is easier to stop using the swap space. You an turn it on and off momentarily with \"sudo swapoff -a\" and \"sudo swapon -a\", however that is not the full solution. Once you turn the swap off, you need to move the swap partition. If you move your swap partition, you must tell Ubuntu that you did so.  .  This can be done in the file \"sudo vim /etc/fstab\". There will be a long string followed by \"swap\" that will look like the line below. This is where you tell your computer where the swap to use is. After you move your swap, you need to get the new string to use here. This can be obtained using \"lsblk -f\". .  \"UUID=4209c845-f495-4c43-8a03-5363dd433153 none swap defaults 0 0\" .  So the full procedure looks like: .   Boot a live CD, or another OS. Turn off the swap, if the OS automatically started using it Delete swap and extended partition Recreate swap elsewhere (and extended partition if you want) Update /etc/fstab Extend \"/dev/sda1\" Reboot  Now there are things that can wrong in this process. Namely, you could mess up your \"/etc/fstab\" or your \"/dev/sda1\" can get corrupted. The first is not really a big deal, as you can always boot a live CD and fix it. There's a good chance your computer will actually boot fine with an error on the swap line anyway. The second is a much bigger concern. Modern tools are pretty good at expanding partitions, but to be safe ALWAYS BACK UP THE DATA ON THE PARTITION / DISK YOU ARE EDITING. .  Sources: .   https://wiki.archlinux.org/index.php/fstab#UUID  ",
      "P-tags": "partit",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_25864093",
      "task": "Specify one output file and another error file for the whole shell script?",
      "P-task": "specifi one output file anoth error file whole shell script",
      "F_verb": "specify",
      "P-body": "As seen in redirect all output in a bash script when using set -x, you can use this approach: .  If you want to specify different files for stdin and stderr, do: .  Test and we get... .  ",
      "P-tags": "shell",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "au_35885",
      "task": "Can I unlock Mac folders from a USB stick?",
      "P-task": "unlock mac folder usb stick",
      "F_verb": "unlock",
      "P-body": "As Slipstream has answered you can use root privileges to access and copy the contents through terminal. All you have to do is boot from a Ubuntu live USB/CD and use following commands: .   Open terminal via \"Applications > Accessories > Terminal\"; use \"sudo su\" to gain root user privileges and \"ls /media/MacOSDrive\" to list the contents. After MacOSDrive you can append \"/Documents/\" or any such directory name to list out their contents. Once you are sure about the contents you need to copy use \"sudo cp <source drive, say /media/MacOSDrive/Documents> -av <destination drive, say /media/an_external_drive>\", where \"a\" stands for all contents and \"v\" for verbose mode, which lists out what is being copied file by file.  Hope it helps. .  ",
      "P-tags": "directori macbook unlock mac",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP from NP"
    },
    {
      "id": "au_109709",
      "task": "Hurricane IPv6 buffer space error",
      "P-task": "hurrican ipv6 buffer space error",
      "F_verb": "buffer",
      "P-body": "Problem 1: the \"/64\" on the end of the \"address\" parameter is incorrect. That's what the \"netmask\" parameter is for; you should delete the /64 on the end of \"address\". .  However, the error you're seeing is what you'd expect if there was already a tunnel configured with the name \"he-ipv6\". At a guess, you've already run \"ifup he-ipv6\", and it's got as far as creating the tunnel before falling over with an error due to the trailing \"/64\". Try doing .  to delete the half-configured tunnel before trying again. .  ",
      "P-tags": "network ipv6",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_6379502",
      "task": "How to use InsertAfter with PowerShell",
      "P-task": "use insertaft powershel",
      "F_verb": "use",
      "P-body": "You need to iterate through \"$childnode\"'s children, remove them from their parent, and import them into the new document context (\"$child\" and \"$parent\" are different \"XmlDocument\" instances) before appending to \"$parentnode\". .  This will append all \"fileAsset\" nodes from \"$childnode\" into \"$parentnode\". .  Fortunately, most of these methods return the same \"XmlNode\" or a new version of it, so the body of the \"while\" loop could chained together like this: .  \"InsertAfter(newChild,referenceChild)\" could also work, but would be done a little differently since it also needs a reference to the the node that it will be inserted after. .  ",
      "P-tags": "powershel insertaft",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_64344",
      "task": "Delete duplicate images. Need Software for computing average color of an image",
      "P-task": "delet duplic imag\nneed softwar comput averag color imag",
      "F_verb": "duplicate",
      "P-body": "Finally I played around a while and found the ImageMagick software pack. It's great because it lets me do it in a one-liner in the console without the need for a script. .  It just does nothing more than loop through the folder (precondition: it just contains images!), get the average color via \"convert \"$i\" -scale 1x1\\! -format '%[pixel:s]' info:-\" extract the relevant part from the output \"cut -db -f2-\" and finally rename the file. Horribly how well it worked. .  Greets .  ",
      "P-tags": "imag color sort",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP"
    },
    {
      "id": "ul_202222",
      "task": "Search a String in a directory- Get output without filename",
      "P-task": "search string directory- get output without filenam",
      "F_verb": "get",
      "P-body": "Use grep with option \"-h\" .  .   find ./files/ -name \"*.txt\" -print0 | xargs -0 grep -h \"5|20150507\" .   ",
      "P-tags": "ksh grep xarg linux find",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP without NP"
    },
    {
      "id": "so_14220149",
      "task": "Terminator can't find Rails",
      "P-task": "termin find rail",
      "F_verb": "find",
      "P-body": "Ensure RVM is Properly Loaded I don't know anything about your terminal emulator, but it's likely that your environment isn't being properly modified for use by RVM. Make sure your shell sources a file that contains the following: .  Depending on your shell and emulator, this is likely to be one of: .   ~/.profile ~/.bash_profile ~/.bashrc  If all else fails, just create a shell script that contains the necessary line and source it interactively into the current shell. For example, you might create a script and then \"source ~/bin/my_rvm_setup.sh\" to set up the correct environment variables and shell functions. .  ",
      "P-tags": "termin linux termin ruby-on-rail",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_318621",
      "task": "How to replace certain strings?",
      "P-task": "replac certain string",
      "F_verb": "replace",
      "P-body": "\"sed\" would work: .  I think you have to put the \"base/0\" case last, otherwise, the 5 -> 10 case kicks in as well. .  ",
      "P-tags": "awk sed text-process",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "so_7992475",
      "task": "Why is it impossible to create this directory?",
      "P-task": "imposs creat directori",
      "F_verb": "create",
      "P-body": "The documentation for mkdir indicates that there is a \"$recursive\" parameter you should use for this. .   \"recursive\" .  Allows the creation of nested directories specified in the pathname. Defaults to FALSE. .   Read the docs for usage. .  ",
      "P-tags": "linux php",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_7506709",
      "task": "YUI Compressor - Automate Javascript Compression but skip some files",
      "P-task": "yui compressor - autom javascript compress skip file",
      "F_verb": "skip",
      "P-body": "You could name all of your uncompressed files \"whatever.max.js\", and then change the rule to something like this: .  ",
      "P-tags": "javascript minifi obfusc windows-shel yui-compressor",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP"
    },
    {
      "id": "ul_118786",
      "task": "Group memberships and setuid/setgid processes",
      "P-task": "group membership setuid setgid process",
      "F_verb": "group",
      "P-body": "The problem is that \"setuid\" and \"setgid\"\u00a0are not sufficient to give your process all the credentials it needs. The authorizations of a process depend on .   its UID its GID its supplementary groups its capabilities.  See \"man 7 credentials\" to get a more detailed overview. So, in your case, the problem is that you correctly set the UID and GID, but you don't set the supplementary groups of the process. And group \"bar\" has GID 54, no 73 so it is not recognized as a group your process is in. .  You should do .  ",
      "P-tags": "setgid group permiss setuid",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_2466169",
      "task": "Sort lines of massive file by number of words on line (ideally in parallel)",
      "P-task": "sort line massiv file number word line ideal parallel",
      "F_verb": "sort",
      "P-body": "A naive approach could be simply: .  This will keep up to 3 CPUs busy. \"sort\" is not limited by the amount of physical memory available, use the \"-S\" and \"-T\" switches to configure how much memory to use (\"-S\") before resorting to temporary files in a temp directory (\"-T\") on a big enough (and ideally fast) partition. .  If you can produce several input files by subdividing the work leading up to the sort phase, you would then be able to do: .  This will use up to \"N*2\" CPUs; moreover, the last sort (merge-sort) is highly efficient. .  Refining further to improve parallelism to \"N*2+1\" by using FIFOs instead of intermediate files, again assuming multiple input files are possible: .  If multiple input files are not possible, you can simulate them (adding I/O overhead which will hopefully be amortized by the number of processes available): .  Because we use modulo-line-number we have good locality and the filesystem cache should ideally bring the cost of reading the input file over and over in \"$PARALLELISM\" processes closer to zero. .  Even better, reading the input file only once and round-robin-ing input lines into several \"sort\" pipes: .  You should measure performance for various values of \"$PARALLELISM\" then pick the optimal one. .  EDIT As shown in other posts, you can of course use \"cut\" instead of the final \"awk\" (i.e. which strips the first column) for potentially better efficiency. :) .  EDIT2 Updated all scripts for the filename convention you provided, and fixed a bug in the last version. .  Also, using the new filename convention, if I/O is not the bottleneck then a very slight variation on \"dave\"/\"niry\"'s solutions should probably be even more efficient: .  ",
      "P-tags": "sort unix shell",
      "cate": "sort",
      "pat": "V NP of NP by NP of NP on NP"
    },
    {
      "id": "au_1045322",
      "task": "I messed up my packages and can't get them to work. Dependencies missing",
      "P-task": "mess packag get work\ndepend miss",
      "F_verb": "get",
      "P-body": "Try restoring your \"sources.list.d\" with the help of Always getting error during apt-get install .  And for your package installation error, run... .  This should work. .  ",
      "P-tags": "depend package-manag command-lin",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_28771400",
      "task": "Can I get only the part of the string that matches with Grep",
      "P-task": "get part string match grep",
      "F_verb": "get",
      "P-body": "Using GNU awk for the 3rd arg to match() and given this input file: .  This might be what you want: .  or this: .  but without more sample input and the expected output it's a guess. .  ",
      "P-tags": "awk bash grep regex",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP that S"
    },
    {
      "id": "ul_281320",
      "task": "Go to first line of console output of a command",
      "P-task": "go first line consol output command",
      "F_verb": "go",
      "P-body": "If the output is very long you could use the \"less\" command like below: .  And then scroll all the way down by pressing keys like Enter, Space etc. For more see the less manpage. .  You could even use \"more\" .  \"more\" works like \"less\" but uses different key combinations to page through the text. For more see the more manpage. .  Now you might remember that very old quote : .   less is more .   ",
      "P-tags": "termin output shell",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V to NP of NP of NP"
    },
    {
      "id": "so_25638795",
      "task": "Bash while loop with read and IFS",
      "P-task": "bash loop read if",
      "F_verb": "loop",
      "P-body": "You can use process substitution for this: .  ",
      "P-tags": "if while-loop bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_65736129",
      "task": "How to verify if rabbitmq is installed on windows?",
      "P-task": "verifi rabbitmq instal window",
      "F_verb": "verify",
      "P-body": "A list of installed software is available. What is the name of the RabbitMQ app in this list? Once this is known, it is easy to identify. .  ",
      "P-tags": "cmd rabbitmq c powershel window",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "au_16907",
      "task": "I can't find .bash_profile",
      "P-task": "find bash_profil",
      "F_verb": "find",
      "P-body": "If you open Nautilus, the file browser, go to your HOME directory and press CTRL+H you will see then all the hidden files (since hidden files start with the DOT \".\" character). Since you are talking about the \".bash_profile\", I am guessing you want to start via console instead of an interactive desktop. .  The difference between \".bash_profile\" and \".bashrc\" is the following: .   \".bashrc\" is the one that you edit when you want to change the way xterm or gnome-terminal open the console. how the bash works in this interactive places. .  \".bash_profile\" is the one you edit when you want to change how bash works when you login via console (Like the same way you login to a Ubuntu server or when you press CTRL+ALT+F1 to start a terminal) .   Since \".bash_profile\" does not come by default, you can just create it. But as I understand the default \".bash_profile\" is now called \".profile\" which can be seen in the HOME directory. Both, \".bashrc\" and \".profile\" can be edited to change how bash works in both, interactive and console modes. .  NOTE: If by some way you create \".bash_profile\", then Ubuntu wont read \".profile\" but instead go directly to \".bash_profile\" since both of them are the same but \".bash_profile\" has more compatibility because of old ways. So basically you do not need \".bash_profile\" if you have \".profile\". So just remember: .  \".bashrc - Interactive Console/Terminal (Gnome, KDE, Xfce...)\" .  \".profile - TTY Console/Terminal\" .  ",
      "P-tags": "10 10 command-lin bash",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "su_493891",
      "task": "On Linux, why does directory tab completion add a \\ to a path starting with ~",
      "P-task": "linux directori tab complet add path start",
      "F_verb": "add",
      "P-body": "I had accidentally created a directory named \"~\" in my home directory. This was the root cause of the problems. Removing this solved them. .  ",
      "P-tags": "linux command-lin",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "so_57539587",
      "task": "Windows Subsystem for Linux 2: Ubuntu, connect to external PostgreSQL database",
      "P-task": "window subsystem linux 2 : ubuntu connect extern postgresql databas",
      "F_verb": "connect",
      "P-body": "So it turns out I was pointing the finger in the wrong direction. .  I logged into the PostgreSQL server box with a colleague, and issued this command: .  \"ps -ef --sort=start_time | fgrep [db host name] | more\" .  It turns out, the existing connections to the server were fine, but something is jammed up. I have a bunch of idle processes, then a slew of ones saying \"startup waiting\" - over 100. Here's the output from the command: .  Aha! The culprit it found: .  \"postgres 14781 48821 0 00:00 ? 00:00:00 postgres: my-pg-server: postgres jsmith_d [local] VACUUM waiting\" .  It appears something is jammed up in the \"VACUUM\" process, which is causing the new connections to just hang, without failing. Time to dig a little deeper and clean it up, but there's the answer to this behavior. .  ",
      "P-tags": "psycopg2 ubuntu postgresql python windows-subsystem-for-linux",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_49841045",
      "task": "Bash for loop print two parameters",
      "P-task": "bash loop print two paramet",
      "F_verb": "loop",
      "P-body": "use shift command.  .  ",
      "P-tags": "bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_42868681",
      "task": "stop or restart the R CMD Rserve in ubuntu",
      "P-task": "stop restart r cmd rserv ubuntu",
      "F_verb": "stop",
      "P-body": "\"address already in use\" means that you have \"Rserve\" already running on the same port. The easiest way to shutdown \"Rserve\" is via .  Once it's down, you can start it again using \"R CMD Rserve\". .  ",
      "P-tags": "ubuntu rserv r",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "so_65757069",
      "task": "View man pages via Emacs in a terminal",
      "P-task": "view man page via emac termin",
      "F_verb": "view",
      "P-body": "Just use double quotes to enable parameters substitution, and escape internal double quotes, like this: .  ",
      "P-tags": "function emac bash",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP via NP in NP"
    },
    {
      "id": "au_1242740",
      "task": "Ubuntu 18.4 can't install latest version of speedtest-cli",
      "P-task": "ubuntu 18 4 instal latest version speedtest-cli",
      "F_verb": "install",
      "P-body": "You have to install it as root and so, will be installed in your PATH. So uninstall what you have installed .  \"pip3 uninstall speedtest-cli\" .  Then install it again, but as root .  \"sudo pip3 install speedtest-cli\" .  You can now run \"speedtest-cli\" (or shorter : \"speedtest\" as you told me) in your terminal (no root needed) .  ",
      "P-tags": "18 04 command-lin",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_663285",
      "task": "How to completely remove Phoronix Test Suite?",
      "P-task": "complet remov phoronix test suit",
      "F_verb": "remove",
      "P-body": "The installation script installs the same as the deb package. Therefore install and remove the deb package. .   Download the deb package .   Install the test suite .   Remove the test suite .    ",
      "P-tags": "uninstal",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_67437495",
      "task": "Why can't I select anything within this variable?",
      "P-task": "select anyth within variabl",
      "F_verb": "select",
      "P-body": "Piping to \"Format-*\" cmdlets is the last thing you'll want to do. .  Think of \"Format-Table\" as a laminator. You feed it a piece of paper, it'll spit it out laminated - very pretty, easy to read - but you can no longer edit the text on the paper. .  Instead, only call \"Format-*\" when you're ready to output to the screen: .  ",
      "P-tags": "powershel",
      "cate": "choose/select",
      "pat": "V NP within NP"
    },
    {
      "id": "so_29499248",
      "task": "Add all the usb devices in the user writen device driver",
      "P-task": "add usb devic user writen devic driver",
      "F_verb": "add",
      "P-body": "First of all you should understand what matching means. When you insert new USB device, kernel obtains information from it (vendor ID, product ID, etc) and tries to find some driver that support this device (i.e. driver that specifies the same vendor ID, product ID, etc). This procedure calls matching. .  NOTE: Usually matching devices (in your driver) that have vendorID/productID different from your device is bad idea. So maybe you don't really want to do that (actually I don't understand why you want to do so). Anyway, the answer is below. .  USB devices matching is happening in \"usb_match_device()\" function (in drivers/usb/core/driver.c). From there you can see that your entries in \".id_table\" must use one of available matching strategies (see matching flags below). .  The crucial thing to notice in \"usb_match_device()\" function is that it returns \"1\" if device successfully matched (not \"0\" which usually stands for \"success\" in kernel). So this function basically checks all matching flags specified, one by one, and checks if corresponding data in your structure is equal to data from tested USB device. All matching fields, specified in \".match_flags\" must be the same for your device and for device table entry being checked, to \"usb_match_device()\" function return success result. .  You can find matching flags in include/linux/mod_devicetable.h: .  Those flags are intended for filling \".match_flags\" field in \"struct usb_device_id\". For your convenience there are macros out there that create the whole \"struct usb_device_id\" using chosen strategy (like \"USB_DEVICE()\" macro that you are using). Those macros are defined in include/linux/usb.h: .  So it looks like you need to use \"USB_DEVICE_INFO()\" instead of \"USB_DEVICE()\": .  ",
      "P-tags": "linux-device-driv linux device-driv",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_61356979",
      "task": "How to get a list of all documents from SharePoint using PowerShell?",
      "P-task": "get list document sharepoint use powershel",
      "F_verb": "get",
      "P-body": "Demo to iterate all site collections by PnP PowerShell and SharePoint online management shell, if you want to access the library in all site collections, the account need access to all site collections(admin not has permissions to all site collections by default). .  ",
      "P-tags": "powershel sharepoint-onlin sharepoint",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP using NP"
    },
    {
      "id": "su_357155",
      "task": "Automatic FTP file transfer to and from Linux machines",
      "P-task": "automat ftp file transfer linux machin",
      "F_verb": "transfer",
      "P-body": "You can use the \"lftp\" client program and use an FTP script. .   \"lftp\" supports the \"~/.netrc\" configuration file, in which you can store your credentials: .  You can store a sequence of FTP commands in a file and have \"lftp\" execute them, like: .  The path in \"cd\" is on the remote host, the first argument to \"put\" is the local file. .  Then, just run .  ",
      "P-tags": "linux ftp",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V to NP"
    },
    {
      "id": "so_39653915",
      "task": "How to verify a PowerShell script is running using c#",
      "P-task": "verifi powershel script run use c",
      "F_verb": "verify",
      "P-body": "You are probably using the \"Pipeline.InvokeAsync\" method: .   After it is called, it changes the state of the pipeline to Running. When the method is completed, it changes the state of pipeline to one of following: Completed: The pipeline state is Completed if the pipeline invocation completed successfully. Failed: The pipeline state is Failed if the pipeline invocation failed or one of the commands in the pipeline threw a terminating error. Stopped: The pipeline state is Stopped if the pipeline was stopped by calling Stop or StopAsync. .   Source. .  ",
      "P-tags": "powershel c",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP using NP"
    },
    {
      "id": "so_17465312",
      "task": "Join conditions in awk",
      "P-task": "join condit awk",
      "F_verb": "join",
      "P-body": " ",
      "P-tags": "awk grep shell conditional-stat",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1031882",
      "task": "Unable to execute python script directly",
      "P-task": "unabl execut python script directli",
      "F_verb": "execute",
      "P-body": "I advise against changing the \"PATH\" variable for just a single script. If you're not going to use it in any other environment, you can simply change your script's shebang to point to \"python2.7\" directly: .  This way you can execute it with the full path, e.g.: .  If you however want to execute it conveniently with just a single keyword, I'd define an \"alias\" in the \"~/.bash_aliases\" file, let's take \u201cpeepdf\u201d: .  With that you're able to run your script simply with e.g.: .  ",
      "P-tags": "python bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_48522125",
      "task": "How to print a separator if value or two consecutive rows do not match for a column",
      "P-task": "print separ valu two consecut row match column",
      "F_verb": "print",
      "P-body": " ",
      "P-tags": "awk bash",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP if S"
    },
    {
      "id": "so_43724421",
      "task": "How to display a few line from the last few lines for a given number of files?",
      "P-task": "display line last line given number file",
      "F_verb": "display",
      "P-body": " ",
      "P-tags": "tail linux grep find",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP from NP for NP of NP"
    },
    {
      "id": "su_1576738",
      "task": "How to integrate Powershell 7 with Windows Explorer?",
      "P-task": "integr powershel 7 window explor",
      "F_verb": "integrate",
      "P-body": "PowerShell 7 (pwsh.exe) is not Windows PowerShell (powershell.exe and powershell_ise.exe) and does not replace or upgrade Windows PowerShell. .  PowerShell 7 (aka PowerShell Core), is a cross-platform version solution. It is designed to run side-by-side with Windows PowerShell on Windows OS's. .  It will never be the default since Windows PowerShell is delivered in the OS, thus the default and Powershell Core is a manual separate install. During the install of PowerShell Core, there were checkboxes that you should have selected. .   C:\\Users\\YourUserName\\Documents\\WindowsPowerShell C:\\Users\\YourUserName\\Documents\\PowerShell  Each having their own separate folder tree, profiles, settings, etc. Just as you had to first create a profile to get the folder tree in Windows PowerShell, you have to do the same for PowerShell core. .  Just open ... .   Windows PowerShell (powershell.exe) Windows PowerShell ISE (powershell_ise.exe) PowerShell Core (pwsh.exe)  ... and create a new profile in each instance. .  PowerShell Core does not, yet, completely provide all the Windows PowerShell does, and Windows PowerShell does not provide all that PowerShell Core does. .  Use the right tool for your goals, but know your legacy PowerShell code can and will break on PowerShell Core. You will have to refactor those. As well as certain settings in your profiles that will fail. .  If you want to use PowerShell Core all the time, then there are several ways to make that happen: .   Hit the Windows Key and type PowerShell and click the PowerShell version you want. Hit the WindowsKey + R to start the run box and type pwsh. Set a shortcut on your taskbar for pwsh.exe that you will use all the time. Use the new Windows Terminal and set pwsh.exe and your default terminal. If you are saying you are you want PowerShell 7 to be the RightClick run with, that means hacking the registry, or just create a shortcut to pwsh.exe and add that to your SendTo folder for use with Right-Click SendTo. If you are saying, you want to right-click the Windows Key to get to the Advance menu (WinX) to select PowerShell, you have to hack that menu area as well.  References: .   'add powershell 7 to explorer right click menu' .  'modify the windows 10 win x menu' .  Editing Windows Terminal JSON Settings .  Profiles.json Documentation .   ",
      "P-tags": "powershel window windows-10",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_16985864",
      "task": "ruby and rails return to earlier versions when I close and reopen terminal",
      "P-task": "rubi rail return earlier version close reopen termin",
      "F_verb": "return",
      "P-body": "Try this: .  It occurs probably because your default ruby version is 1.8.7. You can quickly check it with  .  To install 1.9.2, simply type: .  ",
      "P-tags": "ubuntu-12 04 rvm ruby-on-rails-3 ubuntu rubi",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V to NP when S"
    },
    {
      "id": "so_2149482",
      "task": "How can I replace ALL instances of a string in the previous command in Bash?",
      "P-task": "replac instanc string previou command bash",
      "F_verb": "replace",
      "P-body": "That particular feature is called quick substitution; its documentation can be found in the Event Designators section of the Bash Manual. You can't do what you want with quick substitution; you'll have to resort to something slightly more verbose: .  ",
      "P-tags": "bash",
      "cate": "replace",
      "pat": "V NP of NP in NP in NP"
    },
    {
      "id": "ul_175384",
      "task": "Detect changes in permissions",
      "P-task": "detect chang permiss",
      "F_verb": "detect",
      "P-body": "Check out the \"stat\" command, this shows 3 times the last time the file was accessed, when it was last modified and when it's permissions were last changed. .  The one which you're interested in is permissions (change), see the below output for an example file I have just chmod'ed; .  Or as @0xC0000022L says you could use \"stat -c\" to show just the output you need; .  ",
      "P-tags": "permiss",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_483969",
      "task": "grep pattern and the content after that, and remove others",
      "P-task": "grep pattern content remov other",
      "F_verb": "remove",
      "P-body": "\"sed\" would seem to be the right task for this: .  How this works: .  \"-n\" -- only print lines that match with a \"p\" command .  \"s/.../p\" -- search and replace, printing lines that match .  \".* \\(iwantthis\\) .* \\(url=[^ ]*\\) .*\" -- This will look for the word \"iwantthis\" surrounded by spaces and remember it, and also look for \"url=\" followed by non-spaces, and rememeber that. The \".*\" at each end mean that stuff before \"iwantthis\" and stuff after the URL are discarded. .  \"/\\1 \\2\" -- Replace it with the two remembered words .  ",
      "P-tags": "cut grep",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_1662400",
      "task": "Shell script sort list",
      "P-task": "shell script sort list",
      "F_verb": "sort",
      "P-body": "This might get you started: .   I'm ignoring the header line. You can get rid of it using \"head\" or skip it in the \"for\" loop. Sort the flights by date, arrival, departure and vip number - having the vip number as a sort key simplifies the logic later. I'm saving the result in an array, but you could redirect it to a temporary file and read it in a line at a time with a \"while read line; do ...; done <tempfile\" loop. I'm using indirection to make things more readable (naming the fields instead of using array indices directly - the exclamation point means indirection here instead of \"not\") For each line in the result that occurs on the same date as the most recently printed line, compare its arrival time to the previous flight's departure time Echo the lines that are appropriate. save the date and departure time for later comparison. You should adjust the \"<\" comparison to be \"<=\" if that works better for your data.  Here is the script: .  ",
      "P-tags": "algorithm sort bash",
      "cate": "sort",
      "pat": "V NP"
    },
    {
      "id": "ul_546081",
      "task": "KEYDEF of sort man page",
      "P-task": "keydef sort man page",
      "F_verb": "sort",
      "P-body": "The \"sort\" specification describes this in a little more detail: .   The \"'b'\" modifier shall behave like the -b option, but shall apply only to the field_start or field_end to which it is attached. The other modifiers shall behave like the corresponding options, but shall apply only to the key field to which they are attached; they shall have this effect if specified with field_start, field_end, or both. .   So you can add options in either position, and they apply to the whole key. They are cumulative, and I think the last one wins in case of conflict. .  If you want to compare multiple numeric fields, you should specify them as separate keys; the GNU \"sort\" manual says .   For the large majority of applications, treating keys spanning more than one field as numeric will not do what you expect. .   ",
      "P-tags": "sort",
      "cate": "sort",
      "pat": "V NP"
    },
    {
      "id": "so_45793497",
      "task": "bash: nested while read & for file in - no output",
      "P-task": "bash : nest read file - output",
      "F_verb": "read",
      "P-body": "\"$line_blastn\" is treated as one variable. Since that variable was never assigned any value, the output file will be just \".txt\". Files starting with a dot are hidden in Linux and Max OS, therefore you cannot see the output file. .  Write \"... >> \"${line}_blastn.txt\"\" to use just \"line\" as a variable. .  ",
      "P-tags": "blast while-loop bash",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_20867464",
      "task": "Change a script post-execution in a for loop",
      "P-task": "chang script post-execut loop",
      "F_verb": "change",
      "P-body": "Yes, it will change for the next execution of the loop. .  The shell re-reads and executes \"./file.py\" for each iteration. .  ",
      "P-tags": "linux python bash",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "so_52758294",
      "task": "How do I get disconnected networkdrives in Powershell?",
      "P-task": "get disconnect networkdr powershel",
      "F_verb": "get",
      "P-body": "You can get the status of network drives from the Users registry using: .  To access these reg entries you need to use \"Get-ItemProperty\", you can build a PSObject to hold the properties to make this nicer: .  Example properties: .  ",
      "P-tags": "map network-dr shell powershel net-us",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_20456712",
      "task": "How to get current time with jQuery",
      "P-task": "get current time jqueri",
      "F_verb": "get",
      "P-body": "You may try like this: .  Also using Javascript you can do like this: .     \r  .  ",
      "P-tags": "jqueri unix-timestamp time microtim datetim",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_46454495",
      "task": "Substitution between two patterns with line offset via sed or awk",
      "P-task": "substitut two pattern line offset via sed awk",
      "F_verb": "offset",
      "P-body": "You can use this \"awk\" command: .  Output: .  ",
      "P-tags": "awk sed bash",
      "cate": "move/scroll/offset/advance",
      "pat": "V via NP"
    },
    {
      "id": "au_280459",
      "task": "pygi how to toggle button without running function",
      "P-task": "pygi toggl button without run function",
      "F_verb": "toggle",
      "P-body": "If you want the function to be run most of the time the toggle signal is emitted, and not when you manually toggle it (e.g. when loading saved settings and displaying the appropriate state), then you need to block and unblock the signal. To do so you'll need the handle_id that was returned when the signal was connected to the function. Just assign a variable when you connect the signal. Here's an example: .  ",
      "P-tags": "pygi python program",
      "cate": "toggle",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_66902910",
      "task": "Could someone explain me what this shell bash command \"echo{,}\" means?",
      "P-task": "could someon explain shell bash command echo mean",
      "F_verb": "echo",
      "P-body": "I would start with something simpler to see how \"{}\" works: As @anubhava linked, it generates strings. Essentially, it expands all the elements in it and combines them with whatever is before and after it (space is separator if you don't quote). .  Example: .  Note that there is a space between \"echo\" and the arguments. This is not the case on what you have posted. So what happened there? Check the following: .  The result of the expansion is fed to bash and bash tries to execute it. In the above case, the command that is looking for is \"man1\" (which does not exist). .  Finally, combine the above to your question: .   \"echo{,}\"  \"{,}\" expands to two empty elements/strings These are then prefixed/concatenated with \"echo\" so we now have \"echo echo\" Expansion finished and this is given to \"bash\" to execute Command is \"echo\" and its first argument is \"echo\"... so it echoes echo!    ",
      "P-tags": "brace-expans bash",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_30396252",
      "task": "How to display progress of another command",
      "P-task": "display progress anoth command",
      "F_verb": "display",
      "P-body": "What you want to do is run \"do_something > file.txt\" in the background and then monitor it. You can use the special \"kill\" signal \"0\" to do this. .  ",
      "P-tags": "command-line-interfac shell bash",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP"
    },
    {
      "id": "so_32862039",
      "task": "How to subtract two different date formats to get days in bash?",
      "P-task": "subtract two differ date format get day bash",
      "F_verb": "get",
      "P-body": "Try this: .  ",
      "P-tags": "date unix shell bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_248776",
      "task": "Linux static routing : Ping a private network(Network Diagram Attached)",
      "P-task": "linux static rout : ping privat network network diagram attach",
      "F_verb": "ping",
      "P-body": "The first thing that comes to mind is VPN over SSH. See \"man sshd_config\" and search for PermitTunnel. .  First, make sure that \"PermitTunnel\" (both hosts) is enabled and that \"PermitRootLogin\" ( on systemB) is \"yes\" or \"without-password\" in \"/etc/ssh/sshd_config\" and that \"sshd\" is reloaded. .  Next, login to the host 10.200.8.14 using: .  The following step is to configure the interfaces with a dedicated VPN subnet (192.168.10.0 in this example): .  Then add a route for the network behind System B: .  Another approach is to use \"sshuttle\". Install \"sshuttle\" from source or the package manager. Then run: .  This will ask for \"sudo\" password since \"iptables\" is used to route traffic. You can alter the \"/etc/sudoers\" file using \"visudo\" to avoid asking for a password: .  Some interesting references: .  ",
      "P-tags": "rout linux network",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_31718918",
      "task": "unix console: how to delete lines that contained in other lines",
      "P-task": "unix consol : delet line contain line",
      "F_verb": "delete",
      "P-body": "Using \"awk\" and \"tac\" (concatenate and print files in reverse): .  Here's a more readable version of awk: .  ",
      "P-tags": "command-line-tool unix consol",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP that S"
    },
    {
      "id": "so_33812673",
      "task": "Handle commands like ls -l /somedir",
      "P-task": "handl command like ls -l somedir",
      "F_verb": "handle",
      "P-body": "This worked for me: .  ",
      "P-tags": "c unix",
      "cate": "handle/process/preprocess",
      "pat": "V NP"
    },
    {
      "id": "so_58701352",
      "task": "cmake 2.8 custom target to copy multiple files",
      "P-task": "cmake 2 8 custom target copi multipl file",
      "F_verb": "copy",
      "P-body": " Using a \"foreach\" loop within the \"add_custom_target\" clause does not work. .   But using \"foreach\" you may create a variable with all required commands. Then use that variable in add_custom_target: .  ",
      "P-tags": "linux prebuild cmake",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP"
    },
    {
      "id": "ul_364526",
      "task": "Kill child jobs that are running longer than 20 minutes",
      "P-task": "kill child job run longer 20 minut",
      "F_verb": "kill",
      "P-body": "A \"one-liner\", split onto two lines for less scrolling: .  It could be made tighter by using an output specifier for \"ps\" to limit the output to just the PID and COMM and ARG fields, then specifically matching COMM and ARGS, but the risks of a false-positive match seem low to me, here. .  ",
      "P-tags": "shell-script process background-process bash",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP that S"
    },
    {
      "id": "su_114526",
      "task": "How do I install a gtk theme?",
      "P-task": "instal gtk theme",
      "F_verb": "install",
      "P-body": "Head over to Appearance preferences from \"Administration->Preferences->Appearance\" Menu. Now, drag and drop \".tgz\\.tar.gz\" file. Else, click on the \"Install\" button in Appearance Preferences and navigate to the location where the theme is installed.  .  ",
      "P-tags": "gtk ubuntu-9 10 theme instal",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "su_676381",
      "task": "Ignore case from user input",
      "P-task": "ignor case user input",
      "F_verb": "ignore",
      "P-body": "Assuming you are using \"bash 4.0+\": .  Otherwise, \"tr\" or \"awk\" should work: .  Summaries: .   Awk takes in the input and simply prints \"$0\" (the whole input line) after using the built in \"tolower()\" function. .  Tr looks pretty self explanatory, but let me know if you have questions on it. .   ",
      "P-tags": "termin linux unix bash",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_630752",
      "task": "Using cURL to download a file, but with logging in before",
      "P-task": "use curl download file log",
      "F_verb": "download",
      "P-body": "You very likely need to store cookies. The answer by @jsotola is only appropriate for Basic authentication, which is becoming less common. And you said this is a POST request. .  Have a look at the \"-b\" and \"-c\" options. First issue a curl request to log in and save your cookies using the above mentioned options. Then repeat the call to download the file eg: .  The point of using cookies is to store the authentication tokens, without which every call you make is independent from previous requests. Of course it is possible that the website involves Javascript/Ajax and curl will not always do the job. .  Bonus: if you try with a browser like Firefox, the Web developer tools can even generate the Curl requests for you. .   .  ",
      "P-tags": "curl",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_13274235",
      "task": "How can I change the default GECOS fields under Ubuntu?",
      "P-task": "chang default geco field ubuntu",
      "F_verb": "change",
      "P-body": "Essentially the only software that cares about the GECOS field content (beyond the first comma which delimits the full name) for anything is \"adduser\", \"chfn\" and similar program for updating the pasword file. To a very good approximation, nobody uses these subfields, so you're free to put whatever you like in them. .  The hard-coded prompt strings in \"adduser\" or option letters in \"chfn\" probably can't be changed -- they are conventional uses anyway, and there is nothing like a central definition of subfield names anywhere. But don't let that stop you from storing \"user's favorite food\" in the field ostensibly for work phone numbers if that floats your boat. .  Note, however, that if you want to store any real information about users for more than toy purposes, \"/etc/passwd\" is most probably not the place to do it. Use a separate user-information database which is easier to make Unicode clean. .  ",
      "P-tags": "ubuntu-12 04",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP under NP"
    },
    {
      "id": "au_435899",
      "task": "Using Thunderbird to automatically backup my email account",
      "P-task": "use thunderbird automat backup email account",
      "F_verb": "backup",
      "P-body": "Thunderbird uses the IMAP protocol to download messages. There are command-line IMAP utilities with which you can automate connecting and downloading messages from your account. Look at getmail (http://pyropus.ca/software/getmail/) as a possible option. You can very easily automate this with a cron job (How do I set up a Cron job?). .  As an example you could create a ~/.getmail/getmailrc file with something like: .  Then in /etc/cron.d add a file \"retrieve-email\" with something like this: .  his will cause getmail to download your email every day at 10:15 AM and put it in the Maildir directory. .  PLEASE don't use these examples as they are; they are incomplete and illustrative only, I haven't tested them. Read the documentation I referred to so you can understand which getmail parameters you need. .  ",
      "P-tags": "thunderbird email backup",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "ul_567448",
      "task": "login to system without user id",
      "P-task": "login system without user id",
      "F_verb": "login",
      "P-body": "In your putty setup, go to \"Connection -> Data\" and set the Auto-login username to your user id. Save the session. From then on, the username will be entered for you. .  ",
      "P-tags": "ssh",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V to NP without NP"
    },
    {
      "id": "so_47706121",
      "task": "How can I check if my input file is updated?",
      "P-task": "check input file updat",
      "F_verb": "check",
      "P-body": "With Linux you can use the following code to tell if a file was updated: .  So using threads and a while statement you could do something like this .  ",
      "P-tags": "c++ linux",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_9925843",
      "task": "unixodbc and freetds setup on OSX and Rails 2.3.x",
      "P-task": "unixodbc freetd setup osx rail 2 3 x",
      "F_verb": "setup",
      "P-body": "Solved by compiling ruby-odbc against Homebrew libraries. This works if you are on OSX: .  ",
      "P-tags": "sql-server maco iodbc unixodbc ruby-on-rail",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V on NP"
    },
    {
      "id": "so_43217615",
      "task": "Force the password expiration date for a LOCAL user account",
      "P-task": "forc password expir date local user account",
      "F_verb": "force",
      "P-body": "The simplest way to set an account expiration date is to use the \"net\" command: .  AFAIK password expiration of local users can't be set to a specific date or for individual accounts. The expiration is controlled by the Maximum Password Age (local) security policy. You can set the maximum age from the commandline like this: .  but the policy affects all local accounts, and just defines a maximum age, not a specific expiration date. .  ",
      "P-tags": "powershel window",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP for NP"
    },
    {
      "id": "so_27100628",
      "task": "Does root overrides read only permission(even to root) set to directory in unix?",
      "P-task": "root overrid read permiss even root set directori unix",
      "F_verb": "set",
      "P-body": "Short answer is - Yes, Root user can create files in a directory that is marked as Read Only. You may argue - why? But that's the whole point of root account. It's a special user and it can do things that others can't. .  If you want to prevent the file from accidental modifications, you can set the \"i\" attribute of the file on with \"chattr +i\" command. This will make the file unchangeable. However, note that it will only prevent accidental modifications. Root users can still just unset the attribute first and then modify the file. .  ",
      "P-tags": "linux unix",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V to NP in NP"
    },
    {
      "id": "au_672873",
      "task": "Cannot add proxy exceptions on Ubuntu 15.04",
      "P-task": "add proxi except ubuntu 15 04",
      "F_verb": "add",
      "P-body": "The option is available via \"gconf-editor\" .   .  or with \"dconf-editor\" .   .  or via your Network sessings .   .  ",
      "P-tags": "15 04 network proxi",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_22392530",
      "task": "PHP cannot find MongoDB driver",
      "P-task": "php find mongodb driver",
      "F_verb": "find",
      "P-body": "I can give you my build recipe from a fresh 12.04 installation. Fresh being simply running through the configuration and only selecting the \"SSH server\" option at the end for convenience. .  MongoDB installation is optional, so if you want this on a different server then skip. But the general instructions come from: .  http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/ .  All commands split up and not automated so you can see the steps: .  Lots of compiler output. Ending with success and asking to mofidy php.ini .  Edit the CLI settings. And do the same for the apache config as well .  Personal preference, after the comments on 'Dynamic Extensions' .  Test that usage and connection does not throw an error. Create test.php: .  And run from command line: .  No errors. Then you are all set up. .  ",
      "P-tags": "mongodb ubuntu-12 04 php pecl apache2",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_46220805",
      "task": "how to check if new systemd user have permission to execute a binary file",
      "P-task": "check new systemd user permiss execut binari file",
      "F_verb": "check",
      "P-body": "Since it runs from the CLI but not from \"systemd\" on the same machine. this is a variation of the related FAQ: Difference between systemd and terminal starting program. .  The most likely cause is an environment variable set in one case but not another. Also compare the output of \"systemctl show your-unit-unit.service\" between the system where it works the one that it doesn't. .  Also confirm that \"Type=\" matches the kind of service you are running, documented in \"man systemd.service\", and review the documentation for your binary to see under what circumstances it would exit with a status code of 203. .  Finally, check \"ls -lthd /root\" on the server. Typically the \"/root\" directory has restrictive permissions set that only allow root to access files under it, but you are trying to run a file as a underneath there on your server (where it fails), but not at home (where it succeeds). Moving the code to \"/home/myservice\" would resolve that issue. .  ",
      "P-tags": "ubuntu systemd",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "ul_46707",
      "task": "SSH login to remote machine from another remote machine - How to manage connections?",
      "P-task": "ssh login remot machin anoth remot machin - manag connect",
      "F_verb": "manage",
      "P-body": "You'll need to run something like GNU \"screen\" on the RHEL box if you want to be able to re-connect to the ssh session to your BSD box. .   ssh to RHEL run \"screen\" ssh (from within screen) to BSD .  if/when the ssh to RHEL dies, ssh back in and reconnect to the screen session with \"screen -d -RR\" or similar. .   See the screen man page for details about the various re-attachment options. I use \"-d -RR\". .  BTW, you may want to edit your ~/.screenrc and redefine screen's Escape key...IMO the default of ^A is annoying because ^A means \"move cursor to beginning of line\" in emacs-like editing (which is the default on bash and some other shells). I redefine mine to ^K because it isn't used by many things so pressing ^Kk to send a ^K to the underlying app is no big deal while having to type ^Aa to send ^A to bash all the time is a major PITA. .  e.g. .  ",
      "P-tags": "remot ssh",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_23420572",
      "task": "Trouble formulating a regular expression for use with sed to extract column values",
      "P-task": "troubl formul regular express use sed extract column valu",
      "F_verb": "extract",
      "P-body": "The general caveat applies: \"awk\" is the better tool for the job. .  Here's a simpler \"sed\" solution: .   works with both spaces and tabs between columns takes advantage of repeating capture groups only reporting the last captured instance - in this case, the 5th column caveat: will not work correctly with filenames with embedded spaces  In case only spaces separate the columns - which is the case with \"ls\" output, the command simplifies to: .  To skip the first input line you have several options, but the simplest is to prepend \"1d\" to your \"sed\" program: .  (Other options: .  Use \"tail\" to skip the first line: .  More generically, use \"sed\" to ignore lines that do not have at least 5 columns: .   \"-n\" suppresses default output appending \"p\" to the substitution command only produces output if a substitution was made  ) .  To show only the 3 largest files (a requirement added later by the OP), courtesy of @JS\uc6c3: .  The above will not output the header line, however. To include the header line, use (courtesy of this unix.stackexchange.com answer): .  ",
      "P-tags": "sed linux text-pars shell",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_3389468",
      "task": "Simple shell scripting question: set name of directory using variable?",
      "P-task": "simpl shell script question : set name directori use variabl",
      "F_verb": "set",
      "P-body": "Here is the correct syntax .  Well the syntax may vary a bit depending on what shell you are using.  .  ",
      "P-tags": "shell",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP using NP"
    },
    {
      "id": "so_28651006",
      "task": "How to rename multiple files in directory?",
      "P-task": "renam multipl file directori",
      "F_verb": "rename",
      "P-body": "The solution is  .  ",
      "P-tags": "powershel batch-fil script",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "su_509089",
      "task": "Extract a single directory from rpm",
      "P-task": "extract singl directori rpm",
      "F_verb": "extract",
      "P-body": " use a wildcard, but be careful to protect it from the shell: .  \"rpm2cpio rpm_name | cpio -ivd './a/b/c/*'\" .  Not directly, but \"cpio\" does have a \"-r/--rename\" switch. There are unfortunately two problems with that: it asks about each file and it takes input from \"/dev/tty\" directly. Which means it's not easy to automate it. You could use the \"expect\" program if you really wanted to do it. Warning: not for the faint of heart ;) Note that it doesn't handle files with quotes (or possibly spaces) properly. It expects the name of the rpm file, a pattern for the files to extract and a \"sed\" command to transform each file. Usage example: .  \"cpio.sh rpm_name './a/b/c/*' 's#^./a/b/#foo/#'\" .   Theoretically the script could be piped into \"expect\" but that's left as an excercise for the reader. .  ",
      "P-tags": "linux rpm bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "su_368728",
      "task": "How can I connect to an Oracle database through a shell script?",
      "P-task": "connect oracl databas shell script",
      "F_verb": "connect",
      "P-body": "You're entering the wrong TNS Name while connecting. Check the TNSNames defined in \"$oracle_home\\network\\admin\\tnsnames.ora\" and use the defined TNS Name as  .  ",
      "P-tags": "oracle-10g shell",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP through NP"
    },
    {
      "id": "au_527166",
      "task": "How to set subl:// protocol handler with Unity?",
      "P-task": "set subl : protocol handler uniti",
      "F_verb": "set",
      "P-body": "To register custom protocol handler in chrome 1. Create the desktop file Create the file \"/usr/share/applications/sublime-handler.desktop\" .  2. Update the MIME-types database 3. Create the handler file Create the file \"/usr/share/handlers/sublime-handler\" .  Make it executable: .  4. Register mime-type handler 5. Profit Now you can open links with custom protocols from chrome via custom applications, example: .  6. Modify It can be ported for using with the different IDE, for example \"phpstorm\" .  ",
      "P-tags": "14 04 uniti",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP with NP"
    },
    {
      "id": "so_45991888",
      "task": "PATH issue: Could not find valid SPARK_HOME while searching",
      "P-task": "path issu : could find valid spark_hom search",
      "F_verb": "find",
      "P-body": "Setting  .  would enable to run the executable scripts like \"spark-shell\", \"spark-submit\", \"pyspark\" etc. without need to give full path to the scripts. .  Besides setting \"PATH\", you would need to set  .  which is used internally when you start spark cluster or when you use \"spark-submit\". .  If you are setting the variables in \".bashrc\" file, you need \"export\" keyword too as  .  and if you don't want to reboot Ubuntu to test it worked type  .  into the command line then try your spark command. .  ",
      "P-tags": "apache-spark ubuntu path",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP while S_ING"
    },
    {
      "id": "au_1316243",
      "task": "Librebase does not start for me 20.10",
      "P-task": "librebas start 20 10",
      "F_verb": "start",
      "P-body": "You have to reinstall full LibreOffice package by: .  ",
      "P-tags": "libreoffic",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V for NP"
    },
    {
      "id": "au_70236",
      "task": "How can I create an administrator user from the command line?",
      "P-task": "creat administr user command line",
      "F_verb": "create",
      "P-body": "Add the user to the \"sudo\" group with: .  (If you're running Ubuntu 11.10 or earlier, use the \"admin\" group.) .  Default values are stored in \"/etc/adduser.conf\", you can check them with .  To create a user and add it directly to the \"sudo\" group use .  (Again, use \"admin\" in place of \"sudo\" for 11.10 and earlier.)  .  Have a look at all the options you have with \"adduser\" here. .  ",
      "P-tags": "user-manag sudo addus",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "au_81714",
      "task": "How to escape spaces in pwd path when creating a Boost build script?",
      "P-task": "escap space pwd path creat boost build script",
      "F_verb": "build",
      "P-body": "You can quote the shell variables like: \"-sZLIB_SOURCE=\"$WD\"/\"$ZLIB_ROOT_DIR\"\". Do not escape the quotes. .  ",
      "P-tags": "build compil disk-usag script bash",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_43181692",
      "task": "How to include bluez latest version library using CMake in project",
      "P-task": "includ bluez latest version librari use cmake project",
      "F_verb": "include",
      "P-body": "Firstly, you need to make sure that \"pkg-config\" can find your installed version of \"bluez\". If it can't, then CMake won't be able to either. .  If that does not give you the version you expect, then you need to find the \"bluez.pc\" for the version that you want, and make sure its directory is at the beginning of PKG_CONFIG_PATH. Since you stated that you used \"sudo make install\", the \"bluez.pc\" you want is most likely at \"/usr/local/lib/pkgconfig/bluez.pc\". You will need to look yourself to be sure.) If that's the case, then .  should return the the version your looking for. If so, do what's necessary to make that change permanent to your shell. Delete your CMake cache, and re-cmake your project. .  ",
      "P-tags": "bluetooth linux bluez cmake",
      "cate": "import/include",
      "pat": "V NP using NP in NP"
    },
    {
      "id": "so_68959505",
      "task": "Laravel Envoy to SSH into bastion server, then, SSH into individual private web servers, stdout is split into new lines",
      "P-task": "laravel envoy ssh bastion server ssh individu privat web server stdout split new line",
      "F_verb": "split",
      "P-body": "Fresh Monday morning eyes led me here: .  https://unix.stackexchange.com/questions/572412/when-running-local-script-on-remote-server-via-multiple-ssh-script-is-split-int .  replacing .  with .  caused: .   Pseudo-terminal will not be allocated because stdin is not a terminal. .   A cheeky search later, suggested changing \"-t\" to \"-T\" .  https://appuals.com/fix-pseudo-terminal-will-not-be-allocated-because-stdin-is-not-a-terminal/ .  did the trick .  ",
      "P-tags": "laravel-envoy stdin stdout laravel bash",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V into NP"
    },
    {
      "id": "so_51858907",
      "task": "Loop through line for multiple values",
      "P-task": "loop line multipl valu",
      "F_verb": "loop",
      "P-body": "You could use Regular Expression to get the parts between the brackets in a string like \"[(7)]/[(8)] [ Security Agent 1] as security trustee for the Secured Parties (the \"Security Agent\")\". .  Instead of .  do .  ",
      "P-tags": "powershel",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP"
    },
    {
      "id": "so_17133278",
      "task": "How to access grid files by coordinate args in a bash script?",
      "P-task": "access grid file coordin arg bash script",
      "F_verb": "access",
      "P-body": "Here's a perl solution. .  Since reading all the data will probably be expensive, you should be able to pass in several pairs of coordinates at one time: that's the while loop consuming @ARGV. This gives you: .  ",
      "P-tags": "matrix grid geoloc bash",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP by NP in NP"
    },
    {
      "id": "so_49372578",
      "task": "How can I run a Shell when booting up?",
      "P-task": "run shell boot",
      "F_verb": "run",
      "P-body": "Scripts provided through User Data are only executed the first time the instance is started. Officially, it is executed once per instance id.) This is done because the normal use-case is to install software, which should only be done once. .  If you wish something to run on every boot, you could probably use the cloud-init once-per-boot feature: .   Any scripts in the \"scripts/per-boot\" directory on the datasource will be run every time the system boots. Scripts will be run in alphabetical order. .   ",
      "P-tags": "amazon-ec2 boot shell",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "su_864953",
      "task": "Show qemu command line from virsh",
      "P-task": "show qemu command line virsh",
      "F_verb": "show",
      "P-body": "You can consult the libvirt logs in: .  Source: https://fedoraproject.org/wiki/Windows_Virtio_Drivers .  ",
      "P-tags": "qemu virsh libvirt linux-kvm",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP from NP"
    },
    {
      "id": "au_100487",
      "task": "How can I report a bug for two packages?",
      "P-task": "report bug two packag",
      "F_verb": "report",
      "P-body": "First, it is recommended you use \"ubuntu-bug\" for reporting bugs. Instructions for using it are here. .  \"ubuntu-bug\", the command-line tool, currently only accepts one package at a time. You should try your best to guess what the most relevant one is. In order to add more packages to a bug report after sending, go to its Launchpad page and click \"Also affects project\". .   .  ",
      "P-tags": "launchpad bug-report ubuntu-bug",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V NP for NP"
    },
    {
      "id": "so_43780943",
      "task": "Parameterised powershell script through SSIS Execute Process Task (with UNC)",
      "P-task": "parameteris powershel script ssi execut process task unc",
      "F_verb": "execute",
      "P-body": "OK so as it appears I could not call a UNC path to execute this using an Execute Process Task, I decided to execute this within a Script Task with a reference added to \"System.Management.Automation\" which allowed me to create a PowerShell instance. This is far from my ideal solution as I really wanted to call a .ps1 file, but looks like this is my only solution given I need to use a UNC path. .  I build the PS script with my Dts variables and then executed it within the instance, which achieved the desired result: .  ",
      "P-tags": "powershel sql-server ssi",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_55201127",
      "task": "Limit the files while deploying - git",
      "P-task": "limit file deploy - git",
      "F_verb": "limit",
      "P-body": "There is a way to tell git not to take changes into account specific files : .  (doc) .  You can set it before deploying to production, and unset it for your everyday exchanges on gitlab. .  (The question about the respective interests of using \"--skip-worktree\" or \"--assume-unchanged\" has already been answered here, you might want to take a look.) .  ",
      "P-tags": "linux github bitbucket git gitlab",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP while S_ING"
    },
    {
      "id": "so_40196067",
      "task": "Parse $PATH variable and save the directory names into an array of strings",
      "P-task": "pars path variabl save directori name array string",
      "F_verb": "parse",
      "P-body": "2 main things wrong with your code, pretty much summarized by the comments: .   you strtok a public buffer (returned by \"getenv\") you don't know how many variables will be in the buffer so you don't allocate the array of arrays at all!  Let me propose a working implementation not using strtok, and thus allowing to detect empty path (and replace it by \".\" as Jonathan hinted). Compiles without any warnings using \"gcc -Wall -Wwrite-strings\": .  Details of the operations: .   make a copy of the env string to avoid butchering it count the colons (to make it work with windows, just replace with \";\") and tokenize allocate the array according to number of colons + 1 (1 more token than number of separators!) second pass to go through the string again and fill it with parts of the tokenized string (no need to allocate again, the original string is already allocated) special case: empty path: replace by \".\". Could display a warning to tell the user that this is not safe. print the result  ",
      "P-tags": "strtok malloc bash gcc c",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_26799609",
      "task": "Print only one match per line",
      "P-task": "print one match per line",
      "F_verb": "print",
      "P-body": "You can use \"grep -oP\" command: .  OR using \"awk\": .  ",
      "P-tags": "awk sh grep regex",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_57696406",
      "task": "Shell script to kill a process in specific time with process name and time as input",
      "P-task": "shell script kill process specif time process name time input",
      "F_verb": "kill",
      "P-body": " With this script you can kill the running process at a specific time by giving the process name and the time. [Note: The input for time must be in seconds only, i.e 120 for 2 minutes]  Sample Input: ",
      "P-tags": "linux kill-process bash",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP with NP as NP"
    },
    {
      "id": "so_47453079",
      "task": "Remove blank lines from output?",
      "P-task": "remov blank line output",
      "F_verb": "remove",
      "P-body": "If you really need the format that \"Format-List\" provides, then you can use \"Out-String\" and Trim() to get rid of empty lines: .  But, depending on your needs, it's probably easier to just use CSV or the JSON format for further processing (see \"ConvertTo-Json\" or \"ConvertTo-Csv\"). .  ",
      "P-tags": "powershel",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_2067920",
      "task": "Can I \"draw\"/create an image with a given text with powershell?",
      "P-task": "draw creat imag given text powershel",
      "F_verb": "create",
      "P-body": "Sure, if you're on PowerShell 2.0 try this: .  ",
      "P-tags": "system draw powershel jpeg",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP with NP"
    },
    {
      "id": "su_1092668",
      "task": "How to drop privileges in a Debian Chroot?",
      "P-task": "drop privileg debian chroot",
      "F_verb": "drop",
      "P-body": "I assume that the reason for the error is that the user exists in the old file system, but not the new one that you have changed to with \"chroot\". .  If I knew exactly where all the user details are held, I could advise on which files and directories from the old file system should be copied / linked / mounted into the new, in order that the old users can log into the operating system running with the new root. I think most of them will be in \"/etc\", but you can't just replace that directory regardless, as it will contain configuration data specific to the new file system. .  Failing that, a simple solution is to create the users you want within the new file system. Since your purpose is to test non-privileged users, you do not need to reproduce existing users exactly. .  ",
      "P-tags": "chroot linux debian privileg",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_224942",
      "task": "Command does not execute properly on remote server",
      "P-task": "command execut properli remot server",
      "F_verb": "execute",
      "P-body": "You need to enclose the remote command in quotes to execute it all on remote server, otherwise you run everything after pipe on local host, which is not what you want (as described in comments): .  ",
      "P-tags": "xarg ssh bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V on NP"
    },
    {
      "id": "su_659200",
      "task": "Fonts look thinner in gtk application when not using gnome",
      "P-task": "font look thinner gtk applic use gnome",
      "F_verb": "look",
      "P-body": "I wonder if this blog post would be of any help in understanding the problem. It's three years old, but the basic nature of the rat's nest still persists. .  Since you don't have \"gnome-settings-daemon\" running, \"xrdb\" and \"XSETTINGS\" never pick up the hinting settings established in the GNOME dialogs. So you'll need to fall back on \"fontconfig\" and setting up your own \"$HOME/.fonts.conf\", at which point you're writing obtuse XML entries. This Arch Linux Wiki page may help you get started. .  EDIT: Have a look at \"/usr/share/doc/fontconfig/fontconfig-user.html\" on your system, which describes the gory details. Happily, you may be able to avoid the goriest of the gory details by using some soft links. .  Please be aware that I have not actually tried the following: .  Take a look inside \"/etc/fonts/conf.avail\", which contains a number of pre-made config fragments. Of particular interest will be the files beginning with \"10-*\" and \"11-*\", which control how font hinting and sub-pixel positioning is to be done. Some of these are mutually exclusive; for example, you'll only want to pick one of the \"10-hinting-*\" fragments. .  First, inside your home directory, create a directory named \".fonts.conf.d\" and \"cd\" into it. Next, create soft-links to the config fragments you want to enable, which might look something like: .  At this point, once you have linked to your preferred fontconfig fragments, it will either magically work the next time you launch a program (I think this will be the case); or you'll need to run \"fc-cache\" to get the system to recognize your changes; or you'll need to log out and back in to your X session (least likely). .  ",
      "P-tags": "ubuntu awesome-wm gtk font emac",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP when S"
    },
    {
      "id": "so_9063024",
      "task": "How to write a batch command in linux ubuntu 10.04?",
      "P-task": "write batch command linux ubuntu 10 04",
      "F_verb": "write",
      "P-body": "$FILE includes the \".tif\" extension. Also \"BASE=$FILE .tif\" doesn't do what you think (it executes \".tif\" with $BASE set to $FILE for the duration of the command). .  You also have the difference between \"-a_srs\" and \"-s_srs\". I don't know which you intended. .  The end result is, I think, that you want to use \"test/$FILE\" as the output filename. .  (The quotes make it work with a path with spaces in it. Putting the \"for\" and \"do\" on the same line is a common way of writing it to save space.) .  ",
      "P-tags": "gdal batch-fil linux command",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_77973",
      "task": "How do I remove persistent config data from APT?",
      "P-task": "remov persist config data apt",
      "F_verb": "remove",
      "P-body": "Okay, I was able to find my own solution (ironically) because Gilles wasn't explaining himself properly and making me research his cryptic comments. .  Step 1: use \"dpkg -L $package\" or Synaptic's Properties dialog to find the file that didn't get purged with the rest of the package. I don't know why a file might not be purged properly, but that's what causes this problem. In my case it was /etc/avserver.conf. .  Step 2: install the offending package. This way the package manager will think it fixed the problem itself. .  Step 3: run \"sudo rm $offendingfile\" to delete the file that the package manager doesn't want to. .  Step 4: purge the package again. All package managers will recognize that nothing remains, because everything really is gone this time. .  Except for that one rm, this works with Synaptic, so I can give myself those bonus points. .  ",
      "P-tags": "dpkg apt aptitud synapt",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_40595616",
      "task": "Fix number of arguments / parameters within parentheses of SQL script",
      "P-task": "fix number argument paramet within parenthes sql script",
      "F_verb": "fix",
      "P-body": "SQL is very difficult to parse. If your data is pretty simple and your SQL is pretty regular, you might be able to get away with using awk in the way you're hoping, see next. Personally, I would probably inspect the database for inserted values, and scan the script for them, or vice-versa. Or insert a bunch of print statements and see where the error message is interposed.  .  Hoping for the best in awk, let's give it the old college try: .  With \"tr\", we delete the newlines. With \"sed\", we put each SQL statement (ending with \";\") on a line. With \"awk\", we split each line using parentheses as delimiters, so that the columns are in \"$2\" and the values are in \"$4\". The \"split\" command returns how many fields each of them has, using the comma as a delimiter in both cases. If they don't match, print the line. The last line displayed is the output, because the column name \"two\" is missing.  .  This could return some false positives, which in your case might not be terrible. If the data has semicolons or commas, the splitting will be wrong. If the INSERT doesn't mention column names, it will be wrong. If there are non-insert statements, you'll have to filter them out, or deal with them differently.  .  ",
      "P-tags": "termin shell bash sql sed",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP of NP within NP of NP"
    },
    {
      "id": "au_574206",
      "task": "How do I set the computer to turn off screen when battery is critically low?",
      "P-task": "set comput turn screen batteri critic low",
      "F_verb": "set",
      "P-body": "Just leave the \"gsettings\" on \"nothing\" and use the System Settings - Brightness and lock - \"dim screen to save power\" (use max 80%) and in the same screen \"Turn screen off when inactive for 10 minutes\".  .  The other way is to interfere in the suspend script, but if all you want is to turn off the monitor, the above is a much simpler solution. .  ",
      "P-tags": "batteri",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF when S"
    },
    {
      "id": "so_25829362",
      "task": "Node.js Express JS - Could not find module",
      "P-task": "node js express js - could find modul",
      "F_verb": "find",
      "P-body": "So that means that there is no \"config.js\" in the same folder as the \"app.js\". .  UPDATE: you'll want \"require('./config/config')\". .  ",
      "P-tags": "javascript npm express bash node js",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_22617147",
      "task": "How to sum values in a column grouped by values in the other",
      "P-task": "sum valu column group valu",
      "F_verb": "sum",
      "P-body": "Using \"awk\": .  For your input, it'd produce: .  ",
      "P-tags": "perl bash",
      "cate": "cumulate/sum",
      "pat": "V NP in NP by NP in NP"
    },
    {
      "id": "so_12888748",
      "task": "remove dups from many csv files",
      "P-task": "remov dup mani csv file",
      "F_verb": "remove",
      "P-body": "If you can keep the lines in memory If enough of the data will fit in memory, the \"awk\" solution by steve is pretty neat, whether you write to the \"sort\" command by pipe within \"awk\" or simply by piping the output of the unadorned \"awk\" to \"sort\" at the shell level. .  If you have 100 GiB of data with perhaps 3% duplication, then you'll need to be able to store 100 GiB of data in memory. That's a lot of main memory. A 64-bit system might handle it with virtual memory, but it is likely to run rather slowly. .  If the keys fit in memory If you can't fit enough of the data in memory, then the task ahead is much harder and will require at least two scans over the files. We need to assume, pro tem, that you can at least fit each key in memory, along with a count of the number of times the key has appeared. .   Scan 1: read the files.  Count the number of times each key appears in the input. In \"awk\", use \"icount[$1]++\".  Scan 2: reread the files.  Count the number of times each key has appeared; \"ocount[$1]++\". If \"icount[$1] == ocount[$1]\", then print the line.   (This assumes you can store the keys and counts twice; the alternative is to use \"icount\" (only) in both scans, incrementing in Scan 1 and decrementing in Scan 2, printing the value when the count decrements to zero.) .  I'd probably use Perl for this rather than \"awk\", if only because it will be easier to reread the files in Perl than in \"awk\". .   Not even the keys fit? What about if you can't even fit the keys and their counts into memory? Then you are facing some serious problems, not least because scripting languages may not report the out of memory condition to you as cleanly as you'd like. I'm not going to attempt to cross this bridge until it's shown to be necessary. And if it is necessary, we'll need some statistical data on the file sets to know what might be possible: .   Average length of a record. Number of distinct keys. Number of distinct keys with N occurrences for each of N = 1, 2, ... max. Length of a key. Number of keys plus counts that can be fitted into memory.  And probably some others...so, as I said, let's not try crossing that bridge until it is shown to be necessary. .   Perl solution Example data .  Note the absence of gigabyte-scale testing! .  fixdupcsv.pl This uses the 'count up, count down' technique. .  The '\"while (<>)\"' notation destroys \"@ARGV\" (hence the copy to \"@ARGS\" before doing anything else), but that also means that if you reset \"@ARGV\" to the original value, it will run through the files a second time. Tested with Perl 5.16.0 and 5.10.0 on Mac OS X 10.7.5. .  This is Perl; TMTOWTDI. You could use: .  There are probably ways to compress the body of the loop, too, but I find what's there reasonably clear and prefer clarity over extreme terseness. .  Invocation You need to present the \"fixdupcsv.pl\" script with the file names in the correct order. Since you have files numbered from 1.csv through about 2000.csv, it is important not to list them in alphanumeric order. The other answers suggest \"ls -v *.csv\" using the GNU \"ls\" extension option. If it is available, that's the best choice. .  If that isn't available, then you need to do a numeric sort on the names: .   Awk solution This ignores \"awk\"'s innate 'read' loop and does all reading explicitly (you could replace BEGIN by END and would get the same result). The logic is closely based on the Perl logic in many ways. Tested on Mac OS X 10.7.5 with both BSD \"awk\" and GNU \"awk\". Interestingly, GNU \"awk\" insisted on the parentheses in the calls to \"close\" where BSD \"awk\" did not. The \"close()\" calls are necessary in the first loop to make the second loop work at all. The \"close()\" calls in the second loop are there to preserve symmetry and for tidiness \u2014 but they might also be relevant when you get around to processing a few hundred files in a single run. .  ",
      "P-tags": "linux csv uniq bash sort",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "au_72438",
      "task": "I can not control Banshee from the sound menu in Gnome 3 Shell",
      "P-task": "control banshe sound menu gnome 3 shell",
      "F_verb": "control",
      "P-body": "Banshee's Sound Menu extension is specifically for Ubuntu's sound menu. .  Banshee doesn't currently make use of the playback controls in Gnome Shell's message tray and notifications. That feature is Bug 645628 if you're interested in following the progress. .  However, as Gamx points out below, even if this isn't possible out-of-the-box with Banshee, there are third-party solutions. .  Webupd8's PPA provides a \"gnome-shell-extensions-mediaplayer\" extension that allows you to control various media players -- including Banshee -- using the controls in Gnome Shell. To learn more about Personal Package Archives, see this question on Ask Ubuntu. To install the Gnome-shell extension, in terminal type: .  ",
      "P-tags": "11 10 gnome banshe indicator-sound",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_6558942",
      "task": "How do I write a Cairo surface to png to stdout?",
      "P-task": "write cairo surfac png stdout",
      "F_verb": "write",
      "P-body": "As it says in the documentation, write a function to handle the writing: .  Usage: .  ",
      "P-tags": "c++ linux cairo cgi",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP to NP"
    },
    {
      "id": "so_55360563",
      "task": "How can I skip the first argument in an ash/dash shell function?",
      "P-task": "skip first argument ash dash shell function",
      "F_verb": "skip",
      "P-body": "\"${name:offset}\" is a \"bash\"ism, but you can use the POSIX \"shift\" command for what you want. .  ",
      "P-tags": "dash-shel shell ash",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP in NP"
    },
    {
      "id": "so_286583",
      "task": "Can I print html files (with images, css) from the command-line?",
      "P-task": "print html file imag css command-lin",
      "F_verb": "print",
      "P-body": "You could give html2ps a try, it is written in Perl, so I guess it wil run on any operating system that runs Perl. It does support CSS and images. It does not render as good as you may perhaps want. .  To use in Debian/Ubuntu \"sudo aptitude install html2ps\" and then pipe the output to \"lpr\" to print: .  Or pipe the output to ps2pdf to convert to a pdf file: .  ",
      "P-tags": "print command-lin script linux html",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP from NP"
    },
    {
      "id": "so_11112331",
      "task": "Powershell script to change the format of all files in a folder from Unicode to ANSI",
      "P-task": "powershel script chang format file folder unicod ansi",
      "F_verb": "change",
      "P-body": "Try .  Note that the entire file will be read into memory temporarily. If that's not acceptable, you'll need to use the pipeline method to write to a new file, then delete the old file, and rename the new file to the old file's name. .  ",
      "P-tags": "powershel",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP in NP from NP to NP"
    },
    {
      "id": "so_60771502",
      "task": "How to get distro name and version from linux kernel code?",
      "P-task": "get distro name version linux kernel code",
      "F_verb": "get",
      "P-body": "There's no kernel API for detecting the current OS distribution, simply because it's not really needed. The Linux kernel itself is distribution-agnostic, and it couldn't care less which distribution is being run on top of it (having the kernel depend on what's being run on top of it wouldn't make much sense). .  If you really want, you can open, read and parse the file yourself from kernel space. See more in this other post for an example, and in particular this answer for modern kernels. In any case, remember that filesystem interaction from kernel space is generally discouraged, and could easily lead to bugs and compromise the security of the kernel if done wrong, so be careful. .  If you are developing a kernel module, I would suggest you to parse the \"/etc/os-release\" file from userspace when compiling/installing the module and use a set of \"#define\"s, or even module parameters. In any case, you should ask yourself why you need this information in kernel code in the first place, as you really shouldn't. .  ",
      "P-tags": "linux-device-driv linux linux-kernel",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_60299442",
      "task": "Using awk how do I replace a word in a file with unique values?",
      "P-task": "use awk replac word file uniqu valu",
      "F_verb": "replace",
      "P-body": "You may use it like this: .   .  ",
      "P-tags": "awk sed shell",
      "cate": "replace",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "su_353683",
      "task": "How can I create a Local DNS protocol for my vm?",
      "P-task": "creat local dn protocol vm",
      "F_verb": "create",
      "P-body": "The two most common protocols in use are: .   NBNS, NetBIOS name service \u2013 used by all versions of Windows, MS-DOS, OS/2, ... Supported by Unixes (incl. Mac OS X) via Samba nmbd. .  Uses UDP broadcasts, which are ineffective on large networks, but are just fine on small ones. NBNS only works over IPv4 due to its reliance on broadcasts. Security? What security? .  To make the VM reachable by NBNS, install Samba and start its \"nmbd\" service. \"smbd\" deals with file sharing and is not necessary.) Configuring the workgroup in \"smb.conf\" is optional but recommended \u2013 plain name resolution will work across workgroups, but less reliably. .  To let the VM reach other hosts, install \"nss_wins\" and configure \"/etc/nsswitch.conf\" to use the \"wins\" service: .   mDNS, Multicast DNS (also known as Bonjour) \u2013 used by Mac OS X, supported by Windows via \"Bonjour Print Services\" and Unixes via Avahi. .  Uses multicast UDP, which is better on larger networks (but still doesn't scale well). Again, no security. .  To make the VM reachable by mDNS, install Avahi and start \"avahi-daemon\". Note that all mDNS names by default are in the \".local\" domain (e.g. \"hadoopbox.local\"), as opposed to bare NBNS names. See this page if you already have a DNS domain named \".local\".) .  To let the VM reach other hosts, install \"nss_mdns\" and configure \"/etc/nsswitch.conf\" to use \"mdns\" and/or \"mdns_minimal\". \"avahi-daemon\" must be running as well. .    ",
      "P-tags": "linux dn",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "su_132767",
      "task": "Convert .png images into a .ppt presentation on Linux?",
      "P-task": "convert png imag ppt present linux",
      "F_verb": "convert",
      "P-body": "I'd output to PDF, which is commonly used for presentations. To convert use the \"convert\" program (from Image Magick). .  If you don't have convert yet, install the \"imagemagick\" package .  (It looks like you can also use convert directly to a .ppt file, but for me this doesn't work as well.) .  ",
      "P-tags": "microsoft-powerpoint linux present slideshow",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP on NP"
    },
    {
      "id": "so_5872438",
      "task": "Determine what hard drive a file or directory is on?",
      "P-task": "determin hard drive file directori",
      "F_verb": "determine",
      "P-body": "On Linux you can use the \"df\" utility. I don't know if it exists on mac. .  ",
      "P-tags": "unix maco bash",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V what S"
    },
    {
      "id": "so_38962405",
      "task": "Awk - Control when my $# variables are expanded to merge two files with variable number of columns",
      "P-task": "awk - control variabl expand merg two file variabl number column",
      "F_verb": "merge",
      "P-body": "Try this (untested): .  Don't let shell variables expand within awk scripts, use a regexp to remove fields from the record and idk why the script you haven't shown us is printing literally \"$3\", etc. but you must be including them in a string. You'd have to post that script for help debugging it. .  Check where mf1 vs mf2 should appear, I got confused reading your scripts. .  EDIT - I had to tweak it as above I was deleting $2 before using it: .  Note that the sub() above relies on the key field being $2 and FS being a tab. If you need a more general solution let us know. .  Here's a version that'll do what you want for any key field values and will work in any awk, it just requires the FS to be a tab or some other fixed string (i.e. not a regexp): .  ",
      "P-tags": "awk bash",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP of NP"
    },
    {
      "id": "so_63999457",
      "task": "How to execute powershell code in current directory from terminal?",
      "P-task": "execut powershel code current directori termin",
      "F_verb": "execute",
      "P-body": "Simply omit the directory path altogether (\"powershell.exe -File run.ps1 \"foo bar\"\") or prefix the script file name with \".\\\" (\"powershell.exe -File .\\run.ps1 \"foo bar\"\") in order to run a script located in the current directory. .  Note that in cases where you need to use \"-Command\" rather than \"-File\", the \".\\\" prefix is required, because PowerShell then treats the CLI arguments as PowerShell code, and for security reasons PowerShell doesn't permit running scripts in the current directory by file name only - see this answer. .  See also: about_PowerShell_exe, the documentation of the Windows PowerShell CLI (for PowerShell [Core] v6+, whose executable file name is \"pwsh\", the relevant topic is about_pwsh.) .  ",
      "P-tags": "powershel command-line-interfac",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "au_20053",
      "task": "How to assign correct permissions to both webserver and svn users?",
      "P-task": "assign correct permiss webserv svn user",
      "F_verb": "assign",
      "P-body": "There is also a group called \"www-data\". The files you have in your webroot should all belong to that group and have write-right for the group. Assuming your webroot is \"/var/www\" you can do this by executing (as root or by using \"sudo\") .  ",
      "P-tags": "svn webserv permiss",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_63381",
      "task": "How to list all the installed package in fedora with the time of the installation",
      "P-task": "list instal packag fedora time instal",
      "F_verb": "list",
      "P-body": "As root (or using \"sudo\"), use the \"yum\" option \"history\". .  You can view the packages and changes for a specific \"yum\" transaction: .  You can view the history specific packages with: .  \"man 8 yum\" or \"yum help history\" will list more options that are possible with the history option. .  ",
      "P-tags": "linux fedora yum shell",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP in NP with NP of NP"
    },
    {
      "id": "so_43863203",
      "task": "Need to grep all comments from an SQL file",
      "P-task": "need grep comment sql file",
      "F_verb": "grep",
      "P-body": "In Orignal format:  .  Or in Single line: .  ",
      "P-tags": "awk linux grep sed",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_63885112",
      "task": "How to POST in CURL and save header response",
      "P-task": "post curl save header respons",
      "F_verb": "post",
      "P-body": "Use \"-D <filename>\" .  Example : .  ",
      "P-tags": "xml linux http curl rest",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V in NP"
    },
    {
      "id": "ul_423534",
      "task": "How do I get the pingable IPv6 address of my machine?",
      "P-task": "get pingabl ipv6 address machin",
      "F_verb": "get",
      "P-body": "From \"man ping6\", you must tell ping which interface you are using: .   -I interface address .  Set source address to specified interface address. Argument may be numeric IP address or name of device. When pinging IPv6 link-local address this option is required. .   For example, if your interface is \"eth0\": .  or, without the \"-I\" option: .  ",
      "P-tags": "linux network ipv6",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_3668928",
      "task": "C function to escape string for shell command argument?",
      "P-task": "c function escap string shell command argument",
      "F_verb": "escape",
      "P-body": "Replacing all instances of \"'\" with \"'\\''\" then enclosing the whole string in single quotes (\"'\") is one safe way. This works even with embedded newlines. Another method would be to insert \"\\\" before each character, except that then you have to do some special treatment for newlines since \"\\\" followed by a newline is ignored by the shell, not treated as a literal newline. You'd have to surround newlines with \"'\" (single quotes). .  ",
      "P-tags": "escap c function shell",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP for NP"
    },
    {
      "id": "so_9275909",
      "task": "Validate an ip in dash (not bash)",
      "P-task": "valid ip dash bash",
      "F_verb": "validate",
      "P-body": "Assuming you are happy with the validation string: .  Note that this accepts invalid ip addresses like 876.3.4.5 .  To validate an ip, it's really not convenient to use a regular expression. A relative easy thing to do is: .  ",
      "P-tags": "dash-shel sh shell",
      "cate": "validate/authenticate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_628734",
      "task": "How to run streamus app from terminal",
      "P-task": "run streamu app termin",
      "F_verb": "run",
      "P-body": "TL;DR The script can not work because that shortcut will be sent to the active window, and that's not \"chromium-browser\" with \"Streamus\". .   This is your reload \"xdotool\" command: The complete command in your case is: .  The execution of the shortcut can be somewhat delayed with \"sleep 1\": .   This is your play/pause \"xdotool\" command:  A sample script: To start Streamus, reload and \"press\" play .   Explanation:  \"xdotool search --limit 1 --name \"^Streamus$\"\" .   \"search\" .  Search for windows with titles, names, or classes with a regular expression pattern. .  \"limit N\" .  Stop searching after finding N matching windows. Specifying a limit will help speed up your search if you only want a few results. .  \"--name\" .  Match against the window name. This is the same string that is displayed in the window titlebar. .   \"xargs -I {} xdotool windowactivate --sync {} key ctrl+r\" .   \"xargs -I {}\" .  Build and execute the command \"xdotool\" .  \"xdotool windowactivate --sync {} key ctrl+r\" .   \"windowactivate\" .  Activate the window. .  \"sync\" .  After sending the window activation, wait until the window is actually activated. .  \"{}\" .  \"xargs\" replaces \"{}\" with the window id .  \"key ctrl+r\" .  sends the shortcut Ctrl+R .     ",
      "P-tags": "chromium script xdotool bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_21802223",
      "task": "How to install crontab on Centos",
      "P-task": "instal crontab cento",
      "F_verb": "install",
      "P-body": "As seen in Install crontab on CentOS, the crontab package in CentOS is \"vixie-cron\". Hence, do install it with: .  And then start it with: .  To make it persistent, so that it starts on boot, use: .   On CentOS 7 you need to use \"cronie\": .  On CentOS 6 you can install \"vixie-cron\", but the real package is \"cronie\": .  and .  In both cases you get the same output: .  ",
      "P-tags": "cento linux cron crontab",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_9817712",
      "task": "How do I see the Python doc on Linux?",
      "P-task": "see python doc linux",
      "F_verb": "see",
      "P-body": "Online documentation The simplest way is to use Google to get to online documentation. There is no single point where you find all documentations of all modules. However, a few common ones are: .   Python 3 NumPy and SciPy Theano  If you need offline documentation there are a few other possibilities: .  Download it You can download the documentation as HTML or a PDF: https://docs.python.org/3/download.html .  When you have a web server running, you can use the HTML version and access it as you are used to via a browser. The HTML site looks just like you are used to. Even the search works offline, because it is implemented with JavaScript. .   .  PyDoc Some distributions like Debian offer a \"python-doc\" package. You can access it via \"pydoc -p [some port number]\" or via \"pydoc -g\". This will create a local web server. Then you can open your browser and have a look at it: .    .  Console: help(...) The Python interactive console has a built-in \"help(...)\" system. You can either invoke it without an argument: .  or you can call it with a paramter about which you want to know something. That can be anything (a module, a class, a function, an object, ...). It looks like this: .  ",
      "P-tags": "doc linux python",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP on NP"
    },
    {
      "id": "so_33037476",
      "task": "npm install stops working",
      "P-task": "npm instal stop work",
      "F_verb": "install",
      "P-body": "It could be problem with your npm version or temp directories - there is a similar issue resloved on npm GitHub - https://github.com/npm/npm/issues/7590 .  Check if you have two temp directories set in your .npmrc: .  Look for lines defining the tmp config variable. If you find more than one, remove all but one of them. .  Also try updating your npm version to newest. .  ",
      "P-tags": "node js powershel npm",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V S_ING"
    },
    {
      "id": "so_22586681",
      "task": "can't kill PID from script loop",
      "P-task": "kill pid script loop",
      "F_verb": "kill",
      "P-body": "Don't try to reinvent the wheel. If \"pkill\" is available use it. .  \"pkill -f clipit\" .  If not you can use something like. .  \"kill $(ps -eo pid,comm|grep clipit|grep -v grep|cut -d' ' -f1)\" .  ",
      "P-tags": "shell bash",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from NP"
    },
    {
      "id": "so_27777097",
      "task": "How can I split my file into multiple files?",
      "P-task": "split file multipl file",
      "F_verb": "split",
      "P-body": "Here's another awk answer: .  This is similar to nu11p01n73R's answer but uses the third field of each \"Report\" line to determine the file number. .   When \"/^Report/\" matches the line, the set \"n\" to \"$3\". Use \"n\" when creating the file name to print each line to  If you have a large number of these blocks, you might need to end up closing files and could use this command instead: .   When \"/^Report/\" matches the line, create a filename \"f\". If \"lf\" (last filename) doesn't match \"f\", first try to close \"lf\" then reset \"lf\". Calling close() when \"lf\" hasn't been set is safe print every line to \"f\"  ",
      "P-tags": "awk linux unix",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP into NP"
    },
    {
      "id": "so_21466674",
      "task": "What powershell command can change the TextInfo.ListSeparator?",
      "P-task": "powershel command chang textinfo listsepar",
      "F_verb": "change",
      "P-body": "To give credit where credit is due, please see original source of this function located at: https://gist.github.com/abombss/1129655 .  From that you should be able to either just run the function before and after the application or extrapolate what you need to make the exact script that you want. .  ",
      "P-tags": "powershel",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "au_1156744",
      "task": "Replacing SSD to check if works",
      "P-task": "replac ssd check work",
      "F_verb": "check",
      "P-body": "As a \"Computer Hardware Service Manager\" with over 30 years experience, I'd say don't do this. The risk of taking a working computer (yours), and breaking it, are too high... especially if we're talking laptop. .  If you have a desktop, then their SSD could be connected to a second SATA port (with the appropriate cables), and that would be fine. .  Rather, tell the friend to check the SSD's SMART Data log, and to run the SMART diagnostic tests, both by using the \"Disks\" application or \"smartmontools\" (or Windows equivalents), and check \"/var/log/syslog*\" (or the appropriate Windows log files), on their own computer. .  ",
      "P-tags": "ssd",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V S_INF if S"
    },
    {
      "id": "so_69768598",
      "task": "Propagate bash tracing (set -x) to all child scripts",
      "P-task": "propag bash trace set -x child script",
      "F_verb": "propagate",
      "P-body": "I accomplished this task by creating a file \"$HOME/.bash_env\" like: .  Then I added .  to \".bash_rc\". .  So, each scripts will get bash tracing enabled. .  ",
      "P-tags": "linux shell bash",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_21530785",
      "task": "Make VIM cursor behave like Elvis",
      "P-task": "make vim cursor behav like elvi",
      "F_verb": "make",
      "P-body": "I'm not sure whether it is possible to achieve exactly what you want from the Vim cursor (without changing Vim too much, that is), however I do know how to achieve what you want. .  Usually this is done using the blockwise visual mode. E.g. to perform the refactoring needed for your example you would: .   Select all three lines using \"Ctrl-V\" to enter the visual mode. Press \"Shift-I\" to enter the insert mode Change the first entry Leave the visual mode. The change will be applied to all rows.  I think this is more efficient then the solution offered by Elvis. .   If you use plugins an even better approach is multiple-cursor mode. Add a cursor per each row, perform the same operation on each one. .  ",
      "P-tags": "slackwar ubuntu",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_41235974",
      "task": "Read infile with Unix pipe and sort it",
      "P-task": "read infil unix pipe sort",
      "F_verb": "read",
      "P-body": "You call \"pipe()\" twice; delete the first. You call \"fork()\" twice; it isn't clear cut which one you should delete. However, deleting the first means the fewest other changes. You also need to avoid closing \"fd[1]\" in the parent so that the second and subsequent children still have a valid pipe to use. .  Slightly flawed code This code at least works when the output is sent direct to the terminal (not via a pipe): .  With a copy of the source copied to \"infile\", it produced the correct number of lines of output (double spaced). .  The code is still not good for many reasons, not least of which are that 'one process per line' is somewhat wasteful, and 'fork a process with the content of the line in a buffer, then write that buffer back to the parent (which already knew what was in the buffer) is a bit pointless'. OTOH, it does use a pipe to communicate between two processes. .   More work needed, but no infinite loop When I run the code shown on the data file: .  the output I get is: .  Hmmm...that's a bit odd: first 1; then 1, 2; then 1, 2, 3; then 1, 2, 3, 4. I didn't spot this in my trial with the last 43 lines whizzing past double spaced.) Let me investigate. But there's no infinite loop, so you merged something incorrectly from my code into yours. .   Piping output changes line buffering to full buffering I used the name \"xc19\" for the program (source \"xc19.c\"). .  The problem with the code above is that I used \"xc19 | pbcopy\" to run and copy the output to the clipboard (on a Mac). That meant that the output was no longer line buffered but rather 'fully buffered'. So, the intermediate outputs were still in the standard I/O buffer of each child, so when the child process exited, that information was flushed. But each child got more information in the buffer. .  The fix is very simple: use \"fflush(0);\" or \"fflush(stdout);\" in the parent code. Here's a version with more compressed output (and diagnostics in the form of PIDs being printed): .  Output: .  ",
      "P-tags": "pipelin c unix",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP with NP"
    },
    {
      "id": "so_13036871",
      "task": "Grep files with uncommented \"console.log\" string",
      "P-task": "grep file uncom consol log string",
      "F_verb": "grep",
      "P-body": " Use \"-L\" switch  .   .  Update: ",
      "P-tags": "grep unix regex",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "au_610753",
      "task": "How to boot Ubuntu in complete darkness?",
      "P-task": "boot ubuntu complet dark",
      "F_verb": "boot",
      "P-body": "Try this tutorial: http://www.howtogeek.com/196655/how-to-configure-the-grub2-boot-loaders-settings/ .  When editing your grub file, this option should be enougth to load automatically your first boot option: .  After changing your grub file, apply changes with the command .  Hope this helps you. .  ",
      "P-tags": "boot bootload grub2",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "so_55934254",
      "task": "How to fix 'parse error on input \u2018=\u2019' when compile the following quicksort example?",
      "P-task": "fix pars error input compil follow quicksort exampl",
      "F_verb": "fix",
      "P-body": "The indentation of the two declarations in the \"let\" clause should match, like: .  In your original question, you also forgot to use the \"<-\" operator in the generator expression part of your list comprehension: you should thus write \"a <- xs\", instead of \"a xs\". .  You can however, as @RobinZigmond says, add spaces before and after the \"=\", as long as you have the same number of spaces before the first non-space character, this is fine, like: .  Note that you can use \"partition :: (a -> Bool) -> [a] -> ([a], [a])\" to split a list in two lists where the first sublist has elements that satisfy the predicate, and the latter has the elements that do not satisfy the predicate, like: .  The \"partition\" function is normally implemented in such way that it iterates only once over the given list, and only performs the test once. So this is typically (a bit) more efficient than using two list comprehensions that each individually filter the given list. .  ",
      "P-tags": "ghci linux haskel",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP when S"
    },
    {
      "id": "au_1252659",
      "task": "Why does my ssh login include what looks like a promotion for a TechRepublic article?",
      "P-task": "ssh login includ look like promot techrepubl articl",
      "F_verb": "include",
      "P-body": "In this file: .  Comment out the following 2 lines: .  This should remove the MOTD. .  ",
      "P-tags": "bashrc login ssh",
      "cate": "import/include",
      "pat": "V what S"
    },
    {
      "id": "su_789745",
      "task": "Configure Raspberry PI Access Point to use RADIUS Apache Authentication?",
      "P-task": "configur raspberri pi access point use radiu apach authent",
      "F_verb": "configure",
      "P-body": "RADIUS is commonly used as a way for an AP to use WPA2-Enterprise (802.1X) authentication, but outsource the actual AP-side authentication to a separate server (the RADIUS server). You configure it in \"hostapd\"'s conf file. It has nothing to do with DHCP or your \"/etc/network/interfaces\". .  Web-based authentication (also called \"Captive Portal\") is a separate concept, and it's pretty much mutually exclusive with WPA2-Enterprise. Web based authentication requires that you let clients on basically without authentication, so that they have enough network connectivity that they can get redirected to a web server. Web-based authentication really doesn't have anything to do with DHCP either, although you probably want to have a DHCP server on your network so that the wireless clients get an IP address lease via DHCP so that they have enough network connectivity to try to reach a web server. .  If you want to do web-based authentication but use a separate authentication server, you would configure your AP for Captive Portal mode, and then you would set up your web server to provide an authentication UI, and relay that authentication attempt to a separate authentication server. However, the in the web server world, it's much more common to use LDAP, not RADIUS, as the remote authentication protocol. .  ",
      "P-tags": "wireless-network raspberry-pi linux network",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_410456",
      "task": "zsh completion: make sshrc behave like ssh",
      "P-task": "zsh complet : make sshrc behav like ssh",
      "F_verb": "make",
      "P-body": "This works for me using \"zsh 5.4.2\" .  under the minimal configuration of \"zsh -f\". This may be thwarted by your shell configuration; in that case you'll need to bisect your configuration to see what's screwing up what. .  This trick was found by looking at the \"_ssh\" completion which shows for \"slogin\" an equality with \"ssh\": .  ",
      "P-tags": "autocomplet ssh zsh",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_22103582",
      "task": "Linux: How to execute script when directory is written to",
      "P-task": "linux : execut script directori written",
      "F_verb": "execute",
      "P-body": "Here is a Gtkmm example for detecting when a file or folder is created inside a directory: .  Compile with .  ",
      "P-tags": "incron linux centos6",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "ul_292188",
      "task": "Newline (\"\\n\") before output in bash",
      "P-task": "newlin n output bash",
      "F_verb": "output",
      "P-body": "You can \"trap\" the \"DEBUG\" signal: .  \"DEBUG\" trapped command \"printf \"\\n\"\" will be run before the command is executed unlike \"PROMPT_COMMAND\" which will be run after the command is executed. .  You can add this to your \"~/.bashrc\" to make it permanent. .  Example: .  ",
      "P-tags": "prompt output bash",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in NP"
    },
    {
      "id": "so_43717151",
      "task": "How to save colored text with bash color in txt file?",
      "P-task": "save color text bash color txt file",
      "F_verb": "save",
      "P-body": "   \r  .  After saving data in html file open it in your browser .  or check another example .  ",
      "P-tags": "fwrite php bash",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "au_38026",
      "task": "Will LibreOffice 3.4 be included in an update?",
      "P-task": "libreoffic 3 4 includ updat",
      "F_verb": "update",
      "P-body": "LibreOffice 3.4.3 for Natty was released 7 Oct 2011. Consider adding the libreoffice repository: .  This will make sure you're always up to date with the newest versions of Libreoffice. .  ",
      "P-tags": "11 04 libreoffic",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_45313813",
      "task": "How to start PowerShell in WiX with proper access to Windows Registry?",
      "P-task": "start powershel wix proper access window registri",
      "F_verb": "start",
      "P-body": "Oh... my... god... .  Ok I finally got it working. There were actually several problems and the solutions for these problems were actually in bits and pieces of information that I gather from across multiple SO questions. .  To recap, here is what I was trying to do: .   Launch a powershell from WiX to run my install script. My script search Windows Registry (requires 64bit) for installed Exchange Server's location My script loads the Exchange Management Shell (EMS) script (requires 64bit AND proper user) from the install location Under the EMS session, my script run a brunch of other scripts to register an Exchange plugin  Problem 1) .  No matter what I did, the WiX installer always launches my powershell in 32bit, this is regardless of setting \"Platform=\"x64\"\", \"Win64=\"yes\"\", and even \"WixQuietExec64\". I even built the installer in Visual Studio as \"x64\" and everything else as \"x64\". .  The solution is to directly reference the \"sysnative\" powershell, it has to be \"sysnative\" in the \"SetProperty\".  .  I actually did tried this before, and thought it wasn't working, but the root cause was being masked by Problem 2 below. .  Problem 2) .  Everywhere I read, they said you need to run with \"Execute=\"deferred\" Impersonate=\"No\"\". I believe this would indeed work for the most cases if you are not doing anything funky. However, I had to \"Impersonate\". I discovered that the WiX installer would run your CA as elevated with user \"NT Authority/System\". This screwed me over because the \"Exchange Management Shell\" script I was trying to source would basically use your credential and try to establish a session with the Exchange Server... and of course you can't connect as \"NT Authority/System\"! .  The solution is to use \"Impersonate=\"yes\"\" so that the WiX installer would run your CA as elevated AND the user you are currently logged in. I always had the impression that you must use \"Impersonate=\"no\"\" when using \"Execute=\"deferred\"\"... but you don't. .  I gave up troubleshoot this for a few days and then went back to it and got it working. The 2 most helpful commands that helped me figured this out were actually: .   whoami Get-ChildItem env: (to check the PROCESSOR_ARCHITECTURE)  ",
      "P-tags": "registri wix3 11 windows-instal wix powershel",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP with NP to NP"
    },
    {
      "id": "au_475419",
      "task": "How to Link and use two or more Dropbox Accounts simultaneously",
      "P-task": "link use two dropbox account simultan",
      "F_verb": "link",
      "P-body": "General idea [source] .   The basic idea is to just start Dropbox from the command-line using an alternate home directory. This will create another Dropbox icon, and another Dropbox folder, which has to be in some other place from the original one.  .  The two Dropbox folders will both be called Dropbox (this cannot be changed), but you can distinguish them by their location. .    .  Setup Method: 1 - If you have installed \"nautilus-dropbox\" from the repository Open a terminal and paste the following commands: .  A new Dropbox setup wizard window will open and second Dropbox icon should appear on the status bar.  .   Choose an existing account (different from the original one!) or create a new one. Make sure you choose an alternate location for your new Dropbox folder.  Now your alternate dropbox is set. .  start Dropbox from terminal .  start Alternate-Dropbox from terminal .  Method: 2 - If you have compiled \"dropbox\" in your home from \"tar.gz\" file Open a terminal and paste the following commands: .  Dropbox setup wizard window will appear. Finish the setup similarly as described in Method -1  .  start Dropbox from terminal .  start Alternate-Dropbox from terminal .  Note:  You can create a small script with the above commands to start Dropbox. One can put the script at startup. Don't forget to give the script execution permission.    I have tested the second method. Hope it will be useful.  ",
      "P-tags": "dropbox file-shar",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "au_582177",
      "task": "local DNS lookup not working, despite everything is in /etc/hosts",
      "P-task": "local dn lookup work despit everyth etc host",
      "F_verb": "lookup",
      "P-body": "You are doing everything right like putting the entries in \"/etc/hosts\", server address in \"/etc/resolv.conf\", the \"/etc/nsswitch.conf\" looks good too. .  The problem you are having is due to the understanding of a very specific term \"nameserver\". All the commands used to resolve IP address to hostname and vice versa used the nameserver addresses from \"/etc/resolv.conf\" unless mentioned explicitly. You have put \"nameserver 127.0.0.1\" which is not a valid name server because it is not configured as a nameserver. It is there because of \"dnsmasq\" which acts as a DNS cacher (and DHCP server) but \"host\", \"dig\", \"nslookup\" take data from a valid, configured nameserver only.  .  As the \"host\", \"nslookup\", \"dig\" commands will use the \"nameserver\" mentioned in \"/etc/resolv.conf\" (unless specified), hostname resolution will not work using these in your case. Although the programs that use \"/etc/nsswitch.conf\" or read \"/etc/hosts\" will resolve the hostname to IP addresses and vice versa. .  If you want to resolve hostnames from \"/etc/hosts\" the you need to use \"getent\". For example to resolve \"node1-VirtualBox\", you need the following command : .  ",
      "P-tags": "dn virtualbox network server",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP S_ING"
    },
    {
      "id": "so_49021486",
      "task": "Why does the Linux kernel require small short-term memory chunks in odd sizes\uff1f",
      "P-task": "linux kernel requir small short-term memori chunk odd size",
      "F_verb": "require",
      "P-body": "Because most programs require small allocations, for relatively short periods, in a variety of sizes? That's why \"malloc\" and friends exist: To subdivide the larger allocations from the OS into smaller pieces with sub-page-size granularity. Want a linked list (commonly needed in OS kernels)? You need to be able to allocate small nodes that contain the value and a pointer to the next node (and possibly a reverse pointer too). .  I suspect by \"odd sizes\" they just mean \"arbitrary sizes\"; I don't expect the kernel to be unusually heavy on 1, 3, 5, 7, etc. byte allocations, but the allocation sizes are, in many cases, not likely to be consistent enough that a fixed block allocator is broadly applicable. Writing a special block allocator for each possible linked list node size (let alone every other possible size needed for dynamically allocated memory) isn't worth it unless that linked list is absolutely performance critical after all. .  ",
      "P-tags": "linux operating-system memory-manag",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "su_448152",
      "task": "linux terminal, see the output one page at a time",
      "P-task": "linux termin see output one page time",
      "F_verb": "see",
      "P-body": "Before running \"make\", pipe its STDOUT into a viewer, like \"less\". .  Then, you can skip through pages with CtrlV. Alternatively, write the output to a file and read it later: .  Quit \"less\" with Q. .  ",
      "P-tags": "linux scroll",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP at NP"
    },
    {
      "id": "au_1127603",
      "task": "How can I create a 30 second GIF from a long random video?",
      "P-task": "creat 30 second gif long random video",
      "F_verb": "create",
      "P-body": "Steps: .   Get duration with \"ffprobe\". Use duration as a value in the select filter. Create gif. Script everything.  Example script: .  This fulfills your many requirements: .   Output 30 second GIF comprising of 3 second segments equally spanning input duration 560x340 output size One (\"ffmpeg\") command Using a bash for loop so you can automatically convert hundreds of videos Output name is same as input name but with .mp4 replaced with .gif  ",
      "P-tags": "ffmpeg mp4 gif",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_167340",
      "task": "Reduce length of specific column in delimited text file",
      "P-task": "reduc length specif column delimit text file",
      "F_verb": "reduce",
      "P-body": "If \"file.csv\" looks like this: .  Then, you can do: .  ",
      "P-tags": "column script text-process",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_22718518",
      "task": "Sed to replace lower case string between two strings to upper case",
      "P-task": "sed replac lower case string two string upper case",
      "F_verb": "replace",
      "P-body": "You can use \"\\U\" to make something become upper case: .  And \"\\E\" to stop the conversion: .   In your case, just catch the blocks and place those \"\\U\" and \"\\E\" accordingly: .   \"(foo )(.*)( var)\" catches three blocks: \"foo\", the next text and \"var\". \"\\1\\U\\2\\E\\3\" prints them back, upcasing (is it a verb?) the second one (\"\\U\") and using the current case (\"\\E\") for the 3rd.  Without \"-r\", to make it more similar to your current approach: .  So you can see that you were not catching the \".*\" block, so you were printing back just \"foo\" and \"var\". .   From the manual of sed: .   \\L Turn the replacement to lowercase until a \\U or \\E is found,  .  \\l Turn the next character to lowercase,  .  \\U Turn the replacement to uppercase until a \\L or \\E is found,  .  \\u Turn the next character to uppercase,  .  \\E Stop case conversion started by \\L or \\U. .   ",
      "P-tags": "bash sed regex",
      "cate": "replace",
      "pat": "V NP between NP to NP"
    },
    {
      "id": "ul_26914",
      "task": "Executables show with character * next to their name in output of ls",
      "P-task": "execut show charact next name output ls",
      "F_verb": "show",
      "P-body": "This is caused by the \"-F\"/\"--classify\" flag on \"ls\" (as are the \"/\" after directories, though those can be added independently). It seems this option is \"alias\"ed into your \"ls\". If you would like to disable it, you should track down where it is added as an alias and remove it, or add \"--indicator-style=none\".  .  The following options affect these indicators: .  ",
      "P-tags": "ls shell zsh",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V with NP to NP in NP of NP"
    },
    {
      "id": "ul_116456",
      "task": "When should you use subshells vs `xargs`?",
      "P-task": "use subshel vs xarg",
      "F_verb": "use",
      "P-body": "This is a slightly opinionated question but I'll just say this, it's highly dependent on 2 things: .   What is the command you're going to run? How many instances you're going to run?  If you're likely to run dozens to 100's of the same process, then \"xargs\" makes the most sense. Also if the processes are going to be expensive to start up, \"xargs\" is likely the best route to go.  .  If however there will only be a handful of instances of the command, then running them in a subshell is fine.  .  If the length of the arguments produced by the subshell will be extremely long, then you'd want to use \"xargs\". But this limit is pretty extreme, typically 2MB-4MB of characters, so it's unlikely that you'd exceed it. You can check like this: .  By the way, neither of these commands appear to work. The \"cut -d \" \" -f2\" is not valid, \"cut\" can only take a single character as the delimiter. Try this instead: .  Using \"awk\" here will likely cause you issues if you have any filenames or directories with spaces, so use it with caution. .  I'd use the \"cut -f2-\" method, but that's just me, others' might give you a more sophisticated \"awk\" solution, but use what makes the most sense to you. .  Using awk + cat NOTE: When piping output to \"xargs\" there is no need to call \"cat\", \"xargs\" will automatically echo the output it's passed, by default. .  EDIT #1 If you're using tabs to delimit with cut you don't need to do so explicitly, it defaults to that. .  ",
      "P-tags": "command-lin xarg shell convent subshel",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_34366051",
      "task": "Could not open a connection to your authentication agent (REVIEW)",
      "P-task": "could open connect authent agent review",
      "F_verb": "open",
      "P-body": "openssh-daemon and authentication-daemon are not the same thing. You are interested in the authentication one aka \"ssh-agent\", which is your personal key-store. The openssh-deamon aka \"sshd\" is server that is running system-wide and which is accepting connections to your computer. .  Desktop environments usually start authentication agents (\"ssh-agent\", \"seahorse\", \"gnome-keyring\") by default so the \"ssh-add\" works for you. But the connection is stored in environment variables, which are dropped in transition from your user to superuser (\"su\"). .  You can allow connection persistence using \"-m\" switch to \"su\". This will preserve environment variables and so your connection to authentication agent. .    What's the difference between both case scenarios, even though I am using the same SSH keys? .   There should be no difference, except the \"su\" part dropping environment variables and not executing \".bashrc\" and similar scripts when changing user (you can force \"su\" to behave the same way as a login shell using \"su -l\", but it is not the problem). The problem is that the connection to authentication agent is preserved as environment variable and UNIX domain socket, which gets lost during \"su\". You can use \"su -m\" it should work for you. .   Is it that Pageant is not forwarding the keys? .   Forwarding needs to be allowed in PuTTY:  .  ",
      "P-tags": "cento linux putti ssh",
      "cate": "open",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1201932",
      "task": "Cannot find package eve-ng-addons-netem",
      "P-task": "find packag eve-ng-addons-netem",
      "F_verb": "find",
      "P-body": "I was able to find a solution to the mismatched packages. One of the admins from the eve-ng forum gave me this: .  ",
      "P-tags": "18 04 apt",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_498891",
      "task": "How install legacy grub to gpt uefi disk?",
      "P-task": "instal legaci grub gpt uefi disk",
      "F_verb": "install",
      "P-body": "3 possibilities  .  mbr Use mbr; waste the disk space over 2 TB .  gpt Use grub2 with gpt.  .  [Stressing yourself over the scripts etc is not strictly necessary \u2014 you can just ignore the suggestion not to edit \"grub.conf\" and edit like legacy grub. Just make sure no updates that point to (this) grub automatically run] .  hybrid Use an hybrid approach .  ie 4 mbr partitions (under 2TB) which grub legacy is aware of and a gpt aware OS that uses the rest.  .  Caveat: I've given the third choice since that's what you (seem to) want. However as the link suggests its a great deal of trouble and not worth it. .  ",
      "P-tags": "uefi gpt grub-legaci",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_57398263",
      "task": "Append multiple types to the list",
      "P-task": "append multipl type list",
      "F_verb": "append",
      "P-body": "You are appending the fixed types multiple times, once for each optional type. As a result, you also end up missing some \"-o\" arguments.) .  Instead, start by initializing \"types\" with the fixed types. .  Then append the optional types as necessary: .  Then build the \"findArgs\" array using \"types\". That array will then include all arguments for all types correctly. .  ",
      "P-tags": "bash",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_44620232",
      "task": "Exit jshell with error code",
      "P-task": "exit jshell error code",
      "F_verb": "exit",
      "P-body": "Now, JShell shipping with JDK 10 and later introduced a new version of \"/exit\" that takes an optional snippet as an argument. That snippet is evaluated to the error code that will be returned to the calling process. See http://mail.openjdk.java.net/pipermail/kulla-dev/2017-November/002129.html for details. .  Here is the help text for the new \"/exit\" commands using jdk-10+ea-33: .  Note for JDK 9: You can't use \"/exit\" to exit a jshell session on JDK 9 with a non-zero error code. See https://bugs.openjdk.java.net/browse/JDK-8185840 for details. .  ",
      "P-tags": "jshell java-9",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "so_63522108",
      "task": "How to remove M line breaks to Normal line breaks in Shellscript in a CSV file",
      "P-task": "remov line break normal line break shellscript csv file",
      "F_verb": "remove",
      "P-body": "If \"dos2unix $INPUT\" command doesn't work then you can also use .   \"tr -d '\\r' < $INPUT > $OUTPUT\" Or for inplace editing you can use \"sed -i 's/\\r$//g' $INPUT\"  ",
      "P-tags": "carriage-return linux unix shell",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP to NP in NP in NP"
    },
    {
      "id": "so_27598133",
      "task": "Bash : grep unique lines",
      "P-task": "bash : grep uniqu line",
      "F_verb": "grep",
      "P-body": " assuming your file is in x.txt which gives .  ",
      "P-tags": "uniq grep bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_45483191",
      "task": "How to read CSV file stored in variable",
      "P-task": "read csv file store variabl",
      "F_verb": "read",
      "P-body": "Your issue is that you're one directory up from the path you are trying to read. The quick fix would be \"wc -l \"csv-output/$lastCSV\"\". .  Bear in mind that parsing \"ls -t\" though convenient, isn't completely robust, so you should consider something like this to protect you from awkward file names: .   GNU \"find\" lists all files along with their last modification time, separating the output using null bytes to avoid problems with awkward filenames.  if you remove \"-maxdepth 1\", this will become a recursive search  GNU \"sort\" arranges the files from newest to oldest, with \"-z\" to accept null byte-delimited input. GNU \"head -z\" returns the first record from the sorted list. GNU \"cut -z\" at the end discards the timestamp, leaving you with only the filename.  You can also replace \"find\" with \"stat\" (again, this assumes that you have GNU coreutils): .  ",
      "P-tags": "csv unix shell bash",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1037211",
      "task": "Don't see new kernel after upgrade",
      "P-task": "see new kernel upgrad",
      "F_verb": "see",
      "P-body": "I don't think you want to try \"4.16.9\" but Go to: http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.16.9/ .  Select the files: .   linux-headers-4.16.9-041609_4.16.9-041609.201805161024_all.deb linux-headers-4.16.9-041609-generic_4.16.9-041609.201805161024_amd64.deb linux-image-unsigned-4.16.9-041609-generic_4.16.9-041609.201805161024_amd64.deb linux-modules-4.16.9-041609-generic_4.16.9-041609.201805161024_amd64.deb  for downloading to a directory, say \"~/Downloads\". .  Then change to the directory, confirm they have finished downloading and install the new kernel: .  Then you'll see an error message because of this bug. Now you'll have to fix it using this answer: Unable to upgrade kernel after 4.16.3 .  ",
      "P-tags": "upgrad kernel grub2",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP after NP"
    },
    {
      "id": "ul_465572",
      "task": "add backslash before specific character",
      "P-task": "add backslash specif charact",
      "F_verb": "add",
      "P-body": "Pretty straightforward .  but you can accomplish the same with bash parameter substitution .  ",
      "P-tags": "linux sed text-process",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP before NP"
    },
    {
      "id": "ul_168354",
      "task": "Can I see what's going on in a tmux session without attaching to it?",
      "P-task": "see go tmux session without attach",
      "F_verb": "see",
      "P-body": "I think \"capture-pane\" might suit your needs: .  (see \u201ctarget-pane\u201d in the man page for the ways to specify a pane) .  By default, that command will dump the current contents of the specified pane. You can specify a range of lines by using the \"-S\" and \"-E\" options (start and end line numbers): the first line is 0, and negative numbers refer to lines from the pane\u2019s \u201cscroll back\u201d history. So adding \"-S -10\" gets you the most recent ten lines of history plus the current contents of the pane. .   The \"-p\" option was added in 1.8. If you are running an earlier version then you can do this instead: .  But mind those semicolons if you are issuing this command via \"ssh\" since the remote shell will add an additional level of shell interpretation (the semicolons need to be passed as arguments to the final tmux command, they must not be interpreted by either the local or the remote shell). .  ",
      "P-tags": "tmux",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V what S without S_ING"
    },
    {
      "id": "so_24983834",
      "task": "open file folder in the directory",
      "P-task": "open file folder directori",
      "F_verb": "open",
      "P-body": "When opening a folder, I use the \"xdg-open\" command which opens the specified folder with the preferred file manager for a given desktop environment. .  On my system when I'm running \"KDE\", it calls \"dolphin\" to display the folder, and \"xfce4\", it invokes \"thunar\", as these are the preferred file managers as per my settings. I often don't want \"nautilus\" to be used, as the interface differs from my preferred apps, doesn't look consistent with the other applications - in terms of widgets, style, etc. - and won't group the same in my taskbar. .  It also uses separate preferences for my default open-with settings, and conflicts with my workflow. .  Additionally, \"nautilus\" isn't necessarily guaranteed to be on my system. For example, on some of my older systems, where I've \"emerge\"d a custom gentoo system where I'm either constrained by RAM or HDD space, I've only \"emerge\"d say \"twm\" and \"xfce4\", so \"nautilus\" doesn't exist. .  As far as the nautilus-specific behaviour is concerned, I have had similar problems with nautilus creates a desktop on initial invokation (as is the case when I am running \"twm\"). .  Invoking \"nautilus --help\" shows the following options: .  Unfortunately, I can't help you specifically invoke the \"nautilus\" \"open with...\" dialog, although \"xdg-open\" will use the default application when a file is specified. Perhaps polling configurations within the \"mimeapps.list\" file (which can be in one of several cascading override locations: including, but not limited to, user-desktop, user, sysadmin-desktop, sysadmin, default-desktop, and default). .  ",
      "P-tags": "unix file c++ fork c",
      "cate": "open",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_139371",
      "task": "Where do drafts go when mutt crashes?",
      "P-task": "draft go mutt crash",
      "F_verb": "go",
      "P-body": "If you were still editing the message, saving a backup copy is up to your editor. If you've actually saved the message but haven't sent it yet, it's stored in \"$TMPDIR\" (or \"/tmp\" by default), with a \"mutt-\" prefix. You can check the filename in your editor while you're writing the message; mutt will keep that same file around until you've finished working with that particular message. The \"Drafts\" maildir is for messages you've postponed indefinitely; it copies the temporary file to there until you recall it .  ",
      "P-tags": "crash mutt",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V when S"
    },
    {
      "id": "so_44524190",
      "task": "Iterate over $PATH variable using shell script",
      "P-task": "iter path variabl use shell script",
      "F_verb": "iterate",
      "P-body": "You can use \"read\" with delimiter set as \":\" .  ",
      "P-tags": "linux unix shell bash",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V over NP using NP"
    },
    {
      "id": "so_45163630",
      "task": "How to set permission for Azure Active directory application in Azure DataLake Store using powershell commands",
      "P-task": "set permiss azur activ directori applic azur datalak store use powershel command",
      "F_verb": "set",
      "P-body": "The parameter \"User\" of \"Set-AzureRmDataLakeStoreItemAclEntry\" commands should be the object ID of the AzureActive Directory user, group, or service principal for which to modify an ACE. .  You can refer the command below to assign the permission: .  More detail about this command, you can refer link below: .  Set-AzureRmDataLakeStoreItemAclEntry .  ",
      "P-tags": "azure-powershel azure-active-directori azure-data-lak",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP in NP using NP"
    },
    {
      "id": "so_21983984",
      "task": "Create Out-File-names using array elements",
      "P-task": "creat out-file-nam use array element",
      "F_verb": "create",
      "P-body": "You need to wrap the string(path) inside a subexpression \"$(.....)\" to extract the value of a single element in an array. Atm. the path becomes something like \".SAP_Production Finance Example[$i].sap\". .  Also, you have an extra \"$\" in the second \"Out-File\". Personally I would rewrite everthing to: .  \"$_\" is the current item in the array, and since it's a single object, I don't really need the subexpression \"$()\", but I included it because it easier to see static and dynamic parts of the path. .  ",
      "P-tags": "powershel",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "so_39816225",
      "task": "How to grep a file for text with apostrophes?",
      "P-task": "grep file text apostroph",
      "F_verb": "grep",
      "P-body": "Just quote with double quotes, so that single quotes can be included normally: .  ",
      "P-tags": "linux command-lin bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP with NP"
    },
    {
      "id": "au_666566",
      "task": "How to install a newer version of libav than what is in the repos",
      "P-task": "instal newer version libav repo",
      "F_verb": "install",
      "P-body": "I wasn't running the backports install correctly. The \"-t wheezy-backports\" is necessary. .  It installs version 6.x, but it has the options I need. .  http://backports.debian.org/Instructions/ .  ",
      "P-tags": "ffmpeg apt debian package-manag libav",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP what S"
    },
    {
      "id": "ul_244871",
      "task": "How to force valid authentication in exim before sending at all?",
      "P-task": "forc valid authent exim send",
      "F_verb": "force",
      "P-body": "You can't force a remote client to attempt to authenticate, because you don't know until the \"RCPT TO:\" whether the client is attempting to deliver an email to your server (which doesn't require authentication unless you have a very unusual configuration like only accepting mail from known mail servers) or it is trying to relay through your mail server without authorisation. .  The \"RCPT TO\" stage of an SMTP session comes well after any AUTH negotiation (if any). .  ",
      "P-tags": "email exim debian",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP before S_ING at NP"
    },
    {
      "id": "so_51285196",
      "task": "Copy Active Directory attribute to another attribute and modify it",
      "P-task": "copi activ directori attribut anoth attribut modifi",
      "F_verb": "modify",
      "P-body": "You simply would do that in your subexpression of your calculated property .  That regex string will replace all leading digits (assuming there are not other characters at the start of the string) and all whitespace that follows it.  .  ",
      "P-tags": "powershel active-directori",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_30820977",
      "task": "'find' (command) finds nothing with -wholename",
      "P-task": "find command find noth -wholenam",
      "F_verb": "find",
      "P-body": "The first command generates file names starting with \"./../..\". Thus the wholename pattern will match because they start with \".\". .  The second command generates filenames starting with \"/home\". However, the wholename pattern is still looking for paths starting with \".\" which will not match any file in this case. .  Note that patterns are not regular expressions. If you were expecting them, look at the \"-regex\" option instead. .  ",
      "P-tags": "directori linux find bash",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_10178",
      "task": "How do I force remove a package in Arch with pacman?",
      "P-task": "forc remov packag arch pacman",
      "F_verb": "remove",
      "P-body": "You should be able to reinstall the package with a simple:  .  This will only remove perl-libwww:  .  Please notice the double -d in the command, if you use --nodeps you have to specify that twice too or combine it with a -d like: .  This removes all the packages which depend on perl-libwww:  .  From pacman's man page:  .    ",
      "P-tags": "arch-linux package-manag pacman",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "ul_557684",
      "task": "Select an IP address in a regex group from a multi line string",
      "P-task": "select ip address regex group multi line string",
      "F_verb": "select",
      "P-body": "I think this is a job for \"grep\" (GNU) or \"awk\", rather than \"sed\": .  Ouput: .  ",
      "P-tags": "grep sed regular-express",
      "cate": "choose/select",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "so_68775718",
      "task": "How to use Loop using lowriter command on shell",
      "P-task": "use loop use lowrit command shell",
      "F_verb": "use",
      "P-body": "I have solved my question adding 2>&1 in the end of the convertion line; .  ",
      "P-tags": "sh for-loop unix linux shell",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_22457076",
      "task": "zypper add repository and enable refresh on one line",
      "P-task": "zypper add repositori enabl refresh one line",
      "F_verb": "refresh",
      "P-body": "after looking around on the internet for a while I found the -f option: .  this enables autorefresh automatically. I am wondering why autorefresh is off by default! .  ",
      "P-tags": "linux zypper repositori",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V on NP"
    },
    {
      "id": "ul_367034",
      "task": "How to make several \"startx\" profiles?",
      "P-task": "make sever startx profil",
      "F_verb": "make",
      "P-body": "Just put \"exec \"$@\"\" at the end of your \"xinitrc\", and then execute .  from a tty. .  \"startx\" interprets its first string argument as the client (\"/path/to/xinitrc\", note that it has to be an absolute path), and rest of the arguments are passed to that client (wm and wm-args), which are \"exec\"ed by the xinitrc. .  Note that startx is just an example script and you are encouraged to create another one according to your needs. The above mentioned setup should meet the requirements mentioned in the question though. .  ",
      "P-tags": "startx xinit",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "ul_94037",
      "task": "any command that can format html or xml from shell?",
      "P-task": "command format html xml shell",
      "F_verb": "format",
      "P-body": "If its something related to pretty printing of file in xml aligned format, xmllint as suggested by @warl0ck is nice & here is what I tried & see: .  ",
      "P-tags": "html sed text-process",
      "cate": "format",
      "pat": "V NP from NP"
    },
    {
      "id": "so_61447795",
      "task": "zsh show current dir if not home on MacOS",
      "P-task": "zsh show current dir home maco",
      "F_verb": "show",
      "P-body": "Have you tried this : .  ",
      "P-tags": "shell maco zsh",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP if S"
    },
    {
      "id": "au_1064171",
      "task": "A lot of PAM authentication errors on my logs targeting my mailserver. How do I stop it?",
      "P-task": "lot pam authent error log target mailserv\nstop",
      "F_verb": "stop",
      "P-body": "Firstly, this is not uncommon to see on mail servers. Every Mail Server on the Internet sees these if port 25 is exposed to the web. Even the mail gateways and mail servers at my workplace get hit with these, the reason that many of these attempts get filtered out and blocked is the IDS/IPS (Intrustion Detection / Prevention System) on the border of the network which refers to many sources of OSINT (Open Source Intelligence) to create a reputation-based set of bad IPs which are blocked. Some of these probes get through, but they are not successful when they try. .  In all likelihood, it's not a targeted brute force against your server, it's \"the scanners and probes of the Internet\" doing their thing to every Internet-facing SMTP server. These're probably spambots attempting to probe for open relays, and if they don't find an open relay, they're likely probing to try and gain access to accounts in order to use the SMTP server as a mail relay. Or it's a service scanner trying to see if you've got any 'weak passwords' in play so they can exploit them and then exploit your server to send their own mail via your mailservers. .  So long as you follow the other security practices of strong passwords, not giving users access unless they need it, etc., you should be good to go in terms of them not breaking into your server. I would be less concerned with the authentication failures, and more concerned if the auths were successful. .  An additional security option is to set up Fail2Ban which will work to ban users, however I've yet to get this functioning properly and haven't had time to dig into it to make fail2ban work for my mail server to autoban IPs if they fail to auth too many times). Tread lightly with this though, because it can also block you if you aren't careful. Once I have a 'working' Fail2Ban config I'll share that as a comment to this answer, but it's been tricky to get it to behave the way I want it to) .   As for the \"cron:session\" entries in your \"auth.log\", that's just a note that the system's \"cron\" daemon is running \"cron\" tasks from \"/etc/crontab\", \"/etc/cron.{d,daily,hourly,monthly,weekly}/*\", and the \"root\" user crontab per the schedule set for cron jobs as the root user (where the crontabs are set to run as \"root\"). Those are typically OK, provided that you actually check every single crontab under the root account to make sure nothing 'bad' is running automatically as \"root\". .  ",
      "P-tags": "pam server ssh authent",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "ul_359292",
      "task": "Is it safe to delete the file /etc/hosts.deny?",
      "P-task": "safe delet file etc host deni",
      "F_verb": "deny",
      "P-body": "The man page for \"hosts.deny\" (\"man hosts.deny\") explains the order of processing: .   The access control software consults two files. The search stops at the first match: .   Access will be granted when a (daemon,client) pair matches an entry in the /etc/hosts.allow file. Otherwise, access will be denied when a (daemon,client) pair matches an entry in the /etc/hosts.deny file. Otherwise, access will be granted.   So from this you can see that it is quite safe to delete \"/etc/hosts.deny\" (and \"/etc/hosts.allow\", for that matter). .  Now, as to your question regarding the automatic deletion - or not - of \"/etc/hosts.deny\" when you uninstall \"denyhosts\". This file - and its complement \"/etc/hosts.allow\" - belongs to \"tcp_wrappers\" so it is not for \"denyhosts\" to remove it when you uninstall it. .  ",
      "P-tags": "denyhost",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "su_133897",
      "task": "In linux, how can I get my IP address - ifconfig and ip addr show are not working",
      "P-task": "linux get ip address - ifconfig ip addr show work",
      "F_verb": "get",
      "P-body": "try \"/sbin/ifconfig\". you can also try searching in \"/proc/net\" .  ",
      "P-tags": "ip-address linux tcpip",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_60127728",
      "task": "Read MAX values from CSV file without overwriting the existing values of the new CSV file",
      "P-task": "read max valu csv file without overwrit exist valu new csv file",
      "F_verb": "read",
      "P-body": "OK, I'm still pretty unsure if I got what you're actually trying to do. Let's try it anyway: .  Because you're trying obviously to mix different data sets you have to do a little trick. Assumed the column with the data you want to put in the \"series\" category all start with the word \"session\" you can try to do it like this: .  First you specify the path you want to work in. Then you collect all CSV files and import them with Import-Csv. You sort the data from the CSV file for your desired value and pick the first one. Now you create a new data set where you add the source file name to be able to identify where the source data come from. And you \"convert\" the different \"session\" thing data to the data cell \"Series\". .  Is it that what you needed? .  Of course you can output the data in any way you want or put some further steps to export them to a new CSV file or whatever. ;-) .  ",
      "P-tags": "powershel",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP without S_ING of NP"
    },
    {
      "id": "so_2050581",
      "task": "How to delete mysql database through shell command",
      "P-task": "delet mysql databas shell command",
      "F_verb": "delete",
      "P-body": "Try the following command: .  ",
      "P-tags": "mysql linux ubuntu databas shell",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP through NP"
    },
    {
      "id": "so_54285413",
      "task": "Find pattern with Powershell",
      "P-task": "find pattern powershel",
      "F_verb": "find",
      "P-body": "Find all lines that contain the word \"Exception\": .  If you want to test to see if there are any lines containing the word \"Exception\" then it's as easy as assigning the results of the above command to a variable and testing for a value! .  ",
      "P-tags": "powershel regex",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "so_50524653",
      "task": "Docker file command runs apt-get update from wrong repository",
      "P-task": "docker file command run apt-get updat wrong repositori",
      "F_verb": "update",
      "P-body": " Seems that it tries to do apt-get update from debian repository when I'm on ubuntu xenial. .   Commands to build an image are run within a container based on the previous state of the image. They do not depend on the host you are running on. The result is the same image could be built on different docker host with nearly identical results (external dependencies and timestamps being the normal exceptions). If you follow the path of the Dockerfile you've provided from the \"FROM\" lines, you get: .   \"FROM python:2.7\": docker hub and Dockerfile \"FROM buildpack-deps:stretch\": docker hub and Dockerfile \"FROM buildpack-deps:stretch-scm\": docker hub and Dockerfile \"FROM buildpack-deps:stretch-curl\": docker hub and Dockerfile \"FROM debian:stretch\": docker hub and Dockerfile  You can also run a container based on your base image and use the standard package manager tools to query for what versions of packages are included (this is particularly useful when you don't have the Dockerfile for your image): .  ",
      "P-tags": "ubuntu-16 04 docker",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V from NP"
    },
    {
      "id": "au_960734",
      "task": "bash script stop after execute external script(oh-my-zsh installer.sh)",
      "P-task": "bash script stop execut extern script oh-my-zsh instal sh",
      "F_verb": "execute",
      "P-body": "It's because at the end this last line \"env zsh\" causes installer.sh run a \"zsh\" sub-shell; You can add and redirect \"0>/dev/null\" to \"sh -c\" to fail it to run a sub-shell. .  You can check \"0>/dev/null\" behavior when running \"0>/dev/null env zsh\" and \"enz zsh\" after installation to see that \"0>/dev/null env zsh\" preventing to switch to \"zsh\" shell or any other shells. .  This will also cause to fail/prevent when that wants to change your default shell when asking your password in below. .  ",
      "P-tags": "script zsh command-lin bash",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_41882918",
      "task": "Get Linux kernel module ko file name within running module",
      "P-task": "get linux kernel modul ko file name within run modul",
      "F_verb": "get",
      "P-body": "No. .  First: your module may have been compiled into the kernel, and thus won't have a file path. .  Second: Loading kernel modules from files takes place in userspace. The kernel is passed a module as a data buffer, using the \"init_module\" system call -- it's theoretically possible that this data was never loaded from a file at all. For instance, one can imagine a module loader that loads modules from the network, or from a compressed archive.) .  ",
      "P-tags": "linux kernel-modul c linux-kernel",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP within NP"
    },
    {
      "id": "so_62119972",
      "task": "How to read a file and replace a string in another file using shell script in linux?",
      "P-task": "read file replac string anoth file use shell script linux",
      "F_verb": "replace",
      "P-body": " There were a few issues: .   \"USER\" is a reserved shell variable so you have to give it a different name your sed script needs \"s/.../.../\" to substitute and you also need to match the rest of the line in your regexp so the \".*\" is needed or the old credentials are still in the output \"-i\" option on sed is needed for an in-place edit variable substitution is not performed in a string delimited with \"'\", so changed to \"\"\" here  ",
      "P-tags": "linux sh unix shell",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_454523",
      "task": "delete all files ending with certain string",
      "P-task": "delet file end certain string",
      "F_verb": "delete",
      "P-body": "With a recent version of bash, you can use brace expansion for this: .  Bash's brace expansion deals with leading 0s: .  So you can use \"{000151..000300}\" to generate the list of files you need.  .  ",
      "P-tags": "shell rm",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "so_27332876",
      "task": "How to open a file and anchor to dedicated line number with vim",
      "P-task": "open file anchor dedic line number vim",
      "F_verb": "open",
      "P-body": "Have a look at the file:line - Allows you to open file:line and it does the right thing plugin; it sets up autocmds to handle those, so you can pass your \"path/to/file:lnum\" directly to Vim on the command line and \":edit\" such, too! .  ",
      "P-tags": "linux vim shell",
      "cate": "open",
      "pat": "V NP S_INF with NP"
    },
    {
      "id": "so_31116756",
      "task": "Run script on powershell exit",
      "P-task": "run script powershel exit",
      "F_verb": "run",
      "P-body": "Get it out of the function and run it in the scriptblock, like this: .  *of course, make sure you are with admin privilege as it write to c:\\ .  ",
      "P-tags": "powershel window",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_37116442",
      "task": "Python: run shell script with manual input",
      "P-task": "python : run shell script manual input",
      "F_verb": "run",
      "P-body": "As the earlier answer explained \"subprocess.Popen\" can be used to create process that can be interacted with \"communicate\". \"communicate\" takes string as a parameter that will be passed to the created process and returns tuple \"(stdout, stderr)\". Below is a short example of two Python scripts communicating with it: .  Child .  Parent .  Output .  ",
      "P-tags": "python shell",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "su_560050",
      "task": "How to compare two files for non-printing characters",
      "P-task": "compar two file non-print charact",
      "F_verb": "compare",
      "P-body": "Use \"od -c\" to dump each file as hex, then diff the results. .  ",
      "P-tags": "diff unix",
      "cate": "compare",
      "pat": "V NP for NP"
    },
    {
      "id": "so_26037756",
      "task": "How to overwrite files with Copy-Item in PowerShell",
      "P-task": "overwrit file copy-item powershel",
      "F_verb": "overwrite",
      "P-body": "As I understand \"Copy-Item -Exclude\" then you are doing it correct. What I usually do, get 1'st, and then do after, so what about using \"Get-Item\" as in .  ",
      "P-tags": "powershel",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_14119628",
      "task": "PHP exec and header redirect",
      "P-task": "php exec header redirect",
      "F_verb": "redirect",
      "P-body": "Can you try this instead: .  PS: Note that this is redirecting stdout and stderr to \"/dev/null\" If you want to capture output then use: .  Alternatively use this PHP function to run any Unix command in background: .  Courtesy: A comment posted on http://php.net/manual/en/function.shell-exec.php .  ",
      "P-tags": "linux exec php",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V"
    },
    {
      "id": "ul_375572",
      "task": "Find Maximum of all columns based on distinct first column",
      "P-task": "find maximum column base distinct first column",
      "F_verb": "find",
      "P-body": "awk solution for any number of columns (you have mentioned a sample file with 13 columns): .  Let's say we have the extended sample file: .   The output: .  ",
      "P-tags": "awk gawk text-process",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP on NP"
    },
    {
      "id": "au_1261806",
      "task": "How Do I Migrate a Chromium Snap Between Machines?",
      "P-task": "migrat chromium snap machin",
      "F_verb": "migrate",
      "P-body": "The user configuration data of the snap version of Chromium are located under .  So it would be sufficient to copy the contents of that folder over to the new installation to restore your bookmarks, settings and extensions. .  On the new installation, run Chromium for the first time in order to create the new default user configuration data (folders and files under \"~/snap/chromium\"). Then replace the contents of the folder mentioned above with your backup profile from another Chromium install. .  ",
      "P-tags": "chromium snap",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP between NP"
    },
    {
      "id": "au_929027",
      "task": "Qualcomm Atheros QCA6174 802.11ac Wireless Network Adapter [168c:003e] (rev 32) can't enable wi-fi",
      "P-task": "qualcomm athero qca6174 802 11ac wireless network adapt 168c:003e rev 32 enabl wi-fi",
      "F_verb": "enable",
      "P-body": "Run in a terminal .  and reboot. .  And I suggest not to fiddle with the firmware. Also restore the standard package by .  You need to be connected to the internet to do it. .  ",
      "P-tags": "driver wireless network 16 04",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_1585964",
      "task": "Bourne shell script to convert a number to telephone format",
      "P-task": "bourn shell script convert number telephon format",
      "F_verb": "convert",
      "P-body": "This is what DigitalRoss and Jonathan Leffler were trying to say: .  This should work on all but the most brain-dead versions of \"sed\", however it pays no attention to word boundaries, etc., or whether there are additional digits or groups of digits on the same line. It simply reformats the first ten digit sequence it finds. If you have spaces, tabs, commas or other delimiters, they can be used to further restrict the match. .  ",
      "P-tags": "shell unix",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1057095",
      "task": "Delay dev-sda2.device",
      "P-task": "delay dev-sda2 devic",
      "F_verb": "delay",
      "P-body": "You can't delay this until after booting. .  \"sda2\" is your Root Partition (\"/\") so that means this device is the Root of your Entire OS. .  The Task that takes so long is mounting this Partition so it can be used. .  But it seems that this takes too long, it could be a Driver/Partition Failure (errors shown with fsck ( @N0rbert ) ), slow HDD, something else. We don't have enough information to help for that. .  ",
      "P-tags": "boot",
      "cate": "delay/defer/postpone",
      "pat": "V NP"
    },
    {
      "id": "so_62498437",
      "task": "How to extract the parent folder in bash script?",
      "P-task": "extract parent folder bash script",
      "F_verb": "extract",
      "P-body": "Like this, using pre-defined variable \"PWD\": .  You can replace the last line with: .  The backquote (`) is used in the old-style command substitution, e.g. .  The \"foo=$(command)\" syntax is recommended instead. Backslash handling inside $() is less surprising, and $() is easier to nest. See http://mywiki.wooledge.org/BashFAQ/082 .  ",
      "P-tags": "pwd path bash",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_59633034",
      "task": "Drop Shadow On A Borderless Form (Powershell GUI)",
      "P-task": "drop shadow borderless form powershel gui",
      "F_verb": "drop",
      "P-body": "Based on new knowledge, I myself write the answer to my question. .  I never found a solution on a clean PowerShell. .  ",
      "P-tags": "powershel",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP on NP"
    },
    {
      "id": "so_67067643",
      "task": "PowerShell: Get Key and Value from Json",
      "P-task": "powershel : get key valu json",
      "F_verb": "get",
      "P-body": "You can export the keys and values as plain text using \"Out-File\". .  Edit: .  Credit to @Vivere, did not know \"-AsHashTable\" was introduced on PS Core. Supposing the test is performed on PS 5.1 here is how to get the same result. If the JSON has more depth check out the link provided by him on comment below. .  ",
      "P-tags": "json powershel convertfrom-json",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_45369839",
      "task": "How do I open a folder(on my desktop) from Powershell on Windows?",
      "P-task": "open folder desktop powershel window",
      "F_verb": "open",
      "P-body": "In cmd powershell type: .  where $path is the name of folder with full path .  ",
      "P-tags": "powershel termin window",
      "cate": "open",
      "pat": "V NP from NP on NP"
    },
    {
      "id": "su_1215294",
      "task": "Mongo cannot see libssl and libcrypto files",
      "P-task": "mongo see libssl libcrypto file",
      "F_verb": "see",
      "P-body": "It sounds like you went to https://www.mongodb.com/download-center to download MongoDB. .  I suspect that you didn't download the right binary package. Perhaps you downloaded the Amazon Linux version, which is selected by default but is not compatible with your operating system.) .  At that web page, you should select version \"Ubuntu 14.04 Linux 64-bit x64\" because Ubuntu 14.04 is roughly equivalent to Linux Mint 17.1. Make sure this is the version you download. .  By selecting that version, you'll see the following text (emphasis mine): .   The binary of this version has been compiled with SSL enabled and dynamically linked. This requires that SSL libraries be installed separately. See here for more information on installing OpenSSL. .   Make sure you have OpenSSL installed correctly: .  Once you have the right version and OpenSSL is installed properly, the MongoDB binaries should work as expected. .   There is an alternative to downloading the binaries manually. You can follow this guide to configure your package manager to install MongoDB. .  Remember that you should use the Ubuntu 14.04 instructions because it is mostly compatible with Linux Mint 17.1. .  ",
      "P-tags": "mongodb linux ubuntu",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "ul_606416",
      "task": "Get Linux user password into a C program",
      "P-task": "get linux user password c program",
      "F_verb": "get",
      "P-body": "In a PAM module, the way to get the user\u2019s authentication token is \"pam_get_authtok\". .  However, passing passwords around is usually a bad idea; does your SMS-sending service really need to know the user\u2019s password? (I\u2019m not looking for an answer, just suggesting it\u2019s worth questioning that.) .  ",
      "P-tags": "c linux pam",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_35615398",
      "task": "Trying to make a static link to create a executable",
      "P-task": "tri make static link creat execut",
      "F_verb": "make",
      "P-body": "Don't use \"<>\". These are shell redirections (e.g. \"cat /etc/passwd > /tmp/out\") .  Instead of: .  Try: .  Or: .  ",
      "P-tags": "gcc c bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_264357",
      "task": "To find the size of some group of files",
      "P-task": "find size group file",
      "F_verb": "find",
      "P-body": "In: .  you're piping the output of \"find\" to \"ls\", but \"ls\" doesn't read its input. It takes the list of files to list as arguments. In the absence of arguments like here, it lists the non-hidden files in the current directory. So here, you get the disk usage of all the non-hidden files (of any type) in the current directory (with the size of a given file counted for each of its hard links). .  In: .  You're counting the number of bytes in the output of \"find\", so that's the size of the file paths (and newline delimiters), not their disk usage nor file size. .  In: .  Like \"ls\", \"du\" takes the file list as arguments, not from its input. So here, you get the disk usage of all the files and directories in the current directory (recursively). .  To get the disk usage of all regular files owned by \"agalya\", with GNU utilities, you'd do: .  \"--files0-from\" tells \"du\" (GNU \"du\" only) to take the file list from standard input (represented by \"-\" here). \"-c\" gives the cumulative size (note that hard links of a same file are counted only once). .  To get the file apparent size as opposed to disk usage, add the \"--apparent-size\" option to \"du\" (again, GNU specific). Add the \"-l\" option (also GNU-specific) to count hard links several times. .  ",
      "P-tags": "size find file shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP of NP"
    },
    {
      "id": "so_32769126",
      "task": "How to execute a command with each GREP result while TAILING a file",
      "P-task": "execut command grep result tail file",
      "F_verb": "execute",
      "P-body": "The problem you're having is likely that grep is buffering its output when it sees that its output is another pipe. Your command might eventually produce output if you wait long enough for a buffer to fill up. .  Instead, try the following: .  (Yes, that input redirection option should work just fine. :] ) .  The relevant man page excerpt is: .  which obviously wouldn't have helped you much unless you knew what you were looking for. :-P .  Note that in the Linux world, you're using Linux, where your man page probably states that \"Direct invocation as either egrep or fgrep is deprecated, but is provided to allow historical applications that rely on them to run unmodified.\" Though to be honest, I don't see egrep ever disappearing, and other platforms (FreeBSD, OSX) make no mention of deprecation. .  ",
      "P-tags": "grep linux tail shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP while S"
    },
    {
      "id": "so_18451323",
      "task": "Need assistance for creating a simple bash script",
      "P-task": "need assist creat simpl bash script",
      "F_verb": "create",
      "P-body": "If it does not even do the mkdir, then it sound most likely that the version of the script you want is not the one running. Try using an qualified path, such as \"./myscript\" or an absolute path, like \"/home/joe/bin/myscript\". The command \"type myscript\" will tell from where the shell is running it. .  Also, try running the script after adding \"set -x\" to the top of the script or using \"bash -x myscript\"; that will show every line as it is executed. .  If this still doesn't help, there could be bash startup code, such as in \".bashrc\" getting in the way. That's much harder to diagnose, although the same \"set -x\" can be used, although with great caution unless a second user can login and edit this user's startup scripts since mistakes in startup scripts can make it impossible to login to the system. .  ",
      "P-tags": "termin sh unix linux bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_61871814",
      "task": "Create Set or Vmap for DNAT Nftables",
      "P-task": "creat set vmap dnat nftabl",
      "F_verb": "create",
      "P-body": "In case someone else goes through this I found the solution to my problem. In my case I have security through obscurity for RDP and SSH connections so I just needed one port for Windows and another for Linux devices. the resulting rule was. .  Then my @wan_to_lan map was as follows .  The trick is when setting the rule you have to remember you can use one or multiple maps. The exception is the vmap that already end the rule with a verdict. I think the wiki helps but needs to be updated as some of the syntax is no longer supported. .  ",
      "P-tags": "nftabl firewal debian-bust linux netfilt",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "so_23355287",
      "task": "Convert ambigious date string to unix timestamp in PHP",
      "P-task": "convert ambigi date string unix timestamp php",
      "F_verb": "convert",
      "P-body": "xdazz's answer is almost correct, but you will absorb the current time if you do that without removing it explicitly. .  In understand why we need line 2, replace line 3 with  .  Then, delete line 2, and observe that there is a time in addition to the desired date. .  ",
      "P-tags": "unix-timestamp php",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_60779172",
      "task": "Powershell Get-HotFix find updates supplied in a text file",
      "P-task": "powershel get-hotfix find updat suppli text file",
      "F_verb": "get",
      "P-body": "Why are you not using WSUS for this? It is why it exists. .  There are modules in the MS powershellgallery.com for this kind of use case well. .   I am working on updates for Win 7 x64 ultimate. .   So, what version of PowerShell are you using on Win7? .   I have a text file in which I have typed KBnnnnn one entry per line. .   OK, a standard file that can be easily read using Import-Csv or Get-Content. Yet, why are you doing this? There is a cmdlet called Get-HotFix specifically for this. .   I want sort of a script/loop .   Sure, you can do this. .   About ForEach .   Each of the above help files has examples of loops. .   to go through each entry in text file and find it in installed updates. .   OK, this is a common thing. A PowerShell very beginner thing, with lots of articles, samples and videos all over the web for this and shown in the help cmdlet, resources, etc., shown. .   If found append a new text file with HotFixID, Description, date etc., and status='INSTALLED'. If not found, status='NOT INSTALLED' .   Again, nothing new or complicated here and again a very common thing and done via the -Append switch or the Add-Content cmdlet. .   later I want to selectively uninstall specific HotFixes by simial loop process reading each entry from a text file and uninstalling it, .   Again, nothing new or complicated here and again a very common thing. You do this via a comparison block/command in your code. .  About Comparison Operators .   updating status on screen and in another text log file. .   Again, nothing new or complicated here and again a very common thing. This is what Out-File or Export-Csv, or Start-Transcript or writing your own logger is for and using progress bars. Lots of articles, blogs, videos ho how to do this. .  Script Write-Log PowerShell Logging Function .   I am very new to PowerShell, tried to create a loop in cmd batch scripting using WMIC but no success yet. .   OK, this is fine. It means you should spend time learning it first and there are plenty of free text-based and video-based (YouTube videos, MSDN videos, etc.) for you to use. All it requires is that you search for it, use them as-is and or tweak as needed. .   'powershell windows hotfix management' .  'Beginning PowerShell' .  'Intermediate PowerShell' .  'Advanced PowerShell' .  'PowerShell file and folder management' .  'PowerShell hotfix report' .   Sample scripts .   'powershellgallery.com hotfix management' .  'wmic find hotfix' .  'vbscript wmic hotfix management' .   The question here is, why are you using WMIC, vs Powershell directly? Hence the cmdlets above. One can use WMIC without ever using PowerShell at all, in .bat/cmd/vbs files as has been done for years. .  You say you've done batch file programming, It's good to see you dip into the PowerShell pool, but that does not mean you can't stick with batch to do what you need and then convert that to PowerShell now or later. .  Update based on you code comment .  If you did this in the console/ISE/VSCode, it just works as it would from cmd.exe .  But you could have just done this and gotten something far more useable .  Comparing this against a file is just as simple. Let's say your file looks like this. .  Now read the file, using this .  or this .  You can see the difference is minor (visually) but Csv file needs a header (and really should be properly formatted first). Either add it to the top of the file or add it on the fly .  All the above is just educational stuff for you. You only really need one of the two below, or similar. .  Now just use the file. Read in a loop and use if/then or try/catch statement to get results .  or just compare the file list to the results of the cmdlet .  ",
      "P-tags": "powershel window hotfix wmic",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_53009605",
      "task": "AZURE: Change the PRIORITY Rule configuration in a network security group via PowerShell",
      "P-task": "azur : chang prioriti rule configur network secur group via powershel",
      "F_verb": "change",
      "P-body": "There are two points that you missed: .   You need to use \"Set-AzureRmNetworkSecurityGroup\" at last. .  You need to provide all required security rule parameters, not only \"Priority\", it is not allowed when using \"Set-AzureRmNetworkSecurityGroup\". .   You could try my sample command below, it works fine on my side. .   .  For more details about the parameters, refer to this link. .  ",
      "P-tags": "azur powershel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP via NP"
    },
    {
      "id": "au_1146248",
      "task": "Help me create a script that runs when keyboard is undocked",
      "P-task": "help creat script run keyboard undock",
      "F_verb": "create",
      "P-body": "The following will set up the Microsoft SP3 so that when the keyboard is removed it switches to portrait mode. The scripts ensure that the active stylus and capacitive touch orientation is correct.  .  Thank you to @george udeson for the link to the tutorial which helped me write this. .  UDEV rules .  portrait.sh script .  landscape.sh script .  After creating the udev rules file do not forget to run .  ",
      "P-tags": "script udev keyboard",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP that S"
    },
    {
      "id": "so_24190198",
      "task": "Process grep with pipe returns itself. How do I exclude it?",
      "P-task": "process grep pipe return\nexclud",
      "F_verb": "exclude",
      "P-body": "The traditional way would be: .  in which \"grep -v expr\" returns everything not matching \"expr\" .  You can then use \"awk\" to extract the relevant field (the pid in your case) .  (the \"$2\" corresponds to the relevant field/column) .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_49052365",
      "task": "VSTS API REST Doesn't download sources correctly",
      "P-task": "vst api rest download sourc correctli",
      "F_verb": "download",
      "P-body": "That\u2019s because you queue a new for the same TFVC repo by using \"$env:BUILD_SOURCEBRANCH\" in REST API, which value is the TFVC repo when you execute the PowerShell task. .  Assume you execute the PowerShell task (queue a new build) in buildA (build for \"$/project1\" TFVC repo), and you want to queue a new build for \"$/project2\".  .  Since the PowerShell task is executing in BuildA for \"$/project1\", when you use the predefined variable \"$env:BUILD_SOURCEBRANCH\", and value is \"$/project1\". .  If you want to queue a new build for a different repo \"$/project2\", you should specify \"$/project2\" in the build definition and skip to specify \"sourceBranch\" in PowerShell task (or you can use string \"$/project2\" to replace \"$env:BUILD_SOURCEBRANCH\" in the REST API): .   .  The application/json for the REST API to queue a new build should be: .  Note: Since you also use the predefined variable \"$env:SYSTEM_TEAMPROJECTID\" in your first build, if the new queued build definition located in a different project, you should use the project name/id instead. .  ",
      "P-tags": "powershel api rest azure-devop",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_935672",
      "task": "Ubuntu 16.04 on Dell XPS suspend occasionally fails",
      "P-task": "ubuntu 16 04 dell xp suspend occasion fail",
      "F_verb": "suspend",
      "P-body": "I had the exact same problem. The solution is to create a file in \"/etc/pm/config.d/\" with just one line: .  ",
      "P-tags": "broadcom wireless suspend dell 18 04",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_29610470",
      "task": "Using python to run bash commands and get Output",
      "P-task": "use python run bash command get output",
      "F_verb": "get",
      "P-body": " This semmed to work properly. Thank you. Guys for your help  .  ",
      "P-tags": "youtub linux download python bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_31033489",
      "task": "Create file from shell script (E.g, this-is-the-title)",
      "P-task": "creat file shell script e g this-is-the-titl",
      "F_verb": "create",
      "P-body": "The most glaring error is this: .  It's wrong for several reasons: .   This pipeline runs \"\"$title\"\" as a command -- meaning that it looks for a command named with the title of your blog post to run -- and pipes the output of that command (a command that presumably won't exist) to \"awk\". Using double-quotes around the entire awk command means you're looking for a command named something like \"/usr/bin/awk {print tolower(bash-)}\" (if \"$0\" evaluates to \"bash-\", which it will in an interactive interpreter; behavior will differ elsewhere). Using double-quotes rather than single-quotes to protect your awk script means that the \"$0\" gets evaluated to the shell rather than by awk.   A better alternative might look like: .  ...or, to use simpler tools: .  ...or, to use bash 4.x built-in functionality: .   Of course, all that assumes that \"title\" is set to start with. If you aren't passing it through your environment, you might want something like \"title=$1\" rather than \"title=\"$title\"\" earlier in your script. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "so_27035925",
      "task": "linux deploy, kali, start an app service after its boots up",
      "P-task": "linux deploy kali start app servic boot",
      "F_verb": "start",
      "P-body": "Place your script inside init /etc/init.d/ , then place a link to it inside /etc/rc5.d/ (be sure to get your accurate run-level)... Start the second link with the string S71 like S71apastart .  I.e do the following: .  Place the text: .  inside \"/etc/init.d/apaStart\" (a new file created by you) .  Then .  \"sudo chmod +x /etc/init.d/apaStart\" .  \"sudo ln -s /etc/init.d/tomcat /etc/rc5.d/S71apaStart\" (change rc5.d to rc3.d if needed depending on your runlevel) .  I won't suggest this method but it'll work with your situation. .  ",
      "P-tags": "boot linux bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP after S"
    },
    {
      "id": "so_10451247",
      "task": "how to convert from struct tm to long int in C?",
      "P-task": "convert struct tm long int c",
      "F_verb": "convert",
      "P-body": "You can use the \"mktime()\" function to convert a \"struct tm\" into a \"time_t\", which is an integer value. .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V from NP to NP in NP"
    },
    {
      "id": "so_18582412",
      "task": "You must provide a value expression on the right-hand side of the '-' operator",
      "P-task": "must provid valu express right-hand side - oper",
      "F_verb": "provide",
      "P-body": "This certainly comes to the fact that \"-split\" operator exists on PowerShell V3.0 but not in previous versions (have a look to \"$PSVersionTable\") the syntax is : .  In all Powershell versions you can use the \"split\" method of the \"string\" class : .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP on NP of NP"
    },
    {
      "id": "so_24139231",
      "task": "Remove/Substitute concurrent double quotes in unix",
      "P-task": "remov substitut concurr doubl quot unix",
      "F_verb": "remove",
      "P-body": "With \"sed\": .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "au_42128",
      "task": "Reduce touchpad touch sensitivity or disable tap-to-click unless key is pressed",
      "P-task": "reduc touchpad touch sensit disabl tap-to-click unless key press",
      "F_verb": "disable",
      "P-body": "In the Software Center there is an application called Pointing Devices \"sudo apt-get install gpointing-device-settings\" That should have everything you need. .  ",
      "P-tags": "touchpad 11 04",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP unless S"
    },
    {
      "id": "su_362868",
      "task": "Start Synergy in Crunchbang at Login Screen",
      "P-task": "start synergi crunchbang login screen",
      "F_verb": "start",
      "P-body": "Openbox uses a file at ~/.config/openbox/autostart.sh to start files. You can add or remove things from this file. .  In #!, you'll probably want to comment out the line that has cb-fortune in it, to remove the annoying \"Statler Says\" messages. .  Since you're using #!, there's an easy way to get to this config. Hit SUPER + SPACE, and go to SETTINGS > OPENBOX CONFIG > EDIT AUTOSTART.SH .  At the bottom, add a line that says \"synergyc server-host-name &\", replacing server-host-name with... well... the server host name, save it, and restart with SETTINGS > OPENBOX CONFIG > RESTART .  ",
      "P-tags": "linux synergi",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP at NP"
    },
    {
      "id": "so_55513395",
      "task": "nosetests skip certain tests in python with multiple tests",
      "P-task": "nosetest skip certain test python multipl test",
      "F_verb": "skip",
      "P-body": " I tried this and it worked for me. Before that You need to install \"pytest\" .  Documentation will be find by typing \"pytest --help\" under terminal .  or somewhere here .  ",
      "P-tags": "build command-lin pipelin nose shell",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_41129815",
      "task": "How to resolve npm run dev missing script issues?",
      "P-task": "resolv npm run dev miss script issu",
      "F_verb": "resolve",
      "P-body": " will run bash script from package.json from 'scripts' value of '' attribute. For example: .  package.json .  In this case you can run scripts: .  In your case you probably wont have dev script. .  Remember that few scripts name are reserved (for example npm test will try to run, npm run pretest, npm run test, npm run posttest). More info on https://docs.npmjs.com/misc/scripts .  ",
      "P-tags": "node js git-bash webpack",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_65284204",
      "task": "Powershell - Using Write-Progress to show console output from an executable?",
      "P-task": "powershel - use write-progress show consol output execut",
      "F_verb": "use",
      "P-body": "Relaying standard output messages as progress status updates can be done by simply piping the output from the executable to \"ForEach-Object\" and passing it to \"Write-Progress\": .  ",
      "P-tags": "powershel consol execut",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF from NP"
    },
    {
      "id": "au_153580",
      "task": "Open Dialog, created with quickly does not work",
      "P-task": "open dialog creat quickli work",
      "F_verb": "create",
      "P-body": "I believe there is a typo in his example. The class and the module should have the same name. So instead of: .  it should likely be: .  (i.e. drop the New) .  If that doesn't work, I'd like to see both files if possible. .  ",
      "P-tags": "application-develop python quickli",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V with NP"
    },
    {
      "id": "so_23092994",
      "task": "How do I escape this ssh command correctly?",
      "P-task": "escap ssh command correctli",
      "F_verb": "escape",
      "P-body": " With the nested \"ssh\" commands, you need to quote the pattern twice, once so it isn't expanded on your local host, and again so it isn't expanded on hop1.example.com before being passed to hop2.example.com. Using the \"ProxyCommand\" avoids exposing the command to the shell on hop1.example.com. Also, passing the list of files to zip directly as argument is superior to reading the output of \"ls\", which will break in the (rare) case where file names contain newlines, but also avoids the unnecessary extra process that runs \"ls\". .  If you connect to many different hosts through hop1.example.com, you might add ProxyCommand to your local \".ssh/config\" file. This example shows how to set it up just for hop2.example.com, but you can specify a pattern that matches more than one host name, rather than a single host name. .  Then, you can simply run .  ",
      "P-tags": "ssh shell bash",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP"
    },
    {
      "id": "so_70170590",
      "task": "How to create json file with parameter varible in jenkins?",
      "P-task": "creat json file paramet varibl jenkin",
      "F_verb": "create",
      "P-body": "The issue is due to the quotes as suggested in the comments. .  Script below should work for you: .  Output: .  The value of any variable can\u2019t be read by single quote \"'\", since it only represents the literal value of all characters within it. To get the value of \"company_name\" we need to end the single quotes, then add the variable and start single quotes again. .  Parameter expansion Quoting .  ",
      "P-tags": "json jenkin bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP in NP"
    }
  ],
  "1": [
    {
      "id": "au_1286690",
      "task": "How to scale up the UI of Spotify for 4K displays",
      "P-task": "scale ui spotifi 4k display",
      "F_verb": "scale",
      "P-body": "There is a fairly stable workaround for this. This is discussed in the Spotify forum. .  To scale the UI you can set a different scale factor at the application launch. So you want to edit the .desktop file Ubuntu uses to launch spotify to adopt a custom scale factor. As you've installed it from the snap store it will likely be located at \"/var/lib/snapd/desktop/applications/spotify_spotify.desktop\". If not you can use find like this: \"sudo find / -type f -iname spotify.desktop\". .  Then you just have to edit the \"Exec\" directive of this file to include the \"--force-device-scale-factor=X\" option, where X is the scale factor multiplier: .  Here I use \"vim\" for editing the file but \"nano\" or \"gedit\" can be used as well. .  And then you change the \"Exec\" directive to include the option: .  You save the file, close Spotify, and open it again: it should be scaled properly now. .  ",
      "P-tags": "snap spotifi hdpi",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V up NP of NP for NP"
    },
    {
      "id": "so_9427553",
      "task": "How to download a file from server using SSH?",
      "P-task": "download file server use ssh",
      "F_verb": "download",
      "P-body": "In your terminal, type: .  replacing the username, host, remote filename, and local directory as appropriate. .  If you want to access EC2 (or other service that requires authenticating with a private key), use the \"-i\" option: .  From: http://www.hypexr.org/linux_scp_help.php .  ",
      "P-tags": "ssh linux unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "ul_530956",
      "task": "How to make devtoolset g++ available for Makefile in docker's centos7?",
      "P-task": "make devtoolset g++ avail makefil docker centos7",
      "F_verb": "make",
      "P-body": "According to the comments and my own experience with Docker, each \"RUN\" line is run in a separate shell environment, so when you source an environment in one \"RUN\" line, that environment is not available to other \"RUN\" commands. .  Using the line \"RUN source scl_source enable devtoolset-7 && cd /home/admin/${APP_NAME}/nginx-base/cplusplus && make version && make\" instead of your previous \"RUN\" command makes sure the current environment is setup for the \"make\" command. .  ",
      "P-tags": "docker gcc cento yum make",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_46166953",
      "task": "-bash: create: command not found when 'create' and 'add' on Git",
      "P-task": "-bash : creat : command found creat add git",
      "F_verb": "add",
      "P-body": "\"init\" and \"add\" are both subcommands of \"git\". This means that you must do something like .  or .  ",
      "P-tags": "git bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V on NP"
    },
    {
      "id": "au_394385",
      "task": "Why can't I install gwget?",
      "P-task": "instal gwget",
      "F_verb": "install",
      "P-body": "It means the package is no longer in the repository. You either search for it online and download the .deb and install it manually, or search some third party ppa that provides the package for 13.10. I had a look myself and doesn't seem to be one, the most similar I can find is uget and multiget, also a graphical front-end downloader, you can try them: .  Good luck! .  ",
      "P-tags": "apt software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_57575409",
      "task": "How to receive OU values separately in different columns via powershell?",
      "P-task": "receiv ou valu separ differ column via powershel",
      "F_verb": "receive",
      "P-body": "now that you clarified things a tad, i think this does what you want. [grin]  .  what it does ...  .   creates two user objects to work with delete this when you are ready to work with your data set. [grin]  iterates thru the user list  splits the DistinguishedName to get the OUs  makes the \"$OuList\" variable into an array even if there is only one OU  builds a custom object with the anticipated max number of OUs you will need to determine that ahead of time.  sends that object out to the \"$Results\" collection  displays that collection   at that point, you have a collection that will gracefully export to a CSV file. [grin]  .  here's the code ...  .  output to screen ...  .  ",
      "P-tags": "powershel powershell-5 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP via NP"
    },
    {
      "id": "so_33460629",
      "task": "How to replace the second instance just once using awk",
      "P-task": "replac second instanc use awk",
      "F_verb": "replace",
      "P-body": "removing c=0 fixed the problem: Working version below.- Thanks all for your assistance. .  ",
      "P-tags": "awk linux unix",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_599496",
      "task": "Do programs themselves use symbolic links, or are they just for users?",
      "P-task": "program use symbol link user",
      "F_verb": "use",
      "P-body": "If there are programs that need Python 2, they should be explicitly using \"/usr/bin/python2\" (or similar) instead of the plain \"/usr/bin/python\". However, there might be some that haven't been updated, and still use \"/usr/bin/python\". Those could very well break. .  If you're on Ubuntu 20.04 or newer, the \"python-is-python3\" explicitly makes \"/usr/bin/python\" be Python 3. On older releases, I wouldn't recommend changing that symlink. .  ",
      "P-tags": "ubuntu symlink filesystem",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_39970",
      "task": "How do I look up which package brought a particular command?",
      "P-task": "look packag brought particular command",
      "F_verb": "look",
      "P-body": "You can determine the file name for a command line utility using the \"which\" command. For example, we can look up the path of the \"ls\" command: .  With that information, you can find out which package owns the file using \"dpkg\": .  That tells us that \"ls\" is provided by the \"coreutils\" package. .  ",
      "P-tags": "package-manag",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V up which S"
    },
    {
      "id": "ul_141131",
      "task": "Is this command safe to run from / as root",
      "P-task": "command safe run root",
      "F_verb": "run",
      "P-body": "The \"man\" page for \"rmdir\" says:- .  If you want to remove all empty directories then it will be safe. The question you need to ask is:- .  Do you want to remove all empty directories? .  Some applications need a directory even if it's empty. For example, \"journald\" can be configured so that it only logs to persistent storage if \"/var/log/journald\" exists. If you run your command when that directory is empty then it will be deleted. Afterwards \"journald\" will not log to persistent storage as it can't find the directory. I believe Fedora is configured this way by default. .  Also, empty (unmounted) mount points could also be deleted by your command. They should be reasonably easy to fix, but it could still catch you out. .  ",
      "P-tags": "root directory-structur find",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V from NP as NP"
    },
    {
      "id": "so_27102304",
      "task": "awk script to print in between result before the final result",
      "P-task": "awk script print result final result",
      "F_verb": "print",
      "P-body": "I would go for something like this: .  For your given input it returns: .  Explanation  \"NR==1 {next}\" skip the first line. \"{a[$1]+=$2}\" for every line, keep an array containing \"a[day]=value\". \"END {}\" when finished, print the results. \"for (i in a) {print i, a[i]; tot+=a[i]}\" print the totals for every day and keep a counter for all the values. \"print \"TOTAL\", tot\" print the total count.  If you want to keep the header, you can store it for \"NR==1\": .  ",
      "P-tags": "awk bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in NP before NP"
    },
    {
      "id": "au_142192",
      "task": "Can I install Linux kernel in Ubuntu appart of the default one?",
      "P-task": "instal linux kernel ubuntu appart default one",
      "F_verb": "install",
      "P-body": "To install Linux Kernel 3.4 on Ubuntu (or Kubuntu, etc.) 12.04, you want to use a Ubuntu version of the kernel, not the generic Linux kernel. This avoids the generic kernel problems mentioned by Thomas Ward in his answer. .  A stable version of Linux 3.4 has just been released and this version has important changes for btrfs, so many users of 12.04 LTS may be interested in this kernel.  .  For new changes and improvements in Kernel 3.4, you can refer to this page. .  You can find the Ubuntu specific kernels at this page. .  There are three ways you can potentially upgrade to Ubuntu-specific kernel 3.4:  First, you can download the Ubuntu 3.4 kernel deb packages and install them manually. See details below. .  Second, you can change the apt sources list as explained here: http://www.upubuntu.com/2012/05/how-to-install-kernel-340-stable-on.html. I haven't tested this approach and I'm not recommending it. .  Third, you can wait on an official backport of this kernel in a PPA or in -backports for 12.04 LTS. I don't have any further info on this option. .   Here are more details on how to do the first option: To use a new kernel as-is you only need to download and install the image.deb package that corresponds to your architecture; however if you need to build any external modules you also need the correct header.deb and source.deb packages.  .  You can find the Ubuntu kernels here: http://kernel.ubuntu.com/~kernel-ppa/mainline/ .  Ubuntu apparently released kernel 3.4 for Precise on 21-May-2012 09:41. See this link: http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.4-precise/ .  Make sure you download the correct matching files (32bit or 64bit or PAE). .  Open a terminal and move to the directory where you have downloaded the Ubuntu 3.4 kernel packages. If the files are in /Downloads directory then run the following command. .  Then use dpkg command to install the packages, for example, here I assume the 32-bit versions of the packages. Run the following commands one by one and type the password for sudo access when prompted. .  For linux-headers (of the 3 files, this one is not architecture specific): .  For linux-headers-generic (is architecture specific): .  For linux-image-generic (is architecture specific): .  If you see any warnings or errors while installing then try installing module-init-tools (latest version) first, and try again now it should work. Restart your system now; by default it will boot kernel 3.4. To check the kernel version after booting, open a terminal and type \"uname -a\".  .  ",
      "P-tags": "kernel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP of NP"
    },
    {
      "id": "so_21418748",
      "task": "Insert a string/number into a specific cell of a csv file",
      "P-task": "insert string number specif cell csv file",
      "F_verb": "insert",
      "P-body": "You can use the following: .  And set the bash values \"$value\", \"$row\" and \"$col\". Then you can redirect and move to the original: .  awk ... file > new_file && mv new_file file .  This \"&&\" means that just if the first command (\"awk...\") is executed successfully, then the second one will be performed. .  Explanation  \"-v value=$value -v row=$row -v col=$col\" pass the bash variables to \"awk\". Note \"value\", \"row\" and \"col\" could be other names, I just used the same as bash to make it easier to understand. \"BEGIN{FS=OFS=\"@\"}\" set the Field Separator and Output Field Separator to be \"@\". The \"OFS=\"@\"\" is not necessary here, but can be useful in case you do some \"print\". \"NR==row {$col=value}\" when the number of record (number of line here) is equal to \"row\", then set the \"col\" column with \"value\" value. \"1\" perform the default \"awk\" action: \"{print $0}\".  Example ",
      "P-tags": "awk csv perl bash sed",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP of NP"
    },
    {
      "id": "ul_352245",
      "task": "Using regular expressions to parse ip addresses from logs",
      "P-task": "use regular express pars ip address log",
      "F_verb": "parse",
      "P-body": "You start with using the proper output format for Nmap for this type of thing. Nmap's Grepable output option (\"-oG\") produces output in an easy-to-parse format that is consistent between versions, unlike the \"human-readable\" normal output. Here's how to get the list of all systems with port 25 open: .  Nmap will produce a line like this: .  And the awk command will match it based on the \"Host\" line beginning and print the second field, the IP address. .  ",
      "P-tags": "awk nmap regular-express text-process",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_244381",
      "task": "How can I delete multiple random lines from a text file using sed?",
      "P-task": "delet multipl random line text file use sed",
      "F_verb": "delete",
      "P-body": "You probably wanted to use \"RANDOM % 90\" rather then \"&\". That's where the zeroes come from (deleting line 1 is OK, on the next run, the lines will be numbered 1 .. 89). .  There is a problem, though: The formula could generate the same number several times. To prevent that, use a different approach: shuffle the numbers and pick the first ten: .  If you don't like \"sed\" generating a \"sed\" script, you can use \"printf\", too: .  ",
      "P-tags": "sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "ul_256945",
      "task": "Identify all files having no permission for others using find command",
      "P-task": "identifi file permiss other use find command",
      "F_verb": "identify",
      "P-body": " ",
      "P-tags": "permiss find",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP for NP using NP"
    },
    {
      "id": "ul_177610",
      "task": "unable to view postfix email from centos 7 command line, why not?",
      "P-task": "unabl view postfix email cento 7 command line",
      "F_verb": "view",
      "P-body": "Unless you have a specific requirement to move your mail store; simply restore the configuration to the defaults.  .  That setup stores your emails in \"/var/spool/mail/<username>\" instead of your \"home\" which means any MUA you install will know where to find it without any reconfiguration. .  ",
      "P-tags": "postfix smtp sendmail cento email",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP from NP"
    },
    {
      "id": "so_40136860",
      "task": "Replacing strings in text files",
      "P-task": "replac string text file",
      "F_verb": "replace",
      "P-body": "The \"-replace\" method is using regex. So use this: .  ",
      "P-tags": "powershel regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_608394",
      "task": "Identify duration on log file",
      "P-task": "identifi durat log file",
      "F_verb": "identify",
      "P-body": "Assuming your timestamps always come in pairs, you can do it with \"GNU sed\" and \"GNU coreutils\": .  Output: .  ",
      "P-tags": "command text-process",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP on NP"
    },
    {
      "id": "so_6907248",
      "task": "Subset of x86 without a %gs register: binary patching code that uses %gs instead of trapping to emulation?",
      "P-task": "subset x86 without gs regist : binari patch code use gs instead trap emul",
      "F_verb": "use",
      "P-body": "(This is assuming Adam Rosenfields solution is not applicable. It, or a similar approach, is probably a better way to solve it.) .  You haven't stated how you're emulating the %gs register, but it's probably going to be tough to patch every usage in general unless you have some special knowledge about the program, because otherwise you only have 2 bytes (in the worst, common case) you can modify with your patch. Of course, if you're using something like %es = %gs it should be relatively straight forward. .  Assuming this can somehow be made to work in your case the strategy is to scan the executable sections of the ELF-file and patch any instruction that uses or modifies the GS register. That is at least the following instructions: .   Any instruction with the GS segment override prefix (\"65\" expect for branch instructions in which case the prefix indicates something else) \"push gs\" (\"0F A8\") \"pop gs\" (\"0F A9\") \"mov r/m16, gs\" (\"8C /r\") \"mov gs, r/m16\" (\"8E /r\") \"mov gs, r/m64\" (\"REX.W 8E /r\") (If you support 64-bit mode)  And any others instructions that allow segment registers (I don't think that are that many more, but I'm not 100% sure). .  This is all comming from Intel\u00ae 64 and IA-32 Architectures Software Developer's Manual Combined Volumes 2A and 2B: Instruction Set Reference, A-Z. Be aware that the instructions are sometimes prefixed with other prefixes, sometimes not, so you should probably use a library to do the instruction decoding rather than blindly searching for byte sequences. .  Some of the above instructions should be relatively straight forward to turn into \"call my_patch\" or similar, but you're probably going to have trouble finding something that fits in two bytes and works in general. \"int XX\" (\"CD XX\") might be a good candidate if you can setup an interrupt vector, but I'm not sure it's gonna be faster than the method you're currently using. You will of course need to record which instruction was patched out and have the interrupt handler (or whatever) react differently depending on the return address (that your handler receives). .  You might be able to setup a trampoline if you can find room within -128..127 bytes and use \"JMP rel8\" (\"EB cb\") to jump to the trampoline (usually another \"JMP\", but this time with more room for the target address), which then handles the instruction emulation and jumps back to the instruction following the patched out %gs usage. .  Lastly I'd recommend keeping the trap-and-emulate code running to catch any cases you might not have thought off (self-modifying or injected code for instance). This way you can also log any unhandled cases and add them to your solution. .  ",
      "P-tags": "linux assembl x86 opcod gcc",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of S_ING to NP"
    },
    {
      "id": "ul_131432",
      "task": "Which driver is handling my touchpad?",
      "P-task": "driver handl touchpad",
      "F_verb": "handle",
      "P-body": "It's likely that none of them are doing it. On my system for example where I'm using Fedora 19 and a Thinkpad 410 with a Synaptic touchpad I have no Kernel driver as well. .  So then what's taking care of this device? Well it's actually this Kernel module: .  If you want to see more about this module you can use \"modinfo uinput\": .  As it turns out input devices such as these are often dealt with at a higher level, in this case the actual drivers are implemented at the X11 level. .   uinput is a linux kernel module that allows to handle the input subsystem from user land. It can be used to create and to handle input devices from an application. It creates a character device in /dev/input directory. The device is a virtual interface, it doesn't belong to a physical device. .   SOURCE: Getting started with uinput: the user level input subsystem .  So then where's my touchpad drivers? They're in X11's subsystem. You can see the device using the \"xinput --list\" command. For example, Here's the devices on my Thinkpad laptop: .  Notice that my TouchPad shows up in this list. You can find out additional info about these devices through \"/proc\", for example: .  OK but where's the driver? Digging deeper if your system is using a Synaptic touchpad (which I believe they make ~90% of all touchpads), you can do a \"locate synaptics | grep xorg\" which should reveal the following files: .  The first results there is the actual driver you're asking about. It get's loaded into X.org via the second file here: .  And this line: .  Is what associates the physical devices with this driver. And you're probably asking yourself, how can this guy be so sure? Using this command shows the device associated with my given Synaptic TouchPad using \"id=12\" from the \"xinput --list\" output I showed earlier: .  ",
      "P-tags": "driver linux touchpad",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP"
    },
    {
      "id": "so_59821216",
      "task": "Getting symbol name at address in Linux DWARF executable",
      "P-task": "get symbol name address linux dwarf execut",
      "F_verb": "get",
      "P-body": "One solution is to use ELF for symbols in the current executable and \"dladdr()\" for the symbols in dynamically loaded libraries. .  Here's the full code, in Rust (using goblin crate for reading ELF): .  Using this map I can find symbols in both current executable (which includes statically linked dependencies) and in the dynamic dependencies. .  ",
      "P-tags": "debug dwarf linux elf",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP at NP in NP"
    },
    {
      "id": "au_291010",
      "task": "How to use Bash Script to open URLs in a different profile with Firefox?",
      "P-task": "use bash script open url differ profil firefox",
      "F_verb": "use",
      "P-body": "If you omit the profile, \"firefox\" will open the URL in one of your open Firefox programs. You have to explicitly mention it: .  You can also open multiple URLs at once and combine it, removing the need for a sleep: .  ",
      "P-tags": "12 04 script firefox bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF in NP with NP"
    },
    {
      "id": "au_1078697",
      "task": "How to change the default version of python in ubuntu permanently",
      "P-task": "chang default version python ubuntu perman",
      "F_verb": "change",
      "P-body": "See this existing question about creating a bash alias permanently: .  How do I create a permanent Bash alias? .  Essentially you want to edit the file \"~/.bashrc\" and put that command somewhere (likely near the bottom) in there. The linked question is pretty old (2010) and mentions \"gedit\" but you don't have to use that text editor to modify the file, you can use whatever text editor you want. .  ",
      "P-tags": "command-lin version python python3 18 04",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_40518163",
      "task": "PowerShell Form sizing is different when run outside of ISE",
      "P-task": "powershel form size differ run outsid ise",
      "F_verb": "run",
      "P-body": "Change the following: .  to .  Re-adjust your form pixels as appropriate. .  ",
      "P-tags": "powershel winform",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V of NP"
    },
    {
      "id": "so_22696381",
      "task": "How to select specific lines and echo at the end in bash shell",
      "P-task": "select specif line echo end bash shell",
      "F_verb": "echo",
      "P-body": "You can use BASH array to store certain lines in array to be printed later: .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V at NP in NP"
    },
    {
      "id": "ul_265394",
      "task": "how to create table with fields in command line Centos",
      "P-task": "creat tabl field command line cento",
      "F_verb": "create",
      "P-body": "Assuming this is for MySQL (or MariaDB), and you have the above as the contents of a file named \"table_create.sql\": .  You have to know what your MySQL user ID and password are, and know the database name. Substitute those strings as appropriate for the apparent \"shell variables\" in the above command. .  It's probably advisable to have your table creation in a file, so as to be able to repeat that creation when you screw up, but if you must do it at the command line: .  ",
      "P-tags": "cento mysql command-lin",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_51784846",
      "task": "Find using regex with altenatives",
      "P-task": "find use regex alten",
      "F_verb": "find",
      "P-body": "The idea is right, but you need to type of the regex to use for \"find\". Since you have alternate operator \"|\" here, you need to enable ERE (Extended Regular Expressions) support which you can do as below. The \"-regextype\" allows you to specify the regex flavor that you need for the requirement. Also the \"/\" part is optional if you have enabled a greedy match \".*\" .  From my version of GNU findutils, you could see from the \"man\" page .   \"-regextype type\" .  Changes the regular expression syntax understood by \"-regex\" and \"-iregex\" tests which occur later on the command line. Currently-implemented types are \"emacs\" (this is the default), \"posix-awk\", \"posix-basic\", \"posix-egrep\" and \"posix-extended\". .   ",
      "P-tags": "find shell regex",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V using NP with NP"
    },
    {
      "id": "au_29621",
      "task": "How can I remove gradients from Elementary theme?",
      "P-task": "remov gradient elementari theme",
      "F_verb": "remove",
      "P-body": "The line you are looking for is line 410 in the gtkrc file, under the section  .   style \"murrine-toolbar\" = \"murrine-default\" .   starts with: gradient_shades You need to edit the gradient shade values to what you require. 1.0 is normal color, lesser than 1.0 is darker and greater than 1.0 is lighter shade. .  If you want it flat you can set everything to 1.0 and it would look like : .    ",
      "P-tags": "elementary-them",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_298655",
      "task": "Failing to create /dev entry from sysfs, No such device or address",
      "P-task": "fail creat dev entri sysf devic address",
      "F_verb": "create",
      "P-body": " You created a character device. You wanted a block device. So use \"b\" instead of \"c\" in the \"mknod\" command. .  Block device numbers and character device numbers are independent. Block device 31:0 is unrelated to character device 31:0. Your kernel has no driver for character device 31:0, hence the \u201cNo such device or address\u201d error. .  ",
      "P-tags": "linux devic sysf",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "au_610168",
      "task": "Can't see my files with \"ls\" anymore",
      "P-task": "see file ls anymor",
      "F_verb": "see",
      "P-body": "What happened? You've renamed the \"Desktop\" directory to \"*.txt\" by using the \"mv\" command. Unfortunately, the asterisk on the file name will probably be interpreted as a glob pattern, keeping you from repairing the mistake. .   Reverting the operation From the graphical interface  Open the File Manager. Go to you home folder. Locate a folder called \"*.txt\". Rename it to \"Desktop\"  From the command line Running \"mv \"/home/dlundy1/*.txt\" /home/dlundy1/Desktop\" will be enough, as any argument wrapped by simple or double quotes won't be interpreted as glob. .  ",
      "P-tags": "mv command-lin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP with NP"
    },
    {
      "id": "so_21881924",
      "task": "Hung processes resume if attached to strace",
      "P-task": "hung process resum attach strace",
      "F_verb": "resume",
      "P-body": "\"strace\" uses \"ptrace\". The ptrace man page has this: .  Are you seeing \"select\" return \"EINTR\"? .  ",
      "P-tags": "socket strace ptrace gdb linux-kernel",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V if S"
    },
    {
      "id": "so_12223077",
      "task": "PowerShell: Write-Progress for Progress on Multiple Scripts",
      "P-task": "powershel : write-progress progress multipl script",
      "F_verb": "write",
      "P-body": "Try this out. First file is master.p1: .  Second file is slave.ps1: .  Put those two files in the same dir and from PowerShell (or ISE) execute master.ps1. I have used this approach before to report progress of multiple phases across multiple scripts. The key is to pass the \"ParentId\" of the top level progress to the child scripts so they can report progress in that same context. If you provide a unique \"Id\" for each, they can get their own separate progress bar. Or just the same \"Id\" everywhere to update a single progress bar. .  ",
      "P-tags": "powershel progress loop",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "ul_664211",
      "task": "while loop compare timestamp",
      "P-task": "loop compar timestamp",
      "F_verb": "compare",
      "P-body": "When used with \"[ ... ]\", the unquoted \">\" is a redirection operator. This means that you now probably have a file named \"2021-08-10 05:00:00\" in your current directory, created by redirecting the output of the \"[\" command to file. .  The command .  may also be written .  (see e.g. How is this command legal? \"> file1 < file2 cat\"). This is a test for whether the string \"\"$start_ts\"\" is non-empty, and the output of that test (which is nothing because \"[\" does not output anything) is redirected to the file \"$end_ts\". .  When used with \"[[ ... ]]\", the \">\" is a string comparison operator that tests whether two strings are sorted in a particular way. This is likely what you want to use, but to get the logic right you'd use \"<\", or swap the arguments around \">\", or use \"until\" instead of \"while\". .   Another approach would be to skip the string comparisons completely and instead use integer comparisons of Unix timestamps: .  Since there is no call to GNU \"date\" inside the loop, this runs many times faster than the original code (about 50 times faster on my system). .  ",
      "P-tags": "shell-script bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "au_249138",
      "task": "Configuring a HTTP and HTTPS web accelerator using Varnish",
      "P-task": "configur http http web acceler use varnish",
      "F_verb": "configure",
      "P-body": "After reading the comment by gertvdijk, I have decided that the best strategy is to forward HTTPS traffic from the firewall directly to the web server, bypassing the Varanish proxy (as I don't need it to cache this traffic). .   If I understand your question correctly, you want to handle the SSL layer at your webserver behind Varnish, right? Why would want a caching server to only forward traffic? You can use plain firewall (\"iptables\") rules or have your webserver connected directly at port 443 for this without the need for traffic to pass Varnish. .   ",
      "P-tags": "varnish cach http",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP using NP"
    },
    {
      "id": "au_61208",
      "task": "how to recover from mounting /usr/ nosuid",
      "P-task": "recov mount usr nosuid",
      "F_verb": "recover",
      "P-body": "I'm probably late to the party, but recently I learned that having \"/usr\" on a separate partition is not such a good idea anyway - some things during the early Linux boot expect \"/usr\" to be available - so generally there will be silent failures unless you also modify the initrd to mount /usr during the early boot: .  See Booting Without /usr is Broken for more details. .  ",
      "P-tags": "fstab su sudo",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V from S_ING"
    },
    {
      "id": "so_38666350",
      "task": "Check if remote process is running (linux)",
      "P-task": "check remot process run linux",
      "F_verb": "run",
      "P-body": "I am not sure this is what you are looking for but you can execute the check command in the remote machine direcly inside a ssh call. The return value should correspond to the return value of the command invoked in the remote machine. .  Of course you need a passwordless authentication method enabled (e.g. ssh keys). .  ",
      "P-tags": "linux process ssh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_36004886",
      "task": "elfinder image thumbnails does not show in windows and linux server",
      "P-task": "elfind imag thumbnail show window linux server",
      "F_verb": "show",
      "P-body": "According to nao-pon Answer, This is by design of moono theme that I used for change Style of elFinder. .  Just need to change this line in theme css file. theme.css L.54 .  AND theme.css L.111 .  ",
      "P-tags": "linux elfind php",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V in NP"
    },
    {
      "id": "so_50423893",
      "task": "XAMPP : composer returns error instead create new laravel project",
      "P-task": "xampp : compos return error instead creat new laravel project",
      "F_verb": "create",
      "P-body": "Uninstalled XAMP and Installed LAMP in different way, but got the same issue : .  \"sudo apt install lamp-server^\" .  then solved by enable php mods : .  Followed : https://askubuntu.com/a/767970/509965 .  ",
      "P-tags": "laravel xampp php ubuntu-16 04",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "su_650000",
      "task": "CLI cURL works flawlessly, Apache with mod_php cannot resolve host, how to fix?",
      "P-task": "cli curl work flawlessli apach mod_php resolv host fix",
      "F_verb": "resolve",
      "P-body": "It appears that the problem was with my \"/etc/resolv.conf\". .  I had set up a custom network connection manager, that executed an external command to set up nameservers from a specific configuration file. The setup would simply erase the contents of \"/etc/resolv.conf\", append with new info and then start the network interface, set it's parameters (IP, Mask, Cast, Gate) and voila. .  Apparently that screwed up something. I guess I will have to look for different Before/After targets and write a custom \"resolv.conf\" updater. .  I did leave \"resolv.conf\" static now, and that seems to fix the issue. .  In the end, clearly this was a DNS problem. Thankfully, it's fixed. .  ",
      "P-tags": "dn php arch-linux linux apache-http-serv",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_28725944",
      "task": "merge contents of two files into one file in bash",
      "P-task": "merg content two file one file bash",
      "F_verb": "merge",
      "P-body": "You can always use \"paste\" command. .  ",
      "P-tags": "awk linux merg bash sed",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP of NP into NP in NP"
    },
    {
      "id": "au_429716",
      "task": "How to run a command or script at screen lock/unlock?",
      "P-task": "run command script screen lock unlock",
      "F_verb": "run",
      "P-body": "The following script will write lock/unlock time in a file \"time_xprofile\" in your home. .  save the script. Give it execution permission. .  How to run .  Note The script should run in back ground. Do not kill it. If you turn your screen lock/unlock while the script is running in background, your time of lock/unlock will be recorded in \"time_xprofile\" file at your home. One can use it to run some command or script at screen lock/unlock. .  Mind that if you close the current terminal your script will be killed. You can use  .  Then it will continue running even after closing the terminal. .  How to kill the script .  To kill the process, use in terminal .  Above script is inspired by this answer .  ",
      "P-tags": "command-lin bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP at NP"
    },
    {
      "id": "ul_363728",
      "task": "Which is the correct way to disable a systemd timer unit?",
      "P-task": "correct way disabl systemd timer unit",
      "F_verb": "disable",
      "P-body": "if \"myjob.service\" contains no \"[Install]\" block, then it is sufficient to just disable the timer. The timer was the only thing starting the \".service\" file, so with the \".timer\" disabled, nothing will start the \".service\" file. .  Also remember to run \"systemctl --user stop myjob.timer\". Disabling the timer prevents it from being started on the next boot, but it does not stop the timer currently running. .  ",
      "P-tags": "systemd-tim systemd",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "so_11065697",
      "task": "Successful Write doesn't write anything on the file",
      "P-task": "success write write anyth file",
      "F_verb": "write",
      "P-body": "The problem seems to be with this line: .  The equal comparison operator \"==\" has higher precedence so it is evaluated first. So instead of assigning the file descriptor number to \"fd\", you are assigning the result of the comparison to \"fd\". .  Fixing this is simple, as you can surround the part before the comparison in parentheses \"()\". .  ",
      "P-tags": "system-cal unix linux file c",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP on NP"
    },
    {
      "id": "su_393384",
      "task": "Making POP3 email account",
      "P-task": "make pop3 email account",
      "F_verb": "make",
      "P-body": "POP and IMAP are just protocols which are used to retrieve email messages from the server. Regardless of protocol in use from the client side MDA is the same (assume Dovecot if we are talking about recent cPanel versions). So, you should either re-configure Dovecot not to support IMAP on the server [1] or just block access to IMAP/IMAPs protocol ports with the help of firewall. .  [1] \"WHM -> Service Configuration -> Mailserver Configuration -> Protocols Enabled\" .  ",
      "P-tags": "linux pop3",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "ul_323243",
      "task": "Automatically mounting a partition",
      "P-task": "automat mount partit",
      "F_verb": "mount",
      "P-body": "You can add them in the file /etc/fstab Here is an example : .  ",
      "P-tags": "mount partit",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_1020211",
      "task": "apt-get error on kernel / dpkg on 14.04 LTS",
      "P-task": "apt-get error kernel dpkg 14 04 lt",
      "F_verb": "get",
      "P-body": "After purging the package in question it seems to have resolved it: .  Not sure why and how it broke in the first place. .  ",
      "P-tags": "14 04 apt kernel dpkg",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP on NP"
    },
    {
      "id": "su_533732",
      "task": "Where to store cronjob script?",
      "P-task": "store cronjob script",
      "F_verb": "store",
      "P-body": "Typically, I put mine in: .   \"/usr/local/bin/\" for scripts to be run by more than one normal user \"/usr/local/sbin/\" for scripts which are to be run as root  That way you separate the task that the script does, from cron which just automates launching it. .  You'll need root to store files there, though. .  ",
      "P-tags": "cronjob ubuntu-serv shell-script",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_257530",
      "task": "Problems creating a new user in Ubuntu",
      "P-task": "problem creat new user ubuntu",
      "F_verb": "create",
      "P-body": "You are using wrong command. Use \"useradd\" instead of \"adduser\": .  ",
      "P-tags": "12 04 addus command-lin",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_257999",
      "task": "How can I add new character after each line?",
      "P-task": "add new charact line",
      "F_verb": "add",
      "P-body": "There are few ways to settle this: .   \"sed 's/\\r\\?$/ A/' file_list.txt\"  \"awk '{print $0\"A\"}' RS=\"\\r*\\n\\r*\" file_list.txt\" \"awk -F'\\r' '{print $1\"A\"}' file_list.txt\"  ...  Widely accepted at last:  .  ",
      "P-tags": "awk",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP after NP"
    },
    {
      "id": "ul_132677",
      "task": "Heirloom Toolchest tr: error(s) trying to delete the complement of a set containing a multibyte character?",
      "P-task": "heirloom toolchest tr : error tri delet complement set contain multibyt charact",
      "F_verb": "delete",
      "P-body": "I've seen that before. A bug. Try: .  (that was from a quick look a few months ago, while this patch will get you going, I can't guarantee it's right. Apply with \"patch -l\"). .  Now also note that \"/dev/urandom\" provides with a stream of bytes. In UTF-8, not all sequences of bytes map to valid characters. For instance, 0x41 0x81 0x41 is not valid because \"0x81\" is \">=\" 0x80, so it can only occur in a sequence of 2 or more over 0x80 bytes. .  An invalid byte, because it's not in the set of characters that is the complement of \u2620, will not be deleted by \"tr\". .  Better would probably be: .  ucs-2 being the characters U+0000 to U+FFFF encoded on 2 bytes per character, \"/dev/urandom\" looks more like a stream of ucs-2 characters. we're missing the characters U+10000 to U+10FFFF though). .  But that would still include the D800..DFFF surrogate pair range which \"mbrtowc(3)\" will choke on (at least with my version of libc). .  Those code point are reserved for the purpose of UTF-16 encoding. d800dc00 for instance is the UTF-16BE encoding of U+10000, but there's no U+D800 character or U+DC00. The UTF-8 encoding of those don't make sense as a character either (even if adjacent). .  So you'd need to exclude them first: .  If the point is to get a stream of random Unicode characters encoded in UTF-8, best would probably to get a random code point in the allowable range (0..0xd7ff, 0xf000..0x10ffff) and convert that to UTF-8. If you want to base it on \"/dev/urandom\", you could use 3 bytes (24 bits) from it for each code point: .  ",
      "P-tags": "unicod tr",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_399470",
      "task": "how can I tell the mail command the path to sendmail?",
      "P-task": "tell mail command path sendmail",
      "F_verb": "tell",
      "P-body": "For bsd-mail (which Debian calls the \"bsd-mailx\" package) a \"sendmail\" option can be set in the \"~/.mailrc\" file: .  Which could instead be \"ssmtp\" or something or a simple shell script to test that this even works as documented. .  ",
      "P-tags": "mail-command",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_23835053",
      "task": "convert local time",
      "P-task": "convert local time",
      "F_verb": "convert",
      "P-body": " ",
      "P-tags": "datetim c unix",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "ul_666833",
      "task": "How to remove duplicate values on the same row using awk?",
      "P-task": "remov duplic valu row use awk",
      "F_verb": "remove",
      "P-body": "Using \"awk\": .  ",
      "P-tags": "awk dedupl text-process",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "so_64403232",
      "task": "How to create this Regex for Python?",
      "P-task": "creat regex python",
      "F_verb": "create",
      "P-body": "This will do it in Javascript and Python: \"(\\$product.*$)\" .   \"\\$\" matches the character $ literally (case sensitive) \"product\" matches the characters product literally (case sensitive) \".*\" matches any character (except for line terminators) \"*\" Quantifier \u2014 Matches between zero and unlimited times, as many times as possible, giving back as needed (greedy) \"$\" asserts position at the end of a line  See: https://regex101.com/r/XzEqG3/1 .  ",
      "P-tags": "linux python regex",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_472525",
      "task": "Kernel module shows me 8 processors instead of 4 for Intel i5-2500K",
      "P-task": "kernel modul show 8 processor instead 4 intel i5-2500k",
      "F_verb": "show",
      "P-body": "You should use \"for_each_online_cpu\" or \"for_each_present_cpu\" instead of \"for_each_possible_cpu\". That will limit the output to CPUs which are really online or present, respectively. .  ",
      "P-tags": "cpu hardwar kernel-modul linux-kernel",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP for NP"
    },
    {
      "id": "ul_146299",
      "task": "How did `git pull` eat my homework?",
      "P-task": "git pull eat homework",
      "F_verb": "pull",
      "P-body": "Yes, \"git\" ate my homework. All of it. .  I made a \"dd\" image of this disk after the incident and messed around with it later. Reconstructing the series of events from system logs, I deduce what happened was something like this: .   A system update command (\"pacman -Syu\") had been issued days before this incident. An extended network outage meant that it was left re-trying to download packages. Frustrated at the lack of internet, I'd put the system to sleep and gone to bed. Days later the system was woken up and it started finding and downloading packages again. Package download finished sometime just before I happened to be messing around with this repository. The system glibc installation got updated after the \"git checkout\" and before the \"git pull\". The \"git\" binary got replaced after the \"git pull\" started and before it finished. And on the seventh day, \"git\" rested from all its labors. And deleted the world so everybody else had to rest too.  I don't know exactly what race condition occurred that made this happen, but swapping out binaries in the middle of an operation is certainly not nice nor a testable / repeatable condition. Usually a copy of a running binary is stored in memory, but \"git\" is weird and something about the way it re-spawns versions of itself I'm sure led to this mess. Obviously it should have died rather than destroying everything, but that's what happened. .  ",
      "P-tags": "data-recoveri git debug",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_137894",
      "task": "How do I find out if my wireless card supports 5 GHz?",
      "P-task": "find wireless card support 5 ghz",
      "F_verb": "find",
      "P-body": "Find out the interface name, by running \"iwconfig\" .  In this case it is \"wlan0\", then run \"iwlist <interface> freq\", .  None of these channels are outside of 2.4 GHz. It does not support 5 GHz. .  ",
      "P-tags": "linux wifi 802 1x",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V if S"
    },
    {
      "id": "ul_423796",
      "task": "Content of variable seems to change",
      "P-task": "content variabl seem chang",
      "F_verb": "change",
      "P-body": "You have a trailing CR in the directory name. See the \"0d\" as the final character in the hex dump.) .  This also explains why the directory path is overwritten by the error message. Normally you would get .  But you were getting the equivalent of this, where the leading information has been overwritten by the CR and the subsequent error message: .  Try this to demonstrate the point: .  You can remove the trailing \"\\r\" character with a construct like this .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V"
    },
    {
      "id": "so_45087326",
      "task": "Run a powershell script with different credentials",
      "P-task": "run powershel script differ credenti",
      "F_verb": "run",
      "P-body": "You could use the \"net use\" command to gain access or the \"new-psdrive\" command instead. Another option would be to \"start-process\" a cmd prompt and use \"runas\" within it. Also, you may need to include the full path of powershell.exe or add it to the path variable. \"%SystemRoot%\\system32\\WindowsPowerShell\\v1.0\\powershell.exe\" .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_55291787",
      "task": "Vagrant - No guest IP was given to the Vagrant core NFS helper",
      "P-task": "vagrant - guest ip given vagrant core nf helper",
      "F_verb": "give",
      "P-body": "There isn't a quick and simple fix for this, your best bet is to downgrade the kernel version. .  Get a list of kernels headers and images .  Remove the offending kernel .  \"apt-mark\" - hold the offending kernel for future updates .  Remove other kernels and \"dkms\" .  Reinstall the older kernel and configure \"dkms\" using \"virtualbox-guest-dkms\" .  Reboot to enable the old kernel version .  Run \"apt update\" .  And you should be able to launch your \"virtual-box\" / \"vagrant\" boxes again. .  ",
      "P-tags": "ubuntu-16 04 virtualbox vagrant windows-10",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V to NP"
    },
    {
      "id": "au_1077492",
      "task": "How to create working shortcuts",
      "P-task": "creat work shortcut",
      "F_verb": "create",
      "P-body": "Okay I've got it figured it out, mostly thanks to the help of the folks over at Ubuntu Forums. I'm going to write it here for posterity, although I do still think a lot of this should be included with Ubuntu. .  Links don't work I haven't been able to figure those out, creating a link to an application and moving the link outside the current folder causes a lot of problems. In my particular case, Ubuntu thought the application was being launched from the location of the Link which meant that the application couldn't load its data. .  I just kind of gave up on the idea of getting these to work as they just don't seem reliable enough. Either way, getting Terminal Command Shortcuts is much better. .  Right Click to Create Shortcut Thanks to user mc4man on Ubuntu Forums for this. .   Install the correct filemanager-actions you need by following this guide (the default Ubuntu file explorer is Nautilus) Run \"fma-config-tool\"  Then just set it up like this: .   .   .  This will add an option when right-clicking inside Nautilus that will bring up the Shortcut creator app to add a shortcut in the current folder. This option will be in a sub-menu by default, but you can go into Edit -> Preferences -> Runtime Preferences and deselect \"Create a root filemanager-actions menu\" .   .  Creating Shortcuts for Programs that don't start with a program Programs running through Wine often require to launch a command with \"WINEPREFIX=/path/to/prefix\", this causes problems when trying to create shortcuts for them because they just won't get recognised as programs and fail to start. .  There's an easy fix for that. Instead of creating a command for .  You can just add env at the start: .  This will work. .  Ubuntu 19.04 Disco Dingo Update Updating this because GNOME's dumb and they changed how shortcuts work. The above to launch wine applications will not work if the shortcut is launched from Desktop/Nautilus. .  Take the \".desktop\" file you just created and move it inside \"/home/leonardo/.local/share/applications\". This will add the shortcut to your application list and you'll be able to start it there. .  ",
      "P-tags": "shortcut nautilu",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "au_876082",
      "task": "Can't change default shortcut behaviour in gnome",
      "P-task": "chang default shortcut behaviour gnome",
      "F_verb": "change",
      "P-body": "The settings panel is buggy: setting a default shortcut to a new behaviour won't change the shortcut. It will still perform the old behaviour. .  To correct this: .   Open the \"dconf editor\" by typing dconf in the Activities search bar. Go to \"org>gnome>desktop>wm>keybindings\" Find the old behaviour Uncheck Use default value and remove the shortcut you want to use from the Custom Value field. Syntax is \"['<Modifier>Key1', '<Modifier>Key2']\" Define your shortcut on the new behaviour.  For example: I removed \"'<Super>Up'\" from the \"maximize\" behaviour and defined \"['<Super>Up']\" as the custom value for the \"switch-to-workspace-up\" behaviour. .  ",
      "P-tags": "ubuntu-gnom shortcut-key workspac 16 10 gnome",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "so_53359456",
      "task": "Best way to watch a large number of directories?",
      "P-task": "best way watch larg number directori",
      "F_verb": "watch",
      "P-body": "Your approach is the correct one, and \"inotify\" is the most performant way to do this. If you run into this issue, you could just prompt the user to increase limit on their behalf to provide a better user experience (you have to perform a privilege escalation by asking for password for this). .  ",
      "P-tags": "linux java",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_473721",
      "task": "Calibrating a touch-screen on dual monitors (one touch one not)",
      "P-task": "calibr touch-screen dual monitor one touch one",
      "F_verb": "calibrate",
      "P-body": "I have it working now. The first thing I did was to install the latest version of the display driver from the xorg repo. I'm not sure if this step was absolutely necessary since it doesn't seem to have changed the output from \"xrandr\" much, but it didn't hurt anyway: .  Now \"xrandr\" shows \"DP-1\" with more properties: .  And then start X and run the following command to assign \"eDP-1\" as the touchscreen: .  The manpage of \"xinput\" (v.1.6.2) mentions that the device name can be given as a string as well. Therefore, this would also work: .  ",
      "P-tags": "touch-screen xinput xrandr x11",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_223556",
      "task": "How to check for specific strings in files of a large directory",
      "P-task": "check specif string file larg directori",
      "F_verb": "check",
      "P-body": "(Extracted answer from edit) .  I got the result of the search by letting it run overnight. The command I used was: .  Moving the results file, called \"myfile\" in the above command, definitely helped. .  I also sorted the strings in the file. It was originally called \"strings\", and I learned from one of the comments in this thread to change it to another name. So in the above command it is called \"bar\". Using \"LC_ALL=C\" and \"fgrep\" instead of \"grep\" helped immensely. All the suggestions contributed to the answer. .  ",
      "P-tags": "ubuntu grep",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V for NP in NP of NP"
    },
    {
      "id": "so_17410841",
      "task": "How does USER_HZ solve the jiffy scaling issue?",
      "P-task": "user_hz solv jiffi scale issu",
      "F_verb": "solve",
      "P-body": "\"USER_HZ\" was implemented as a compromise: although user code could have a hard-coded value different from \"USER_HZ\", the Linux kernel historically had a \"HZ\" value of 100 -- so virtually all hard-coded \"HZ\" values in existing user code had been set to 100. .  Here's the essence of what happened: .  Now, this leaves the question of why some kernel jiffies are exposed to userspace unscaled (e.g. in \"/proc/timer_list\"). Thomas Gleixner explains: .   All instances which are de facto APIs, syscalls and also various files in proc/ must be in USER_HZ because userspace applications depend on the USER_HZ value. .  proc/timer_list is exempt from that because its more a debugging interface which is not part of the strict kernel API. And we really want to see the real values and not the scaled USER_HZ ones for that purpose. I hope that answers your question. .   So all instances which are part of the strict kernel API are meant to scale kernel jiffies via \"USER_HZ\" before exposure to userspace, which other instances are exempt. .  See also  The Tick Rate: HZ section of Linux Kernel Development Second Edition by Robert Love .   ",
      "P-tags": "linux linux-kernel",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP"
    },
    {
      "id": "su_1269130",
      "task": "How to change the max size of the u-boot environment?",
      "P-task": "chang max size u-boot environ",
      "F_verb": "change",
      "P-body": "Solved it: .  In order to update the environment size with flash memory (in particular on the Tegra), we need to: .   Ensure the \"CONFIG_FILE\" is defined in /tools/env/fw_env.h in uboot src (make sure this line is uncommented (#define CONFIG_FILE \"/etc/fw_env.config\") .  Change \"CONFIG_ENV_SIZE\" to desired size (/include/configs/tegra-common.h in uboot src), note it needs be 4k aligned for flash if using mmc .  Match Env. size below to the size of \"CONFIG_ENV_SIZE\" .  Set the Device offset below to ((end of environment addr + 1) - \"CONFIG_ENV_SIZE\") (turns out uboot environment is stored at the end of the boot partition) .  Keep Flash sector size below set to 0x2000 if Env. size differs .   ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP"
    },
    {
      "id": "au_25540",
      "task": "Suspend fails and I know the module causing it. What can I do?",
      "P-task": "suspend fail know modul caus",
      "F_verb": "suspend",
      "P-body": "This is a known bug: https://bugs.launchpad.net/ubuntu/+source/linux/+bug/522998 .  From there: .   If \"SUSPEND_MODULES=\"xhci\"\" is added to \"/etc/pm/config.d/unload_module\" then the system can suspend normally.  .   And a comment on there also points at Post #7 of this thread: http://ubuntuforums.org/showthread.php?t=1444822 .  Similar stuff and lots of people saying it works. Hopefully it will. .  ",
      "P-tags": "10 10 kernel suspend-resum suspend",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_336090",
      "task": "How install GraphicsMagick with quantum 16",
      "P-task": "instal graphicsmagick quantum 16",
      "F_verb": "install",
      "P-body": "You should build it from source (you should make sure that your \"deb-src\" lines in your \"sources.list\" are activated, and you ran \"sudo apt-get update\"): .  Enter the graphicsmagick-* directory. Now, run \"vim debian/rules\" (if you want to use another text editor, be my guest) and look for the line that reads: .   ./configure $(gm_confflags) \\ .   bellow this add (you need to press I to insert) \"--with-quantum-depth=16 \\\" so it should more or less looks like: .  Save the file (press Esc, then type \":wq\" and hit Enter), and run: .  The first one installs the build dependencies, the second builds the package, the third installs the packages. And thats it. .  ",
      "P-tags": "imagemagick apt configur",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_56589083",
      "task": "How to pass a powershell variable defined in one stage of jenkinsfile to another stage of same jenkinsfile?",
      "P-task": "pass powershel variabl defin one stage jenkinsfil anoth stage jenkinsfil",
      "F_verb": "pass",
      "P-body": " ",
      "P-tags": "powershel jenkins-pipelin",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP in NP of NP to NP of NP"
    },
    {
      "id": "so_21486965",
      "task": "Running a batch file (with blanks) from powershell script",
      "P-task": "run batch file blank powershel script",
      "F_verb": "run",
      "P-body": "Is there a reason you want to start it with cmd.exe /k? .  ",
      "P-tags": "batch-fil window powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_43383276",
      "task": "How does Docker run a Linux kernel under macOS host?",
      "P-task": "docker run linux kernel maco host",
      "F_verb": "run",
      "P-body": "While the other answers are correct about the hypervisor, they don't answer your specific question. .  The answer is \"Docker [Desktop] for Mac\" does run a Linux host VM with a replacement for boot2docker - LinuxKit developed and maintained by Docker for the purpose of making lightweight distributions. .  https://blog.docker.com/2017/04/introducing-linuxkit-container-os-toolkit/ .  The uname you saw didn't have the keyword in it, but it seems to be included now, e.g. from Docker for Mac 18.03.1 I see: .  You can see links to the included versions on the release pages. https://docs.docker.com/docker-for-mac/release-notes/ .  So it's not so different from the old days \"Docker Machine + VirtualBox + boot2docker\",  .  for the new days, it's just the \"provisioning is done internally\" by \"Docker [Desktop] for Mac\" \"and VirtualBox is replaced by Apple's Hyperkit\", and \"the \"default VM\" is a bit more tucked away\". .  ",
      "P-tags": "linux linux-kernel maco docker",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP under NP"
    },
    {
      "id": "au_891623",
      "task": "How to list/access all the available audio input and output ports/channels of a USB soundcard from a particular PC",
      "P-task": "list access avail audio input output port channel usb soundcard particular pc",
      "F_verb": "list",
      "P-body": "After playing around a lot and experimenting with plugins, I was able to find a solution to the above problem. It was nothing but an extension of the above answer and the hints I got from here. To start with, the following is the \".asoundrc\" I used to get it working: .  I've tried to keep the whole thing simple. The ALSA commands \"aplay\" and \"arecord\", which are command-line sound player and recorder respectively, then allowed me to do what was required, i.e, play a speech file as well as to play a speech file at one channel (connected to an analog output port) and record it with another mono channel (connected to an analog input port). .  In order to test the configuration file, I used the following \"aplay\" command: .  With the above, playback works just fine. Now, in order to get down to business, and to see if both playback and capture and working, the following was used: .  The above uses channel-1 (connected to analog output port 1 on my M-Audio M-Track Eight soundcard) to playing device and channel-2 (connected to analog input port 2 on my M-Audio M-Track Eight soundcard) as recording device. To use other devices, outch1 can be replaced by any of outch2, outch3, outch4, outch5, outch6, outch7, outch8 and inch2 by any of inch1, inch3, inch4, inch5, inch6, inch7, inch8 (in accordance with what was defined in \".asoundrc\"). .  It was a bit hard to find the right and well documented literature for ALSA. But, from my experience, it is the parameter \"bindings\" you need to tinker with in order to route audio from analog ports (possibly a client channel) to ALSA channels (slave channels defined as above in \".asoundrc\"). .  ",
      "P-tags": "soundcard sound alsa python-2 7",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_9260948",
      "task": "How to see the compilation platform of a static library file",
      "P-task": "see compil platform static librari file",
      "F_verb": "see",
      "P-body": "In Unix (and similar - say, Linux or Minix) systems, you can use the \"file\" utility: .  (the \"%\" indicates a shell prompt and is not part of the command) .  As for Windows, I don't know if there is a built-in command already present, but if not, you can find the utility on this page: http://gnuwin32.sourceforge.net/packages.html (the \"file\" package is about 1/3 down the page). .  EDIT: For static libraries (\".a\" files), you first need to extract them and check a \".o\" file: .  WARNING: \"ar -x ...\" will pollute the local directory, so be sure to copy the files somewhere else (say \"/tmp/something\") first! .  I'm sure there is a way to directly check into these files, but this works just as well! .  ",
      "P-tags": "c unix maco",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_435757",
      "task": "xargs with rm + filename containing spaces",
      "P-task": "xarg rm + filenam contain space",
      "F_verb": "contain",
      "P-body": " This assumes GNU coreutils' version of \"xargs\" that supports the \"-d\" option for specifying the delimiter. .  This will not work together with your \"find\" command because it adds double quotes to the pathnames found by \"find\". This means that instead of \"./somedir/file.scala\", the call to \"rm\" is done with the literal pathname \"\"./somedir/file.scala\"\". .  Example: .  It works when you pipe the generated commands to \"bash\" because \"bash\" does quote removal. .  It would probably also have worked if you didn't go through the extra effort to add the quotes in the first place: .   To delete your files properly, use .  or, if you still want to use \"xargs\": .  which passes the pathnames between \"find\" and \"xargs\" as a nul-delimited list. Nul (\"\\0\") is the only character that is not allowed in a pathname on Unix systems. Filenames can additionally not contain \"/\", but newlines are allowed. .  A third option would be to call \"rm\" directly from \"find\": .  Note that \"{}\" does not need to be (and should not be) quoted as \"find\" knows perfectly well how to pass pathnames with spaces (or newlines or whatever it may be) to the named utility. .  ",
      "P-tags": "linux xarg find shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_42264015",
      "task": "Windows 10 CMD/Powershell Buffer adjusts only when enlarging the console window; not when shrinking. Fix?",
      "P-task": "window 10 cmd powershel buffer adjust enlarg consol window shrink\nfix",
      "F_verb": "adjust",
      "P-body": " As you've discovered, switching to the legacy console on Windows 10 (via a console shortcut's Properties dialog, tab Options, checkbox \"Use legacy console (requires relaunch)\" is, unfortunately, a global setting (affects all future console windows, irrespective of the shell run in them). .   Windows 10's new console, always sets the buffer width to the window width when you resize with the mouse, avoiding the need for horizontal scrolling (whereas the legacy console retains the original, larger buffer width when you make a window narrower with the mouse, at which point a horizontal scrollbar appears; as an aside: the legacy console doesn't allow making a window wider using the mouse). .   If a shortcut file of yours doesn't behave that way while not in legacy mode, recreate the shortcut file.    Note: The terms legacy and new console above refer to modes of the legacy \"conhost.exe\"-based console windows overall, as distinct from their modern successor, Windows Terminal. .   Therefore, the remaining part of this answer is only of interest, if any of the following apply: .   you're using the legacy console - either because you've opted to do so on Windows 10 or because you're running on Windows 8.1 or below - and want a simple command to fix the horizontal scrolling issue. .   you want to modify the startup dimensions of your console window by way of shortcut files. .   you're interested in a script that programmatically resizes a console window. .     There's no simple UI fix to avoid the horizontal scrolling when you narrow a window using the mouse - short of using the window's system menu's \"Properties\" dialog to make the buffer width match the window with, but that's cumbersome. .  Here is a command you can run after mouse-based resizing to fix the horizontal scrolling issue: .   PowerShell: .  So you don't have to type this every time, put it in a function, say, \"fixwin\", and add it to your \"$PROFILE\" (initialization script): .   \"cmd.exe\": .  Using \"mode\" is not an option, because it would set your buffer height to the window height as well, so you'd lose your scroll-back buffer - see this answer. .  You, can, however, call the above PowerShell command ad-hoc, using a DOSKEY macro: .  So you don't have to define the macro in every session, save the command to a batch file, say, \".cmdrc.cmd\" in folder \"%USERPROFILE%\", then modify the shortcut file that you use to start \"cmd.exe\" as follows: .   Open the shortcut file's Properties dialog (via the shortcut menu, by right-clicking; for a taskbar item, right-click for the taskbar-related shortcut menu, then right-click the second to last item representing the underlying shortcut file). .   In the Shortcut tab, replace the existing content of text box Target with the following: \"%windir%\\system32\\cmd.exe /k \"%USERPROFILE%\\.cmdrc.cmd\"\" .       As an alternative to resizing a window after the fact, you can use a shortcut file to launch a console with preconfigured dimensions, which works with both the legacy and the new consoles: .   Create a shortcut file pointing to the executable of interest (\"cmd.exe\" or \"powershell.exe\"). .   Launch the shortcut. .   Use the window's system menu's \"Properties\" dialog to set the desired window and buffer dimensions. .    The next time you launch that shortcut file, the previously configured dimensions should take effect again. .  To also remember the window position, position the window as desired, open the system menu's \"Properties\" dialog (again), uncheck \"Let system position window\", and click \"OK\". .   \"cmd.exe\" / PowerShell script for fixing the buffer-width issue and/or programmatically resizing the window: If you follow the instructions below, you'll be able to: .   Simply execute \"rw\" (for resize window) after having used the mouse to narrow the window, so as to make the buffer width the same as the window width. .   Alternatively, call \"rw <new-width> [<new-height>]\" to resize your window programmatically, which also sets the buffer width to the window width. .    Instructions: .   Pick or add a directory in your \"%PATH%\" in which to place the scripts below. .   Create wrapper batch file \"rw.cmd\" with the following content: .   Create PowerShell script \"rw.ps1\" with the following content (ignore the broken syntax-highlighting): .    ",
      "P-tags": "windows-consol vim shell bash powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V when S"
    },
    {
      "id": "so_53478428",
      "task": "Java/OpenJDK: How to add JAR to classpath",
      "P-task": "java openjdk : add jar classpath",
      "F_verb": "add",
      "P-body": "OK, I finally figured this out by myself. This is how you correctly add modules, which the JAR expects to be present: .  So it does not really have anything to do with the classpath, it's just about adding the module. .  ",
      "P-tags": "linux java",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1191075",
      "task": "How to open a text file in current working directory with `gedit admin://`?",
      "P-task": "open text file current work directori gedit admin :",
      "F_verb": "open",
      "P-body": "Unfortunately, no, it is not possible to pass a relative path with this \"admin://\" URI. This answer may be disappointing, but that is how it currently (Ubuntu 18.04, Ubuntu 19.10) works. .  Using a short wrapper script .  You can, however, very conveniently work around the issue with a wrapper script. With the script \"sedit\", you edit a file correctly with administrator privileges, just by typing the command and a filename, as in \"sedit ubuntu.css\". .  \"sedit\"): .  If you place that in a folder in your path, the command \"sedit ubuntu.css\" will open the file using the admin URI. Also providing the full path, or any valid path, will work. .  Other options .  Other, more standard options to not to have to type the pathname are: .   You can use Tab expansion once you typed the three slashes of the URI. .  You could drag the file from Files (nautilus) into the terminal. Thus, you could type \"gedit admin://' in the terminal, find the file in Files, and then drag the file from Files into the terminal. This can make it easier to enter the URI in the terminal. .  You could avoid typing the path using \"$(pwd)filename\" or \"$(readlink -f filename)\".  .  or .   You can install the nautilus python extension, \"nautilus-admin\". Install it with the command \"sudo apt install nautilus-admin\" or using Synaptic Package manager (unfortunatelly, you cannot find it using Software). This small python extension integrates in the right-click menu, and converts the selected file to an 'admin://' URI for editing with root permissions. .   ",
      "P-tags": "18 04 command-lin gedit",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_30582516",
      "task": "bash script grep using variable fails to find result that actually does exist",
      "P-task": "bash script grep use variabl fail find result actual exist",
      "F_verb": "find",
      "P-body": "HTML files can contain carriage returns at the ends of lines, you need to filter those out. .  Notice that there's no need to use \"grep\", you can use a regular expression filter in the \"sed\" command. You can also use the \"tr\" command in \"sed\" to remove characters, but doing this for \"\\r\" is cumbersome, so I piped to \"tr\" instead). .  ",
      "P-tags": "grep carriage-return curl bash sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP that S"
    },
    {
      "id": "ul_120291",
      "task": "How to get external monitor resolution set by xrandr to persist",
      "P-task": "get extern monitor resolut set xrandr persist",
      "F_verb": "get",
      "P-body": "I'm sure there's a better way, I think this is all handled by \"udev\" now but if you know that those commands will solve it, you could always just make them into a script: .  Make it executable and then add it to your Desktop Environment's startup applications. This is probably the best choice if your DE provides you with the option. .   If you can't do the above, as a dirty hack you could add them to your \"~/.profile\": .  The \"if [ ! -t 0 ]\" should ensure this is only run in the GUI and \".profile\" is sourced by mint's login manager as I recall. .  Now, you should also be able to use \"~/.xsession\" but I've had issues with that being ignored. A lot of the older approaches are being replaced and I'm not sure what the state of the art way is. .  ",
      "P-tags": "multi-monitor resolut linux-mint xrandr",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP by NP S_INF"
    },
    {
      "id": "au_92379",
      "task": "How do I get permissions to edit system configuration files?",
      "P-task": "get permiss edit system configur file",
      "F_verb": "get",
      "P-body": "Which text editor are you using? If you are a sudoer and know your password, try (in a terminal) either: .   \"sudoedit /etc/dhcp/dhcpd.config\" if you are using a terminal-based editor such as \"nano\" or are ssh'ing into a server. \"gksudo <text editor here> /etc/dhcp/dhcpd.config\" if you are using a GUI-based editor such as \"gedit\"  In either case, you'll need to first provide your password when requested. .  In Ubuntu 14.04 onwards, \"gksudo\" is not installed by default. You will have to install the \"gksu\" package (either from the Software Centre or via \"sudo apt-get install gksu\") to get it. .  In Ubuntu 17.10, Wayland is default instead of the traditional X server, and running graphical editors as root is difficult. See Why don't gksu/gksudo or launching a graphical application with sudo work with Wayland? for details. .  In Ubuntu 18.04, \"gksudo\" is not available in the official repositories. Use \"sudo -H <text editor>\" instead, or the \"admin://\" protocol: .  ",
      "P-tags": "root configur permiss",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_613851",
      "task": "libMagicWand.so.5 cannot open shared object file?",
      "P-task": "libmagicwand 5 open share object file",
      "F_verb": "open",
      "P-body": "The library \"libMagickWand.so.5\" doesn't exist anymore in Vivid. Install the following library if it is not already installed. .  If that does not produce the desired result, then proceed here: .   Either you install the official package of emacs or you must recompile it yourself. .  With this command you can see, where do you get emacs via APT. .  Take the URL that is closest to the top. If the URL DOESN'T looks like this: .  THAN you can search in the files in \"/etc/apt/sources.list.d\" and in \"/etc/apt/sources.list\" and remove the affected line. .   Alternatively, you can also try to install the libraries from Utopic by hand. .  ",
      "P-tags": "shared-librari 15 04 emac",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "au_108689",
      "task": "How can I get tab completion with juju in zsh?",
      "P-task": "get tab complet juju zsh",
      "F_verb": "get",
      "P-body": "If you don't already have custom completion scripts, make a directory (e.g., \"~/.zsh/completion\") and add a line like \"fpath=(~/.zsh/completion $fpath)\" to the top of your .zshrc. .  You can then visit http://bazaar.launchpad.net/~benji/+junk/zsh-juju-completion/view/head:/_juju and click \"Download File\" and save it as _juju in the directory you made. .  Alternatively, if you have bzr installed, you can fetch the file like so: .  The completion file is generated by the script located at .   https://code.launchpad.net/~benji/+junk/zsh-juju-completion.  I'd like to add completion of service, unit, and charm names eventually. Patches welcome! .  ",
      "P-tags": "juju zsh",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_38766256",
      "task": "How to Expand Tab Symbol \\t with Spaces Correctly in Matlab?",
      "P-task": "expand tab symbol space correctli matlab",
      "F_verb": "expand",
      "P-body": "The format specification \"%6.0f x %6.0f\" specifies that each number is a floating-point number with a field width of six digits, with zero digits after the decimal point. Therefore, since the number is only \"960\", three spaces must be inserted in front of that number. .  Have a look at the documentation, it's explained quite well.  .  \"\\t\" is the ASCII code for tab, not four spaces. You might get four spaces in an editor, but in a string it's unambiguous, it's ASCII code point 9. The easiest and cleanest way is probably just to substitute the tab with four spaces directly in the string using \"regexprep\": .  By the way, I guess the format you want is: .  Note that all numbers occupy the same amount of characters as the headers above. The easier way would of course be to store all the column names in a cell and count the number of characters in each cell to determine the length of the corresponding numbers. .  Or use \"table\"!  .  ",
      "P-tags": "matlab ubuntu usabl tab",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_62082353",
      "task": "How to declare a global variable in an header file and how he need to be in the c file",
      "P-task": "declar global variabl header file need c file",
      "F_verb": "declare",
      "P-body": "Declare and define the global variable only in 1 \".c\" file and use \"extern\" to declare the global variable only in the other \".c\" files. .  Example with 3 source files: \"g.h\", \"g1.c\" and \"g2.c\":  .  You compile with: .  And execution says: .  ",
      "P-tags": "linux c global-vari extern",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_227032",
      "task": "rsyslogd running but cannot connect on port?",
      "P-task": "rsyslogd run connect port",
      "F_verb": "connect",
      "P-body": "Telnet will only connect to TCP services. You have loaded the \"imudp\" module, which provides a UDP service. .  You could use a tool like netcat (\"nc\") to send messages to a UDP socket: .  ",
      "P-tags": "rsyslog syslog",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V on NP"
    },
    {
      "id": "so_26479517",
      "task": "How can I create a table in powershell using variables and data I input",
      "P-task": "creat tabl powershel use variabl data input",
      "F_verb": "create",
      "P-body": "I believe you are trying to achieve something like this? : .  You will get the data as you've specified. You can use -ExpandProperty \"Column1\" (e.g. if you want to expand on all it's values). You can use ConvertTo-Html if you like to create a html-table of the data. .  However, I would consider structuring the data in another fasion. How about keeping this data in seperate objects instead of formatting it in this way? .  You could e.g. have a set of objects with the properties representing what you want. E.g. objects having the representative data :  .  That'd be more representative, and you could play and format the $myLocations for the properties you'd want. .  ",
      "P-tags": "powershel hashtabl",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "so_62759024",
      "task": "How to UNinstall php7.2-fpm WITHOUT installing Apache 2 (on a LEMP machine)",
      "P-task": "uninstal php7 2-fpm without instal apach 2 lemp machin",
      "F_verb": "uninstall",
      "P-body": "Ok, by sheer chance, when trying to fix this again, I stumbled upon the following explanation: https://www.digitalocean.com/community/questions/trying-to-uninstall-phpmyadmin-dpkg-error-while-cleaning-up .  While this is not directly related to my own issue with \"php7.2-fpm\", I've noticed a very important thing: the asterisk at the end! .  So I basically did: .  \"apt-get remove php7.2*\" .  and, for good measure, .  \"apt-get purge php7.2*\" .  (surprisingly, there were a few extra packages that had not been removed...) .  and, because it cannot hurt... .  \"apt-get autoremove\" (it returned that there was nothing left to remove) .  Also, to my astonishment, I still found a few old packages from \"php7.1\" available!! (I deleted them in the same way). And, sadly, because I have such an old base Ubuntu system, I need a few files from \"php7.0\" just to get a working Roundcube (critical for the overall operation of my server), but my next cleanup task will be to figure out how to get rid of it without disturbing \"Roundcube\"... .  ",
      "P-tags": "php ubuntu php-7 2 fpm apache2",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP without S_ING on NP"
    },
    {
      "id": "su_386601",
      "task": "Is it possible to add an exception with a \"ls -l *\"",
      "P-task": "possibl add except ls -l",
      "F_verb": "add",
      "P-body": "You can do it with a glob if you have \"extglob\" enabled. You can enable it with: .  And you can use it like: .  and it can be used in other ways, too: .  Since this is a shell glob it can be used with other commands as well. One side effect, however, is that it causes any subdirectories to be listed explicitly, which means that \"ls\" would list them too. But, that can easily be handled with: .  ",
      "P-tags": "unix linux script shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_38378090",
      "task": "Why is idle skipping over f = open('filename' , 'r')",
      "P-task": "idl skip f open filenam r",
      "F_verb": "skip",
      "P-body": "You only put file into variable 'f', so you need to read it or work it with someway to show it. .  You can find more way how to work with files on this http://www.tutorialspoint.com/python/python_files_io.htm .  ",
      "P-tags": "linux python python-3 x",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V over NP"
    },
    {
      "id": "so_28158544",
      "task": "NPM unable to install browserify globally",
      "P-task": "npm unabl instal browserifi global",
      "F_verb": "install",
      "P-body": "I was finally able to install modules globally using npm.  .  What I did: .  I had to use sudo and set the proxy/https proxy in several places. I followed the advice from this blog: http://wil.boayue.com/blog/2013/06/14/using-npm-behind-a-proxy/. .  I set the following variables in ~/.bashrc and exported them: .   http_proxy https_proxy npm_config_proxy npm_config_https_proxy  I also added them to env_keep using visudo (so they'd be available to sudo). .  I then set the proxy and https-proxy config settings on npm using: .  I'm not sure if all of this was necessary but it worked for me. Also, at one point I realized that I had the incorrect proxy and had to change it in several places (so be sure to double check that). .  ",
      "P-tags": "linux npm browserifi node js cento",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_36064852",
      "task": "Mac Terminal Strange Behaviour (no newline when hitting enter, no visible text )",
      "P-task": "mac termin strang behaviour newlin hit enter visibl text",
      "F_verb": "enter",
      "P-body": "As noted in comments (and as described by OP), the expected newline after each message was lost. That is because the application changed the terminal I/O modes dealing with carriage-return / line-feed, e.g., .   pressing Enter (which is a carriage return) was not translated into a newline (actually a line-feed), and newlines sent from the computer were not translated into carriage return / line-feed.  However, on \"any\" keyboard, you can type a newline by pressing controlJ. The usual fixes apply pressing controlJ first to get a prompt, and completing the command with pressing controlJ): .   \"stty sane\" (resets the terminal driver) \"reset\" (resets the terminal driver as well as asking the terminal to reset itself).  ",
      "P-tags": "termin maco bash",
      "source": "qa",
      "cate": "enter",
      "pat": "V NP"
    },
    {
      "id": "so_42225677",
      "task": "Listen error: unable to monitor directories for changes",
      "P-task": "listen error : unabl monitor directori chang",
      "F_verb": "monitor",
      "P-body": "1000 is way too small, try with 524288 as explained in the wiki page: https://github.com/guard/listen/blob/master/README.md#increasing-the-amount-of-inotify-watchers  .   Listen uses inotify by default on Linux to monitor directories for changes. It's not uncommon to encounter a system limit on the number of files you can monitor. For example, Ubuntu Lucid's (64bit) inotify limit is set to 8192. .   and .   If you are running Debian, RedHat, or another similar Linux distribution, run the following in a terminal: .  If you are running ArchLinux, run the following command instead .   ",
      "P-tags": "rubi ubuntu ruby-on-rail",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP for NP"
    },
    {
      "id": "so_30624446",
      "task": "Limit a set of processes' CPU and memory usage",
      "P-task": "limit set process cpu memori usag",
      "F_verb": "limit",
      "P-body": " Will the program launched from this console inherit the niceness of the console itself? .   The answer is yes. You can check it \"nice -n19 xterm\". In the console, start someprocess, then check the nice level using \"ps -efl | grep someprocess\". The nice level is inherited. .  ",
      "P-tags": "linux process maco limit resourc",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "so_61656172",
      "task": "Using sed on a long line including conditions keywords and specific characters",
      "P-task": "use sed long line includ condit keyword specif charact",
      "F_verb": "include",
      "P-body": "The \"[\" \"]\" have special meaning in regular expressions (and also \".\" and in extended regular expression also \"+\", but that doesn't affect here). Read about regular expressions. Escape special characters with backslash. .  Do: .  ",
      "P-tags": "linux operator-keyword sed bash",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP"
    },
    {
      "id": "ul_213957",
      "task": "Cannot access the hardware clock as a non-root user",
      "P-task": "access hardwar clock non-root user",
      "F_verb": "access",
      "P-body": "If it's standard for \"/dev/rtc0\" to belong to the \"audio\" group in Arch, you could just add yourself to the \"audio\" group (using \"adduser\"; you'll need to log out and log back in for the change to be effective). Alternatively, you could add an ACL giving yourself access to the device (look up \"setfacl\" to see how to do this). .  Ideally you shouldn't need to access the RTC as yourself though... .  ",
      "P-tags": "arch-linux clock not-root-us",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP as NP"
    },
    {
      "id": "so_59159933",
      "task": "Run multiple commands using wsl",
      "P-task": "run multipl command use wsl",
      "F_verb": "run",
      "P-body": " This way I load my own own profile and then I'm able to run the commands.  .  The option is just to run sh or any shell and then execute the commands you'd like within that shell. The other answer is also valid, but I like mine most, as I'm able to use the user profile (path, aliases, etc.) .  ",
      "P-tags": "windows-subsystem-for-linux",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP using NP"
    },
    {
      "id": "so_41751924",
      "task": "can't select item in dropdown",
      "P-task": "select item dropdown",
      "F_verb": "select",
      "P-body": "Actually $type was \"6\", but quotes marks were part of the string. .  So I need to remove them, which I did by the following line: .  ",
      "P-tags": "powershel html-select html",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_247576",
      "task": "How to get HOME, given USER?",
      "P-task": "get home given user",
      "F_verb": "get",
      "P-body": "There is a utility which will lookup user information regardless of whether that information is stored in local files such as \"/etc/passwd\" or in LDAP or some other method. It's called \"getent\". .  In order to get user information out of it, you run \"getent passwd $USER\". You'll get a line back that looks like: .  Now you can simply cut out the home dir from it, e.g. by using cut, like so: .  ",
      "P-tags": "shell-script user bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_69825942",
      "task": "PowerShell: Add-Member incorrectly changes Objects that aren't the input",
      "P-task": "powershel : add-memb incorrectli chang object input",
      "F_verb": "add",
      "P-body": "To flesh out the helpful comments on the question: .  \"$NewData = $Data\" does not copy data, because \"$Data\" contains a reference to an array, which is an instance of a .NET reference type. Instead, it is the reference that is copied, so that both variables end up referencing the very same array. .  An easy (albeit inefficient) way to create a copy of an array in PowerShell is to enclose it in \"@(...)\", the array-subexpression operator: .  However, if the array's elements too contain references to .NET reference-type instances, the copied array's elements still reference the very same instances - and the \"[pscustomobject]\" instances that \"Import-Csv\" outputs are indeed reference-type instances. .  You can create a copy of the \"$Data\" array and its elements with the following, using the intrinsic \".psobject\" member to create (shallow) copies of \"[pscustomobject]\" instances: .  However, as noted, \".psobject.Copy()\" creates a shallow copy of each \"[pscustomobject]\" input object. That is: .   properties that happen to contain instances of .NET value types result in true copies in the copied object; similarly, string values are in effect copies.[1] .   by contrast, properties containing references to instances of .NET reference types result in those references being copied, which means that both the original object's property value as well as the copied object's point to the very same instance, which means that if the referenced instance is mutable, changes to it are reflected in both containing objects. .    That said, with objects created via \"Import-Csv\", whose properties by definition are all strings, that is not a concern. .  See this answer for more information. .   [1] \"[string]\" is technically a reference type, but is usually treated like a value type in .NET. Since a string instance is by definition immutable, you can rely on any copy of it to remain unchanged. A string can never be modified, it can only be replaced by a )new_ string. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP that S"
    },
    {
      "id": "so_44953633",
      "task": "scripting a write command to another user",
      "P-task": "script write command anoth user",
      "F_verb": "write",
      "P-body": "You need to give input to write. Something like: .  or: .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_168423",
      "task": "Command not found when run with sudo bash",
      "P-task": "command found run sudo bash",
      "F_verb": "find",
      "P-body": "When you call \"sudo bash\" you run new instance of bash with \"user root environment\". But if you call \"sudo bash -c \"whoami; which bundle\"\" the environment is remain as for your user. If you havn't intention to do so you can modify last call by \"sudo\" options \"-i\" .   -i, --login .  Run the shell specified by the target user's password database entry as a login shell. This means that login-specific resource files such as .profile or .login will be read by the shell. If a command is specified, it is passed to the shell for execution via the shell's -c option. If no command is specified, an interactive shell is executed. sudo attempts to change to that user's home directory before running the shell. The command is run with an environment similar to the one a user would receive at log in. The Command Environment section in the sudoers(5) manual documents how the -i option affects the environment in which a command is run when the sudoers policy is in use. .   ",
      "P-tags": "path sudo shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V when S"
    },
    {
      "id": "au_732878",
      "task": "apt-get substitute MariaDB in place of MySQL",
      "P-task": "apt-get substitut mariadb place mysql",
      "F_verb": "get",
      "P-body": "postfixadmin should work with MariaDB. It is a drop-in replacement. In $CONF[database_type] you would need to to configure 'mysql' or 'mysqli' and not 'mariadb'. .  if postfixadmin keeps trying to install MySql you can try the \"--nodeps\" flag with \"apt-get\" or download and install the package using \"dpkg\" with the option \"--ignore-depends\" .  Good luck! .  ",
      "P-tags": "mariadb apt mysql",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP of NP"
    },
    {
      "id": "so_34034585",
      "task": "Remove duplicate lines by specifying more than one field, keep second sorted line",
      "P-task": "remov duplic line specifi one field keep second sort line",
      "F_verb": "remove",
      "P-body": " ",
      "P-tags": "awk unix bioinformat uniq sort",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP by S_ING"
    },
    {
      "id": "so_68145102",
      "task": "Compile RAID controller device driver (linux kernel module)",
      "P-task": "compil raid control devic driver linux kernel modul",
      "F_verb": "compile",
      "P-body": "I believe since Linux v4.x you fell victim to (or benefitted from, depending on your perspective) an effort to overhaul the DMA unmapping support. That patchset, and particularly the specific patch linked to here, show what PCI driver maintainers who were obliged to accommodate this rework were expected to do: .  [3/3] PCI: remove pci_set_dma_max_seg_size .  Fortunately for you, they gave specific examples of how existing drivers got patched and it's not bad. It should be pretty straightforward for you to figure out at least roughly the Linux version this change corresponds to around the 2018-19 date of the patch's acceptance upstream, code a new stanza in the Adaptec driver source to update it accordingly (e.g. .  compile the driver and be on your way. Note that the README does not explicitly mention support for the Adaptec 6805e RAID controller yet, so if you manage to make it work and post your patch you should at least add a comment to the effect that you believe this supports the controller now. .  ",
      "P-tags": "linux kernel c ubuntu",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP"
    },
    {
      "id": "so_31455622",
      "task": "Linux command to change xx.xx into xx,xx (for currency)",
      "P-task": "linux command chang xx xx xx xx currenc",
      "F_verb": "change",
      "P-body": "This sed command replaces '.' between digits with a comma (komma) .  ",
      "P-tags": "currenc linux command",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP"
    },
    {
      "id": "so_8402919",
      "task": "How to make GREP select only numeric values?",
      "P-task": "make grep select numer valu",
      "F_verb": "make",
      "P-body": "If you try: .  It returns: .   Here's the details on the \"-o\" (or \"--only-matching\" flag) works from the grep manual page. .   Print only the matched (non-empty) parts of matching lines, with each such part on a separate output line. Output lines use the same delimiters as input, and delimiters are null bytes if -z (--null-data) is also used (see Other Options). .   ",
      "P-tags": "linux grep bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_69748710",
      "task": "Powershell script - How can I get this script to only output values that match a certain string",
      "P-task": "powershel script - get script output valu match certain string",
      "F_verb": "get",
      "P-body": "Try with the \"Where-Object\" filter as follows: .  ",
      "P-tags": "azure-active-directori azur script office365 powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF that S"
    },
    {
      "id": "so_34064047",
      "task": "How to get name (path) of uinput created device",
      "P-task": "get name path uinput creat devic",
      "F_verb": "get",
      "P-body": "Yes, you can use \"UI_GET_SYSNAME\" (defined in \"/usr/include/linux/uinput.h\") if it's available on your platform (Android, for instance, does not define it for some reason). It will give you a name for the device created in \"/sys/devices/virtual/input\". Once you know the device in sysfs, you can figure out the device(s) created in \"/dev/input\" by reading this SO question. .  Use it after calling \"UI_DEV_CREATE\" like so (omitting error/sanity checking): .  If it is not available, you can try looking up the sysfs device in \"/proc/bus/input/devices\" which should contain an entry like:  .  ..which is a bit messier. But as you can see it'll also give you a shortcut to the device created in \"/dev/input\". .  ",
      "P-tags": "uinput linux linux-kernel linux-device-driv c",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_440537",
      "task": "What is the good way to remove SDK and other soft?",
      "P-task": "good way remov sdk soft",
      "F_verb": "remove",
      "P-body": "To uninstall APP SDK components on linux systems: .   Delete the directory pointed to the \"AMDAPPSDKROOT\" environment variable. Remove the \"AMDAPPSDKROOT\" and \"LD_LIBRARY_PATH\" environment variables. Delete the \"amdocl[32]64].so\" from \"/etc/OpenCL/vendors\". Manually remove temporary and new files created with OpenCL.  Unless otherwise modified at install, the main files would have been installed to \"/opt/AMDAPP\". .  Source: AMD APP SDK v2.9 Installation Notes .  ",
      "P-tags": "software-instal ati install-from-sourc",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_29116194",
      "task": "How to print output once using getopt with several commands in C",
      "P-task": "print output use getopt sever command c",
      "F_verb": "print",
      "P-body": "You should separate the getopt loop from the business logic. .  Here is an example how you could do it: .  ",
      "P-tags": "linux c getopt unix",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP using NP with NP in NP"
    },
    {
      "id": "so_2822040",
      "task": "system call to map memory to a file descriptor (inverse mmap)?",
      "P-task": "system call map memori file descriptor invers mmap",
      "F_verb": "map",
      "P-body": "You should Check out \"shm_open()\". .  ",
      "P-tags": "posix system-cal unix mmap c",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_3600170",
      "task": "How to cat two files after each other but omit the last/first line respectively?",
      "P-task": "cat two file omit last first line respect",
      "F_verb": "omit",
      "P-body": " ",
      "P-tags": "line text-fil bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_57719606",
      "task": "Delete lines in a text file that contain a specific string with /",
      "P-task": "delet line text file contain specif string",
      "F_verb": "delete",
      "P-body": "Escape the slashes: .  ",
      "P-tags": "linux text sed bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP that S"
    },
    {
      "id": "ul_229839",
      "task": "Set static IP when DHCP server is unreachable",
      "P-task": "set static ip dhcp server unreach",
      "F_verb": "set",
      "P-body": "There is a lease declaration. A quote from the manual: .   The DHCP client may decide after some period of time (see PROTOCOL TIMING) that it is not going to succeed in contacting a server. At that time, it consults its own database of old leases and tests each one that has not yet timed out by pinging the listed router for that lease to see if that lease could work. It is possible to define one or more fixed leases in the client configuration file for networks where there is no DHCP or BOOTP service, so that the client can still automatically configure its address. This is done with the lease statement.  .   So, you could add into your \"dhclient.conf\" a declaration something like this .  ",
      "P-tags": "dhcp dhclient raspbian",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP when S"
    },
    {
      "id": "su_1576774",
      "task": "Powershell || Cannot Change Cursor Shape",
      "P-task": "powershel chang cursor shape",
      "F_verb": "change",
      "P-body": "The \"PSReadLine\" module seems to be resetting the console properties every time when you change. Run \"Remove-Module PSReadLine\" to remove the module, console properties including cursor shape/size/colour would stay, but you will lose ReadLine features. .  ",
      "P-tags": "powershel windows-10",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "au_338381",
      "task": "How to prevent USC from opening a terminal when updating the cache?",
      "P-task": "prevent usc open termin updat cach",
      "F_verb": "prevent",
      "P-body": "You need to configure the \"update-manager\" to not automatically open when new updates are available. It typically doesn't just display a window though. It is designed to open as a minimized application, so you should only see it in the running apps list. You can simply close and ignore it, if you wish, and use \"sudo apt-get upgrade\" or \"sudo apt-get dist-upgrade\" to install any packages that need upgrading, after running \"sudo apt-get update\". .  ",
      "P-tags": "apt updat command-lin",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING when S"
    },
    {
      "id": "au_144531",
      "task": "How do I install OpenStack?",
      "P-task": "instal openstack",
      "F_verb": "install",
      "P-body": "Using the Ubuntu OpenStack Installer As the title suggests this little gem is an Openstack installer tailored specifically to get you from zero to hero in just a short amount of time. .  There are a few options available today for deploying an Openstack cloud. For instance, juju-deployer with an Openstack specific bundle or that other thing called devstack. A lot of people may not have 10 systems laying around to utilize juju-deployer or you may be wanting to demonstrate to the power of Ubuntu. .  The Ubuntu OpenStack Installer was created for these reasons.  .  Requirements  Decent machine, tested on a machine with 8 cores, 12G ram, and 100G HDD. Ubuntu Trusty 14.04 Juju 1.18.3+ (includes support for lxc fast cloning for multiple providers) About 30 minutes of your time.  First Add the ppa and install the software: .  Second Run it. .   .  Install selection .  Third You're presented with 3 options, a Single Install, Multi Install, and Landscape. Select Single Install. .  Post The installer will go through its little routine of installing necessary packages and setting up configuration. Once this is complete you'll be dropped into a status screen which will then begin the magical journey of getting you setup with a fully functioning OpenStack cloud. .  Yep, to elaborate a bit I'll explain what's happening: .  The entire stack is running off a single machine. Juju is heavily utilized for its ability to deploy services, setup relations, and configure those services. Similar to what juju-deployer does. What juju-deployer doesn't do is automatically sync boot images via simplestreams or automatically configure neutron to have all deployed instances within nova-compute available on the same network as the host machine all while using a single network card. We even throw in juju-gui for good measure! .  The experience we are trying to achieve is that any one person can sit down at a machine and have a complete end to end working OpenStack environment. Here's a screenshot of the nifty console ui: .   .  Verify Verifying your cloud is easy, just go through the process of deploying an instance via Horizon (OpenStack Dashboard, displayed at the bottom of the status screen), associating a floating IP (already created for you just need to select one) and ssh into the newly created instance to deploy your software stack. Depending on bandwidth some images may not be immediately available and may require you to wait a little longer. .  What about those other install options? Well, as I stated before we have a lot of cool technologies out there like MAAS. That is what the Multi Install is for. The cool thing about this is you install it the same way you would a Single Install. Fast-forward past the package installing and to the status screen you'll be presented with a dialog stating to PXE boot a machine to act as the controller. Our installer tries to do everything for you but some things are left up to you. In this case you'd commission a machine in the MAAS environment and get it into a ready state. From there the Installer will pick up that machine and continue on its merry way as it did during the single installation. .  One thing to note is you'll want to have a few machines whether it be bare metal or virtual registered in MAAS to make use of all the installer has to offer. I was able to get a full cloud deployed on 3 machines, 1 bare metal (the host machine running maas), 2 virtual machines registered in MAAS. Keep in mind there were no additional network devices added as the installer can configure neutron on a single NIC .  If you need swift storage for your glance images hit (F6) in the status screen and select Swift storage. This will deploy the necessary bits for swift-storage to be integrated into your Openstack cloud. Swift storage requires at least 3 nodes (in the single install this would be 3 VMs) so make sure you've got the hardware for this. Otherwise, for developing/toying around with Openstack leaving the defaults works just as good. .   .  Add swift storage Want to deploy additional instances on your compute nodes? Add additional machines to your MAAS environment or if running on a single machine and you have the hardware add a few more nova-compute nodes (via F6 in the status screen) to allow for more instances to be deployed within Openstack. .  This is just an intro into the installer more documentation can be found @ ReadTheDocs. The project is hosted @ GitHub and we definitely encourage you to star it, fork it, file issues, and contribute back to make this a truly enjoyable experience. Unofficial support can be found at irc.freenode.net in channel #ubuntu-solutions. .  Resources  Adam Stokes original blog post - this post derived from that post with permission. How do I deploy an OpenStack cloud with Juju? - This is basically what's happening underneath the cloud installer, go here for the indepth details.   ",
      "P-tags": "cloud openstack server",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_27694250",
      "task": "Why does `sched_setscheduler()` require root priveledges?",
      "P-task": "sched_setschedul requir root priveledg",
      "F_verb": "require",
      "P-body": "Presumably because processes using a realtime scheduler can completely take over a machine and not give the CPU to other processes - which normal users should not have the power to do. .  Linux allows you to do a bit more fine grained control than running as root though, you can set the CAP_SYS_NICE capability on your executable (done once, as the root user) with the command:  .  Which will allow your executable to use sched_setscheduler even when it's not run as the root user. .  ",
      "P-tags": "linux c linux-kernel root",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_23177413",
      "task": "I need to get the amount of numbers entered from a parameter and assign them to variables",
      "P-task": "need get amount number enter paramet assign variabl",
      "F_verb": "get",
      "P-body": "Consider the following as a starting point. Add more error checking for getting practice.  .  Output: ",
      "P-tags": "script shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_46125062",
      "task": "How to convert \"21 marzo 2017\" to Unix timestamp?",
      "P-task": "convert 21 marzo 2017 unix timestamp",
      "F_verb": "convert",
      "P-body": "You should first convert your months in english with \"str_replace\": .  Then you can use \"echo strtotime('21 march 2017');\"  .  If you have to convert other date, consider using a function and a switch-case. .  ",
      "P-tags": "strtotim unix-timestamp php data-convers",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_41636138",
      "task": "Python - Executing multiple shell commands one after another",
      "P-task": "python - execut multipl shell command one anoth",
      "F_verb": "execute",
      "P-body": "This code helps .  Here is the source http://eyalarubas.com/python-subproc-nonblock.html .  ",
      "P-tags": "subprocess python shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP after NP"
    },
    {
      "id": "au_407780",
      "task": "Does geary have a command flag to compose new email?",
      "P-task": "geari command flag compos new email",
      "F_verb": "compose",
      "P-body": "To launch the composer in Geary, specify a mailto: URI on the command-line: .  It's not listed in the --help, unfortunately. That's ticketed at https://bugzilla.gnome.org/show_bug.cgi?id=722647 .  ",
      "P-tags": "thunderbird geari messaging-menu indic",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "ul_184393",
      "task": "Manually executing a CRON - Confused about params",
      "P-task": "manual execut cron - confus param",
      "F_verb": "execute",
      "P-body": "As you are adding \"$APPVENV/bin\" to your path in order to run this from \"cron\" you should use: .  ",
      "P-tags": "linux debian shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_1571461",
      "task": "git: a quick command to go to root of the working tree",
      "P-task": "git : quick command go root work tree",
      "F_verb": "go",
      "P-body": "This has been asked before, Is there a way to get the git root directory in one command? Copying @docgnome's answer, he writes .  Make an alias if you like: .  ",
      "P-tags": "git script bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP"
    },
    {
      "id": "so_16595201",
      "task": "Why does -O to gcc cause \"stat\" to resolve?",
      "P-task": "-o gcc caus stat resolv",
      "F_verb": "resolve",
      "P-body": "In all likelihood, the optimization triggered removal of unreachable code, removing the need for the symbol altogether. .  When you built the \"test-files.so\" shared object, you likely did not use the C compiler but invoked \"ld\" directly. Thus, any library dependencies that \"test-files.so\" had would not be present. Loading the file dynamically would make it attempt to resolve the symbols with those already available within your \"test\" binary, and it could not be found. .  Compiling with the optimization removed the unreachable code that called \"stat\", and so the symbol did not need to be resolved on the call to \"dlopen()\". .  ",
      "P-tags": "linux glibc c shared-librari",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V"
    },
    {
      "id": "so_21935175",
      "task": "Converting virtual address to page table entry",
      "P-task": "convert virtual address page tabl entri",
      "F_verb": "convert",
      "P-body": "1) I think this is a typo indeed, as \"0000000001|0000000011|000000000100\" binary = 4,206,596 decimal .  2) The response is in the previous paragraph of the book :  .   Entry 0 of the top-level page table points to the page table for the program text, entry 1 points to the page table for the data, and entry 1023 points to the page table for the stack .   So he is just saying that \"0000000001|0000000011|000000000100\" corresponds to \"0000000011|000000000100\" into the data. Indeed \"0000000001\" corresponds to the data in the top level page table, and \"0000000011|000000000100\" binary = 12,292 decimal. .  ",
      "P-tags": "virtual-memori operating-system unix",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_9783848",
      "task": "Perl script to capture stderr and stdout of command executed in back-quotes",
      "P-task": "perl script captur stderr stdout command execut back-quot",
      "F_verb": "execute",
      "P-body": " The \"2>&1\" at the end sends standard error to the same place as standard output, which is captured by the back-quotes. .  ",
      "P-tags": "linux perl",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP"
    },
    {
      "id": "ul_7123",
      "task": "shell scripts that respond to console output",
      "P-task": "shell script respond consol output",
      "F_verb": "respond",
      "P-body": "I was in doubt when you said \"svnsync sync accepts no options to specify a login\" so I checked the documentation and guess what, it does: .  Those options should be enough for you to go back to a simple cron script. .  Back into the case where you really can't specify such options, it is still easy to write a wrapper script that sends data to the program's stdin. For example the following may work (where \"program\" is the program you wan to run, and \"text\" is a file where you store text to be sent to the program): .  However, for authentication, programs are often written to ready from \"tty\" and not from \"stdin\" (for security reasons). I'm not familiar with it, but you can still create a fake terminal in that case. This is where \"expect\" comes into use. .  ",
      "P-tags": "subvers shell-script shell",
      "source": "qa",
      "cate": "respond",
      "pat": "V to NP"
    },
    {
      "id": "so_43821157",
      "task": "sed: how to extract a part of a line containing colon",
      "P-task": "sed : extract part line contain colon",
      "F_verb": "extract",
      "P-body": "Change it to  .  Notice I added a colon in the last \"[0-9:]*\". The error was because you hadn't included a colon in your regex search .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_15101854",
      "task": "Keep user env variables executing gksu",
      "P-task": "keep user env variabl execut gksu",
      "F_verb": "keep",
      "P-body": "See the man page. Use \"gksu -k command...\" to preserve the environment (in particular, \"PATH\" and \"HOME\"). .  Or, like Lewis Richard Phillip C indicated, you can use \"gksu env PATH=\"$PATH\" HOME=\"$HOME\" command...\" to reset the environment variables for the command. The logic is that the parent shell, the one run with user privileges, substitutes the variables, and \"env\" re-sets them when superuser privileges have been attained.) .  If your application should only be run with root privileges, you can write a launcher script -- just like many other applications do. The script itself is basically .  or .  The script is installed in \"/usr/bin\", and your application as \"/usr/bin/yourapp-bin\" or \"/usr/lib/yourapp/yourapp\". The \"exec\" means that the command replaces the shell; i.e. nothing after the \"exec\" command will ever be executed (unless the application or command cannot be executed at all) -- and most importantly, there will not be an extra shell in memory while your application is begin executed. .  While Linux and other POSIX-like systems do have a notion of effective identity (defining the operations an application may do) and real identity (defining the user that is doing the operation), \"gksu\" modifies all identities. In particular, while \"getuid()\" returns the real user ID for example for set-UID binaries, it will return zero (\"root\") when \"gksu\" is used. .  Therefore, the above launch script is the recommended method to solve your problem. It is also a common one; run .  to see which commands are (or declare themselves to be) launcher scripts on your system, or .  to see which ones use \"gksu\" explicitly. There is no harm in adopting a known good approach.. ;) .  ",
      "P-tags": "linux c gtk",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_13705437",
      "task": "Shell script to read two values from file and insert them into a command",
      "P-task": "shell script read two valu file insert command",
      "F_verb": "read",
      "P-body": "Try this, in bash: .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "so_40804392",
      "task": "Ignoring table in mysqldump?",
      "P-task": "ignor tabl mysqldump",
      "F_verb": "ignore",
      "P-body": "For ignoring tables you must use this syntax  .  general syntax .  Note : we need to set the options to ignore some tables .  Thanks Suman W. .  ",
      "P-tags": "mysql bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP in NP"
    },
    {
      "id": "so_51894606",
      "task": "How to display select query in nice way using sqlplus in unix",
      "P-task": "display select queri nice way use sqlplu unix",
      "F_verb": "display",
      "P-body": "If you're stuck using SQL*Plus the simplest thing to do is concatenate the values yourself: .  If you can use SQLcl or SQL Developer instead then they can output CSV natievly: .  and that will include wrapping string in double-quotes etc. to avoid issues with embedded commas. .  ",
      "P-tags": "select sqlplu unix oracl",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP using NP in NP"
    },
    {
      "id": "au_1117684",
      "task": "Why is it possible to delete the entire file system?",
      "P-task": "possibl delet entir file system",
      "F_verb": "delete",
      "P-body": "\"rm\" is a low level system tool. These tools are built as simply as possible as they must be present on any system. \"rm\" is expected to have well known behaviour, especially with regard to confirmation prompts so that it can be used in scripts. .  Adding a special case to prompt on \"rm /*\" would not be possible as the rm command doesn't see it in this form. The \"*\" wildcard is expanded by the shell before being passed to \"rm\", so the actual command which needs a special case would be something like \"rm /bin /boot /dev /etc /home /initrd.img /lib /lib64 /lost+found /media /mnt /opt /proc /root /run /sbin /srv /sys /tmp /usr /var /vmlinuz\". Adding the code to check for this case (which will probably be different on diffferent linuxes) would be a complex challenge as well as being prone to subtle errors. The standard linux \"rm\" does have a default protection against system destruction by refusing to remove \"/\" without the \"--no-preserve-root\" option.  .  By default there are three protections against deleting your system in this way: .   Permissions - regular users won't be able to remove important files. You bypassed this with sudo Directories - by default rm will not remove directories. You bypassed this with the -r flag Write protected files - by default, rm will ask for confirmation before deleting a write protected file (this would not have stopped all the damage, but may have provided a prompt before the system became unrecoverable). You bypassed this protection with the -f flag  To remove all the contents of a folder, rather than running \"rm /path/to/folder/*\", do \"rm -rf /path/to/folder\", then \"mkdir /path/to/folder\" as this will trigger the \"--preserve-root\" protection as well as removing any dotfiles in the folder .  ",
      "P-tags": "command-lin rm",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_10679510",
      "task": "How to map {Ctrl  0,-,=} keys in vim?",
      "P-task": "map ctrl 0 - key vim",
      "F_verb": "map",
      "P-body": "Notice how in command-line mode, Ctrl-_ results in \"^_\", but Ctrl-0 and Ctrl-= yield nothing. .  Due to the way that the keyboard input is handled internally, differentiating this as well as many other key combinations (like Ctrl+Letter vs. Ctrl+Shift+Letter) unfortunately isn't possible today, even in GVIM. This is a known pain point, and the subject of various discussions on vim_dev and the #vim IRC channel. .  Some people (foremost Paul LeoNerd Evans) want to fix that (even for console Vim in terminals that support this), and have floated various proposals, cp. link .  But as of today, no patches or volunteers have yet come forward, though many have expressed a desire to have this in a future Vim 8 major release. .  ",
      "P-tags": "ubuntu-12 04 keyboard-shortcut vim map",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "so_62847222",
      "task": "Grep, awk not working on HTML curl file (getting link from html)",
      "P-task": "grep awk work html curl file get link html",
      "F_verb": "get",
      "P-body": "With \"xmlstarlet\": .  Output: .  I have used \"xmlstarlet format --html\" to save the correctable parts from broken HTML. .  Update .  To get last URL with Domain na-update.cedock.com: .  ",
      "P-tags": "awk grep bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_3047651",
      "task": "get an ioctl file descriptor for ethernet port",
      "P-task": "get ioctl file descriptor ethernet port",
      "F_verb": "get",
      "P-body": "Just use the file descriptor of an open socket, using the name of the device in the \"ifreq\" structure passed to \"ioctl()\", assuming your program has adequate permissions to do so. .  From the docs: .   Linux supports some standard ioctls to configure network devices. They can be used on any socket's file descriptor regardless of the family or type. They pass an ifreq structure: .   The socket need not be bound to the target device, or be of any specific family. Any open socket fd will do (again, with appropriate privileges), just open one for your specific task, wait for \"ioctl()\" to return and close it. .  See \"man 7 netdevice\" for more, or here if you don't have the appropriate documentation packages installed (hint, the package is usually named \"manpages-dev\" or \"manpages-devel\", depending on your distro) .  You can also take a look at the source to the \"net-tools\" package, which may be named differently depending on your distro. That's the source to \"ifconfig\" (Debian / Ubuntu here). .  Sorry for the original ambiguity, I thought you were trying to configure a special multi function device (not sure why now, perhaps lack of sleep). .  ",
      "P-tags": "linux c ioctl",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP"
    },
    {
      "id": "so_1731700",
      "task": "How do I turn the beep slash bell off in cygwin?",
      "P-task": "turn beep slash bell cygwin",
      "F_verb": "turn",
      "P-body": "Add \"set bell-style none\" to \".inputrc\" in your home directory. You need to start a new shell for this to take effect; that may be why your test didn't work. .  ",
      "P-tags": "cygwin bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP off in NP"
    },
    {
      "id": "ul_545254",
      "task": "ip address validation for setting up open vps",
      "P-task": "ip address valid set open vp",
      "F_verb": "set",
      "P-body": "The command \"ip a show eth0\" can also be written as \"ip addr show dev eth0\", which means \"show me the addressing for network device eth0\". When you get the error, \"Device \"eth0\" does not exist.\" it means that \"eth0\" is the wrong device name for your system. .  You then tried \"ip addr\", which can also be written as \"ip addr show\", and will have listed the addressing for all devices on your system. I assume that in the result you showed us you had ignored the loopback device \"lo0\" and included just the one remaining device entry for \"wio1\". .  So everywhere in your tutorial that references \"eth0\" you can probably substitute \"wio1\". And everywhere in the tutorial that uses \"172.26.6.74\" you should use \"192.168.43.288\". .  If you were to edit your question to include a link to the tutorial it would be possible to check that there's nothing unexpected in it. .  ",
      "P-tags": "ethernet linux network linux-kernel network-interfac",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP"
    },
    {
      "id": "so_23320931",
      "task": "Convert recursively all layer II mp3's to layer III and also update ID3",
      "P-task": "convert recurs layer ii mp3 layer iii also updat id3",
      "F_verb": "convert",
      "P-body": "This should get you started .   Noticed I have not used \"-print0\", might be a good idea. .  \"-q:a 0\" will maintain the quality. .  FFmpeg defaults to Layer III codec when you use output extension \".mp3\" .  FFmpeg writes 2.4.0 metadata by default .   ",
      "P-tags": "audio mp3 shell convert",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_64481406",
      "task": "Reset remote to specific commit in github (can't reset local and force push because of a large file)",
      "P-task": "reset remot specif commit github reset local forc push larg file",
      "F_verb": "reset",
      "P-body": "If the commit already exists on the remote, \"git\" will not upload it again. .  ",
      "P-tags": "github git-remot git-reset git-bash git",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "ul_636961",
      "task": "How to increase variable value in rename command",
      "P-task": "increas variabl valu renam command",
      "F_verb": "increase",
      "P-body": "With \"zsh\": .  Would rename up to 100 jpeg files (list numerically sorted). .  (remove the \"-n\" for dry run if happy). .  With \"perl\"-based \"rename\"s and basic shells, you could do something approaching (without the numerical sorting of the original list nor the safeguards of \"zmv\" though) with: .  \"rename\" runs the given \"perl\" code for each file in a loop with the name of the current file in \"$_\". The code is meant to change \"$_\" to the new name for the file. .  Here \"our $i\" defines the scope of the \"$i\" variable. You don't want local scope as in \"my $i\" as you want the incremented value of \"$i\" to be remembered from one file to the next, hence \"our\" (see \"perldoc -f our\" for details). .  The \"s/regexp/replacement/flags\" perl construct is to do regexp substitution on the contents of \"$_\". You don't need it here if you're building the replacement name from scratch. .  ",
      "P-tags": "renam",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP"
    },
    {
      "id": "so_60936794",
      "task": "delete all lines starting by: INSERT INTO `mdl_logstore_standard_log` VALUES",
      "P-task": "delet line start : insert mdl_logstore_standard_log valu",
      "F_verb": "delete",
      "P-body": "Looks like a duplicate of this.  .  Following the \"Better Solution\" in the chosen answer there, you would likely want to consider using \"sed\". This will delete the lines without needing to open the file. .  For your specific case, you can run  .  where you'd replace \"text_file.sql\" and \"new_text_file.sql\" with your current file and the file with lines deleted. You may also want to consider looking at the \"-i\" (or equivalent \"--in-place\") option if you'd prefer to overwrite your previous file with the new one. .  ",
      "P-tags": "command moodl text-fil linux sql",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP by NP"
    },
    {
      "id": "so_49827582",
      "task": "Powershell Rest API- Encode PDF to B64",
      "P-task": "powershel rest api- encod pdf b64",
      "F_verb": "encode",
      "P-body": "I've figured it out with this:: .  ",
      "P-tags": "powershel api",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP to NP"
    },
    {
      "id": "so_12899810",
      "task": "Why do I get unexpected token?",
      "P-task": "get unexpect token",
      "F_verb": "get",
      "P-body": "I don't have a Unix box to test but: .  ... should at least not trigger a syntax error. .  ",
      "P-tags": "linux grep shell regex",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_473630",
      "task": "Create a new file, but add a number if the filename already exists",
      "P-task": "creat new file add number filenam alreadi exist",
      "F_verb": "create",
      "P-body": " The loop in the above script will increment the \"num\" variable by one and create a new output filename in \"outfile\" using this number, until a filename that is no taken is found. .  This potentially fails if multiple copies of the script are run simultaneously, as there is a race condition between testing for the existence of the filename and creating the new file. Running the script with a one minute interval should not be a problem unless it takes a minute or longer for \"raspistill\" to create the new file. In this case, add \"touch \"$outname\"\" after the loop to \"claim\" the filename as soon as possible (simultaneous invocations of the script may still fail though). .  By \"failing\" I mean two or more invocations of the script using the same filename with \"raspistill\". .  ",
      "P-tags": "filenam",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP if S"
    },
    {
      "id": "ul_327571",
      "task": "Using sed to find and change information in configuration file",
      "P-task": "use sed find chang inform configur file",
      "F_verb": "change",
      "P-body": "When using variables in arguments of a command, you can't enclose it in simple quotes. .  Troubleshooting shell scripts, try running your commands one after the other, ... this would help you narrow down your problem. .  ",
      "P-tags": "shell-script sed",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_543894",
      "task": "Permissions problem with remote mount",
      "P-task": "permiss problem remot mount",
      "F_verb": "mount",
      "P-body": "OK there were TWO components that helped solve this. .  1) I set \"user_allow_other\" in /etc/fuse.conf .  However that was not enough .. After reading \"-man\" I saw the option flag \"-o allow_other\" on the mount command. This allows Apache to see and change the files without being a \"user\" specified in the permissions.  .  2) So I changed the command to: .  All is well with Apache displaying my images now. .  ",
      "P-tags": "mount permiss sshf",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "so_28690151",
      "task": "Linux, C++, Waiting for an event using poll/select ( w/o blocking the executing thread )",
      "P-task": "linux c++ wait event use poll select w block execut thread",
      "F_verb": "execute",
      "P-body": "Pthread mutexes do not have a file handle. .  Implement your own mutex on top of eventfd, then you can wait for it with \"poll()\". .  ",
      "P-tags": "c++ linux linux-kernel multithread",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_1190129",
      "task": "How to close terminal without shutting down Android emulator booted from terminal",
      "P-task": "close termin without shut android emul boot termin",
      "F_verb": "close",
      "P-body": "To prevent any process that was started from a terminal being killed when the terminal the process was launched from is closed, you need to prefix the emulator command with nohup or setsid. nohup is short for no hang-ups, and you will probably want to redirect output to /dev/null otherwise it wants to generate a nohup.out file. The ampersand & at the end causes the command to be run as a background process. Usage example: .  setsid runs a process or program in a new session preventing the process/program being killed when the terminal it was launched from is closed. Usage example: .  Note: On my system, I had to first cd into ~/Android/Sdk/emulator to run the emulator, in case any one tries to run the emulator from the command line right out of the box and gets a command not found error. .  see the man pages for nohup or setsid for more information. .  ",
      "P-tags": "android emul",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP without S_ING from NP"
    },
    {
      "id": "so_23017969",
      "task": "Name of linux shell command mapped to a given keyboard shortcut?",
      "P-task": "name linux shell command map given keyboard shortcut",
      "F_verb": "give",
      "P-body": "To pretty-print all active \"readline\" key bindings: .  That said, some bindings like Ctrl-c, Enter are not mapped to \"shell commands\" but rather to internal functions of the current shell. To figure out what a shell does when you press Ctrl-c you'd have to refer to the actual source code of the program which captures the shortcut, which could include anything from the shell to any other program in the foreground of the stack running in the shell. .  ",
      "P-tags": "keyboard-shortcut command-lin linux shell return",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "su_361683",
      "task": "Run mplayer from bash in background without extra bash",
      "P-task": "run mplayer bash background without extra bash",
      "F_verb": "run",
      "P-body": " ",
      "P-tags": "mplayer bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP in NP without NP"
    },
    {
      "id": "so_32576250",
      "task": "How do I call a button click by pressing the Enter key in Powershell",
      "P-task": "call button click press enter key powershel",
      "F_verb": "call",
      "P-body": "Set the Form's AcceptButton property to the Go button e.g.: .  ",
      "P-tags": "powershel button form enter",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP by S_ING in NP"
    },
    {
      "id": "so_67083968",
      "task": "How to temporarily load an env file for a single shell command, as a bash util/function/alias?",
      "P-task": "temporarili load env file singl shell command bash util function alia",
      "F_verb": "load",
      "P-body": "Based on your \"xenv()\": .  Note that usage like \"xenv ./envfile echo \"$FOO\"\" does not work because \"$FOO\" would expand in current shell's env. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP for NP as NP"
    },
    {
      "id": "so_41315062",
      "task": "How to list the 3rd party softwares installed in Centos",
      "P-task": "list 3rd parti softwar instal cento",
      "F_verb": "list",
      "P-body": "I do not have CentOS install. So I will show it how I will do that on my Fedora: .  This will get me who is vendor of rpm package. You may have there something like CentOS. Get that string. And then: .  This will print all installed packages which are not from vendor \"Fedora Project\". .  ",
      "P-tags": "cento linux rpm",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_108346",
      "task": "yum installs an old version of cmake",
      "P-task": "yum instal old version cmake",
      "F_verb": "install",
      "P-body": "You don't say but what versions are you getting and what versions do you expect? .  What repositories do I have? You can find out what repositories your system is configured to query using this command: .  Package info You can query any package whether it's installed or not using \"yum info <pkg>\". .  Package's URL You can find out where a RPM is being downloaded from using the \"repoquery\" command. .  Which is part of this repository: .  So this is a base repository to the CentOS distro that's providing this package. .  What other repositories have it? You can query what repositories contain a specific package (at least most of the major repos) using pkgs.org. .   http://pkgs.org/search/?query=cmake&type=smart  According to this list the EPEL repo has the latest version pre-built. The version of this package is as follows: cmake 28-2.8.11.2-1. .  ",
      "P-tags": "cento scientific-linux yum repositori",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_564938",
      "task": "MAAS Network question - Node cannot ping to outside world (ip shows up correctly)",
      "P-task": "maa network question - node ping outsid world ip show correctli",
      "F_verb": "ping",
      "P-body": "I'm still working on etherwake but for the moment I have figured a few things out about how MAAS works. I was correct about editing the cluster interfaces with the ifconfig from the machine that runs it. However, what I didn't know was that I have to forward the traffic from IPv4 to the internal LAN as well. In this case, I connect to the internet via wlan0 and my internal is connected via eth0. So, this is how I forward my traffic. .  Add this line into /etc/rc.local before exit 0 line .  Edit /etc/sysctl.conf (remove # from #net.ipv4.ip_forward=1) then .  Source: https://help.ubuntu.com/community/Internet/ConnectionSharing .  Note: I'm still working on Etherwake problem. Any pointers are highly appreciated. .  ",
      "P-tags": "juju wakeonlan network server maa",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V to NP"
    },
    {
      "id": "ul_29117",
      "task": "How to keep track of changes in /etc/",
      "P-task": "keep track chang etc",
      "F_verb": "keep",
      "P-body": "It sounds like you want etckeeper from Joey Hess of Debian, which manages files under \"/etc\" using version control. It supports git, mercurial, darcs and bazaar. .   git is the VCS best supported by etckeeper and the VCS users are most likely to know. It's possible that your distribution has chosen to modify etckeeper so its default VCS is not git. You should only be using etckeeper with a VCS other than git if you're in love with the other VCS. .   ",
      "P-tags": "git etc backup btrf",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_14615060",
      "task": "performing the same script on every directory",
      "P-task": "perform script everi directori",
      "F_verb": "perform",
      "P-body": "Try this .  ",
      "P-tags": "powershel batch-fil window",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_11131477",
      "task": "How to change the owner for a rsync",
      "P-task": "chang owner rsync",
      "F_verb": "change",
      "P-body": "There are hacks you could put together on the receiving machine to get the ownership right -- run 'chmod -R apache /website' out of cron would be an effective but pretty kludgey option -- but instead, I'd recommend securely allowing rsync-over-ssh-as-apache. .  You'd create a dedicated ssh keypair for this:  .  and then take ~/.ssh/apache-rsync.pub over to the webserver, where you'd put it into ~apache/.ssh/authorized_keys and carefully specify the allowed command, something like so, all on one line: .  and then your rsync command on your \"home\" machine would be something like .  There are other ways to skin this cat, but this is the clearest and involves the fewest workarounds, to my mind. It prevents getting a shell as apache, which is the biggest security concern, natch. If you're really deadset against allowing ssh as apache, there are other ways ... but this is how I've done it. .  References here: http://ramblings.narrabilis.com/using-rsync-with-ssh, http://www.sakana.fr/blog/2008/05/07/securing-automated-rsync-over-ssh/ .  ",
      "P-tags": "rsync unix",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP for NP"
    },
    {
      "id": "so_8414370",
      "task": "Go to next item in ForEach-Object",
      "P-task": "go next item foreach-object",
      "F_verb": "go",
      "P-body": "You may want to use the \"Continue\" statement to continue with the innermost loop. .  Excerpt from \"PowerShell\" help file: .   In a script, the \"continue\" statement causes program flow to move immediately to the top of the innermost loop controlled by any of these statements: .   \"for\" \"foreach\" \"while\"   ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V to NP in NP"
    },
    {
      "id": "so_11759761",
      "task": "Powershell invoke-command script return code",
      "P-task": "powershel invoke-command script return code",
      "F_verb": "invoke",
      "P-body": "I found the solution shortly after. I added an echo of the return code to my $cmdString, then used invoke-command to return the remote variable back to the local instance, then I interrogated the results for the return code: .  ",
      "P-tags": "powershel cmd invoke-command perl",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "so_18222248",
      "task": "Building OpenCV as static libraries",
      "P-task": "build opencv static librari",
      "F_verb": "build",
      "P-body": "Looking at OpenCV's CMakeLists.txt, it appears as if you're using the wrong names for the OpenCV CMake options. .  \"BUILD_SHARED_LIBRARIES\" should be \"BUILD_SHARED_LIBS\" and \"BUILD_PYTHON_SUPPORT\" should be \"BUILD_opencv_python\" .  ",
      "P-tags": "opencv linux static-librari gcc cmake",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP as NP"
    },
    {
      "id": "ul_511557",
      "task": "NetworkManager doesn't find predefined system-connections files",
      "P-task": "networkmanag find predefin system-connect file",
      "F_verb": "find",
      "P-body": "NetworkManager clients (like nmtui) never look at these files directly. They usually don't run as root and wouldn't have the permissions to read/modify them. Instead, they use NetworkManager's D-Bus API. .  You are welcome to create connection profiles in the editor or pre-deploy them. That is, configuring files directly instead of using the D-Bus API is very much supported and what you try to do is fine. .  Keyfile files (the connection profiles in\"/etc/NetworkManager/system-connections\") must be owned by root and have permissions \"0600\". Check the files owner and permissions with \"ls -l\" and fix it with \"chown\" and \"chmod\". .  Less likely is that NetworkManager cannot access the files. Eg. we SELinux labels. .  In any case, looking at NetworkManager's logfile would tell you why it doesn't load them. Check syslog/journal. .  ",
      "P-tags": "networkmanag",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_37528319",
      "task": "How to detect error (as in \"Directory not found\", \"TNS listener lost contact\", etc) in JSch?",
      "P-task": "detect error directori found tn listen lost contact etc jsch",
      "F_verb": "detect",
      "P-body": "The error are usually written to the error output. You can read the error output using \"getErrStream\". .  Note that you need to read the standard output (\"getInputStream\") and the error output in parallel, not in sequence. I mean that you cannot just clone your \"while\" loop, you have for \"getInputStream\", for \"getErrStream\". You need to have one loop, reading from both (read what's available in one, read what's available in the second, wait for new data and repeat) .  When you read first one and then the other, if the latter output is large, its output buffer gets full, the command stops, never finishing. So if you keep waiting for the first output to close, you deadlock with the server. .   Note that the \"Auth failed\" is not an error outputted by a command. It's an exception thrown by the JSch library. So it's irrelevant to your code. .  ",
      "P-tags": "linux stderr java jsch",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "so_57657143",
      "task": "using sed to replace version in file",
      "P-task": "use sed replac version file",
      "F_verb": "replace",
      "P-body": "You can do like this: .  For inline file edit: .  You need to escape the \"/\" like this \"\\/\". Then back reference \"\\1\" is used to retain the text. .  ",
      "P-tags": "sed shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "so_49085962",
      "task": "How do I run the ./configure script on git package?",
      "P-task": "run\nconfigur script git packag",
      "F_verb": "run",
      "P-body": "Gnash :  .   git clone git://git.sv.gnu.org/gnash.git .   ",
      "P-tags": "gnash linux autotool autoconf",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "au_69648",
      "task": "Gnome shell: pressing the super key does not work",
      "P-task": "gnome shell : press super key work",
      "F_verb": "press",
      "P-body": "finally found it myself. .  In older Ubuntu versions, go to System Settings > Keyboard Layout > Layouts and then choose Options. .  In newer Ubuntu versions, install Tweaks (\"sudo apt install gnome-tweaks\") and open it, then Keyboard & Mouse and then choose Additional Layout Options. .  There is an option for the Alt/Win key behaviour and there I had the option selected Meta is mapped to Win keys. .  Deselecting that option, and choosing Alt and meta are on Alt keys fixes it for me. At least the super is working again to access the Activities. Not quite sure what the impact is of this choice. .   .  ",
      "P-tags": "shortcut gnome",
      "source": "qa",
      "cate": "touch/press",
      "pat": "V NP"
    },
    {
      "id": "au_821212",
      "task": "How to set a ethernet device for Internet by force?",
      "P-task": "set ethernet devic internet forc",
      "F_verb": "set",
      "P-body": "I am assuming you are using NetworkManager, .  First Disable the Ethernet device. .  Then go to network manager and select edit connections and then the ethernet device running on its own LAN. .  Go to the IPV4 tab .  Select \"Routes\" .  Check the \"Use this connection only for resources on its network\". Make sure it is selected .  Finally: .  ",
      "P-tags": "ethernet",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP by NP"
    },
    {
      "id": "ul_268161",
      "task": "Can't find source package with apt-get source on Debian Squeeze",
      "P-task": "find sourc packag apt-get sourc debian squeez",
      "F_verb": "find",
      "P-body": "The \"APT::Default-Release \"stable\";\" line in your configuration is pinning you to \"stable\" which none of your \"deb\" or \"deb-src\" lines provide (\"stable\" is now \"jessie\"). To be able to use \"apt-get source\" without upgrading your whole distribution, you should either comment the line or change \"stable\" to \"squeeze-lts\". .  Note that you don't need to be \"root\" to run \"apt-get source\", you can run it as a standard user. .  Also, as garethTheRed points out, Squeeze is no longer supported (which, importantly, means that it no longer receives security updates). Not only that, but Squeeze LTS itself is no longer supported either, so you should really migrate to Wheezy LTS or Jessie sooner rather than later. .  ",
      "P-tags": "apt sourc debian",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "so_27795953",
      "task": "Case where Linux can be made to Crash or Hang in CPL3 (User Mode) without Root Acces?",
      "P-task": "case linux made crash hang cpl3 user mode without root acc",
      "F_verb": "make",
      "P-body": "The answer is: \"YOU CAN'T\". Alain Knaff, who is the writer of linux kernel says; And i Quote .   This is Linux, not Windows, and Linux doesn't have any bugs which would allow you to do this. There is a reason, after all, why more and more >people are ditching Windows, and using Linux. Ofcourse, you could always try manipulating the hardware (blocking the CPU fan to make the CPU overheat, jiggling the memory SIMMs, etc.), but I guess that wouldn't really count... .   Moreover u can crash your kernel from user mode in the earlier kerenel versions 2.0 etc . From user mode if u send the ping packet more than 653476 but conditional to earlier version of Linux kernel..current kernels have been resolved this Bug. .  Also that A null pointer dereference flaw was discovered in the Linux kernel's SCTP implementation when ASCONF is used. A remote attacker could exploit this flaw to cause a denial of service (system crash) via a malformed INIT chunk one more, A race condition with MMIO and PIO transactions in the KVM (Kernel Virtual Machine) subsystem of the Linux kernel was discovered. A guest OS user could exploit this flaw to cause a denial of service (guest OS crash) via a specially crafted application .  ",
      "P-tags": "linux c crash linux-kernel",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V S_INF without NP"
    },
    {
      "id": "ul_316397",
      "task": "Is there a way to provide \"overrides\" to a terminfo entry?",
      "P-task": "way provid overrid terminfo entri",
      "F_verb": "provide",
      "P-body": "You appear to have mentioned all of the possibilities. But you did not mention which terminal configuration you are using. The mention of a control sequence .  gives a hint. .  The issue with regard to the (not new: more than 20 years old) behavior of the initialization string is almost all from PuTTY users. In spite of its using \"xterm\" for the \"TERM\" setting, PuTTY is not xterm. In contrast to xterm (which makes the corresponding menu item off by default), PuTTY enables it by default (and makes the option available only by choosing whether to allow any resizing). .  Further reading: .   Why not just use TERM set to \"xterm\"? (ncurses FAQ) Why not make \"xterm\" equated to \"xterm-256color\"? VTTEST \u2013 Examples of VT100/non-VT100 wrapping: PuTTY (pterm)  Debian provides more bug reports related to PuTTY than Red Hat: .   Debian #435715 - Remove window resize from 'putty' Debian #515672 - ncurses-base: Please move 'putty' from ncurses-term to ncurses-base Debian #783808 - Please add a new terminal type: xterm-256color-utf8  The point of all of this is that terminal descriptions (like other things that are used frequently) do not change often when there is a well-established way in which they are used. PuTTY's terminal description differs from xterm's in other ways because it does not implement certain features (such as line-wrapping) consistently with xterm. .  Further reading (aside from the ncurse FAQ regarding \"TERM\" vs \"xterm\"): .   What versions are available? (xterm FAQ) Comparing versions, by counting controls (xterm FAQ)  ",
      "P-tags": "terminfo ncurs",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1064972",
      "task": "While launching samba I get an Error",
      "P-task": "launch samba get error",
      "F_verb": "get",
      "P-body": "Open a terminal and run this command: .  Then run this command to start the application: .  Edit: To have it launch from the menu: .  ** Create a new file at: /usr/share/polkit-1/actions/com.ubuntu.pkexec.samba.policy .  Add this to it: .  ** Edit the launcher at /usr/share/applications/system-config-samba.desktop .  Find this line: Exec=gksu system-config-samba .  Replace with this line: Exec=pkexec system-config-samba .  Note: This seems overkill for something that: .  (1) WIll likely be used once or twice in a year. .  (2) Will eventually be removed from the repository: https://bugs.launchpad.net/ubuntu/+source/system-config-samba/+bug/1740419 .  ",
      "P-tags": "gksu system samba",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_52777484",
      "task": "cd to a directory doesn't work but ls does - why is this happening?",
      "P-task": "cd directori work ls - happen",
      "F_verb": "happen",
      "P-body": "I discovered why this was happening; perhaps it can help others who experience the same problem. .  It turns out that fish was mounted onto my drive, so instead of typing .  I have to type .  UPDATE (27th March 2019): .  I found some documentation that highlights this in more detail. .  ",
      "P-tags": "cygwin shell",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V"
    },
    {
      "id": "so_66608543",
      "task": "Docker-compose - no space left on device",
      "P-task": "docker-compos - space left devic",
      "F_verb": "compose",
      "P-body": "Increase your disk size for docker. Check your status with \"docker system df\" Also you can clean your volumes with prune \"docker system prune --volumes\" .  ",
      "P-tags": "amazon-ec2 docker-compos linux docker amazon-web-servic",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1162084",
      "task": "How to treat an output of find as a string not a refrence to a file or directory",
      "P-task": "treat output find string refrenc file directori",
      "F_verb": "treat",
      "P-body": "Removing the path is better done using \"find\"'s \"-printf\" option: .   %P File's name with the name of the starting-point under which it was found removed. .    To fix your \"sed\" version, do not use \"xargs\", just pipe directly to \"sed\" like @choroba commented alrady. .  ",
      "P-tags": "pipe find sed bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP as NP to NP"
    },
    {
      "id": "ul_7691",
      "task": "Removing broken packages",
      "P-task": "remov broken packag",
      "F_verb": "remove",
      "P-body": "\"phpmyadmin\" depends on \"dbconfig-common\", which contains \"/usr/share/dbconfig-common/dpkg/prerm.mysql\". It looks like you've managed to uninstall \"dbconfig-common\" without uninstalling \"phpmyadmin\", which shouldn't have happened (did you try to \"--force\" something?). .  My advice is to first try \"aptitude reinstall dbconfig-common\". If it works, you should have a system in a consistent state from which you can try \"aptitude purge phpmyadmin\" again. .  Another thing you can do is comment out the offending line in \"/var/lib/dpkg/info/phpmyadmin.prerm\". This is likely to make you able to uninstall \"phpmyadmin\". I suspect you did what that line is supposed to do when you edited those mysql tables manually, but I don't know \"phpmyadmin\" or database admin in general, so I'm only guessing. .  The difference between \"remove\" and \"purge\" is that \"remove\" just removes the program and its data files (the stuff you could re-download), while \"purge\" first does what \"remove\" does then also removes configuration files (the stuff you might have edited locally). If \"remove\" fails, so will \"purge\". .  ",
      "P-tags": "aptitud package-manag debian",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_24691387",
      "task": "How to echo a statement based on the result of the previous echo",
      "P-task": "echo statement base result previou echo",
      "F_verb": "echo",
      "P-body": "Can't you use if statement on the result of pipes, to check the output is empty or not? .  In this way you capture the output of \"a | b | c | d\" into a string and check if it's empty or not, if not then you can continue with your next command e (or actually \"echo e\") .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP on NP of NP"
    },
    {
      "id": "so_56066184",
      "task": "Need to run two actions inside a scheduled task. Need one to run after the first finishes",
      "P-task": "need run two action insid schedul task\nneed one run first finish",
      "F_verb": "run",
      "P-body": "If it's an existing item that you're waiting on a change for and your roughly know how long the \"ghost\" usually takes, a simple solution would be to just build a control in the PowerShell-script that will be run afterwards, to wait for a new LastWriteTime on the image. In the below example, when the $temp.LastWriteTime matches the current month, day, year and hour, the script will continue. .  See the below example: .  Another alternative would be to create a temp-file that's generated after the first task has been completed and just use a do/until loop until the statement is true. .  ",
      "P-tags": "powershel scheduled-task",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_18603888",
      "task": "Udev rule doesn't run",
      "P-task": "udev rule run",
      "F_verb": "run",
      "P-body": "Not sure what changed, but the rule is now being used in the file /etc/udev/rules.d/81-pantech.rules .  One possibility is the missing /run/udev/rules.d/ directory. When I ran .  I got a line reporting that the directory was missing. .  Another possibility is me manually running the udev daemon with .  ",
      "P-tags": "angstrom-linux beagleboard udev",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_10093505",
      "task": "How can I get the name of a file in a directory on unix based on grep, sed, or awk in unix or linux?",
      "P-task": "get name file directori unix base grep sed awk unix linux",
      "F_verb": "get",
      "P-body": "You can simplify your script a little bit and get the desired result: .  ",
      "P-tags": "awk grep unix linux sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP on NP on NP in NP"
    },
    {
      "id": "so_53173933",
      "task": "Combine multiple log files to archive using PoSh and 7zip",
      "P-task": "combin multipl log file archiv use posh 7zip",
      "F_verb": "combine",
      "P-body": "this line \"$Args = a -mx9 $archive $log\" likely needs to have the right side value wrapped in double quotes OR each non-variable wrapped in quotes with a comma between each so that you get an array of args.  .  another method would be to declare an array of args explicitly. something like this ...  .   i also recommend you NOT use an automatic $Var name. take a look at \"Get-Help about_Automatic_Variables\" and you will see that \"$Args\" is one of those. you are strongly recommended NOT to use any of them for anything other than reading. writing to them is iffy. [grin]  .  ",
      "P-tags": "archiv powershel log 7zip",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP using NP"
    },
    {
      "id": "au_909955",
      "task": "GRUB won't boot persistent - \"hd0,4 not found\"",
      "P-task": "grub boot persist - hd0 4 found",
      "F_verb": "find",
      "P-body": "Trying to find a general bugfix Normally the computer will identify the boot drive as \"hd0\", but this is not the case in your computer. I will try to find a way to get around that problem. I tested with Lubuntu 17.04 in my Toshiba laptop in UEFI mode, and could not reproduce the bug. So I will need your help to test whatever bugfix I can find. .  Edit: I have modified the shellscript \"dus-persistent\" of mkusb and uploaded the new version 12.1.1 to the unstable PPA. The main improvements address a change in the boot structure of Ubuntu 17.04 and the fact that your computer does not boot from hd0. The main difference is how to identify partition #4 with the image from the iso file (the iso9660 file system), .  and it is done automatically by mkusb-dus. Please test if it solves the problem! You get the new version according to this link, .  help.ubuntu.com/community/mkusb/gui#from_the_unstable_PPA .  The unstable version is still developed and debugged. It is available from \"ppa:mkusb/unstable\" via the following command lines, .  Workaround - bugfix in your case Thanks for the feedback (that you edited into the original question). It makes it easier to help. .   \"I tried editing the grub commands (\"e\") and changing \"hd0\" to \"hd2\". That works! The persistent flash drive boots as expected. Wonder why grub doesn't just set root to the disk it was loaded from ...?)\" .   I would suggest editing the \"grub.cfg\" file in partition #3 of the 'USB drive to be persistent' (the 'usbboot' partition). This should make the bugfix persistent in your USB flash drive. But it would not work in other computers, that behave like my computers. .  \"grub.cfg\" has the following content, where you modify \"hd0,4\" to \"hd2,4\". You might also modify \"hd0,3\" to \"hd2,3\", but Memtest86+ will not work in UEFI mode anyway.) .  In your case you can expect 'Ubuntu' instead of 'Lubuntu', but otherwise it would look the same. .  Alternative An alternative is to copy the menuentries of \"grub.cfg\" and modify one of them to have two alternatives to make the USB flash drive boot easily in different computers. .  ",
      "P-tags": "persist mkusb uefi live-usb grub2",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_24016774",
      "task": "powershell - get file, parse it and if \"value=\" < X then function sendMail",
      "P-task": "powershel - get file pars valu x function sendmail",
      "F_verb": "get",
      "P-body": "Here's another possibility (I think it requires Powershell 4 because of Send-Mailmessage, but I could be wrong): .  Along about line 8 we setup some stuff for sending email. Starting at line 15, we build a hash table mapping printer IPs/Ports with Printer Names (since printer queues aren't always listed in DNS, I decided to use a hash table instead). On line 23, we use a regular expression to grab the ip and port, and the toner value by using the \"-match\" operator. Stuff grabbed by the regex is stored in an array called \"$Matches\". .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_25650337",
      "task": "JavaScript/PowerShell: Compare Two files and Save Results to a Text File",
      "P-task": "javascript powershel : compar two file save result text file",
      "F_verb": "compare",
      "P-body": "\"Results\" needs to be concatenated to \"CommandPS\" in the third snippet. It should look like this: .  ",
      "P-tags": "powershel javascript",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "au_524177",
      "task": "New keyboard layout does not refresh unless renamed",
      "P-task": "new keyboard layout refresh unless renam",
      "F_verb": "refresh",
      "P-body": "Keyboard layouts are compiled and cached; the cache is cleaned on reboot (I think \u2014 but I am not sure at all). What I normally do is to manually delete the cache files, which are the files that ends in \".xkm\" in \"/var/lib/xkb/\".  .  (as root, or add the appropriate \"sudo\"). .  (Data form my blog post on modifying layouts). .  ",
      "P-tags": "keyboard-layout xkb xorg",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V unless S"
    },
    {
      "id": "ul_274656",
      "task": "How to manually add startup applications on Mint 17.3",
      "P-task": "manual add startup applic mint 17 3",
      "F_verb": "add",
      "P-body": "I found it at: .  ",
      "P-tags": "startup linux linux-mint",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_41321092",
      "task": "how to truncate on glob files through sudo?",
      "P-task": "truncat glob file sudo",
      "F_verb": "truncate",
      "P-body": "The globs are evaluated in the shell of the current user, before the elevated permissions of \"sudo\" are in effect (before the actual execution of \"sudo\"). The current user probably doesn't have permission to access the affected paths. .  You can run it in a \"sh\" shell, that way the globs will be evaluated inside \"sudo\"'s shell: .  ",
      "P-tags": "sudo bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V on NP through NP"
    },
    {
      "id": "so_37064172",
      "task": "Replace Parent Process with Child Process After Death",
      "P-task": "replac parent process child process death",
      "F_verb": "replace",
      "P-body": "Normally the child you fork shouldn't be killed when it's parent is killed, unless you do something like: How to make child process die after parent exits? .  If the parent is killed, the children become a children of the init process. You probably saw on terminal that the process returns immediately after you send KILL to parent. That's because the sub-bash is waiting only on the parent's PID. But the child is actually running elsewhere. .  Here is a example to show it: .  Then within sleep period: .  So the child is actually still alive. .  --Edit-- .   Why when the parent is killed my program exits back to the shell?  Bash invokes the command also via folk/exec via something like this: .  Since from bash's point of view, the parent of your program is the child, it would return to prompt input when it returns from \"waitpid(childPid)\". .   Is there a way to stay within the program and continue functioning as it was but with a new parent?  It might be a bit difficult if you want to \"re-attach\", but it's not impossible: .  Attach to a processes output for viewing .  https://unix.stackexchange.com/questions/58550/how-to-view-the-output-of-a-running-process-in-another-bash-session .  Reference: .  http://www.cs.cornell.edu/Courses/cs414/2004su/homework/shell/shell.html .  ",
      "P-tags": "linux signal c",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP after NP"
    },
    {
      "id": "so_53706983",
      "task": "Splitting a large, complex one column file into several columns with awk",
      "P-task": "split larg complex one column file sever column awk",
      "F_verb": "split",
      "P-body": "With GNU awk for multi-char RS and true multi dimensional arrays: .  ",
      "P-tags": "awk field row bash",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP into NP with NP"
    },
    {
      "id": "so_33706881",
      "task": "how to get the next hour's date string in bash",
      "P-task": "get next hour date string bash",
      "F_verb": "get",
      "P-body": "Try this: .  Output: .  See: 3.5.3 Shell Parameter Expansion  .  ",
      "P-tags": "date bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_57581490",
      "task": "Compare two strings using Visual Studio Code?",
      "P-task": "compar two string use visual studio code",
      "F_verb": "compare",
      "P-body": "VSCode will only diff files, so save your buffers to files. .  ",
      "P-tags": "powershel visual-studio-cod",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP using NP"
    },
    {
      "id": "so_39111060",
      "task": "Combine file IO for -replace and Set-Content in PowerShell",
      "P-task": "combin file io -replac set-cont powershel",
      "F_verb": "set",
      "P-body": "Sure, just chain your replaces inside the \"ForEach-Object\" block: .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "au_997166",
      "task": "Unable to run TortoiseHg, broken libraries and missing dependencies",
      "P-task": "unabl run tortoisehg broken librari miss depend",
      "F_verb": "run",
      "P-body": "Recompiling doesn't seem to fix the problem up. For whatever reason it still uses Qt4 rather than Qt5. .  Luckily found the pre compiled binary. .  \"sudo apt-get install python-pyqt5.qsci\"  .  fixed the problem up. .  ",
      "P-tags": "apt pyqt package-manag mercuri qt",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_321160",
      "task": "Why am I being prompted for a sudo password when I specified \"NOPASSWD\" in my /etc/sudoers file?",
      "P-task": "prompt sudo password specifi nopasswd etc sudoer file",
      "F_verb": "specify",
      "P-body": "\"sudo\" resets your environment by default, so it won't search your \"$PATH\". So it might be trying to run a system-default version of \"ruby\" instead of the one listed. In particular the \"$PATH\" seen by \"sudo\" is given in your \"sudoers\" file: .  Try using \"sudo -E\" to preserve your environment or use the fully-qualified pathname for \"ruby\", or add the paths to \"secure_path\", before the ones given. .  ",
      "P-tags": "password ubuntu sudo",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "au_114643",
      "task": "Is there a way to learn which files in the installed system are changed/updated during a kernel update?",
      "P-task": "way learn file instal system chang updat kernel updat",
      "F_verb": "learn",
      "P-body": "The kernel is made up of two main packages the linux-image-* and linux-headers-* packages. A kernel is made up of the pair at the same version. You can see all of your installed kernel with the command below, the latest kernel has the largest version number: .  To see the pair associated with the current running kernel use the command below: .  The files which make up a kernel package (or indeed any package) are listed using the \"dpkg -L\" command, something similar to the following: .  Of course there are a few other files which get updated which are not contained within these packages, for example the \"initramfs\" for each kernel is generated after installation and the bootloader (typically grub) configuration is rebuilt to contain the new kernel. .  ",
      "P-tags": "kernel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V which S during NP"
    },
    {
      "id": "au_424161",
      "task": "how to install both qt5-qmake and qt4-qmake",
      "P-task": "instal qt5-qmake qt4-qmake",
      "F_verb": "install",
      "P-body": "I could not find a reliable way though some say that qtchooser works but it doesn't work. What I do as a workaround is to install \"qt4\" at first then install qt5, to revert back to qt4 just remove \"qt5-default\", it will use qt4. To switch back to \"qt5\" just install \"qt5-default\". It's a tiny deb package lower than 500kb. .  EDIT: When you attepted to remove qt5-default it will automatically install qt4-default .  EDIT2: What I did yesterday to use latest version of qmake, I downloaded 32 bit offline installer from http://download.qt-project.org/official_releases/qt/5.2/5.2.1/qt-opensource-linux-x86-5.2.1.run then set executable flag and installed it to \"/home/$USER/Qt5.2.1\", it doesn't install it into system path. To use qmake to create makefile you need to specify the path\"/home/$USER/Qt5.2.1/5.2.1/gcc/bin/qmake -Wall ../project.pro\" worked for me .  EDIT3: I found an easier way to switch between qt4 and qt5 using environment variables .  To switch to qt4 .  EDIT4: .  As I get experienced about programming I come across more simple solutions. .  You don't need to switch between QT4 <-> QT5 at all. .  Install QT4 and QT5 packages from Ubuntu repositories and then locate qmake  .  I am running Ubuntu 14.04.3 32 bit so my qmake paths are: .  All you can do to build your project is to run  .  for qt4: .  or for qt5: .  in your source directory where project*.pro file exist. .  Then to compile it with \"make\" command. .  ",
      "P-tags": "ppa qt",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_547716",
      "task": "Don't understand my mounted partitions",
      "P-task": "understand mount partit",
      "F_verb": "mount",
      "P-body": "udisks2 is likely the utility which is auto-mounting your removable storage devices. There's Ubuntu documentation about how it works, and how to disable it if you'd like. .  As for the mounted filesystems, in short, that's how linux works. Here's an overview of the filesystems you have mounted: .   \"/dev\" - This is a pseudo-filesystem which presents device files. \"/run\" - This is an in-memory (RAM) filesystem used for temporary files used during runtime. \"/\" - This is your root filesystem. \"/snap/*\" - These are filesystem image files being mounted via loop devices, which in your case are being used to mount filesystems containing various Snap programs. \"/run/cgmanager\" - cgmanager is used to manage Linux cgroups (control groups), typically for containers.  While it may be possible to remove some of those filesystems, unless you know precisely what you are doing, I recommend leaving them as-is. Otherwise you may accidently cause some of your programs to stop working. .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_3216195",
      "task": "Simplest way to get an interactive console for my app",
      "P-task": "simplest way get interact consol app",
      "F_verb": "get",
      "P-body": "You could use the \"ConsoleShell\" of PowerShell. Something like: .  This would start PowerShell within your process, and you could access your variables, add cmdlets that interact with your app etc'. The ConsoleShell gives you the input/output mechanism, including tab completion and other features of the command line interface. .  ",
      "P-tags": "net-4 0 user-interact net console-appl powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP"
    },
    {
      "id": "so_36666463",
      "task": "Why System.Windows.Forms.Control MousePosition property can be read, but Location not?",
      "P-task": "system window form control mouseposit properti read locat",
      "F_verb": "read",
      "P-body": " The purpose of this code is to get the dimensions and position in pixels of the cmd.exe window in which the PowerShell script run. What is the right way to get these values in PowerShell? .   If so, \"System.Windows.Forms.Control\" is not what you want - the console host is not a Windows Forms control. .  You can get these values from the Win32 API (\"user32.dll\") with the \"GetWindowRect\" function: .  The \"$WindowRect\" variable now has the location coordinates of the Window: .  ",
      "P-tags": "powershel net winform",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "so_33936074",
      "task": "Decode PowerShell output possibly containing non-ASCII Unicode characters into a Python string",
      "P-task": "decod powershel output possibl contain non-ascii unicod charact python string",
      "F_verb": "decode",
      "P-body": "The output character encoding may depend on specific commands e.g.: .  Output \u270c (U+270C) character is received successfully. .  The character encoding of the child script is set using \"PYTHONIOENCODING\" envvar inside the PowerShell session. I've chosen \"utf-32\" for the output encoding so that it would be different from Windows ANSI and OEM code pages for the demonstration. .  Notice that the stdout encoding of the parent Python script is OEM code page (\"cp437\" in this case) -- the script is run from the Windows console. If you redirect the output of the parent Python script to a file/pipe then ANSI code page (e.g., \"cp1252\") is used by default in Python 3. .  To decode powershell output that might contain characters undecodable in the current OEM code page, you could set \"[Console]::OutputEncoding\" temporarily (inspired by @eryksun's comments):  .  Output Both \"fl\" and \"tee\" use \"[Console]::OutputEncoding\" for stdout (the default behavior is as if \"| Write-Output\" is appended to the pipelines). \"tee\" uses utf-16, to save a text to a file. The output shows that \u270c (U+270C) is decoded successfully. .  \"$OutputEncoding\" is used to decode bytes in the middle of a pipeline: .  Output that is correct: \"b'\\xf0\\x9f\\x98\\x8a'.decode('utf-8') == u'\\U0001f60a'\". With the default \"$OutputEncoding\" (ascii) we would get \"b'????\\r\\n'\" instead. .  Note:  .   \"b'\\n'\" is replaced with \"b'\\r\\n'\" despite using binary API such as \"os.read/os.write\" (\"msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)\" has no effect here) \"b'\\r\\n'\" is appended if there is no newline in the output: .  Output: .  The newline is appended to the piped output. .   If we ignore lone surrogates then setting \"UTF8Encoding\" allows to pass via pipes all Unicode characters including non-BMP characters. Text mode could be used in Python if \"$env:PYTHONIOENCODING = \"utf-8:ignore\"\" is configured. .   In interactive powershell running \"Get-NetAdapter | select Name | fl\" displayed correctly the name even its non-cp437 character.  .   If stdout is not redirected then Unicode API is used, to print characters to the console -- any [BMP] Unicode character can be displayed if the console (TrueType) font supports it. .   When I called powershell from python non-ascii characters were converted to closest ascii characters (e.g. \u0101 to a, \u017e to z) and .decode(ascii) worked nicely.  .   It might be due to \"System.Text.InternalDecoderBestFitFallback\" set for \"[Console]::OutputEncoding\" -- if a Unicode character can't be encoded in a given encoding then it is passed to the fallback (either a best fit char or \"'?'\" is used instead of the original character). .   Could this behavior (and correspondingly solution) be Windows version dependent? I am on Windows 10, but users could be on older Windows down to Windows 7. .   If we ignore bugs in cp65001 and a list of new encodings that are supported in later versions then the behavior should be the same. .  ",
      "P-tags": "python-3 x unicod subprocess powershel window",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP into NP"
    },
    {
      "id": "su_443982",
      "task": "How can I show the current year in Ubuntu's Clock-indicator/applet?",
      "P-task": "show current year ubuntu clock-ind applet",
      "F_verb": "show",
      "P-body": "With due respect to the answer helping me figure out, let's customize the indicator-datetime. .  That would give an output of \"Mon, 02, Jul 21:00 2012\".  .  You can customize the format as long as they are understood by \"strftime\". For other formats, you can consult the manpage for the \"strftime\" command  and customize accordingly.  .  ",
      "P-tags": "ubuntu clock",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_15238083",
      "task": "sending a file over serial port",
      "P-task": "send file serial port",
      "F_verb": "send",
      "P-body": "Let's start with the obvious. .  a : \"Sendfile\" doesn't have any looping construct in it... .  b: buffer overruns, like this: .  c: You have debug like this 'read 1 bytes, value is A' but it's not in the code. Difficult to fix code you haven't posted... .  ",
      "P-tags": "linux c serial-port file-io",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP over NP"
    },
    {
      "id": "so_41146032",
      "task": "SH File not setting ENV variables (Mac OS X)",
      "P-task": "sh file set env variabl mac os x",
      "F_verb": "set",
      "P-body": "Use \"source\" command instead: .  The command executes the script in the current shell context as opposed to invocation via separate shell process: \"sh set_env.sh\" (the environment variables are set within the new \"sh\" process which is isolated from the current process). .   By the way, you can use dot (\".\") instead of \"source\", if you prefer. .  ",
      "P-tags": "termin sh maco bin",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_50817367",
      "task": "RegEx for finding similar strings in PowerShell",
      "P-task": "regex find similar string powershel",
      "F_verb": "find",
      "P-body": "Here is one way to find matching users: .  You can access the actual user object again like this: .  ",
      "P-tags": "powershel regex",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "su_808748",
      "task": "How to create a local server to compile and run programs in C, Java,..etc",
      "P-task": "creat local server compil run program c java etc",
      "F_verb": "create",
      "P-body": "This site is a good starting point: Installing Ubuntu 11.04 Server Natty Narwhal .  After installation of the server you will need to prepare your system for building packages:  .  In the next steps you will surely want to install LAMP and run your own Web Server. You can access your system and start the build from the tablet as well through SSH(SecureShell). .  I've made a good experiences with openSUSE Build Service (if you are not depend on Ubuntu). .  ",
      "P-tags": "webserv compil java c ubuntu-serv",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP to NP"
    },
    {
      "id": "so_12620375",
      "task": "How to return several items from a Powershell function",
      "P-task": "return sever item powershel function",
      "F_verb": "return",
      "P-body": "You can return an array of \"[string]\" and then let the caller split it or return a custom object and always the caller do the split.  .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_68028572",
      "task": "child process seems to get stuck in sleep in a while loop",
      "P-task": "child process seem get stuck sleep loop",
      "F_verb": "get",
      "P-body": " The problem is that the child process seems to get stuck in the sleep while loop, even when the parent process has set the status to 'K' (checked in the file that is memory mapped). .   There are several odd things about your program, with one of them being that you are using shared memory for this task at all. See below for a better approach. .  Issues with the current approach As to the question as it stands, however, you have a synchronization problem. The contents of the mapped memory are being changed outside the scope of the child process, but you've given it no reason to suspect that that might be the case. The compiler can therefore assume that if the wait loop condition is satisfied when it is first evaluated, then it will be satisfied on every subsequent evaluation, too. .  For a more complicated interaction, you might need to set up a process-shared mutex or similar to guard access to the shared memory, but for this, it would probably be sufficient to declare \"child_file\" as a pointer to \"volatile\" \"char\". .  A better approach You want the child to wait for a one- or maybe two-byte instruction from the parent. You presently do this by polling the contents of a shared memory segment, but that's complex to set up and use, as you discovered. It would be a lot easier to use a pipe to convey the needed information from parent to child: .   setup: Declare an array. Call \"pipe()\". child use: The child performs a blocking \"read()\" on the pipe. parent use: \"write()\" the message to the pipe when ready, then close it. Or just close it.  Note that the pipe itself then provides adequate synchronization, and that there is no need for a wait loop. Note also that the child can detect the case that the parent dies without sending any message, which your shared memory approach does not support. .  ",
      "P-tags": "linux memory-mapped-fil fork c sleep",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_31133840",
      "task": "Shell comparing files",
      "P-task": "shell compar file",
      "F_verb": "compare",
      "P-body": "If I understood correctly, you want the first two fields compared and if they differ the line should be printed: .  The first file \"file.txt\" is read in an array. And when the second file is processed the array contents are compared. .  ",
      "P-tags": "diff command-lin shell text-process",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "au_682170",
      "task": "Why doesn't Libre Office Writer 5 correctly check spelling?",
      "P-task": "libr offic writer 5 correctli check spell",
      "F_verb": "check",
      "P-body": "First, select an installed language for Default Languages for Documents. Installed languages have an little icon in front of the name as you can see in my screenshot. .   .   Second, install your missing language English (UK) via .  or via the Language Support .   Install via .   Open Language Support and all missing libraries will be installed automatically .   ",
      "P-tags": "spell-check libreoffic",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_20110986",
      "task": "Passing a parameter to a function",
      "P-task": "pass paramet function",
      "F_verb": "pass",
      "P-body": "Powershell won't expand variables in single quoted strings, so you have to use a double quoted string: .  Though \"$args\" is an array of all arguments, so it may be more robust if you just specify a parameter:  .  ",
      "P-tags": "powershel user-defined-funct powershell-3 0",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_15368656",
      "task": "grails run-app > can't see terminal input",
      "P-task": "grail run-app see termin input",
      "F_verb": "see",
      "P-body": "\"grails --plain-output run-app\" should disable the use of ANSI colour codes, which might help, depending on which terminal program you're using. .  ",
      "P-tags": "ubuntu-12 04 grail termin consol",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "au_216726",
      "task": "What is the application that displays notifications in Lubuntu 12.04 and how to remove it?",
      "P-task": "applic display notif lubuntu 12 04 remov",
      "F_verb": "remove",
      "P-body": "I'm pretty sure that whether notifications are sent to the notifier daemon is on a program by program basis, and you would have to change that in your browser's settings (if possible). I am not 100% sure on this though. At any rate, to just remove notifications altogether: .  You can also replace Lubuntu's notification system with XFCE's, which won't queue up your notifications, like the default one does. To do that: .  When doing it this way, it shouldn't ask to remove all those extra packages, as there will still be a notification system in place. I think it will still say it is uninstalling lubuntu-desktop, but that is because it is a meta package, meaning a package of packages. It won't remove your desktop. :-) .  To change the settings for XFCE's notification system (timeouts, position, color), run this: .  ",
      "P-tags": "uninstal 12 04 notif lubuntu",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_52013195",
      "task": "Linux script to create new directory with name as datestamp",
      "P-task": "linux script creat new directori name datestamp",
      "F_verb": "create",
      "P-body": "The destination of \"cp\" is the second argument to the command. You're using the date as the name of a file to redirect the output, but \"cp\" doesn't produce any output. .  You need to execute the \"mkdir\" command to create the directory, and then use that as the destination of the \"cp\" command.  .  ",
      "P-tags": "linux ubuntu syntax",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP as NP"
    },
    {
      "id": "au_703101",
      "task": "Why does (package) nslcd recommend nscd?",
      "P-task": "packag nslcd recommend nscd",
      "F_verb": "recommend",
      "P-body": "\"nscd\" and \"nslcd\" are not the same and also not similar, read the man pages. \"nscd\" isn't neccessary but recommended by the package maintainers and for this reason \"nslcd\" recommends \"nscd\". .   From \"man nscd\" .  From \"man nslcd\" .   Perhaps you have read another description. My description says: .  nscd .   Name Service Cache Daemon .   nslcd .   daemon for NSS and PAM lookups using LDAP .   ",
      "P-tags": "package-manag ldap",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_54755245",
      "task": "Powershell regex match sequence doesn't work although it matches in Sublime Text find and replace",
      "P-task": "powershel regex match sequenc work although match sublim text find replac",
      "F_verb": "match",
      "P-body": "The simplest - and faster - approach is to read the input file as a single, multiline string with \"Get-Content -Raw\" and let the regex passed to \"-replace\" operate across multiple lines: .   \"(?s)\" activates in-line option \"s\" which makes \".\" match newline (\"\\n\") characters too. .  \"^.+?\\n(?==)\" matches from the start of the string (\"^\") any number of characters (including newlines) (\".+\"), non-greedily (\"?\") .  until a newline (\"\\n\") followed by a \"=\" is found. .   \"(?=...)\" is a look-ahead assertion, which matches \"=\" without consuming it, i.e., without considering it part of the substring that matched.   Since no replacement operand is passed to \"-replace\", the entire match is replace with the implied empty string, i.e., what was matched is effectively removed. .   As for what you tried: .  The \"-replace\" operator passes its LHS through if no match is found, so you cannot use it to filter out non-matching lines. .  Even if you match an undesired line in full and replace it with \"''\" (the empty string), it will show up as an empty line in the output when sent to \"Set-Content\" or \"Out-File\" (\">\"). .  As for your specific regex, \"^[^=]*.[+][\\n]\" (whether or not the first \"^\" is followed by an ESC (\"0x1b\") char.): .   \"[\\n]\" (just \"\\n\" would suffice) tries to match a newline char. after a literal \"+\" (\"[+]\"), yet lines read individually with \"Get-Content\" (without \"-Raw\") by definition are stripped of their trailing newline, so the \"\\n\" will never match; instead, use \"$\" to match the end of a line.   Instead of \"%\" (the built-in alias for the \"ForEach-Object\" cmdlet) you could have used \"?\" (the built-in alias for the \"Where-Object\" cmdlet) to perform the desired filtering: .  \"$_ -notmatch '^\\e['\" returns \"$True\" only for lines that don't start (\"^\") with an ESC character (\"\\e\", whose code point is \"0x1b\") followed by a literal (\"\\\") \"[\", thereby effectively filtering out the lines before the \"= Heading\" line. .  However, the multi-line \"-replace\" command at the top is a more direct and faster expression of your intent. .  ",
      "P-tags": "asciidoc sublimetext3 regex powershel git",
      "source": "qa",
      "cate": "match",
      "pat": "V in NP"
    },
    {
      "id": "so_61657856",
      "task": "Bash Terminal: Write only specific lines to logfile",
      "P-task": "bash termin : write specif line logfil",
      "F_verb": "write",
      "P-body": "If you want to save into \"logfile\" only the output containing \"mypattern\" but you want the see all the output at the terminal, you could issue: .  I also assumed that the output of \"cmd\" may be directed to the standard output stream as well as to the standard error stream, by adding \"2>&1\" after \"cmd\". .  ",
      "P-tags": "logfil bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP"
    },
    {
      "id": "su_1170136",
      "task": "Translating MIDI input into computer keystrokes on Linux?",
      "P-task": "translat midi input comput keystrok linux",
      "F_verb": "translate",
      "P-body": "This cannot be done without some programming. .  First, test how to detect MIDI events. Go to a terminal, and run \"aseqdump -l\" to list the MIDI ports; this outputs something like this: .  Then run it with the client name to check whether events arrive: .  Second, to simulate key strokes, you need \"xdotool\". If you do not yet have it installed, run \"sudo apt-get install xdotool\". You can use \"type\" to type text, or \"key\" to simulate special keys: .  Please note that not all special keys are handled correctly by \"xdotool\". And Ctrl+Alt+Del is handled very specially by the kernel and probably does not work when simulated; try running \"sudo reset\" instead of \"xdotool\". .  Finally, tie everything together with a script. Put this into a text file, for example, \"~/bin/midi-to-keys\": .  Make it executable (\"chmod +x ~/bin/midi-to-keys\"), and run it (\"~/bin/midi-to-keys\"). Now, pressing E-5 or C-4 should have some effect. .  Change or add lines of the form \"\"Note on x\" ) command ;;\" to do whatever you want. .  ",
      "P-tags": "keyboard-shortcut midi linux ubuntu keyboard",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP on NP"
    },
    {
      "id": "so_68347127",
      "task": "Why my CGI Script can't access to ttyUSB0?",
      "P-task": "cgi script access ttyusb0",
      "F_verb": "access",
      "P-body": "The command below solved my problem : .  ",
      "P-tags": "serial-port linux cgi raspberry-pi apach",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V to NP"
    },
    {
      "id": "so_28821794",
      "task": "How can I use the '>' redirector operator when running an external command?",
      "P-task": "use redirector oper run extern command",
      "F_verb": "use",
      "P-body": "In the example you pasted the command interpreter is parsing your command and outputting STDOUT to a text file. In the one you pasted you're passing params that Execute-Process doesn't know how to handle. Instead try this: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "so_39091516",
      "task": "How do i pipe a long string to via child_process.spawn() in Node.js?",
      "P-task": "pipe long string via child_process spawn node js",
      "F_verb": "spawn",
      "P-body": "pdftotext should allow reading from stdin and writing to stdout (at least it worked for me with v0.41.0), so you could do this instead: .  Or possibly better yet, you might be able to stream the file to the child process instead of buffering its entire contents in memory first: .  ",
      "P-tags": "child-process pdftotext bash node js amazon-s3",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V in NP"
    },
    {
      "id": "so_50872115",
      "task": "How to apply filters in get builds list VSTS REST API?",
      "P-task": "appli filter get build list vst rest api",
      "F_verb": "apply",
      "P-body": "Based on your comments the solution is the following: .   Use the 2.0 version of the API Do not use quotes around tag(s)  URL: \"https://tfs.*****.com/STS/FORIS_Mobile/_apis/build/builds?api-version=2.0&statusFilter=completed&tagFilters=Rejected&definitions=6331&resultFilter=succeeded&maxBuildsPerDefinition=1&queryOrder=finishTimeDescending\" .  And the code to generate it: .  ",
      "P-tags": "azure-devops-rest-api powershel azure-devop",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_49895088",
      "task": "Searching for several Operating Systems with Get-ADComputer using LDAP Filter",
      "P-task": "search sever oper system get-adcomput use ldap filter",
      "F_verb": "get",
      "P-body": "The way you have defined \"$computersFilter\", if you look at it's type you will notice that it is of type \"string\". And hence it doesn't return anything.  .  \"$computersFilter\" should be declared as an array, so that the \"-LDAPFilter\" parameter is evaluated against the collection of object, like this -  .  ",
      "P-tags": "powershel active-directori script",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP using NP"
    },
    {
      "id": "so_20003492",
      "task": "Specify a non-standard temporary directory for open() method in Ubuntu",
      "P-task": "specifi non-standard temporari directori open method ubuntu",
      "F_verb": "specify",
      "P-body": "Looking at the \"OpenURI\" source code we can see that it uses \"Tempfile\": .  \"Tempfile\" in order to choose the temporary directory uses \"Dir.tmpdir\", which in turn uses the system temporary directory or a directory specified by the environment variable \"TMPDIR\" (between others). So we can write something like this: .  In a single command (please ensure that \"$HOME/.tmp\"does not exist and is not used): .  It should print something like .  P.S. I'm using Ruby 2.1.0 preview, so maybe you have to look at \"#{ruby directory}/lib/ruby/2.0.0/open-uri.rb\" source in order to understand how \"OpenURI\" manages the temporary file (but it should be very similar) .  ",
      "P-tags": "rubi ubuntu",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_15890897",
      "task": "How to manually cause an interrupt?",
      "P-task": "manual caus interrupt",
      "F_verb": "cause",
      "P-body": "This is to close my question. There is no way to manually issue an interrupt. If using android's virtual machine, there're a limited set of interrupts and signals that can be invoked virtually using console command. This console could be open by \"telnet localhost 5554\" to the virtual machine. .  ",
      "P-tags": "linux c linux-kernel",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_637696",
      "task": "set -n not working in shell script when executing with source",
      "P-task": "set -n work shell script execut sourc",
      "F_verb": "execute",
      "P-body": "Quoting the docs on the behaviour of an interactive shell: .    The \"-n\" invocation option is ignored, and \u2018\"set -n\"\u2019 has no effect (see The Set Builtin).   Since you sourced the script from an interactive shell, \"set -n\" is ignored. .  ",
      "P-tags": "script sourc command-lin bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V with NP"
    },
    {
      "id": "so_25609228",
      "task": "compare time between two sequential log entries",
      "P-task": "compar time two sequenti log entri",
      "F_verb": "compare",
      "P-body": "Let's play a bit with dates: .  Explanation  \"while read -r dat hour rest\" reads every line in three blocks: first one contains the date, second one the hour and the last one the rest of the content. \"${dat//.//}\" converts dots into slashes (\".\" --> \"/\") in the date field so that \"date\" will interpret it properly. \"secs=$(date -d\"${dat//.//} $hour\" \"+%s\")\" converts the date into seconds since 1 January 1970. This way we will be able to compare each other. \"[ $((secs - prev)) -ge 60 ] && echo \"$dat $hour $rest\"\" compare current seconds with previous one. If the difference is \"g\"reater or \"e\"qual than 60, output the entire line. \"prev=$secs\" store the current seconds for next loop. \"while read; do ... done < file > output\" reads from \"file\" and outputs into \"output\" file.  To debug: .  Returns: .  ",
      "P-tags": "date bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP between NP"
    },
    {
      "id": "au_349631",
      "task": "Why is my ssh connection dropping immediately after I enter my password?",
      "P-task": "ssh connect drop immedi enter password",
      "F_verb": "enter",
      "P-body": "There is a \"exit 0\" in your \".bash_profile\" file that provokes bash to exit. Remove it as it's not necessary: .  ",
      "P-tags": "ssh",
      "source": "qa",
      "cate": "enter",
      "pat": "V NP"
    },
    {
      "id": "au_978233",
      "task": "do not compress just zip files in command line",
      "P-task": "compress zip file command line",
      "F_verb": "compress",
      "P-body": "This is what tarball archives are for. .  This creates an uncompressed archive. .  ",
      "P-tags": "zip tar",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_238331",
      "task": "Is there any command that read their standard input in special cases?",
      "P-task": "command read standard input special case",
      "F_verb": "read",
      "P-body": "There are a few cases that come to mind: .   missing arguments, the special argument \"-\", the program detects that the standard input is not a terminal, and an option (or environment variable) overrides the behavior.  For missing arguments, \"cat\" is a useful example. Likewise \"grep\", \"sed\". .  The special argument \"-\" is used in several programs to tell it explicitly to read from the standard input. You can find discussion (with examples) in these: .   What's the difference between STDIN and arguments passed to command? How to read stdin when no arguments are passed? Pipe, standard input and command line arguments in Bash  For the case where the standard input is not a terminal\u2014offhand, the cases I'm familiar with are less known: .   dialog checks on startup if its input is a terminal, and if not, opens the terminal device. This is part of a larger scheme where it can read data from a pipe, e.g., for the gauge widget. diffstat handles missing arguments by reading its input from the standard input, but in addition, its \"-v\" (verbose) option when doing this shows progress, e.g., a \".\" for each file piping to vi-like-emacs makes it read the input as a file. vim's comparable feature (implemented [later4), uses the explicit \"-\" argument.  For special arguments: .   dialog has an option \"--gauge\" which reads data from the standard input. Also \"--input-fd\" tells it which file descriptor to use as its input for pipes. lynx has an option \"-stdin\" telling it to interpret the standard input as html. Otherwise, it accepts configuration options on the standard input, e.g., using \"-get_data\" or \"-post_data\".  ",
      "P-tags": "input command-lin",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "so_50809438",
      "task": "Requiring unknown module \"499\" error in React Native",
      "P-task": "requir unknown modul 499 error react nativ",
      "F_verb": "require",
      "P-body": "At first, remove all the installed npm packages and install them again by running the following command: .  And then, start React-Native again by the following command: .  ",
      "P-tags": "android linux react-n reactj",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_5343558",
      "task": "Cannot get rsync exclude option to exclude dir",
      "P-task": "get rsync exclud option exclud dir",
      "F_verb": "get",
      "P-body": " This works. As \"test/a\" is the base directory synced from, the exclude pattern is specified by starting with \"a/\" .  Show us the real paths/excludes if this doesn't help. .  Running rsync with -vn will list dirs/files - the pattern is matched against the format that rsync prints. .  ",
      "P-tags": "script linux rsync unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_740253",
      "task": "How to install Grub in an external hard drive?",
      "P-task": "instal grub extern hard drive",
      "F_verb": "install",
      "P-body": "I eventually found the solution to my problem. I'll post it here in case someone may need it. Also, I'm not entirely sure what worked and if all the steps I took were really necessary, however this worked. .   Make sure you have an EFI partition on your external drive using gparted or something similar. The partition should be FAT32, have the boot and esp flags, and be mounted at /boot/efi. The size should be at least 200 Mb although I made it 1Gb since I hade space available on my HD. If you do not have this partition, then make it. Check that the UUID of the EFI BOOT partition on your external hard drive matches the one in the fstab file.  to check partitions' UUID just type in the terminal .  while to edit the fstab file .   Now install Grub. You can also try to copy grub from the internal drive to the external drive partition but it did not work for me). .  sudo grub-install /dev/sdX .   replace sdX with the actual drive. .   In case you haven't already done it, enable boot from USB drive and make sure external boot loader is loaded before the internal one from your UEFI setup menu. Now your machine should boot first from USB then (if no boot loader has been found) from the internal hard drive.  ",
      "P-tags": "boot grub2 usb",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_64010765",
      "task": "Show the ServerName for Get-WinEvent result in OutGridView?",
      "P-task": "show servernam get-winev result outgridview",
      "F_verb": "show",
      "P-body": "Capture the computer name taken from the HostName straight away in your first ForEach loop .  and use that in the Select-Object .  Then in the second Select-Object you can do .  or again .  ",
      "P-tags": "powershel active-directori",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_24106132",
      "task": "Move-Item not reading the path correctly",
      "P-task": "move-item read path correctli",
      "F_verb": "read",
      "P-body": "Your script passes relative paths to Move-Item and it defaults to the working directory. An easy solution is to pass absolute paths using \".FullName\" property: .  Also using \"foreach\" in conjunction with pipelines doesn't look very elegant because of all the parentheses. You can get rid of it: .  ",
      "P-tags": "powershel windows-server-2008-r2 powershell-2 0",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_43237542",
      "task": "Why doesn't \"where\" work as I would expect here to select certain results?",
      "P-task": "work would expect select certain result",
      "F_verb": "select",
      "P-body": "\"Where-Object\" requires either a scriptblock or a comparison statement (3.0+).  .  In your case, replacing the parenthesis with a curly brace would work: .  Or you could use a comparison statement: .  ",
      "P-tags": "powershel powershell-4 0",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP"
    },
    {
      "id": "so_35786393",
      "task": "How can I download using a bash script from a CSV file with URLs?",
      "P-task": "download use bash script csv file url",
      "F_verb": "download",
      "P-body": "You can simply use: .  ",
      "P-tags": "csv bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V using NP from NP with NP"
    },
    {
      "id": "su_634636",
      "task": "Update to Fedora 19 failed with curl 403 error",
      "P-task": "updat fedora 19 fail curl 403 error",
      "F_verb": "update",
      "P-body": "I ended up updating from an ISO file: .  More info here https://ask.fedoraproject.org/question/7030/upgrade-fedora-17-to-18-with-fedora-18-install-dvd/ .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V to NP with NP"
    },
    {
      "id": "so_58064606",
      "task": "How to get log in only **mylog**, instead of **mylog** and **syslog** using syslog-ng?",
      "P-task": "get log mylog instead mylog syslog use syslog-ng",
      "F_verb": "use",
      "P-body": "Starting from syslog-ng v3.15.1, you can use if-else, for example: .  syslog-ng v3.5 is really old, I'm not sure about its feature set, but: .   you can always create another filter negating \"f_local2\" or you can use the \"final\" flag to \"terminate\" a log path, for example:  ",
      "P-tags": "embedded-linux c syslog-ng",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_62472259",
      "task": "How to resolve curl: (6) Couldn't resolve host",
      "P-task": "resolv curl : 6 resolv host",
      "F_verb": "resolve",
      "P-body": "Why I think issue is single quote? Try replacing single quotes with double quotes  .  (reference: https://www.php.net/manual/en/language.types.string.php#language.types.string.syntax.double ) .  convert to: .  ",
      "P-tags": "curl bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "au_110423",
      "task": "Java command not found even after \"sudo apt-get install openjdk-6-jdk\"",
      "P-task": "java command found even sudo apt-get instal openjdk-6-jdk",
      "F_verb": "find",
      "P-body": "Solved this by manually setting java path with \"/etc/profile\". .  Add following lines to there. .  ",
      "P-tags": "java software-instal",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V after NP"
    },
    {
      "id": "so_56864122",
      "task": "Replace newline with comma and space to produce 1 line output",
      "P-task": "replac newlin comma space produc 1 line output",
      "F_verb": "produce",
      "P-body": "I believe that \"tr\" can only replace a character with another one and it can't be used to insert more characters. Try it with this .  or .  If you want to escape the last comma, then .  ",
      "P-tags": "tr cygwin linux",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_31301482",
      "task": "Shell/awk script to read a column of files and combining columns to make a TSV file",
      "P-task": "shell awk script read column file combin column make tsv file",
      "F_verb": "combine",
      "P-body": "You can use awk like this: .  ",
      "P-tags": "calculated-column shell",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_618286",
      "task": "How to append a string to shell's last executed list (which is accessing by Up-key)?",
      "P-task": "append string shell last execut list access up-key",
      "F_verb": "append",
      "P-body": "The technical name for what you call \"last executed list\" is \"history\". .  Usually, every command that your user executes is added to it. However, depending on your shell, you can edit the \"history\"-file and add your own lines. For \"bash\", this file is \"~/.bash_history\". .  ",
      "P-tags": "shell zsh",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP which S"
    },
    {
      "id": "so_1133698",
      "task": "Using find to locate files that match one of multiple patterns",
      "P-task": "use find locat file match one multipl pattern",
      "F_verb": "find",
      "P-body": "Use \"-o\", which means \"or\": .   You'd need to build that command line programmatically, which isn't that easy. .  Are you using bash (or Cygwin on Windows)? If you are, you should be able to do this: .  which might be easier to build programmatically. .  ",
      "P-tags": "find shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP that S"
    },
    {
      "id": "au_651252",
      "task": "Postifx receives mail but won't send mail out",
      "P-task": "postifx receiv mail send mail",
      "F_verb": "receive",
      "P-body": "In \"main.cf\" add \"relayhost =smtp.some_mail_server.com\" .  This host can be \"smtp\" server of your provider .  Restart \"postfix\" after this. .  ",
      "P-tags": "postfix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_546317",
      "task": "Synapse launcher: what is the difference between the `locate` command and the simple search?",
      "P-task": "synaps launcher : differ locat command simpl search",
      "F_verb": "locate",
      "P-body": "Trying to learn about this, I have found about the basics of Synapse's operation, which can be presented here as an answer. .   Not only Synapse launcher has a lot of plugins that enhance its operation, but it is entirely based on plugins. Disabling all of them makes it useless: even Application Search is a plugin. .   When just typing in Synapse, file search is done through Zeitgeist plugin, which provides search within the Zeitgeist logs. These are event logs, not files logs. More here. For a file to be found in this way, it has to have been already accessed in some way. Synapse cannot and is not intended to search for any file by simply typing part or all of its name.  .  That can be done through the \"locate\" search, which is based on a specific plugin intended to run that command (by selecting the last entry in the list of the simple Synapse search \u2014 which is the only entry when nothing is found).  .   .  The \"locate\" search is made within databases prepared by updatedb. The \"sudo updatedb\" command is needed to update the data base. Once found by \"locate\", if files are accessed/opened, they can be then found by simple Synapse search . To be found by \"locate\" a file needs (1) to be on a partition that is not excluded through the settings in \"/etc/updatedb.conf\", and (2) to have been created before \"sudo updatedb\" was run. .  Files created on the desktop are immediately found by Synapse.  .  Folder search is based on a separate plugin. .  After a file was opened and added to Zeitgeist, thus available with a simple search (without \"locate\"), other similar files will be found in the same way (e.g. with the same extension, within the same folder); that is due to other plugins: \"Hybrid Search\" and \"Related files\". .  More here and here. .   The answer to the above question is that normal Synapse file search (just typing in Synapse) uses different methods and tools than the search made with the \"locate\" command (selecting last entry after simple search and pressing ENTER). Normal search by just typing involves a tool (Zeitgeist) that only logs events, and thus finds only names of files already accessed (supplementary results are given because of the other plugins mentioned above). The search with \"locate\" is applied to all files listed when \"sudo updatedb\" was run last. Thus, it is the only way of finding files in Synapse that haven't been previously accessed and are not related to such files.  .  ",
      "P-tags": "locat partit synaps zeitgeist",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_36011046",
      "task": "How to specify path in os.system() to execute a shell script in Flask",
      "P-task": "specifi path os system execut shell script flask",
      "F_verb": "specify",
      "P-body": "I figured it out! In the script I was executing (script.sh) I was redirecting the output of some commands to text files. I needed to add the path the absolute path in those text files like this: .  this code is working fine though: \"output = execute(['sh', 'path/to/myscript/script.sh'], ['path/to/myscript/file1.txt', 'path/to/myscript/file2.txt'])\" .  Thanks everyone for your help! .  ",
      "P-tags": "python flask shell",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_40757087",
      "task": "When does a process acquire a file to read",
      "P-task": "process acquir file read",
      "F_verb": "acquire",
      "P-body": "When you run a command like \"file > my_script\" the contents located at \"file\" are piped into \"my_script\" (as a file descriptor). This decouples the contents from the name, meaning you can immediately modify/replace \"file\" in another process. .  If you instead run a command like \"my_script file\" you're passing the name \"file\" to \"my_script\", which may read from that file at any point (or write to it, delete it, etc.), thus you can't safely change \"file\" while the script is running. Notably this doesn't happen immediately; a long running process might not read from \"file\" until much later, after you've already edited the file. .  Therefore if you design your program to read from stdin you can safely modify the input file and re-run the command while the first process is still running. .  ",
      "P-tags": "linux process",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "su_655500",
      "task": "How to save linux command?",
      "P-task": "save linux command",
      "F_verb": "save",
      "P-body": "Your \"grep\" command is using \"--color=auto\": .  So you can still get the color adding this block in your \"grep\": .    also my grep is by default ignoring the case, how can I force case sensitiveness? .   It means that your grep is using \"-i\": .   Ignore case distinctions in both the PATTERN and the input files. -i is specified by POSIX.) .   You have two options: .  1) Try using the default grep with \"\\grep\". It will bypass any alias (see \\curl \u2026 | bash \u2026 what's the slash for? for more info): .  2) Change the \"grep\" definition in your \"~/.bashrc\" to the one you want. By now it will something like: .  ",
      "P-tags": "grep command-lin ubuntu shell bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_50870",
      "task": "How do I update virtualenv?",
      "P-task": "updat virtualenv",
      "F_verb": "update",
      "P-body": " ",
      "P-tags": "apt package-manag 11 04 python",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_43623310",
      "task": "How to find all file paths in a directory with bash",
      "P-task": "find file path directori bash",
      "F_verb": "find",
      "P-body": "If you don't want \"find\" to enumerate directories, then exclude them: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "au_898460",
      "task": "14.04 USB install GRUB2 issue",
      "P-task": "14 04 usb instal grub2 issu",
      "F_verb": "install",
      "P-body": "You've got several things going on here. I'll try to address all of them. .  The CSM The Compatibility Support Module (CSM) provides support for booting BIOS boot loaders (and therefore OSes) on an EFI-based computer. This is also known as \"legacy\" support. Thus, three names may be used to refer to the same thing -- BIOS, CSM, and legacy. Note that you cannot disable the EFI on an EFI-based computer -- the firmware on the computer is an EFI, full stop. There is a partial exception in some older EFI implementations for x68/x86-64, like Gigabyte's Hybrid EFI, but they're something of a footnote in firmware history.) The most you can do is to tell it to ignore EFI-mode boot loaders -- and on many computers, even if you do that, it's treated more as a suggestion than as a command; the computer may still boot an EFI-mode boot loader under certain circumstances. Disabling the CSM, OTOH, is usually more reliable; this usually prevents any BIOS-mode boot loader from running on the computer. .  Most computers that ship with Windows 8 and later are configured by default to boot in EFI mode only. They're also configured with Secure Boot active by default. Thus, if you want a universal boot medium, it should support both BIOS-mode and EFI-mode booting, and with Secure Boot support for the latter. This is possible, but it can be rather tedious to set up. There are several questions/answers on this site that cover this topic: .   Ubuntu on a USB stick - boot in both BIOS and UEFI modes Boot usb key on both UEFI and MBR? Making a pen-drive with a image from scratch bootable both in BIOS and UEFI mode  GRUB Boot Options GRUB's boot menu is controlled via a file called \"grub.cfg\", which is normally located in the \"/boot/grub\" directory. This configuration file is normally generated by scripts that come with GRUB, and is customized for a particular installation. Thus, when you installed to a USB flash drive on a system that had Windows XP on its hard disk, your \"grub.cfg\" file included an entry for that Windows XP installation, and that entry persisted on other computers, despite the fact that the entry would become useless. When you ran \"update-grub\" on a system that included Windows 7, the Windows 7 entry replaced the Windows XP entry because the scripts found Windows 7 but not Windows XP. There are several ways to fix this problem: .   Run the \"update-grub\" command on a system that has no OS installed except for the Ubuntu on the USB drive. Use the GRUB Customizer tool to edit \"grub.cfg\". I'm not 100% positive that it will enable you to remove your unwanted entries, though, since I've never used this tool myself.) Manually edit \"grub.cfg\". This is generally a bad idea because of the risk of error, but it might be necessary in some cases.) Switch to a boot loader other than GRUB. Most such boot loaders require manual editing of their configuration files -- but those files are simpler and therefore easier to edit than \"grub.cfg\". My own rEFInd boot manager detects OSes on every boot, which makes it less reliant on configuration files and more adaptable to the current system. OTOH, rEFInd is an EFI-only tool -- which is true of most boot loaders. Thus, if you switch, you may need different BIOS-mode and EFI-mode boot loaders. This isn't necessarily much of a drawback; EFI-mode and BIOS-mode versions of GRUB can be tricky to get to coexist.)  Note that any solution you try might be undone by an update to GRUB or to your Linux kernel, since the scripts that generate the configuration file run after every kernel or GRUB update. A kernel update won't trigger a switch back to GRUB from another boot loader, but a GRUB update might.) .  Missing USB drive Some EFIs include a feature called \"fast startup\" or something similar (or completely different -- the lack of standardization in names is frustrating) that disables USB initialization, or at least cuts it back to the bare minimum. It could be that this feature is active on your Dell Alienware system, and is preventing GRUB from accessing the USB flash drive. This would result in the symptoms you describe. If so, the solution is to disable this feature in the firmware setup utility. Some systems offer fine-grained control over USB initialization, so you might look for options about that, too. .  A similar issue might arise if the system treats different USB ports differently. For instance, USB 2 and USB 3 ports might be initialized differently. If so, moving the USB drive from one port to another might help. .  One doubt I have about this explanation is that the system was obviously able to load GRUB itself, presumably from the USB drive. This suggests that USB access is active, which flies in the face of my hypothesis. Perhaps it's active enough to load the initial boot loader but not to let GRUB access the USB drive, though. Another possibility is that GRUB was loading from somewhere else, such as your hard disk. Yet another possibility relates to your Ubuntu version.... .  Ubuntu 14.04... Really? Although Ubuntu 14.04 is still officially supported, it's getting a bit long in the tooth, and is likely to fail completely on the most modern hardware. This is because new hardware often requires new drivers, and the older Ubuntu 14.04 may lack these drivers. Thus, rather than Ubuntu 14.04, you may want to use 16.04.2, 16.10, or even the 17.04 beta that was recently released. .  There's a slim chance that this accounts for your Dell's inability to boot, too; there could be a bug or missing driver in GRUB that's causing it to fail to access the USB drive. .  Device Names Don't worry too much about this. Ubuntu identifies disks by their UUID values, which are unique 128-bit identifiers of filesystems. Thus, if the USB drive on which Ubuntu is installed switches from (say), \"/dev/sdb\" to \"/dev/sdc\", the system should continue to boot and work just fine. .  I've already alluded to one exception to this rule: If a computer uses a new type of USB controller, the USB device might not be visible to the older Ubuntu 14.04. There may be other exceptions, too, such as if a computer's hard disk has a filesystem with the same UUID as one on your USB drive -- but such a collision is very unlikely unless you deliberately clone the filesystem or duplicate its UUID. There might be other reasons problems might crop up, but nothing else springs immediately to mind. .  ",
      "P-tags": "uefi boot grub2 usb",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_47187191",
      "task": "Getting jq output in single line for JSON output using Bash",
      "P-task": "get jq output singl line json output use bash",
      "F_verb": "get",
      "P-body": "\"jq\" can alone parse the JSON to the desired format: .  ",
      "P-tags": "json bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP for NP using NP"
    },
    {
      "id": "au_91221",
      "task": "How to tell Xubuntu not to clone but to expand the laptop display to the external one?",
      "P-task": "tell xubuntu clone expand laptop display extern one",
      "F_verb": "tell",
      "P-body": "If you ran into the same situation like me: .   Enter \"xrandr\" into your terminal and figure the \"name\" of your laptop screen and the \"name\" of your external screen. Mine were \"VGA-0\" for the laptop and \"LVDS\" for the external one. While you are on it you can figure the resolutions supported by both devices. .  Create an executable script somewhere on your computer and name it e.g. \"dual_monitor.sh\". .  Put the following commands into the script. The comments should explain what is for what! .  Just comment out what you don't want and uncomment what you need and you will be done - after running this script! .   I got this solution from here and here. .  ",
      "P-tags": "xubuntu multiple-monitor",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_54986777",
      "task": "Sending IFS File to Outq Prints Line of \"@\" Symbols",
      "P-task": "send if file outq print line symbol",
      "F_verb": "send",
      "P-body": "I get different results, yet similar. I created a test.txt with Windows Explorer, put in Hello, world!, saved it and tried the script. I got gibberish for the 'Hello, world!' and then the line of @ symbols. .  My system is 7.3 TR5, CCSID 37 (US English) and my IFS file is CCSID 1252 (Windows English). Results did not change if I used a stream file of CCSID 819 (US ASCII). .  I didn't have any luck modifying Rfile switches. .  I found that removing devtype(*userascii) produced printed output in plain English without the @ symbols. Do you really need *USERASCII? I would think that would be more for a pre-formatted 'print-ready' file like Postscript or the like. .  EDIT: some more things to try I don't understand why *USERASCII is adding those @ symbols; it looks like a translation issue.  .  I tried this and still got the extra @@@... You might have to play with the TOCCSID() parameter. Although a failure, it did give me an idea: what if those @ symbols are EBCDIC spaces being sent as-is to the *USERASCII print stream? All we'd need is a way to send only the number of bytes in the stream file, without any padding. .  The data in QTEMP/PRTSTMF is in ASCII; DSPPFM shows that much. It also shows a bunch of spaces: after all, it is a fixed length file. My next step was to write an RPG program to read the stream file and print it, but Scott Klement already did that: http://www.scottklement.com/PrtStmf.zip  .  This works on my system: .  ",
      "P-tags": "print ibm-midrang qshell",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "so_15230702",
      "task": "how to run an application with user privileges from root console",
      "P-task": "run applic user privileg root consol",
      "F_verb": "run",
      "P-body": "With \"sudo -u username\" you can run a program with \"username\" privileges. Like this: .  If you can't use \"sudo\", you can try with the followind command, as @Torrius suggested: .  If you can't even use the latter solution, you can write a small c program that runs an executable with the privileges of parametrized \"user and group id\". .  Look at this concept code: .  To test it: .  ",
      "P-tags": "privileg linux consol",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP from NP"
    },
    {
      "id": "so_13402801",
      "task": "convert unix time to date object",
      "P-task": "convert unix time date object",
      "F_verb": "convert",
      "P-body": "You can take a look at date.js .  http://www.datejs.com/ .  This alerts a date string set to today's date, but with the time in datestr.  .  NOTE For this to work, I needed to zero-pad the seconds. .  EDIT .  The link for date.js format specifiers is a bit buried, so here's that link if you need it: .  http://code.google.com/p/datejs/wiki/FormatSpecifiers .  ",
      "P-tags": "unix-timestamp javascript date",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_36210082",
      "task": "DPI scaling of borderless Winforms window goes wrong",
      "P-task": "dpi scale borderless winform window goe wrong",
      "F_verb": "go",
      "P-body": "The solution is not to set \"size\" but \"clientsize\" for the form itself. .  ",
      "P-tags": "powershel dpi winform",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP"
    },
    {
      "id": "au_486090",
      "task": "Restart an install process",
      "P-task": "restart instal process",
      "F_verb": "restart",
      "P-body": "I've never used SSH to connect to servers, but if I were having this problem on a local machine I would reboot to get rid of the lock problem, and then type \"\"sudo apt-get install --reinstall phpmyadmin\"\" .  ",
      "P-tags": "phpmyadmin software-instal",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_19943274",
      "task": "sed remove and replace certain match",
      "P-task": "sed remov replac certain match",
      "F_verb": "remove",
      "P-body": "awk is probably better suited to handling this  .  ",
      "P-tags": "sed bash unix regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_278939",
      "task": "How do you put date and time in a file name?",
      "P-task": "put date time file name",
      "F_verb": "put",
      "P-body": "If you want to use the current datetime as a filename, you can use \"date\" and command substitution. .  This results in the file \"2016_04_25_10_30_AM.log\" (although, with the current datetime) being created with the md5 hash of \"/etc/mtab\" as its contents. .  Please note that filenames containing 12-hour format timestamps will probably not sort by name the way you want them to sort. You can avoid this issue by using 24-hour format timestamps instead. .  If you don't have a requirement to use that specific date format, you might consider using an ISO 8601 compliant datetime format. Some examples of how to generate valid ISO 8601 datetime representations include: .  If you want \"safer\" filenames (e.g., for compatibility with Windows), you can omit the colons from the time portion. .  Please keep in mind that the above examples all assume local system time. If you need a time representation that is consistent across time zones, you should specify a time zone offset or UTC. You can get an ISO 8601 compliant time zone offset by using \"%z\" in the format portion of your \"date\" call like this: .  You can get UTC time in your \"date\" call by specifying the \"-u\" flag and adding \"Z\" to the end of the datetime string to indicate that the time is UTC like this: .  ",
      "P-tags": "filenam date text-process",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_646804",
      "task": "How to append a Linux command line to file?",
      "P-task": "append linux command line file",
      "F_verb": "append",
      "P-body": "Expansions in the here-document are carried out by the shell unless the expansions themselves are quoted, or the here-document itself is quoted. .  To quote the command substitution and the various other variables that the shell would try to expand in the here-document in your example: .  Note that we have to quote not only the \"$\" in the command substitution, but also in \"$2\" in the \"awk\" code and in \"$ipaddress\" in the \"echo\" invocation. We actually need to doubly quote these strings using \"\\\\\\\" since they are actually part of an embedded here-document (\"SHELL\"). each \"\\\\\\$\" would be replaced by \"\\$\" when \"Vagrantfile\" is written. .  Unless you really want the shell to expand some variable in the here-document, it is usually easier to just quote the here-document as a whole. This is done by quoting the initial here-document delimiter string: .  Here I've opted for quoting both the embedded here-document and the outer here-document. .  Depending on how this code is used and where, you may want to make sure that both the first and the embedded here-documents are indented with tabs and that both here-documents are started with \"<<-\" (\"<<-'EOL'\" and \"<<-'START'\"). This would ensure that the embedded here-document could be correctly parsed (the ending \"SHELL\" needs to be first on the line once \"Vagrantfile\" has been created). .  Note that I have not commented on the contents of the here-document in terms of what it tries to achieve. I don't know whether \"sudo su\" makes sense or not, for example. .  ",
      "P-tags": "here-docu bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "su_1657083",
      "task": "How do I pass a path with spaces to WSL for Windows Terminal",
      "P-task": "pass path space wsl window termin",
      "F_verb": "pass",
      "P-body": "It's a bit non-intuitive, and just as undocumented as the \"~\" option, but \"wsl --cd\" sounds like what you are looking for. It actually takes a Windows path spec, not the WSL/Linux form. So: .  If you are using the Windows Terminal Settings UI, then it will automatically provide the proper quoting for you in the \"settings.json\", which is: .  And just for fun, here's an alternative, hacky method that you really shouldn't ever need to use, since the \"--cd\" option is the non-hacky, better way: .  While it's not the best option for this particular case, it does demonstrate the ability to edit the environment (\"PWD\" in this case) before exec'ing a shell. That can be useful sometimes. .  ",
      "P-tags": "termin windows-subsystem-for-linux",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP for NP"
    },
    {
      "id": "ul_433644",
      "task": "Linux Mint 18.3 Cinnamon cannot start a session",
      "P-task": "linux mint 18 3 cinnamon start session",
      "F_verb": "start",
      "P-body": "It's VirtualBox that is the problem. Fix: <Ctrl><Alt><F1> to get a shell and login to the prompt. .  Then: .  Credit goes to: Mint forum .  ",
      "P-tags": "login linux-mint cinnamon session",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_20712559",
      "task": "Including -lcurl in makefile",
      "P-task": "includ -lcurl makefil",
      "F_verb": "include",
      "P-body": "You run g++ with the '-c' option like this: .  The -c option means \"Compile or assemble the source files, but do not link.\", so adding -lcurl does not do anything at all. The references to curl functions remain as unresolved references in the ParseText.o file. .  You need to add -lcurl to the linking phase, which is the rule 'Aprog' in your makefile. This rule takes all of the object files from the individual translation units (ie. cpp files) and links them together, then adds linkage to any libraries you specify. .  or, since you have set the variable LDFLAGS you can use: .  ",
      "P-tags": "c++ curl unix",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_436526",
      "task": "Try to Get Single Row from Ansible Output",
      "P-task": "tri get singl row ansibl output",
      "F_verb": "get",
      "P-body": "This is working. .  ",
      "P-tags": "ansibl linux shell-script",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_20473944",
      "task": "Change my R environment language (Ubuntu)",
      "P-task": "chang r environ languag ubuntu",
      "F_verb": "change",
      "P-body": "One way I've been able to get around the problem was to install Rstudio and type on the console: .  No clue still why that doesn't work when typing on Ubuntu terminal thought. .  ",
      "P-tags": "ubuntu r",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_42760138",
      "task": "Ubuntu docker image doesn't contain any /dev/sdX block devices?",
      "P-task": "ubuntu docker imag contain dev sdx block devic",
      "F_verb": "contain",
      "P-body": "Docker doesn't create virtual machines, it creates containers to run an application in an isolated space. Including physical hardware devices would allow those applications to escape from the container isolation, so they are not provided by default. You can include specific devices inside the container with the \"docker run --device ...\" cli flag, and you will most likely need to include \"--privileged\" give the root user back various capabilities that are removed. None of this is recommended for running untrusted containers. .  ",
      "P-tags": "linux ubuntu devic docker",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_779583",
      "task": "Can anyone help me find and install beta amd driver?",
      "P-task": "anyon help find instal beta amd driver",
      "F_verb": "install",
      "P-body": "Make a temporary directory in your /home folder .  Download the driver here and put it in that directory .  Now extract it .  Change to the extracted directory .  Now run the install script .  Follow any instructions given and this will install the driver. .  Ensure that your user account is a member of the \"video\" group prior to using the vulkan driver. You can find which groups you are a member of with the following command: .  To add yourself to the video group you will need the sudo password and can use the following command: .  You will need to log out and in again to activate this change. .  That should be it, reboot and you will be using the beta driver. .  You can delete the ~/tmp folder we created in the first step. .  If for any reason you wish to remove the AMD GPU-PRO graphics stack you can do this using the uninstallation script which was part of the installation and is present in your path. From the command prompt enter the following command: .  Source .  ",
      "P-tags": "driver 64-bit amd-processor",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_748796",
      "task": "How to match exported OpenPGP public and private key pairs?",
      "P-task": "match export openpgp public privat key pair",
      "F_verb": "match",
      "P-body": "By listing the secret key file's contents, you can query which public key a secret key belongs to. .  The last line quoted \"keyid\" contains the public key's long key ID. .  ",
      "P-tags": "openpgp gnupg",
      "source": "qa",
      "cate": "match",
      "pat": "V NP"
    },
    {
      "id": "ul_172008",
      "task": "Script to replace all symbolic links to a target to point to another target (in the same directory)",
      "P-task": "script replac symbol link target point anoth target directori",
      "F_verb": "replace",
      "P-body": "I assume you are using bash, so I would use \"globstar\" to loop through all directories at once with \"**\". After that all what is left is to play a little bit with \"readlink\", \"realpath\", etc: .  ",
      "P-tags": "shell-script symlink bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_249929",
      "task": "Replace numbers in file1 with corresponding line in file2",
      "P-task": "replac number file1 correspond line file2",
      "F_verb": "replace",
      "P-body": "You could use \"awk\", constructing an array from file2 indexed by its line (record) number, and then doing a lookup based on the first field of file1 .  This tab-separates the two parts: you could comma-separate them instead if you prefer. .  ",
      "P-tags": "file text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP"
    },
    {
      "id": "so_43850105",
      "task": "Find text in files and than move those files into new location",
      "P-task": "find text file move file new locat",
      "F_verb": "find",
      "P-body": "To copy all matching files to a directory you can write: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "au_1238482",
      "task": "Ubuntu Failed to install and now I don't know which partition it's on so I don't have access to my other 500GB",
      "P-task": "ubuntu fail instal know partit access 500gb",
      "F_verb": "install",
      "P-body": "Disk 1 partition 3 is the partition that according to you, Ubuntu is holding hostage. You can safely delete this and get the space back. But as you have the \"EFI system partition\" in the middle, you will have trouble combining it with the \"D:\" partition. There are workarounds. For example, you can do this with the Easeus Partition Master Paid version. You can find a safe crack if you try. I found a safe one from YouTube.) You can also delete the \"EFI system partition\" (after finding whether it is safe to do so with Microsoft Community and/or Microsoft Community Advocates.) and combine the partition with \"D:\". Another way to use that space is to assign a new drive letter like \"E:\" and use it as a separate partition. .  ",
      "P-tags": "dual-boot partit hard-driv boot windows-10",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_64953498",
      "task": "Edit XML ID value with powershell",
      "P-task": "edit xml id valu powershel",
      "F_verb": "edit",
      "P-body": "If I understand correctly, you have given us a really shortened example of what the XML looks like, so I extended it a bit here: .  You can use either the 'dot' (Case-Insensitive) method for changing the value of the setting with id 'noteid' like this: .  Or use XPath (remember that this is Case-Sensitive..) .  In both cases the result will be: .  ",
      "P-tags": "powershel xml",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_149629",
      "task": "Why does sendmail's status keep changing to \"dead but subsys locked\"?",
      "P-task": "sendmail statu keep chang dead subsi lock",
      "F_verb": "keep",
      "P-body": "Turns out \"postfix\" and \"sendmail\" were running at the same time. Something was occasionally causing the \"postfix\" service to start which then caused the status of \"sendmail\" to jump to \"dead but subsys locked\". .  I thought I had checked that \"postfix\" wasn't running by performing \"sudo service --status-all\". Rather confusingly the main process for \"postfix\" is listed as \"master\" not \"postfix\". Upon scanning the output of \"sudo service --status-all\" I was expecting to see \"postfix (pid xxxx) is running...\" and as there was no such line I assumed \"postfix\" wasn't running! .  To fix this I simply performed \"sudo service master stop\" followed by \"sudo service sendmail restart\" and all is well again. Now time to track down what's causing \"postfix\" to start up every now and then... .  ",
      "P-tags": "sendmail cento linux servic",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V S_ING"
    },
    {
      "id": "so_55415289",
      "task": "How to return any object with sys.stdout",
      "P-task": "return object sy stdout",
      "F_verb": "return",
      "P-body": "You can use data serialization with pickle : .  sender.py .  receiver.py .  ",
      "P-tags": "pipe list python bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_43462401",
      "task": "run iperf in background and redirect output to a file",
      "P-task": "run iperf background redirect output file",
      "F_verb": "run",
      "P-body": "Instead of using the daemon option, use \"nohup\": .  That will put iperf3 in the background and make it immune to hangups. The shell will print out the job number and PID: .  You can stop it later by sending a SIGTERM using \"kill\": .  ",
      "P-tags": "linux iperf3 iperf bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "au_670038",
      "task": "Ubuntu 14.04: Can I automatically deactivate my touchpad when a USB-mouse is connected?",
      "P-task": "ubuntu 14 04 : automat deactiv touchpad usb-mous connect",
      "F_verb": "deactivate",
      "P-body": "There is a setting for Ubuntu 15.10 and I believe it is applicable for 14.04 too. The feature can be accessed by using Dconf editor. Navigate to \"org.gnome.desktop.peripherals.touchpad\" and change the \"send-events\" path. .  This can be done via command line as well. The following command gives the output: .  Of course last property is of our pursue. To change the settings type this command: .  Again, you may want to revert things. If so, run following: .  Update: I can only confirm it works with a wired USB mouse. .  ",
      "P-tags": "14 04 touchpad mous",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP when S"
    },
    {
      "id": "au_297052",
      "task": "Need help adding a PPA",
      "P-task": "need help ad ppa",
      "F_verb": "add",
      "P-body": "To install PS2 Emulator in Ubuntu, just press Ctrl+Alt+T on your keyboard to open Terminal. When it opens, run the command(s) below: .  (you just misspelled the name) .  ",
      "P-tags": "12 04 ppa",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_6178619",
      "task": "Responding to \"write\" messages",
      "P-task": "respond write messag",
      "F_verb": "respond",
      "P-body": "I can't think of any obvious way to do this. Here's why... .  Your shell receives its input from, and send its output to, some terminal device: .  When \"write\" writes to the terminal, it sends data directly to the same terminal device. It doesn't go anywhere near your shell: .  So, in order for you to be able to capture what is sent by \"write\", you'd need some hook provided by the terminal device itself, and I don't think there is anything you can use to do this. .  So how does \"script\" work, and why doesn't it capture the \"write\" output? .  \"script\" can't hook into the terminal device either. It really wants to interpose itself between your shell and your terminal, but there isn't a good way to do that directly. .  So, it creates a new terminal device (a pseudo-terminal, also known as a \"pty\") and runs a new shell in it. A pty consists of two sides: the \"master\", which is just a stream of bytes, and a \"slave\", which looks just like any other interactive terminal device. .  The new shell attaches to the slave side, and \"script\" controls the master side -- which means that it can save the stream of bytes to a file, as well as forwarding them between the new shell and the original terminal: .  Now you can see that a \"write\" to the original terminal device bypasses everything, just like it did in the simple case above: .  If you write data to the slave side of the new terminal here, you will see the output show up, because it will appear in the stream of data on the master side, which \"script\" sees. You can find the name of the new pty with the \"tty\" command from the shell inside \"script\". .  Unfortunately, this doesn't help with \"write\", as you probably won't be able to \"write\" to it: your login session is associated with the original terminal, not the new one, and \"write\" will probably complain that you're not logged in. But if you e.g. \"echo hello >/dev/pts/NNN\", you'll see that it does show up in the \"script\" output. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "respond",
      "pat": "V to NP"
    },
    {
      "id": "au_564584",
      "task": "How can I get librefblas.a on Ubuntu 14.04.1 LTS Trusty?",
      "P-task": "get librefbla ubuntu 14 04 1 lt trusti",
      "F_verb": "get",
      "P-body": "Using Lapack version 3.5.0 with gfortran installed .  librefblas.a is in directory lapack-3.5.0 .  ",
      "P-tags": "14 04 source-cod librari",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1040485",
      "task": "Unable to open \"Cisco Anyconnect Secure mobility client\" on my Ubuntu 18.04 LTS after the complete installation",
      "P-task": "unabl open cisco anyconnect secur mobil client ubuntu 18 04 lt complet instal",
      "F_verb": "open",
      "P-body": "I had the exactly same problem, the VPN was working but couldn't see the GUI, I found that is because of some missing dependency (\"libpangox-1.0-0\" and \"libcanberra-gtk-module\"), try installing it: .  You may check if you need anything more or have other errors by running the UI executable, mine was installed on  .  You can run \"bin/vpnui\" and check what error you may have, hope it helps! .  ",
      "P-tags": "vpn cisco openvpn",
      "source": "qa",
      "cate": "open",
      "pat": "V NP on NP after NP"
    },
    {
      "id": "so_16492442",
      "task": "can't use SOIL in linux mint",
      "P-task": "use soil linux mint",
      "F_verb": "use",
      "P-body": " So you probably want the following on the g++ command-line .  Or just use the following in your C++ .  And you probably want the following on the command-line when linking .  ",
      "P-tags": "c++ linux soil opengl",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_4863707",
      "task": "How to see Linux' view of the RAM in order to determinate the fragmentation",
      "P-task": "see linux view ram order determin fragment",
      "F_verb": "see",
      "P-body": "Memory Fragmentation When a Linux system has been running for a while memory fragmentation can increase which depends heavily on the nature of the applications that are running on it. The more processes allocate and free memory, the quicker memory becomes fragmented. And the kernel may not always be able to defragment enough memory for a requested size on time. If that happens, applications may not be able to allocate larger contiguous chunks of memory even though there is enough free memory available. Starting with the 2.6 kernel, i.e. RHEL4 and SLES9, memory management has improved tremendously and memory fragmentation has become less of an issue. .  To see memory fragmentation you can use the magic SysRq key. Simply execute the following command: .  This command will dump current memory information to /var/log/messages. Here is an example of a RHEL3 32-bit system: .  The first line shows DMA memory fragmentation. The second line shows Low Memory fragmentation and the third line shows High Memory fragmentation. The output shows memory fragmentation in the Low Memory area. But there are many large memory chunks available in the High Memory area, e.g. 28 4MB. .  If memory information was not dumped to /var/log/messages, then SysRq was not enabled. You can enable SysRq by setting sysrq to 1: .  Starting with the 2.6 kernel, i.e. RHEL4 and SLES9, you don\u2019t need SysRq to dump memory information. You can simply check /proc/buddyinfo for memory fragmentation. .  Here is the output of a 64-bit server running the 2.6 kernel: .  In this example I used SysRq again to show what each number in /proc/buddyinfo is referring to. .  Source: http://www.puschitz.com/pblog/ .  ",
      "P-tags": "linux ram",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_11563535",
      "task": "How to catch PowerShell function call from c#",
      "P-task": "catch powershel function call c",
      "F_verb": "catch",
      "P-body": "You could define a cmdlet (in your c# code) with the name \"TestFunction\" and add it to the runspace configuration like this: .  ",
      "P-tags": "net c overrid function powershel",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP from NP"
    },
    {
      "id": "so_13836307",
      "task": "How to prevent PHP script running more than once?",
      "P-task": "prevent php script run",
      "F_verb": "prevent",
      "P-body": "Now I check whether the process is running by \"ps\" and warp the php script by a \"bash\" script: .  and run the \"bash\" script by \"cron\" every minute. .  ",
      "P-tags": "cento linux cron php",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP S_ING"
    },
    {
      "id": "so_25056611",
      "task": "curl: pass a named parameter from stdin",
      "P-task": "curl : pass name paramet stdin",
      "F_verb": "pass",
      "P-body": "Is this not possible? .  Or .  \"echo \"some data\"\" can be another command or file input: \"$(<somefile)\". .  ",
      "P-tags": "curl bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP from NP"
    },
    {
      "id": "so_48617956",
      "task": "bash cript: ssh create file; sleep 3m; rm file;",
      "P-task": "bash cript : ssh creat file sleep 3m rm file",
      "F_verb": "create",
      "P-body": "Your ssh command will sleep for 3 minutes and remove the files, then your script proceeds to try to rsync the files that got removed. There is no easy workaround for having your first ssh command sleep while your own script proceeds to run rsync. .  Do either: .   ssh into the server twice. After rsync completes, ssh into the server again and remove the files. Tell rsync to remove the files after it's synced them. Add the \"--remove-source-files\" to rsync.  ",
      "P-tags": "linux rsync ssh bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "su_527642",
      "task": "Linux (Ubuntu) Run program in background",
      "P-task": "linux ubuntu run program background",
      "F_verb": "run",
      "P-body": "Another quick answer is..assumming that the program really needs no user input: .  The reason it is stopping is that the program is opening \"stdin\" for some reason, eventhough it might not need any input. .  ",
      "P-tags": "linux php",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1045622",
      "task": "Cmake has not updated, what I am doing wrong?",
      "P-task": "cmake updat wrong",
      "F_verb": "update",
      "P-body": "The output of \"which cmake\" says that your \"cmake\" is located in /usr/local/bin/cmake and that is the problem. .  Remove it with \"sudo rm /usr/local/bin/cmake\" and try again. .  ",
      "P-tags": "sudo 16 04 cmake",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_24780934",
      "task": "Get NTP IP in windows servers",
      "P-task": "get ntp ip window server",
      "F_verb": "get",
      "P-body": "This will be returning the IP of NTP server. Prerequisites: RemoteRegistry running on the server and of course access to the remote registry.  .  Edit: .  Since it seems I misunderstood the question .  Here is something that returns exactly the referenceID field from W32TM. This will however extract the data from the FIXED point. if something is different in your setup, you will have to manuever around calling the array elements, splits and substrings. On the other hand, the referenceID for me returns the IP address of ntp server if there is a domain one set... Plus, you have to have Enable-PSremoting -force set up on the servers for them to accept calls. .  ",
      "P-tags": "batch-fil ntp window powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_37015073",
      "task": "Convert between byte count and \"human-readable\" string",
      "P-task": "convert byte count human-read string",
      "F_verb": "convert",
      "P-body": "numfmt  .  To:  .  From: .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V between NP"
    },
    {
      "id": "ul_389068",
      "task": "What are the implications of setting the baud rate of a terminal from userspace?",
      "P-task": "implic set baud rate termin userspac",
      "F_verb": "set",
      "P-body": "It looks like you might be a bit confused about how this all works.  .  First, \"/dev/ttyACM0\" does not represent the USB link, or even the USB endpoint for whatever serial adapter you have connected, it represents the UART inside the adapter that handles the serial communications. Data you read from it will not include any USB headers or framing, just like data you read from \"/dev/ttyS0\" will not include any PCI Express headers or framing. Setting the baud rate on these affects the hardware that it represents, not the bus it's connected to, so this won't do anything to the USB connection. .  Second, the baud rate is a hardware setting, not a software one. When you call \"stty\" to set it on a serial port, that is telling the kernel to tell the hardware to change what baud rate it is trying to receive data at. This means in particular that any data that was received prior to this change will either be bogus (because it wasn't interpreted correctly by the hardware, sometimes the case if the baud rates are close to each other or exact harmonics), or completely lost (because the hardware just didn't accept it, the more likely case on modern hardware).  .  If you plan on reading data from a serial line, you need to have the baud rate set correctly prior to any data being transmitted by the other end. This also means that changing the baud rate won't change how the kernel interprets the data. If the data is already buffered in the kernel, then it's not going to change just because you change the baud rate (although it is good practice after changing the baud rate to drain the kernel buffers so that you know any future data is good). .  So, to clarify, the correct method to get data out of a USB to serial adapter without using special software is to: .   Set the baud rate during system startup. For a USB to serial adapter, this should probably be a udev rule so that it gets set when the device gets plugged in too. Use \"cat\" (or \"od\" if you need the byte values instead of text) to read data. This will return the exact data that is received by the USB to serial adapter (assuing the adapter doesn't do special processing).  ",
      "P-tags": "usb devic stti uart",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP from NP"
    },
    {
      "id": "so_32438367",
      "task": "Install libuv on Ubuntu 12.04",
      "P-task": "instal libuv ubuntu 12 04",
      "F_verb": "install",
      "P-body": "Try building from source: .  ",
      "P-tags": "ubuntu-12 04 libuv",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_55055780",
      "task": "find: list date and size without using -printf",
      "P-task": "find : list date size without use -printf",
      "F_verb": "find",
      "P-body": "I've figured it out. .  could be used instead to get size and date info. .  This is useful when the -printf option is not available. .  ",
      "P-tags": "linux find grep command-lin",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_25336248",
      "task": "C struct error \"pointer to incomplete class type is not allowed\"",
      "P-task": "c struct error pointer incomplet class type allow",
      "F_verb": "allow",
      "P-body": "You can't use \"NODE\" inside the definition of \"struct node\", because \"NODE\" isn't defined yet. .  The slow way to do it would be: .  so that after you define what \"struct node\" is, you can refer to it as \"NODE\". .   Change .  to .  ",
      "P-tags": "linux struct c pointer",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V"
    },
    {
      "id": "so_42444615",
      "task": "How to write a shell script to open four terminals and execute a command in each?",
      "P-task": "write shell script open four termin execut command",
      "F_verb": "write",
      "P-body": "You could use a \"for\" loop, and a \"&\" to run xterm in background: .   ",
      "P-tags": "unix script linux xterm shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_1188297",
      "task": "I'm running fsck and getting \"ext2fs_open2: Bad magic number in super-block\"",
      "P-task": "run fsck get ext2fs_open2 : bad magic number super-block",
      "F_verb": "get",
      "P-body": "You're doing the \"fsck\" on the wrong partition (sdb2). .  \"sudo fdisk -l\" shows us that the following partitions are \"Linux filesystem\"... .  Here are the commands that you should be using... .  Boot to Ubuntu Live DVD/USB in \"Try Ubuntu\" mode. .  Open the \"terminal\" application and type: .  ",
      "P-tags": "fsck",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_344617",
      "task": "\"error constructing proxy...\" when trying to launch gnome-terminal as root",
      "P-task": "error construct proxi tri launch gnome-termin root",
      "F_verb": "launch",
      "P-body": "Remember how Windows applications mainly worked back in the Win16 days before Win32 came along and did away with it: where there were \"hInstance\" and \"hPrevInstance\", attempting to run a second instance of many applications simply handed things over to the first instance, and this made things difficult for command scripting tools (like Take Command) because one would invoke an application a second time, it would visibly be there on the screen as an added window, but as far as the command interpreter was concerned the child process that it had just run immediately exited? .  Well GNOME has brought the Win16 behaviour back for Linux. .  GNOME Terminal is now a client-server application. The \"gnome-terminal\" program is just a client that constructs Desktop Bus messages to a server, passing along its command line options, environment, working directory, and arguments, and then simply exiting. The server is \"gnome-terminal-server\" which registers as \"org.gnome.Terminal\" on the Desktop Bus and which is responsible for all of the actual terminal emulation and displaying the window(s) on the GUI(s). .  A Desktop Bus client like \"gnome-terminal\" locates the Desktop Bus broker via an environment variable, which usually points to socket in a per-user directory such as \"/run/user/1001\". Alternatively, the environment variable specifies to look in \"the current user's runtime directory\" and a path similar to the aforementioned is constructed from the client process's effective user ID. This directory in either case is conventionally private to the individual user, and inaccessible to other (unprivileged) users.  .  Hilarity ensues when people attempt to run \"gnome-terminal\" as another user via \"sudo\" and suchlike. If the environment variable points to an explicitly-named runtime directory, an unprivileged client cannot connect to the per-user Desktop Bus. If the environment variable points to \"the current user's\" runtime directory, it looks for the wrong Desktop Bus broker, often the one for a user that does not currently have a Desktop Bus broker running because the user has not logged in and started up that user account's per-user services. Per-user Desktop Bus brokers are run by a per-user service manager. The per-user service manager is either started explicitly or, in the case of some service management softwares, by some rather ugly hooks into the user authentication process employed by the likes of the \"login\", \"su\", and SSH server programs.) .  The reason that \"dbus-launch\" worked for you as the superuser is that \"dbus-launch\" explicitly launched another Desktop Bus broker, running as the superuser, which \"gnome-terminal\" was able to talk to. Luckily, the system was also configured to demand-start the \"gnome-terminal-server\" server when the client attempted to connect to it via the broker. This is not necessarily the case, and nowadays such demand-starting is seen as an inferior mechanism as it ends up with lots of Desktop Bus server processes that aren't running under any kind of service management. Indeed, not having the broker itself under service management is considered inferior too. It's also generally not considered a good idea for the superuser account to have these sorts of services running, as many of them do not expect to be running with superuser privileges because they expect to be running under the aegides of ordinary user accounts.) .  Further hilarity ensuses if, as the questioner at \"How can I launch gnome-terminal remotely on my headless server? (fails to launch over X11 forwarding)\" does, people attempt to run \"gnome-terminal\" when even the original user does not have a Desktop Bus broker running. This happens when, for example, one has logged in via SSH but the SSH login process does not start up the per-user service manager, which in turn means that the per-user Desktop Bus broker is not run, and the \"gnome-terminal-server\" server cannot be reached over a Desktop Bus. According to how the system is configured, graphical login could still trigger starting the per-user service manager, and hence one might observe that logging in graphically as the same user magically makes things work. And again \"dbus-launch\" would explicitly start a non-service-managed Desktop Bus broker.) .  Yet more hilarity ensues when one has one of the service managers that has the hooks into \"login\", \"su\", and the SSH server. These hooks usually implement the semantics of starting up per-user service management, and all of the per-user services that it starts, at first log-on for that user; and stopping them all at last log-off for that user. If one has a lot of short-lived and non-overlapping SSH sessions, then there can be a lot of overhead generated uselessly starting up and shutting down the entire per-user service management system (and all of its auto-start services) at the starts and ends of each of those SSH sessions. systemd, one such service manager, has an imperfect \"linger\" mechanism that only really half addresses this. It means that per-user service management \"lingers\" after the final log-off, but it does not stop the per-user service management from being started at all. .  Further reading  Jonathan de Boyne Pollard (2016). \"/run/user/jim/dbus\". \"Gazetteer\". nosh Guide. Softwares. jdebp.eu. Jonathan de Boyne Pollard (2016). \"per-user user services\". nosh Guide. Softwares. jdebp.eu. Run true multiple process instances of gnome-terminal Make user systemd service persistent https://unix.stackexchange.com/a/323700/5132  ",
      "P-tags": "gnome-termin opensus d-bu",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP as NP"
    },
    {
      "id": "au_746552",
      "task": "How to Add PCloud in startup applications?",
      "P-task": "add pcloud startup applic",
      "F_verb": "add",
      "P-body": "To find the command: .   Most default applications will have a \".desktop\" file located in \"/usr/share/applications\". .  To find out about the corresponding terminal command that will be run when launching one of these applications open the file browser Nautilus and right click on the application's icon to select Properties in the context menu. [Then, look at the \"command\" box] .    Taken from here   Then: Dash > Startup Applications .  Add a new entry, and in the \"command\" box, put the command to launch this program from CMDline. .  Please note, it may not start instantly after logon. It might be 30 seconds before it opens. .  ",
      "P-tags": "14 04 cloud startup-appl",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "su_454101",
      "task": "Is there a way to disable Intel SpeedStep steppings on an Ubuntu Server using a command line application?",
      "P-task": "way disabl intel speedstep step ubuntu server use command line applic",
      "F_verb": "disable",
      "P-body": "The Ubuntu kernel is shipped with CPU controlling governors, normally set to \"ondemand\" they will regulate the performance of your CPU in your Ubuntu system. .  You can change the CPU performance setting in Ubuntu per logical CPU. .  Start by reading the current available settings for your system: .  this will return a list of available settings you can use to regulate each core of your CPU, if you can you should then set them to max performance by selecting the \"performance\" option. This will make your CPU cores run always at max frequency. .  Knowing what options you have and if the \"performance\" option is available, you can then set each core to \"performance\" mode with the command: .  this will make cpu0 (first core) run all the time at max performance. Do it for all the logical cores in your CPU. .  You can then check if the option was successfully changed with the command: .  this will check the current set option for cpu0 (first core). Check if the change was successful for all cores and if everything was set correctly you are good to go: Intel SpeedStep will be on but all your cores will be running at max frequency speed all the time. .  You can then check and get information about the actual frequency using \"cpufreq-info\" from the package \"cpufrequtils\" in the universe repository, it will report per core the actual speed and a lot of other information including the set governor, but you need to install it first using the command \"sudo apt-get install cpufrequtils\". .   cpufreq-info .   ",
      "P-tags": "linux ubuntu perform",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "au_861917",
      "task": "I installed PHP7 but apache2 directory in /etc is not created. Now what?",
      "P-task": "instal php7 apache2 directori etc creat",
      "F_verb": "create",
      "P-body": "You need to install a package for that. D'oh! .  Running: .  resolved the problem. .  ",
      "P-tags": "php lamp server apache2",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V"
    },
    {
      "id": "so_11503025",
      "task": "Find and replace at powershell",
      "P-task": "find replac powershel",
      "F_verb": "replace",
      "P-body": "Something like this; .  ",
      "P-tags": "powershel powershell-is",
      "source": "qa",
      "cate": "replace",
      "pat": "V at NP"
    },
    {
      "id": "so_46289178",
      "task": "How to exclude keywords from already filtered list in Powershell",
      "P-task": "exclud keyword alreadi filter list powershel",
      "F_verb": "exclude",
      "P-body": "There isn't an \"-exclude\" operator, but you can achieve your result by using the \"Where-Object\" cmdlet and \"-notin\": .  Or if you'd prefer to use the \"?\" alias for \"Where-Object\" to make this shorter: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_4674587",
      "task": "Use the Get-Help cmdlet to display comment-based help in the same format",
      "P-task": "use get-help cmdlet display comment-bas help format",
      "F_verb": "use",
      "P-body": "It will work, but you are trying to run get help on the script. You have added the help to the function. If you dot source your script, and then type get-help isalive, you will see your help for the function. .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_20296024",
      "task": "How to set a property in Powershell on an instance of a class that implements IDictionary and ICollection",
      "P-task": "set properti powershel instanc class implement idictionari icollect",
      "F_verb": "set",
      "P-body": "If you are trying to set this when you are creating the object it is possible using the \"Property\" parameter of \"New-Object\": .  However if you are trying to set the property at some later time, the only way I have found is somewhat clumsy, using the .NET Reflection API: .  ",
      "P-tags": "sqlite powershel c",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP that S"
    },
    {
      "id": "so_22918630",
      "task": "Java delete file/directory equivalent of linux \"rm -rf /tmp/garbagedir*\"",
      "P-task": "java delet file directori equival linux rm -rf tmp garbagedir",
      "F_verb": "delete",
      "P-body": "The new file API has all the tools you need: .   it has a method accepting globs as arguments; it has a \"FileVisitor\" interface which you can use to perform recursive file deletion (see here for an example).  Feel free to salvage the recursive deletion example, and note that it can be improved. In particular, this one will stop at the first deletion error, but it is trivial to modify so that it continues in this case instead. .  ",
      "P-tags": "file-io linux java",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "so_57813763",
      "task": "Bash script to create and delete a file N times",
      "P-task": "bash script creat delet file n time",
      "F_verb": "create",
      "P-body": "You can use \"mktemp\" that should give almost a random filename and execute it count times: .  Alternatively you could use \"$RANDOM\": .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_57334471",
      "task": "How to replace a character in a row based on the numbers in a column as the index of that character?",
      "P-task": "replac charact row base number column index charact",
      "F_verb": "replace",
      "P-body": "The following script with comments inside: .  will output: .  Tested on tutorialspoint. .  I create a sed script with the lines \"2s/./C/<number>\" which command in \"sed\" substitutes the characters for C in the second line at specified index. So for each index I create such line, and then such script is run with \"sed\". .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP on NP"
    },
    {
      "id": "au_596482",
      "task": "Custom terminal function to change text case",
      "P-task": "custom termin function chang text case",
      "F_verb": "change",
      "P-body": "That is not too complicated: .   Copy the script below into an empty file, save it as \"change_case\" (no extension) in \"~/bin\" (you may have to create the directory). Make the script executable You may have to log out/in, especially if the directory did not yet exist (or alternatively, run: \"source ~/.profile\") Open a terminal window, test it by running the command: .  output: .    I tested it with all options from your question (upper, lower, sentence, custom) and all should work as your example. .  The script ",
      "P-tags": "text command-lin text-process",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "ul_193729",
      "task": "Set ionice for a multi-threaded application",
      "P-task": "set ionic multi-thread applic",
      "F_verb": "set",
      "P-body": "\"ionice\" can take a process group ID as an argument (\"-P\" switch), which, obviously, affects all processes (and threads) in the given process group. Once can find the process group ID by looking at the 5th field of \"/proc/<PID>/stat\" (or using \"ps\"). This setting is a bit more coarse than what I really wanted, but works well enough. .  ",
      "P-tags": "linux process multithread io ionic",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_23941087",
      "task": "Table not showing output in new line",
      "P-task": "tabl show output new line",
      "F_verb": "show",
      "P-body": "Iterate through $members and make an object for each one. This creates an empty array, loops through the computers in your text file, and in that loop it pulls a list of the local administrators, and for each one it creates a custom object just like you are doing, and it adds it to that array. .  ",
      "P-tags": "powershel format",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1342494",
      "task": "Cannot update Ubuntu 20.04 due to unresolvable dependencies",
      "P-task": "updat ubuntu 20 04 due unresolv depend",
      "F_verb": "update",
      "P-body": "Try running: .  \"sudo apt update && sudo apt autoremove && sudo apt --fix-broken install && sudo apt upgrade\" .  This will attempt to: .   update the package list autoremove unnecessary packages fix any broken installations and packages upgrade all packages that can be upgraded  ",
      "P-tags": "dpkg apt depend package-manag grub2",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_380280",
      "task": "Magento not seeing mcrypt in LAMP",
      "P-task": "magento see mcrypt lamp",
      "F_verb": "see",
      "P-body": "There seems to be an issue with the mcrypt package in that it isn't included in the available mods after being installed. .   https://stackoverflow.com/questions/19446679/mcrypt-not-present-after-ubuntu-upgrade-to-13-10 https://bugs.launchpad.net/ubuntu/+source/php-mcrypt/+bug/1241286  To fix, simply: .  If the last command doesn't work, do \"sudo service apache2 restart\" instead. .  ",
      "P-tags": "lamp php magento 13 10 14 04",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_47230019",
      "task": "awk - Compare columns from two files and replace text in first file",
      "P-task": "awk - compar column two file replac text first file",
      "F_verb": "compare",
      "P-body": "awk one-liner: .  The output: .  ",
      "P-tags": "gawk shell",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_171514",
      "task": "How to make man(1) use the entire terminal width?",
      "P-task": "make man 1 use entir termin width",
      "F_verb": "make",
      "P-body": "Ony my Linux systems, \"man 1 man\" mentions the \"MANWIDTH\" environment variable, which, now that I look it up, is also specified in the FreeBSD \"man(1)\" manpage: .  ",
      "P-tags": "freebsd termin man",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "su_550040",
      "task": "How to increase the time the operating system choice screen flashes up, to choose the OS",
      "P-task": "increas time oper system choic screen flash choos os",
      "F_verb": "increase",
      "P-body": "What you've done via those instructions is replaced the linux bootloader named grub, with the windows bootloader. Windows bootloader has no notion of being able to boot to other operating systems (I bet you're not surprised there), but the linux bootloader grub can boot to many types of OSes, so you want to keep grub installed instead. .  I think your original problem was the grub timeout was set too small. Once you get back into your linux partition, edit /boot/grub/grub.cfg, find the lines that say \"set timeout=1\" or something similar. That's the timeout in seconds for grub's OS selection screen to show before it automatically chooses the default option to boot to. Just change that to something larger. In my install, there's two lines: .  The timeout=-1 means leave the screen up (don't autoselect) after a failed boot, and the timeout=10 is the default wait. This file is owned by root so you'll have to use sudo to edit it. If you're unfamiliar with doing this, do this at the command line: \"sudo pico /boot/grub/grub.cfg\". .  You'll want to get your grub install back though. Boot to a live CD and follow instructions to reinstall grub to a hard drive. You might just want to google those, I don't remember them off the top of my head. .  ",
      "P-tags": "bio linux-mint mbr",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_501486",
      "task": "How do I add numbers from two txt files with Bash?",
      "P-task": "add number two txt file bash",
      "F_verb": "add",
      "P-body": "This is basic task many tools can solve; \"paste\" + \"awk\" combo seems exceptionally handy: .  ",
      "P-tags": "shell-script text-process numeric-data bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_236794",
      "task": "Linux: Command-line tool for easy change the actual wireless \u201cconnected to\u201d network?",
      "P-task": "linux : command-lin tool easi chang actual wireless connect network",
      "F_verb": "connect",
      "P-body": "Solution using the nmcli tool, included in most distros or easily installable via apt-get, yum ... etc : .  To show already-stored WiFi networks: .  Note the network is stored by a unique UUID identifier. .  To connect to any of these networks (example for \"Wireless-1\"): .  See the man page for more functions, like forget, disconnect, scan or connect to new (not yet stored) network. The \"nmcli\" tool is great: it can work with a specific wireless device (i.e: \"wlan0\") or with any of them in a generic manner (i.e: you just specify \"wifi\" and the tool makes in charge of establishing the connection). .  Info extracted from here. Thanks to @ThatGuy for the link. .  ",
      "P-tags": "wifi",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_18917363",
      "task": "Error when running a script (with a while Loop) in a script created background process",
      "P-task": "error run script loop script creat background process",
      "F_verb": "run",
      "P-body": "  You write to a file called \"swtich\" and then read to a file called \"switch\". That file doesn't exist, so the variable \"check\" ends up empty. .  Incidentally, why call \"more\"? That's only useful to view a file page by page. If you're piping the output, \"cat\" is equivalent. If \"more\" doesn't have a controlling terminal, which happens when you call \"test.sh\" in the background, \"more\" prints an extra line containing the file name, so its output  .  So you really must use \"cat\" and not \"more\". In bash, you can also write \"check=$(<switch)\".) .    Since \"$check\" is empty, the command \"[\" receives three arguments: \"=\", \"Running\" and \"]\". This is not valid syntax for the \"[\" command. .  Always put double quotes around variable substitution and command substitution: \"\"$check\"\", \"\"$(somecommand)\"\". If a \"$\" substitution occurs outside quotes, the result is split into separate words (0 words in your case, since the result was empty) and the words are interpreted as file glob patterns. This is almost never desirable, so always use double quotes unless you really have a list of glob patterns. .  \"check=$(cat switch)\" is actually safe, because in an assignment, a single word is expected on the right-hand side, so word splitting doesn't happen. However, you might as well write \"check=\"$(cat switch)\"\" for clarity. Also, the quotes are required if you write \"export check=\"$(cat switch)\"\". .  So we have: .  In bash (but not in sh), you can write \"[[ $check = Running ]]\" instead of \"[ $check = Running ]\". That's because \"[[ \u2026\u00a0]]\" is special syntax, unlike \"[\" which is a built-in command with no special parsing. However, you would need double quotes if the variable was on the right-hand side of the \"=\" operator, because the right-hand side of \"=\" inside \"[[ \u2026\u00a0]]\" is a pattern. Rather than learn such complicated rules, just use double quotes all the time and you'll be fine. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_26782078",
      "task": "Run parameters in a Powershell script from a batch file",
      "P-task": "run paramet powershel script batch file",
      "F_verb": "run",
      "P-body": " The problem was the space between the first, and second variable of parameter -Apps. .  Should work now. .  ",
      "P-tags": "powershel batch-fil command-line-argu",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_235158",
      "task": "how to check the filesystem type of a logical volume",
      "P-task": "check filesystem type logic volum",
      "F_verb": "check",
      "P-body": "Same as you would with any other block device. e.g. .  If \"/dev/vg1/lv1\" is a symbolic link, you'll also need \"file\"'s \"-L\" (aka \"--dereference\") option to de-reference it (i.e. follow it to the real device node it's pointing to): .  BTW, it's OK to use \"-L\" on a regular file. .  If it's ext4, it'll say something like: .  Alternatively, you could run \"blkid /dev/vg1/lv1\". That would report something like: .  From \"man file\": .   -s, --special-files .  Normally, file only attempts to read and determine the type of argument files which stat(2) reports are ordinary files. This prevents problems, because reading special files may have peculiar consequences. Specifying the -s option causes file to also read argument files which are block or character special files. .  This is useful for determining the filesystem types of the data in raw disk partitions, which are block special files. This option also causes file to disregard the file size as reported by stat(2) since on some systems it reports a zero size for raw disk partitions. .   ",
      "P-tags": "hard-disk partit lvm",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "au_500870",
      "task": "Looking for a countdown app where I can set value in days",
      "P-task": "look countdown app set valu day",
      "F_verb": "look",
      "P-body": "You can use Screenlets: .   .  ",
      "P-tags": "14 04 xubuntu",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V for NP where S"
    },
    {
      "id": "so_68358789",
      "task": "Using bash to get Two variables in for-loop form two different lists",
      "P-task": "use bash get two variabl for-loop form two differ list",
      "F_verb": "get",
      "P-body": "Define two arrays such that they have the same indices, then iterate over the indices of one array: .  ",
      "P-tags": "for-loop loop bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_444365",
      "task": "Why is yum picking a lower version to install",
      "P-task": "yum pick lower version instal",
      "F_verb": "install",
      "P-body": "See the epoch (the \"1\" in \"1:1.9.4-21\"), it overrides your (default) epoch \"0\" packages. .  The epoch was introduced in rpm packages precisely to be able to \"fix\" version numbers that go backwards. Use with extreme caution. .  Besides, the RHEL/Centos packages probably include lots of local fixes/tweaks. I'd suggest you start with the official source packages and tweak those, replacing the sources with newer versions as needed. .  ",
      "P-tags": "cento yum",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_52397191",
      "task": "/usr/bin/x86_64-linux-gnu-ld: cannot find?",
      "P-task": "usr bin x86_64-linux-gnu-ld : find",
      "F_verb": "find",
      "P-body": "The \"-l\" option is for linking dynamic libraries (like \"libkeccak.so\"). Static libraries are linked into the executable already if they're in one of the \"standard\" directories, so there's no need to provide the option \"-lkeccak\". .  If you want to explicitly tell GCC to link a static library, .  ",
      "P-tags": "makefil c ubuntu ld",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_41832641",
      "task": "Parsing an HTTP response from a curl POST",
      "P-task": "pars http respons curl post",
      "F_verb": "parse",
      "P-body": "Pipe the JSON output to python \"json\" to grab the \"id\" value you need, and use bash command substitution to assign the result to your \"NETWORK_ID\" environment variable. .  ",
      "P-tags": "json curl bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP from NP"
    },
    {
      "id": "so_65881231",
      "task": "Create a command on crontab that stream editor and rewrite a file every 15 minutes",
      "P-task": "creat command crontab stream editor rewrit file everi 15 minut",
      "F_verb": "create",
      "P-body": "The following crontab would run your script every 15 minutes: .  With \"script\" reading .  The trick we use here is to do revere substitution. The file \"example.conf\" always contains only one string which is also in \"file_names.txt\". So if you attempt to substitute from the last to the front you will only do a single substitution. .  We use \"awk\" here to build a \"sed\"-script and \"tac\" to reverse it so that we only have a single match: .  If we do a \"sed\" with the above script, we will always end up with \"pfg424T\" (the last entry) as it will find a single match (assume we are in the third entry \"pfg068T\"), so sed will perform every substitution after that. However, when we reverse the order (using \"tac\"), \"sed\" will only find a single match. .  ",
      "P-tags": "cron sed bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP that S"
    },
    {
      "id": "so_33617348",
      "task": "Unable to reset mysql password for my Ubuntu machine",
      "P-task": "unabl reset mysql password ubuntu machin",
      "F_verb": "reset",
      "P-body": "Try: .  \"sudo /usr/sbin/mysqld --skip-grant-tables --skip-networking --user=mysql\" .  ",
      "P-tags": "ubuntu mysql",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP for NP"
    },
    {
      "id": "so_35577845",
      "task": "How to convert an INI file into an CSV file",
      "P-task": "convert ini file csv file",
      "F_verb": "convert",
      "P-body": "In Python you can use the ConfigParser library for reading the INI file and the csv library for writing a comma separated file. I wrote below a small script \"ini2csv.py\" that you can use to handle your conversion using the following command:  .  Here is the script: .  I tested it with the link you provided in your question and it appears to work as expected. .  ",
      "P-tags": "ini csv python bash export-to-csv",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP"
    },
    {
      "id": "so_12136948",
      "task": "Why does shell ignore quoting characters in arguments passed to it through variables?",
      "P-task": "shell ignor quot charact argument pass variabl",
      "F_verb": "ignore",
      "P-body": "Why When the string is expanded, it is split into words, but it is not re-evaluated to find special characters such as quotes or dollar signs or ... This is the way the shell has 'always' behaved, since the Bourne shell back in 1978 or thereabouts. .  Fix In \"bash\", use an array to hold the arguments: .  Or, if brave/foolhardy, use \"eval\": .  On the other hand, discretion is often the better part of valour, and working with \"eval\" is a place where discretion is better than bravery. If you are not completely in control of the string that is \"eval\"'d (if there's any user input in the command string that has not been rigorously validated), then you are opening yourself to potentially serious problems. .  Note that the sequence of expansions for Bash is described in Shell Expansions in the GNU Bash manual. Note in particular sections 3.5.3 Shell Parameter Expansion, 3.5.7 Word Splitting, and 3.5.9 Quote Removal. .  ",
      "P-tags": "bash expans quot syntax variabl",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP in NP"
    },
    {
      "id": "so_47265200",
      "task": "Use sed to find and replace a number following by its successor in bash",
      "P-task": "use sed find replac number follow successor bash",
      "F_verb": "replace",
      "P-body": "with \"awk\" .  with appropriate separator setting, print the record when second field is not +1.  .  \"RS\" is the record separator and \"ORS\" is the outpout record separator. .  test: .  ",
      "P-tags": "oper linux sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "so_32093775",
      "task": "Create an bash alias to link change directory in terminal",
      "P-task": "creat bash alia link chang directori termin",
      "F_verb": "create",
      "P-body": "Or add this to your .bashrc: .  and you can use \"cd project1\" from everywhere. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_147376",
      "task": "Calculate relative positions in strings",
      "P-task": "calcul rel posit string",
      "F_verb": "calculate",
      "P-body": "A \"perl\" solution: .  How does it work .   First two lines print the original entry. \"for $pos_ss (split \",\",$F[5])\": we split field 6, get each index wanted in simple string. \"$char = substr($F[3],$pos_ss-1,1)\": get the character at given index in simple string. \"@cs = split //,$F[1]\": we get all characters in complete string, save them to an array. \"@cs_idx = grep {$cs[$_] eq $char} 0..$#cs\": get all indexs in array \"@cs\", which value equal \"$char\". \"push @res,++$cs_idx[$pos_ss-1]\": save the index we wanted to array \"@res\". Last two lines just print the result we got and empty \"@res\" array for next use.  ",
      "P-tags": "text-process",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP"
    },
    {
      "id": "au_157688",
      "task": "How to keep skype-wrapper in messaging menu after closing it?",
      "P-task": "keep skype-wrapp messag menu close",
      "F_verb": "keep",
      "P-body": "The \"/usr/share/indicators/messages/applications\" directory holds a list of text files each containing the path to the desktop launcher of the application the text file is named after. .  To add Skype-Wrapper, simply write following command (all one line): .  \"echo \"/usr/share/applications/skype-wrapper.desktop\" | sudo tee /usr/share/indicators/messages/applications/skype-wrapper\" .  This is, of course, assuming that the Skype-Wrapper launcher is at \"/usr/share/applications/skype-wrapper.desktop\". .  Logout, log back in and you are set. .  ",
      "P-tags": "12 04 skype",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP after S_ING"
    },
    {
      "id": "so_64788944",
      "task": "No-op shell command that preserves $?",
      "P-task": "no-op shell command preserv",
      "F_verb": "preserve",
      "P-body": "The easiest would be to make use of a simple assignment. Instead of using \":\", do \"_rc=$?\". .  Using this variable \"_rc\", you have stored the exit status of the last executed command, whether this is \"condition\" or the last command in \"list-true\" or \"list-false\". .   The arguments in favour of this method is the low overhead of an assignment. The argument against is the need to at least rewrite \"list-post-if\" to make use of \"_rc\" instead of \"$?\". If the latter is not possible, or too tedious, you might concider to add a \"(exit $_rc)\" just after the conditional statement. This, however, requires a sub-shell, but it is only one.  ",
      "P-tags": "sh posix code-gener",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_41470470",
      "task": "Unix.error 31 write when using Functory module",
      "P-task": "unix error 31 write use functori modul",
      "F_verb": "write",
      "P-body": "The error you get is (type the following in the toploop)\u00b9: .  which means: Protocol wrong type for socket. So you have to examine how you initialize your socket. .  \u00b9 You can also count the exceptions in \"unix.mli\", knowing that the first one, \"E2BIG\", is \"0\". Emacs \"C-u 43 \u2193\" helps. .  ",
      "P-tags": "ocaml unix",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V when S_ING"
    },
    {
      "id": "su_1308888",
      "task": "Reliably identify a disk (not a partition) in Linux (Debian)",
      "P-task": "reliabl identifi disk partit linux debian",
      "F_verb": "identify",
      "P-body": "Use \"/dev/disk/by-id/\" anyway. The issue you link to looks to me like a rare hardware malfunction or something similarly bad. .  Compare .  to .  However on some of my systems the above command displays blank values; still you can try: .  I don't know much about WWN but serial numbers should be hardcoded in hardware. My point is, if any serial number changes for whatever reason then you may have bigger problems than a backup script that suddenly doesn't work. .   Note a serial number identifies a physical device no matter what its partition table is (or if there is one at all, study the term \"superfloppy\" and this question). If you want to identify partition tables themselves then these \"Disk Identifier\" UUIDs you discovered will be the right approach (note they are 128-bit UUIDs in GPT scheme but 32-bit optional signatures in MBR, example here). They are just few bytes on disk that can be changed, cloned, backed up. I haven't found any quick way to identify a device node by this type of identifier, other than browsing through available devices: .    \"/dev/disk/by-uuid\" [...] include partitions only (not disks). .   Well, it may include not even all of them because these UUIDs refer to structures inside partitions (like filesystems or swap), not to partitions themselves (and if you deal with superfloppy, it will be here as a whole disk). Each of these UUIDs is written somewhere inside its corresponding partition (or device, if superfloppy). These are identifiers you see when you invoke e.g. .  If you need partitions identifiers, they are in \"/dev/disk/by-partuuid/\". These are the same as in .  and they are stored in a corresponding partition table, not inside any partition. You can get a broader picture by running .  To identify a device that holds a partition with a given UUID, try: .  (\"sed\" just strips trailing digits here). This solution can be easily adapted to retrieve information from \"/dev/disk/by-uuid/\" if you need. .  ",
      "P-tags": "partition-recoveri linux debian backup",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "so_37287260",
      "task": "awk/sed join all lines and pass it to another program",
      "P-task": "awk sed join line pass anoth program",
      "F_verb": "join",
      "P-body": "It's better not to quote filenames manually because names can contain quotes as well, so you should properly escape them. .  One may write the filenames one by one, with each filename on its own line and then use xargs program to feed vlc with arguments: .  Admittedly, if your music collection contains files with '\\n' (newline) in its name (well, unlikely, but it could :) ), then you have to cope with the case, and use '\\0' as a record separator on each stage of processing: .  but usually it's an overkill. .  Also it should be mentioned that in unix like shells, unlike Microsoft Windows approach, programs do not parse their command line arguments because the latter are passed to programs in separated form. All splittings by whitespaces, handling quotings etc are performed by a calling side, usually a shell. This explains why vlc runs correctly when you simply copy a given line to shell and run it \"manually\". .  ",
      "P-tags": "awk sed bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "au_456382",
      "task": "How to run zsh and tmux with xterm-256color by default",
      "P-task": "run zsh tmux xterm-256color default",
      "F_verb": "run",
      "P-body": "Usually \"tmux\" should get the \"TERM\" parameter from your terminal emulator. So you could just set it to \"xterm-256color\" in your its configuration. .  If this does not work for some reason, you can start \"tmux\" like that .  The parameter \"-2\" forces \"tmux\" to assume 256-color support. Additionally you can set \"default-terminal\" in your `~/.tmux.conf .  ",
      "P-tags": "tmux zsh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_411121",
      "task": "Can I userdel a user without removing their home directory?",
      "P-task": "userdel user without remov home directori",
      "F_verb": "remove",
      "P-body": "If you don't provide the \"-r\" option to userdel, it should not remove the home directory: .  Notice that the \"-r\" option is in square brackets, indicating that it is an optional flag. .  Oracle man pages section 1M: System Administration Commands: userdel .  ",
      "P-tags": "solari home user useradd",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "su_559973",
      "task": "FFMpeg convert jpeg images to video",
      "P-task": "ffmpeg convert jpeg imag video",
      "F_verb": "convert",
      "P-body": "\"[mjpeg @ 0x233aea0] overread 8\" is an error that is thrown when \"ffmpeg\" tries to read a JPEG image (or a frame from an MJPEG stream) block-by-block, but there are still leftover bits. .  In that case, even though your images might be showing fine in other viewers, it's something FFmpeg can't (or won't) handle. To fix this you need to re-save the images, either as PNGs as you tried before, or as JPEGs. You can do that kind of batch conversion with ImageMagick, for example: .  This would re-save the JPEG files under the same name. Note that you'll lose quality in that process, so it's not ideal and I'd go with PNGs as intermediates as they're lossless. .  By the way: It's always a good idea to use the latest version of FFmpeg, which you can download as a static build (just download, extract, use), or compile yourself. The packages that come with Ubuntu are always outdated, and \u2013 depending on your Ubuntu version \u2013 not even the \"real\" FFmpeg, but the Libav fork (which is fine to use, but one should know the difference). .  Don't forget that the images need to have sequential names when you use the \"%07d.jpg\" syntax for \"ffmpeg\", without missing numbers. See also the documentation on the \"image2\" muxer for more options. .  ",
      "P-tags": "ffmpeg jpeg linux debian",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_86688",
      "task": "Periodically get new lines from file, possibly logrotated",
      "P-task": "period get new line file possibl logrot",
      "F_verb": "get",
      "P-body": "Assuming \"your-filter\" reads its data from stdin: .  That assumes \"your-filter\" just reads the data and doesn't attempt to \"lseek\" in it for instance. .  Now, to address the log rotation issue, if on Linux (where, contrary to most other systems, \"/dev/fd/n\" are symlinks to the actual files), with \"ksh\", \"bash\", \"zsh\", \"dash\", \"yash\" (most POSIX shells except the most pedantically POSIX ones like \"posh\" as \"-ef\" is not POSIX): .  Upon the log rotation, that would call \"your-filter\" twice, if you'd rather it being called once with the concatenation of the old and new: .  Now upon the log rotation, there may be a time when the old file.log has been renamed, but the new \"file.log\" not created yet, in which case the above will fail if it does the \"exec < file.log\" at that very moment. Then you could fix that with: .  So it carries on reading the old file until the new one shows up. .  \"command\" is needed to avoid \"exec\" to cause the shell to exit when it fails (as POSIX requires). It's not needed with \"zsh\" or \"bash\" when not in \"sh\" mode. .  Now, we sleep for 60 seconds in the loop, and \"your-filter\" might take a few seconds to run. If it's important for \"your-filter\" to be run every minute on average, with \"ksh\", \"bash\" or \"zsh\", you could change it to: .  With \"ksh93\" and \"zsh\", and provided your \"sleep\" accepts floating point arguments, you could run \"typeset -F SECONDS\". .  ",
      "P-tags": "log tail logrot syslog",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_7598017",
      "task": "Passenger is listing all files instead of running my Rails application",
      "P-task": "passeng list file instead run rail applic",
      "F_verb": "run",
      "P-body": "It doesn't work in this way. The \"ServerName\" must be a hostname. .  You must set \"ServerName transprintusa.com\", then use the \"Location\" or \"Directory\" directive to enable passenger when the request matches given location. .  See Deploying to a sub URI from the Passenger documentation. .  ",
      "P-tags": "ubuntu vhost passeng apach ruby-on-rail",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_48805752",
      "task": "how to stop jar file using process id and run it agin",
      "P-task": "stop jar file use process id run agin",
      "F_verb": "stop",
      "P-body": "Here's how you would use the answer you already received. .  You should not \"kill -9\" the process, because that prevents Java from doing any cleanups before terminating -- you should regularly use just \"kill\" unless you know there are bugs in the code which prevent this from working (and even then probably try a regular \"kill\" before bringing out the heavy artillery with \"kill -9\"). .  It's not clear from your question in which scenario you would kill it (do you want to kill it when you find that it's already running?) In any event, this is a very common FAQ -- please look for duplicates e.g. in the list of common questions in the Stack Overflow \"bash\" tag info page .  ",
      "P-tags": "ubuntu shell",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP S_ING"
    },
    {
      "id": "so_14392349",
      "task": "don't fail jenkins build if execute shell fails",
      "P-task": "fail jenkin build execut shell fail",
      "F_verb": "build",
      "P-body": "To stop further execution when command fails: .  \"command || exit 0\" .  To continue execution when command fails: .  \"command || true\" .  ",
      "P-tags": "linux jenkin unix",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V if S"
    },
    {
      "id": "ul_291258",
      "task": "shell script echo text name in for looping multiple texts",
      "P-task": "shell script echo text name loop multipl text",
      "F_verb": "echo",
      "P-body": " Output: .  ",
      "P-tags": "variabl shell-script dash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "so_22907986",
      "task": "java -version returning an error but bash profile is correct",
      "P-task": "java -version return error bash profil correct",
      "F_verb": "return",
      "P-body": " Am I missing something? .    Your bash profile is NOT correct. .  If \"/opt/java\" is your Java installation directory, then you need \"/opt/java/bin\" to be on your command search path; i.e. the \"PATH\" environment variable. .   ",
      "P-tags": "linux java bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_63071953",
      "task": "How to continue the script execution after a background process ending?",
      "P-task": "continu script execut background process end",
      "F_verb": "continue",
      "P-body": "Variable names have to be literal, you can't just use an expression as a variable name like you're doing. Also variable names can't have \"-\" in them, but that's a second problem) .  bash has associative array variables: you want .  ",
      "P-tags": "background-process loop bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP after S"
    },
    {
      "id": "su_444244",
      "task": "Can't get static IPs configured correctly",
      "P-task": "get static ip configur correctli",
      "F_verb": "get",
      "P-body": "The CRUX documentation has some configuration examples. .  EDIT: Set the broadcast explicitly in the \"ip\" command: .  According to the \"ip\" documentation, it does try to guess but it's probably best to eliminate moving parts. .  Then bring up the adapter with: .  Try doing a tcpdump (if you can) of traffic going out to your gateway: .  tcpdump host xxx.xxx.xxx.249 .  ",
      "P-tags": "linux network static-ip ip",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_9975043",
      "task": "Implementing correct inter-module synchronization in Linux kernel",
      "P-task": "implement correct inter-modul synchron linux kernel",
      "F_verb": "implement",
      "P-body": "Traditionally IRQ handling in Linux is done in two parts: .   So called \"upper-half\" is actual working in IRQ context (IRQ handler itself). This part must exit as fast as possible. So it basically checks interrupt source and then starts bottom-half.  .  \"Bottom-half\". It may be implemented as work queue. It is where actual job is done. It runs in normal context, so it can use blocking functions, etc.  .   If you only want to wait for IRQ in your worker thread, better to use special object called \"completion\". It is exactly created for this task.  .  ",
      "P-tags": "linux embed kernel-modul c driver",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_62833179",
      "task": "How to convert Date & Timsestamp from one format to another & Compare in Linux Shell Scripting",
      "P-task": "convert date timsestamp one format anoth compar linux shell script",
      "F_verb": "convert",
      "P-body": "You could convert the output into unix timestamp, i.e: .  And compare with the current time: .  To wrap up, you could do: .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP to NP in NP"
    },
    {
      "id": "ul_226089",
      "task": "How to install `service` command in a Stable Debian?",
      "P-task": "instal servic command stabl debian",
      "F_verb": "install",
      "P-body": "The \"service\" command is part of the sysvinit-utils package. .  Install it with: .  But most probably, it is already installed in \"/usr/sbin/service\". .  If it's missing in your \"$PATH\", add this line to your \"~/.bashrc\": .  ",
      "P-tags": "debian servic",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_37816644",
      "task": "Run bash command on aws instance using fog",
      "P-task": "run bash command aw instanc use fog",
      "F_verb": "run",
      "P-body": "Ok, I found out how to do it, firstly we should add our instance username (on aws default is ubuntu) and path to your key file:  .  Then, we finally can use \"ssh\" method: .  \"server.ssh(\"your command\")\" .  ",
      "P-tags": "fog amazon-web-servic bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "so_11856632",
      "task": "Run git gc on multiple repositories",
      "P-task": "run git gc multipl repositori",
      "F_verb": "run",
      "P-body": "You could try something like: .  This will find every directory matching \"*.git\" under \"/git\", \"cd\" into it, and run \"git gc\". .  ",
      "P-tags": "git bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_52166347",
      "task": "temporarily take ownership of a folder",
      "P-task": "temporarili take ownership folder",
      "F_verb": "take",
      "P-body": "I tend to use the NTFSSecurity module when dealing with filesystem permissions, it's well written and I've had good success with it so far. .  Note: You do need to install the module, if you're using a modern version of Powershell this is easy as you can just use \"Install-Module -Name NTFSSecurity\". If it's an older version you will need download and install the module manually. .   EDIT: .  The other option is to use \"Enable-Privileges\" to grant your account the privileges for \"Backup, Restore, and Security\". .  With these you will be able to edit the permissions without your own account having explicit permissions to the data. Use of these command is covered in the documentation in the link above. Be sure to \"Disable-Privileges\" after enabling them as it's not good practice to run with these all the time. .  ",
      "P-tags": "powershel windows-server-2012 powershell-4 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_34277698",
      "task": "Dynamically read and store values in variables in shell",
      "P-task": "dynam read store valu variabl shell",
      "F_verb": "read",
      "P-body": "You can grow the array dynamically at each step. Assume you start with the count, initialize the empty array and add elements one by one. .  works in version: Version AJM 93t+ 2010-06-21. .  This works with BASH in AIX .  ",
      "P-tags": "ksh sh shell",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "so_21739444",
      "task": "How to look for files contain a character in name",
      "P-task": "look file contain charact name",
      "F_verb": "look",
      "P-body": "This was some code I found worked better. .  ",
      "P-tags": "powershel net",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V for NP"
    },
    {
      "id": "so_58609977",
      "task": "Add numbers to end of every alternate line before bracket",
      "P-task": "add number end everi altern line bracket",
      "F_verb": "add",
      "P-body": "Could you please try following. .  OR if every line starts from \"[\" where you want to insert numbers and not with \"[tab\" then try following. .    Or with OP's attempt, in case you want to insert count for odd number lines then try following. .  ",
      "P-tags": "awk linux vim string sed",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_59289989",
      "task": "how to use split and substring and foreach to handle array",
      "P-task": "use split substr foreach handl array",
      "F_verb": "use",
      "P-body": "The example of your array is a bit ambiguous as I'm not sure exactly how it's structured. Assuming each record is just a string as you defined in your question, the code below may work for you. .  I split each element using \"space\" as a delimiter. I select the first and last element and I then join the elements back together to produce the string shown in your expected output. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_904142",
      "task": "How to convert Filezilla PPK to openssh sftp compatible key",
      "P-task": "convert filezilla ppk openssh sftp compat key",
      "F_verb": "convert",
      "P-body": "Thanks to the comment from Spas Spasov (@pa4080) I did get it going. .  This is what I did. .  Finally I needed to read the man page to use puttygen to convert the ppk. .  The command to perform the conversion was: .  Then I was able to use the key for ssh/sftp and sshfs. .  ",
      "P-tags": "sftp openssh filezilla ssh",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "au_123598",
      "task": "Why does dpkg give me a \"package was interrupted\" error?",
      "P-task": "dpkg give packag interrupt error",
      "F_verb": "give",
      "P-body": "Try running \"sudo dpkg --configure -a\" in a terminal and see if that helps.  .  ",
      "P-tags": "11 10 lock dpkg",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "ul_415454",
      "task": "Find and replace using files with regex",
      "P-task": "find replac use file regex",
      "F_verb": "find",
      "P-body": "\"Awk\" solution: .   \"NR==FNR{ ... }\" - processing the 1st input file i.e. \"FileB.txt\":  \"a[$1]=$3\" - capturing each 3rd field value \"$3\" into array \"a\" using the 1st field \"$1\" as array index/key \"next\" - jump to next record  \"$1 in a\" - while processing the 2nd input file (i.e. \"FileA.txt\"), check if the 1st field value \"$1\" occurs in array \"a\" keys:  \"$1=a[$1]\" - replace with replacement value    The output: .  ",
      "P-tags": "awk text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP using NP with NP"
    },
    {
      "id": "ul_414487",
      "task": "How to copy all files in directory recursively and unzip compressed files on fly",
      "P-task": "copi file directori recurs unzip compress file fli",
      "F_verb": "unzip",
      "P-body": "I would approach this as 3 separate steps, using \"$SOURCE\" and \"$DEST\" as your source and destination directories. .   Recreate the source directory structure in the destination directory .  \"find $SOURCE -type d | sed -e \"s~^$SOURCE~~\" | xargs -r -I dir mkdir -p \"$DEST\"/\"dir\"\" .  Move all files that don't need to be decompressed .  \"find $SOURCE -type f -not -name '*.gz' | sed -e \"s~^$SOURCE/~~\" | xargs -r -I file cp \"$SOURCE\"/\"file\" \"$DEST\"/\"file\"\" .  Decompress all compressed files into the destination directory .  \"find $SOURCE -type f -name '*.gz' | sed -e \"s~^$SOURCE~~\" | sed -e \"s~.gz$~~\" | xargs -r -I file bash -c 'gzip -dc \"'\"$SOURCE\"'\"/\"file\".gz > \"'\"$DEST\"'\"/\"file\"'\" .   That said, as a word of advice I would recommend using \"rsync -av\" to copy all the files and then \"find . -name '*.gz' -exec gunzip \\{\\} \\;\" in the destination directory to decompress the files. This is a far simpler approach with fewer potential pitfalls. The three steps above worked for me on a small test directory with a limited number of files and relatively simply filenames; YMMV for a more complex use case.) .  ",
      "P-tags": "zip shell-script find bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP on NP"
    },
    {
      "id": "so_4773300",
      "task": "Simplest way to script slowly sending data through a socket connection",
      "P-task": "simplest way script slowli send data socket connect",
      "F_verb": "send",
      "P-body": "Shell commands to echo a line at a time from a file to telnet: .  ",
      "P-tags": "script linux socket tcp",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP through NP"
    },
    {
      "id": "so_12433436",
      "task": "SVN update by executing TortoiseProc.exe in a script created in bash",
      "P-task": "svn updat execut tortoiseproc exe script creat bash",
      "F_verb": "update",
      "P-body": "Defining an alias for a directory change is not the same as executing that directory change. Also changing directory is not a good idea since then TortoiseProc would not know what directory you want to update. .  I'd recommend using \"TortoiseProc.exe\" full path or putting \"TortoiseSVN/bin\" in PATH. .  The error could be caused also by \"bash\" not finding \"START.EXE\". .  I was able to invoke by hand TortosieProc without \"START\" using the following line .  Notice how the \"path\" parameter has to be invoked by TortoiseProc and therefore has to follow Windows syntax. TortoiseProc complained if I used a UNIX style for the path. .  Tested on \"cygwin\", Windows 7, TortoiseSVN 1.7 .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V by S_ING in NP"
    },
    {
      "id": "ul_157241",
      "task": "Assign Subshell background process pid to variable",
      "P-task": "assign subshel background process pid variabl",
      "F_verb": "assign",
      "P-body": "\"bash\" shouldn't print the job status when non-interactive. .  If that's indeed for an interactive \"bash\", you can do: .  We want \"sleep\"'s stdout to go to where it was before, not the pipe that feeds the \"$pid\" variable. So we save the outer stdout in the file descriptor 3 (\"3>&1\") and restore it for \"sleep\" inside the command substitution. So \"pid=$(...)\" returns as soon as \"echo\" terminates because there's nothing left with an open file descriptor to the pipe that feeds \"$pid\". .  However note that because it's started from a subshell (here in a command substitution), that \"sleep\" will not run in a separate process group. So it's not the same as running \"sleep 20 &\" with regards to I/O to the terminal for instance. .  Maybe better would be to use a shell that supports spawning disowned background jobs like \"zsh\" where you can do: .  With \"bash\", you can approximate it with: .  \"bash\" outputs the \"[1] 21578\" to stderr. So again, we save stderr before redirecting to /dev/null, and restore it for the \"sleep\" command. That way, the \"[1] 21578\" goes to \"/dev/null\" but \"sleep\"'s stderr goes as usual. .  If you're going to redirect everything to /dev/null anyway, you can simply do: .  To redirect only stdout: .  ",
      "P-tags": "variabl subshel shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "so_46113583",
      "task": "customizing git diff output format (own function name for my files in chunk header)",
      "P-task": "custom git diff output format function name file chunk header",
      "F_verb": "customize",
      "P-body": "The solution is to define a custom hunk-header: .  You can adapt the regexp for more accuracy .  ",
      "P-tags": "git linux github",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V np"
    },
    {
      "id": "ul_167261",
      "task": "How do I perform the same set of commands within multiple subdirectories, in a numerical order?",
      "P-task": "perform set command within multipl subdirectori numer order",
      "F_verb": "perform",
      "P-body": " Notes: .   You can loop over a range of numbers by using the braces notation: .   You can also loop over an explicit list of items: .   You can change the directory so some place that depends on variables: .   The argument to the \"cd\" command is a directory specified relative to the current directory. After we have done our work in that directory, we want to change back to the parent_directory. There are many ways to deal with this but one simple way is to do that is to put the \"cd\" command and commands to be performed in that directory into a subshell, denoted by parens. After we exit the parens, the directory is automatically restored to what it was before. .   ",
      "P-tags": "shell-script",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP within NP in NP"
    },
    {
      "id": "so_24279941",
      "task": "how to print just filename without using __FILE__ in C",
      "P-task": "print filenam without use __file__ c",
      "F_verb": "print",
      "P-body": "In your C code, you might use instead of \"__FILE__\" the expression \"basename(__FILE__)\"; however, this has the disadvantage of calling \"basename\" at every occurrence. .  Alternatively, compile \"path/foo.c\" with a command like .  (you could have a generic \"make\" rule giving that : with GNU make use functions like \"basename\" and automatic variables ) .  then use \"BASE_FILE\" instead of \"__FILE__\" in your code. .  With GCC, you could use \"__BASE_FILE__\" instead of \"__FILE__\" .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_25834676",
      "task": "linux: how to remove file with this kind of name \"test\\download\\\"?",
      "P-task": "linux : remov file kind name test download",
      "F_verb": "remove",
      "P-body": "Try something like .  and read glob(7) and rm(1) .  ",
      "P-tags": "file linux ssh",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_44551459",
      "task": "spiting the values of CSV file if the content is also contains comma in bash or awk command",
      "P-task": "spite valu csv file content also contain comma bash awk command",
      "F_verb": "contain",
      "P-body": "You can use \"awk\" to swap out the delimiters (comma in this case) that occur within your double quotes with something else: .  Here awk is: .   Setting the field separator and output field separator to double quote (\"BEGIN{FS=OFS=\"\\\"\"}\") Looping through each field that it finds (\"{for(i=1;i<=NF;++i)\") Testing the field ordinal's mod 2 to see if it is 0 (\"if(i%2==0)\") If it is even then it swaps out the semicolons with pipes (\"gsub(/;/, \"|\", $i)\") Prints out the transformed record (\"{print $0}\")  In action: .   If you want to just pull out data in that last comma for later parsing then you can employ the same \"awk\" trick by setting the FS to a double quote, then just pull out the second to last field: .  It's a lot more simple here since we are only tackling a single field, so you can go right to the thing you are after.  .  ",
      "P-tags": "awk csv shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_521902",
      "task": "Grub 2.02 cannot see all drives",
      "P-task": "grub 2 02 see drive",
      "F_verb": "see",
      "P-body": "It looks like some of your disks aren't always getting detected in a reliable way. This suggests a possible hardware or firmware problem.  .  Check the health of your disks with Windows CrystalDiskInfo or Linux \"smartctl\" command. For example, to check disk \"/dev/sda\": .  If all your disks are good, see if your BIOS settings allow adding a short delay in the boot process, to allow your disks more time to spin up/reset before the BIOS attempts to detect them. .  ",
      "P-tags": "grub grub2",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "au_1113736",
      "task": "Unable to locate package libsslcommon2-dev in Ubuntu 18.04",
      "P-task": "unabl locat packag libsslcommon2-dev ubuntu 18 04",
      "F_verb": "locate",
      "P-body": "As user Olorin mentions the \"libsslcommon2-dev\" package was removed from Debian in 2017. You probably want to use the \"libssl-dev\" package instead: .  That's assuming you want to use the OpenSSL library in C, which will provide the header files. .  ",
      "P-tags": "apt 18 04 package-manag repositori",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_484149",
      "task": "How to convert shell output to JSON?",
      "P-task": "convert shell output json",
      "F_verb": "convert",
      "P-body": "With plain bash you could do: .  outputs .  ",
      "P-tags": "json python ifconfig shell",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_47027464",
      "task": "Get the IP from the list and ping using powershell",
      "P-task": "get ip list ping use powershel",
      "F_verb": "use",
      "P-body": "Try this: .  \"$log -like \"*Gateway*\"\" extracts Gateway lines. .  \"($g -split ':')[0]\" is \"Gateway\" .  \"($g -split ':')[1]\" is \"10.212.208.1\" .  \"Trim()\" is the trimming method of \"System.String\" .  \"$?\" contains the result of \"ping\". For more information, see about_Automatic_Variables .  If you would like to suppress the output of \"ping\", run \"ping $ip > $null\" .  If you would like to overwrite Gateway.txt, remove \"-Append\" switch parameter from \"Out-File\" cmdlet. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_65780988",
      "task": "How Can I Solve \"Failed To Source Bitbake\" With Xilinx Petalinux SDK",
      "P-task": "solv fail sourc bitbak xilinx petalinux sdk",
      "F_verb": "solve",
      "P-body": "First you need to investigate the error a little further, do this: .  It will return something similar to this below: .  Source the environment setup: .  followed by: .  In my case I can see more about the actual error: .  This is pointing to the /proc/sys/fs/inotify/max_user_instances that need to be increased. In my case I went from 128 to 256 by doing this: .  You need to become root with \"su\" and change the mac_user_instances. .  ",
      "P-tags": "ubuntu-16 04 petalinux bitbak xilinx",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP with NP"
    },
    {
      "id": "so_41288970",
      "task": "One-liner to move files that match a pattern to a new directory",
      "P-task": "one-lin move file match pattern new directori",
      "F_verb": "move",
      "P-body": "You can try with \"-regex\" option: .  ",
      "P-tags": "move linux unix bash",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP that S to NP"
    },
    {
      "id": "so_68828252",
      "task": "Need 'built-in.o' error when compiling U-Boot",
      "P-task": "need built-in error compil u-boot",
      "F_verb": "build",
      "P-body": "The problem is due to incomplete or corrupted downloading of U-Boot files. It should download properly. .  When compiling, the \"make ARCH=arm\" statement should be removed. .  ",
      "P-tags": "kernel build linux u-boot",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP when S_ING"
    },
    {
      "id": "ul_391492",
      "task": "mount error(13): Permission denied",
      "P-task": "mount error 13 : permiss deni",
      "F_verb": "mount",
      "P-body": "You need to ensure your \"/etc/fstab\" entry actually matches the \"mount\" command that works. .  You've shown that this works: .    However, in your \"/etc/fstab\" entry you've got an outdated \"sec=ntlm\" setting. Remove that and it's probable all will be well: .    Split here over two lines for readability. In \"fstab\" this must be a single line. .   As a little hint, whenever you get an error in this client-server kind of situation it's always worth checking the server error logs. The client will get told simply \"No.\", but the server will record the actual details, \"No such user\" or \"Password expired\" (just examples). This is true not only of SAMBA but also services such as \"ssh\". .  ",
      "P-tags": "raspberry-pi cif samba",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    }
  ],
  "2": [
    {
      "id": "ul_420190",
      "task": "how to send standard output and standard error to two files",
      "P-task": "send standard output standard error two file",
      "F_verb": "send",
      "P-body": "The task is to preserve the log output even if an application deletes the log file. .  By creating a second name for the log file with \"ln\", the data in the log will be available under two names. If one of the names is deleted, the data is still available under the other name. .  In a script: .  If \"$log\" does not previously exist, you will need to create it with \"touch \"$log\"\" before the call to \"ln\". .  This assumes that both names reside on the same filesystem. .  This answer does not assume that you're using \"bash\". It will work with any \"sh\"-compatible shell. .  ",
      "P-tags": "log linux exec rhel standard",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "so_47329964",
      "task": "A Perl system call must send exactly both characters single & double quote ' \"",
      "P-task": "perl system call must send exactli charact singl doubl quot",
      "F_verb": "send",
      "P-body": "If you want to execute a system command and don't have to use any shell syntax like redirects, it's usually better and safer to use the list form of \"system\": .  See perldoc -f system .  It's not clear from your question if you want to pass \"'\"XYZ\"'\" or \"\"XYZ\"\". .  ",
      "P-tags": "ksh cleartool perl shell",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "so_68589866",
      "task": "How to convert text file into json file using powerShell",
      "P-task": "convert text file json file use powershel",
      "F_verb": "convert",
      "P-body": "You could use \"switch -Regex -File\" to loop over the lines in the file and create an object as you go. Finally, convert this array of objects to JSON: .  Output: .  ",
      "P-tags": "json powershel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP using NP"
    },
    {
      "id": "ul_333967",
      "task": "Auto detect already open browser instead of opening default one",
      "P-task": "auto detect alreadi open browser instead open default one",
      "F_verb": "detect",
      "P-body": "The following Python program uses the psutil module to get a list of processes that belong to you, checks if a known browser is running, and if so, start that one again. If no browser could be found, a default one is started. I've added some comments to clarify what's going on in the script. .  Apart from the script itself, you'd still need to make this executable with chmod and make sure that the script is executed instead of launching a particular browser. .  ",
      "P-tags": "linux user-experi desktop-environ browser",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of S_ING"
    },
    {
      "id": "so_42095377",
      "task": "Appending two files based on common column",
      "P-task": "append two file base common column",
      "F_verb": "append",
      "P-body": "Something like this should work (assuming that entries in column-1 occur only once in both files): .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_50622933",
      "task": "Populating a variable from a script that needs to write to the terminal",
      "P-task": "popul variabl script need write termin",
      "F_verb": "populate",
      "P-body": "Don't rule out \"result=$(inner.sh)\" just yet. If you want to display interactive prompts or dialogs in the script, do those on stderr, and have it write only the answer to stdout. Then you can have your cake and eat it too: interactive prompts and the result saved to a variable. .  For example, \"dialog\" does exactly this if you use \"--output-fd 1\" to tell it to write its answer to stdout. It uses curses to draw a dialog to the alternate screen but does it all on stderr. .  (via Ask Ubuntu: How to get dialog box input directed to a variable?) .  The script you posted can be made to do the same thing. It currently writes to stdout. Put \"exec 3>&1 1>&2\" at the top so it'll write to stderr instead, and change the final \"echo ${options[$selected]}\" to \"echo ${options[$selected]} >&3\" to write the answer to stdout. That'd get rid of the need for the caller to juggle file descriptors. .   That said, prompts are not very UNIX-y. Consider eschewing interactivity entirely in favor of command-line arguments, configuration files, or environment variables. These options are better for power users who know how to use your script and want to automate it themselves. .   My main purpose here is to commit a \"latest-stable-config\" from a selection of my last backups, which in my opinion needs the human judgement of when to consider a backup as appropriately stable. .   The way I'd personally handle it is by writing a script with a couple of modes. Let's call it \"backups\". \"backups --list\" would display a list of backups. You pick one and then call \"backups --commit <id>\" which would commit the named config. \"backups\" with no arguments would display usage for the unfamiliar user. .  ",
      "P-tags": "sh bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP from NP that S"
    },
    {
      "id": "au_895703",
      "task": "unsafe map file /etc/mail/access.db: Permission denied",
      "P-task": "unsaf map file etc mail access db : permiss deni",
      "F_verb": "deny",
      "P-body": "The error you are facing is: .   hash map \"access\": unsafe map file /etc/mail/access.db .   means that \"sendmail\" identify potential security issue with the permission access to the file/folder. i.e. non-root user might be able to use it in order to gain \"root\" permission. .  Limiting access to the file/folder to root only: .   The file \"access.db\" is writeable to both user \"root\" and group \"root\".  The following will allow writing to this file only by \"root\" and not by group \"root\" and will make this file safer (as only \"root\" account will be able to write to this file) .   according to this old book \"/etc/mail\" directory should be owner by root.  In your case, the directory is owner by non root user. .  Updating \"/etc/mail\" permissions to be owned by root: .  Updating \"/etc/mail\" permissions to be read/write by root only: .  ",
      "P-tags": "sendmail email dkim",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "so_15374806",
      "task": "Converting a curve to a diagonal line with Cairo (in Avant Window Navigator on Linux)",
      "P-task": "convert curv diagon line cairo avant window navig linux",
      "F_verb": "convert",
      "P-body": "Info on drawing curves with Cairo can be found here. .  A four point Bezier curve looks like this: .   .  \"cairo_curve_to\" takes the current pen position for \"p0\" and its arguments are the next 3 points. .  So you could make \"cairo_curve_to\" draw a straight line by passing the same point for each argument. This is kinda wasteful but not a serious issue for you probably. .  It looks like if you pass the end position for both arguments of \"_line_from_to\" it will degenerate to drawing a straight line, as you want. e.g. if the call to that function was \"_line_from_to(cr, &x, &y, x2, y2)\" change it to \"_line_from_to(cr, &x2, &y2, x2, y2)\".  .  Alternatively, change the code for \"_line_from_to\" to be .  If you want more info on \"cairo_curve_to\", see this example. .  ",
      "P-tags": "desktop dock linux cairo c",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "so_22642704",
      "task": "Create string array from git status bash output",
      "P-task": "creat string array git statu bash output",
      "F_verb": "create",
      "P-body": "How about: .  \"files=(git status | grep '^\\s*modified:' | cut -f 2- -d :)\" .  Reading from inside out, that: .   Passes \"git\" status to \"grep\", which looks for lines with \"modified:\" on them singularly, then cuts everything after the colon on those lines, then finally puts that into an array assigned to \"$files\"  ",
      "P-tags": "git bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "so_32980230",
      "task": "How to read numbers from a text file in multiple columns",
      "P-task": "read number text file multipl column",
      "F_verb": "read",
      "P-body": " ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "su_1104872",
      "task": "Verifying linux mint iso image",
      "P-task": "verifi linux mint iso imag",
      "F_verb": "verify",
      "P-body": "I accessed the mirror, chose the stable branch, klicked on \"18\" and found the sha256sum.txt and the corresponding gpg file sha256sum.txt.gpg. https://ftp.heanet.ie/mirrors/linuxmint.com/stable/18/ .  You should definetily check them out yourself, but know you can compare them with PsFCIV .  ",
      "P-tags": "linux bittorr linux-mint iso-imag",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "su_1148390",
      "task": "SCP stalls at `sending command -v -t .`",
      "P-task": "scp stall send command -v -t",
      "F_verb": "send",
      "P-body": "There is \"~/.bashrc\", which might interfere with the remote commands (such as \"scp\"). .  If you want to do something like this, you should do it only on interactive shells (not to break scripts). You can add to the start of your \"~/.bashrc\": .  ",
      "P-tags": "linux ssh scp",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "ul_183992",
      "task": "Downloading images from csv file to a folder based on its id",
      "P-task": "download imag csv file folder base id",
      "F_verb": "download",
      "P-body": " ",
      "P-tags": "imag csv-simpl wget shell-script",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "ul_12976",
      "task": "How to move 100 files from a folder containing thousands?",
      "P-task": "move 100 file folder contain thousand",
      "F_verb": "move",
      "P-body": " That assumes file names don't contain blanks, newline (assuming the default value of \"$IFS\"), wildcard characters (\"?\", \"*\", \"[\") or start with \"-\". .  ",
      "P-tags": "mv file",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP from NP"
    },
    {
      "id": "au_875859",
      "task": "Accidentally removed /usr/share/applications",
      "P-task": "accident remov usr share applic",
      "F_verb": "remove",
      "P-body": "The applications still work because they are not located in the \"/usr/share/applicatons\" folder. That is the folder with the launchers of the applications. .  One way to get the largest amount back is to install Ubuntu on a temporary space such as a Pen Drive, then copy the \"/usr/share/applications\" folder to your working install. .  After that you will have all the default launchers. You can restore the launchers for the missing ones by reinstalling the particular applications. Use this command: .  Replace \"[specific applications]\" NOT including the bracket with the name of the application you want to restore to it's proper state. .  Once you have the apps listed in a file you can use this cli (or a variation of) to automate the install: .  ",
      "P-tags": "sudo lubuntu",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_19678772",
      "task": "Converting environment variable from double quoted string to single quoted",
      "P-task": "convert environ variabl doubl quot string singl quot",
      "F_verb": "convert",
      "P-body": " ",
      "P-tags": "batch-fil bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_38203246",
      "task": "find and verify contents in subfolders",
      "P-task": "find verifi content subfold",
      "F_verb": "verify",
      "P-body": "There may be a more integrated way, but here's my shot at it : .  Note that this \"find\" also returns the current directory. If you wish to avoid that, you might want to add a \"-mindepth 1\" option. .  Also to make it into a script, you might want to replace the \"find\" kocation \".\" by \"$1\" so you can specify the target more flexibly. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "au_217237",
      "task": "Run clementine minimised and playing",
      "P-task": "run clementin minimis play",
      "F_verb": "play",
      "P-body": "Create a playlist in Clementine. Then add the following commands into Startup Applications separately. .  ",
      "P-tags": "clementin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V"
    },
    {
      "id": "so_40729112",
      "task": "Shell script to take thread dump of a java process",
      "P-task": "shell script take thread dump java process",
      "F_verb": "take",
      "P-body": "For me this pipe works: .  Explanation: .  ps -eo pid,%cpu,comm : prints all processes with PID CPU usage and command name .  grep java : greps all java processes .  sort -nr -k2 : sorts the result numerical reverse by the second column .  head -n1 : prints the first row .  awk '{print $1}' : prints the first column .  xargs jstack : takes the input and uses it as argument for the jstack command .  ",
      "P-tags": "shell java-thread linux java",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_6995",
      "task": "How to enable ufw firewall to allow icmp response?",
      "P-task": "enabl ufw firewal allow icmp respons",
      "F_verb": "enable",
      "P-body": "ufw does not allow specifying icmp rules via the command line interface command. It does allow you to adjust your ruleset via its rules files, which are iptables-restore style files. .  ufw does allow certain icmp traffic by default including icmp echo reply, and this is already configured by default in \"/etc/ufw/before.rules\": .  If your host is not responding to ping, look in this file to make sure the above line is present and if that doesn't work, look at the pinging host and any firewalls between them. .  ",
      "P-tags": "10 04 firewal server",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_31888580",
      "task": "A better way to check if a path exists or not in PowerShell",
      "P-task": "better way check path exist powershel",
      "F_verb": "check",
      "P-body": "If you just want an alternative to the cmdlet syntax, specifically for files, use the \"File.Exists()\" .NET method: .   If, on the other hand, you want a general purpose negated alias for \"Test-Path\", here is how you should do it: .  \"notexists\" will now behave exactly like \"Test-Path\", but always return the opposite result: .  As you've already shown yourself, the opposite is quite easy, just alias \"exists\" to \"Test-Path\": .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_53697280",
      "task": "sed: couldn't write 26 items to stdout: Broken pipe",
      "P-task": "sed : write 26 item stdout : broken pipe",
      "F_verb": "write",
      "P-body": "As @KamilCuk said in a comment, this is happening because \"head -10\" only reads the first 10 lines from the pipeline (plus maybe some input buffering), and then closes it; if the input is big enough, this happens before \"sed\" has written everything into the pipe (and the pipe's buffer isn't big enough to absorb the extra). So whether this happens or not depends on the input size, OS and its parameters (which determine the pipe's characteristics), \"sed\"'s behavior on having its output dropped, etc. Just changing things up a bit may be enough to avoid the problem, for example: .  And here's one that will avoid the error: .  The way this works is it tells \"sed\" to discard lines 11 through the end of input (\"$\"), but since it discards them after reading them (rather than never reading them in the first place, like \"head -10\"), \"sort\"'s entire output gets read and no error occurs. .  BTW, as @triplee pointed out, using \"cat\" at the beginning of the pipeline is useless; you should have \"awk\" read the file directly, like this: .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP"
    },
    {
      "id": "so_28925649",
      "task": "Determine the correct /dev/usb/lp*",
      "P-task": "determin correct dev usb lp",
      "F_verb": "determine",
      "P-body": " ",
      "P-tags": "print usb linux",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_3612257",
      "task": "Bash scripting: Deleting the oldest directory",
      "P-task": "bash script : delet oldest directori",
      "F_verb": "delete",
      "P-body": "This is not pretty but it works: .  ",
      "P-tags": "directori delete-directori file-io bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_21741803",
      "task": "Powershell SecureString Encrypt/Decrypt To Plain Text Not Working",
      "P-task": "powershel securestr encrypt decrypt plain text work",
      "F_verb": "encrypt",
      "P-body": "What is with the backtick in the \"$BSTR = ...\" line? I agree with Graham above. If I remove the backtick it work just fine: .  Outputs: .  You're not trying to run this on something like Windows RT or some other PowerShell configuration where the language is restricted - are you? .  ",
      "P-tags": "powershel encrypt",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V to NP"
    },
    {
      "id": "au_881636",
      "task": "Disabling ntp.service for the boot, since it takes a long time",
      "P-task": "disabl ntp servic boot sinc take long time",
      "F_verb": "disable",
      "P-body": "Network Time Protocol: .   NTP- is a protocol which runs over port 123 UDP at Transport Layer and allows computers to synchronize time over networks for an accurate time. While time is passing by, computers internal clocks tend to drift which can lead to inconsistent time issues, especially on servers and clients logs files or if you want to replicate servers resources or databases. .   Commands: .   Stop: .   Start: .   Disable at start-up: .   Enable at start-up: .    Source: .  http://www.tecmint.com/install-ntp-server-in-centos/ .  ",
      "P-tags": "boot",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP for NP"
    },
    {
      "id": "so_48163822",
      "task": "How to get a version string from a website and compare it?",
      "P-task": "get version string websit compar",
      "F_verb": "compare",
      "P-body": "I suggest using the \"[version]\" type accelerator to make the comparison. For example: .  The Version accelerator converts the version string in to a System.Version .NET class object: .  With which you can then do comparisons using all the standard comparison operators. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "su_1662778",
      "task": "Linux - accidentally used dd on a LUKS encrypted drive, is there a way to recover?",
      "P-task": "linux - accident use dd luk encrypt drive way recov",
      "F_verb": "use",
      "P-body": "There is no hope in recovering LUKS container if there is no LUKS header backup. .  Frankly, the answer is contained in the first sentence, but I can provide more information to explain the situation. LUKS encryption explaining simply works the following way: some initial MB (actual size depends on LUKS version and configuration) of partition are allocated for LUKS header, and the rest of the partition - for the data (root partition, or home partition, etc). The LUKS header 'contains' the 'master' password which is used to encrypt the data. This master password is generated by LUKS (to be 'big' and 'strong') when partition is encrypted at first time. The master password is 'protected' by 'key slot password' - password which user actually types to decrypt the drive. In short, LUKS header contains master password which is protected by 'user' password. So, if LUKS header is gone, the master password is also gone, so there is no way to decrypt the data - even if you still know 'user' password. .  Regarding 'LUKS.mod' output from grep - this looks like the name of grub \"LUKS.mod\" module stored in the FAT table of EFI partition. This output shows that the boot partition (which is usually unencrypted) happens to be in the first 1G of disk which you query with the command \"head -c 1G /dev/sda | hexdump -C | grep LUKS\". This information does not help to solve the problem. .  ",
      "P-tags": "dd partit linux partition-recoveri luk",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_53505660",
      "task": "Copy file to a folder based on folder created from file",
      "P-task": "copi file folder base folder creat file",
      "F_verb": "create",
      "P-body": "IMO you are overcomplicating things, to append the name without extenson simply \"Join-Path $TargetPath $_.BaseName\" .  To reduce redundancy with same long pathes use the variable you already defined.  .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V from NP"
    },
    {
      "id": "ul_21193",
      "task": "How to run a GUI program as a different user (Debian)?",
      "P-task": "run gui program differ user debian",
      "F_verb": "run",
      "P-body": "First off, don't use \"sudo\" or \"su\" to change users to run a graphical process, or you're liable to have problems down the line (\"~/.ICEauthority\" changing owner is a notable issue). Instead, create a shortcut that uses the following command: .  \"gksu\" launches a graphical prompt for the user's password, and upon entering the correct password, launch the application as the user specified. .  ",
      "P-tags": "gui su debian root sudo",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP"
    },
    {
      "id": "so_15292414",
      "task": "Why echo fails on element of an array?",
      "P-task": "echo fail element array",
      "F_verb": "echo",
      "P-body": "You need to capture the output of echo into \"( )\": .  or  .  Or dispense with the \"tr\" altogether: .  by using substitution in the expansion: \"${var//from/to}\" with \"\\/\" escaped as the \"from\". Or better still (more robust), dispense with the sub-process altogether: .  ",
      "P-tags": "array script echo bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP on NP"
    },
    {
      "id": "so_48810135",
      "task": "How do I populate an array with the output of a function that sets a global variable?",
      "P-task": "popul array output function set global variabl",
      "F_verb": "populate",
      "P-body": "If you don't want parallelization (and thus a subshell whose scope gets lost), the alternative is buffering. Bash not doing that for you makes it explicit and visible that storage is being used, and where your data gets stored. So: .  To automate this kind of pattern, I'd suggest something like: .  ...thereafter: .  ",
      "P-tags": "array side-effect pass-by-refer bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP that S"
    },
    {
      "id": "ul_145289",
      "task": "How can I count the number of words in a file whilst editing the file in vim",
      "P-task": "count number word file whilst edit file vim",
      "F_verb": "count",
      "P-body": "You can count words and lines inside \"vi\" using \"vi\"'s own counter: .  Press g and then CTRL-g. Then the bottom line look for example like this: .  Or use \"vi\"'s method to call shell commands: .  This calls the save (\":w\") command first and then \"wc -w\" and shows the output. Example: .  Press Enter to go back to \"vi\". .  ",
      "P-tags": "vi vim",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP whilst S_ING"
    },
    {
      "id": "so_52664082",
      "task": "Need Azure powershell command to get the Azure Kubernetes Service",
      "P-task": "need azur powershel command get azur kubernet servic",
      "F_verb": "get",
      "P-body": "you could use \"get-azurermresource\" with a \"where-object\" to filter down results: .  but you'd have to create a loop around all subscriptions. .  or you could use new AzureRmGraph module: .  ",
      "P-tags": "azur powershel azure-ak azure-powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_64980479",
      "task": "How to run a PowerShell script before my .NET project is transfered into memory and built?",
      "P-task": "run powershel script net project transfer memori built",
      "F_verb": "run",
      "P-body": "\"BeforeBuild\" target happens after compilation happens, so your code will already be compiled by then... to achieve the desired functionality, you should try using \"BeforeCompile\" target: .  See this Microsoft Docs link for more info .  ",
      "P-tags": "powershel msbuild c net",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP before NP into NP"
    },
    {
      "id": "so_26359806",
      "task": "How to use an alias on server with JSch?",
      "P-task": "use alia server jsch",
      "F_verb": "use",
      "P-body": "The correct solution is really to not use aliases at all; they are intended as a convenience for interactive use. If you have a complex alias which you would like to use noninteractively, convert it to a regular shell script, save the file in your \"$PATH\", and mark it as executable. Or convert it to a function. Even for interactive use, functions are actually superior to aliases, and work in noninteractive shells, too. .  Having said that, you can always wing it. The command you execute could be, for example, .  You may need to smuggle a newline into that command line if you need to explicitly \"source\" the alias definition before you can use it; there is a caveat in the manual about this. Do read all of it, and especially the last sentence.) .  Of course, for something this simple, the proper solution is to just run the standard command \"ls -l\" and forget about the alias. It's better for portability, too; while many sites have this alias, it's by no means guaranteed to exist. Personally, the first thing I do when I set up an account is remove these \"de facto standard\" aliases.) .  ",
      "P-tags": "bash linux alia java jsch",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP with NP"
    },
    {
      "id": "so_18062403",
      "task": "Cannot ping google.com from Ubuntu terminal behind a proxy server",
      "P-task": "ping googl com ubuntu termin behind proxi server",
      "F_verb": "ping",
      "P-body": "The usual reason for a proxy server is to isolate internal machines, and force them out through a central point in order to manage bandwidth, content and/or security concerns. Organizations who employ this mechanism will often disable routes from internal machines directly outside. .  In this configuration, you are not truly connected to the internet, just the intranet which includes a server that proxies data from the internet to the intranet. .  \"wget\" can work, if you set up the \"http_proxy\" environment variable, and perhaps add the \"--proxy-user\" and \"--proxy-password\" parameters. It is, in fact, a royal PITA. .  \"ping\" will not work, if your network admin has disabled direct access to the larger network. To get \"ping\" working, you'll have to petition to have an exception for your workstation/server to be granted a direct route to the internet. .  A technical explanation would be really appreciated. .  Your network admin has disabled direct access to the internet, probably by dropping packets that are headed outside the intranet. .  ",
      "P-tags": "proxy-serv ubuntu proxi ping",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_642390",
      "task": "How to list readline variables with their current value",
      "P-task": "list readlin variabl current valu",
      "F_verb": "list",
      "P-body": "You seem to be looking for \"bind -V\": .  As far as I can see, no variable name includes the whole name of a different variable (e.g. there is no \"show-all\" variable that will also match \"show-all-if-unmodified\" when used as a non-anchored pattern), nor any special character in the context of regular expressions. Hence it should be safe to define \"bind -V | grep\" as a shell alias or function. .  ",
      "P-tags": "readlin autocomplet command-lin bash",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP with NP"
    },
    {
      "id": "so_57352537",
      "task": "How to extract filename inside the folder based on pattern in PowerShell",
      "P-task": "extract filenam insid folder base pattern powershel",
      "F_verb": "extract",
      "P-body": "I'd use a regex pattern for this where the filename parts are joined with the \"OR\" symbol \"|\": .  If you're on PowerShell version below 3.0, use this instead of the \"-File\" switch: .  Output: .    ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP inside NP in NP"
    },
    {
      "id": "au_447772",
      "task": "How to tell which parameter is being supplied to a command with a redirectioin operator?",
      "P-task": "tell paramet suppli command redirectioin oper",
      "F_verb": "tell",
      "P-body": "You are using two different things here and should be using a third. Let's see: .   \"|\" : This is the pipe operator, it serves to pass the output of one process as input to another: .  This runs the program \"foo\" and passes its output as input to the program \"bar\". .  \">\",\"<\",\">>\" and \"<<\": These are the redirection operators, they serve to send data to/from files: .   \"foo > bar\" : runs the program \"foo\" and saves its output to the file \"bar\", overwriting1 its contents and creating it if it does not exist. .  \"foo >> bar\" : runs the program \"foo\" and saves its output to the file \"bar\", appending to its contents and creating it if it does not exist. .  \"foo < bar\" : runs \"foo\", telling it to read input from the file \"bar\".  .  The \"<<\" is a special case, since there is no point in \"appending\" input to a command, the \"<<\" is primarily (exclusively AFAIK) used for Here Documents: .  The construct \"<< SomeStringHere > Out.file\" will redirect all text written until it encounters the ending string (\"EOF\" in the example above) to the target file. Here docs allow you to easily format multi-line strings and include variables and special characters. .   The \"<<<\" operator, the Here String, is like a Here Document but it expands variables. So, for example: .  The command above is equivalent to \"echo \"$bar\" | grep foo\". .  What you are actually looking for is called process substitution and is another way to pass the output of a command to another. It consists of \"<(command)\". .  So, for your \"at\" example, you could do .  The above works because process substitution actually creates a file (read the link above for more details) and it is the file descriptor of that file that is passed with \"<\" to \"at now\". .    1 The default behavior is to overwrite, this can be modified by setting the \"noclobber\" option to bash. If set, \"echo foo > bar\" will fail if \"bar\" exists. In that case, it can be forced using \"echo foo |> bar\" instead. See section 3.6.2 here. .  ",
      "P-tags": "command-lin bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V which S with NP"
    },
    {
      "id": "au_730908",
      "task": "WiFi disconnects for few seconds and resumes",
      "P-task": "wifi disconnect second resum",
      "F_verb": "disconnect",
      "P-body": "You need an internet connection: .  Run the following command: .  install build-essential and linux-headers .  install or reinstall wpa_supplicant .  install b43 firmware .  and .  load the driver .  and  .  You can reboot .  ",
      "P-tags": "broadcom wireless",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V for NP"
    },
    {
      "id": "so_26069409",
      "task": "running ec2config.exe -sysprep remotely using powershell",
      "P-task": "run ec2config exe -sysprep remot use powershel",
      "F_verb": "run",
      "P-body": "Well, that output suggests that it IS running that command. The \"-Passthru\" parameter of \"Start-Process\" pipes the \"Process\" object to the pipeline, and it won't wait for the process to terminate. .  I guess the problem is that you want the command to wait while the process completes so you can do the next job, viz restart the computer and image it. If you want to wait for the process to complete you might find it easier to just use \"invoke-expression\" or just the \"&\" operator to run the \"Ec2Config.exe\" command. .  ",
      "P-tags": "amazon-ec2 powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_179976",
      "task": "How to access the contents of a file that is used as an argument when running a bash script?",
      "P-task": "access content file use argument run bash script",
      "F_verb": "access",
      "P-body": " A non-interactive shell will treat any redirection from a file that cannot be read or that does not exist when associated w/ a special builtin as a fatal error and exit immediately with a meaningful diagnostic message written to stderr. So either your parameters are valid, readable files and the above statement will do nothing useful until you replace the \": ...\" part w/ something useful, or the user has provided an invalid parameter and the script exits meaningfully. .  When you do... .  The \"in ...;\" bit is an optional statement in the syntax which enables you to substitute a parameter set for the default set - which is your argument list. .  So... .  ...is probably what you're looking for, here. .  ...where the shell will iteratively assign to stdin and validate as readable files any arguments provided your script for all commands that follow the \"exec\" statement until all parameters are exhausted and the \"for\" loop is \"done\". If it cannot do this then it will format and print your error message for you in a standard form to which the user is already accustomed. .  ",
      "P-tags": "script paramet file bash",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP that S when S_ING"
    },
    {
      "id": "ul_595422",
      "task": "How can I run a Windows program without granting it any Internet access?",
      "P-task": "run window program without grant internet access",
      "F_verb": "run",
      "P-body": "You could unshare the network namespace: .  ",
      "P-tags": "wine",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without S_ING"
    },
    {
      "id": "su_767430",
      "task": "Can 'at' command keep on working after ssh connection broke?",
      "P-task": "command keep work ssh connect broke",
      "F_verb": "keep",
      "P-body": "Yes it would. The at command places the script in a file in \"/var/spool/cron/atjobs\", which regularly get checked by the \"atd\" daemon. .  ",
      "P-tags": "linux ssh",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V on S_ING after NP"
    },
    {
      "id": "ul_552052",
      "task": "SSH add key to known_hosts from ssh-keyscan",
      "P-task": "ssh add key known_host ssh-keyscan",
      "F_verb": "add",
      "P-body": "The \"|1|b64|b64\" format in known_hosts is a hashed hostname; see \"HashKnownHosts\" in \"man 5 ssh_config\" and \"-H\" in \"man 1 ssh-keygen\". Using this format is optional; if you want it, see \"-H\" in \"man 1 ssh-keyscan\" .  Note that if anyone intercepts your first connection from a given machine to what you think is the correct address (your 100.101.102.103) they can supply a fake key and steal and/or alter the data you send and receive on that machine. .  ",
      "P-tags": "openssh ssh",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP from NP"
    },
    {
      "id": "so_32672654",
      "task": "How to run python script only once in a specific day of the week in bash",
      "P-task": "run python script specif day week bash",
      "F_verb": "run",
      "P-body": "What you need is cronjob: .  Start by adding a shebang line on the very top of your python script. .  Make your script executable with chmod +x .  And do a \"crontab -e\" and add \"0 0 * * 2,5,0 /path/to/my/script/myscript.py\" .  2, 5, 0 for every Tuesday, Friday, Sunday. .  ",
      "P-tags": "python bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_17705974",
      "task": "Remove the last page of a pdf file using PDFtk?",
      "P-task": "remov last page pdf file use pdftk",
      "F_verb": "remove",
      "P-body": "This will create the \"outfile.pdf\" with all but the last page in \"infile.pdf\" .  Explanation of parameters .   \"infile.pdf\" is the original pdf file \"cat\" is the operation \"1-r2\" is the page range    You can reference page numbers in reverse order by prefixing them with the letter r. For example, page r1 is the last page of the document, r2 is the next-to-last page of the document, and rend is the first page of the document. You can use this prefix in ranges, too, for example r3-r1 is the last three pages of a PDF. .      \"output\" will output it to a specific file \"output.pdf\" is the output pdf file  More examples are here: https://www.pdflabs.com/docs/pdftk-cli-examples/ .  ",
      "P-tags": "pdftk linux pdf",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "so_56266114",
      "task": "Read Write to Memory space",
      "P-task": "read write memori space",
      "F_verb": "read",
      "P-body": "Your problem is here: .  You're casting your \"(void *) weights\" as a \"(unsigned char *)\", then storing the value of \"conv.lw\" at that pointer location. But by doing that type-cast, you've explicitly told your compiler that you only want to write a single \"unsigned char\", so it quite happily does that with the least-significant byte of \"conv.lw\". Similarly, when you read it back, you again cast \"weights\" as an \"(unsigned char *)\" and so you're only reading a singe byte form that location.  .  If you instead did something like: .  you'd be writing and reading all the bytes of \"conv.lw\".  .  There are also a few reasons which make what you're trying to do non-portable, including: \"unsigned long\" is only typically only 4 bytes on a 32-bit architecture, and dereferencing pointers cast from other types is (at least sometimes) undefined behavior. .  ",
      "P-tags": "c petalinux fpga zynq",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_590524",
      "task": "Use arguments to pass parameter information to cURL script",
      "P-task": "use argument pass paramet inform curl script",
      "F_verb": "pass",
      "P-body": "You're using $1 and $2 inside single quotes, and the shell doesn't expand variables inside single quotes. .  Consider, a simplified example: .  If I run that, notice that I get a literal \"$1\" and \"$2\": .  You need do get those variables outside of single quotes. One option is the following (I've also added the necessary quote literals around the variables: .  Now I get: .  ",
      "P-tags": "argument shell-script curl bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "au_699869",
      "task": "Ubuntu 14.04, touchpad scrolling does not work after kernal update",
      "P-task": "ubuntu 14 04 touchpad scroll work kernal updat",
      "F_verb": "update",
      "P-body": "You touchpad looks like this one: .   pnp 00:05: Plug and Play ACPI device, IDs ETD0b00 SYN0002 PNP0f13 (active) .   The \"ELAN PS/2 Port Smart-Pad\". .  And now it's detected as a PS/2 Generic Mouse, therefore the scrolling feature is gone. .  If it works before upgrade, this issue might be a regression bug, I will suggest you to open a bug report on launchpad.net by following the guidelines in this Debugging Touchpad Detection wiki.  .  Address the touchpad model name, PNP device ID in the report. Also it's crucial to mention that the scrolling feature works before upgrade. But not with the current kernel version (run \"uname -a\" in a terminal). You can boot to the previous kernel to verify this by entering the grub menu on boot, and select \"Previous Linux version\" there. .  ",
      "P-tags": "14 04 synapt touchpad",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_30668837",
      "task": "How to pass variable from Batch File to a Powershell Script",
      "P-task": "pass variabl batch file powershel script",
      "F_verb": "pass",
      "P-body": "I have found that if you are calling the Powershell script from a batch file and need to have the Powershell script run with admin, you would need to use this syntax. .  The PowerShell script name and parameters need to be wrapped in 4 double quotes in order to properly handle paths/values with spaces .  This is the only solution that worked for me so far. .  ",
      "P-tags": "powershel batch-fil window",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_61763168",
      "task": "Can a failed transaction using Psycopg2 cause SQL constraints to stop behaving as deferred?",
      "P-task": "fail transact use psycopg2 caus sql constraint stop behav defer",
      "F_verb": "stop",
      "P-body": "With the help of a colleague, I have found the solution to my problem. .  The failed transaction with the \"bad_upload\" internally increments the nextval of the sequence. So after one failed transaction the id to be used for the next Session will be not the current maximum id + 1, but the current maximum + 2. .  To prevent this kind of issues, the correct way of obtaining the next Session id would be executing the Session insertion with: .  Then getting the id to be used with: .  And then use that Session id when inserting the Data table. .  According to the Postgres documentation: \"To avoid blocking concurrent transactions that obtain numbers from the same sequence, a nextval operation is never rolled back; that is, once a value has been fetched it is considered used and will not be returned again. This is true even if the surrounding transaction later aborts, or if the calling query ends up not using the value.\" .  So this ended up being an issue with Postgres, not even Psycopg. Many thanks to everyone who helped with this issue. .  ",
      "P-tags": "postgresql python ubuntu psycopg2",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V S_ING"
    },
    {
      "id": "so_66701410",
      "task": "Assistance with bash script to correctly pull the required column and set proper header using filename regex",
      "P-task": "assist bash script correctli pull requir column set proper header use filenam regex",
      "F_verb": "pull",
      "P-body": "Initialize \"tsamples\" with the \"Name\" heading. Then when you're processing the file contents, skip the first line with \"tail -n +2\". .  You can also use bash's \"%%\" parameter expansion operator to remove everything from the \".\", rather that piping to \"cut\". .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_47554135",
      "task": "Linux find catalogs and print only names",
      "P-task": "linux find catalog print name",
      "F_verb": "find",
      "P-body": "Some tiny example with the \"*\" wildcard.  .  If you don' use wildcards, it will try to find exactly the files named \"program\". Also, echoing is done automatically, you don't need the \"exec\" command. .  Update Answering to your comment. You can get the base name (name without the path) with: .  ",
      "P-tags": "termin linux shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "au_770695",
      "task": "My Wifi has suddenly stopped working!! Ubuntu 16.04",
      "P-task": "wifi suddenli stop work\nubuntu 16 04",
      "F_verb": "stop",
      "P-body": "Kernel module \"ndiswrapper\" is wrong. .  Remove it by  .  And start the proper module by .  ",
      "P-tags": "broadcom network driver dell 16 04",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V S_ING"
    },
    {
      "id": "so_21413768",
      "task": "how to start all daemon process in hadoop - like start-all.sh in linux",
      "P-task": "start daemon process hadoop - like start-al sh linux",
      "F_verb": "start",
      "P-body": "Change the \"for\" condition to match the path of your Hadoop daemons: .  ",
      "P-tags": "hadoop linux window bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "au_588282",
      "task": "Is it possible to prevent a file from being deleted unless in safe mode?",
      "P-task": "possibl prevent file delet unless safe mode",
      "F_verb": "prevent",
      "P-body": "No. The problem you have is that if an admin would not be able to remove a file it would introduce a security risk: someone with malicious intent and access to the system would then be able to install a file on your system even the admin of that system could not remove. A disgruntled admin could have some real fun with that... .  Besides \"attr\" (that can be easily changed by an admin) you can also start the file with a dot making it invisible for normal commands (\"ls\" would need the \"-a\" option) making it harder for uneducated people to find and delete it (It will not fool someone who knows that there is a secret file present on the system). Nothing that can prevent deleting the file.  .  But ... .  One method that will work though is to mount the file on a read only encrypted partition. The encryption is needed so \"root\" can not remount it without knowing the password. Someone could still remove the file when that person is able to remount it writeable and it has no relation to the \"only in safe mode\" part of your question though. But this seems to be the most practical approach.  .  Ubuntu also supports encrypted private directories (package \"ecrypt-utils\" but there are similar tools like \"cryptkeeper\"). But it depends if you need the contents of the file to enforce something or if it is actually the deleting of it that is a concern. To use the file you will need to open the directory with your login and password; it is then also possible to remove the file (so when you are not behind the system you will need to unmount the private directory to prevent deleting; when you are behind the machine and need it you can mount it and unmount it when not needed; limiting the time frame someone can delete it). .   I do have one problem with your question: in general you really should trust an administrator to not mess with files. If you can not trust that person remove his access and restrict his account to a normal account with some extra privileges. Making sure you are the only admin is a better and a lot easier method in preventing deletion of that file.  .  ",
      "P-tags": "14 04 delet filesystem file",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING"
    },
    {
      "id": "ul_126217",
      "task": "When would you use pivot_root over switch_root?",
      "P-task": "would use pivot_root switch_root",
      "F_verb": "use",
      "P-body": "I found a wonderful explanation here. However, let me try to put in a shorter format of what I understood in the answer.  .  Shorter Version .   While the system boots, it needs an early userspace. It can be achieved using either initramfs or initrd. initrd is loaded into ramdisk which is an actual FILE SYSTEM. initramfs is not a file system. For initrd \"pivot_root\" is used and for initramfs \"switch_root\" is used.  Longer Version .  Now, to the detailed explanation of what I had put above.  .   While both an initramfs and an initrd serve the same purpose, there are 2 differences. The most obvious difference is that an initrd is loaded into a ramdisk. It consists of an actual filesystem (typically ext2) which is mounted in a ramdisk. An initramfs, on the other hand, is not a filesystem. It is simply a (compressed) cpio archive (of type newc) which is unpacked into a tmpfs. This has a side-effect of making the initramfs a bit more optimized and capable of loading a little earlier in the kernel boot process than an initrd. Also, the size of the initramfs in memory is smaller, since the kernel can adapt the size of the tmpfs to what is actually loaded, rather than relying on predefined ramdisk sizes, and it can also clean up the ram that was used whereas ramdisks tend to remain in use (due to details of the pivot_root implementation). .  There is also another side-effect difference: how the root device (and switching to it) is handled. Since an initrd is an actual filesystem unpacked into ram, the root device must actually be the ramdisk. For an initramfs, there is a kernel \"rootfs\" which becomes the tmpfs that the initramfs is unpacked into (if the kernel loads an initramfs; if not, then the rootfs is simply the filesystem specified via the root= kernel boot parameter), but this interim rootfs should not be specified as the root= boot parameter (and there wouldn't be a way to do so, since there's no device attached to it). This means that you can still pass your real root device to the kernel when using an initramfs. With an initrd, you have to process what the real root device is yourself. Also, since the \"real\" root device with an initrd is the ramdisk, the kernel has to really swith root devices from one real device (the ramdisk) to the other (your real root). In the case of an initramfs, the initramfs space (the tmpfs) is not a real device, so the kernel doesn't switch real devices. Thus, while the command pivot_root is used with an initrd, a different command has to be used for an initramfs. Busybox provides switch_root to accomplish this, while klibc offers new_root.  .   ",
      "P-tags": "startup linux initramf init",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP over NP"
    },
    {
      "id": "ul_434151",
      "task": "What Happens to /dev/bus/usb After 1001 Connections",
      "P-task": "happen dev bu usb 1001 connect",
      "F_verb": "happen",
      "P-body": "If I read correctly https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git/tree/drivers/usb/core/hub.c#n2030 (code for a function called \"choose_devnum\"), it may wrap far earlier than that, at value 127 in fact, and then going back to 1: .  And later on the \"bus->devnum\" property is really set only if \"devnum\" is less than 128. .  ",
      "P-tags": "lsusb usb-driv usb usb-devic alpine-linux",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V to NP after NP"
    },
    {
      "id": "so_37332941",
      "task": "Shell script to create linux users where username and password are read from a config file",
      "P-task": "shell script creat linux user usernam password read config file",
      "F_verb": "create",
      "P-body": "The problem is that you source \"guest.cfg\" which will set the variable \"username\" and \"password\" multiply times, each time overriding the previous set. You need to parse the config file. .  One way - assuming there is no newline in the usernames/ passwords - is with sed: .  This will print lines that match the patterns: \"username=\"...\"\" and \"password=\"...\"\" so for instance with your example the output will be: .  As you can see you now got this pattern: .  This can be utilized in a while loop: .  ",
      "P-tags": "config-fil login bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "so_17900485",
      "task": "Convert an output to string",
      "P-task": "convert output string",
      "F_verb": "convert",
      "P-body": "How to fix the problem The shell (or the \"test\" command) uses \"=\" for string equality and \"-eq\" for numeric equality. Some versions of the shell support \"==\" as a synonym for \"=\" (but \"=\" is defined by the POSIX \"test\" command). By contrast, Perl uses \"==\" for numeric equality and \"eq\" for string equality. .  You also need to use one of the test commands: .  Or: .  With the \"[[\" operator, you could drop the quotes around \"\"$a\"\". .  Why you got the error message When you wrote: .  the shell expanded it to: .  which is a request to execute the command \"AC\" with the 5 arguments shown, and compare the exit status of the command with 0 (considering 0 \u2014 success \u2014 as true and anything non-zero as false). Clearly, you don't have a command called \"AC\" on your system (which is not very surprising). .  This means you can write: .  If you want to test strings, you have to use the \"test\" command or the \"[[ ... ]]\" operator. The \"test\" command is the same as the \"[\" command except that when the command name is \"[\", the last argument must be \"]\". .  ",
      "P-tags": "linux ubuntu shell bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_55448346",
      "task": "\"Unknown Switch\" error when using 7-zip in PowerShell script to archive file names that start with a `-`",
      "P-task": "unknown switch error use 7-zip powershel script archiv file name start -",
      "F_verb": "start",
      "P-body": "Try this: .  ",
      "P-tags": "powershel 7zip",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V with NP"
    },
    {
      "id": "au_50778",
      "task": "How do I install KDE 4.7 RC on Kubuntu?",
      "P-task": "instal kde 4 7 rc kubuntu",
      "F_verb": "install",
      "P-body": " Compiling 4.7 RC1 The complete source code for 4.7 RC1 may be freely downloaded. Instructions on compiling and installing 4.7 RC1 are available from the 4.7 RC1 Info Page.  .   \"KDE SC 4.6.90\" is the RC for \"KDE 4.7\". .  You need to compile the source files by yourself.  .  The final release is planned for July 27, 2011.  .  ",
      "P-tags": "kubuntu kde",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_69518375",
      "task": "Delete a locked file using powershell",
      "P-task": "delet lock file use powershel",
      "F_verb": "delete",
      "P-body": " will delete the locked files as well. Please validate .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "so_26963377",
      "task": "Bash script to read EXIF, rename JPG files and check output if file exit -> create newfile-01.jpg",
      "P-task": "bash script read exif renam jpg file check output file exit - creat newfile-01 jpg",
      "F_verb": "check",
      "P-body": "Before: .  use something like: .  You can of'course use \"counter\" of your script to handle sequential numbers, but this version won't recount on re-run (safer I think). .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP if S"
    },
    {
      "id": "so_47518260",
      "task": "Hash using a key in Powershell",
      "P-task": "hash use key powershel",
      "F_verb": "hash",
      "P-body": "In the PowerShell version you perform an additional operation - converting the byte array to a Base64 string - before converting it to upper case: .  Python on the other hand converts the array to a hexadecimal string. .  Change the powershell version to: .  \"-join($signature |ForEach-Object ToString X2).ToUpper()\" will produce the exact same format as \".hexdigest().upper()\" .  ",
      "P-tags": "powershel python",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V using NP in NP"
    },
    {
      "id": "su_71639",
      "task": "How can I install DropBox without root privileges?",
      "P-task": "instal dropbox without root privileg",
      "F_verb": "install",
      "P-body": "You don't give your distribution, but since you aren't installing as root it's probably not important. The binaries are meant to be installed system-wide, so unless you can convince your system administrator to install the package, you'll need to compile and install to your home directory.) .  Essentially, Dropbox's Linux client is two parts: a daemon, \"dropboxd\", that provides a \"per-user closed-source daemon process that makes sure your \"$HOME/Dropbox\" directory is properly synchronized\", and a client that connects to the daemon and provides information. The binaries provided supply a Nautilus plugin for Gnome, although there are also CLI clients available. .  You'll want to refer to Installing to a Text-Based Linux Environment, which includes links to the daemon binaries for 32-bit and 64-bit systems. If you don't need the Nautilus plugin, make use of the official Dropbox CLI script or a user-created alternative CLI script. .   If you really want the Nautilus plugin, you'll need to build it from the source package, and install it to your home directory. .  Untar the source package: .  Run the configure script; add the options you wnat, but you'll need the \"--prefix=\" option: .  If this fails, you'll probably need to grab headers for the libraries needed to compile the program: GTK 2.12, GLib 2.13, Nautilus 2.16, and Libnotify 0.4.4 (minimum versions; if you can match up the version provided by your system, you can avoid the actual compilation and just grab header files to install to your own \"~/include\" directory). .  Build and install the binaries; they should be installed to your home directory (eg \"~/bin\", \"~/share\", \"~/lib\", \"~/man\", etc). .  Note this is the basic process, and you may need to work through them a few times depending on what libraries and headers are available on your system. All of these steps are possible without root access, but you will have to modify any installations to install them to your home directory instead of system locations like \"/lib\" or \"/usr\". .  If you run into trouble, your best bet for finding help is the Dropbox forums. .  ",
      "P-tags": "privileg linux instal root dropbox",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP without NP"
    },
    {
      "id": "so_48708185",
      "task": "How to add own custom function in standard shared library (C) in linux?",
      "P-task": "add custom function standard share librari c linux",
      "F_verb": "add",
      "P-body": "Lower-case \"t\" for the symbol type? .    Are you sure that's a visible function? On my Ubuntu 16.04 VM, the linkable functions defined in an object file have \"T\" (not \"t\") as the symbol type. Is there a stray \"static\" kicking around and causing confusion? Check a couple of other functions defined in \"libgcrypt.so\" (and documented in \"gcrypt.h\") and see whether they have a \"t\" or a \"T\". They will have a \"T\" and not \"t\". You'll need to work out why your function gets a \"t\" \u2014 it is not clear from the code you show. .  The (Ubuntu) man page for \"nm\" includes: .   The symbol type. At least the following types are used; others are, as well, depending on the object file format. If lowercase, the symbol is usually local; if uppercase, the symbol is global (external).  .   The line you show says that \"MyFunction\" is not visible outside its source file, and the linker agrees because it is not finding it. .  Your problem now is to check that the object file containing \"MyFunction\" has a symbol type \"T\" \u2014 if it doesn't the problem is in the source code. .  Assuming that the object file shows symbol type \"T\" but the shared object shows symbol type \"t\", you have to find what happens during the shared object creation phase to make the symbol invisible outside the shared object. This is probably because of a 'linker script' that controls which symbols are visible outside the library (or maybe just compilation options). You can search on Google with 'linker script' and various extra words ('tutorial', 'provide', 'example', etc) and come up with links to the relevant documentation. .  You may need to research documentation for LibTool, or for the linker BinUtils. LibTool provides ways of manipulating shared libraries. In a compilation command line that you show in a comment, there is the option \"-fvisibility=hidden\". I found (mostly by serendipitous accident) a GCC Wiki on visibility. See also visibility attribute and code generation options. .  ",
      "P-tags": "gcc linux shared-librari",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_23930533",
      "task": "Parse contents of .txt file to HTML file using Bash",
      "P-task": "pars content txt file html file use bash",
      "F_verb": "parse",
      "P-body": "One possibility, using \"sed\": .  In your \"HOME.html\" file, put a placeholder where you want \"CONTENTS.txt\" to be inserted, e.g., .  Then use \"sed\" as: .   Regarding your comment: .  You should have a template file, say \"HOME-template.html\" that contains your structure and the placeholders, say: .  and you should generate your \"HOME.html\" file like so: .  So that each time you change your \"CONTENTS.txt\" file, you run this command, and the \"HOME.html\" will reflect the changes. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP of NP to NP using NP"
    },
    {
      "id": "ul_408125",
      "task": "How to change folder's creation date to match the creation date of the .nfo file inside?",
      "P-task": "chang folder creation date match creation date nfo file insid",
      "F_verb": "change",
      "P-body": "I was able to do it with the following command: \"for i in *;do touch -r \"$i/\"*.nfo\" .  ",
      "P-tags": "touch command-lin",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_14720797",
      "task": "Sending Unix/Linux SIGNAL through PIPE",
      "P-task": "send unix linux signal pipe",
      "F_verb": "send",
      "P-body": "\"sleep .5; kill -9 $(pidof some_process)\" should work. \"pidof\" returns a process id for a process name. The \"$()\" returns the result of the command to the \"kill\" command. An alternative would be:  .  \"sleep .5; pidof some_process | xargs kill -9\"  .  check \"man pidof\" for details.  .  Edit: there is also \"timeout\". \"timeout -s SIGKILL 0.5s some_process\" should do the trick if I understood your question correctly. .  ",
      "P-tags": "signal linux pipe bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP through NP"
    },
    {
      "id": "so_30903477",
      "task": "Is it possible to run command \"route -n\" specifically for a NIC",
      "P-task": "possibl run command rout -n specif nic",
      "F_verb": "run",
      "P-body": "Do you want see route for ether0, you can use below command  .  or .  or .  or .  To see NIC for ether0, you can use ifconfig command and Gateway NIC you can use arp -a commands .  for see GW and direct connected NICS you can use below command  .  ",
      "P-tags": "script linux shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP"
    },
    {
      "id": "au_457868",
      "task": "How to automatically change the volume after Pulse Audios starts?",
      "P-task": "automat chang volum puls audio start",
      "F_verb": "change",
      "P-body": "The pulseaudio module responsible to restore any device's volume to values before rebooting is the \"module-device-restore\". If restoring devices does not work as expected we may want to check if that module was loaded with: .  If it was not there we should add the module to our \"default.pa\" settings file. This file is located in \"/etc/pulse\" by default but we can have an additinal per-user \"default.pa\" overriding this in \"~/.pulse/\" or in \"~/.config/pulse/\". When editing make sure you choose the appropriate file, and make a backup beforehand. .  To load \"module-device-restore\" on starting the pulseaudio sound server the following line has to be included (or uncommented) in the \"default.pa\": .  ",
      "P-tags": "xubuntu volume-control pulseaudio",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP after NP"
    },
    {
      "id": "so_60807894",
      "task": "Is there a better way to run a repeat command in terminal?",
      "P-task": "better way run repeat command termin",
      "F_verb": "run",
      "P-body": "\"grep\" does not know the filename, so you see only the matching lines, but not which file they come from originally. I would in your case write an explicit loop: .  Since \"dfits\" already obscures the file name in its output, we store the output from grep into a variable, and if there is a match, output this line together with the file name. .  ",
      "P-tags": "command shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_41180529",
      "task": "Sed replace string with whitespaces",
      "P-task": "sed replac string whitespac",
      "F_verb": "replace",
      "P-body": "The following seems to work (with some whitespace differences): .  i.e. first replace all \"\", u \"\" with newlines, then remove all \"u\", where \"u\" is not preceded by a word character. .  Note that the output isn't a valid JSON. .  ",
      "P-tags": "replac sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP"
    },
    {
      "id": "so_8741074",
      "task": "Compiling MongoDB r2.0.2 on ubuntu 10.04 resulted in error",
      "P-task": "compil mongodb r2 0 2 ubuntu 10 04 result error",
      "F_verb": "compile",
      "P-body": "Dude it worked! Do this: .  Then run \"scons all\" again .  ",
      "P-tags": "mongodb ubuntu-10 04 compiler-error",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP on NP"
    },
    {
      "id": "so_41650179",
      "task": "How to reload nginx config if it is running or start if it's stopped?",
      "P-task": "reload nginx config run start stop",
      "F_verb": "start",
      "P-body": "If you can't count on the fact that nginx is already running then you should just restart it. But, if you really want the above, assuming you're running on linux/unix and it looks like you are then you can create a tiny shell script. Again, assuming your default shell is bash or bash compatible (other shells would have to be ported) you could do something like this: .  You can take the above to a whole new level by using inotify. Again, assuming you're running a Linux distribution, you can install your OS distribution's inotify-tools package and automate running the above script file every time your config files change. See this for more info on using inotify: .  How to execute a command when a file changes .  ",
      "P-tags": "nginx linux",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V if S"
    },
    {
      "id": "au_948878",
      "task": "Ubuntu replaced my /home directory after install",
      "P-task": "ubuntu replac home directori instal",
      "F_verb": "replace",
      "P-body": "Get the UUID of the partition with \"blkid\" and add it to your \"/etc/fstab\" as follows (assuming it has an \"ext4\" file system): .  Then a simple \"sudo mount -a\" (or a reboot) suffices to mount it and it is mounted automatically from now on. .   An example how you can set a partition's mountpoint in the installation gives this screenshot:  Of course this is different from your case \u2013 here the home partition \"/dev/sda6\" is set to be formatted with \"reiserfs\". .  ",
      "P-tags": "partit ubiqu debian 16 04",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP after NP"
    },
    {
      "id": "so_44254538",
      "task": "Character Limit on CSV when running import-csv powershell script",
      "P-task": "charact limit csv run import-csv powershel script",
      "F_verb": "run",
      "P-body": "you can change this behaviour by modifying buffer size of console: .  You can get more details about this from this reference link : https://blogs.technet.microsoft.com/heyscriptingguy/2006/12/04/how-can-i-expand-the-width-of-the-windows-powershell-console/ .  ",
      "P-tags": "powershel csv",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_70108435",
      "task": "Powershell email sender with html body (htmlbody.Replace)",
      "P-task": "powershel email sender html bodi htmlbodi replac",
      "F_verb": "replace",
      "P-body": "You are on the good path. You just need to extend what you are doing. .   Remove the thing that might or might not be in the email (The \"errors list\" section as it won't be there if there are no error) Put the section your removed in its own variable Add a placeholder in your main html template at the location where it is supposed to be (just like you do already so we can do a replace in the html template.  From there, the logic is : .   If there are 0 errors, you replace the placeholder from the main template by an empty string (you don't want that placeholder to appear in the final email) If there are 1 or more error, instead of replacing by your error list, you build a new variable that contain the section you want to append, then you replace its loop by the errors content and finally you replace the placeholder by that section (which contains the error loop)  That would look something like this. .  ",
      "P-tags": "html-email autom pars html-pars powershel",
      "source": "qa",
      "cate": "replace",
      "pat": "V"
    },
    {
      "id": "au_117452",
      "task": "How do you add \"open in terminal\" to the right-click mouse menu for folders/directories?",
      "P-task": "add open termin right-click mous menu folder directori",
      "F_verb": "add",
      "P-body": "You first need to install the package \"nautilus-open-terminal\" from Software Center or \"Synaptic Package Manager\" .   .  Then goto command line and type .  Then open nautilus and you can find \"Open in Terminal\" .   .  If you want to assign a keyboard shortcut to this action, please consult the following Q&A: .  Keyboard shortcut for \"open a terminal here\" .  ",
      "P-tags": "menu 10 04 nautilu mous",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP for NP"
    },
    {
      "id": "so_31230558",
      "task": "How could I remove one older folder with bash?",
      "P-task": "could remov one older folder bash",
      "F_verb": "remove",
      "P-body": "You can do .   \"ls -lt | tail -1\" shows the last line after sorting the directories by date \"awk '{print $NF}'\" \"prints\" the last column (which is the directory name) \"xargs rm -rf\" deletes that directory  ",
      "P-tags": "sh bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "au_218429",
      "task": "I can't start mysql in ubuntu 11.04",
      "P-task": "start mysql ubuntu 11 04",
      "F_verb": "start",
      "P-body": "Converting between package formats intended for different distributions is not a perfect process (and never will be), you really should try to use Ubuntu (or at least Debian) packages. Sometimes if you need a newer version than exists in the Ubuntu repositories you can find it in Debian testing, unstable or even experimental series. .  But first thing I'd try is: .  ",
      "P-tags": "mysql",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "so_14624302",
      "task": "How to make a Python script runs as trivial linux command with Distutils?",
      "P-task": "make python script run trivial linux command distutil",
      "F_verb": "make",
      "P-body": "If you specify a list of scripts in \"setup()\", distutils will automatically install them into an appropriate directory: .  Note that \"mymodule\" here for your example will need to be a runnable python script with that name; it probably shouldn't be your actual module but rather import your module if necessary. .  ",
      "P-tags": "termin linux python command",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP as NP with NP"
    },
    {
      "id": "so_44485421",
      "task": "Using a relative path in executable with symbolic link",
      "P-task": "use rel path execut symbol link",
      "F_verb": "use",
      "P-body": "Is it \"realpath\" you're after? Something like this (source for \"test\" in below example): .  Example execution: .  ",
      "P-tags": "linux ubuntu c++ symlink qt",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_45492017",
      "task": "Compile assets with Laravel Mix Error on Laravel 5.4 and Node.js",
      "P-task": "compil asset laravel mix error laravel 5 4 node js",
      "F_verb": "compile",
      "P-body": "Since you're running Ubuntu, odds are good the \"cross-env\" part of the command is tripping up your NPM. I've run into this issue numerous times and found removing \"cross-env\" (which, IIRC, is a fix/workaround for Windows boxes, so if you're not running Windows anywhere, it's not necessary) to fix it. Alternatively (or if you are running Windows), you should be able to install \"cross-env\" with \"npm install -g cross-env\". .  I've found it helpful to run the node commands directly when I run into problems, so I get the errors themselves. In this case: .  If my suspicion is correct, you'll want to convert it to: .  Things like \"npm run watch\" are simply shortcuts to these longer scripts. These shortcuts are declared in your \"package.json\" file (where you can also define your own script shortcuts if you want). .  ",
      "P-tags": "plesk ubuntu npm laravel node js",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "so_40719722",
      "task": "Unable to locate package apt-get in docker container",
      "P-task": "unabl locat packag apt-get docker contain",
      "F_verb": "locate",
      "P-body": "You didn't end your apt-get upgrade command with the \"&&\" so it tried to install the \"packages\" on the following line. I like to put my \"&&\" at the start of each line since it's easier for me to see when this happens (and makes copy/paste a little easier): .  ",
      "P-tags": "ubuntu-14 04 docker",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_290754",
      "task": "How to compress all files in folder and erase the untared versions via command line?",
      "P-task": "compress file folder eras untar version via command line",
      "F_verb": "erase",
      "P-body": "Someone may have a script (or write one). I do this sort of thing either using \"zip\", or a script which uses gzip or bzip2. Both have provisions for removing the files after the archive is complete. .  The issues are .   you can certainly write compressed archives for each directory until the archive is complete, you cannot remove the directory you cannot update a compressed archive, e.g., by adding files to it.  So you have to have enough free space to create the first archive, and gradually get enough space to write larger archives. Presumably you do not have a lot of compressed files (such as png, jpg, pdf). Otherwise you will not gain space. .  If it were not for the strong likelihood of running short of space, the problem would be simply a script loop over the directories to be compressed/removed. However, with 17Gb freespace of 3Tb, it's likely that some directories have gotten rather large. You will have to do some analysis to see if this interferes with the simple solution outlined.  .  Further reading: .   How do I compress files in-place? Add/update a file to an existing tar.gz archive?  ",
      "P-tags": "archiv script compress backup",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP via NP"
    },
    {
      "id": "so_37494532",
      "task": "How to bind two domain names to two different websites(php and nodejs) running in same Azure Ubuntu VM?",
      "P-task": "bind two domain name two differ websit php nodej run azur ubuntu vm",
      "F_verb": "run",
      "P-body": "Yes, the answer of Apache and Node.js on the Same Server also works fine on Azure VM. .  Generally, you can refer to the following steps: .   Enable the 80 port inbound rules of your Azure VM. .   Install \"proxy_module\" of apache2 in your Azure VM, via command \"a2enmod proxy proxy_http\" .   config the Virtual Host in apache configuration file, E.G. as default, .  run \"sudo vim /etc/apache2/sites-available/000-default.conf\", and modify as: .   Restart the apache service: \"sudo service apache2 restart\" .   Start node server. .    Then, directly browse your VM like via \"<vm_name>.cloudapp.net\" will browse the PHP site in the configured directory, and browse via \"<vm_name>.cloudapp.net/node\" will browse the node application. .  ",
      "P-tags": "dn php azur ubuntu node js",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP"
    },
    {
      "id": "so_53306212",
      "task": "Checking the result of a postgres query from Bash",
      "P-task": "check result postgr queri bash",
      "F_verb": "check",
      "P-body": "The contents of \"userexists\" are likely to actually contain the linebreaks, but you probably checked the contents with an unquoted expansion: .  Additionally, if you want to compare two strings containing linebreaks with \"[ ... ]\", you can't use \"\"\\n\"\" to insert a linebreak. ANSI-C escapes, \"$'\\n'\", would work: .  prints \"Match\". Two remarks: Bash will understand \"==\" when used in \"[ ]\", but it's not portable, so \"=\" is recommended. Also, \"[ ]\" doesn't support pattern matching, so the \"*\" at the end of your right-hand side won't do what you expect. \"[[ ]]\" and \"case\" can be used for pattern matching. .  To avoid the whole problem in the first place, you can supply a few flags to \"psql\", specifically: .   \"--quiet\" \u2013 no informational output \"-t\" \u2013 tuples only; no column names, result count footers etc. \"-A\" \u2013 unaligned output (removes leading blank from line)  and the return from your command will be just \"1\" and you can compare with .  ",
      "P-tags": "postgresql bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "ul_57016",
      "task": "What's a good way to filter a text file to remove empty lines?",
      "P-task": "good way filter text file remov empti line",
      "F_verb": "remove",
      "P-body": "I know this would have been easier if I gave the file, but unfortunately it contained confidential info that I couldn't share. In the meanwhile I wrote me a ruby script that seemed to do the trick: .  Thanks everyone for helping! .  ",
      "P-tags": "sed awk shell text-process",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "au_1031543",
      "task": "Creating additional Virtual Host Ubuntu Server",
      "P-task": "creat addit virtual host ubuntu server",
      "F_verb": "create",
      "P-body": "1. You do not need second IP address to serve more than one virtual host on the server. Something more as I understood correctly you have only one static IP. So if you don't have any other special requirements I would advice you to revert the changes related to the network interfaces. .  2. It is not mandatory to do anything with \"/etc/hosts\". This file serves as local DNS and if you want to access your domain name (FQDN) locally (from the machine itself, when you do not have internet access or DNS setup) an entry as the next is enough: .   where \"127.0.0.1\" is the address of the loopback interface that normally is bound to the localhost domain name.  You can edit the \"hosts\" file at the other LAN connected PCs in order to access your LAN server via domain name instead of an IP address. For this purposes you need to enter the LAN IP of the server within the \"hosts\" files of the other LAN connected PCs: .   replace \"192.168.0.111\" with the actual server's LAN IP address.  3. How the virtual hosts work? .  On the client side, when you type any FQDN in the browser (for example \"http://example.com\") it checks[1] whether there is a record for this FQDN in \"/etc/hosts\". If there is not presented such record, it asks your DNS (provided in \"/etc/network/interfaces\" or in \"/etc/resolv.conf\", or by DHCP) for the IP address of the requested FQDN. And the DNS returns the \"A\" record for the requested domain name. Then the browser sends HTTP request to the provided IP address. The request's header contains the IP, the fully qualified domain name, etc. .   [1] not exactly the browser, but I do not want to extend the answer.  On the server side, when a request arrives to the server's IP address on certain port this request will be handled by the service that listen to this port. The default \"HTTP\"/\"HTTPS\" port is \"80\"/\"443\" and Apache listen to it/them - this is defined in \"/etc/apache2/ports.conf\". .  When Apace handle the request it reads the request header and redirects the request to the virtual host that correspond to the domain name in the request header. .  4. Do not use the VirtualHost tag in this way: \"<VirtualHost mydomain.com:80>\". This is a typo. Instead, use it as it is by default: \"<VirtualHost *:80>\". Actually the asterisk \"*\" means all available network interfaces (IP addresses handled by the server). .  5. According to the above your Apache's configuration should look like this: .   Usually the definitions of the different virtual hosts are placed in separate \".conf\" files to be \"a2ensite\"/\"a2dissite\" easily. .   It is not mandatory to separate the log files (at it is shown in the example). This is just another idea. .   In the question is written \"ServerAdmin admin.example.com\", you must provide email with this directive. .    6. If everything works fine you can go further and setup free HTTPS (SSL/TLS) certificate by the help of Let's encript (Certbot): .   Let's Encrypt, Apache2 - Editing vhosts properly .   When does Ubuntu 16.04 use /etc/apache2/ssl/apache.crt? .   Failed to upgrade certbot on Ubuntu Bionic .    ",
      "P-tags": "virtualhost network server apache2",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "su_823519",
      "task": "How to make tee not break lines at window width in powershell?",
      "P-task": "make tee break line window width powershel",
      "F_verb": "make",
      "P-body": "Your problem is the way the \"MatchInfo\" object returned by \"select-string\" is being output. If you just extract the \"Line\" property from the matchinfo object, (in which case you are outputting strings and not MatchInfo objects) you should get the behavior you want: .  ",
      "P-tags": "powershel command-lin",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_ING at NP in NP"
    },
    {
      "id": "ul_120405",
      "task": "Can Start Service With init.d script, however doing service <SERVICE_NAME> start does not work",
      "P-task": "start servic init script howev servic service_nam start work",
      "F_verb": "start",
      "P-body": "The main difference between runnning \"/etc/init.d/foo start\" and \"service foo start\", is that \"service\" runs the init script in a clean environment. If you have a case where running the init script directly works, but does not with \"service\", the an environment variable is being used in the startup that you have not manually initialized inside of the script. Since your init script is really simple, the environment variable usage is likely in the \"/home/oracle/scripts/startup.sh\" script. .  Also note that if it does not run with \"service\", it will not properly start on boot. .  ",
      "P-tags": "cento startup script",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP with NP"
    },
    {
      "id": "so_36988863",
      "task": "how to generate equal number of two values in bash",
      "P-task": "gener equal number two valu bash",
      "F_verb": "generate",
      "P-body": "I'm adding a separate answer since you may actually be looking for something much simpler. If you want to loop through 20 values, ten of which are \"1\" and ten of which are \"-1\", in random order, I would just do this: .  ",
      "P-tags": "array if-stat bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_64217596",
      "task": "How do I get the first letter capitalized of two different textboxes?",
      "P-task": "get first letter capit two differ textbox",
      "F_verb": "get",
      "P-body": "That is built into the \"Get-Culture\" cmdlet. There's a method named \".ToTitleCase()\" that will allow you to capitalize things such as named. .  That would get you 'John Doe'. There is also a method \".ToUpper()\" that will convert a character or string to entirely upper case, so you could get their initials, then run that through the \".ToUpper()\" method to capitalize them. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_518481",
      "task": "How to get PID of shell running in a terminal window under mouse?",
      "P-task": "get pid shell run termin window mous",
      "F_verb": "get",
      "P-body": "If terminal has only one shell process, I cannot see a problem. .  Works for XTerm, should work for GNOME Terminal too, I believe. .  Otherwise \u2013 if there may be more than one shell running under single terminal process (in several windows, tabs, regions, via multiplexer, etc), it\u2019s not clear from the question, what do you want. .  ",
      "P-tags": "gnome-termin window-manag xdotool bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP under NP"
    },
    {
      "id": "su_827083",
      "task": "How to get original library/package version from rpm package version?",
      "P-task": "get origin librari packag version rpm packag version",
      "F_verb": "get",
      "P-body": "The exact contents of an rpm package depend entirely on the maintainers. .  An rpm could contain patches, configuration files and documents that the original source did not. .  To get an exact idea of what is in an RPM, you should look for the SRPM (source rpm) corresponding to the package and unpack it with \"rpm2cpio <rpmname.rpm> | cpio -idmv\" .  The .spec file contains the exact instructions to build the package, references to the original source code and to all the files involved. .  To understand this better, I advise www.rpm.org/max-rpm/ .  It is a fully detailed guide to rpm building, and it is my reference of choice to build rpms. .  To answer you other questions: it is very likely that a Fedora rpm will not work in CentOS; mainly because Centos uses init.d and Fedora systemd (does not apply to most libraries). .  You should stick to rpms from repositories (epel and rpmforge will give you most of what you might need) and source code installs; pick and mix of rpms downloaded through http are a bad idea, a bad policy to have and a great source of troubles. .  ",
      "P-tags": "rpm linux-distribut compil packag",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_60935914",
      "task": "Install PyPy globally Ubuntu",
      "P-task": "instal pypi global ubuntu",
      "F_verb": "install",
      "P-body": "As @keith-thompson says, you can do \"sudo apt install pypy pypy-dev\". If you want a more up-to-date version you can do \"snap install pypy pypy-dev\". Another way to get a working environment is to use conda, as per this link. The advantage of conda is that you can easily install pre-built packages such as numpy, sciy (coming soon), and more. If you use the first recipes, \"pip install\" will currently have to build many packages from source. .  Note that \"pip\" is never \"available anywhere\", it is tied to the particular python instance, and installs packages into a path for that specific instance. Thus the \"pip\" you use for python2 is different than the \"pip\" you use for python3, likewise for pypy. .  ",
      "P-tags": "ubuntu python pypi",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_38865382",
      "task": "Overwriting specific Line in multiple Files using PowerShell with User Input",
      "P-task": "overwrit specif line multipl file use powershel user input",
      "F_verb": "overwrite",
      "P-body": "Use the Get-ChildItem cmdlet to retrieve the files, iterate over it using the ForEach-Object cmdlet, read the content of the file using Get-Content, overwrite the specific line and finally write the text back to the file using the Set-Content cmdlet: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP using NP with NP"
    },
    {
      "id": "so_9267837",
      "task": "How do I conditionally execute bash code based on the comparison of file dates?",
      "P-task": "condit execut bash code base comparison file date",
      "F_verb": "execute",
      "P-body": "Use a file test operator. .  Taken from: http://tldp.org/LDP/abs/html/fto.html .  f1 -nt f2 file f1 is newer than f2 .  f1 -ot f2 file f1 is older than f2 .  Assuming test and test2 are files. .  Executed: .  ",
      "P-tags": "script bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP of NP"
    },
    {
      "id": "au_838364",
      "task": "What do I have to do getting access the port 8787?",
      "P-task": "get access port 8787",
      "F_verb": "get",
      "P-body": "The \"<server-ip>\" part of that command means to insert your computer's IP address there. For example, if your computer's IP was \"192.168.0.256\", you would go to: .  If you want to access it from another computer in the same LAN, just go to that same address. If you want to be able to access it from any computer on the internet, you'll have to setup port forwarding on your router's firewall. For more details, see this answer. .   If you don't know your IP address, open a terminal, and run \"hostname -I\" (CaSe sensitive) .  ",
      "P-tags": "support",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_41461984",
      "task": "Start process and wait until logfile has specific entry",
      "P-task": "start process wait logfil specif entri",
      "F_verb": "wait",
      "P-body": "In comments I expressed my concerns about the stability of such a solution because the process might already have been stepped further at the moment the watchdog detects the message in the logfile. .  You said to that: \"The whole thing is about doing an automated analysis for one time on about 50 different inputs. Job done. It is not an academic exercise\". .  Ok, for such an use case you can do the following: .  Note: I suppose that \"process\" will exit nicely on \"kill\" in this example. .  ",
      "P-tags": "process kill bash",
      "source": "qa",
      "cate": "wait/await/sleep",
      "pat": "V until S"
    },
    {
      "id": "au_585617",
      "task": "How to install ImageMagick on Ubuntu 12.04?",
      "P-task": "instal imagemagick ubuntu 12 04",
      "F_verb": "install",
      "P-body": "It might be that your sources are out of date, so are asking for old URLs instead of the current ones - try running \"sudo apt-get update\" before installing stuff. .  If you want to see what it does, read this. .  ",
      "P-tags": "imagemagick 12 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_164795",
      "task": "Where are default compose-key bindings stored?",
      "P-task": "default compose-key bind store",
      "F_verb": "store",
      "P-body": "You can find the compose table used by your system at the same place programs do: it's a text file. To locate it, you can run something like .  For example, the relevant lines on Debian wheezy are: .  This demonstrates several things: .   To define your own table, put it in the file \"~/.XCompose\". Actually, you can override this location by setting the environment variable \"XCOMPOSEFILE\". The location of the system table is listed in \"/usr/share/X11/locale/compose.dir\". This file can list different tables for different locales.   ComposeFU is a recent addition, the corresponding character is itself a recent addition to Unicode. .  ",
      "P-tags": "compose-key x11",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V"
    },
    {
      "id": "su_816197",
      "task": "How to copy a list files to a list of directories or subdirectories",
      "P-task": "copi list file list directori subdirectori",
      "F_verb": "copy",
      "P-body": " The names of files and directories are with numbers as above? .  ",
      "P-tags": "cp xarg linux find bash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "so_47865962",
      "task": "Windows batch file to list the file from one folder into csv / txt file",
      "P-task": "window batch file list file one folder csv txt file",
      "F_verb": "list",
      "P-body": "You could shorten your script and still output what you asked for. .  ",
      "P-tags": "batch-fil window shell",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP from NP into NP"
    },
    {
      "id": "so_38616490",
      "task": "Unable to launch x11vnc before login on Kubuntu 16.04",
      "P-task": "unabl launch x11vnc login kubuntu 16 04",
      "F_verb": "launch",
      "P-body": "I solved this problem on Kubuntu 16.04 adding into /usr/share/sddm/scripts/Xsetup the following line: .  Before that I generated password using: .  This allows to launch x11vnc process as root even at Kubuntu login screen. .  ",
      "P-tags": "ubuntu",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP before NP on NP"
    },
    {
      "id": "so_65161086",
      "task": "How to read() from a file continuosly into a variable",
      "P-task": "read file continuosli variabl",
      "F_verb": "read",
      "P-body": "Use \"malloc\". Find the size first (How do you determine the size of a file in C?) then malloc the appropriate number of bytes and do the \"read\". .  ",
      "P-tags": "c unix",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V from NP into NP"
    },
    {
      "id": "so_6939695",
      "task": "Parsing a text stream with one word in each line in BASH",
      "P-task": "pars text stream one word line bash",
      "F_verb": "parse",
      "P-body": "In some cases the \"xargs\" command can be sufficient: .  This assumes that the way of passing the words from the stream to the command is by specifying that word as an argument for the command. .  If this is not the case @aioobe's suggestion might be more suitable for you. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP with NP in NP in NP"
    },
    {
      "id": "au_490178",
      "task": "Suspend from the command line and show Unity's lock screen in 14.04?",
      "P-task": "suspend command line show uniti lock screen 14 04",
      "F_verb": "show",
      "P-body": "Since I figured out how to get the 14.04 lock screen, I just chained the dbus lock command with the suspend one: .  ",
      "P-tags": "14 04 lock-screen suspend",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_28667490",
      "task": "How to prevent hang with wildcard at powershell shell. (perforce)",
      "P-task": "prevent hang wildcard powershel shell\nperforc",
      "F_verb": "prevent",
      "P-body": "PowerShell does not add quotes around parameter when passing it to native apps when parameter does not contains space or begins with quote. So this PowerShell command: .  will result in this command line: .  To solve your issue, you need to put quotes literally in the parameter string: .  or .  or .  ",
      "P-tags": "perforc powershel wildcard-expans shell",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP with NP at NP"
    },
    {
      "id": "ul_191221",
      "task": "Implementing TLS 1.2 when I SSH into a box as a measure against POODLE",
      "P-task": "implement tl 1 2 ssh box measur poodl",
      "F_verb": "implement",
      "P-body": "You misunderstand something, but it is an easy thing to get confused about. .   SSH = Secure SHell SSL = Secure Sockets Layer  \"ssh\"/\"sshd\" is a standalone client-server application that uses it's own high level protocol (the SSH protocol); SSL is a parallel protocol used with (e.g.) HTTPS servers. Applications which use one or the other may use the same low level ciphers (which you can delimit with the \"Ciphers\" option in \"sshd_config\"), hence \"ssh\" implementations are generally linked to \"libssl\" (which actually implements the ciphers1), but the high level protocol used for secure shell communication is neither SSL nor TLS. .  You can set which versions of the ssh protocol to accept, (see the \"Protocol\" option in \"man sshd_config\") but the default is already the most secure. .   1. TBH I'm not positive that's the reason for the linkage, but point being, it's not in order to use the SSL protocol. .  ",
      "P-tags": "poodl tl openssl ssh fedora",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP when S"
    },
    {
      "id": "au_693765",
      "task": "./configure: No such file or directory while installing tar.gz",
      "P-task": "configur : file directori instal tar gz",
      "F_verb": "configure",
      "P-body": "The archive \"pycharm-community-5.0.tar.gz\" doesn't contain a \"configure\". Extract the archive and run PyCharm .  For a better integration in your desktop, create a desktop file: .  and add the configuration below .  ",
      "P-tags": "gzip configur tar",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP while S_ING"
    },
    {
      "id": "so_63250884",
      "task": "Get AD-Computer not like distinguished name",
      "P-task": "get ad-comput like distinguish name",
      "F_verb": "get",
      "P-body": "\"-notlike\" does not support collections on the right-hand side (RHS). A similarly intended approach is to use \"-notmatch\", which is a regex string: .   If you want your server names in a list first, you can create a regex string from that. .   If you do not anchor your regex strings, it looks for the regex match anywhere within the target string (effectively having surrounding wildcards). \"|\" is an alternation (an effective \"OR\"). .  There are other operators that support collections like \"-contains\", \"-in\", \"-notin\", and \"-notcontains\". However, they must match exactly and cannot use wildcards. .  ",
      "P-tags": "powershel active-directori window",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_20619482",
      "task": "What is causing these whitespace problems on Mac OS X bash?",
      "P-task": "caus whitespac problem mac os x bash",
      "F_verb": "cause",
      "P-body": "Use the \"-n\" argument to force \"xargs\" to run the given command with only a single argument: .  Otherwise, it tries to use each line from the input as a separate argument to the same invocation of the command. .  Note that this will fail if any of the matched file names contain newlines, since \"ls\" has no way of producing output that distinguishes such names from a sequence of newline-free file names. That is, there is no option to \"ls\" similar to the \"-print0\" argument to \"find\", which is commonly used in pipelines like \"find ... -print0 | xargs -0\" to guard against such file names.) .   Your question implies that you realize that you could do something like: .  which is unlikely to be noticeably slower than any attempt at using \"xargs\". In each case the process of spawning multiple \"tar\" processes is likely to outweigh any differences in looping in \"bash\" vs the internal loop in \"xargs\". .  ",
      "P-tags": "xarg maco bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP on NP"
    },
    {
      "id": "so_10726287",
      "task": "Passing char** into a function , doesn't change its values , or does it ?",
      "P-task": "pass char function chang valu",
      "F_verb": "change",
      "P-body": " This is the likely culprit. Calling \"realloc()\" can allocate a new (presumably larger) block of memory into which the data from the old block is copied, and then deallocate the old block. The problem isn't that you're changing the value of \"argv\" in \"main()\", it's that you're not changing it. You're deallocating the block that it points to without updating main()'s \"argv\" to point to the new block. .  ",
      "P-tags": "linux c ubuntu array",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_44762430",
      "task": "Why do I get /etc/cups conflicts between attempted installs in Yocto?",
      "P-task": "get etc cup conflict attempt instal yocto",
      "F_verb": "get",
      "P-body": "Turns out the issue is that each file to be packaged in Yocto will also generate a \"%dir\" for each parent of each file. We don't want to own a directory that is owned by another package, so if you add this to your recipe: .  It will cause your package to not own parent directories of the files you package. .  This will generate an rpm spec file without the \"%dir\" entries. .  ",
      "P-tags": "linux cup yocto",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP between NP in NP"
    },
    {
      "id": "su_1457060",
      "task": "How can you start two chrome windows with different WM_CLASS attributes?",
      "P-task": "start two chrome window differ wm_class attribut",
      "F_verb": "start",
      "P-body": "There is a bug-report for this problem: Issue 118613: The --class argument is ignored unless using --user-data-dir. .  This bug has been fixed and then lately re-appeared again. .  Until it is fixed again, probably the previous workaround of using different \"--user-data-dir\" folders for each Chrome instance will still work. .  ",
      "P-tags": "google-chrom linux ubuntu",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP with NP"
    },
    {
      "id": "so_17417741",
      "task": "How to set up Node server for production on own machine?",
      "P-task": "set node server product machin",
      "F_verb": "set",
      "P-body": "Two options. Either disable any other service running on port 80 and run Node with \"sudo\". Or setup something like nginx to forward traffic from port 80 to your Node instance. To do that you can open a socket file with node and configure nginx similar to https://github.com/trevnorris/norrd/blob/master/conf/nginx.conf .  Creating the socket is simple enough. It's as simple as .  I usually opt to spawn child processes for easier monitoring from the parent process, but use nginx to connect to each socket. For two reasons, one is it's easy to set route static content around the node process, and also because I prefer not to setup my own access privileges from scratch. .  ",
      "P-tags": "node js raspberry-pi linux",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "so_39546500",
      "task": "How to make scanf to read more than 4095 characters given as input?",
      "P-task": "make scanf read 4095 charact given input",
      "F_verb": "make",
      "P-body": "It is because your terminal inputs are buffered in the I/O queue of the kernel. .   Input and output queues of a terminal device implement a form of buffering within the kernel independent of the buffering implemented by I/O streams. .  The terminal input queue is also sometimes referred to as its typeahead buffer. It holds the characters that have been received from the terminal but not yet read by any process. .  The size of the input queue is described by the MAX_INPUT and _POSIX_MAX_INPUT parameters; .   By default, your terminal is in Canonical mode. .   In canonical mode, all input stays in the queue until a newline character is received, so the terminal input queue can fill up when you type a very long line. .   Now to answer your questions: .  Is there a way to instruct \"scanf\" to read more than 2 line? .  That 2 line concept is wrong. Anyways, you can't instruct \"scanf\" to read more than 4096 bytes if the maximum size of I/O queue of the terminal is set to 4096 bytes. .  Is there any other function which we can use which doesn't have this limitation ? .  No you can't even with any other function. It's not a limitation of \"scanf\". .   EDIT: Found a rather standard way of doing it  .  We can change the input mode of terminal from canonical mode to non-canonical mode. .  To change the input mode we have to use low level terminal interface. .  We can do the task as follows: .  In case you want to know how to do it from terminal .   Earlier answer was: (This technique is older) .  I don't know whether it is the best way or not, but It can be done by changing the terminal mode from \"cooked\" (default) to \"cbreak\" or to \"raw\" mode. .  When the terminal is in \"cbreak\" mode, It works with single characters at a time, rather than forcing a wait for a whole line and then feeding the line in all at once. .  either you can use \"stty cbreak\" in terminal before executing the program. .  or .  To use cbreak mode programatically .  First install the \"curses\" package by running .  Next edit the program as follows: .  Now compile with the \"-lcurses\" option .  ",
      "P-tags": "linux c gcc",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_411793",
      "task": "Mount .ISO using the terminal",
      "P-task": "mount iso use termin",
      "F_verb": "mount",
      "P-body": "The problem here's that you can't have spaces among the command or the terminal interprets it as a separate command/statement, what you have to do is rather simeple, just rename your file from \"Windows 7 Ultimate SP1.iso\" to \"Windows_7_Ultimate_SP1.iso\", and do the same with command. .  The command should look like this \"sudo mount -o loop /home/varbo/Downlaods/Windows_7_Ultimate_SP1.iso /media/iso\" .  I hope this helps, good luck. .  ",
      "P-tags": "mount iso",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP using NP"
    },
    {
      "id": "so_31909203",
      "task": "How to convert years to days (in the past)?",
      "P-task": "convert year day past",
      "F_verb": "convert",
      "P-body": "The current time in seconds since 1970/01/01 (The Unix 'day 1'): .  The time exactly 10 years ago: .  Calculate today's day in the year: .  Then just subtract one from the other, divide by the number of seconds in a day, and add today's day-in-the-year: .  You should set \"$dnow\" after \"$dthen\", to avoid an off-by-one error. .  I'm not sure why anyone would want to do this, so if I've misinterpreted your question, please come back to us. .  ",
      "P-tags": "linux command bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "au_459154",
      "task": "Remove all development libraries",
      "P-task": "remov develop librari",
      "F_verb": "remove",
      "P-body": "Basically, you don't need any development libraries to run your system. As the name says, they are for development purposes. The libraries used to run these applications are different ones. .  Your command looks fine to me, but anyway APT is giving you a list with the packages to be removed. Just watch it for packages you need (everything without the \"-dev\" would be suspicious) .  ",
      "P-tags": "uninstal librari develop",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_4368348",
      "task": "Why does \"F5 - Start Debugging\" ignore breakpoints in PowerGUI?",
      "P-task": "f5 - start debug ignor breakpoint powergui",
      "F_verb": "start",
      "P-body": "It looks like there's a problem with PowerShell and square brackets in folder and filenames. .  Both PowerGUI and PowerShell ISE won't hit breakpoint if the script being debugged resides in a folder with \"[\" or \"]\" in the name. .  ",
      "P-tags": "powershel powershell-2 0 powergui",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V S_ING"
    },
    {
      "id": "su_1414795",
      "task": "Cloning HDD containing /boot and LVM to new HDD",
      "P-task": "clone hdd contain boot lvm new hdd",
      "F_verb": "contain",
      "P-body": "\"dd\" will handle the LVM just fine. .  Make sure your boot loader points to the right drive on your clone, otherwise it won't boot. .  Finally, you will need to resize the LVM on the clone. Technically you should be able to enlarge a logical volume without a problem while it is mounted, but I suggest doing all operations of this nature on unmounted drives. .  \"lvresize -L <new size>G --resizefs MyLVGroup/myvol\" .  will resize the partition and the filesystem at the same time. Tip: add \"+\" right before \"<new size>\" in the above command to extend by that amount instead of resizing to it. .  To extend the logical volume separately from resizing the filesystem do the following: .  \"lvresize -L +<amount to extend>G MyLVGroup/myvol\" .  Then expand the filesystem with: .  \"resize2fs /dev/MyLVGroup/myvol\" .  Look at askubuntu's Q \"How can I resize an LVM partition? (i.e: physical volume) and archwiki's LVM - Volume Operations for more information on resizing the LVM. .  ",
      "P-tags": "disk-clon linux lvm",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_122305",
      "task": "undelete a just deleted file on ext4 with extundelete",
      "P-task": "undelet delet file ext4 extundelet",
      "F_verb": "delete",
      "P-body": "Looking at the usage guide on extundelete it seems as though you're limited to undeleting files to a few ways. .  Restoring all  extundelete is designed to undelete files from an unmounted partition to a separate (mounted) partition. extundelete will restore any files it finds to a subdirectory of the current directory named \u201cRECOVERED_FILES\u201d. To run the program, type \u201cextundelete --help\u201d to see various options available to you. .  Typical usage to restore all deleted files from a partition looks like this: .   Restoring a single file In addition to this method highlighted in the command line usage: .  So you should be able to accomplish what you want doing this: .  NOTE: In both cases you need to know the device, \"/dev/sda4\" to perform this command. You'll have to remount the filesystem as readonly. This is one of the conditions of using \"extundelete\" and there isn't any way around this. .  ",
      "P-tags": "data-recoveri deleted-fil extundelet file",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP on NP with NP"
    },
    {
      "id": "so_22695948",
      "task": "Renaming Files With Same Name, Different Extension in Linux:",
      "P-task": "renam file name differ extens linux :",
      "F_verb": "rename",
      "P-body": "You can use parameter expansion: .  There is an excellent write-up about it here .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_303297",
      "task": "start a service a at bootime in systemd",
      "P-task": "start servic bootim systemd",
      "F_verb": "start",
      "P-body": "You should store your custom unit files in \"/etc/systemd/system/\". After you create them, you have to enable them with \"systemctl enable name\", which creates necessary symlinks. .  ",
      "P-tags": "systemd systemd-boot",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP at NP in NP"
    },
    {
      "id": "so_65437057",
      "task": "how to check ping for a bluetooth device in python",
      "P-task": "check ping bluetooth devic python",
      "F_verb": "check",
      "P-body": "so we can use hcitool to know the status of the bluetooth device. here is a small snippet that worked for me. there is no delay to get the output and this works absolutely fine. .  ",
      "P-tags": "bluetooth python-3 x ubuntu root pybluez",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "su_1556852",
      "task": "How to check if your ssh keys are in the ssh-rsa2 format?",
      "P-task": "check ssh key ssh-rsa2 format",
      "F_verb": "check",
      "P-body": "The key format has not changed. The only thing that changes is the signature format that's sent during each authentication handshake. .  What makes everything confusing is that originally in SSHv2, the key type and the signature type used to be defined in combination. For example, the same \"ssh-rsa\" identifier was defined to mean RSA keys and RSA/SHA-1 signatures.) So changing the signature process would have meant assigning a new key type identifier, and that would have meant generating a new key... .  However, protocol extensions have been developed to avoid this, and modern SSH clients will automatically negotiate the signature types whenever RSA keys are involved. If you connect with \"ssh -v\" you will notice a few additional packets being exchanged: .  So you can continue using \"ssh-rsa\" keys \u2013 you only need to upgrade the software on both ends to something reasonably recent, and it will automatically start producing \"rsa-sha2-256\" signatures from that key. For example, you might need to install a new version of PuTTY and Pageant, and you might have troubles with older versions of gpg-agent.) .  Signatures in ssh-keygen  the default option \"rsa\" for the \"-t\" argument explains that the chosen option is using the SHA1 signature, so one should choose \"rsa-sha2-256\" for example. .   This applies when issuing certificates, but is irrelevant when generating plain keys. .  Each certificate is signed by the parent CA at the time it is issued. This long-term signature is stored in the certificate itself (and it's very important to realize that this is a different thing from the short-term signatures that are made during each connection and then thrown away). That's why many HTTPS (X.509) certificates had to be replaced \u2013 the issuing CA had stamped them with RSA/SHA-1 signatures. .  OpenSSH has also created its own certificate format, which is what the manual page is referring to. These so-called \"SSH certificates\" are not just regular SSH keys \u2013 they're additionaly signed by e.g. your workplace CA. So if you have files whose names end with \"*-cert.pub\", you might need to have those re-issued. Use \"ssh-keygen -Lf <file>\" to check how they were signed). .  But plain SSH keys do not hold any long-term signature inside \u2013 they're only used to make temporary signatures during each connection. So there is nothing that needs replacement in the key itself. .  The \"-l\" option  I tried checking the type of the key with \"ssh-keygen -l -f key\" and it shows me that it is indeed SHA256 type .   No, that is not what ssh-keygen shows at all. The \"-l\" option is showing you the key's \"fingerprint\" and it's telling you that it used SHA256 to compute this fingerprint \u2013 but it has nothing to do with the key's type, nor with how the key will actually be used. The fingerprint is just a hash that was computed right now in order to be shown to you. .  (Remember that previously SSH software used to show MD5-based key fingerprints \u2013 even though there was no MD5 usage in the actual SSHv2 protocol.) .  Other key types  Is this the type not recommended anymore and I should switch for example, to ECDSA? .   From what I know (i.e. from what I gathered on Security.SE), RSA as a signature algorithm is still strong \u2013 problems mostly just occur when trying to use RSA as an encryption algorithm, and that's not an issue with SSHv2. Well, the ever-increasing key size is not great either.) .  ECDSA has its own problems \u2013 it is difficult to get its implementation right and certain kinds of programmer mistakes can be disastrous. If you had to switch, EdDSA (that is ssh-ed25519 or ssh-ed448) would be a better option. .  ",
      "P-tags": "openssh linux rsa ssh sha1",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_19736007",
      "task": "extract 2 column rages from TXT; insert comma delimiter; save as CSV",
      "P-task": "extract 2 column rage txt insert comma delimit save csv",
      "F_verb": "save",
      "P-body": "Assuming that your columns are delimited by a start and end index, you could do something like this: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V as NP"
    },
    {
      "id": "so_17724421",
      "task": "Why my Ubuntu still claims the version of Ruby on Rails is 4.0.0 after explicitly uninstalling it and installing the previous one?",
      "P-task": "ubuntu still claim version rubi rail 4 0 0 explicitli uninstal instal previou one",
      "F_verb": "claim",
      "P-body": "I can't explain the whole mechanism, but I found my rails.rb to be .  var/lib/gems/1.9.1/gems/railties-4.0.0/lib/rails/version.rb .  These should have something to do with this mess, so I tried to remove railties.  .  ",
      "P-tags": "ruby-on-rails-3 2 ubuntu ruby-on-rail",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP on NP after S_ING"
    },
    {
      "id": "so_34145728",
      "task": "What happens if I remove shared memory of other processes?",
      "P-task": "happen remov share memori process",
      "F_verb": "happen",
      "P-body": "In current POSIX standard, shared memory is just a file for each process. Let's see the interface shm_open() which set up shared memory: .  We could see that shm_open() just create a file about the information of shared memory. When one process delete shared memory opened by itself, it will not affect other processes using the shared memory. That also means, the access to shared memory is not synchronized for processes. .  For the second question, only root and owner of a process can use ipcrm to delete the shared memory file of a process, so it is probably a safe operation. .  ",
      "P-tags": "linux c++ c operating-system",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V if S"
    },
    {
      "id": "so_35840133",
      "task": "Automate execute command",
      "P-task": "autom execut command",
      "F_verb": "execute",
      "P-body": "create file run.sh and run - \"chmod +x run.sh\" .  The file should look like this -  .  \"#!/bin/bash cd /mydir/folder parse deploy\" .  ",
      "P-tags": "termin shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_16784587",
      "task": "Finding Version of IIS using powershell",
      "P-task": "find version ii use powershel",
      "F_verb": "find",
      "P-body": "You can try: .  ",
      "P-tags": "powershel ii",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP using NP"
    },
    {
      "id": "so_3902388",
      "task": "Permanently reversing a patch-file",
      "P-task": "perman revers patch-fil",
      "F_verb": "reverse",
      "P-body": "You can use the tool \"interdiff(1)\" from patchutils. In particular, the man page for \"interdiff\" says: .   To reverse a patch, use /dev/null for diff2. .   So, .  The \"-q / --quiet\" prevents the insertion of \"reverted:\" lines. .  ",
      "P-tags": "diff linux patch",
      "source": "qa",
      "cate": "flip/rotate/permute/swap/transpose/reverse/shuffle",
      "pat": "V NP"
    },
    {
      "id": "au_436806",
      "task": "How to completely remove Xubuntu and install Ubuntu (including boot screen etc.)",
      "P-task": "complet remov xubuntu instal ubuntu includ boot screen etc",
      "F_verb": "install",
      "P-body": "It will be a long command, but here it is: .  For Ubuntu 15.04:  .  General instruction: For a different version of Ubuntu or any Ubuntu based distribution, run this command and if the package manager fails to locate any of the packages, remove them from the command and run the command again. .  ",
      "P-tags": "xubuntu uniti",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_39388759",
      "task": "How to identify the .so file used by Android for system functions?",
      "P-task": "identifi file use android system function",
      "F_verb": "identify",
      "P-body": "The \"connect\" function, like most low level system functions, is in \"libc.so\". .  The proper tools for investigating the contents of binaries (like nm, objdump) are not installed by default on Android, but you can yet use \"strings\": .  ",
      "P-tags": "android shared-librari linux-kernel",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP by NP for NP"
    },
    {
      "id": "au_10410",
      "task": "Windows 7 doesn't boot after Ubuntu install",
      "P-task": "window 7 boot ubuntu instal",
      "F_verb": "install",
      "P-body": "From your BootInfo Script, I can see that GRUB2 resides erroneously on /sda1, your Windows boot partition. I'm not much into Windows anymore, but from what I know there are tools on the Windows CD that allow restoration of bootsectors. You need to boot from the Windows CD and start the repair mode. On the command line, you can try .  to restore your Windows partition boot sector. .  Then, however, you won't be able to boot Ubuntu, because there will be no more GRUB2. GRUB2 should have been installed in the MBR of /sda which is not so in your case. This means you will either have to reinstall GRUB (using a Ubuntu live CD) there, or you may find it less time consuming to reinstall Ubuntu as a whole. The latter should not be a great thing if you only installed it recently for testing. In any case, take note that you should not install Grub2 on your Windows boot sector again. .  ",
      "P-tags": "dual-boot 10 10 boot windows-7 grub2",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_7974779",
      "task": "using sed to find and replace in bash for loop",
      "P-task": "use sed find replac bash loop",
      "F_verb": "find",
      "P-body": "You're running BSD sed (under OS X), therefore the \"-i\" flag requires an argument specifying what you want the suffix to be. .  Also, no files match the glob \"*.js\". .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP for NP"
    },
    {
      "id": "so_60896302",
      "task": "unable to install programs",
      "P-task": "unabl instal program",
      "F_verb": "install",
      "P-body": "\"mono-devel is already the newest version (6.8.0.105-0xamarin3+ubuntu1804b1).\" .  So the package you were installing is already installed properly, however you have other packages that are \"not fully installed\", as the error states. .  You can try to see which process uses via .  \"sudo fuser -v /var/cache/debconf/config.dat\" .  and probably kill the process with \"kill -9 PID_ID\" .  And then use: \"apt install -f\" .  to resolve these dependencies. .  ",
      "P-tags": "dpkg ubuntu ubuntu-18 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_117144",
      "task": "Can I use variables inside {} expansion without `eval`?",
      "P-task": "use variabl insid expans without eval",
      "F_verb": "use",
      "P-body": "Brace expansion happens very early during expansion (first thing, in fact), before variable expansion. To perform brace expansion on the result of a variable expansion, you need to use \"eval\". .  You can achieve the same effect without \"eval\" if you make \"extensions\" a wildcard pattern instead of a brace pattern. Set the \"extglob\" option to activate ksh-like patterns. .  ",
      "P-tags": "variable-substitut brace-expans wildcard bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP inside NP without NP"
    },
    {
      "id": "ul_206633",
      "task": "Disallow `apt-get`, `yum` to install setuid binaries when itself run via sudo",
      "P-task": "disallow apt-get yum instal setuid binari run via sudo",
      "F_verb": "get",
      "P-body": "This is probably doable with an SELinux policy (and probably not doable without SELinux or other a security module that can confine root), but it's pointless. .  As you note, a package could declare that it installs \"/etc/sudoers\". Even if you make an ad hoc rule to somehow prevent that, the package could drop a file in \"/etc/sudoers.d\". Or it could drop a file in \"/etc/profile.d\", to be read the next time any user logs in. Or it could add a service that's started by root at boot time. The list goes on and on; it's unmanageable, and even if you caught the problematic cases, you'd have prevented so many packages from installing that you might as well not bother (for example, that facility wouldn't allow most security updates). Another thing the package could do is to install a program that you'd be tricked into using later (for example, if you forbid write access to \"/bin\" altogether, it could install \"/usr/local/bin/ls\") and which injects a backdoor via your account the next time you invoke the program. To prevent a package installation from injecting a potential security hole, you need to either restrict the installation to trusted packages, or to make sure you never use the installed packages. .  Basically, if you don't trust a user, then you can't let them install arbitrary packages on your system. Let them install software in their home directory if they need something that isn't in the distribution. .  If you want to give an untrusted user the ability to install more packages (from a predefined list of sources that you approve as safe) or upgrade existing packages on the main system, that can be safe, but you need to take precautions, in particular to disable interaction during the installation. See Is it safe for my ssh user to be given passwordless sudo for `apt-get update` and `apt-get upgrade`? for some ideas about \"apt-get upgrade\". .  Under recent Linux versions (kernel \u2265 3.8), any user can start a user namespace in which they have user ID 0. This basically allows a user to install their own distribution in their own directory. .  ",
      "P-tags": "account-restrict sudo software-instal",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF when S"
    },
    {
      "id": "so_26634563",
      "task": "applying regex in bash",
      "P-task": "appli regex bash",
      "F_verb": "apply",
      "P-body": "You're using an extended regular expression; the standard regex language which grep uses doesn't support what you're trying to do. Change grep to be \"grep -E\" and the match will work. This specifies that your regex is an extended one. .  See this link for more information on the distinction between regular and extended regex. .  ",
      "P-tags": "bash regex",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP in NP"
    },
    {
      "id": "au_515103",
      "task": "How can I display all users and groups with a command?",
      "P-task": "display user group command",
      "F_verb": "display",
      "P-body": "You can display with the help of \"compgen\" builtin command as follows: .   To display all users run following command: .   To display all groups run following command: .    However you can also display all users by \"cut -d \":\" -f 1 /etc/passwd\". .  ",
      "P-tags": "group command-lin user",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_268171",
      "task": "linux: detect if external keyboard is plugged to laptop",
      "P-task": "linux : detect extern keyboard plug laptop",
      "F_verb": "detect",
      "P-body": "You can use a \"udev\"-rule for this. In my example I am using a USB dongle for my wireless mouse, you will have to adjust accordingly: .  1. Getting the identifiers .  In order to make a unique rule for the device, we need to identify it properly. Use the output of \"udevadm\" for this ( your USB keyboard should show in \"/dev/usb/<device>\". Plug it in and out to see if this device (dis)appears ). The vendor and device IDs should be unique enough, but the more matches, the better. .  Note the two values that match the output from \"lsusb\" at ID (to know which device this is, either test the difference of \"lsubs\" with and without the keyboard, or see if you can match the names in the output) .  So we will use \"0e8f\" and \"00a4\" for vendor and product ID, respectively. .  2. Creating a rule .  The rule itself is just a listing of what to do. Save it in \"/etc/udev/rules.d/\" as e.g. \"keyboard.rules\" (note that the \".rules\" suffix is obligatory). The file will match (\"==\") a few attributes, the action, and run our script: .  You might run into problems for the \"ACTION==\"remove\"\" part, have a read of this. The problem being some of the attributes being deleted upon removal, and thus \"udev\" cannot match them anymore for your removal rule. .  In my case I used \"udeadm monitor --environemnt\" and unplugged the devive. I selected .  and used this as the only requirement (you might need to do a bit of trial and error for good matches here, however a single match is rather save for your case of changing keymaps only). Note that the removal rule needs \"ENV\" instead of \"ATTRS\" (AFAIK \"ENV\" works for the plugin rule, too, but \"ATTRS\" fails for removal) .  The add and remove rules can be one file with one line for each action. .  3. The script .  The script will ALWAYS be run by \"root\", so make sure that a) it is writeable by \"root\" only (for security reasons) b) if your command needs to be executed by a user, use \"sudo -u user1 command\" in the script. It should be executable of course. If you are trying to directly execute a command (i.e. without using a script) use the absolute path of said command. .  Good luck. .  ",
      "P-tags": "linux virtualbox keyboard keyboard-layout",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_22456520",
      "task": "Setting up gettext for php under ubuntu",
      "P-task": "set gettext php ubuntu",
      "F_verb": "set",
      "P-body": "So this mystery resolved by excellent SOQ .  One of the comment for gettext on php.net says: .  My issue resolved exactly by following these steps: .   sudo apt-get install language-pack-da-base (danish) locale -a (confirmed da_DK locale loaded) mv da_DK da_DK.utf8 (renamed the locales dir) \"bind_textdomain_codeset('messages', 'UTF8');\"  .  One of the debugging point for me was \"setlocale(LC_ALL, 'da_DK.utf8');\" which was returning false for invalid/non-existent locales  .   What about gettext.so extension: .  The php installation I got through apt-get seems to have the extension added during compilation We can see if gettext is compiled module e.g \"php -m |grep gettext\" , which seems to be true ! I don't need gettext.ini, which is desired only when PHP is compiled \"--with-gettext=shared\", which is not the case here. .  ",
      "P-tags": "ubuntu apach php gettext",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP under NP"
    },
    {
      "id": "ul_589793",
      "task": "How to create a column which has the \"+\" or \"-\" depending on the value in another column?",
      "P-task": "creat column + - depend valu anoth column",
      "F_verb": "create",
      "P-body": "How about:  .  ",
      "P-tags": "awk bioinformat",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP which S"
    },
    {
      "id": "so_69521599",
      "task": "Can't run the command 'find' inside script",
      "P-task": "run command find insid script",
      "F_verb": "run",
      "P-body": "Your string is ill-formed - you can't use un-escaped double-quotes within a double-quoted string. .  Either you could do something like this: .  or, simply: .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_10086586",
      "task": "How to call powershell function properly?",
      "P-task": "call powershel function properli",
      "F_verb": "call",
      "P-body": "Your switch statment is wrong try this: .  ",
      "P-tags": "powershel function",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "so_40356582",
      "task": "PHP Startup: Unable to load dynamic library `curl.so` Ubuntu",
      "P-task": "php startup : unabl load dynam librari curl ubuntu",
      "F_verb": "load",
      "P-body": "Update php5.6(-common) to a newer version. This can be done using \"apt-get update && apt-get upgrade\". You have just updated php5.6-curl to the latest version but it depends on a newer php5.6. .  ",
      "P-tags": "php-extens php ubuntu-14 04 curl apach",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "ul_452541",
      "task": "Using awk to calculate 'rolling max' and print respective record from column 2",
      "P-task": "use awk calcul roll max print respect record column 2",
      "F_verb": "calculate",
      "P-body": "I don't think that looping over fields is what you want here. Instead just look at the record number (or file record number to allow it to work over multiple files) modulo 5: .   if the \"FNR\" is 1,6,... OR \"$2\" is greater than the current running max, save the current row / max .  if \"FNR\" is 5,10,... print the current row / max .   ",
      "P-tags": "awk",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP from NP"
    },
    {
      "id": "so_21191512",
      "task": "Get owner of one file, and apply it to another",
      "P-task": "get owner one file appli anoth",
      "F_verb": "get",
      "P-body": "Actually you want \"chown(1)\", not \"chmod(1)\" to change the owner. And GNU \"chown\", which you probably have if you're on Linux, has a nifty option \"--reference=file\" which will change the owner to be the same as in the referenced file. .   If you insist on doing it manually, or your \"chown\" doesn't have that option, you can store the output as a variable and use that: .  But be advised that \"ls\" does not guarantee stable output, i.e. you should not depend on the format. You might want to use \"stat\" as PaulProgrammer suggests. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_9919973",
      "task": "Application appears to run multiple times depending on input size",
      "P-task": "applic appear run multipl time depend input size",
      "F_verb": "run",
      "P-body": "This probably has something to do with \"xargs\"' \"ARG_MAX\" which defines a batch size for how many args to send to an executable; hence why multiple invocations of your script since it is splitting up the args across multiple calls. .  Try the \"-n\" (or \"--max-args\") flag of \"xargs\" . .  A better way alltogether would be to have \"simulate.py\" accept a file argument so you could do something like this: .  It would probably be a lot faster since it avoids the \"xargs\" overhead .  ",
      "P-tags": "python unix xarg",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_42708187",
      "task": "How to modify CMakelists for Qt5 from Windows to Linux?",
      "P-task": "modifi cmakelist qt5 window linux",
      "F_verb": "modify",
      "P-body": "finally solved version: .  ",
      "P-tags": "linux c++ qt qt5 cmake",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP for NP from NP to NP"
    },
    {
      "id": "so_48209064",
      "task": "setsid is not working, giving error",
      "P-task": "setsid work give error",
      "F_verb": "give",
      "P-body": "Just as if you were running it without \"setsid\" you need to tell it to execute with a complete path. .  ",
      "P-tags": "linux setsid shell",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_44513955",
      "task": "weird output when i run sh file.",
      "P-task": "weird output run sh file",
      "F_verb": "run",
      "P-body": "You should remove this  .  it is printing out the contents of /etc, and you are not seeing your wanted output .  ",
      "P-tags": "script termin sh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_124444",
      "task": "How can I cleanly add to $PATH?",
      "P-task": "cleanli add path",
      "F_verb": "add",
      "P-body": "Suppose that the new path that we want to add is: .  Then, using any POSIX shell, we can test to see if \"new\" is already in the path and add it if it isn't: .  Note the use of colons. Without the colons, we might think that, say, \"new=/bin\" was already in the path because it pattern matched on \"/usr/bin\". While PATHs normally have many elements, the special cases of zero and one elements in the PATH is also handled. The case of the PATH initially having no elements (being empty) is handled by the use of \"${PATH:=$new}\" which assigns \"PATH\" to \"$new\" if it is empty. Setting default values for parameters in this way is a feature of all POSIX shells: see section 2.6.2 of the POSIX docs.) .  A callable function For convenience, the above code can be put into a function. This function can be defined at the command line or, to have it available permanently, put into your shell's initialization script (For bash users, that would be \"~/.bashrc\"): .  To use this path update function to add a directory to the current PATH: .  ",
      "P-tags": "path shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V to NP"
    },
    {
      "id": "au_867735",
      "task": "How to print in following output",
      "P-task": "print follow output",
      "F_verb": "print",
      "P-body": "You only have 2 cases: .   the \"38=\" field comes before the \"11=\" (\"Clientid\") field the \"38=\" field comes after the \"11=\" (\"Clientid\") field  Therefore a KISS way to process the file is .  Testing: .  ",
      "P-tags": "sed awk command-lin text-process",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in NP"
    },
    {
      "id": "so_14799185",
      "task": "Create a process and tell it to sleep?",
      "P-task": "creat process tell sleep",
      "F_verb": "tell",
      "P-body": "Start with \"man fork\" which is slightly shorter than 9000 pages. The main thing is that successful \"fork\" returns two times: it returns 0 to the child process and the child's PID to the parent process. It's typically used like this: .  You don't normally tell the child process to do this and that, you just add code doing it to the appropriate \"if\" branch. .  In your example, if all forks are successful, you end up with 8 processes: .   First fork creates a new process, \"p1\" gets 0 in the new process and some pid in the parent. Second fork is called both in the original parent and in the child, adding 2 processes to the picture. \"p2\" gets 0 in all \"grandchildren\" and two different pids in 2 processes existing before step 2. Third fork is called in four different processes, adding four other processes to the picture.  ",
      "P-tags": "unix process fork c sleep",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_60839282",
      "task": "Cannot execute bash script in Snakemake",
      "P-task": "execut bash script snakemak",
      "F_verb": "execute",
      "P-body": "You need to replace \"script\" with \"shell\": .  ",
      "P-tags": "snakemak bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_1340263",
      "task": "What is the fastest way to find all the file with the same inode?",
      "P-task": "fastest way find file inod",
      "F_verb": "find",
      "P-body": "Here's a way: .   Use \"find -printf \"%i:\\t%p\" or similar to create a listing of all files prefixed by inode, and output to a temporary file Extract the first field - the inode with ':' appended - and sort to bring duplicates together and then restrict to duplicates, using \"cut -f 1 | sort | uniq -d\", and output that to a second temporary file Use \"fgrep -f\" to load the second file as a list of strings to search and search the first temporary file.  (When I wrote this, I interpreted the question as finding all files which had duplicate inodes. Of course, one could use the output of the first half of this as a kind of index, from inode to path, much like how locate works.) .  On my own machine, I use these kinds of files a lot, and keep them sorted. I also have a text indexer application which can then apply binary search to quickly find all lines that have a common prefix. Such a tool ends up being quite useful for jobs like this. .  ",
      "P-tags": "inod linux bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_223337",
      "task": "Trying to get the specific information from the array",
      "P-task": "tri get specif inform array",
      "F_verb": "get",
      "P-body": " This is a straightforward C-style for loop. You can ignore any of the fields you don't want to care about, and change the numbers. .   Wherever this array originally came from, you'd almost certainly be better off in general using a proper parser on the source text, but this does satisfy the scenario you've described adequately. As soon as it gets more complicated it's going to get much harder, though \u2014 it's only because it happens to be purely stepping by four that this works out simply. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "su_1266881",
      "task": "How to change the default user name in WSL?",
      "P-task": "chang default user name wsl",
      "F_verb": "change",
      "P-body": "As of the time of this answer in 2021 (and for a few years now), the current Microsoft recommended way of setting the username in an instance is to create a \"/etc/wsl.conf\" in the instance with the following setting: .  Changing, of course, username to be your default username. .  This works in WSL1, WSL2, and regardless of the distribution name. It even works if the distribution wasn't installed from the Store. .  ",
      "P-tags": "windows-subsystem-for-linux",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_36804",
      "task": "Which users are allowed to log in via SSH by default?",
      "P-task": "user allow log via ssh default",
      "F_verb": "allow",
      "P-body": "Paradeepchhetri isn't exactly correct.  .  Debian's unmodified \"sshd_config\" has the following: .  Thus, login via ssh would only work for users that have a populated password field in \"/etc/shadow\" or an ssh key in \"~/.ssh/authorized_keys\". Note that the default value for \"PubkeyAuthentication\" is \"yes\" and for \"PermitEmptyPasswords\" is \"no\", so even if you remove them the behavior will be the same. .  In the question example, \"www-data\" by default won't be allowed to log in since Debian's installer neither assigns a password nor creates a key for \"www-data\". .  \"pam_access\", \"AllowUsers\" and \"AllowGroups\" in \"sshd_config\" can be used for finer control if that's needed. In Debian it's strongly encouraged to \"UsePAM\". .  ",
      "P-tags": "linux debian login ssh user",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V S_INF via NP"
    },
    {
      "id": "so_28647532",
      "task": "Can not access rails console on ubuntu 14.04",
      "P-task": "access rail consol ubuntu 14 04",
      "F_verb": "access",
      "P-body": "It's a bug and described here. .  Run these following commands : .  And I think using \"RVM\" or \"RBENV\" is a popular practice amongst the Ruby Community to install and maintain ruby versions. .  Install \"Ruby\" using \"RVM\": .  Make sure you have logged in using shell: .  Terminal > Edit > Profile Preferences > Title and Command > Check Run command as a login shell .  Install depencies: .  Install \"RVM\" and \"Ruby 2.1.5\" .  To exclude documentation for each package: .  Before installing rails you can install node which will come along the v8 JS engine: .  Finally rails (optional):  .  ",
      "P-tags": "ubuntu server consol rubi ruby-on-rail",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP on NP"
    },
    {
      "id": "so_57930768",
      "task": "Prevent PowerShell ForEach-Object to flatten the list?",
      "P-task": "prevent powershel foreach-object flatten list",
      "F_verb": "prevent",
      "P-body": "You can take advantage of the fact that both \"Where-Object\" and \"ForEach-Object\" run the script blocks passed to them (\"{ ... }\") in the same scope, the caller's scope: .  That is, the \"$count\" variable that is assigned to in the \"Where-Object\" script block is accessible in the \"ForEach-Object\" script block as well, input object by input object. .  That said, you can do all you need with \"ForEach-Object\" alone: .  Note that I've switched from the \".Split()\" method to using PowerShell's more flexible \"-split\" operator. .   As for what you tried: .  Outputting an array (enumerable) to the pipeline causes its elements to be sent one by one rather than as a whole array. .  The simplest way to avoid that, i.e, to send an array as a whole, is to wrap such an array in an auxiliary single-element wrapper array, using the unary form of \",\", the array-construction operator: \", $_.Split(',')\" .  Note that enclosing a command in \"@(...)\" does not perform the same wrapping, because \"@(...)\" doesn't construct an array; loosely speaking, it merely ensures that the output is an array, so if the input already is an array - as in your case - \"@(...)\" is - loosely speaking - a (costly) no-op - see the bottom section of this answer for details. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_8839",
      "task": "Start with interactive console shell",
      "P-task": "start interact consol shell",
      "F_verb": "start",
      "P-body": "In your previous post you say \"I edited gdm.conf not to start.\". .  I think it can depend on how you modified that file, it is possible that you happen to go to the tty7 where gdm would start the X server, but without the X server started, so you have to change console to go to, say, tty1. .  If you do not use it, it should be better to remove the \"gdm\" package. .  ",
      "P-tags": "root boot keyboard consol",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V with NP"
    },
    {
      "id": "au_239672",
      "task": "How do I automatically create links to directories?",
      "P-task": "automat creat link directori",
      "F_verb": "create",
      "P-body": "You could write use below mentioned shell script to create links for those directories for existing users and could use skel so that links are automatically created when new users are added. .  Tested on my system. .  ",
      "P-tags": "symbolic-link user file-shar",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP to NP"
    },
    {
      "id": "au_39556",
      "task": "What is the command to open a webpage in a new chromium tab?",
      "P-task": "command open webpag new chromium tab",
      "F_verb": "open",
      "P-body": "Try this: \"chromium-browser www.google.de\" .  ",
      "P-tags": "chromium command-lin",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP"
    },
    {
      "id": "so_6976729",
      "task": "Why am I getting extra bits in my recv() calls with libnfqueue?",
      "P-task": "get extra bit recv call libnfqueu",
      "F_verb": "get",
      "P-body": "It seems that buffer contains char with value exceeding 128 and the signed/unsigned conversion error takes place. .  I've calculated the value of your byte - it is 164. Try to convert your bytes into unsigned chars before passing them to printf: .  ",
      "P-tags": "linux c network-program iptabl",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_47690668",
      "task": "How to prevent a svn user to avoid accessing other projects",
      "P-task": "prevent svn user avoid access project",
      "F_verb": "prevent",
      "P-body": " This is your issue. \"* = r\" means all users are given read access. And since this command is underneath the \"[/]\" (or root) directory, that means they have read access to everything in the repository. .  You have two options: .   Remove the \"* = r\" line from underneath the root directory. Underneath \"[project2:/]\" you can add a line that says \"@project1 =\"  With option #2, you have the ability to forbid certain users/groups from accessing a directory completely, however, doing this means they will still have access to any additional projects you may add to the repository and thus, you would need to continuously do option #2 for every project you add. I personally recommend option #1 and then only adding authenticated users to each project. Only admins should have root access in my opinion/experience. .  Also, since you've added \"admin = rw\" underneath \"[/]\" you don't need to add \"admin = rw\" underneath any projects, because they inherently get read/write access to the entire repository.  .  ",
      "P-tags": "svn apach ubuntu-16 04",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP S_ING"
    },
    {
      "id": "au_436171",
      "task": "Why the apt prompts me to enter the full phrase while purging a package?",
      "P-task": "apt prompt enter full phrase purg packag",
      "F_verb": "enter",
      "P-body": "\"login\" package consists of programs such as \"login\",\"newgrp\" and \"su\".These programs are also called system login tools.These tools are required to be able to login and use your system. .   The login program invokes your user shell and enables command execution.  .  The newgrp program is used to change your effective group ID (useful for workgroup type situations).  .  The su program allows changing your effective user ID (useful being able to execute commands as another user). .   This is an essential system package.So that the Warning message(This should NOT be done unless you know exactly what you are doing!) like below appears and asks you to enter the whole phrase \"Yes, do as I say!\", while you trying to purge the package \"login\" .   What will happen if i enter \"Y\" or \"Yes\"? .   You have to enter correct phrase \"Yes, do as I say!\", so that the package \"login\" will be removed.If you enter \"Y\" or \"Yes\", it will abort the process of purging the package.Even the exclamatory mark,spaces,upper and lowercase letters are considered strictly. .  After you successfully entered the phrase, dpkg removes the \"login\" package with force option enabled, .  ",
      "P-tags": "dpkg apt",
      "source": "qa",
      "cate": "enter",
      "pat": "V NP while S_ING"
    },
    {
      "id": "so_16556497",
      "task": "MySQL: How to reset or change the MySQL root password?",
      "P-task": "mysql : reset chang mysql root password",
      "F_verb": "change",
      "P-body": "Set / change / reset the MySQL root password on Ubuntu Linux. Enter the following lines in your terminal. .   Stop the MySQL Server: \"sudo /etc/init.d/mysql stop\" Start the \"mysqld\" configuration: \"sudo mysqld --skip-grant-tables &\"  In some cases, you've to create the \"/var/run/mysqld\" first: .   Login to MySQL as root: \"mysql -u root mysql\" Replace \"YOURNEWPASSWORD\" with your new password:  For MySQL < 8.0 .   Note: on some versions, if \"password\" column doesn't exist, you may want to try: \"UPDATE user SET authentication_string=password('YOURNEWPASSWORD') WHERE user='root';\" .   Note: This method is not regarded as the most secure way of resetting the password, however, it works. .  For MySQL >= 8.0 .  References: .   Set / Change / Reset the MySQL root password on Ubuntu Linux How to Reset the Root Password (v5.6) How to Reset the Root Password (v8.0)  ",
      "P-tags": "ubuntu mysql phpmyadmin",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_66088600",
      "task": "integrate head in a one-liner bash CLI",
      "P-task": "integr head one-lin bash cli",
      "F_verb": "integrate",
      "P-body": "Make the output of \"head\" the input of \"sha1sum\", just as the output of \"sha1sum\" is the input to \"cut\". .  or, if the file is binary, use the first N bytes with \"-c\" .  ",
      "P-tags": "pipe linux shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_517838",
      "task": "How to install debian jessie-backports package after package removal using Docker?",
      "P-task": "instal debian jessie-backport packag packag remov use docker",
      "F_verb": "install",
      "P-body": "To solve the issue I needed to pull all of the Debian main repository, for certbot to be installed correctly. .  ",
      "P-tags": "debian docker",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP after NP using NP"
    },
    {
      "id": "so_54705706",
      "task": "unable to match and replace using sed in unix",
      "P-task": "unabl match replac use sed unix",
      "F_verb": "replace",
      "P-body": "Sounds like you are simply looking for .  ",
      "P-tags": "awk sed unix",
      "source": "qa",
      "cate": "replace",
      "pat": "V using NP in NP"
    },
    {
      "id": "so_65702914",
      "task": "How do I remove openCV",
      "P-task": "remov opencv",
      "F_verb": "remove",
      "P-body": "Best way if you installed opencv from source and still have the build directory, simply go there and call \"make uninstall\". Another solution is to delete all opencv related files as you already know and suggested in many other similar questions like this. You could also try to use synaptic package manager if you installed using a package. I suggest for the future to install development libraries a custom folder, so it will be just a matter of deleting that folder if something goes wrong. In this way you can also have different opencv versions in your system, this is how I do. .  ",
      "P-tags": "opencv ubuntu ro",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "au_1349286",
      "task": "Cached Memory Takes all the memory",
      "P-task": "cach memori take memori",
      "F_verb": "take",
      "P-body": "Well, I've figured out my problem with the \"sync; echo 1 > /proc/sys/vm/drop_caches\" command, I misspelled this command somewhere, and now if I use this command properly then it cleans my cached memory, hence my problem seems to be solved, though more answers for future references and for community will be appreciated. .  ",
      "P-tags": "memory-usag cach ram",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_23632191",
      "task": "Bash array - pick selected members(slice) and put them into a new variable",
      "P-task": "bash array - pick select member slice put new variabl",
      "F_verb": "pick",
      "P-body": "Using array slicing: .  ",
      "P-tags": "array variabl bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_19252462",
      "task": "Locate files then Grep their contents",
      "P-task": "locat file grep content",
      "F_verb": "locate",
      "P-body": "you have to pass the filenames as arguments to grep: .  (the \"$(...)\" will evaluate the command and return it's stdoutput) .  ",
      "P-tags": "linux locat grep",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_23369255",
      "task": "Segmentation fault opening a file in ADA",
      "P-task": "segment fault open file ada",
      "F_verb": "open",
      "P-body": "I see you are using a multi-threaded program. When using gdb, note that 'bt' will not be terribly useful, as it only shows one thread (I can't rememeber if this is the main thread or the current thread). .  Instead, using the following: .  or .  Also, using \"strace -f -e trace=file your_program args\" will be useful to determine if the fault comes before or after the system call to open. .  It would be quite useful to know what version of the compiler you are using, and what options were used to build it (esp. if any warnings were disabled). .  Are the filename encoding anything more or less than US-ASCII? .  ",
      "P-tags": "linux ada segmentation-fault file-io",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP"
    },
    {
      "id": "so_39856314",
      "task": "When is scons \"Depends\" useful when compiling c/cpp files?",
      "P-task": "scon depend use compil c cpp file",
      "F_verb": "compile",
      "P-body": "It can be useful to force dependencies which SCons may not be aware of. For example you may use  .  It may be a simple command but you know it depends on a file \"templatefile.wxy\". .  You can either write a full builder with Scanner (which would probably be overkill in this case). Or use Command + Depends. .  ",
      "P-tags": "scon c++ linux depend",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP"
    },
    {
      "id": "so_16178820",
      "task": "PHP Script to Sort a Large Folder of Files into Date based Sub Folders",
      "P-task": "php script sort larg folder file date base sub folder",
      "F_verb": "sort",
      "P-body": "This might give you a starting point: .   get files iterate through files create new directory/file_name create directory if !exists copy file delete old file  Model: .  ",
      "P-tags": "file linux php",
      "source": "qa",
      "cate": "sort",
      "pat": "V NP of NP into NP"
    },
    {
      "id": "so_65798099",
      "task": "How to remove all list item permissions using PnP Powershell",
      "P-task": "remov list item permiss use pnp powershel",
      "F_verb": "remove",
      "P-body": "I tested to connect to SharePoint Online site with a read permission user in PnP PowerShell and then run the Set-PnPListItemPermission command, it will throw Access Denied error instead of adding with Full Control Permissions: .   .  In Summary, to set permssions for list item, it's expecetd to have the Full Control Permission on the site level for the user who is running the script. Otherwise, the Access Denied error will throw. .  The Full Control permissions should be applied with the site group, in the list, try to break permission inheritance and remove the group: .  ",
      "P-tags": "powershel permiss sharepoint",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "so_30623137",
      "task": "Remove numerous characters including underscore",
      "P-task": "remov numer charact includ underscor",
      "F_verb": "remove",
      "P-body": " ",
      "P-tags": "powershell-2 0",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "au_1025264",
      "task": "How can I download a .exe file from a given URL?",
      "P-task": "download exe file given url",
      "F_verb": "download",
      "P-body": "This link will be redirected to exe file. You can download it as usual: .  Or simply open link from your question with your web-browser. .  ",
      "P-tags": "execut wine",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_53067812",
      "task": "Grep to find a pattern and replace in same line",
      "P-task": "grep find pattern replac line",
      "F_verb": "replace",
      "P-body": "Why are you using grep at all? Sed does pattern matching: .  or:  .  If you are using \"grep\" to try to trim down the number of files that \"sed\" will operate on, you're fooling yourself if you believe that is more efficient. By doing that, you will read every file that doesn't match only once, but every file that does match will be read twice. If you only use \"sed\", every file will be read only once. .  ",
      "P-tags": "sed grep unix",
      "source": "qa",
      "cate": "replace",
      "pat": "V in NP"
    },
    {
      "id": "so_57930750",
      "task": "Invoke-Command InDisconnectedSession SessionOption and IdleTimeout One Liner",
      "P-task": "invoke-command indisconnectedsess sessionopt idletimeout one liner",
      "F_verb": "invoke",
      "P-body": "what about:  .  \"Invoke-Command -ComputerName localhost -Credential Administrator -ScriptBlock { ipconfig } -InDisconnectedSession -SessionOption (New-PSSessionOption -IdleTimeout 180000)\" .  Hope it helps.  .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "au_3539",
      "task": "How can I make and distribute an Ubuntu screensaver?",
      "P-task": "make distribut ubuntu screensav",
      "F_verb": "make",
      "P-body": "A screensaver in Linux is a pretty simple thing made up of two key parts: .   A graphical application that renders the images. A \".desktop\" file pointing to that application.  I'm not sure what end-result you're trying to achieve so I'll start in reverse. The \".desktop\" files for existing screensavers live in \"/usr/share/applications/screensavers/\". Here's \"ubuntu_theme.desktop\" for an example of what you're aiming for: .  If you want to float a different image around, you could just clone the launcher, and replace \"/usr/share/pixmaps/ubuntu-screensaver.svg\" with your own image (use SVGs where possible as they scale a lot better). .  If you want to write your own binary for a completely custom screensaver, you should probably start here: http://www.dis.uniroma1.it/~liberato/screensaver/ .  It uses very simple X graphics to do some pretty simple things. You can pimp it out with OpenGL but it's important you get the basics laid out first. .  Once you're done, packaging is its whole set of problems but for a very simple package, you can quickly bang a package out following something like this: https://help.ubuntu.com/community/PythonRecipes/DebianPackage .  But if you're serious about distributing this to lots of people you probably want to start with a PPA (a private repository). You can read about PPAs, building source packages, the build process, etc on LaunchPad's help system. .  ",
      "P-tags": "screensav program",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_49980714",
      "task": "How To Use Cloud Init To mount an unformatted EBS volume",
      "P-task": "use cloud init mount unformat eb volum",
      "F_verb": "use",
      "P-body": "cloud-init on Amazon Linux does not support the \"fs_setup\" module. Hence, your disk is not formatted. Furthermore the home directory /jenkins is created for the user, and used as a mount point. This hides the home directory. .  I would suggest: .  ",
      "P-tags": "amazon-ec2 linux cloud-init user-data amazon-linux",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_60397436",
      "task": "How to use PERF_SAMPLE_READ with mmap",
      "P-task": "use perf_sample_read mmap",
      "F_verb": "use",
      "P-body": "I've found the bug ! .  The problem is that the kernel don't support the use of PERF_SAMPLE_READ when the \"inherit\" member of the \"perf_event_attr\" structure is set. .  The following code is from the kernel sources : https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/kernel/events/core.c#n10788 .  ",
      "P-tags": "c++ linux perf linux-kernel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_29027827",
      "task": "How can I change the output of SqlPlusresults with PLSQL?",
      "P-task": "chang output sqlplusresult plsql",
      "F_verb": "change",
      "P-body": "You're simply missing a \"-s\" flag in your call to \"sqlplus\". Example code:  .  Example output without the \"-s\" flag: .  Example with the \"-s\" flag: .  ",
      "P-tags": "plsql oracle-sqldevelop sqlplu shell sql",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP with NP"
    },
    {
      "id": "so_1802127",
      "task": "How to run a PowerShell script without displaying a window?",
      "P-task": "run powershel script without display window",
      "F_verb": "run",
      "P-body": "You can either run it like this (but this shows a windows for a while): .  Or you use a helper file I created to avoid the window called PsRun.exe that does exactly that. You can download source and exe file Run scheduled tasks with WinForm GUI in PowerShell. I use it for scheduled tasks. .  Edited: as Marco noted this -windowstyle parameter is available only for V2. .  ",
      "P-tags": "silent batch-fil script powershel window",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_36219931",
      "task": "Permission Denied launching python script on Mint 17.3",
      "P-task": "permiss deni launch python script mint 17 3",
      "F_verb": "deny",
      "P-body": "Two options: .   Invoke \"[\"python\", \"myscript.py\"]\" instead of trying to execute the script directly.  .  Programmatically \"chmod\" it to add the executable flag .   ",
      "P-tags": "javascript linux-mint cinnamon python applet",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP on NP"
    },
    {
      "id": "so_52348221",
      "task": "Can I use \"mount\" inside a Docker Alpine container?",
      "P-task": "use mount insid docker alpin contain",
      "F_verb": "mount",
      "P-body": "You won't be able to safely do this inside of a container. Docker removes the mount privilege from containers because using this you could mount the host filesystem and escape the container. However, you can do this outside of the container and mount the filesystem into the container as a volume using the default local driver. The size option isn't supported by most filesystems, tmpfs being one of the few exceptions. Most of them use the size of the underlying device which you defined with the image file creation command: .  I had trouble getting docker to create the loop device dynamically, so here's the process to create it manually: .  When defining the volume mount options are passed almost verbatim from the mount command you run on the command line: .  or in a single service create command: .  With \"docker run\", the command looks like: .  The only prerequisite is that you create this file and loop device before creating the service, and that this file is accessible wherever the service is scheduled. I would also suggest making all of the paths in these commands fully qualified rather than relative to the current directory. I'm pretty sure there are a few places that relative paths don't work. .  ",
      "P-tags": "mount sh alpin docker",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V inside NP"
    },
    {
      "id": "so_34685538",
      "task": "Java getting bash root access",
      "P-task": "java get bash root access",
      "F_verb": "get",
      "P-body": "Your \"runBash()\" method is poorly named, as it does nothing to cause the given command to be run via \"bash\". It is therefore also inappropriate for use with a command string such as you are specifying, which relies on the shell's pipe operator to string two separate commands together. .  When you do this ... .  ... Java splits the string on whitespace, takes the first substring (\"echo\") as the command, and executes that command with all the other substrings strings as arguments. Needless to say, that will run without error, but also without the effect you intended. .  If you really want to execute the command string via bash (as it appears you do), then in your \"runBash()\" method you could change this ... .  ... to this ... .  . That should at least get you past your first hurdle. .  You also should close the \"Process\"'s \"OutputStream\" (by which you could have piped data into the process), and drain the \"Process\"'s error stream. In general, you need to drain the input and error streams in parallel, because if either one's buffer fills up then the process can block. Perhaps that's not a risk for this particular command, but you'll need to judge. It's also good form to \"waitFor()\" the \"Process\"; doing so may avoid Java accumulating zombie child processes. .  ",
      "P-tags": "root linux sudo java",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_57150765",
      "task": "Compare two files and append the differences at the end",
      "P-task": "compar two file append differ end",
      "F_verb": "append",
      "P-body": "I think you can solve this problem by using \"diff -U <large number>\". This will give you output that will be easy to parse to reconstruct what you want. If \"<large number>\" is larger than the longer of your two files, then you will get a predictable output format: .  Then you can use grep and sed to reconstruct the two output files you want: .  Notes: .   \"sed '1,3d'\" just deletes the first three lines of the diff output, since they're not contents. I previously had \"tail +3\" here but that is not so portable; sed is safer. The first grep extracts lines in common (start with a space in the diff). The next two greps extract lines not in common (\"-\" means in \"file1\" only, \"+\" in \"file2\" only). If \"file1\" and \"file2\" are identical, this will yield empty output files.  ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP at NP"
    },
    {
      "id": "so_40026728",
      "task": "Get TFS Build Process Parameters",
      "P-task": "get tf build process paramet",
      "F_verb": "get",
      "P-body": "I was missing a reference to Newtonsoft.Json.dll: .  I added that in, and all was well. .  Final script: .  ",
      "P-tags": "powershel tf",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_48355825",
      "task": "How can i switch python version, that runs by command \"python\" in UBUNTU 14.04",
      "P-task": "switch python version run command python ubuntu 14 04",
      "F_verb": "run",
      "P-body": "It is not recommended to change default python. You just type 'python3' .  Or take a look at this Two versions of python on linux. how to make 2.7 the default .  ",
      "P-tags": "python-2 7 ubuntu python python-3 x",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V by NP in NP"
    },
    {
      "id": "ul_257861",
      "task": "Automatically add slash when navigating through symlink",
      "P-task": "automat add slash navig symlink",
      "F_verb": "add",
      "P-body": "Set the \"mark-symlinked-directories\" readline option. .  The usual way to do this is to edit \"~/.inputrc\", put .  in there, then start a new bash shell (or press Ctrl+X Ctrl+R to reload your readline settings). .  Less commonly, you could also put it straight in your \"~/.bashrc\" like this .  ",
      "P-tags": "cd-command autocomplet symlink bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP when S_ING through NP"
    },
    {
      "id": "so_23991830",
      "task": "libthrift-0.9.1.so: cannot open shared object file: No such file or directory",
      "P-task": "libthrift-0 9 1 : open share object file : file directori",
      "F_verb": "open",
      "P-body": "When a dynamic library is used (\"-lthrift\"), Linux searches for the directory containing \"libthrift.so\" in the directories within the environment variable \"LD_LIBRARY_PATH\", you must make sure that the directory containing \"libthrift.so\" is setup correctly in the environment variable \"LD_LIBRARY_PATH\". .  ",
      "P-tags": "thrift c++ linux compil",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "ul_115377",
      "task": "mount --bind other user as myself",
      "P-task": "mount -- bind user",
      "F_verb": "mount",
      "P-body": "You can't do that with the Linux bind mount kernel feature. But you can do it with the FUSE filesystem bindfs. Bindfs is slower than bind mounts and doesn't pass extended attributes, but on the flip side, it can be used by non-root users and on Unix variants other than Linux, and most importantly for you, allows simple transformations of ownership and permissions. .  In \"/etc/fstab\", that would translate to: .  ",
      "P-tags": "mount bind-mount",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP as NP"
    },
    {
      "id": "so_2160190",
      "task": "imports while starting an interactive shell",
      "P-task": "import start interact shell",
      "F_verb": "start",
      "P-body": "\"-v\" traces the first import of a module -- the one that actually loads the module (executes its code, and so may take a bit of time) and sticks it into \"sys.modules\". .  That has nothing to do whether your interactive session (module \"__main__\") gets the module injected into its namespace, of course. To ensure module \"'goo'\" does get into the namespace of module \"'X'\" (for any \"X\", so of course including \"__main__\"... among many, many others), module \"'X'\" just needs to \"import goo\" itself (a very fast operation indeed, if \"sys.modules['goo']\" is already defined!-). .  ",
      "P-tags": "django python import shell",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_38241072",
      "task": "how can I download a file from a url(not a direct url) in Linux",
      "P-task": "download file url direct url linux",
      "F_verb": "download",
      "P-body": "You need to put quotation marks around the URL because of the special characters: .  ",
      "P-tags": "linux wget",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_548417",
      "task": "Can't mount NTFS drive - \"NTFS signature is missing.\"",
      "P-task": "mount ntf drive - ntf signatur miss",
      "F_verb": "mount",
      "P-body": "You are trying to mount whole Hard Disk drive instead of Partition on it. Try mounting \"/dev/sdc1\" instead of \"/dev/sdc\". .  ",
      "P-tags": "server hard-driv mount ntf 14 04",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "ul_391223",
      "task": "Why am I getting \"line 1: $' :\\r': command not found\"?",
      "P-task": "get line 1 : : r : command found",
      "F_verb": "get",
      "P-body": "You have Windows-style line endings. .  The no-op command \":\" is instead read as \":<carriage return>\", displayed as \":\\r\" or more fully as \"$':\\r'\". .  Run \"dos2unix scriptname\" and you should be fine. .   If you don't have \"dos2unix\", the following should work almost anywhere (and I tested on MobaXterm on Windows): .  Then in \"vi\", type: .  You're good to go. .   In \"vim\", which is what you are using on Cygwin for \"vi\", there are multiple ways of doing this. Another one involves the \"fileformat\" setting, which can take the values \"dos\" or \"unix\". Either explicitly change it after loading the file with  .  or explicitly force the file format when writing out the file with  .  .  For more on this, see the many questions and answers here covering this subject, including: .   Remove ^M character from log files Why is vim creating files with DOS line endings? How to add a carriage return before every newline?  ",
      "P-tags": "cygwin shell-script newlin bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_287623",
      "task": "Replace only the first character of a matched pattern",
      "P-task": "replac first charact match pattern",
      "F_verb": "replace",
      "P-body": "You can find lines that begin with two digits using either \"^[0-9][0-9]\" or \"^[0-9]\\{2\\}\" .  Then you can replace a single character with 0 using \"s/./0/\" .  Putting it together, .  or .  ",
      "P-tags": "sed text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP of NP"
    },
    {
      "id": "so_40654612",
      "task": "Will Hostname rename affect git",
      "P-task": "hostnam renam affect git",
      "F_verb": "rename",
      "P-body": "Change you host name does not affect git, but username or homedir do. .  SSH connection uses SSH-key files located in your \"<home-directory>/.ssh/\" folder. So, if you change the user - be sure your new home folder contains folder \".ssh/\" with original files. I think you can backup the folder (.ssh) before you create/rename user and his home folder. .  In case you want create a new SSH-key files - use \"ssh-keygen\" utility. It requires to add content of ssh public key to your user settings in gitolite server .  ",
      "P-tags": "hostnam git ubuntu",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_30635061",
      "task": "Turning off ADB over WiFi through ADB shell?",
      "P-task": "turn adb wifi adb shell",
      "F_verb": "turn",
      "P-body": "\"adbd\" is the adb daemon that runs on your devices, awaiting connection. .  issuing \"stop adbd\" should kill it - you may have to run this as root, should stop adb on the device, and disconnect your active shell. .  edit .  just tried this and it worked for me, running cyanogenmod. using \"adb connect <ip>\", and entering an adb shell, \"su\" for super user privileges, and then issue \"stop adbd\". your shell should terminate, and you will not be able to reconnect until you restart it from your device. shell or settings menu) .  ",
      "P-tags": "android android-developer-api shell adb",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP over NP through NP"
    },
    {
      "id": "so_25373993",
      "task": "How to show \"npm outdated\" current != wanted lines only?",
      "P-task": "show npm outdat current\nwant line",
      "F_verb": "show",
      "P-body": "\"npm outdated | awk '$2!=$3'\" will do what you want. .  ",
      "P-tags": "javascript consol npm bash node js",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "so_34945641",
      "task": "system() executes shell command differently C++",
      "P-task": "system execut shell command differ c++",
      "F_verb": "execute",
      "P-body": "Edit: The old idea of mis-placed quotes was wrong; I realize that \"-w\" is actually an option to \"output_http.so\", so the whole shebang must be passed as a single parameter to the \"-o\" option, as shown here or here etc. .  In that case, check file permissions etc. Does /usr/local/www exist? Is it possible that you are running the shell command from a root shell? .   Hey, I have a book recommendation, too, \"one of the best tech books ever published\": Stevens' Advanced Programming in the Unix Environment. The guy knows -- sorry: knew -- what he was talking about. .  ",
      "P-tags": "c++ linux shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_235331",
      "task": "Iterate Through Sets of Command Arguments in Bash",
      "P-task": "iter set command argument bash",
      "F_verb": "iterate",
      "P-body": "This approach uses three arrays, one for each argument of the \"my_command\": .  Alternate style Depending on how many commands are to be run, you may want to consider the following alternative for defining the arrays: .  ",
      "P-tags": "shell-script shell bash",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V through NP in NP"
    },
    {
      "id": "so_62822515",
      "task": "What type of unix commands can I use to capture the permissions from \"ls -ld\" and output it in a certain format?",
      "P-task": "type unix command use captur permiss ls -ld output certain format",
      "F_verb": "capture",
      "P-body": "Hopefully this is what you're after (I've omitted \"/\" from the \"ls\" in my example) .  The additional sed command captures each character from the output of awk and prepends a space before it. .  Hope that helps! .  ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_22622233",
      "task": "Windows Linux c++ compiling issue: \"no matching function for call\"",
      "P-task": "window linux c++ compil issu : match function call",
      "F_verb": "compile",
      "P-body": "Microsoft's C++ compiler incorrectly allows binding non-\"const\" references to temporary variables. They won't fix the bug now, because it would break existing code. But that code already is broken on conformant compilers, as you've discovered. .  See if you can't pass by value (for small types) or by const reference (for ones that are expensive to copy). If it's an output argument, you'll need to change the caller to pass an lvalue instead of a temporary. .  ",
      "P-tags": "c++ linux compiler-error compil",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP for NP"
    },
    {
      "id": "so_13762625",
      "task": "Bash while read loop extremely slow compared to cat, why?",
      "P-task": "bash read loop extrem slow compar cat",
      "F_verb": "compare",
      "P-body": "The reason \"while read\" is so slow is that the shell is required to make a system call for every byte. It cannot read a large buffer from the pipe, because the shell must not read more than one line from the input stream and therefore must compare each character against a newline. If you run \"strace\" on a \"while read\" loop, you can see this behavior. This behavior is desirable, because it makes it possible to reliably do things like: .  in which the commands inside the loop are reading from the same stream that the shell reads from. If the shell consumed a big chunk of data by reading large buffers, the inner commands would not have access to that data. An unfortunate side-effect is that \"read\" is absurdly slow. .  ",
      "P-tags": "linux perform shell bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V to NP"
    },
    {
      "id": "so_16286149",
      "task": "bash alias - running two commands",
      "P-task": "bash alia - run two command",
      "F_verb": "run",
      "P-body": "If you want to pass an argument, you can't use an alias. You need to use a shell function. It sounds like you want something similar to .  ",
      "P-tags": "linux sh shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_31274200",
      "task": "How to start Java program as root but downgrade to non-root user",
      "P-task": "start java program root downgrad non-root user",
      "F_verb": "start",
      "P-body": "Unfortunately there is no way to do this in pure Java. But you can use JNI or JNA to call \"setuid\" system function. For instance, you may reuse \"jetty-setuid\" package for doing so: JAR + Native library. .  ",
      "P-tags": "secur linux java permiss userid",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP as NP"
    },
    {
      "id": "au_195468",
      "task": "Program/Wrapper (how do you call it) to automate a certain script",
      "P-task": "program wrapper call autom certain script",
      "F_verb": "call",
      "P-body": "You could use cron to schedule the call of your script, but cron can only run a script every minute. It can't go faster than this, so it is probably not fast enough for your use. .  It sounds like a really bad idea to run every few milliseconds, but if that's what you really want you can run the script below in the background: .  ",
      "P-tags": "script window window-manag",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_841197",
      "task": "Logs of Ubuntu going into Sleep and waking up?",
      "P-task": "log ubuntu go sleep wake",
      "F_verb": "go",
      "P-body": "The favorite place for me (but not the only place) is accessed using: .  To view older log records look at: .  ",
      "P-tags": "suspend power-manag",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V into NP"
    },
    {
      "id": "au_695536",
      "task": "How to Install Xfce Desktop Environment from \"xfce-4.6.1-src.tar.bz2\"?",
      "P-task": "instal xfce desktop environ xfce-4 6 1-src tar bz2",
      "F_verb": "install",
      "P-body": "First you want this file, use another PC to get it. .  OK This is going to take you a long time, you must compile each part individually .  First put the file in your /home folder and extract the package .  That will extract to a folder called \"src\", change to this folder .  In here are lots of tar.bz2 files, you must compile each one in the following order .  Now this is an issue for you, you need these xfce dependancies,  .  If they are not installed the build will just fail, if it fails you can google .debs for all of these and download them on another PC. .  Now we will build the first package, extract it .  Enter its directory .  Now configure .  Now make .  Now install it .  Now go back to the src directory  .  Extract, configure and make the next one .  You get the point, once all packages are successfully made and installed in the correct order, you can log out and select \"xfce\" from log in screen. .  SOURCE .  ",
      "P-tags": "xfce package-manag software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP from NP"
    },
    {
      "id": "au_708549",
      "task": "How to select language keyboard by hotkey?",
      "P-task": "select languag keyboard hotkey",
      "F_verb": "select",
      "P-body": "The way unity/gnome change their language settings is through \"gsettings\" schema \"org.gnome.desktop.input-sources\", and the key \"current\". I've used it in several other scripts before to answer questions on Askubuntu.  .  Basic idea is that you run command .  Where $1 is the number of the language source. Language sources are ordered starting from 0, just like shown in your drown down menu with all the languages. So suppose my language order is english, chinese, russian. English is source 0, chinese is source 1, russian is source 3. .  So what can one do is go to System Settings -> Keyboard -> Shortcuts -> Custom. By clicking plus mark, create 3 shortcuts, for 3 numbers. I suggest you use Ctrl+Shift+number, because Ctrl+number may be taken by an application, like firefox for it's own internal usage. .  This I bind Ctrl+Shift+1 to \"gsettings set org.gnome.desktop.input-sources current 0\" for english. Repeat same process for chinese: Ctrl+Shift+2 to \"gsettings set org.gnome.desktop.input-sources current 1\". Repeat the same for other sources .  ",
      "P-tags": "shortcut-key keyboard-layout",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP by NP"
    },
    {
      "id": "so_2935704",
      "task": "Running shell commands without a shell window",
      "P-task": "run shell command without shell window",
      "F_verb": "run",
      "P-body": "I imagine your observation is limited to Windows, since that, I believe, is the only platform on which you'll get that \"console flash\" issue. If so, then the docs offer the following semi-helpful paragraph: .   The startupinfo and creationflags, if given, will be passed to the underlying CreateProcess() function. They can specify things such as appearance of the main window and priority for the new process. Windows only) .   Unfortunately the Python online docs do not reproduce the relevant portion of the Windows API docs, so you have to locate those elsewhere, e.g. starting here on MSDN which leads you here for the \"creationflags\", and specifically to .   The process is a console application that is being run without a console window. Therefore, the console handle for the application is not set. .   So, adding \"creationflags=0x08000000\" to your \"Popen\" call should help (unfortunately I have no Windows-running machine on which to try this out, so you'll have to try it yourself). .  ",
      "P-tags": "subprocess python window shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without NP"
    },
    {
      "id": "au_665647",
      "task": "How to make it so that a file can only be executed by root, but not as root?",
      "P-task": "make file execut root root",
      "F_verb": "make",
      "P-body": "Try using \"setuid\" from package \"super\". Do \"sudo apt-get install super\", then create a shell script that can only be run as root. Have that shell script run only one command: .  Then, set an alias for each of the users so that \"applicationcommand\" points to the shell script you created by adding into each of their \".bashrc\" files: .  Alternatively, or as well as creating an \"alias\" you can edit the \".desktop\" file of the application you want to run, assuming that your applications has a \".desktop\" file (if it's not an application that runs in the GUI, but rather the CLI it is likely not to have a \".desktop\" file), so that the \"Exec=\" line has \"sh /path/to/shell/script\" after it, or the name of the alias if you decided to create that. You will find \".desktop\" files in \"/usr/share/applications\" and \"~/.local/share/applications\". .  ",
      "P-tags": "password execute-command permiss root",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP that S"
    },
    {
      "id": "so_54476097",
      "task": "Jenkins error :54: expecting anything but ''\\n''; got it anyway",
      "P-task": "jenkin error :54 : expect anyth n got anyway",
      "F_verb": "get",
      "P-body": "Groovy doesn't like a newline in a GString. According to the Grails cookbook you can make multiline Strings using either \"'''Your multiline String'''\" or \"\"\"\"Your multiline ${GString}\"\"\"\". .  I'm not very sure on bash syntax, but you also seem to be missing a semicolon after \"if [ -e dev.ear ]\" according to these docs. .  Putting it all together: .  ",
      "P-tags": "jenkin jenkins-groovi shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_49569796",
      "task": "How can create new user on tableau server in python",
      "P-task": "creat new user tableau server python",
      "F_verb": "create",
      "P-body": "You can added users to your server using a python client library like server-client-python .  From the documentation you can add a new user using the User.add method as shown below .  You first take in arguments for the server address, username and password. Then use the TableauAuth method to authenticate the user. After connecting create a new user object by using the UserItem method passing in the name and role for the user.  .  ",
      "P-tags": "ubuntu tableau-api python",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP in NP"
    },
    {
      "id": "so_30904024",
      "task": "Variable not resetting during loop creating misleading output",
      "P-task": "variabl reset loop creat mislead output",
      "F_verb": "reset",
      "P-body": " I fully support Matt's answer! Either of those two options are simple solutions to your problem. What I offer is more of a re-write with some definite changes to how some things are done. I dropped the stream writer in favor or collecting results, and dumping them to a file at the end with Set-Content (why lock open a file for the whole process and write little bits to it when you can just do it all at once at the end?). Also, I create your computer object at the beginning of each loop, and skip the \"$IsOnline\", \"$Status\", and \"$errmsg\" variables all together. Then for each loop I add that object to an array (created before the loop), and at the end I output that. .  Oh yeah, I also output the whole thing as a CSV so that it can be easily opened in Excel in case you need to work with it later (filter for systems that failed to update, were offline, or whatever). .  ",
      "P-tags": "error-handl powershel",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V during NP S_ING"
    },
    {
      "id": "au_28216",
      "task": "Setting the Python path for the trunk version of Django",
      "P-task": "set python path trunk version django",
      "F_verb": "set",
      "P-body": "From bash (or other shell) you can manipulate the $PYTHONPATH to point to the parent directory, e.g., \"echo $PYTHONPATH\" \"export PYTHONPATH=\"/newhome/django_x.x/trunk\"\" .  This will prepend the paths given to the existing python path list. .  python.org : .   For example, if PYTHONPATH is set to \"/www/python:/opt/py\", the search path will begin with  .  (Note that directories must exist in order to be added to sys.path; the site module removes paths that don\u2019t exist.) .   From within python, you can also change sys.path (\"import sys\" if you haven't) to point to your testing branch. .  Example from python.org : .  To add a path, use something like : .  A Django-centric example from djangotricks (blog) : .   Additionally, unless you've suppressed the behavior, python loads \"site.py\" on execution, so you can also edit the \"site.py\" file, e.g. \"/usr/lib/python2.7/site.py\" : .  The comments of the \"site.py\" file are also instructive. .    References: python.org docs, v2.7 search path python.org docs, v3 search path Djangotricks blog, a note on python paths Martin Jansen : Django settings files for development and production .  ",
      "P-tags": "django python",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP of NP"
    },
    {
      "id": "ul_116036",
      "task": "How to enable libass on Linux?",
      "P-task": "enabl libass linux",
      "F_verb": "enable",
      "P-body": "First you need to make sure that your particular version of \"ffmpeg\" was built with and supports that switch. You'll also likely need to make sure that the library \"libass\" is installed as well. .  You don't specify your Linux distro but I did notice that \"libass\" is available in my stock Fedora 19 repository so it's trivial to install. .  Now back to \"ffmpeg\"'s support of \"libass\". You can confirm how it was built by simply running it without any arguments. .   $ ~/ffmpeg |& grep libass configuration: --prefix=/root/ffmpeg-static/64bit --extra-cflags='-I/root/ffmpeg-static/64bit/include -static' --extra-ldflags='-L/root/ffmpeg-static/64bit/lib -static' --extra-libs='-lxml2 -lexpat -lfreetype' --enable-static --disable-shared --disable-ffserver --disable-doc --enable-bzlib --enable-zlib --enable-postproc --enable-runtime-cpudetect --enable-libx264 --enable-gpl --enable-libtheora --enable-libvorbis --enable-libmp3lame --enable-gray --enable-libass --enable-libfreetype --enable-libopenjpeg --enable-libspeex --enable-libvo-aacenc --enable-libvo-amrwbenc --enable-version3 --enable-libvpx .   So the version that I have, does include this support, \"--enable-libass\". If your version of \"ffmpeg\" doesn't support it you can simply download a static build: .   https://johnvansickle.com/ffmpeg/  ",
      "P-tags": "ffmpeg linux",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP"
    },
    {
      "id": "so_40454390",
      "task": "Mnesia can't create tables when ran by Yaws, but can when ran from the Erlang shell",
      "P-task": "mnesia creat tabl ran yaw ran erlang shell",
      "F_verb": "create",
      "P-body": "When you run Yaws, pass the command-line option \"--mnesiadir dir\" to tell it where you want it to store mnesia data. The \"dir\" argument of the option should be the pathname of the directory where you want the data to live. For example, passing \"--mnesiadir /tmp\" will cause Yaws to store mnesia data in the \"/tmp\" directory. .  BTW, you can see the same error with the Erlang shell without Yaws if you pass it an mnesia \"dir\" option that sets the mnesia data directory to something nonexistent: .  Here, we assume there's no such directory \"/xyzfoo\". The first Erlang shell command defines the same \"user\" record you're using, and the second command performs the same steps as your \"authenticate:setup/0\" function. As shown, it returns the same error you're seeing with Yaws. .  Note that the unusual quoting shown here for the directory name, \"'\"/xyzfoo\"'\", needed for passing the option properly to the Erlang shell (on typical UNIX-based systems, anyway), isn't necessary for the Yaws \"--mnesiadir\" option. Also note that the Erlang option is a single hyphen followed by two words, \"mnesia\" and \"dir\", followed by the quoted directory name, whereas for Yaws the option is one word \"mnesiadir\" preceded by two hyphens and followed by a plain directory name. .  EDIT: if after setting the mnesia dir for Yaws you're still seeing problems, it's because you're trying to create your schema after mnesia is already running. When Yaws sees the \"--mnesiadir\" option, it starts the mnesia application. You should, therefore, either create your schema before you run Yaws, or stop mnesia before creating your schema. Change your \"authenticate:setup/0\" function to the following, and it will work from Yaws: .  ",
      "P-tags": "erlang-shel erlang web mnesia yaw",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP when S"
    },
    {
      "id": "so_4964060",
      "task": "Variable Not Being Set When sh Script is Called With PHP shell_exec()",
      "P-task": "variabl set sh script call php shell_exec",
      "F_verb": "set",
      "P-body": "try adding dbl-quotes around the output of your variable assignment for imageList .  I hope this helps. .  P.S. as you appear to be a new user, if you get an answer that helps you please remember to mark it as accepted, or give it a + (or -) as a useful answer  .  ",
      "P-tags": "sh php shell-exec",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V when S"
    },
    {
      "id": "ul_318833",
      "task": "How do I find a word in a file and insert text two lines below that?",
      "P-task": "find word file insert text two line",
      "F_verb": "find",
      "P-body": "  \"N;N;\" get next two lines \"s/$/\\nyay/\" add another line  ",
      "P-tags": "linux find sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_23004784",
      "task": "Mac command - check free space on USB?",
      "P-task": "mac command - check free space usb",
      "F_verb": "check",
      "P-body": "You can find free space in kilobytes using the \"df\" command: .  Since you will need to use that number, you'll need to assign it to a variable: .  Then you can compare it against another number: .  And finally eject the volume: .  Note, however, that checking for free space is probably not the most robust approach. Flash drives from different manufacturers differ slightly in size, even if they're the same nominal capacity. Also flash memory degrades with use and defective blocks might get remapped to working ones, further reducing the total capacity of the drive. Even if you have the same contents, free space can differ. .  If you actually have a template directory containing the files needed on the flash drive, you can compare it against the contents of the drive: .  This will print out all differences, but you can also take action based on whether there are differences, discarding the actual output from \"diff\": .  Manual pages: .  \"df\" \"umount\" \"diff\" Shell Scripting Primer .  ",
      "P-tags": "shell maco",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP on NP"
    },
    {
      "id": "so_60888129",
      "task": "Using sed to replace value in lines, between specific line number range in a file",
      "P-task": "use sed replac valu line specif line number rang file",
      "F_verb": "replace",
      "P-body": "Just add the line numbers in commas .  ",
      "P-tags": "bash sed regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP between NP in NP"
    },
    {
      "id": "au_7776",
      "task": "How do I lock the desktop screen via command line?",
      "P-task": "lock desktop screen via command line",
      "F_verb": "lock",
      "P-body": "You can lock the computer by running \"gnome-screensaver-command\" with the \"-l\" flag like so: .  However this will only work if you have Gnome Screensaver running for your session (should be - unless you've disabled it) you can start that from the commandline with: .  ",
      "P-tags": "lock-screen command-lin",
      "source": "qa",
      "cate": "lock/seal/relock",
      "pat": "V NP via NP"
    },
    {
      "id": "so_44829079",
      "task": "Disable the arrow keys while a JAR is executed",
      "P-task": "disabl arrow key jar execut",
      "F_verb": "disable",
      "P-body": "Now this is rather convoluted, but it`s still better than nothing. .  The code below is a primitive BASH key filter to bypass cursor keys and halt any input on pressing Enter. Currently it lacks backspace support, but this is also doable if need be. .  Requires BASH 4.2 or greater. .   \"read\" is a BASH built-in function that captures keyboard input. \"echo\" is a BASH built-in function that prints what it`s told. \"tee\" redirects the output to both STDOUT and the file provided. \">()\" is the so-called process substitution; it acts like a file for the writer and passes the resulting file`s contents as input to the command inside its brackets. \"stdbuf\" disables output buffering, just in case.  Both \"tee\" and \"stdbuf\" are parts of \"coreutils\", so they have to be present almost everywhere (maybe except Android, but that`s another story). .  [UPD.] Last line, adapted: .  Hopefully that`d work. .  [UPD2.] FINALLY! A different solution! .  Just add this before \"eval\": .  Okay, this is also not perfect (the user is now able to travel the screen by pressing cursor keys\u2026) but that`s still better than \"^[[B^[[A^[[D^[[C\" .  ",
      "P-tags": "sh jar bash",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP while S"
    },
    {
      "id": "su_1404099",
      "task": "Unable to change kernel.perf_event_paranoid",
      "P-task": "unabl chang kernel perf_event_paranoid",
      "F_verb": "change",
      "P-body": "It turned out, for some reason the system just didn't want me to change the kernel.perf_event_paranoid, while in session.  .  So I ran  .  and rebooted the system and now it works like a charm. .  ",
      "P-tags": "ubuntu perf",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_7452050",
      "task": "Running C++ program multiple times",
      "P-task": "run c++ program multipl time",
      "F_verb": "run",
      "P-body": "In POSIX shells, .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_568455",
      "task": "Remove directory of a known file in CentOS 6",
      "P-task": "remov directori known file cento 6",
      "F_verb": "remove",
      "P-body": "One solution would be using \"php\" to remove the filename from the location. .  However, if you prefer a shell solution, I'd suggest using \"dirname\". .  ",
      "P-tags": "cento php rm",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_26393687",
      "task": "why use int[2] array when creating a pipe?",
      "P-task": "use int 2 array creat pipe",
      "F_verb": "use",
      "P-body": "The two FDs correspond with the two sides of a pipe. By its nature, a pipeline has an input end and an output end -- more than that doesn't make sense. .  If you pass in anything larger than an \"int[2]\", the other slots will be unused. .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S_ING"
    },
    {
      "id": "so_60337793",
      "task": "Get substring from path",
      "P-task": "get substr path",
      "F_verb": "get",
      "P-body": "Use \"cut\": .  Store output in a variable: .  Using \"grep\" + \"sed\": .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_361142",
      "task": "Graphical interface not logging in",
      "P-task": "graphic interfac log",
      "F_verb": "log",
      "P-body": "The suggested fix found in the a FreeBSD forum is to create a \"~/.xinitrc\" and call your desktop manager, lumina in my case, from it. The \".xinitnrc\" also has to have the executable bit set. .  As in: .  After this change, I am able to login using \"slim\". .  ",
      "P-tags": "freebsd slim xorg",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in"
    },
    {
      "id": "so_49323749",
      "task": "Azure Powershell command unable to store bacpac file in Azure blob storage",
      "P-task": "azur powershel command unabl store bacpac file azur blob storag",
      "F_verb": "store",
      "P-body": "Your problem that you specify container address as a target. You need to put full desired stored url of the file, not just container path.  .  So your \"-StorageUri\" parameter value should look like  .  Also you need to make sure that container already exist before you try to backup, it will not be created for you by the export. .  ",
      "P-tags": "azur azure-blob-storag azure-powershel",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "au_55352",
      "task": "Convert library of WMA tracks to MP3's?",
      "P-task": "convert librari wma track mp3",
      "F_verb": "convert",
      "P-body": "MPlayer is likely to be installed already. Also make sure you have lame: .  Then there are two ways to do it, an easy to read version, and a short and dirty script to do it: .  All wma's should be in your current directory. Create a file called wmamp3 in your home directory (~/) containing: .  \"chmod +x ~/wmamp3\" to make it executable .  \"sudo cp ~/wmamp3 /usr/bin\" to pop it somewhere useful on your path .  Type \"wmamp3\" to run your conversion. .   The short and dirty version (does exactly the same as above): .  ",
      "P-tags": "wma sound convers mp3",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "ul_436802",
      "task": "How does postgresql.service know which postgresql instances to start?",
      "P-task": "postgresql servic know postgresql instanc start",
      "F_verb": "start",
      "P-body": "To answer this, start with checking the contents of the two files in question. If you aren't sure where to find them, you can search the package contents for \"systemd\" files: .  From looking at the \"postgresql.service\" file you can see you not doing much at all: .  From the comments, we learn that the file is being used as a systemd \"target\". Moving on to the template file: .  The interesting directives are: .  If you aren't sure where find the docs for a \"systemd\" directive, you can check: \"man systemd.directives\". From there, we find both these directives in \"man systemd.unit\".  .  Your biggest clue comes when you enable the service: .  Putting it all together:  The symlink is how \"systemd\" knows to boot up PostgreSQL 9.6 when the server starts. The \"PartOf=\" and \"ReloadPropagatedFrom=\" directives handle making sure that \"stop\", \"start\", \"restart\" and \"reload\" on the \"postgresql\" service end up applying to all the related installed PostgreSQL instances.  ",
      "P-tags": "postgresql systemd",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V"
    },
    {
      "id": "ul_659184",
      "task": "Replacing columns using awk",
      "P-task": "replac column use awk",
      "F_verb": "replace",
      "P-body": "You should be using \"$1 = ar[$2]\", not \"ar[$1]\". .  Also, you don't need the \"for\" loop, or to do the redirection in shell. \"awk\" can construct filenames and redirect its output by itself. .  Output: .  BTW, you probably should use a different filename prefix (or a different output directory) so any subsequent runs don't re-process the \"small_file*_em\" files too. e.g. .  and change the print statement in the awk script to: .  ",
      "P-tags": "awk",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP using NP"
    },
    {
      "id": "so_62870122",
      "task": "shellScript to execute a command in new shell from SSHing",
      "P-task": "shellscript execut command new shell sshing",
      "F_verb": "execute",
      "P-body": "You can pass the \"docker exec\" command to ssh command. .  or if you want to run command in container then you can pass the command to container .  ",
      "P-tags": "linux docker bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "so_56426519",
      "task": "Find users that are not members of a specific GG group?",
      "P-task": "find user member specif gg group",
      "F_verb": "find",
      "P-body": "Depending on how dynamic you want your code to be, there are a number of ways to approach this question. .  Scenario 1 (Users Not in a Single Group): .  Scenario 2 (Users Not in Multiple Groups): .  Scenario 1 queries for the Distinguished Name of the group and stores that result in \"$groupDN\". \"Get-ADUser\" is used to query all AD users and then the result is filtered to output users who do not have the group Distinguished Name in the \".MemberOf\" attribute. The \".where()\" method is used with the \"-notcontains\" operator for the post-query filtering. .  Scenario 2 loops through multiple groups and creates an array of strings that will be used later in the \".where()\" method. The strings are created using the format operator (\"-f\") even though concatenation would look prettier in this case. Each array entry simply contains \"$_.memberOf -notcontains <Group Distinguished Name>\". The entries are joined by an \"-and\" operator and then converted to a ScriptBlock, which is represented by \"$whereFilter\". Since the \".where()\" method accepts a ScriptBlock type as a parameter, we can simply just pass \"$whereFilter\". .  \"$Users\" contains the user objects returned from the queries. I've selected the properties that you provided in your question, but this could easily be tweaked for whatever properties you want. .  In all honestly, it may just be easier to query all AD users. Then do your specific filtering from the all AD users query. The main reason the search isn't simpler besides the lack of robust commands in the ActiveDirectory module is that you are searching for an array of values within an array. Checking for single values in an array is much simpler and PowerShell can natively handle those types of queries among most of the Collection object types. .  ",
      "P-tags": "powershel active-directory-group",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP that S"
    },
    {
      "id": "so_59086294",
      "task": "Powershell script to log out users without specific process",
      "P-task": "powershel script log user without specif process",
      "F_verb": "log",
      "P-body": " ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V out NP without NP"
    },
    {
      "id": "au_753335",
      "task": "Top command - what do the \"slash number\" next to each process name mean?",
      "P-task": "top command - slash number next process name mean",
      "F_verb": "slash",
      "P-body": "It depends on the process. The \"/\u2026\" is part of the process name, as can be seen from \"pgrep\" output: .  For \"kworker\" processes, the answer is in this Unix & Linux post: .   According to kernel.org, the syntax is \"kworker/%u:%d%s (cpu, id, priority)\". The \"u\" designates a special CPU, the unbound cpu, meaning that the kthread is currently unbound. .  The workqueue workers which have negative nice value have 'H' postfixed to their names. source) .   ",
      "P-tags": "top command-lin",
      "source": "qa",
      "cate": "cut/slash/separate/clip/crop",
      "pat": "V NP to NP"
    },
    {
      "id": "su_272106",
      "task": "config.status not found",
      "P-task": "config statu found",
      "F_verb": "find",
      "P-body": "Try typing: .  This will assess your system to determine if all dependencies are satisfied and evaluates how to best compile your program. If successful, it generates the required files to run \"make\", including \"config.status\". .  ",
      "P-tags": "linux make",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "ul_333046",
      "task": "How to connect to a xserver from my system-wide terminal?",
      "P-task": "connect xserver system-wid termin",
      "F_verb": "connect",
      "P-body": "In a terminal in your GUI environment, type: .  In the non-GUI environment, type: .  Then, graphical applications that you launch from the non-GUI environment will be displayed in the GUI environment. .  You can read more in \"man xhost\" .  See also this answer from: What does this \"xhost \u2026\" command do? .  ",
      "P-tags": "tmux gui raspbian openbox x-server",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP from NP"
    },
    {
      "id": "so_57209027",
      "task": "How to change the data of registry property data without knowing the key beforehand",
      "P-task": "chang data registri properti data without know key beforehand",
      "F_verb": "change",
      "P-body": "I am addressing the question, how do I search property values in the registry? The way I do it is with this script: .  With that script in hand, here's an example.  .  The results can be used with set-itemproperty. .  ",
      "P-tags": "powershel powershell-5 0",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP without S_ING"
    },
    {
      "id": "so_50710299",
      "task": "Kudu REST API Command endpoint error when executing powershell",
      "P-task": "kudu rest api command endpoint error execut powershel",
      "F_verb": "execute",
      "P-body": "After checking this issue on github the correct POSH command should be:  .  \"get-childitem -recurse | remove-item -recurse -force\"  .  It works well when executing directly from Kudu console or even REST API /api/command endpoint .  ",
      "P-tags": "azur powershel rest kudu",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "su_1257094",
      "task": "Can't change resolution with xrandr",
      "P-task": "chang resolut xrandr",
      "F_verb": "change",
      "P-body": "Well, I figured out what I was missing, it needed \"--output eDP-1-1\". Still not quite sure why that isn't implied and what was operating on when I left it out, but it works now. .  ",
      "P-tags": "linux resolut xrandr xorg",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_445051",
      "task": "How to start Vim from a trap and still be able to resume it after suspending it?",
      "P-task": "start vim trap still abl resum suspend",
      "F_verb": "resume",
      "P-body": "The problem is starting a background job from a trap. The job seems to get \u201clost\u201d sometimes. Changing \"vim\" to \"vim &\" makes the job be retained sometimes, so there may be a race condition. .  You could avoid this by not starting the job from a trap. Set a flag in the trap, and fire up vim outside the trap, in the \"precmd\" hook. Here's an adaptation of your minimum example. .  You lose the ability of popping Vim up to the foreground while editing a command prompt, but that doesn't really work anyway since vim and zsh would be competing for the terminal. .  In your real code, you may run into trouble because you're starting vim from a subshell. Don't run the \"nv\" function in a subshell: use braces { \u2026 }\"around the body, not parentheses. Use\"local IFS\"to make the\"IFS` variable local. .  ",
      "P-tags": "job-control zsh vim trap function",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP after S_ING"
    },
    {
      "id": "au_1172124",
      "task": "Run Webstorm as privileged user",
      "P-task": "run webstorm privileg user",
      "F_verb": "run",
      "P-body": "Please try the following steps- .   Open the installation directory of Web Storm (\"dpkg --listfiles webstorm\" or \"which webstorm\") .  Find the executable (i.e., webstorm.sh) .  Run as sudo \"sudo ./webstorm.sh\" .  Update .   ",
      "P-tags": "flatpak ide user",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP"
    },
    {
      "id": "so_53367054",
      "task": "Find a string in a file, run a script on it, and replace the original string with the new string using PowerShell",
      "P-task": "find string file run script replac origin string new string use powershel",
      "F_verb": "find",
      "P-body": "Given the line-oriented nature of your input, you can process your input file line by line and decide for each line whether it needs transformation or not: .  Note the \"(...)\" around the pipeline before \"Set-Content\", which ensures that \"$file\" is read into memory in full up front, which allows writing back to the same file - do note that this convenient approach bears the slight risk of data loss, however, if the command is interrupted before writing completes; always create a backup of the input files first. .  ",
      "P-tags": "powershel pandoc shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_70016088",
      "task": "Generate 6 digit number from 000001 to 999999 in Linux",
      "P-task": "gener 6 digit number 000001 999999 linux",
      "F_verb": "generate",
      "P-body": "This should work: .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP to NP in NP"
    },
    {
      "id": "so_52116221",
      "task": "BASH comparing Linux version to number?",
      "P-task": "bash compar linux version number",
      "F_verb": "compare",
      "P-body": "Version numbers aren't floating point values; they are \".\"-delimited sequences of integers. \"42.27\" is newer than \"42.3\", and \"42.2.9\" could be a valid version number. .  Split the version number into its integer components, and compare them \"lexiconumerically\": .  ",
      "P-tags": "compar bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP to NP"
    },
    {
      "id": "so_45749509",
      "task": "Cordova build failed",
      "P-task": "cordova build fail",
      "F_verb": "build",
      "P-body": "Try downgrading API level to \"23.0.3\". You can do that using \"Android SDK Manager\" and \"Android Studio\" or you can follow the instructions here. .  Versions newer than \"23.0.3\" still have bugs. .  ",
      "P-tags": "android cordova linux command-line-interfac node js",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_20245371",
      "task": "Trying to Pull list of computers from AD via powershell",
      "P-task": "tri pull list comput ad via powershel",
      "F_verb": "pull",
      "P-body": "It's a funny odd frustrating problem, but the issue is because you are using capital letters (camelCase) when referencing the properties, when you need to reference them with all lower case letters. .  i.e. instead of \"$objitem.distinguishedName\" it should be: \"$objitem.distinguishedname\" .  So, replace your foreach block with this, and you should be getting all those properties: .  ",
      "P-tags": "directorysearch powershel csv powershell-1 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP via NP"
    },
    {
      "id": "so_28397035",
      "task": "Close a file handle opened by .NET",
      "P-task": "close file handl open net",
      "F_verb": "handle",
      "P-body": "Since you only read from the the file, then a call to \"Dispose()\" should do the trick. Ex. .  ",
      "P-tags": "powershel filelock",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V by NP"
    },
    {
      "id": "so_59131097",
      "task": "find string with most occurrences in .txt file with powershell",
      "P-task": "find string occurr txt file powershel",
      "F_verb": "find",
      "P-body": "You can do something like the following: .  Explanation: .  \"Where\" specifies the \"Length\" property's condition. \"Group-Object -NoElement\" leaves off the \"Group\" property, which contains the actual object data. \"Sort-Object\" sorts the grouped output in ascending order by default. Here the \"Count\" property is specified as the sorted property and the \"-Descending\" parameter reverses the default sort order. .  ",
      "P-tags": "powershel window count script",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP in NP with NP"
    },
    {
      "id": "so_21053948",
      "task": "How to call Get-Counter in PowerShell with a variable",
      "P-task": "call get-count powershel variabl",
      "F_verb": "call",
      "P-body": "The following worked fine on my computer .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "ul_140184",
      "task": "How can I use mutt execute command tag-pattern and then delete-pattern via shell?",
      "P-task": "use mutt execut command tag-pattern delete-pattern via shell",
      "F_verb": "delete",
      "P-body": "A simple example: .  Suppose you want to delete and purge messages from the \"testmbox\" mailbox, containing [DELETE-ME] in the subject line. .  You can do this:  .  \"mutt -f testmbox -e \"push <tag-pattern>~s[DELETE-ME]\\n<tag-prefix><delete-message><sync-mailbox>\\n\"\" .  This works because:  .   -e executes configuration commands 'push' is a configuration command that add key sequences to the keyboard buffer, i.e. to mutt, looks just like entering \"T~s[DELETE-ME]<ENTER>;d$<ENTER>\" interactively (assuming a default keyboard layout).  Tested with mutt 1.5.21 .  ",
      "P-tags": "mutt",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V via NP"
    },
    {
      "id": "so_33944858",
      "task": "TeamCity - NamedParameterNotFound for Get-ChildItem on TeamCity",
      "P-task": "teamciti - namedparameternotfound get-childitem teamciti",
      "F_verb": "get",
      "P-body": "In the \"Script arguments\" box in TeamCity, I  .  changed this .  to this .  And it works. Lord knows. .  ",
      "P-tags": "powershel teamciti teamcity-9 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_2865047",
      "task": "Can I prevent a Linux user space pthread yielding in critical code?",
      "P-task": "prevent linux user space pthread yield critic code",
      "F_verb": "prevent",
      "P-body": "You can use the \"sched_setscheduler()\" system call to temporarily set the thread's scheduling policy to \"SCHED_FIFO\", then set it back again. From the \"sched_setscheduler()\" man page: .   A \"SCHED_FIFO\" process runs until either it is blocked by an I/O request, it is preempted by a higher priority process, or it calls \"sched_yield(2)\". .   (In this context, \"process\" actually means \"thread\"). .  However, this is quite a suspicious requirement. What is the problem you are hoping to solve? If you are just trying to protect your linked list of completion handlers from concurrent access, then an ordinary mutex is the way to go. Have the completion thread lock the mutex, remove the list item, unlock the mutex, then call the completion handler. .  ",
      "P-tags": "embedded-linux pthread linux schedul",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP S_ING in NP"
    },
    {
      "id": "ul_416298",
      "task": "How to add some text before another with sed in FreeBSD?",
      "P-task": "add text anoth sed freebsd",
      "F_verb": "add",
      "P-body": "found this way: .  or .  ",
      "P-tags": "freebsd sed",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP before NP with NP in NP"
    },
    {
      "id": "au_161037",
      "task": "Ubuntu won't log in after update",
      "P-task": "ubuntu log updat",
      "F_verb": "log",
      "P-body": "Somebody asked me that same question the other day :  .   since yesterday my ubuntu 12.04 locks me out, i can only access the guest account. if i enter the correct password for the admin account, the screen turns black and then goes back to the log in screen. if i enter an incorrect password, it says incorrect password. if i create a new admin account via the guest account, i get the same problem. resetting the password won't help :( any ideas anyone? .   It seem's a few people have had this problem, and using \"gdm\" instead of \"lightdm\" is the recommended workaround, and it worked for the person that asked me - after a couple of reboots. Have a look at these links for instructions & let me know if it helps. .  https://askubuntu.com/questions/130387/stuck-at-login-screen .  Can't log in to ubuntu 12.04 .  https://askubuntu.com/questions/130721/12-04-lightdm-cannot-login .  ",
      "P-tags": "updat login",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in after NP"
    },
    {
      "id": "au_1369522",
      "task": "Can't mount ext4 partition with write permissions",
      "P-task": "mount ext4 partit write permiss",
      "F_verb": "mount",
      "P-body": "This drive appears to be properly mounted. There is no indication that it is mounted read only. Then, of course, by default, only the administrator can use it. If desired, the administrator must give write permission to either the entire partition, or selected folders created on the new partition. .  Before determining that the partition is mount read only, check whether you can create a folder on that partition as root user: .  If that command succeeds, see the folder listed in the output of .  Make your user owner of the \"testfolder\" so that user has full access: .  \"$USER\" will automatically be substituted by your own login name. Suply another user name if you want to do this for another user. .  Now test if you can create a file on that folder: .  The \"cat\" command should print the contents of the file. .  If it does not succeed, then indeed your partition might be mounted read only. That, however, would point to an issue during mounting, because you did not set it up to mount read only. .  ",
      "P-tags": "partit fstab mount permiss",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP with NP"
    },
    {
      "id": "au_634386",
      "task": "14.04 unity does not start after login screen",
      "P-task": "14 04 uniti start login screen",
      "F_verb": "start",
      "P-body": "I had a similar error and the problem was due to my /tmp/ directory having the incorrect permissions and .Xauthority. This Answer worked for me (I copied and pasted it in case it gets removed, @SiddharthaRT is the original author): .  Press Ctrl+Alt+F3 and login into the shell. .  Now run \"ls -lah\". If in the output the line .  then you need to do \"chown username:username .Xauthority\" and try logging in. .  Else, do \"ls -ld /tmp\". Check for the first 10 letters in the left: they should read exactly so: \"drwxrwxrwt\". .  Else, you need to do \"sudo chmod a+wt /tmp\" and check again. .  If not both, I'd recommend you either .  or uninstall, reinstall it. .  Now press Alt+-> until you reach the login screen again, and restart. .  ",
      "P-tags": "14 04 lightdm uniti xorg",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V after NP"
    },
    {
      "id": "so_51010491",
      "task": "ForEach line of a list get the string, search for specific node in XML and delete the parent node using Powershell",
      "P-task": "foreach line list get string search specif node xml delet parent node use powershel",
      "F_verb": "delete",
      "P-body": "If I correctly understood you. .  ",
      "P-tags": "xml xpath list foreach powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "au_1163708",
      "task": "Optimal way to resize root partition of a running ubuntu VM?",
      "P-task": "optim way resiz root partit run ubuntu vm",
      "F_verb": "resize",
      "P-body": "Since your root partition is on LVM, you can always add a new disk to your VM and extend your root partition online. .  Create a new partition on your newly added disk with parted or similar tool. .  Create LVM Physical Volume as (assuming your new partition is /dev/sdb1): .  Extend the Volume Group (replace ubuntu--vg with your VG name, check under vgs command): .  Extend the Logical Volume: .  Finally resize the ext based filesystem (for xfs filesystem use xfs_growfs command): .  ",
      "P-tags": "partit 18 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP of NP"
    },
    {
      "id": "so_47030161",
      "task": "curl always connects to a specific ip:port pair",
      "P-task": "curl alway connect specif ip : port pair",
      "F_verb": "connect",
      "P-body": "To be sure what is happening, turn on verbosity with \"-v\" switch: .  In your case, I'd guess that Curl tries to use proxy. If that is the case, you should check the following: .   \"http_proxy\" environment variable:  Check: .   Curl configuration file \"~/.curlrc\" (unlikely, it doesn't show in \"strace\") .  Proxy can be proxided on command line (\"-x\" or \"--proxy\"), so check if \"curl\" isn't aliased in your shell .   ",
      "P-tags": "linux curl",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_46424581",
      "task": "bash: running a command with quotes and variables",
      "P-task": "bash : run command quot variabl",
      "F_verb": "run",
      "P-body": "Use double quotes so the shell expands the variables; using single quotes keep the value as-is .   Rule of thumb: always double quote your variables in bash. .   from TLDP docs: When referencing a variable, it is generally advisable to enclose its name in double quotes. This prevents reinterpretation of all special characters within the quoted string -- except $, ` (backquote), and \\ (escape). .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_38177736",
      "task": "How to start the upstart process for golang application?",
      "P-task": "start upstart process golang applic",
      "F_verb": "start",
      "P-body": "OP eventually solved after fixing a few issues. See comments, notably: .   upstart might not recognise environment variables Amazon Linux Image currently uses an old version of init (upstart 0.6.5), lacking newer features such as \"console log\" & nested script tags .  status 127 can occur if exec can't find the binary .  status 1 can occur if binary runs but fails substituting a simple program in an upstart script can help diagnose errors  ",
      "P-tags": "amazon-ec2 go linux upstart",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP for NP"
    },
    {
      "id": "so_22293671",
      "task": "How to pass build parameters and other information to powershell script in TFS2013 build?",
      "P-task": "pass build paramet inform powershel script tfs2013 build",
      "F_verb": "pass",
      "P-body": "Figured it out. .  Variables are automatically written as environment variables, dir env: showed me that tfs automatically create following variables: .  ",
      "P-tags": "build powershel tf",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "au_638339",
      "task": "How to Launch Lan Messenger in Ubuntu 14.04",
      "P-task": "launch lan messeng ubuntu 14 04",
      "F_verb": "launch",
      "P-body": "One you download it you can install: .  Once installation is finished you can run the app directly from terminal using command: .  The app will run and you can see the app indicator in the top panel .   .  right click on the icon opens the menu so you can do what you want. .   .  Also, open \"prefrences\" then you can choose to make it run when system startup .   .  ",
      "P-tags": "14 04 software-instal",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "so_48296581",
      "task": "Unable to redirect the output of each line read from the file and create a new file for each redirected output",
      "P-task": "unabl redirect output line read file creat new file redirect output",
      "F_verb": "redirect",
      "P-body": " Add increment for example. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_51406323",
      "task": "How to extract string in file and replace specific pattern text",
      "P-task": "extract string file replac specif pattern text",
      "F_verb": "extract",
      "P-body": "You could try: .  See live demo here .  Regex breakdown: .   \"!\\[]\" Match \"![]\" literally \"(\" Match an opening parenthesis  \"[^()]*\\/\" Match up to and including last slash mark \"\\(\" Start of capturing group 1  \"[^)]*\" Match up to next closing parenthesis  \"\\)\" End of capturing group 1  \")\" Match a closing parenthesis  ",
      "P-tags": "linux sed regex",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_38896445",
      "task": "Converting date/time string to unix timestamp in MySQL",
      "P-task": "convert date time string unix timestamp mysql",
      "F_verb": "convert",
      "P-body": "The \"UNIX_TIMESTAMP()\" function requires a valid date/time format to convert correctly, so you need to convert your existing date/time format to a valid/recognised format (including the year) first. You can do this using MySQL's \"STR_TO_DATE()\" function, telling it what format you are passing in, and concatenating in a hard-coded year value as it's always 2016 in your case. .  You can then use the \"UNIX_TIMESTAMP()\" function to convert that valid date to your unix timestamp and update all those records in a single step: .  ",
      "P-tags": "unix-timestamp mysql date timestamp",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "ul_305228",
      "task": "How to scan for interference due to _wide_ Wifi channels (40, 80 Mhz)",
      "P-task": "scan interfer due _wide_ wifi channel 40 80 mhz",
      "F_verb": "scan",
      "P-body": "Remember \"iwlist\" is deprecated! Use the \"iw\" tool. .  ",
      "P-tags": "linux wifi",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V for NP to NP"
    },
    {
      "id": "au_972121",
      "task": "How to find all hardlinks in a folder?",
      "P-task": "find hardlink folder",
      "F_verb": "find",
      "P-body": " That will show all regular files that have more than one link (name) to them. It will not tell you which names are linked to the same file, for that you could use \"-samefile\" or \"-inum\", e.g. \"find -samefile \"$somefile\"\" .  In the technical sense, all files (file names) are (hard) links, it's just that files with more than one link pointing to them are interesting in this sense. But even in those cases, there's no way to say that one of them is the \"proper\" file, and the other a link, the links are equal. .  As an example: .  ",
      "P-tags": "luk encrypt external-hdd hard-link",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_48655308",
      "task": "How to redirect one of several inputs?",
      "P-task": "redirect one sever input",
      "F_verb": "redirect",
      "P-body": "Rather than trying to pipe the output of \"tail\" to \"cat\", bash provides process substitution where the process substitution is run with its input or output connected to a FIFO or a file in \"/dev/fd\" (like your terminal tty). This allows you to treat the output of a process as if it were a file. .  In the normal case you will generally redirect the output of the process substitution into a loop, e.g, \"while read -r line; do ##stuff; done < <(process)\". However, in your case, \"cat\" takes the file itself as an argument rather than reading from \"stdin\", so you omit the initial redirection, e.g.  .  So be familiar with both forms, \"< <(process)\" if you need to redirect a process as input or simply \"<(process)\" if you need the result of process to be treated as a file. .  ",
      "P-tags": "linux unix bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP"
    },
    {
      "id": "au_1353585",
      "task": "How to get Enno Gr\u00f6per selectyall-Terminator-Plugin working (Ubuntu)?",
      "P-task": "get enno gr per selectyall-terminator-plugin work ubuntu",
      "F_verb": "get",
      "P-body": "It looks like your plugins folder is somewhere else. Please post the output of (copy-paste as text, not screen capture): .  and if it is something different, try adding \"selectall.py\" in that directory. .  ",
      "P-tags": "plugin termin python copy-and-past",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_ING"
    },
    {
      "id": "so_67287878",
      "task": "Traversing Azure PIM Roles for Review",
      "P-task": "travers azur pim role review",
      "F_verb": "traverse",
      "P-body": "Yes, there is a command \"Get-AzureADMSPrivilegedRoleAssignment\" in \"AzureADPreview\" module that calls the Microsoft Graph - \"List governanceRoleAssignments\", it should meet your requirement, but it is in preview and I believe there is a bug in this command/api, as when you run the command/call the api, there is always an \"UnknownError\"(I have tested it with the Global admin in AAD tenant and Owner role in subscription, so there should be no permission issue). So to use it successfully, I think you may need to wait for it to be GA. .   I understand there is \"Access Review\" of PIM but that needs admin level permissions .   Besides, even it becomes GA in the future, I think it needs admin permissions, because the feature in the portal and the powershell should both call the same API, it needs the same permission. So if you don't have the enough permission, anyway you could not do this. .  ",
      "P-tags": "azure-active-directori azur pim azure-powershel powershel",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP for NP"
    },
    {
      "id": "so_50487211",
      "task": "Bash - one liner to sort a bed file on qvalue column then extract top 20% of rows with highest q value",
      "P-task": "bash - one liner sort bed file qvalu column extract top 20 row highest q valu",
      "F_verb": "sort",
      "P-body": "Is this what you are looking at? .  ",
      "P-tags": "r percentag filter bash sort",
      "source": "qa",
      "cate": "sort",
      "pat": "V NP on NP of NP with NP"
    },
    {
      "id": "so_21694422",
      "task": "CentOS yum install gcc error: glibc-common conflicts with glibc",
      "P-task": "cento yum instal gcc error : glibc-common conflict glibc",
      "F_verb": "install",
      "P-body": "Try .  then... .  It should fix you. .  ",
      "P-tags": "gcc cento linux glibc",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_480286",
      "task": "Sometimes wget just hangs, when it should just restart with --continue",
      "P-task": "sometim wget hang restart -- continu",
      "F_verb": "restart",
      "P-body": " \u2018--timeout=seconds\u2019 .  Set the network timeout to seconds seconds. This is equivalent to specifying \u2018--dns-timeout\u2019, \u2018--connect-timeout\u2019, and \u2018--read-timeout\u2019, all at the same time.  .   https://www.gnu.org/software/wget/manual/wget.html#Basic-Startup-Options .  http://man7.org/linux/man-pages/man1/timeout.1.html .  https://stackoverflow.com/a/30986740/1133275 .  ",
      "P-tags": "wget",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V with NP"
    },
    {
      "id": "so_5183389",
      "task": "How to stream the output of a programmatically executed ScriptBlock?",
      "P-task": "stream output programmat execut scriptblock",
      "F_verb": "execute",
      "P-body": "Here's some code that will add an extension method to ScriptBlock to stream output, calling a delegate for each output object. It is true streaming as the objects are not backed up in a collection. This is for PowerShell 2.0 or later.  .  Example: .  (updated 2011/3/7 with parameter support) .  Hope this helps. .  ",
      "P-tags": "powershel net stream",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_83026",
      "task": "Prevent gedit from creating files with the '~' (tilde) suffix",
      "P-task": "prevent gedit creat file tild suffix",
      "F_verb": "prevent",
      "P-body": "Those are just backups of your original files that \"gedit\" creates before saving changes to your edited documents. .  In \"gedit\" preferences you need to disable Create a backup copy of file before saving, and if you want to automatic save your edits automatically set a timer with the option enable Autosave files every X minutes. .  That way the \"~\" will be gone and your last changes will be saved on the file every x minutes in case something goes bad or your computer crashes. .   .  The changes made to the file will be saved to the file itself and not to a temporary file. .  Please be aware that if you delete the contents of a file and auto save is enable there will be a chance that you end up with a saved empty file. .  Always make sure that when you close on file while auto save is enabled that the contents of the file are correct, else undo them and save the file again. .  ",
      "P-tags": "gedit",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING with NP"
    },
    {
      "id": "so_44328574",
      "task": "In UNIX find and list file_names consisting number and date, if greater than a specific number",
      "P-task": "unix find list file_nam consist number date greater specif number",
      "F_verb": "list",
      "P-body": "In bash with a for construct .  ",
      "P-tags": "unix-socket unix",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP if S"
    },
    {
      "id": "so_56246443",
      "task": "Exclude a certain directory while (find command) - BASH",
      "P-task": "exclud certain directori find command - bash",
      "F_verb": "exclude",
      "P-body": "Use the \"-prune\" option to prevent descending into the \"test\" directory. .  You can also exclude \"__init__.py\" in \"find\" so you don't need to test that with \"if\". .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP while S_ING"
    },
    {
      "id": "au_462123",
      "task": "Pipe symbol executes from left to right or right to left?",
      "P-task": "pipe symbol execut left right right left",
      "F_verb": "execute",
      "P-body": "Pipe will execute the commands from left to right. So \"ls -l\" would be executed first. .  Ouput of first command is feded as input to the second command. .  \"ls -l\" command would be executed first. Then it's output is passed as input to the next command \"grep \"Aug\"\" after that the ouput of \"ls -l | grep \"Aug\"\" command is passed to the last command \"sort +4n\" as input. .  ",
      "P-tags": "script",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V from NP to NP"
    },
    {
      "id": "so_56850609",
      "task": "sed to pick value from one file and replace in another",
      "P-task": "sed pick valu one file replac anoth",
      "F_verb": "pick",
      "P-body": "Taking a shot in the dark as I don't know how your resolv.conf is configured: .   collect nameserver from first file insert collected nameserver, preserving leading whitespace print modified second file test for success before file change  edit: Now requires GNU Awk: \"gensub\" to dynamically preserve leading whitespace, \"nextfile\" to skip current file once we have a nameserver .  ",
      "P-tags": "replac text string bash sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_176426",
      "task": "Grep lines that contain \"1111-11-11\" or \"2382-21-20\". (Any Numbers)",
      "P-task": "grep line contain 1111-11-11 2382-21-20\nnumber",
      "F_verb": "contain",
      "P-body": "you are overquoting... .  ",
      "P-tags": "grep text-process",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_34574039",
      "task": "Using wc * to count the numer of lines of the files in the current directory",
      "P-task": "use wc count numer line file current directori",
      "F_verb": "count",
      "P-body": "You can use \"find\": .  Or with \"gnu wc\": .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "au_297564",
      "task": "go back from Gnome 3.8 to Gnome 3.6 in LUBUNTU 13.04",
      "P-task": "go back gnome 3 8 gnome 3 6 lubuntu 13 04",
      "F_verb": "go",
      "P-body": "http://ubuntuforums.org/showthread.php?t=2143894 .  That will remove the Gnome ppa entirely if you need it to. If not, my suggestion (if you were lucky/smart enough to partition home separately from root) is to just install Ubuntu Gnome 13.04 if you're willing to go full bore into Gnome. I've been using it and aside from an issue with the workspace switching, it has been buttery smooth. I'm actually impressed as last time I used it it was twitchy, would lock up on lock screen, and had a few crashes of the shell. .  And after the fact, if you want you can always add the Gnome PPA again and go for 3.8. .  Edit- Try this- http://www.omgubuntu.co.uk/2013/04/gnome-3-8-ppa-for-ubuntu-gnome .  Basically, purge the Gnome PPA, update your repo list, remove the Gnome shell entirely (should leave you with just Lubuntu interface) and then go back and reinstall Gnome shell. Gnome will then be picked up from the official Ubuntu repositories and install 3.6 (and all other Gnome required libs, apps, etc.) .  ",
      "P-tags": "gnome lubuntu",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP from NP to NP in NP"
    },
    {
      "id": "so_26621647",
      "task": "Convert human readable to bytes in bash",
      "P-task": "convert human readabl byte bash",
      "F_verb": "convert",
      "P-body": " ",
      "P-tags": "awk linux human-read bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_35064099",
      "task": "add an item to arraylist in powershell workflow foreach -parallel",
      "P-task": "add item arraylist powershel workflow foreach -parallel",
      "F_verb": "add",
      "P-body": "The problem here is that you're using, uh \"$using:\" the wrong way. .  Your workflow is basically it's own sandbox. You can use $using to instantiate a variable with the same values within it, but you can't use that to manipulate the same variable outside of it.  .  However, you can have your workflow emit an object, and then capture that with the .Add() method of your \"$newlist\" Arraylist variable. .  Tweak the code like so, and it should work: .  Then, after the code has run, we can get the values out, like so. .  ",
      "P-tags": "workflow parallel foreach arraylist powershel inline-script",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_46426526",
      "task": "How to run a JShell File?",
      "P-task": "run jshell file",
      "F_verb": "run",
      "P-body": "\"JShell\" is not meant to run a Java class directly. If you want to run a java class, you still need to do it the old way - \"java <your-class-name>\".  .  From the docs,  .   The Java Shell tool (JShell) is an interactive tool for learning the Java programming language and prototyping Java code. JShell is a Read-Evaluate-Print Loop (REPL), which evaluates declarations, statements, and expressions as they are entered and immediately shows the results. .   As per this quote, JShell is meant for running or trying out individual Java statements. In the traditional java way, you have to write a full Java program before you can run it and see the results. But JShell allows you a way to try out the Java statements without needing you to build the full standalone java application.  .  So the short answer to your question is that, no, you can't call standalone java applications like \"jshell my-jshell-skript.java\". However, you CAN call a script file which contains individual JShell commands or Java statements. So if you copy all the statements from your Java program and paste them to a JShell script, you can run the script like: .  \"% jshell my-jshell-skript.jsh\" .  But this is not quite the same as running a standalone java application. .  ",
      "P-tags": "jshell java-9 java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_310061",
      "task": "vmlinuz.efi : not found error",
      "P-task": "vmlinuz efi : found error",
      "F_verb": "find",
      "P-body": "Okay, I found out a way to rectify this problem. All you have to do is to remove the installed kernel in the iso file, and install a new one. .  1) Remove initrd.img and vmlinuz .  2) Remove the kernel files .  3) Install kernel generic version .  This one solves my problem. .  ",
      "P-tags": "virtualbox 13 04",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_451709",
      "task": "`timedatectl set-timezone` doesn't update `/etc/timezone`",
      "P-task": "timedatectl set-timezon updat etc timezon",
      "F_verb": "update",
      "P-body": "\"timedatectl\" updates \"/etc/localtime\", which is the documented way of setting the default timezone in most Linux-based environments (along with its override, the \"TZ\" environment variable, which is the only POSIX-defined way of specifying the timezone). .  \"/etc/timezone\" appears to be mostly Debian-specific (including derivatives). On Debian systems, \"timedatectl set-timezone\" also updates \"/etc/timezone\". .  If you manually update \"/etc/timezone\", you should also update the \"/etc/localtime\" symlink (and make sure you keep the latter a symlink). Updates to \"/etc/localtime\" appear to be taken into account by (most?) desktop environments, so there\u2019s no need to use environment-specific tools to update the timezone. .  If you\u2019re running Debian, you should use \"dpkg-reconfigure tzdata\" to configure the default timezone; that updates \"/etc/localtime\" and \"/etc/timezone\" as above, and it also updates the selected timezone in the debconf database (which serves as the default when configuring \"tzdata\"). If you don\u2019t do this, the next time \"tzdata\" is updated, the timezone will be restored to the value in the debconf database. \"dpkg-reconfigure tzdata\" also takes care of updating the SE Linux context, if you\u2019re using SE Linux. .  ",
      "P-tags": "arch-linux timezon linux date",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_20504550",
      "task": "One element containing hashes instead of multiple elements - how to fix?",
      "P-task": "one element contain hash instead multipl element - fix",
      "F_verb": "contain",
      "P-body": "I think the problem is that for what you're doing you actually need two foreach-object loops. Using Get-Content with -Readcount is going to give you an array of arrays. Use the -Match in the first Foreach-Object to filter out the records that match in each array. That's going to give you an array of the matched records. Then you need to foreach through that array to create one object for each record: .  You don't really need to use the collection as an accumulator, just output PSCustomObjects, and let them accumulate in the result variable. .  ",
      "P-tags": "array powershel hash robocopi",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_7393",
      "task": "Attempting to update Amazon Route53 using a script, but domain is not being updated",
      "P-task": "attempt updat amazon route53 use script domain updat",
      "F_verb": "update",
      "P-body": "Aha! Your script is missing a newline at the end. Unix text files (such as scripts) are sequences of line, and each line (even the last) must be terminated by a newline. .  Most modern unix tools can cope with malformed text files, but tcsh doesn't count as modern: it looks like it ignores the last, unterminated, logical line (everything after the last newline that's not preceded by a backslash). .  A good editor (such as Emacs or Vi(m)) automatically makes sure that csh scripts are terminated by a newline.\u00b9 It looks like your editor is not doing the right thing, so make sure your scripts do end with a newline (\"cat /path/to/script\" must show the last script line above the next prompt, not next to it). .  \u00b9  In a really good editor, such as Emacs, this doesn't apply to other kinds of files that may legitimately be not newline-terminated.  .  ",
      "P-tags": "amazon-ec2 dn linux shell-script tcsh",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP using NP"
    },
    {
      "id": "su_367454",
      "task": "Change the Ubuntu program that runs when a command can't be found",
      "P-task": "chang ubuntu program run command found",
      "F_verb": "change",
      "P-body": "When bash encounters a command it cannot find, it looks for a function called command_not_found_handle() and executes it. .  Under ubuntu, this is defined in \"/etc/bash.bashrc\" .  By default it runs a python script in \"/usr/lib/command-not-found\" .  You could make it do whatever you liked, and this is best done in your own \"~/.bashrc\" file: .  The sudo part answers the section part of your question, but will obviously need to prompt for a password to escalate to root to do the install. .  ",
      "P-tags": "ubuntu apt-get",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP that NP when S"
    },
    {
      "id": "au_740179",
      "task": "bash script to delete last 10 lines in histroy",
      "P-task": "bash script delet last 10 line histroy",
      "F_verb": "delete",
      "P-body": "There are several errors. .   i= history | wc -1  You've got spaces in here so you'd need to wrap this in \"\" to avoid an error, and additionally you've added an unneeded space after the equal sign. However, all you've done is create a variable containing \"history | wc -1\". Firstly, there is no \"wc -1\". I think you meant \"wc -l\", which counts the lines. Secondly, I think you wanted to actually run this command.  .  You could use: .  However, it's always going to be 0 as the result, because you're in a subshell. .   j= $i-10  You've added a space after the equal sign. You could use \"j=$i-10\", but that's not actually going to do any math. .  Try something like: .  You're probably going to want to write an if statement to handle senarios where i is 10 or less.  .  Try something like: .   for x in {$i..$j}  You can't use variables here. The result will be #..# instead of a list of numbers. You could get around this problem by creating a one-liner for do done statement that is echoed into a variable and then use eval to actually execute it. This way the $i and $j will already have been replaced with the actual numbers when the command is run. .  Ultimately though, the entire approach is pointless, because when you run the history command in the shell script you're going to get zero as the result of the count, because you're in a subshell, and subshells do not report their history. To see what I mean, run several commands, and then run this script: .  As you can see, the result is 0. Why? Because it's the history of the subshell, and the subshell doesn't report history. Even if you add other commands into the script before the history command, the result will be 0. .  Start over. Look into editing the history file directly as @kos has suggested. Keep in mind commands from the current shell aren't written to the file until the shell exits. .  Good luck. .  ",
      "P-tags": "14 04 script command-lin bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "so_11367639",
      "task": "Get a list of devices with missing drivers using powershell",
      "P-task": "get list devic miss driver use powershel",
      "F_verb": "get",
      "P-body": "I did this when i had some devices that where not being picked up by my script , give it a try and see if it detects your devices. .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP with NP using NP"
    },
    {
      "id": "au_712825",
      "task": "Nvidia X Server Settings don't save screen position settings",
      "P-task": "nvidia x server set save screen posit set",
      "F_verb": "save",
      "P-body": "There are many possible reasons why a screen configuration does not \"survive\" a restart. In most cases, there are local sources like the \"monitors.xml\" file that simply overrule previously made settings.  .  Finding out what it is exactly, can be time-consuming, so my approach would be the practical solution: simply overrule whatever happens on log in by a simple command or small (\"xrandr\") script. In this case, it is probably done by the command: .  which arranges the screens from left to right, which you should always do. .  Add the command to startup (log in) Choose Dash > Startup Applications > Add, add the command: .  Explanation: .   postioning a screen can be done with the command: .  to position e.g the left screen, then: .  Always arrange the screens from left to right .  The \"sleep 15\" is to make sure the command runs when the desktop is \"ready\", and possible local settings do not overrule the command.  ",
      "P-tags": "multiple-monitor nvidia xorg 14 04 display-resolut",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_25277",
      "task": "Unable to connect to remote server via SSH (requires public key)",
      "P-task": "unabl connect remot server via ssh requir public key",
      "F_verb": "connect",
      "P-body": "If you have been given the .ppk file by the sysadmin, you can use puttygen to create the ssh key files (install putty-tools from software centre) .  also, there are some mac instructions which should also work .  Note that when running command .  it may ask for password to decrypt the key, plus you should run it as the user which will make the ssh connection so that it stores the key in the correct directory (the ~ symbol is equivalent to the home directory of the current user) Then after checking the chmod permissions are correct you can use .  ",
      "P-tags": "ssh",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP via NP"
    },
    {
      "id": "au_1190284",
      "task": "How to debug black screen after logging in with NVidia drivers that strangely fixes itself at random times?",
      "P-task": "debug black screen log nvidia driver strang fix random time",
      "F_verb": "debug",
      "P-body": "It's several months later and I don't know why, but my issue is resolved. Possibly due to one of the latest system updates. .  In the meantime I have been using suspend rather than shutdown: Whenever I had to restart, I would see the login screen, then after the login I would only see the mouse cursor and the TeamViewer window on an otherwise black screen, and another message complaining that it cannot place an icon on the taskbar (because the taskbar did not exist). If I waited, the machine would suddenly show me the login screen again, after a random amount of time, usually around 10 to 30 minutes. Once this happened, I could login again. .  But now after I first login, I see (as before) TeamViewer on a black screen, I also see the message complaining about the taskbar, but then after about a minute or so, the desktop appears. This is much better, because I don't mind waiting for a minute or so, as I rarely have to restart the machine! .  I suspect that one of the recent updates has fixed the issue, or at least made it less severe. The system is currently at: .  I no longer think this was an Nvidia driver issue, possibly something to do with dbus, according to the logs. .  I was not able to find the root cause unfortunately. .  Thank you to all who offered to help. .  ",
      "P-tags": "graphic systemd-logind dbu xorg 18 04",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP after S_ING with NP that S"
    },
    {
      "id": "au_1374872",
      "task": "Can not call defined funtions from .bashrc",
      "P-task": "call defin funtion bashrc",
      "F_verb": "call",
      "P-body": "If you're running \"zsh\" shell then you have to put this in \"~/.zshrc\" instead of \"~/.bashrc\". .  Once you've added it there, you can either open a new terminal or run \"source ~/.zshrc\" to use it. .  ",
      "P-tags": "bashrc command-lin zsh",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP from NP"
    },
    {
      "id": "so_47821329",
      "task": "how to copy lines one by one from a file and paste then into another file after every n lines using shell script",
      "P-task": "copi line one one file past anoth file everi n line use shell script",
      "F_verb": "copy",
      "P-body": "Here is a way to do it with \"paste\" .  The dash argument for \"paste\" means to read from the standard input, which is the \"cat file2\" output, while the fourth argument is \"file1\". So, with three dashes, we will paste every 3 lines of one file with 1 from another and the delimiter is the newline character (\"-d'\\n'\"). .  This will work in case of remaining lines in any of these files, as paste will continue when \"EOF\" is found for one of the inputs. But it may print a couple of empty lines in that case, so you can pipe to any command to remove them, (supposing you don't have actual empty lines in your files), for example .  ",
      "P-tags": "csh bash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP by NP from NP"
    },
    {
      "id": "so_56175071",
      "task": "Bash delete all symbols before last 2 \"/\" symbols in variable",
      "P-task": "bash delet symbol last 2 symbol variabl",
      "F_verb": "delete",
      "P-body": "Bash parameter parsing. No need to run a subprocess. .  If you want to get rid of that leading slash as well... .  ",
      "P-tags": "variabl sed bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP before NP in NP"
    },
    {
      "id": "so_28056609",
      "task": "Flattening records in Unix",
      "P-task": "flatten record unix",
      "F_verb": "flatten",
      "P-body": "It is a matter of identifying and storing the code from the first of each pair of lines to go on each output line with the individual values parsed from the second of each pair of lines. The code is more succinct if we set the field separator to \"*\" and the output field separator to \"|\" at the start. .  ... which, given the input shown in the question, produces the output: .  ... as required. .  ",
      "P-tags": "awk normal unix",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP in NP"
    },
    {
      "id": "so_52089981",
      "task": "What's the equivalent of \"find -mmin\" in HP-UX?",
      "P-task": "equival find -mmin hp-ux",
      "F_verb": "find",
      "P-body": "According to the man page hpux 10.20 - find (1), your implementation of \"find\" doesn't support the \"-mmin\" option. .  The closest equivalent would be \"-mtime\" .   -mtime n True if the file has been modified in n days. .   Similar questions (Find files modified within one hour in HP-UX, how to find files modified in the last hour?) suggest creating a \"reference\" file with \"touch -mt $time\" and using \"find -newer\". .  Quoting the second link, you could do: .   Create a temp file using the 'touch' command, such that the modification time is one hour in the past. For example: .  Then run 'find' with the '-newer' switch, taking advantage of this file: .   ",
      "P-tags": "hp-ux linux unix shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "au_641169",
      "task": "how to install pgbench?",
      "P-task": "instal pgbench",
      "F_verb": "install",
      "P-body": "Your mistake in: .  It should be: .  Or just run: .  And after that you can run: .  ",
      "P-tags": "postgresql",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_1185860",
      "task": "how to solve this error? (collect2: fatal error: cannot find 'ld')",
      "P-task": "solv error\ncollect2 : fatal error : find ld",
      "F_verb": "solve",
      "P-body": "I do not see any issues compiling this software as follows: .  After compilation it runs normally: .  You may have some missing dependencies. .  ",
      "P-tags": "fortran compil make",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP"
    },
    {
      "id": "so_5198962",
      "task": "How to use Bash to see what URL Firefox / Chrome is pulling?",
      "P-task": "use bash see url firefox chrome pull",
      "F_verb": "use",
      "P-body": "Wireshark I don't know of a way to do it with bash, but from your question it sounds like the Wireshark packet sniffer would be a good option. You set it up to capture all packets matching a specific set of criteria (for instance, those going to host \"www.example.com:80\") and you can then inspect the HTTP traffic. .  ",
      "P-tags": "maco bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF what S"
    },
    {
      "id": "so_13323778",
      "task": "Bash script how to execute a command from a variable",
      "P-task": "bash script execut command variabl",
      "F_verb": "execute",
      "P-body": "You want \"eval\". It's evil. Or at least, dangerous. Read all about it at BashFAQ #48. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_48571641",
      "task": "Get .NET Core DLL version on Linux",
      "P-task": "get net core dll version linux",
      "F_verb": "get",
      "P-body": "I use \"exiftool\": .  Originally discovered from here. .  Watch out, though. It doesn't work on \"crossgen\"ed stuff: .  ",
      "P-tags": "linux net-cor",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_191595",
      "task": "Delete folders which not match a list",
      "P-task": "delet folder match list",
      "F_verb": "delete",
      "P-body": "Assuming your file names do not contain any of \":\\[*?\", you could still use \"GLOBIGNORE\". Just format your list of directories accordingly. For example: .  That is very easy to transform into a colon separated list: .  So, you can now set that as the value of GLOBIGNORE: .  And proceed to delete them normally: .  I just tested this on Linux with 300 directories and it worked perfectly. .  ",
      "P-tags": "shell-script bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP which S"
    },
    {
      "id": "so_44870142",
      "task": "PowerShell detect if command terminated",
      "P-task": "powershel detect command termin",
      "F_verb": "detect",
      "P-body": "Wrap the script invocation in a try/catch block to handle the OOM exception, then wrap that in a loop: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_28499844",
      "task": "php scripts get 'exec format error' or 'permission error'",
      "P-task": "php script get exec format error permiss error",
      "F_verb": "get",
      "P-body": "Ok, figured it out myself: .  The mod_php5 package was installed, but that didn't automatically activate it. Do: .  The file needs to be configured as follows: .  ",
      "P-tags": "linux apach php suse",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_23822564",
      "task": "bash, find nearest next value, forward and backward",
      "P-task": "bash find nearest next valu forward backward",
      "F_verb": "find",
      "P-body": "Try this: .  . .  ",
      "P-tags": "awk asort find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_52518485",
      "task": "Makefile - Compile all sub directories and output .o files in a separate directory",
      "P-task": "makefil - compil sub directori output file separ directori",
      "F_verb": "compile",
      "P-body": "It is not trivial because you have your sources in different directories and simple make pattern rules cannot easily handle this. But using slightly more advanced make features can make it: .  Beware: you could have several source files with the same base name in different directories. And if this happens, you will end up with a fatal conflict of object file names... .  EDIT (add conflicts detection): .  The following detects conflicts situations and issues an error (replace \"error\" by \"warning\" or \"info\" depending on the severity level you assign to these conflicts): .  (\"sort\" sorts and also removes duplicates and \"words\" returns the number of space-separated words in its string parameter). .  ",
      "P-tags": "makefil bash rule compil subdirectori",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP in NP"
    },
    {
      "id": "so_9374195",
      "task": "Jetty (mis)configuration: it wont respond from an external machine... why?",
      "P-task": "jetti mi configur : wont respond extern machin",
      "F_verb": "respond",
      "P-body": "Make sure this is not an firewall issue. Maybe 8080 port is closed by firewall. .  Also try add line into file /etc/default/jetty : .  See similar question .  ",
      "P-tags": "amazon-ec2 jetti ubuntu configur",
      "source": "qa",
      "cate": "respond",
      "pat": "V from NP"
    },
    {
      "id": "su_498312",
      "task": "How to reset Bash on Mac OSX, .bash_profile corrupted and bash no longer works",
      "P-task": "reset bash mac osx bash_profil corrupt bash longer work",
      "F_verb": "reset",
      "P-body": "Just putting all my comments together for an answer: .  First thing you should do is change the shell, this way you can set a shell that will not load the bash init-scripts (\".bashrc\", \".bash_profile\") - how to do this for the Mac OS X terminal app can be seen here: Apple Support .  Now you should be able to open a terminal again and use your favourite command-line editor to open the \".bash_profile\" file (e.g. \"nano\" or \"vi\"): .  In this file you have to reset your \"PATH\" variable that is used by the terminal to find the programs it can execute. .  This can be done with the following two lines: .  This will first set the directories that you want to have on your PATH and the export this PATH to make it available to all programs started from this shell (via export). .  ",
      "P-tags": "termin bash-profil maco bash",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP on NP"
    },
    {
      "id": "so_55090078",
      "task": "Termcap tgetstr getting arrow keys",
      "P-task": "termcap tgetstr get arrow key",
      "F_verb": "get",
      "P-body": "Terminal descriptions are written for full-screen applications, which are initialized using one or more terminal capabilities assigned to this. About half of the terminal descriptions initialize the terminal's cursor- and keypad-keys to use application mode. In application mode, those keys send different characters. .  The ncurses FAQ My cursor keys do not work goes into more detail. .  If you are trying to use a terminal description for some non-screen command-line application, you could make your command-parser treat both \"\\E[\" (CSI) and \"\\EO\" (SS3) as the same thing, and ignore the difference between the two modes. That was done in some configuration for \"zsh\", as mentioned in the xterm manual page. .  By the way, if your \"termcap\" is actually an interface to a terminfo system (such as ncurses), it is not necessary to allocate the buffer, since that is ignored. ncurses' manual says: .    The emulation ignores the buffer pointer \"bp\". The termcap library would store a copy of the terminal description in the area referenced by this pointer. However, ncurses stores its terminal descriptions in compiled binary form, which is not the same thing.   ",
      "P-tags": "termcap c tti unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_52410332",
      "task": "Trying to add 1 day to a timestamp in bash script but it's only adding 19 hours",
      "P-task": "tri add 1 day timestamp bash script ad 19 hour",
      "F_verb": "add",
      "P-body": "\"date\"'s free-form date parser seems to get pretty confused with \"+ something\" at the end of a date-time. All the gory details here: https://www.gnu.org/software/coreutils/manual/html_node/Date-input-formats.html .  I get similar results: .  but if you ask for \"tomorrow\" instead of \"+1 day\": .  ",
      "P-tags": "linux time shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "au_487283",
      "task": "New PHP5.3.10 update error",
      "P-task": "new php5 3 10 updat error",
      "F_verb": "update",
      "P-body": "In order to fix broken alternatives link for awk try: .  Verify if it is fix with command: .  Redo apt command: .  If this doen't work and directory /etc/alternatives doesn't exists, try: .  chose everything to be in 'auto' mode. .  ",
      "P-tags": "dpkg awk php updat 12 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_199364",
      "task": "Create a loopback interface and make it permanent (FreeBSD)",
      "P-task": "creat loopback interfac make perman freebsd",
      "F_verb": "create",
      "P-body": "You can add in your \"/etc/rc.conf\": .  where \"a.b.c.d\" is the ip address. .  ",
      "P-tags": "freebsd ifconfig network-interfac",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_15346568",
      "task": "Qt 4.8.4 Cross-Compiled for Embedded Linux fails with QNetworkProxy Error",
      "P-task": "qt 4 8 4 cross-compil embed linux fail qnetworkproxi error",
      "F_verb": "compile",
      "P-body": "I found out that there was a qconfig.h file being included that had the following define: .  This was obviously the problem. .  ",
      "P-tags": "embedded-linux qtembed qtnetwork cross-compil qt",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V for NP with NP"
    },
    {
      "id": "so_53023867",
      "task": "Definition of unit in Modelica (OpenModelica) for parameters, cannot be found in scope of parameters file",
      "P-task": "definit unit modelica openmodelica paramet found scope paramet file",
      "F_verb": "find",
      "P-body": "Seems to be working fine, but you need to import def_units elements in your param record or you need to define them as \"parameter def_units.min_1 beta=0.002;\" I would also suggest changing def_units from a model to a package. Read more about Modelica imports and different Modelica classes such as packages, records, models and blocks in the Modelica Specification on modelica.org or the Modelica Book: http://book.xogeny.com/. .  File def_units.mo .  File param.mo .  File script t.mos .  Running the script with the OpenModelica compiler OMC: .  ",
      "P-tags": "openmodelica ubuntu-18 04 paramet unit-test modelica",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP of NP"
    },
    {
      "id": "so_27282206",
      "task": "How can I use the -last parameter in PowerShell to select files to copy?",
      "P-task": "use -last paramet powershel select file copi",
      "F_verb": "use",
      "P-body": " The input object for \"Copy-Item\" is the issue. One way around it is to use a \"ForEach-Object\" and use the \"FullName\" property as the \"Path\" for \"Copy-Item\" .  Like Ansgar says you can just pipe directly into \"Copy-Item\" as well as long as you use the named parameter \"-Destination\" .  \"Copy-Item\" only has space for 2 positional paramenters for \"-Path\" and \"-Destination\". In your example those were specified leaving no space for the pipeline input. Removing the \"-Path\" allowed the pipeline input to match. To make sure there were no positional conflicts \"-Destination\" needed to be named.  .  ",
      "P-tags": "powershel file-io",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP S_INF"
    },
    {
      "id": "au_330735",
      "task": ".deb built in PPA doesn't install my binary",
      "P-task": "deb built ppa instal binari",
      "F_verb": "build",
      "P-body": "I still have no idea why it was screwing me - I was following the Ubuntu packaging guide to the letter - but eventually I got it working. .  What I ended up doing is: \"apt-get source zfsync\" into a completely different directory, then investigating what was in there.  .  In addition to a \"zfsync-1.0.0\" folder which contained all my stuff, there was a \"zfsync\" folder that had \"usr/share/doc\" in there but no \"usr/bin\" at all. I manually created \"usr/bin/zfsync\" in the \"zfsync\" folder, made damn certain that the \"debian/install\" had \"zfsync usr/bin\" in it, then did a \"bzr init\", a \"bzr commit\", and a \"dput ppa:jrssnet/zfsync zfsync_1.0.0-0ubuntu5_source.changes\" ... and, five or ten minutes later, SUCCESS! Ubuntu's build process actually resulted in not only a .deb, but a .deb that ACTUALLY INSTALLED MY DAMN SCRIPT. :) .  ",
      "P-tags": "apt ppa deb",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V in NP"
    },
    {
      "id": "so_31356110",
      "task": "SCP a file that match a particular pattern and extension",
      "P-task": "scp file match particular pattern extens",
      "F_verb": "match",
      "P-body": "This will do your job: .  ",
      "P-tags": "linux unix scp",
      "source": "qa",
      "cate": "match",
      "pat": "V NP"
    },
    {
      "id": "su_196864",
      "task": "How to install local .deb packages with apt-get",
      "P-task": "instal local deb packag apt-get",
      "F_verb": "install",
      "P-body": "usually I do \"dpkg -i <deb file>\", it'll fail saying it needs dependencies. After that when you do an \"apt-get update\" it'll say at the end something like \"dependencies are ready to install\" I think it then advises to use \"apt-get install -f\". .  Once that's done, I use \"dpkg -i\" again. .  Worked fine for me last few years. .  edit: looking a bit further, apparently a tool called \"gdebi\" can do this as \"gdebi [deb file]\". .  ",
      "P-tags": "aptitud apt linux debian packag",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_493720",
      "task": "bash remove duplicate lines from txt files in folder",
      "P-task": "bash remov duplic line txt file folder",
      "F_verb": "remove",
      "P-body": " This loops over all the names that end in \".txt\" in the current directory and removes duplicated lines from each of them in turn. .  The file is first copied to a temporary file, and this temporary file is then processed with \"uniq\". The output is written to the original filename. .  Doing it this way ensures that the permissions on the original files are not altered (which they may be if one did \"uniq \"$file\" >\"$tmpfile\"\" followed by \"cp \"$tmpfile\" \"$file\"\"). .  The call to \"uniq\" is also depending on the \"cp\" to be successful. If the \"cp\" failed, the \"uniq\" command's redirection would otherwise truncate the original file and you would loose that data. .  ",
      "P-tags": "uniq shell-script bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_6016",
      "task": "How to set Monday as the first day of the week in GNOME 2 Calendar applet?",
      "P-task": "set monday first day week gnome 2 calendar applet",
      "F_verb": "set",
      "P-body": "Here's another solution, also from Ubuntu Forums. I think this is somewhat cleaner and more robust: it doesn't involve customizing Ubuntu's locale files (only settings that you're supposed to edit). .   Gnome calendar applet adheres to your locale settings. In Ubuntu, you can assign locale components by editing the file \"/etc/default/locale\". Here is what I've got there: .  Which means: I want software messages in American, but time, paper size and units in British i.e.weeks starting with Mondays, A4, metric. .   Props to artm who posted that! .  Of course, \"LC_TIME=\"en_GB.UTF-8\"\" is the relevant setting to get weeks to start on Mondays. .  You need to log out and back in for the change to take effect. .  ",
      "P-tags": "gnome local calendar",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP as NP of NP in NP"
    },
    {
      "id": "so_39621144",
      "task": "Ubuntu can't use node to run mongod database",
      "P-task": "ubuntu use node run mongod databas",
      "F_verb": "use",
      "P-body": "You can't ping a port. Ping is ICMP and not TCP or UDP. The line \"mongodb start/running, process 1382\" indicates that MongoDB is running. .  It is likely that MongoDB's bind IP is set to \"127.0.0.1\". In the MongoDB configuration, check the value of \"bind_ip\". It is likely set to localhost (127.0.0.1) and thus will only accept connections from the local VM. .  There are many guides out there that can help, such as this or this.  .  ",
      "P-tags": "mongodb amazon-web-servic ubuntu",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_31588035",
      "task": "Bash one-line command to send wake on LAN magic packet without specific tool",
      "P-task": "bash one-lin command send wake lan magic packet without specif tool",
      "F_verb": "send",
      "P-body": "The minimum requirements I can think off: .   Bash supporting brace expansion (I think it is v3.5.1 and above). The sed command (1). NetCat.  Assuming: .   WOL package for LAN, broadcast to 255.255.255.255.  The command line would be: .  Replace \"$MAC\" by the destination MAC. Or, this time in a two-liner :-) command: .  So, in a more generic notation: .  Explanations: .   The WOL magic packet is composed of \"ffffffffffff\" (12 times \"f\") followed by 16 times the destination MAC without colons (\":\"). The \"sed\" command is used here to remove colons (\":\") from the MAC and to add the \"\\x\" hex specificator (so that \"11\" becomes \"\\x11\", \"22\" becomes \"\\x22\" ... and so on) prior to sending the string to the network stack. The forged wake on LAN package is sent to the network stack piping it to NetCat. SoCat can be used instead (syntax will differ, of course).  Tested working on Ubuntu, Kali and even CygWin (Windows 7 SP 1 64 bits ). .  To take under consideration: .   CygWin's NetCat version doesn't need for \"-b\" parameter. NetCat's OpenBSD version has a bug as for today (Juy 2015) on broadcast data sending (\"-b\"), so you will have to replace it by NetCat Traditional version (netcat-traditional package on apt-get installers). This example uses UDP port 4.000. The specific port number seems not to be important on WOL. The above one-line bash command should work too for wake on LAN via internet. In this case replace \"$Broadcast\" address by the destination public IP, and open/forward the specified \"$PortNumber\" (UDP) on destination. \"echo -e\" can be replaced by \"printf\".  WOL magic packet string for the above example: .  (1) Well, indeed, \"sed\" is not explicitly required. It is used here to remove ':' and add \"\\x\" to each pair of characters in the magic packet's forged string. I know there are ways to replace \"sed\" by some shell expansion or so. .  ",
      "P-tags": "wake-on-lan bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP on NP without NP"
    },
    {
      "id": "ul_153559",
      "task": "How is the content of configuration files parsed on different Linux distributions?",
      "P-task": "content configur file pars differ linux distribut",
      "F_verb": "parse",
      "P-body": "The kernel doesn't read any configuration file. As a rule, kernels avoid accessing the filesystem; there are a few exceptions and variation, but mainly, the kernel launches a program at the location \"/sbin/init\" when it boots, and the only accesses filesystems on behalf of user land processes. .  Network configuration files (like other kinds of configuration files) are read by applications. For the network configuration files, these applications are suites of scripts and accompanying binaries that read the file and apply the configuration by making system calls. For network configuration on Linux, the system calls are mostly \"ioctl\" calls on sockets (you don't need to understand this). .  Over the history of Linux (and Unix before it), some configurations have become standard, because everybody agreed on how to do it. This is largely the case (though not universal) for users (\"/etc/passwd\", NSSwitch) and filesystems (\"fstab\"). On the other hand, network configuration has remained pretty diverse. Distributions derived from Red Hat keep it under \"/etc/sysconfig/network\"; distributions derived from Debian keep it in \"/etc/network/interfaces\". .  Going with Debian as an example, \"/etc/network/interfaces\" is parsed by the \"ifup\" program, which is invoked from \"/etc/init.d/networking\", the init script in charge of setting up networking, itself invoked by \"init\". .  ",
      "P-tags": "linux network configur",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V on NP"
    },
    {
      "id": "so_45320885",
      "task": "How to package c++ dependencies on linux",
      "P-task": "packag c++ depend linux",
      "F_verb": "package",
      "P-body": "The worst part of your contitions is an incompatible standard library. You have to link it statically anyway (see comments to your answer). .  A number of options: .  Completely static linking: I think it's easiest way for you, but it requires that you can build (or get by any way) all third-party libs as static. If you can't for some reason it's not your option. .  You just build your app as usual and then link it with all libs you need statically (see documentation for your compiler). Thus you get completely dependencies-free executable, it will work on any ABI-compatible system (you may need to check if x86 executable works on x86_64).  .  Partially static linking You link statically everything you can and dynamically other. So you distribute all dynamic libs (\"*.so\") along with you app (in \"path/to/app/lib\" or \"path/to/app/\" folder), so you don't depend on system libraries. Create your \"deb\" package which brings all files into \"/opt\" or \"$HOME/appname\" folder. You have to load all dynamic libs either \"by hand\" or ask compiler to do it on linking stage (see documentation). .  Docker container I don't know much about it but I know exactly it requires that docker be installed on target system (not your option). .  Useful links: .  g++ link options .  static linking manual .  Finding Dynamic or Shared Libraries .  There are similar docs for clang, google it. .  ",
      "P-tags": "c++ linux packag cmake",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP on NP"
    },
    {
      "id": "so_24028104",
      "task": "Find latest modified file information in PowerShell",
      "P-task": "find latest modifi file inform powershel",
      "F_verb": "find",
      "P-body": "Are you sure that what you are trying to do is not the following? .  You can try this: .  ",
      "P-tags": "last-modifi powershell-3 0",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_115245",
      "task": "Install RPM file on Arch Linux?",
      "P-task": "instal rpm file arch linux",
      "F_verb": "install",
      "P-body": "Jasonwryan (as per usual) was right on the mark with his initial comment. .  Arch's packages are supposed to be as close to \"vanilla\" as possible. Now, while you could use \"rpmextract\" or \"alien\", there isn't really a good reason to do so. What you should do is create a \"PKGBUILD\" that uses the RPM as the source file and then installs everything that's needed where it should be in the \"package()\" function. If you are unsure of how to do this, take a look at some packages on the ArchLinux User Repository; there are plenty that do similar things. .  Now, since \"bsdtar\" (the default extractor used on source files by \"makepkg\") supports extracting RPMs without issue, there is no reason to use \"rpmextract\"\u2014it adds a makedependency without adding any real functionality. .   Some related reading from the wiki: .   \"PKGBUILD\"s Basic \"PKGBUILD\" templates Arch packaging standards  ",
      "P-tags": "arch-linux rpm software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_13065664",
      "task": "Comparing a string in a text file in a line and remove that line when found",
      "P-task": "compar string text file line remov line found",
      "F_verb": "compare",
      "P-body": "You can copy each line one by one into \"buff\" as you did and then match with the line which you want to delete from existing file. if not matched then copy it to some temporary file . Do it till eof(). You just don't have to copy the line which you want to delete from the existing file. .  After it just rename the temporary file with same name as it was earlier. .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_14833771",
      "task": "trouble getting sublime to execute with linux terminal",
      "P-task": "troubl get sublim execut linux termin",
      "F_verb": "get",
      "P-body": "I'm using Linux Mint 13, but should be similar for you. \"cd\" into /usr/bin. There should a file called sublime-text-2. Copy that file and name subl. Then \"subl\" command should be usable in the terminal. .  Just in case, here is the contents of the file: .  ",
      "P-tags": "termin unix linux ubuntu sublimetext2",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF with NP"
    },
    {
      "id": "au_298247",
      "task": "How do i enable compiz widget layer onto ubuntu 13.04?",
      "P-task": "enabl compiz widget layer onto ubuntu 13 04",
      "F_verb": "enable",
      "P-body": "All you have to do is installing the extra package. Just press Ctrl+Alt+T on your keyboard to open Terminal. When it opens, run the command(s) below: .  ",
      "P-tags": "installed-program",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP onto NP"
    },
    {
      "id": "ul_583892",
      "task": "How can one record mic audio straight to a FLAC file?",
      "P-task": "one record mic audio straight flac file",
      "F_verb": "record",
      "P-body": "Ffmpeg is capable of applying the same options to different inputs and outputs, which result in ffmpeg being sensitive to the position of the options. .  The following will use your settings and output to a FLAC file (recognized by the file ending): .  The settings are applied to the next input or output, so while it is not needed in your example, you can use the \"-acodec\" after listing your input files or streams, and before your output e.g.: .  ",
      "P-tags": "ffmpeg record alsa",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP"
    },
    {
      "id": "so_56976664",
      "task": "Fastest way to compare hundreds of thousands of files, and create output results file in bash",
      "P-task": "fastest way compar hundr thousand file creat output result file bash",
      "F_verb": "create",
      "P-body": "Here's a solution in Python, using its ordered dictionary datatype. .  Output: .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_52007260",
      "task": "Checking out a Github PR and then pulling updates?",
      "P-task": "check github pr pull updat",
      "F_verb": "check",
      "P-body": "One simple modification, assuming your PRs are all expected to be on \"upstream\" (as the existing code assumes) might be: .  That's if you want to preserve any local changes you may have made, though force-pushes by others to the PR branch may mess things up a bit. If you just want to reset the branch to the remote one, discarding any local changes: .  ...or, to put local changes on top of remote ones rather than discarding them outright: .   That there's no one right way to do this is probably a good hint that git upstream did the right thing by not making it all one built-in command: Human judgment is appropriate to decide the right action based on the scenario at hand. .  ",
      "P-tags": "git github git-bash bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V out NP"
    },
    {
      "id": "so_19212305",
      "task": "Seg faulting when getting user input?",
      "P-task": "seg fault get user input",
      "F_verb": "get",
      "P-body": "The problem is with this statement: .  You need to pass in a pointer to a buffer for the input string, not a pointer to a \"char *\". Replace it with something like: .  Of course, this is not secure code since the user's input could exceed 1000 characters. But let's get the basics right first. .  ",
      "P-tags": "scanf linux strcat shell c",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_349389",
      "task": "Bash reliable way to test file exists",
      "P-task": "bash reliabl way test file exist",
      "F_verb": "test",
      "P-body": "The problem isn't with the circular link, it's the symlink pointing to a file that doesn't exist. The same thing will happen any time you point a symlink to any file that doesn't exist. .  From the \"test\" man page: .   If file is a symbolic link, test will fully dereference it and then evaluate the expression against the file referenced, except for the -h and -L primaries. .   This is the only edge case for \"test\" mentioned in its man page. .  ",
      "P-tags": "test file shell bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "au_276847",
      "task": "running gnome-terminal with no window border on startup in xubuntu 12.10",
      "P-task": "run gnome-termin window border startup xubuntu 12 10",
      "F_verb": "run",
      "P-body": "You can do that stuff with devilspie. Install the devilspie package, and write the following configfile (save as \"~/.devilspie/gnome-terminal.ds\") .  Now you just run \"devilspie\" when you log in (e.g. by adding it to startup applications), then whenever a window with the role \"borderless\" appears, it will be moved to position (0,0), maximized vertically, and decorations removed. .  You specify the role of gnome-terminal with the \"--role\" option. .  ",
      "P-tags": "gnome-termin xubuntu python bash pygtk",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP on NP in NP"
    },
    {
      "id": "ul_178747",
      "task": "Create folder as Apache with user add Centos",
      "P-task": "creat folder apach user add cento",
      "F_verb": "create",
      "P-body": "You should be able to use .  but as usual, you'll need to be root to create files/dirs with somebody else's ownership. At that point, you could as easily \"sudo -u apache /bin/bash\" to gain a shell as the apache user. .  ",
      "P-tags": "mount cento php apache-httpd",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP as NP with NP"
    },
    {
      "id": "so_40043029",
      "task": "Multiple array level of json rendering with jq",
      "P-task": "multipl array level json render jq",
      "F_verb": "render",
      "P-body": "I will make another answer to work with jq .  First you can rewrite the first query .  Then if you want to add additional value from the Json like `DeviceName`` .  you get the following .  which are the 6 lines you expect .  ",
      "P-tags": "json amazon-ec2 jq bash",
      "source": "qa",
      "cate": "draw/render/paint/redraw/plot",
      "pat": "V with NP"
    },
    {
      "id": "au_672974",
      "task": "Why doesn't the icon change in the launcher when I change the .desktop file?",
      "P-task": "icon chang launcher chang desktop file",
      "F_verb": "change",
      "P-body": "The problem is that qBittorrent's \".desktop\" file sets the icon based on the localization: .  So changing the icon set by the first generic \"Icon=\" entry doesn't help: .   .  You'll have to set the \"Icon=\" entry matching your current locale; however since localizing the icon by setting the very same icon for each locale is a very silly thing to do in first place, you might as well just change all the \"Icon=\" entries by running this command (it will create a \"qBittorrent.desktop.bak\" backup file in \"/usr/share/applications\"): .  Or delete the localized \"Icon=\" entries and change the generic \"Icon=\" entry by running this command (it will create a \"qBittorrent.desktop.bak\" backup file in \"/usr/share/applications\"): .  Or just change the \"Icon=\" entry matching your current locale by any mean, such as: .   .  ",
      "P-tags": "14 04 uniti",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_26104052",
      "task": "How do I ignore all output of a bash command until a given marker",
      "P-task": "ignor output bash command given marker",
      "F_verb": "ignore",
      "P-body": "Another choice:  .  ",
      "P-tags": "xcodebuild xcode shell bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP of NP until NP"
    },
    {
      "id": "ul_288667",
      "task": "How to delete a variable string in file",
      "P-task": "delet variabl string file",
      "F_verb": "delete",
      "P-body": "Assuming you just wanted to delete all string starting with \"Perro\", you can use: .  If you want to edit the file in place, you can use \"-i\" option with \"sed\", like .  Update .  If you don't want to have multiple spaces, you can use: .  sample data, .  ",
      "P-tags": "sed command-lin text-process",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "so_7725151",
      "task": "Script to delete all files in directory then email",
      "P-task": "script delet file directori email",
      "F_verb": "delete",
      "P-body": "Some notes: .  You use all-caps DIR, LIST and FILES, but all-caps variables in shell scripts are, by convention, environment variables. You should use e.g. .  instead. .  To find how many files are in a directory use .  You use both LIST and FILES; it seems like you're tring to find out if there are any files before deleting them. There's no point to this from a functionality point of view but if you must conditionally echo the list of files it's better to make the decision this way. .  Although you should be aware that this output cannot be reliably used to reconstruct the actual file names. .  To actually delete the files you should again use \"find\" .  Putting it all together .  Here I have combined the \"print files\" and \"delete files\" steps into a single invocation of \"find\". .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP then NP"
    },
    {
      "id": "su_361258",
      "task": "If I stop Linux process will it quit by itself",
      "P-task": "stop linux process quit",
      "F_verb": "stop",
      "P-body": "It will stay. \"ctrl + Z\" sends SIGTSTP signal to process not SIGQUIT or SIGKILL. If you would like to kill process then use \"ctrl + C\" or kill your stopped process with kill command. In some shells it is just \"kill %\". .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP by NP"
    },
    {
      "id": "so_9840970",
      "task": "How to code in java to run unix shell script which use rSync internally in windows environment using cygwin?",
      "P-task": "code java run unix shell script use rsync intern window environ use cygwin",
      "F_verb": "run",
      "P-body": "Use the Runtime class to run Cygwin. This is very brittle, and dependent upon your setup, but on my machine I would do:  .  Then wait for the Process to complete, and get a handle to it's InputStream objects to see what was sent to stdout and stderror.  .  The first part of the command is to run cygwin, and the second is to execute some script, or command (using \"-e\" or \"--exec\"). I would test this command on the DOS prompt to see if it works first before cutting any code. Also, take a look at the options available by doing: .  Also from within the DOS prompt. .  EDIT: The following works for me to print version information .  Unfortunately, can't seem to get it working with \"--exec\", so you're going to have to do some more research there. .  ",
      "P-tags": "cygwin jakarta-e shell java window",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP which S"
    },
    {
      "id": "so_33350854",
      "task": "how to use grep to search for 2 or more parentheses and words capitalization",
      "P-task": "use grep search 2 parenthes word capit",
      "F_verb": "use",
      "P-body": "Try this regex: .  Output: .  \"grep -Elr\" will output: .  The regex searches for: .   ?? !! () used at least twice on a line Four or more capitalized words on a line ;  ",
      "P-tags": "grep bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF for NP"
    },
    {
      "id": "so_33968812",
      "task": "Shell script can't use logical or with find command",
      "P-task": "shell script use logic find command",
      "F_verb": "use",
      "P-body": "You need to think in terms of: .   \"-iname \"*.txt\"\" or \"-iname \"*.log\"\" and \"-type f\" and \"-mtime +15\" or \"-size +10000k\"  which translates to: .  The default conjunction between terms is 'and' so there's no need for explicit \"-and\" operations. .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_59783063",
      "task": "Gnu parallel getting stuck, not giving output",
      "P-task": "gnu parallel get stuck give output",
      "F_verb": "give",
      "P-body": "As we debugged in the comments your \"(/usr/local)/bin/rm\" is not the normal \"(/usr/local)/bin/rm\". .  ",
      "P-tags": "linux ubuntu-18 04 gnu-parallel",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_24197327",
      "task": "Shell Script via Crontab - Start Jetty, works fine manually, but not via crontab",
      "P-task": "shell script via crontab - start jetti work fine manual via crontab",
      "F_verb": "start",
      "P-body": "Try setting the PATH in your cronjob file .  In my case,  .  Add the Path in your crontab : \"crontab -e\" .  You can check this question for more details. .  ",
      "P-tags": "linux ubuntu cron shell",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP via NP"
    },
    {
      "id": "ul_471363",
      "task": "Duplicate a line the same number of times as column 1",
      "P-task": "duplic line number time column 1",
      "F_verb": "duplicate",
      "P-body": "With \"awk\" same as JigglyNaga's answer: .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP of NP as NP"
    },
    {
      "id": "so_59447571",
      "task": "Modify Linux kernel config file",
      "P-task": "modifi linux kernel config file",
      "F_verb": "modify",
      "P-body": "The \".config\" file is not generally supposed to be modified manually, event though you can. .  The clean and simple way is: .   \"make <device>_defconfig\" \"make menuconfig\"  edit exit saving changes  \"make savedefconfig\"  creates a file named \"defconfig\"  \"cp defconfig arch/$ARCH/configs/<device>_defconfig\"  where \"$ARCH\" is the CPU architecture, e.g. \"arm\"   A defconfig is similar to \".config\", except it contains only values that differ from their default values. As such they are much shorter and readable. The entire \".config\" is very verbose but it's what \"make menuconfig\" edits and what the kernel needs to build. .  ",
      "P-tags": "android android-kernel kernel linux linux-kernel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_46322",
      "task": "how can I recursively delete empty directories in my home directory?",
      "P-task": "recurs delet empti directori home directori",
      "F_verb": "delete",
      "P-body": "The \"find\" command is the primary tool for recursive file system operations. Use the \"-type d\" expression to tell \"find\" you're interested in finding directories only (and not plain files). The GNU version of \"find\" supports the \"-empty\" test, so .  will print all empty directories below your current directory. .  Use \"find ~ -\u2026\" or \"find \"$HOME\" -\u2026\" to base the search on your home directory (if it isn't your current directory). .  After you've verified that this is selecting the correct directories, use \"-delete\" to delete all matches: .  ",
      "P-tags": "linux find filesystem rm",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "so_20713782",
      "task": "Suspend or hibernate from PowerShell",
      "P-task": "suspend hibern powershel",
      "F_verb": "suspend",
      "P-body": "You can use the \"SetSuspendState\" method on the \"System.Windows.Forms.Application\" class to achieve this. The \"SetSuspendState\" method is a static method. .  [MSDN] SetSuspendState .  There are three parameters: .   State \"[System.Windows.Forms.PowerState]\" Force \"[bool]\" disableWakeEvent \"[bool]\"  To call the \"SetSuspendState\" method: .  Putting this into a more complete function might look something like this: .  Note: In my testing, the \"-DisableWake\" option did not make any distinguishable difference that I am aware of. I was still capable of using the keyboard and mouse to wake the computer, even when this parameter was set to \"$true\". .  ",
      "P-tags": "powershel window net",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP from NP"
    },
    {
      "id": "so_41854555",
      "task": "perl + delete the line only if match the exactly string in line",
      "P-task": "perl + delet line match exactli string line",
      "F_verb": "delete",
      "P-body": "Why don't you just include the double quotes in the regex pattern? .  ",
      "P-tags": "linux perl regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP if S"
    },
    {
      "id": "so_6195940",
      "task": "debugging server's cgi program",
      "P-task": "debug server cgi program",
      "F_verb": "debug",
      "P-body": "For starters you set the \"Content-length\" header to the length of the content, then sent the content, then sent more data in both threads. The browser is within its rights to ignore everything after content-length bytes in the output stream. .  ",
      "P-tags": "fork linux webserv cgi",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_64396410",
      "task": "Can't use assembly in PowerShell after I've installed the appropriate nuget package",
      "P-task": "use assembl powershel instal appropri nuget packag",
      "F_verb": "use",
      "P-body": "I found that the reason assemblies installed with \"Install-Package\" need to be loaded in this way: .  is because the package/lib directories in the \"PackagementManagement\" provider folders are not part of .NET default probe paths. This is less of a problem when you have modules or projects where the assembly paths are configurable in a file, but in a PowerShell session AFAIK you can't modify the assembly probe path. So you have to load the assembly with the full path. .   As for why the AWS assemblies in question couldn't find the assembly name after I loaded it into my session, I found the solution as well. After some additional testing, I found that there is an order of operations here; if you add an assembly with \"Add-Type\" or \"[Reflection.Assembly]::LoadFile\" after another assembly attempts to use it, that second assembly won't be able to find the first assembly for the duration of the PowerShell session. In my case, any assembly making use of \"Amazon.DynamoDBv2.DynamoDBEntryConversion\" in some way was failing because it could never locate \"Microsoft.Bcl.AsyncInterfaces\". .  My issue here was I would load up a new session, and start running my code forgetting to first use \"Add-Type\" to add the \"Microsoft.Bcl.AsyncInterfaces\" assembly, then use the AWS library which relied on it. Once the method failed, I added the assembly but it was too late for that session. So the fix here was to do the following: .  ",
      "P-tags": "nuget powershel amazon-web-servic powershell-cor",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP after S"
    },
    {
      "id": "so_46768604",
      "task": "How can I access methods of dynamically created variables?",
      "P-task": "access method dynam creat variabl",
      "F_verb": "create",
      "P-body": "I do not have access to those cmdlets but it looks like you are just trying to create some dynamic variables here and use some associated methods. .  First lets just capture the output from the first dynamic variable and save it.  .  So now \"$serversession\" would be a \"System.Management.Automation.PSVariable\" which at a minimum would have a name and value property. .  Now we can use the value of \"$serversession\" to perform our next operation .  That should do it.  .  Personally I would question the need for dynamic variables here. If you are planning on having multiple concurrent sessions maybe..... but there are many ways to deal with that.  .  Like a hashtable for example .  ",
      "P-tags": "powershel script",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP"
    },
    {
      "id": "so_52744308",
      "task": "how to merge two JSON objects using jq?",
      "P-task": "merg two json object use jq",
      "F_verb": "merge",
      "P-body": "Since I find jq pretty hard, I started in a procedural way: using ruby's json module: .  But we want jq, so after some trial and error, and finding this in the manual: https://stedolan.github.io/jq/manual/#Complexassignments -- (note, I changed the state for one of the instances so I could verify the output better) .  First, extract the states into an object mapping the id to the state: .  Then, update the instances in the first file: .  ",
      "P-tags": "json jq shell bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP using NP"
    },
    {
      "id": "so_24591914",
      "task": "Find and replace surounding of a string in file",
      "P-task": "find replac suround string file",
      "F_verb": "find",
      "P-body": "You can use \"sed\" command as following: .  This creates backup of your original file under .bak extension. Then it replaces all the the occurences in the file specified. .   \"s/original/replace/g\" replaces all occurences of \"original\" with \"replace\" \"\\(...\\)\" captures the match between to \"\\1\" which is applied on the right side \"[^}]*\" matches any number of characters other than \"}\" \"\\\\en{\\([^}]*\\)}\" i.e. the full left hand side therefore matches the \"\\en{some_string}\" pattern and stores what's between \"{\" and \"}\" to \"\\1\" which is used as a replacement on the right hand side.  You can apply the exact same command also in \"vim\": .  Here \":\" switches to command line mode, \"%\" means a range of all lines of the file, the rest is the same. .  ",
      "P-tags": "vim bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_56982373",
      "task": "Bash Script to download list of identifier and save to file",
      "P-task": "bash script download list identifi save file",
      "F_verb": "save",
      "P-body": " How to fix my code so that all the metadata that was download has a file name that resembles its identifier .   You have to tell \"wget\" not to write the output to a file it sees as appropriate, but rather to the standard output, and redirect the output of \"cut\" to your desired file: .  If by \"I want to split the metadata\" you meant the metadata identifiers rather than the downloaded metadata records, then the output doesn't need to be changed, just the identifier: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V to NP"
    },
    {
      "id": "so_45146499",
      "task": "Casting a String as an int, incrementing the int, and seeing the change in an exported CSV file",
      "P-task": "cast string int increment int see chang export csv file",
      "F_verb": "see",
      "P-body": "When I put your three parts correctly together I get your expected output. .  Sample output: .  ",
      "P-tags": "string csv int powershel",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_50933517",
      "task": "How does Powershell array flattening work?",
      "P-task": "powershel array flatten work",
      "F_verb": "flatten",
      "P-body": "Re: .   I expected the pipeline to flatten the list. But it does not happen. What am I doing wrong? .    Actually, some flattening did happen when you typed \"$x\" (your last command). Note how the previous \"$x.Length\" gave you 2, but the \"$x\" got you 3 elements of: .   an array (its properties were shown, instead of contents) The item \"4\" The item \"5\"  This shows that 'one level flattening' did occur. I hope you'll admit that this counts as flattening. .   Now, judging from your dissatisfaction from the result, you are rather wondering: .  \"Why didn't it go 'all the way'?\" .    I was also wondering about this behavior and what I learned is: .  1. The apparent rule behind PowerShell's behavior: A 'one level' flattening occurs on evaluation of scripts (including at least script files, script blocks, functions), when they yield their result to the caller. That is, if a script produces an array with any items also being an array, these items' arrays will rather be concatenated in their place (between their siblings). This flattening happens only once, on the top level array, so only its immediate 'children arrays' will be flattened but not any deeper ones. .  To look at your example, this flattening happened to you in two statements, actually: .   On the last statement, the already mentioned \"C:\\> $x\", when the shell performed an evaluation and returned 3 items (it didn't happen on the \"$x.Length\", as the \"$x\" evaluation did not yield to the calling shell) But also earlier, with \"@($x |% { $_ }).Length\", which also returned 3 items. This one got a flattening because \"% { $_ }\" is a 'script block', which introduces a new evaluation and a result yield to its caller of \"%\" (which itself is an alias to \"ForEach-Object\"). There were no other yields, as \".Length\" follows immediately, so it resulted in only one-level flattening again.  2. Documentation? Well, I could not find a documentation section that would be dedicated to this behavior. I am not even sure how to look for it because... How would the mechanism be called? 'Flattening of array results'? Couldn't find anything related under these keywords. I admit, not seeing this documented anywhere prominently is pretty surprising, given that getting your data structures changed implicitly can be quite a treacherous thing. .  3. Why flatten at all? For the lack of the documentation I can only speculate, but thinking about it, this seems to be built-in into PowerShell and is in fact part of its very fabric. Overall, I think it makes it easier to add more behavior to existing code, by reducing the modifications required. .  To elaborate, consider these two properties of a language which are certainly desired: .   allowing to add to the return array using simply multiple \"Write-Output\". It's desired especially because shell scripting deals with multiples of items all the time (multiple lines of text being the first obvious). Being able to compose the programs from from existing components/subroutines. Desired intuitively, I'd say.  Now, if the behavior of flattening wasn't there, extracting a group of statements that contains multiple output statements into a subroutine would mean that you suddenly get an array, where you previously had just flat multiple \"Write-Output\"s. Now this isn't a problem if it's you have no outputs left in the original top-level routine (because you can just \"return\" the array), but it is a problem if you still have multiple \"Write-Output\"s in it. One would need to either create an array variable and change each \"Write-Output\" into appends to it, or use a \"for\" loop around each extracted subroutine (because \"ForEach-Object\", AKA \"%\" or \"ForEach\", operates in its own inner scope). .  Perhaps a different solution to this problem could be a special operator (like JavaScript's \"yield*\") to return each item of an array, but it seems that PowerShell chose minimum operators, or minimum writing to achieve that - you simply \"Write-Output\" the whole array as normal (so that operator works like a JS \"yield\" for a single item, and a \"yield*\" for an array automatically). Somewhat notably, I think, this is done at the expense of those cases where one actually doesn't want the array to be flattened, which, I guess, it considered very much corner-case use of PowerShell. This SO question is one of them. Interestingly, an answer actually points at a workaround: it's using the unary variant of the comma operator \"(,$someArrayItem)\" to create an extra array around the 'item which is also an array', to have that one flattened, instead of the inner). .  4. Why not 'all the way'? Well, again, without the documentation this can only be a guess. What I can think of though is this: .  While flattening 'all the way' might seem like the desired behavior for those most common cases where flattening is desired at all, building it in by default would really be leaving the people in corner-cases where it isn't desired, without any simple workaround (because the extra \"(,$someArrayItem)\" to add a nesting level would be futile). The only way to get the out of the pickle for them would be using data structures different than arrays. This would be quite costly. .  A bit of a digression here: It's probably too wishful, but this surprising behavior isn't something that PowerShell couldn't evolve out of, if it wanted. For example, it could introduce some kind of array that would be never be flattened automatically (there could still be explicit flattening using an explicit statement over it). For that, by the way, what I feel would be rather fitting is a new parenthesis-based operator (similar to the \"@(...)\", for example a \"!(...)\"), because expressing a single array using \"(,$item)\" seems a bit odd (in some languages, e.g. JavaScript, \"[,$item]\" means an array of length 2 - first item being undefined). .  ",
      "P-tags": "array powershel",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_32065124",
      "task": "Can we implement .NET interfaces in PowerShell scripts?",
      "P-task": "implement net interfac powershel script",
      "F_verb": "implement",
      "P-body": "Here's a simple example with PowerShell 5.0 implementing the .Net IEqualityComparer interface: .  You could even have a class (called A), which inherits from another class (called B) and implements IEqualityComparer: .  ",
      "P-tags": "powershel c net powershell-3 0",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    }
  ],
  "3": [
    {
      "id": "ul_626495",
      "task": "Add a list of values of column A and B separated by space and show the summation result",
      "P-task": "add list valu column b separ space show summat result",
      "F_verb": "add",
      "P-body": "With \"awk\": .  in awk language which is a tool for text-processing purposes, \"$1\" represent first column's value, \"$2\" represent second column's value, \"$3\" for third and so on and one special one \"NF\" is represent the last column Id and accordingly \"$NF\" is the last column's value (so you can replace \"$2\" above with \"$NF\" too; and yes you catch it when \"NF\" is the last column Id, so value of the variable tells you how many columns do you have (its value update for each line awk is read form the input) ). .  To handle the edge case where the input file is empty and still get numeric output we add 0 to the result forcing \"awk\" to output numeric result. .  columns (or fields) in \"awk\" distinguished by the \"FS\" variable (Feild Separator) which default is use Space/Tabs. if you want columns split on different character, you can redefine it with the \"-F\" option for \"awk\" like in: .  or within \"BEGIN{...}\" block like with \"FS\": .  for example for a input file like below (now it's comma instead of space): .  you can write your \"awk\" code as following: .  Or within \"BEGIN\" block: .   Going a little bit complex and to sum all N columns of your input file on the following sample: .   So we talked about \"NF\" in first paragraph (NF value is telling you how many columns do you have (update per each line)): .  the only new things here is we used \"awk\" array to address the same column Id taking from the value of \"i\" and add their values \"$i\" into that array (index/keys of this array is column Ids); then at the \"END{...}\" block we loop over our array on the keys it's seen then print the column Id first then sum of those next to it, you will see output like below: .  ",
      "P-tags": "awk text-process",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP of NP by NP"
    },
    {
      "id": "so_34569626",
      "task": "Prism: How to load Default View in Shell Region with Unity Bootstrapper",
      "P-task": "prism : load default view shell region uniti bootstrapp",
      "F_verb": "load",
      "P-body": "Assuming you have a CreateModuleCatalog override in your bootstrapper, you use it to add a module to the catalog. .  In the YourModule Initiaize override, register the view you want displayed like below. .  Using view discovery: .  OR .  Using view injection (if you want a little more control, or need a scoped region, etc.): .  This injection method needs you have to a reference to the region manager, and you have registered the view with the Unity container, and you have a reference to the container .  As long as the YourRegion region is in your Shell xaml, and is visible at runtime, the YourView will show in it. .  The Hello World quick start shows this too, and uses the Unity container. .  https://github.com/PrismLibrary/Prism-Samples-Wpf/tree/master/HelloWorld .  ",
      "P-tags": "prism c prism-6 wpf shell",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "su_1689558",
      "task": "how to reinstall bash on Mac High Sierra (10.13.6) The current bash just does not work",
      "P-task": "reinstal bash mac high sierra 10 13 6 current bash work",
      "F_verb": "reinstall",
      "P-body": "I checked my .bash_profile on Mac and there was a syntax error that was corrupting the whole thing. From .  To .  The PATH value now begins with a double quote and ends with a double quote as well, whereas earlier, it ended with the single quote. .  ",
      "P-tags": "macos-highsierra bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "au_746009",
      "task": "How do I compare two files containing several md5 checksums to determine changed files?",
      "P-task": "compar two file contain sever md5 checksum determin chang file",
      "F_verb": "compare",
      "P-body": " I want to know if this can be done using \"md5sum --check\"? (since it normally checks for any changes in only 1 MD5 file). .   No, it can't. .  \"md5sum --check\" is meant to read the path to each file in the second column of the input files and check their MD5 checksum agains the checksum reported on the first column; if you want to directly compare the checksums in the two files, you'll have to compare the text files. .  Using \"paste\" + AWK you could do: .   \"paste file1 file2\": joins line N of \"file1\" on line N of \"file2\"; \"awk '{x = $1 == $3 ? \"OK\" : \"FALSE\"; print $2\" \"x}'\": if the first field is equal to the third field (i.e. the MD5 sums match), assigns \"OK\" to \"x\", otherwise assigns \"FALSE\" to \"x\" and prints the second field (i.e. the filename) followed by the value of \"x\".  ",
      "P-tags": "md5sum command-lin text-process",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_97369",
      "task": "Editing Spec file in RPM",
      "P-task": "edit spec file rpm",
      "F_verb": "edit",
      "P-body": "I have found the solution. The problem was my Provides are in the wrong area. It is suppose to be at the top of the code. .  To verify this. I have used \"rpm -qp --provides mysoftware.rpm\" inside the built folder. It will display what are provided from my packages.Thanks for all the help. .  ",
      "P-tags": "depend rpm",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_14539525",
      "task": "how to run asmx webservice on ubuntu/linux?",
      "P-task": "run asmx webservic ubuntu linux",
      "F_verb": "run",
      "P-body": " 1) is it possible (im guessing yes) to load that asmx(lets call it a file) to run on ubuntu? .   Yes, you could use \"Mono\". .   2) what are the best tools/frameworks to deploy asmx webservice on ubuntu? .   Hard to talk about best tools or frameworks. But you could \"run ASP.NET application on Apache\". .   3) is there a reason why i should not do that, and deploy it on a windows based server instead? (like performance, ease of use etc) .   Yes, the native home of .NET applications is Windows. Mono can only follow the evolution and new features that get introduced in the .NET framework on Windows. .  ",
      "P-tags": "linux c ubuntu web-servic asmx",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_65715415",
      "task": "Path in .bash_profile give error: \"-bash: flutter: command not found\"",
      "P-task": "path bash_profil give error : -bash : flutter : command found",
      "F_verb": "give",
      "P-body": "I have faced the same issue. I assume that you've downloaded the flutter SDK from official docs as I did and tried so many solutions. .  I resolved this issue with the following steps: .   download the Android Studio Open Android studio's preferences -> Plugins -> download flutter plugin File -> New -> Create New Flutter project In the next dialogue under the \"Flutter SDK path\" you can see install SDK... option (install the SDK from there at your desired location) Once SDK is installed then update your .bash_profile with the newly downloaded SDK.  Your .bash_profile should look something like this: .  \"export PATH=\"$PATH:$HOME/Developer/flutter/bin\"\" .    .  ",
      "P-tags": "android flutter maco bash",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_33077547",
      "task": "How can I join the result of `ls` as a char separated string in PowerShell?",
      "P-task": "join result ls char separ string powershel",
      "F_verb": "join",
      "P-body": "You can use the \"-join\" operator: .  If you need more control about the individual items being joined here, just amend the pipeline appropriately: .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "ul_610699",
      "task": "run for loop with bash command in fish shell",
      "P-task": "run loop bash command fish shell",
      "F_verb": "run",
      "P-body": "Fish is not bash compatible, but uses its own scripting language. .  In this case the only differences are .   it doesn't support backticks (```), instead it uses parentheses. for-loops don't use do/done, instead they just end in \"end\"  \"for acc in (cat uniprot_ids.txt); curl -s \"https://www.uniprot.org/uniprot/$acc.fasta\" ; end > uniprot_seqs.fasta\" .  Also command substitutions only split on newlines, not newlines/spaces/tabs, but I'm betting this has entries on lines anyway. If not, you need to use \"string split\". .  ",
      "P-tags": "fish shell-script bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "au_456908",
      "task": "How to pass string variable as parameter to awk",
      "P-task": "pass string variabl paramet awk",
      "F_verb": "pass",
      "P-body": "To use bash variables inside your awk, you have to use the \"-v\" syntax like this: .  Example ",
      "P-tags": "awk script command-lin",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP as NP to NP"
    },
    {
      "id": "au_879350",
      "task": "awk: unknown option -w ignored",
      "P-task": "awk : unknown option -w ignor",
      "F_verb": "ignore",
      "P-body": "\"-W\" is a mawk option, and you maybe using gawk (GNU awk). Run the command with \"mawk -W ...\". \"mawk\" is installed by default, but if \"gawk\" is installed, it becomes the default \"awk\". .  ",
      "P-tags": "awk command-lin",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "su_10997",
      "task": "Find what package a file belongs to in Ubuntu/Debian?",
      "P-task": "find packag file belong ubuntu debian",
      "F_verb": "find",
      "P-body": " or .   .  To install \"apt-file\", use: .  You will need to update its database before you can use it: .  ",
      "P-tags": "dpkg aptitud ubuntu debian package-manag",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V what S"
    },
    {
      "id": "so_1766275",
      "task": "How to obtain the PIDL of an IShellFolder",
      "P-task": "obtain pidl ishellfold",
      "F_verb": "obtain",
      "P-body": "I found that you can query an IShellFolder for its IPersistFolder2, which has GetCurFolder(), which returns its absolute PIDL. I could then simply use the IShellFolder for the desktop to CompareIDs() to determine if they're equal. I found the outlines of this while looking at SHGetIDListFromObject. I couldn't just use that function, because its Vista, and I need XP compatibility. .  Here's a sketch of how it works (assuming you have an ifolder_desktop, and ifolder_other, which are IShellFolder pointers. Pidl is a simple helper that ensures that the IDLISTs are deallocated properly): .  In case anyone is interested in my simple Pidl class: .  ",
      "P-tags": "windows-shel c++ com winapi",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_532182",
      "task": "Network Manager unable to connect to network (Debian 10 / Kernel 4.19)",
      "P-task": "network manag unabl connect network debian 10 kernel 4 19",
      "F_verb": "connect",
      "P-body": "Your integrated Intel NIC most likely supports Energy Efficient Ethernet (EEE): if a link is inactive for a while, it will drop to a lower speed level until there is traffic again. This is mostly important for gigabit links, but according to the messages, the interface is negotiating only a 100Mbps link, so perhaps the other end of the link does not support gigabit speeds and EEE.  .  Or if the other end should definitely be gigabit-capable, then the fact that only a 100Mbps link is being negotiated indicates that the remote end might be getting confused by rapid switches between 100Mbps and gigabit modes caused by EEE. An unexpected or too slow switch from one mode to another might cause NetworkManager's \"carrier-changed\" state. .  So you might try switching EEE off: .  Or it might be similar to this bug: what does this command say? .  If it says \"auto\", try this: .  That tells the kernel to keep the PCIe side of the network interface powered up, instead of possibly powering it down whenever the NIC seems to be not configured for use. .  Worst case, it might be a hardware compatibility issue between the NIC in your new motherboard and whatever is at the other end of the network cable. I once had a 8-port DLink 10/100Mbps switch that refused to work with some new gigabit NICs. .  ",
      "P-tags": "networkmanag ethernet linux network debian",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_52532709",
      "task": "Treat tmpfs as a device for grep",
      "P-task": "treat tmpf devic grep",
      "F_verb": "treat",
      "P-body": "Although I haven't found a way how to treat \"tmpfs\" as a device, there is a way for solving my taks described above (may be useful sor someone). .  We will treat a file as a device. The algorithm is as follows: .   Create an empty file with specified size: .   Create a filesystem inside that file: .   Now we are able to create a device from that file and mount it as an ordinary disk: .   That's all. We're able to treat the file as a device. Create/delete arbitrary files/directories inside it. And \"grep\" through \"/dev/loop0\" works as expected, w/o processing entire physical storage device, crawling inside the \"storage_file\" only. .    ",
      "P-tags": "linux grep tmpf",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP as NP for NP"
    },
    {
      "id": "so_30013743",
      "task": "source: not found error while running shell script on ubuntu 14.04",
      "P-task": "sourc : found error run shell script ubuntu 14 04",
      "F_verb": "find",
      "P-body": "You need to run it with: .  not \"sh parser.sh\". .  If your script is written for \"bash\", you shouldn't try to execute it with \"sh\". Every syntax of your script may not meet the standards of \"sh\" Bourne shell. .  Change the cron job command to: .  to specify \"bash\" exclusively. Or as your OS is Ubuntu 14.04, you generally don't need to specify bash, i.e .  should work just fine. .  ",
      "P-tags": "sh ubuntu-14 04 cron bash django",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP while S_ING on NP"
    },
    {
      "id": "ul_237250",
      "task": "How can I open all urls in my browser with xdg-open?",
      "P-task": "open url browser xdg-open",
      "F_verb": "open",
      "P-body": "I've managed to fix this by going to \"System Settings -> Applications -> Web Browser\" and setting parameter \"Open http and https URLs\" to \"in the following browser -> firefox\"  .  This works with KDE 5, but should work similar in previous versions. .  ",
      "P-tags": "plasma xdg-open kde",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_59444878",
      "task": "Checking if strings in one file occur in another set of files, list those that don't",
      "P-task": "check string one file occur anoth set file list",
      "F_verb": "occur",
      "P-body": "Since you make use of \"fgrep\", which is synonymous to \"grep -F\" we know that the pattern file are fixed strings. To find which patters did not match, you use the following method: .  In case of the OP, this becomes: .  You can also do this with awk in a single go: .  The above works for exact matches, so no need to have the extra spaces. If you want to keep the extra spaces, it is a bit more tricky: .  All the above will print the VLAN-File entries that do not appear in the MAC-File .  ",
      "P-tags": "grep shell bash",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V in NP of NP"
    },
    {
      "id": "so_23510512",
      "task": "Simplify Get-Messagetrackinglog with a new function including MB Conversion",
      "P-task": "simplifi get-messagetrackinglog new function includ mb convers",
      "F_verb": "get",
      "P-body": "What do you think about this? .  ",
      "P-tags": "powershel exchange-serv powershell-2 0 exchange-server-2010",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "su_844769",
      "task": "How to git pull without asking password?",
      "P-task": "git pull without ask password",
      "F_verb": "ask",
      "P-body": "From the \"git@dev01\", I'm guessing that you are pulling over SSH. Therefore you can use the same methods as for general passwordless SSH \u2013 specifically, public-key authentication. How to set it up has been described in great detail across many websites and tutorials, but here's the short summary: .   On the client, create a keypair using \"ssh-agent\" or PuTTYgen. .  (In this case, \"root@dev02\" is the client, and \"git@dev01\" is the server.) .  Copy the public key to the server, into the \"~/.ssh/authorized_keys\" file. .  (Copy it from the \"~/.ssh/id_rsa.pub\" file, or the \"OpenSSH Public Key\" text from PuTTYgen.) .  Run \"ssh -v user@server\" and make sure it shows the key being used: .    ",
      "P-tags": "linux ssh bash git password",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP"
    },
    {
      "id": "au_1162691",
      "task": "Allow only predefined devices to connect to my device via IP tables",
      "P-task": "allow predefin devic connect devic via ip tabl",
      "F_verb": "allow",
      "P-body": "Got the result in following way(make sure proper IP addresses and ports are filled up in \"ip.txt\" file): .  First make everything connectable to avoid losing existing connections by running the following 3 commands on terminal: .  Then, flush all the existing IP tables settings: .  Finally run the script that blocks all the connections and then enables only the IPs those are mentioned in \"IP.txt\" file (sample of this file at the end): .  Sample IP.txt file: .  ",
      "P-tags": "iptabl",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP S_INF to NP via NP"
    },
    {
      "id": "so_22418668",
      "task": "Can't install package reshape2 for R 2.15.3 on Ubuntu 12.04.4",
      "P-task": "instal packag reshape2 r 2 15 3 ubuntu 12 04 4",
      "F_verb": "install",
      "P-body": "A few things: .   You insist on Ubuntu 12.04 LTS. A stable distribution. That is fine. Your choice. It also means you chose to freeze your software at a point a few months before April 2012. .  Now you want something from CRAN. Something current. That is in conflict with the previous point. .  Either you stay in distro. Or you become current. .  Read the Ubuntu README and learn to how to stay with Ubuntu 12.04 yet at the same time get a current R package. .  Install R 3.0.3 (current) via that repo. .  Install the CRAN packages you want into \"/usr/local/lib/R/site-library\". .   ",
      "P-tags": "ubuntu-12 04 rcpp r reshape2 plyr",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "so_63770819",
      "task": "When signal handler is not called when segment fault occurs?",
      "P-task": "signal handler call segment fault occur",
      "F_verb": "call",
      "P-body": "A well-formed, well-defined C++ application will never result in a segfault. .  A segfault is a result of undefined behavior; but when undefined behavior occurs, by definition you can not expect any specific result or behavior. You have no expectation that a seg fault will occur as a result of undefined behavior, and even if occurs you cannot expect that the \"SIGSEGV\" handler will produce any expected result, at all. .  The number of examples that can be given has no limit. Let's say, for example, the segfault handler attempts to remove a temporary file that gets created before the segfault. Too bad, the undefined behavior resulted in corrupting the buffer that stored the name of the temporary file, in addition to causing a segfault. The segfault handler fails. Or, even better, the corrupted filename buffer happened to match the name of another file, and it gets deleted by mistake. If you were running as root, and the corrupted filename buffer by chance ended up containing \"/bin/bash\", you've just turned your machine into an unbootable brick. .  Many other possibilities can also happen, limited only to one's imagination. You did not describe what your sigsegv handler attempts to do, but it doesn't matter. Whatever it tries to do it has no guarantee of always working. It is too late, by the time it gets invoked undefined behavior already happened, and you have no expectation of anything happening, from that point on. .  So, whatever the segfault handler attempts to do, it has no guarantee, whatsoever that it can accomplish its task. By the time the segfault handler gets invoked the state of the rest of the program, and its data, is undefined and unspecified. .  Which is why when there's a bug that results in a segfault, the correct way to handle it is to figure out the reason for the segfault, find the bug and fix it. Any attempt to remedy the situation by catching the signal and the cleaning up is, at best, a crapshoot has no guarantee of always succeeding. .  ",
      "P-tags": "embedded-linux linux linux-kernel c++ c",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V when S"
    },
    {
      "id": "so_2732484",
      "task": "How can I get read-ahead bytes?",
      "P-task": "get read-ahead byte",
      "F_verb": "get",
      "P-body": "You can indeed use your second method, at least on Linux. \"mmap()\" the file, then use the \"mincore()\" function to determine which pages are resident. From the man page: .   \"int mincore(void *addr, size_t length, unsigned char *vec);\" .  \"mincore()\" returns a vector that indicates whether pages of the calling process's virtual memory are resident in core (RAM), and so will not cause a disk access (page fault) if referenced. The kernel returns residency information about the pages starting at the address \"addr\", and continuing for \"length\" bytes. .   There's of course a race condition here - \"mincore()\" can tell you that a page is resident, but it might then be swapped out just before you access it. C'est la vie. .  ",
      "P-tags": "operating-system virtual-memori linux pagefil window",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_91488",
      "task": "Allow a user to read some other users' home directories",
      "P-task": "allow user read user home directori",
      "F_verb": "allow",
      "P-body": "If the users are cooperative, you can use access control lists (ACL). Set an ACL on the home directory of \"user1\" (and friends) that grants read access to \"superuser\". Set the default ACL as well, for newly created files, and also the ACL on existing files. .  \"user1\" can change the ACL on his files if he wishes. .  If you want to always give \"superuser\" read access to \"user1\"'s files, you can create another view of the users' home directories with different permissions, with bindfs.  .  Files accessed through ~superuser/spyglass/user1 are world-readable. Other than the permissions, \"~superuser/spyglass/user1\" is a view of \"user1\"'s home directory. Since \"superuser\" is the only user who can access \"~superuser/spyglass\", only \"superuser\" can benefit from this. .  ",
      "P-tags": "linux permiss",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_7960258",
      "task": "Bash - How to put variable in command?",
      "P-task": "bash - put variabl command",
      "F_verb": "put",
      "P-body": " You don't need to use backticks if you're not capturing the output of the command. Just run the command. If you're putting the output to devnull, you don't need to append (\">>\"), just write (\">\").  That should work. If it's not working, something else is wrong.  .    ",
      "P-tags": "variabl command script bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_1093410",
      "task": "Pulling MX record from DNS server",
      "P-task": "pull mx record dn server",
      "F_verb": "pull",
      "P-body": "The simplest method is to simply use commonly available tools. .  The basic \"dig\" command will return the records to you via this query: .  If you want just the lines with the mx records... .  dig is available on most linux / unix boxes. .  If you're on windows you can use nslookup .  Then just parse the output of these common tools. .  EDIT: Simple C example of sockets from the web Since you put \"C\" as a tag, I guess you're looking for source code to do MX lookups using raw sockets. I copied this from http://www.developerweb.net/forum/showthread.php?t=3550. It may be more what you're looking for? .  ",
      "P-tags": "linux mx-record c dn",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_69080883",
      "task": "Getting prompted with a GitHub Login Interface whenever I try to push to repo",
      "P-task": "get prompt github login interfac whenev tri push repo",
      "F_verb": "push",
      "P-body": "Support for password authentication was removed on August 13, 2021 for security reasons by the developers. They recommend to use a personal access token instead. .  To create a token: .   From your GitHub account > profile picture > settings Developer settings from the left sidebar > Personal Access Tokens Generate new token.  To use the token: .  Replace your password with the token when prompted to login/authenticate. Note: PAT doesn't work with UI, but it does from cmd prompt .  To cache your credentials and stop the prompt appearing every time you commit: .  Follow the prompts > set HTTPS as the preferred protocol > paste PAT in the very last step. .  Now you're hooked and ready to go .  Links: https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ .  https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token .  https://docs.github.com/en/get-started/getting-started-with-git/caching-your-github-credentials-in-git .  https://cli.github.com/manual/gh_auth_login .  ",
      "P-tags": "git-credential-manag github github-cli git-bash git",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V to NP"
    },
    {
      "id": "au_664031",
      "task": "how to export folder specific environment variables?",
      "P-task": "export folder specif environ variabl",
      "F_verb": "export",
      "P-body": "If using the bash shell, add to your .bash_profile: .  Then when you type \"cd ...\" it will run \"mycd\" in which you can do stuff. It starts by calling the real built-in cd. .  You need to start a new interactive bash to see the effect, of course. .  ",
      "P-tags": "java environment-vari command-lin",
      "source": "qa",
      "cate": "export",
      "pat": "V NP"
    },
    {
      "id": "so_27261378",
      "task": "How might I pass text data from the ruby console into my clipboard without saving to a file?",
      "P-task": "might pass text data rubi consol clipboard without save file",
      "F_verb": "save",
      "P-body": "You can just echo it instead if there are no newline characters in the string; otherwise, use the \"IO\" class. .  Using \"echo\": .  OR .  Ruby will then just rip the text from memory, inject it into the shell command which opens a pipe between the \"echo\" and \"pbcopy\" processes. .  Using the \"IO\" class: .  If you want to do it the Ruby way, we simply create a pipe with \"pbcopy\" using the IO class. This creates a shared files between the processes which we write to, and \"pbcopy\" will read from. .  \"IO.popen(\"pbcopy\", \"w\") { |pipe| pipe.puts \"Hello world!\" }\" .  ",
      "P-tags": "clipboard rubi pbcopi unix",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V to NP"
    },
    {
      "id": "so_53278029",
      "task": "How to transfer existing git repo from local server to gitlab repo, using CLI(Shell script)?",
      "P-task": "transfer exist git repo local server gitlab repo use cli shell script",
      "F_verb": "transfer",
      "P-body": "Save below file by filename.sh - open terminal - goto file saved directory - type \"sh filename.sh\" command and hit enter .  Here all the projects from local server are moved to your GitLab server by using this shell script. .  Edit this script as per requirement. .  ",
      "P-tags": "github command-line-interfac shell git gitlab",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP to NP using NP"
    },
    {
      "id": "so_69253512",
      "task": "replace entire line in file with new line given arguments line number and replacement string with special characters",
      "P-task": "replac entir line file new line given argument line number replac string special charact",
      "F_verb": "replace",
      "P-body": "Try .  this works because: .   You require \"\"\" enclosing the entire sed command instead of backtick so that the variables are expanded No other quotes or backticks are needed to escape \"\"\" in the variables as there aren't any: there are no literal (escaped) quotes inside the variables An alternate separator (such as \"#\") is required due to the \"/\" inside the \"NEWLINE\" variable.  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_7640939",
      "task": "Startup code of a statically-linked executable issues so many system calls?",
      "P-task": "startup code statically-link execut issu mani system call",
      "F_verb": "call",
      "P-body": "\"uname\" is needed to check that the kernel version is not too ancient.  .  Two \"brk\"s are needed to set up thread local storage. Two others are needed to set up dynamic loader path (the executable still might call \"dlopen\", even if it's statically linked). I'm not sure why these come in pairs. .  On system \"arch_prctl\" isn't called, \"set_thread_area\" is called in its place. This sets up TLS for the current thread. .  These things probably could be done lazily (i.e. called when corresponding facilities are used for the first time). But perhaps it would make no sense performance-wise (just a guess). .  By the way \"gdb-7.x\" can stop on system calls with the \"catch syscall\" command. .  ",
      "P-tags": "static-link system-cal linux libc c",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V"
    },
    {
      "id": "so_28438413",
      "task": "Properly Declare a List Collection?",
      "P-task": "properli declar list collect",
      "F_verb": "declare",
      "P-body": " In Powershell, you need to use square brackets \"[...]\" when specifying the type of the list's items: .  Note that this is different from C#, which would use angle brackets \"<...>\". .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_68206007",
      "task": "Creating and saving function in powershell for global use",
      "P-task": "creat save function powershel global use",
      "F_verb": "save",
      "P-body": "If you would like to just have a function that is available for yourself, you can add it to your profile by copying and pasting your function in to the file that is returned by typing \"$PROFILE\" in to PowerShell. You can run \"notepad $PROFILE\" on Windows, \"open $PROFILE\" on MacOS or use your favourite editor on Linux. Your profile is loaded every time you open PowerShell .  If you want the function to be available for more people, then you could go down the route of making it a module, but there is an Amazon PowerShell module already. It is easier if you just have a few functions, to import them in to your session by dot-sourcing them. .  After this, I'm not quite clear on what the issue you're having is. As you seem to be working on Windows, I assume you have followed these steps from the linked document: .  Then you set the options you would like to use with an alias name in the file. Something like: .  Which I assume you should be able to call, as long as the file is formatted correctly with. .  You are getting the parsing error above because I assume the alias file is not configured properly. If you would like help with that, please post the contents of the file created in your user profile. .  If you would like to create a similar effect with PowerShell using the cli tool. You could create a couple of helper functions in your profile or a \".ps1\" file saved for multiple users as discussed above. Although, as I said, there is an existing AWS Module for PowerShell. .  You might want a function that can invoke EC2 commands for you. Here is an untested sample as I do not have aws cli installed. .  Which will act as a base for other things that you want to do with EC2. Then you might want a function that calls the base and allows you to just specify to start some instances. .  You should then be able to start your instances like this. .  ",
      "P-tags": "powershel amazon-web-servic",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP for NP"
    },
    {
      "id": "ul_447517",
      "task": "Is it possible to customize Dconf's file storing path?",
      "P-task": "possibl custom dconf file store path",
      "F_verb": "customize",
      "P-body": "\"man 7 dconf\" explains that the user configuration is saved by default in file \"$XDG_CONFIG_HOME/dconf/user\". Depending on your system, this often means file \"~/.config/dconf/user\" when \"XDG_CONFIG_HOME\" is not defined. .  You should be able to move this directory to the wanted place, and replace it with a symbolic link. Eg .   Alternatively, you can make a bind mount which makes the same directory appear in 2 different places: .  To undo the binding use \"sudo umount ~/Dropbox/dconf\". .  ",
      "P-tags": "dconf configur synchron",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_1052563",
      "task": "Move Ubuntu from one drive with dual boot to a new drive with single boot",
      "P-task": "move ubuntu one drive dual boot new drive singl boot",
      "F_verb": "move",
      "P-body": "The best practice is to clone Ubuntu in such the case - it's pretty simple. .   Create Live CD/USB and load your system from this live drive. Choose Ubuntu version same as your old system, for example, 16.04. Create backups of all important data! .  Install Ubuntu to your new drive - DON'T INVOLVE your old drives into the new installation. During installation create /, /home and swap partitions on new drive like it has been done on you old Ubuntu drive. Reboot your computer at the end of installation and check if new Ubuntu is loading well. .  Load computer from live CD/USB again. Mount your root \"/\" partitions on both old and new drives from terminal or Nautilus. Become root: .  Check CAREFULLY where are your old and new root \"/\" partitions mounted: .  Let's assume your old root \"/\" partition mounted to .  and new old partition available at .   Create in the root's home directory empty plain text file with name \"exclude-list\": .  Edit the newly created file, open it in your favorite text editor - let it be nano for instance: .  Insert into the file the following text: .  Please check carefully the text file for absence of additional spaces - the spaces must be absent everywhere including end of every line! .  If the rsync utility isn't installed in your live system, install it before partition cloning: .   Copy your old root \"/\" partition to the new one using the following command in terminal: .   Reboot your computer and check if everything is right with your cloned Ubuntu. .  Repeat steps 3 and 4 for your \"/home\" partitions or just copy files from old to new \"/home\" partition inside your new installed Ubuntu instead. .   ",
      "P-tags": "partit migrat dual-boot",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP from NP with NP to NP with NP"
    },
    {
      "id": "ul_664311",
      "task": "Current date in cal is not highlighted in recent Debian",
      "P-task": "current date cal highlight recent debian",
      "F_verb": "highlight",
      "P-body": "I believe the correct \"Answer\" to this question is documented here on GitHub .  To quote add .  into your shell rc file. .  This is an extremely irritating change. Changing the behavior of a frequently used cli command for at least 17 years to make it \"correct\" is kind of insane. Now I understand why so many people hate Windows so much but are still reluctant to switch to Linux. I'm pretty sure almost all package maintainer who use \"cal\" (actually I think majority of them uses date anyway) are trained to use \"cal -h\" to turn off the highlight. Now the change even breaks compatibility with \"cal -h\". .  The change is documented here .  A simpler hack to solve the \"no highlight\" is to alias \"cal\" to \"ncal -b\", but it is not 100% correct with the package \"ncal\" maintainer's expectation. .  ",
      "P-tags": "cal linux highlight debian",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V in NP"
    },
    {
      "id": "so_49213477",
      "task": "To convert the extension of a file to the different directory by a ffmpeg command",
      "P-task": "convert extens file differ directori ffmpeg command",
      "F_verb": "convert",
      "P-body": "Simple method is to execute the command from the directory containing the input files: .  Or you could use \"basename\" if you want to put the full path in the for loop: .  ...but it is less efficient than only using parameter expansion: .  Other relevant questions: .   How do you convert an entire directory with ffmpeg? Use ffmpeg to get middle frame of a video? How can I extract a good quality JPEG image from an H264 video file with ffmpeg?  ",
      "P-tags": "ffmpeg plesk centos6 unix",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP to NP by NP"
    },
    {
      "id": "so_34704700",
      "task": "edit-and-execute-command bash with sublime text",
      "P-task": "edit-and-execute-command bash sublim text",
      "F_verb": "edit",
      "P-body": "You should export the EDITOR as: .  as: .   To use Sublime Text as the editor for many commands that prompt for input, set your EDITOR environment variable: .  \"export EDITOR='subl -w'\"  .  Specifying -w will cause the subl command to not exit until the file is >closed. .   Full explanation here .  ",
      "P-tags": "sublimetext3 linux command-lin bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_84676",
      "task": "How is umask calculated in Linux?",
      "P-task": "umask calcul linux",
      "F_verb": "calculate",
      "P-body": "Assume the default mask of 0666. \"umask\" 0022 would make the new mask 0644 (0666-0022=0644) meaning that group and others have read (no write or execute) permissions. .  The \"extra\" digit (the first number = 0), specifies that there are no special modes. .  If mode begins with a digit it will be interpreted as octal otherwise its meant to be symbolic.  .  0 is a digit, as is 1 (for the sticky bit) or 6 (for SGID). A command such as \"chmod\" can be called by other methods, such as \"chmod ug+rw mydir\" where you would add the read and write permissions to user and group. Note that the mode in this case (ug+rw) does not begin with a digit, thus would not be interpretted as octal but rather symbolic.  .  See en.wikipedia.org/wiki/Chmod#Symbolic_examples for symbolics as well as www.lifeaftercoffee.com/2007/03/20/special-permission-modes-in-linux-and-unix/ for a bit on special modes.  .  I don't know that you would unmask the first bit with \"umask\", but technically you could. It would explain why you almost always see it as a zero. .  Credit to pinkfloydx33 .  The first digit of the mask deals with special permissions that don't fit quite so cleanly into the owner/group/other model. When four digits are provided for a file permission, the first refers to those special values: .  The SUID bit, short for set-user-ID, causes an executable program to run with the effective user id (uid) of the owner -- in other words, no matter who executes it, the program executes with the owner's rights. This is commonly seen in programs that do things that require root privileges, but are meant to be run by normal users: \"passwd\" is one such example. .  The SGID bit, short for set-group-ID, is very similar, but runs with the effective group id (gid) of the owner. .  The sticky bit is a little more complicated, if you want more information on that, you can read the manpage for \"sticky\". .  These bits can also be used with directories, but their meanings change. .  I don't believe you can actually set the \"umask\" to allow you to enable any of these extra bits by default, but you probably would never want to do that anyways. .  Credit to user470379 .  ",
      "P-tags": "umask",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V in NP"
    },
    {
      "id": "so_41104726",
      "task": "Invoke-Command Cannot Bind Argument Error",
      "P-task": "invoke-command bind argument error",
      "F_verb": "invoke",
      "P-body": "I have modified the code and now its working fine. The issue what you are facing is because inside the script block , $svc is not holding any value because its not in the scope even. To make it within the scope you have to pass as an ArgumentList and it has to be initiated inside the block as param. Thats why ou are getting as Null .  Use the below code. I just modified the Invoke part .  Hope you understand the issue now. .  ",
      "P-tags": "powershel invoke-command",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V"
    },
    {
      "id": "so_25706767",
      "task": "bash script duplicating i/o using a file descriptor like it were tee",
      "P-task": "bash script duplic use file descriptor like tee",
      "F_verb": "duplicate",
      "P-body": " I would like every command in my script to print stdout to /dev/ps/9 and ./myscript.stdout at the same time. .   The above combines redirection and process substitution. With redirection alone, one can send stdout to a file. For example: .  However, with bash, filenames can often be replaced with commands. This is called process substitution and it looks like \">(some command)\" or \"<(some command)\" depending on whether one wants to write-to or read-from the process. In our case, we want to write to a \"tee\" command. Thus: .  Or, more specifically: .  Note that we have to maintain the space between the redirect (\"1>\") and the process substitution (\">(tee ./myscript.stdout >/dev/ps/9)\". Without the space, it would look like we were trying to append to a file whose name starts with a parens and this would generate a \"bash\" error. .  For more information on this see the sections entitled \"REDIRECTION\" and \"Process Substitution\" in \"man bash\". .  ",
      "P-tags": "bash io tee file-descriptor log",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_81863",
      "task": "how to copy and rename files with \":\" and incrementing number in the filename",
      "P-task": "copi renam file : increment number filenam",
      "F_verb": "rename",
      "P-body": "Not sure if I understand your question right, but in Bash this could work: .  That would copy \"ifcfg-eth1:22\" through \"ifcfg-eth1:99\" to \"ifcfg-eth1:122\" through \"ifcfg-eth1:199\". .  I'm not sure why you would use such files. If this is about ethX:Y aliases, you no longer need them. You can just \"ip addr add\" to the main interface. So maybe you should take a step back and ask a question about the problem you're actually trying to solve. .  ",
      "P-tags": "renam filenam",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_389678",
      "task": "In directory how can find files and apply md5sum of all files at same time?",
      "P-task": "directori find file appli md5sum file time",
      "F_verb": "find",
      "P-body": " ",
      "P-tags": "hashsum linux",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP at NP"
    },
    {
      "id": "so_27764543",
      "task": "Read a file using two processes in linux?",
      "P-task": "read file use two process linux",
      "F_verb": "read",
      "P-body": "Finally it works Just i need to add fflush() after each in and out as. .  ",
      "P-tags": "linux file c++ signal file-io",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP using NP in NP"
    },
    {
      "id": "ul_611370",
      "task": "Libtool searches wrong directory while path specified",
      "P-task": "libtool search wrong directori path specifi",
      "F_verb": "specify",
      "P-body": "One of the dependencies (proj) linked in its .la file to the malicious sqlite3 version. Reinstalling this dependency solved the issue. .  What would help in similar cases would be to search the 'wrong path' in the dependencies: .  \"find <deps lib dir> -type f -exec grep -l \"<wrong path>\" {} +\" .  Kudos go to https://stackoverflow.com/a/62500481/14339502 who stated the valuable hint that \"it seems like you have some other .la file that references it\". .  ",
      "P-tags": "sqlite libtool compil make",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V"
    },
    {
      "id": "so_69916879",
      "task": "I have two huge sequencefiles where i want to extract the same linenumbers from file1 in file2",
      "P-task": "two huge sequencefil want extract linenumb file1 file2",
      "F_verb": "extract",
      "P-body": "If I understand the question - file 1 has a list of \"line numbers\" and you desire to print those lines in file2: .  ",
      "P-tags": "awk for-loop linux shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_52675315",
      "task": "How to change Install Dir when Building OpenCV 3.1.0 on Ubuntu 18.04 for Android NDK18rc and ARMEABI-7?",
      "P-task": "chang instal dir build opencv 3 1 0 ubuntu 18 04 android ndk18rc armeabi-7",
      "F_verb": "change",
      "P-body": "I have managed to get it to work, basically, OCV didn't support NDKr18, and I also had to install ninja from source. I have also used python3 instead of python2 to run the opencv/platforms/android/build_sdk.py . One more thing is that I use Eclipse Android ADT which Google has for no reason deprecated ;(, but I find it super fast compared to the heavy Android Studio. .  ",
      "P-tags": "android-ndk ubuntu-18 04 opencv3 0 cmake opencv4android",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP when S_ING on NP for NP"
    },
    {
      "id": "so_595002",
      "task": "How do you execute a command on a remote system insde a BASH script?",
      "P-task": "execut command remot system insd bash script",
      "F_verb": "execute",
      "P-body": "Following Tim Post's answer: .  Setup public keys and then you can do the following: .  ",
      "P-tags": "script remote-execut unix bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP inside NP"
    },
    {
      "id": "ul_515846",
      "task": "Who initializes the address_space data structure?",
      "P-task": "initi address_spac data structur",
      "F_verb": "initialize",
      "P-body": "linux-5.0/source/fs/inode.c:123 .  ",
      "P-tags": "c linux-kernel",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP"
    },
    {
      "id": "au_300509",
      "task": "How to replace /lib/modules in chroot?",
      "P-task": "replac lib modul chroot",
      "F_verb": "replace",
      "P-body": "I booted into the live system, logged into a root shell, logged into root .  I mounted my filesystem:  .  then I mounted sys, proc, dev, & dev/ptsL .  then I chroot'd:  .  after that I made sure that any modules I had moved over were removed, because I was finally able to copy my modules that were backed up on my external, and the modules from the live system into my filesystem, and they didn't completely work, all they did was fix the problem mounting my other filesystems and some USB acccess. So to do this I used: .  then I made sure my internet connection was still good:  .  then, after verifying that I could access the internet, I ran some updates because every few days updates come out, and my filesystem checked my kernel to see if I needed to update anything and I was able to re-install my modules this way. I ran: .  After all this, I used \"ls\" to check and see if my modules were back and indeed they were, in \"/lib/modules\". I rebooted the computer, and everything worked perfectly. .  Thanks the wonderful person that helped me, over at ubuntuforums.org .  ",
      "P-tags": "driver chroot",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "au_974769",
      "task": "Suspicious ethernet \"connection established\" despite not being plugged in",
      "P-task": "suspici ethernet connect establish despit plug",
      "F_verb": "establish",
      "P-body": "\"enp0s25\" is a network interface on your computer (an ethernet port). .  You were given a 169.254.0.0/16 IP address, which is known as a link-local address. This will usually happen when a network interface is \"activated\" but doesn't have a static IP and can't get a dynamic IP from the network. .  I'd believe the most likely culprit is your driver (accidentally) thinking it was connected, or some script/similar tried to activate your network port with nothing plugged in. The connection itself is normally perfectly harmless, and deleting it seemed to take care of your issue. .  If you're worried still, check your Ethernet port to make sure someone didn't plug anything in. It might even just need a bit of cleaning. .  ",
      "P-tags": "ethernet network",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V S_ING in"
    },
    {
      "id": "ul_48534",
      "task": "How to adjust charging thresholds of laptop battery?",
      "P-task": "adjust charg threshold laptop batteri",
      "F_verb": "adjust",
      "P-body": "You need to install \"tp_smapi-dkms\", just do .  \"apt-get install tp_smapi-dkms\" .  When finished, use \"lsmod | grep tp_smapi\" to check if module is loaded, to adjust the charge thresholds, do something like this .  Add these lines to \"/etc/rc.local\" to run them at boot. .  This module works at least on X220. .  ",
      "P-tags": "batteri linux ubuntu power-manag thinkpad",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_651198",
      "task": "Podman volume mounts: When to use the :z or :Z suffix?",
      "P-task": "podman volum mount : use : z : z suffix",
      "F_verb": "mount",
      "P-body": "\u201cShared\u201d means that multiple containers can share the volume; \u201cunshared\u201d says that they can\u2019t. In a little more detail, \":z\" labels the volume inside each container with the appropriate label (\"container_file_t\"), and any given volume can be mounted inside multiple containers in parallel, and all running containers with the volume mount will have access to it. Any change made by the host, or any running container, will be visible to all running containers. .  \u201cPrivate\u201d means that in addition, the label used inside the container will be private to that container. There\u2019s no additional layering at the file system level, so this effectively means that the content is labelled privately even from the host\u2019s perspective. Containers with the same mount can\u2019t share their access to it \u2014 at least with Podman, the last container wins, and is the only container with access to the volume. The opposite of \u201cprivate\u201d here would be \u201cshared\u201d in my mind, which would explain why there\u2019s no opposing term in the documentation (\u201cshared shared label\u201d). .  I\u2019m not sure there\u2019s any significance in \u201ccontent label\u201d v. \u201clabel\u201d, unless it\u2019s an allusion to the fact that any content created in such containers will be labelled accordingly, including in the host, so you\u2019ll see files with the \"container_file_t\" label. .  See this post demonstrating the difference in more detail on Podman. Docker has the same distinction. .  ",
      "P-tags": "contain podman selinux docker",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V when S_INF"
    },
    {
      "id": "so_58340935",
      "task": "How to fix @{DisplayName=Firstname Lastname}",
      "P-task": "fix displaynam firstnam lastnam",
      "F_verb": "fix",
      "P-body": "You are passing an object type with properties to a parameter (\"-Identity\") that expects just a value. As a result, PowerShell converts that object into a string, which results in the value \"@{DisplayName=Firstname Lastname}\". If you access the \"DisplayName\" property before passing it into the \"-Identity\" parameter, your issue will be resolved. .  You can replicate a similar behavior by typing the following at the console: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_19002",
      "task": "Determine if the current user has write permission in a directory",
      "P-task": "determin current user write permiss directori",
      "F_verb": "determine",
      "P-body": "I suppose  .  should do what you want. .  Also, \"stat -c %U ~/foo\" is a better way to obtain the owner than parsing \"ls\" output. .  ",
      "P-tags": "permiss shell",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_61728249",
      "task": "Powershell - Get last modified file's parent directory name",
      "P-task": "powershel - get last modifi file parent directori name",
      "F_verb": "get",
      "P-body": "You can do this using \"Get-ChildItem\", filter for '*.log' files and recurse through the root folder where the subfolders are. .  Then sort on the files LastWriteTime property, select the newest one and take the folder name from that: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "su_870510",
      "task": "Run ifconfig without sudo",
      "P-task": "run ifconfig without sudo",
      "F_verb": "run",
      "P-body": "If any non root user would be trusted to do so, you can merely add a setuid flag on ifconfig exec:  .  It will grant root privilege for execution of this executable to anyone. Of course, you need to have root access to run the chmod. .  ",
      "P-tags": "ifconfig linux embed sudo busybox",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without NP"
    },
    {
      "id": "so_29981055",
      "task": "Can mmap pass the address through a function?",
      "P-task": "mmap pass address though function",
      "F_verb": "pass",
      "P-body": "Yes. .  And the only thing that I can see that you've done wrong is you've used \"*data=\" to assign the result to \"data\". \"*data = something\" does not assign the variable \"data\", but rather assigns the thing \"data\" points to (i.e. \"*data\"). Since \"data\" was never set to point to anything in particular, you don't know what you're assigning to, which is bad. .  To assign the variable \"data\" to the result of calling the function, you'd use \"data = memory(fd, 64, 0)\" - just the same as if \"data\" was an \"int\" or any other type. .  ",
      "P-tags": "c ubuntu beagleboneblack",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP through NP"
    },
    {
      "id": "so_41864322",
      "task": "Merge files with same name in different folders",
      "P-task": "merg file name differ folder",
      "F_verb": "merge",
      "P-body": "Your code looks quite OK. It is giving warnings because you are trying to merge directories as well! You can add a check to skip over directories, like the code below: .  It's important to quote the variables above to prevent word splitting. .  ",
      "P-tags": "linux while-loop cat",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_577161",
      "task": "How to find which program is executing given program?",
      "P-task": "find program execut given program",
      "F_verb": "find",
      "P-body": "On Linux you can get a PID of the parent process from \"$PPID\" variable or /proc/pid/status. Parent process is not always a calling process in case of daemons for examples but it usually is. That being said, you can convert every program into a wrapper that will first log PID of its parent process to a file and then execute an original binary. I don't use sxkhd but as you use X11 let's use xeyes as an example. Create \"xeyes\" script with the following contents and make it executable: .  Now rename an original xeyes binary to xeyes.orig: .  Replace original \"xeyes\" with a script wrapper: .  Call \"xeyes\" normally: .  Now every time you run xeyes PID of its parent process will be appended to /tmp/XEYES_RUN. If you start it from the command line it will be PID of your shell, for example /bin/bash. .  ",
      "P-tags": "strace debug i3 process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V which S"
    },
    {
      "id": "su_152514",
      "task": "Killing all processes of current user",
      "P-task": "kill process current user",
      "F_verb": "kill",
      "P-body": "No. \"killall\" first lists all processes that are to be killed, and then iterates through that list and kills them. If you have a forkbomb running, after \"killall\" will kill one of its processes, it is very likely that another process will immediately reclaim PID which has just freed, but \"killall\" thinks it already killed that process, so effectively nothing will happen. .  You should use ulimit if a forkbomb is a problem for you. Limit number of processes to, for example, 128, and a forkbomb will silently die or stop expanding, depending on how it was written. Anyway, it will not present any danger to other users of that system. .  ",
      "P-tags": "linux process kill",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP of NP"
    },
    {
      "id": "so_56506060",
      "task": "How to unzip all zip folders in my subdirectories?",
      "P-task": "unzip zip folder subdirectori",
      "F_verb": "unzip",
      "P-body": "Try: .  This runs \"unzip\" on each zip file found by your \"find\" command. .  The above will work even if the zip files or directories have spaces or other difficult characters in their names. .  ",
      "P-tags": "termin linux zip bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP in NP"
    },
    {
      "id": "au_962812",
      "task": "I'm using LAME to convert .wav files to .mp3 how I can append the passed arguments in terminal to output .mp3 name?",
      "P-task": "use lame convert wav file mp3 append pass argument termin output mp3 name",
      "F_verb": "convert",
      "P-body": "Original version I suggest that you use a shellscript. .   Use for example the name \"wav2mp3\" .  Store the command line and all other relevant information in the shellscript. .  I suggest that you avoid characters with a special meaning (space \"[\" and \"]\") in the file name, replace with \"_\" .   Make it executable .   Run it (it is 'only' echoing here, showing what the real thing would look like), .    Version with a parameter If the b-value is the only option, you want to change, you can have that as the only parameter, when you call wav2mp3. .  Examples: .  Version with arbitrary number of parameters Example: .  ",
      "P-tags": "mp3 command-lin lame 16 04 bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_54017214",
      "task": "Parse delimited string using awk and fetch the matched string",
      "P-task": "pars delimit string use awk fetch match string",
      "F_verb": "fetch",
      "P-body": "With simple \"awk\" solution: .  or .  ",
      "P-tags": "awk sed unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_475649",
      "task": "Find and remove audio files which has less than 3 minutes of play duration",
      "P-task": "find remov audio file less 3 minut play durat",
      "F_verb": "find",
      "P-body": "Here's one way. Run \"mediainfo\" against every mp3 file, if shorter than 3 minutes, delete it. .  Or for fans of one-liners: .  ",
      "P-tags": "audio linux find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP which S"
    },
    {
      "id": "so_45241855",
      "task": "ubuntu create a tensorflow worker node",
      "P-task": "ubuntu creat tensorflow worker node",
      "F_verb": "create",
      "P-body": "I think you missed the content at bottom of the page on how to run tensorflow as parameter server or workers, here are two parameter servers and two workers. The job_name says whether it's a parameter server or worker and the task_index tells the index of the machine in that group: .  ",
      "P-tags": "cluster-comput ubuntu tensorflow distributed-comput",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_47333864",
      "task": "Connecting to Sybase using sqsh",
      "P-task": "connect sybas use sqsh",
      "F_verb": "connect",
      "P-body": "I'm on Linux and I use sqsh like this: .  -D argument is optional .  and in the \"/etc/freetds/freetds.conf\" there is an entry .  This used to work for many years. Right now I have some connectivity problems (segfaults), but this can be due to library configuration issues on my PC. .  ",
      "P-tags": "command-lin sybas linux sqsh database-connect",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_236712",
      "task": "Find multiple matches in a tabular file and print second column?",
      "P-task": "find multipl match tabular file print second column",
      "F_verb": "find",
      "P-body": "With \"join\": .   This will merge the two files at field number 1 and if they match, print the second field of the first file \"1.2\".  Or with \"awk\": .   The file \"file\" is loaded into an array \"a\". When the second file \"index\" in processed \"awk\" checks if the first field is in the array as index \"a[$1]\". If yes, print the second field \"$2\".  ",
      "P-tags": "awk join text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "au_57154",
      "task": "can not ping by host name for some computers",
      "P-task": "ping host name comput",
      "F_verb": "ping",
      "P-body": "Just add \"WINS\" to the \"hosts:\" line in the \"/etc/nsswitch.conf\" file: .  This tells the system to use WINS in order to lookup netbios. The \"winbind\" package has to be installed for this to work. .  ",
      "P-tags": "hostnam 11 04 ping",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V by NP for NP"
    },
    {
      "id": "au_1102848",
      "task": "compilation terminated: How to install FiSHLiM on Ubuntu and Debian",
      "P-task": "compil termin : instal fishlim ubuntu debian",
      "F_verb": "install",
      "P-body": "For me it seems that you should install the package containing \"hexchat-plugin.h\" file. According to the search on packages.ubuntu.com it is named \"hexchat-dev\". So you need to install it: .  ",
      "P-tags": "compil irc hexchat package-manag software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_974257",
      "task": "Read string with $USER variable as text and resolve it",
      "P-task": "read string user variabl text resolv",
      "F_verb": "resolve",
      "P-body": "\"read\" does not expand variables from your config file. .  You can verify that: .  This answer on Stackoverflow gives a solution. Change your script to this to make it expand variables: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_9077149",
      "task": "Different results when running java awt code on Windows and Linux",
      "P-task": "differ result run java awt code window linux",
      "F_verb": "run",
      "P-body": "Your method is based on \"getFontMetrics()\", that return the font metric of the current font. I assume you're using default font in your program, and they are different in the different OS, so the result height might be different. .  ",
      "P-tags": "linux window awt java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "so_741841",
      "task": "tcsh: How to change the file extension for multiple files?",
      "P-task": "tcsh : chang file extens multipl file",
      "F_verb": "change",
      "P-body": "Type in these four lines. After the first the prompt, tcsh will tell you that you are inside the \"foreach\" loop. You could also turn it into a shell script and call that shell script. .  ",
      "P-tags": "linux tcsh shell regex",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP for NP"
    },
    {
      "id": "so_50379249",
      "task": "How can I prevent that a Client can search a file in any directory of the Server?",
      "P-task": "prevent client search file directori server",
      "F_verb": "prevent",
      "P-body": "It depends how you implemented the search on the server side. The easiest and obvious but not always the right answer would be to strip slashes \"/\" from the search string you get. .  However if you implemented your search with a shell command using \"system()\" with, for example, \"find\" and your filename concatenated you need a serious filter function for the user input because otherwise one could execute random shell commands with a prepared search string .  ",
      "P-tags": "linux c secur client-serv",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V that S"
    },
    {
      "id": "au_46494",
      "task": "Will moving music to another folder mess up Banshee's metadata?",
      "P-task": "move music anoth folder mess banshe metadata",
      "F_verb": "move",
      "P-body": "I have moved my Music from one system to another and I have also moved from one LVM to another LVM. .  One move I completed was an scp from my laptop (Ubuntu) to my desktop (Windows) and all the information including the metadata of each of my songs were great. .  I then did another copy from LVM volume to another LVM volume using the following command: .  I am using that new copied Music folder for Banshee as we speak with no metadata problems. .  Before you move all your music from one folder to another, just do a small test for one song move to a new directory. Once the song has been moved, import it back into Banshee to verify that the metadata is not harmed. Example below: .  Hope this helps. .  ",
      "P-tags": "media banshe",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1049240",
      "task": "view the column names for CSV file?",
      "P-task": "view column name csv file",
      "F_verb": "view",
      "P-body": " or .  or .  or .  ",
      "P-tags": "csv command-lin text-process",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP for NP"
    },
    {
      "id": "so_113737",
      "task": "How do I use PowerShell to stop and start a clustered \"Generic Service\"?",
      "P-task": "use powershel stop start cluster gener servic",
      "F_verb": "start",
      "P-body": "You can also use WMI. You can get all the Generic Services with: .  To stop and start a service: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "ul_404060",
      "task": "How to sort results of Find statement by date?",
      "P-task": "sort result find statement date",
      "F_verb": "sort",
      "P-body": " get file names only ... sorted by modification day .   \"find\" + \"sort\" + \"cut\" approach: .    \"%T@\" - File's last modification time, where \"@\" is seconds since \"Jan. 1, 1970, 00:00 GMT,\" with fractional part .  \"%f\" - File's name with any leading directories removed (only the last element) .    To sort in descending order: .  ",
      "P-tags": "linux file find sort",
      "source": "qa",
      "cate": "sort",
      "pat": "V NP of NP by NP"
    },
    {
      "id": "so_38465846",
      "task": "finding latest version files in each directory",
      "P-task": "find latest version file directori",
      "F_verb": "find",
      "P-body": " ",
      "P-tags": "linux command find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "au_545835",
      "task": "How can I play music?",
      "P-task": "play music",
      "F_verb": "play",
      "P-body": "All you need to do is to install sound plugins. The easiest way is to: .  That should fix it, and install some other useful things along with it (e.g Adobe Flash). .  ",
      "P-tags": "14 04 codec sound",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "au_450837",
      "task": "Kingston Datatraveler won't mount in ubuntu 14.04",
      "P-task": "kingston datatravel mount ubuntu 14 04",
      "F_verb": "mount",
      "P-body": "I fixed it. I tried the advice of pushing the USB in slowly. That didn't work.  .  What did work was pushing it in very slowly in a timed manner. Here is how: .  I used \"dmesg -wH\" which keeps live updating \"dmesg\" in your terminal.  .  And right at the moment where Ubuntu said that it recognized it. I stopped pushing it in any further. Weirdly enough, this is as much a skill as learning how to use a small screwdriver or a semi-complex game controller combination in a video game. .  My Kingston Datatraveler mounted. It did not mount by pushing it in slowly, but by pushing it in very slowly and immediately stopping when dmesgh said: \"USB Mass Storage device detected\"  .  ",
      "P-tags": "14 04 usb usb-driv",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V in NP"
    },
    {
      "id": "so_7715922",
      "task": "Sending a SIGHUP signal with PHP via shell_exec",
      "P-task": "send sighup signal php via shell_exec",
      "F_verb": "send",
      "P-body": "Try .  and see if any errors are reported. Also, you could try \"pgrep\", \"pkill\" or \"killall\" instead of messing about with \"ps\" and \"grep\". .  Alternatively, try just running \"ps\" and parsing its full output in PHP yourself. \"preg_match()\" and/or \"preg_grep()\" may be useful for this.) And you can use \"posix_kill()\" instead of running an external \"kill\" program. .  Edit: As per comments, it seems the actual issue was a missing or incorrectly set \"PATH\" environment variable. One way to solve this issue would be to run \"echo $PATH\" in shell, copy the output and set \"PATH\" to the same value in PHP with \"putenv()\". Another solution is to use \"which\" in shell to determine the full paths to \"ps\" et al., and use those full paths in \"shell_exec()\". .  ",
      "P-tags": "php ubuntu signal shell bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP with NP via NP"
    },
    {
      "id": "so_42631265",
      "task": "Detecting child process creation in fork()",
      "P-task": "detect child process creation fork",
      "F_verb": "detect",
      "P-body": "Add a little extra code to get something like: .  Then compile, execute, and check its output: 5 child process IDs. .  ",
      "P-tags": "c++ fork unix",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "su_810937",
      "task": "How can I set the parity bits when using screen to access a serial port",
      "P-task": "set pariti bit use screen access serial port",
      "F_verb": "set",
      "P-body": "Long story short, it looks as if \"screen\" doesn't support setting those flags. The alternative would be to run \"stty\" to set the flags while screen is connected to the port, as you've done. Alternately, you could run kermit or another terminal emulator program inside a conventional screen command-line session, instead of having screen connect directly to the serial port. .  The \"screen\" source code is at http://git.savannah.gnu.org/cgit/screen.git. It looks like the file of interest is tty.sh. This is shell script which runs during the build process to produce \"tty.c\". tty.c contains the code for accessing serial ports. .  The function \"SttyMode()\" appears to be what parses the tty options and sets the tty mode. It appears to me that it handles a small, fixed set of options. \"parenb\" and \"parodd\" aren't among them. .  It looks like it'd be straightforward for a developer experienced with C to add support for these options, if that's an option for you. .  ",
      "P-tags": "linux serial-port gnu-screen",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP when S"
    },
    {
      "id": "ul_395742",
      "task": "How to convert a String into Array in shell script",
      "P-task": "convert string array shell script",
      "F_verb": "convert",
      "P-body": " Explanations: .   First we are taking backup of default/current shell IFS with \"bkpIFS=\"$IFS\"\"; Then we set IFS to set of delimiters \",\", \"(\", \")\", \"]\" and \"[\" with \"IFS=',()]['\" which means our input string can be delimited with one-or-more of these delimiters. .  Next \"read -r -a array\" reads and split the line into an array called \"array\" only based on defined IFS above from input string passed in Here-String method. The \"-r\" option is used to tell \"read\" command don't does expansion on back-slash \"\\\" if come in input. .  see the last \",k\" which it caused by having back-slash in input and \"read\" without its \"-r\" option. .  With \"echo ${array[@]}\" we are printing all elements of array. see What is the difference between $* and $@? and Gilles's answer about \"${array[@]}\" there with more details. .  With \"printf \"%s\\n\" ${array[@]}\" also there is other approach to printing array elements. .  Now you can print a specific element of array with \"printf \"%s\\n\" ${array[INDEX]}\" or same with \"echo ${array[INDEX]}\". .  Ah, sorry, forgot to give \"IFS\" back to shell, \"IFS=\"$bkpIFS\"\" : ) .   Or using \"awk\" and its \"split\" function. .  Explanations: .   Same here, we are splitting the entire line of input based on defined group of delimiters \"[...]\" in regexp constant \"/[...]/\" which support in modern implementation of \"awk\" using \"split\" function. read more in section of \"split()\" function. .  Next at the \"END{for (x in arr) printf (\"%s \",arr[x]); ...}\" we are looping over array called \"arr\" and print their corresponding value. \"x\" here point to the index of array \"arr\" elements. read more about \"awk\"'s BEGIN/END rules. .   Side-redirect to How to add/remove an element to the array in bash?. .  ",
      "P-tags": "array shell-script bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP in NP"
    },
    {
      "id": "so_14929318",
      "task": "Python MySQLdb not inserting data",
      "P-task": "python mysqldb insert data",
      "F_verb": "insert",
      "P-body": "Add : .  at the bottom of your script. .  On a side note, have a look at the following : http://mysql-python.sourceforge.net/MySQLdb.html .  ",
      "P-tags": "python-2 7 mysql-python ubuntu-12 10",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_58605",
      "task": "How to reference a script-local dictionary in a Vim mapping?",
      "P-task": "refer script-loc dictionari vim map",
      "F_verb": "reference",
      "P-body": "There is no way (that I know of) to directly access script-local variables outside the context of that script; \"<SID>\" only works for functions (and only in mappings). .  You could provide indirect access through a function, though: .  Depending on how isolated you want to keep the variable, you could make the \u201caccessor\u201d function more restrictive (only allow certain keys, only allow read access, only allow writes to certain keys, etc).  .  ",
      "P-tags": "script function vim",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_8320414",
      "task": "Committing to Git on VirtualBox - error: unable to write sha1 filename",
      "P-task": "commit git virtualbox - error : unabl write sha1 filenam",
      "F_verb": "commit",
      "P-body": "Using \"git\" in synchronised folders like Dropbox or this is generally a bad idea \u2013 \"git\" seems to assume that nobody else tries to touch a repo concurrently, doesn't try to perform sets of filesystem operations atomically, and you get race conditions like this. .  Don't put git repos into automatically synced folders. Synchronise the host and the VM by pushing/pulling to your github fork. .  ",
      "P-tags": "git virtualbox ubuntu github",
      "source": "qa",
      "cate": "commit/submit/upload",
      "pat": "V to NP on NP"
    },
    {
      "id": "so_22641918",
      "task": "How do I execute a linux command in PHP and echo the output in original format?",
      "P-task": "execut linux command php echo output origin format",
      "F_verb": "execute",
      "P-body": "For a browser: .  Browsers render HTML. Whitespace has no meaning in HTML, only to format the source. \"pre\" tags instruct the browser to render the text as pre-formatted text. .  ",
      "P-tags": "linux php shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "su_1366469",
      "task": "i2cdetect -l don't return anything",
      "P-task": "i2cdetect -l return anyth",
      "F_verb": "return",
      "P-body": "First step is to \"modprobe i2c-dev\", do \"cat /sys/bus/i2c/devices/i2c-*/name\", and edit your question with the output, so we at least what bus master hardware is currently already recognized. It's entirely possible to have a bus master, but no devices behind it. .  Second step is to edit your question with all the details how \"the\" SMBus (there can be lots of busses, each with different hardware) is recognized under Windows, i.e. what kind of hardware the bus master sits on, which ports it uses, etc. .  Third step is to use this data and find the corresponding hardware device under Linux, then check if you have a driver for it. .  Edit .  As long as you don't edit the question which details about what exactly you see under windows, I can't be sure, and I'm not familiar with your hardware, but: The motherboard SMBus on Intel-CPU systems is located in the southbridge, uses the \"i2c-i801\" module on my Intel-based system, and is visible as PCI-card. So (1) edit your question with the output of \"lspci -nn\", (2) edit the question with the details of what you see under Windows (PCI address, ports, anything that gives a hint how the hardware actually looks like, instead of having us guess). .  The \"no such file or directory\" indicates no module is loaded which actually provides a bus. This could be because your HP has some other hardware, or your Linux kernel has not enabled the module you need, or for a variety of other reasons. .  ",
      "P-tags": "fsb linux debian linux-kernel kernel-modul",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_9826928",
      "task": "generating a makefile for the dumb",
      "P-task": "gener makefil dumb",
      "F_verb": "generate",
      "P-body": "I don't think you want what you say you want, but how about: .  ",
      "P-tags": "linux makefil c",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "au_1042068",
      "task": "How to delete accidental folder on /media",
      "P-task": "delet accident folder media",
      "F_verb": "delete",
      "P-body": "Since these directories are the result of failed backup attempts, I assume that you have no data in them that you want to preserve, or that you've already saved the data elsewhere.  .  NOTE be sure to type this command accurately - you can break your system with typos in this command. .  This will delete the directory, and all the files and directories beneath it. .  ",
      "P-tags": "partit mount permiss rsync",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP on NP"
    },
    {
      "id": "au_512395",
      "task": "How do you prevent the 2nd page in a PageStack from running?",
      "P-task": "prevent 2nd page pagestack run",
      "F_verb": "prevent",
      "P-body": "\"Component.onCompleted\" runs as soon as the interpreter has read the QML file and parsed it into objects. Your \"page 2\" object is created at this time, but it has \"visible: false\" so you can't see it. That doesn't keep the \"onCompleted\" code from running. .  I know of three ways to get code to run only when the page gets pushed to the stack: .   Create a custom function that calls \"pageStack.push()\" and triggers whatever other code you want run. .  Move the code from page 2's \"onCompleted\" handler to the \"onVisibleChanged\" handler. Note that this will be called both when the page is pushed a popped from the stack; check the value of \"visible\" to tell which is happening. .  Move the page 2 object into a separate file, say \"page2.qml\", and change the push call to \"pageStack.push(Qt.resolvedUrl(\"page2.qml\"))\". This will create a new page 2 object each time it's pushed to the stack; this may or may not be what you desire. .   Note that all three of these will call the code each time page 2 is pushed to the stack. If you only want it to be called the first time, you'll have to keep track of that yourself. For more information on how object creation interacts with the pageStack, check out this answer. .  ",
      "P-tags": "application-develop ubuntu-sdk qml",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP from S_ING"
    },
    {
      "id": "so_12499869",
      "task": "Obj-m command not found",
      "P-task": "obj-m command found",
      "F_verb": "find",
      "P-body": "You're using \"obj-m\" as a command when it's not, it shouldn't be listed after a target as you're doing. .  The easiest way to compile your module is to follow this guide, or in your case just copy their simple makefile which makes it quite convenient to build it; .  ",
      "P-tags": "modul linux",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_20666695",
      "task": "How to safely open regular files without denial-of-service vulnerability?",
      "P-task": "safe open regular file without denial-of-servic vulner",
      "F_verb": "open",
      "P-body": "If your only concern is fifos, \"O_NONBLOCK\" will prevent blocking and allow you to open a fifo even if it has a no writers (see http://pubs.opengroup.org/onlinepubs/9699919799/functions/open.html for where this is specified). However, there are also a few other concerns: .   Device nodes Fake files in Linux \"/proc\" with bad properties ...  Since these normally can't be created in arbitrary locations by non-root users, \"O_NOFOLLOW\" should be sufficient to avoid following symlinks to them. .  With that said, on modern Linux there is an even safer solution: perform the initial \"open\" with \"O_PATH|O_NOFOLLOW\", then perform \"stat\" on \"/proc/self/fd/%d\" to check the file type. You can then open \"/proc/self/fd/%d\" and be completely certain it corresponds to the same file you just \"stat\"'d. .  Note that on sufficiently new Linux, you don't need to use \"/proc/self/fd/%d\" to reach the file to which you obtained an inode handle with \"O_PATH\". You can use \"fstat\" and \"openat\" on it directly to \"stat\" it and get a descriptor to a real open file description, respectively. However \"O_PATH\" file descriptors had a lot of broken/unimplemented corner cases like this in the range of late 2.6.x (when they were first added) to 3.8 or so, and I find the \"/proc\" method the most reliable. Of course you could always try the direct method and fallback to \"/proc\" if it fails. .  ",
      "P-tags": "linux c filesystem",
      "source": "qa",
      "cate": "open",
      "pat": "V NP without NP"
    },
    {
      "id": "au_537983",
      "task": "Ubuntu search not finding any files",
      "P-task": "ubuntu search find file",
      "F_verb": "find",
      "P-body": "The reason search isn't working in this case is because \"/media\" is blacklisted in \"/etc/updatedb.conf\". The solution is to mount the partition on \"/mnt\" and ran \"sudo /etc/cron.daily/mlocate\". .  Search uses multiple search engines. Zeitgeist indexes the recently used documents, which is why some files from the partition are showing, and some aren't. But other search engines (mlocate) and os-walk (previously 'find') are problematic. .  If your drives are NTFS, they aren't blacklisted, but are probably mounted in \"/media\", which is why they aren't being indexed. .  ",
      "P-tags": "nautilu uniti search",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_53750593",
      "task": "C : String comparing",
      "P-task": "c : string compar",
      "F_verb": "compare",
      "P-body": "When you read from 0, you're reading from stdin. If that is a terminal that you are typing into (you don't say), you likely have it set up in normal (canonical) mode, so you'll read a line, which probably includes a newline (\\n) character. So when you enter \"/done\", the string you get in your msg buffer is \"\"/done\\n\"\" which doesn't match \"\"/done\"\"... .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "compare",
      "pat": "V"
    },
    {
      "id": "so_24876631",
      "task": "Escape characters in private key for sed replace",
      "P-task": "escap charact privat key sed replac",
      "F_verb": "escape",
      "P-body": "As ymonad said in the comments, assuming that \"%\" does not appear in the SSH private key, you can use: .  Alternatively, choose any other character that does not appear in the contents of \"$ssh_private_key\". .  Also, consider whether you want to escape the \"\\\" in the output or whether you want the \"\\n\" to become real newlines in the output. .  ",
      "P-tags": "bash sed regex",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP for NP"
    },
    {
      "id": "so_19992889",
      "task": "How to parse for a number greater than x in a file",
      "P-task": "pars number greater x file",
      "F_verb": "parse",
      "P-body": "I did a try as following: .  text.txt: .  my commands: .  and the output is: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V for NP in NP"
    },
    {
      "id": "so_57200168",
      "task": "How to solve \"ImportError: No module named networkx\" in Ubuntu 18.04?",
      "P-task": "solv importerror : modul name networkx ubuntu 18 04",
      "F_verb": "solve",
      "P-body": "You should install:  .  ",
      "P-tags": "python-2 7 ubuntu-18 04",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP"
    },
    {
      "id": "so_61630608",
      "task": "Remove substrings between < and > (including the brackets) with no angle brackets inside",
      "P-task": "remov substr includ bracket angl bracket insid",
      "F_verb": "remove",
      "P-body": "You may use .  The patterns match .   \"<\\+\" / \"<\\{1,\\}\" - 1 or more occurrences of \"<\" char \"[^>]*\" - negated bracket expression that matches 0 or more chars other than \">\" \">\\+\" / \">\\{1,\\}\" - 1 or more occurrences of \">\" char  Note that in the last, POSIX ERE, example, \"+\" that is unescaped is a quantifier matching 1 or more occurrences, same as \"\\+\" in the POSIX BRE pattern. .  See the online \"sed\" demo: .  Result of each sed command is \"aabbvvh\". .  ",
      "P-tags": "linux sed regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP between NP with NP"
    },
    {
      "id": "so_19736536",
      "task": "How to print Google Test output to a text file?",
      "P-task": "print googl test output text file",
      "F_verb": "print",
      "P-body": "You can redirect the output of your \"runTests\" command to a file:  .  Also, see this which explains why you do not need the \"&\" I had used in my comment. As Awaken's answer says, the \"&\" redirects both the \"stdout\" and \"stderr\" to the same file. But since \"googletest\" output always goes to \"stdout\" you may leave out the \"&\".  .  ",
      "P-tags": "googletest c++ bash c cmake",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_653381",
      "task": "awk: Create new record and update NR",
      "P-task": "awk : creat new record updat nr",
      "F_verb": "create",
      "P-body": "You cannot create a new input record in one pass of an input file. Creating a new input record would mean that this code: .  would print the original record then enter an infinite loop printing \"Foo\" because by definition awk executes the above code once per input record. .  You can do things to execute code on strings whether they're from an input record or created internally, e.g.: .  but that's not the same as actually creating a new input record. .  You could also do a 2-pass approach to create and write to a temp file on the first pass so that when reading the temp file for the second pass the newly printed strings are now present as input records. .  You're overload/abusing the meaning of \"NR\" though. \"NR\" is the count of input records read, you're trying to print a count of output records printed which is a completely different thing. There is no builtin variable for that as it's trivial to just keep track of it yourself in a separate variable rather than messing with \"NR\", e.g. with \"onr\" below: .  Again though - we are NOT creating new input records and so (as always) it'd be completely inappropriate to try to adjust the value of the builtin variable \"NR\". Instead we're simply generating new output records and keeping track of the total number of output records in a user-defined variable named \"onr\". .  I added both \"NR\" and \"onr\" to the output and changed the sample input to: .  to highlight that there's actually 3 separate data items in play: .   \"NR\" = the number of input records, \"onr\" = the number of output records, \"val\" = the value of the $2 to be printed for each record  and for clarity, cohesion, coupling, maintenance etc. of your program it's best not to overload any of them. .  ",
      "P-tags": "awk",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "au_522759",
      "task": "How can I find out the temperature components are running at in 14.04?",
      "P-task": "find temperatur compon run 14 04",
      "F_verb": "find",
      "P-body": "Look up for \"lm-sensors\" and \"psensor\". Those will give you a command line output as well as a GUI for your laptop.  .  Here is a good tutorial how to use lm-sensors: lm-sensors Howto .  ",
      "P-tags": "14 04 temperatur overh diagnost",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_389255",
      "task": "Determine how long tabs '\\t' are on a line",
      "P-task": "determin long tab line",
      "F_verb": "determine",
      "P-body": "The \"TAB\" character is a control character which when sent to a terminal\u00b9 makes the terminal's cursor move to the next tab-stop. By default, in most terminals, the tab stops are 8 columns apart, but that's configurable. .  You can also have tab stops at irregular intervals: .  Only the terminal knows how many columns to the right a TAB will move the cursor. .  You can get that information by querying the cursor position from the terminal before and after the tab has been sent. .  If you want to make that calculation by hand for a given line and assuming that line is printed at the first column of the screen, you'll need to: .   know where the tab-stops are\u00b2 know the display width of every character know the width of the screen decide whether you want to handle other control characters like \"\\r\" (which moves the cursor to the first column) or \"\\b\" that moves the cursor back...)  It can be simplified if you assume the tab stops are every 8 columns, the line fits in the screen and there are no other control characters or characters (or non-characters) that your terminal cannot display properly. .  With GNU \"wc\", if the line is stored in \"$line\": .  \"wc -L\" gives the width of the widest line in its input. It does that by using \"wcwidth(3)\" to determine the width of characters and assuming the tab stops are every 8 columns. .  For non-GNU systems, and with the same assumptions, see @Kusalananda's approach. It's even better as it lets you specify the tab stops but unfortunately currently doesn't work with GNU \"expand\" (at least) when the input contains multi-byte characters or 0-width (like combining characters) or double-width characters. .   \u00b9 note though that if you do \"stty tab3\", the tty device line discipline will take over the tab processing (convert TAB to spaces based on its own idea of where the cursor might be before sending to the terminal) and implement tab stops every 8 columns. Testing on Linux, it seems to handle properly CR, LF and BS characters as well as multibyte UTF-8 ones (provided \"iutf8\" is also on) but that's about it. It assumes all other non-control characters (including zero-width, double-width characters) have a width of 1, it (obviously) doesn't handle escape sequences, doesn't wrap properly... That's probably intended for terminals that can't do tab processing. .  In any case, the tty line discipline does need to know where the cursor is and uses those heuristics above, because when using the \"icanon\" line editor (like when you enter text for applications like \"cat\" that don't implement their own line editor), when you press TabBackspace, the line discipline needs to know how many BS characters to send to erase that Tab character for display. If you change where the tab stops are (like with \"tabs 12\"), you'll notice that Tabs are not erased properly. Same if you enter double-width characters before pressing TabBackspace. .   \u00b2 For that, you could send tab characters and query the cursor position after each one. Something like: .  Then, you can use that as \"expand -t \"$tabs\"\" using @Kusalananda's solution. .  ",
      "P-tags": "control-charact text-process",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP on NP"
    },
    {
      "id": "au_590244",
      "task": "Apt-get update fails ubuntu 14.04",
      "P-task": "apt-get updat fail ubuntu 14 04",
      "F_verb": "get",
      "P-body": "As can be seen from the output of \"dpkg --print-foreign-architectures\", you have a bunch of invalid architectures added, for some reason. Remove them: .  In future, do check what you're adding. .  ",
      "P-tags": "apt updat",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_56838657",
      "task": "How to search word on unix folders",
      "P-task": "search word unix folder",
      "F_verb": "search",
      "P-body": "When you are using \"grep\" recursively, you do not need a list of files at the end, in your case -- \"*\". .  Use \"grep -Rin \"word\"\" from the directory you want to begin your search from. .  Alternatively, \"find\" command can be used.  .  \"find <top_path> -type f | xargs grep -in \"word\"\". .  top_path can be \".\" or present working directory or a full path. \"-type f\" only finds files to speed up the search. \"xargs\" gives \"find\" results to \"grep\" as arguments. .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_43003",
      "task": "Using VI keys to edit shell commands in UNIX",
      "P-task": "use vi key edit shell command unix",
      "F_verb": "edit",
      "P-body": "You're talking about the greatest feature ever! .  You can use vi commands to edit shell commands (and command history) by adding this to your \".bashrc\" file: .  \"set -o vi\" .  You can also run that command from the command line to affect only your current session. .  If you don't use bash, substitue the appropriate rc file for your shell. .   This allows you to use vi commands to edit any command... .  You can also use j and k to move through your history (after pressing ESC). .  You can also use / (after hitting ESC) to search for old commands. .  In other words, to find that super-long \"cp\" command you did ten minutes ago: .  ESC/cpENTER .  Then you can cycle through all the matching commands in your history with n and N. .  All this makes me 10 trillion times more productive at the command line! .  ",
      "P-tags": "termin vim vi shell",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_167628",
      "task": "how to test if can connect to port in rhel 7 (telnet client?)",
      "P-task": "test connect port rhel 7 telnet client",
      "F_verb": "test",
      "P-body": "You can install just the \"telnet\" package and have telnet client functionality. Alternately, you can use the \"nc\" command to test port connectivity if you'd rather not mess with telnet at all. .  ",
      "P-tags": "rhel network",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "ul_87983",
      "task": "How to securely allow scp, but not ssh",
      "P-task": "secur allow scp ssh",
      "F_verb": "allow",
      "P-body": "Ok, you messed things up.  .  From what I've understood, you just want to copy a file from bar to foo: .  In order to do just that, you first \"ssh\" to bar then \"scp\" file to foo: .  then: .  If you are doing like this, you are doing it insecurely and wrong. All you have to do is scp the file back to you directly: .  in other words: .  Now there are a couple of problems to be solved\u202f\u2026 .  How to know where the file is? a) Use SSH in another terminal Just open a second terminal, SSH to bar, find your file and copy/paste the path to the first one. .  b) Use SFTP SFTP (not related to FTP nor FTPS in any way!) is implemented in OpenSSH and is available by default. Just SFTP to the server and use the FTP-like commands to find you files and \"get\" them. .  c) Use a GUI Filezilla or Nautilus for instance can browse remote SFTP/SSH shares. .  d) Set up certificates When you set up certificate connection, you can do tab completion on the local side as well as on the remote side! For instance, with your \"buzz\" example, you can do: .  and wait a little for the list of files contained in the remote /guest/ folder. .  How to set up SSH with certificates? a) If not already done, generate your personal RSA key pair If you've installed OpenSSH client, you can do it by typing  .  (look at the manual or online for all the available options). It may ask you for a password. This is not your local account password but an optional password that can be used to encrypt the private key you are about to generate. .  Actually, you will generate 2 files: .   /Users/[yourusername]/.ssh/id_rsa /Users/[yourusername]/.ssh/id_rsa.pub  The first one, *id_rsa* ought to be private. By default, \"ssh-keygen\" will do everything it can to avoid making it public (using filesystem access permission). That's why it will also ask you for an (optional) password. Don't be too paranoid with that, but just remember *id_rsa* == personal key == private. This key should never ever leave your computer. .  The second one is public. It requires a huge amount of computer power to get back your private key from this public certificate (I really mean HUUUUUUGE). This is perfectly safe to share it with the whole world. Even in the very unlikely event that the NSA or the likes really want to spend millions of dollars cracking your public key, your macbook will still be safe\u202f\u2026 (or not. Thinking about it, if someone wants to spend that much, you are in trouble :) .  This public certificate is actually what you will put on the remote server bar. .  b) How do I put my public certificate on the server? Two options.  .   Use \"ssh-copy-id\" if available: \"bob@foo$ ssh-copy-id bob@bar\". Done. If it is not, copy \"~/.ssh/id_rsa.pub\" to bar: .  bob@foo$ sftp ~/.ssh/id_rsa.pub bob@bar:pub_cert .   (here, you copied your public cert \"id_rsa.pub\" from \".ssh/\", in your personal \"~\" folder to the remote computer bar in the home folder of the user bob. This is the default. Also note that \"id_rsa.pub\" has been renamed to \"pub_cert\" in the process. I used \"sftp\" just to show you that it can be used exactly as \"scp\"). .  Now, we shall copy this certificate to the right location: .  Now you are in bob's personal folder in bar. .  (here, you displayed the content of pub_cert with \"cat\". But instead of printing it to the screen, you redirect this output to a file: \".ssh/known_hosts\". Note that a redirection with \">\" would mean \"replace the content of the file with this stream\" while \">>\" means \"append the stream at the end of the existing file\"). .  c) Result? Now you can \"scp\"/\"sftp\"/\"ssh\" to bar as much as you want without having to provide a password. You can also autocomplete local and remote paths using the [tab] key. .  d) What about my mac security? With this way of doing this, you don't even need a running SSH server on your computer. Only an SSH client (the \"scp\"/\"sftp\"/\"ssh\" programs). This is safe for you even if bar is compromised. .  e) What did I do exactly with these keys/certificates? First you generated a couple of files: a private key and a public certificate. You can do a lot of things related to security and authentication with them. But in our case, with a fair bit of simplification, these are used this way: .  When you try to connect to bar, you will advertise that you've got a certificate that you can use for the connection. bar will inspect various locations in the system, including \"~/.ssh/known_hosts\". It will find the certificate that you advertised and use it to send you encrypted data. .  Actually, public certificates can encrypt stuff! .  Now this is great, but how can foo understand that? Using your private key. .  Private keys can decrypt stuff encrypted with the corresponding public certificate! .  This is what is called asymmetric encryption. .  Then, basically, the server will send a complicated password to you encrypted with your public certificate. You will receive it, decrypt it with your private key and start to use it to encrypt data with the server both ways. .   Now, what if you really really want to do the things your way and SCP back to foo? You are just asking for troubles. But to mitigate the effect of a possible compromission, you can set up a chrooted \"SFTP\"-only server. \"scp\" and \"ssh\" won't work any more, but \"sftp\", Filezilla and stuff are gonna work. .  ref: https://www.allthingsdigital.nl/2013/05/12/setting-up-an-sftp-only-account-with-openssh/  .  ",
      "P-tags": "scp ssh bash",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP"
    },
    {
      "id": "ul_302084",
      "task": "Error in awk for merge files",
      "P-task": "error awk merg file",
      "F_verb": "merge",
      "P-body": "Assuming the data is sorted, for the type of situation I would use the \"join\" command .  You use \"-o\" to set the format in a \"x.y\" style where \"x\" is the file and \"y\" is the field. .  ",
      "P-tags": "awk join text-process",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_64194648",
      "task": "Delete all file and keep the latest using powershell",
      "P-task": "delet file keep latest use powershel",
      "F_verb": "keep",
      "P-body": "As Lee_Daily suggests, rather than using a time window to filter by, it is simpler to sort your files by last write time and delete all but the latest files. .  The challenge is to determine which files relate to the same database and should therefore be considered as a group, so that you keep the most recent backup in each group. .  The code below uses the following approach: .   The \"Group-Object\" cmdlet allows you to group the input files by the shared part of the file names that indicates the database. .   Passing script block \"{ $_.Name -replace '^Backup\\d+-' }\" to \"Group-Object\" uses the regex-based \"-replace\" operator to make it group the input file objects by the shared name part that indicates the source database, by removing the \"'Backup<n>-'\" prefix. E.g., the result for both \"'Backup1-Database-A.bak'\" and \"'Backup2-Database-A.bak'\" is just \"'Database-A.bak'\", so the two files are grouped together.   The files in each resulting group can then be sorted by last write time in descending order, with \"Sort-Object\". .   You can exclude the first - and therefore most recent - file from the output with \"Select-Object\" \"-Skip 1\". .   The resulting files - all but the most recent ones for each database - can then be sent to \"Remove-Item\". .    Note: The \"-WhatIf\" common parameter in the command above previews the operation. Remove \"-WhatIf\" once you're sure the operation will do what you want. .  Also note the simplification of the initial file selection: \"-File\" (PSv3+) limits output to files only (not also directories), and \"-Filter *.bak\" is an efficient way to filter by filename extension. .  ",
      "P-tags": "file powershel backup",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP using NP"
    },
    {
      "id": "so_66399237",
      "task": "Couchdb 1.x removed from my server, reinstalled Couchdb 3.x, how do I get my old files with the .couch extension to work with it?",
      "P-task": "couchdb 1 x remov server reinstal couchdb 3 x get old file couch extens work",
      "F_verb": "remove",
      "P-body": "I finally managed to do it, and this is how: .  I installed an older version of Ubuntu server on a virtual machine (I used VirtualBox) and installed couchdb 1.6. I manually added my .couch files into /var/lib/couchdb using FileZilla. I tested that everything worked fine and it did. .  After that I upgraded couchdb 1.6 to couchdb 2.3 and used the couchup tool that comes with couchdb 2 (note that couchdb 2 and 3 require you to set an admin password). This page shows how to use it. The couchup script is located in /opt/couchdb/bin. .  I navigated to this folder and I ran the following: .  It turns out that couchdb 2.x databases work just fine with couchdb 3 so there wasn't anything else needed. I uploaded the replicated databases to my deployed server and it worked right away. .  INFO: note that with couchdb 1, each database you create appears as one single file. e.g. db1.couch, db2.couch, etc.), but with couchdb 2 and 3 they are all located in the file _dbs.couch (you may want to transfer shards, _users.couch and the other files in /var/lib/couchdb to ensure everything works well). .  INFO 2: the couchup utility is only installed by default with couchdb 2, you won't have it if you jump straight to couchdb 3. However, couchup is just a python script and I believe it is possible to download it from this github page, so you may not even need to install couchdb 2 (I have not tried it this way, so no guarantees). .  ",
      "P-tags": "ubuntu-18 04 couchdb",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V from NP"
    },
    {
      "id": "so_65929229",
      "task": "SED Replace multiple second occurrence of a character",
      "P-task": "sed replac multipl second occurr charact",
      "F_verb": "replace",
      "P-body": "Using \"awk\", you can set a variable whenever the line contains one field. If it does, use a variable to hold the last value of that field, and skip printing the line when they match. .  ",
      "P-tags": "awk grep sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V"
    },
    {
      "id": "so_69604464",
      "task": "Build .ko file from .c file using GCC command line",
      "P-task": "build ko file c file use gcc command line",
      "F_verb": "build",
      "P-body": " I'm trying to build a kernel object file from a c file which would only do printk(\"hello, world\") .   A short google search for such module resulted for me in the following examples: https://github.com/maK-/SimplestLKM https://github.com/moutoum/linux-kernel-module-hello-world https://github.com/ichergui/hello-world https://github.com/carloscdias/hello-world-linux-module . .   How do I compile it using gcc to create a valid my_driver.ko file that can be loaded with modprobe? .   The first project has the following source for a hello world module saved in \"hello.c\": .  The following is a transcript of a session with compiling the first project with \"V=1\": .  From that we know that we also need the generated hello.mod.c. The content for this module as generated by modpost program is as follows: .  With both files in place, we can compile them with gcc, first to \"hello.o\" and \"hello.mod.o\" and then combine with \"ld\". So these are the compiler flags needed to compile the module on my system: .  After that we can \"insmod hello.ko\" and have hello world printed with CRIT in dmesg. .   what are the compiler flags to use in order to do it. .   In the same fashion as presented above, you can find out what options are passed to the compiler on your system. .  ",
      "P-tags": "kernel-modul c linux-kernel",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "au_859556",
      "task": "Permission denied to view directory",
      "P-task": "permiss deni view directori",
      "F_verb": "deny",
      "P-body": "Try using \"sudo chown yourUserName /path/to/folder\" this will give you ownership of the directory if it was for some reason mounted as root. If this still doesn't work try \"chmod +rwx /path/to/folder\" which will allow reading and writing to that directory .  ",
      "P-tags": "gui command-lin copi directori permiss",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V S_INF"
    },
    {
      "id": "so_44488636",
      "task": "OpenCV: reading frames from VideoCapture advances the video to bizarrely wrong location",
      "P-task": "opencv : read frame videocaptur advanc video bizarr wrong locat",
      "F_verb": "read",
      "P-body": "Your video file data contains just 1313 non-duplicate frames (i.e. between 7 and 8 frames per second of duration): .  Converting the avi file with \"ffmpeg\" reports 16697 duplicate frames (for some reason 10 additional frames are added and 16697=18010-1313). .   BTW, thus converted video (\"demo.mp4\") is devoid of the problem being discussed, that is OpenCV processes it correctly. .   In this case the duplicate frames are not physically present in the avi file, instead each duplicate frame is represented by an instruction to repeat the previous frame. This can be checked as follows: .  In the above log, frames with actual data are represented by the lines starting with \"\"[avi @ 0xHHHHHHHHHHH]\"\". The \"\"video: delay=xxxxx A-V=yyyyy\"\" messages indicate that the last frame must be displayed for \"xxxxx\" more seconds. .  \"cv2.VideoCapture()\" skips such duplicate frames, reading only frames that have real data. Here is the corresponding (though, slightly edited) code from the 2.4 branch of opencv (note, BTW, that underneath ffmpeg is used, which I verified by running python under gdb and setting a breakpoint on \"CvCapture_FFMPEG::grabFrame\"): .  ",
      "P-tags": "opencv video-process ubuntu python video",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_24200953",
      "task": "Converting datetime to unix timestamp in mySQL",
      "P-task": "convert datetim unix timestamp mysql",
      "F_verb": "convert",
      "P-body": "You don't need to reformat/convert anything. Just do .  Here is SQLFiddle demo .  Recommended reading .   The DATE, DATETIME, and TIMESTAMP Types  ",
      "P-tags": "unix-timestamp datetim mysql insert-into",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "ul_10026",
      "task": "How can I best copy large numbers of small files over scp?",
      "P-task": "best copi larg number small file scp",
      "F_verb": "copy",
      "P-body": "You can pipe tar across an ssh session: .  ",
      "P-tags": "tar scp",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP of NP over NP"
    },
    {
      "id": "so_20398851",
      "task": "how to get md5sum command and get the string output in code",
      "P-task": "get md5sum command get string output code",
      "F_verb": "get",
      "P-body": "This is a proof of concept I wrote some time ago. Pretty much like the second answer in the link in @slugonmission 's comment but a bit better I think (using \"fread\"). Actually at the end I preferred the approach using the library as a little bit faster. So I suggest if dependency on openssl is ok with you and performance is important to prefer the library.  .  ",
      "P-tags": "c++ linux unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_661279",
      "task": "Nautilus launcher icon no longer contains Places and Bookmarks on right-click (14.04.02)",
      "P-task": "nautilu launcher icon longer contain place bookmark right-click 14 04 02",
      "F_verb": "contain",
      "P-body": "Nautilus is represented by multiple \".desktop\" files in \"/usr/share/applications\". Most likely, your current \"new\" icon is the \"nautilus-folder-handler.desktop\" -file. .  The one you need is \"nautilus.desktop\". .  What to do  Just navigate to the directory \"/usr/share/applications\" Look for the file \"nautilus.desktop\" Drag the file to the launcher Log out and back in  No need to say that you need to unpin the wrong nautilus icon... .  ",
      "P-tags": "nautilu uniti launcher",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_52541024",
      "task": "unix echo string with underscore next to variable",
      "P-task": "unix echo string underscor next variabl",
      "F_verb": "echo",
      "P-body": "\"printf\" works in this case (since \"$var_name\" stands alone): .  Or use \"{braces}\" around the variable to disambiguate where the variable name ends within an interpolated string: .  ",
      "P-tags": "linux echo unix",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP with NP to NP"
    },
    {
      "id": "so_53973537",
      "task": "JetBrains Rider hangs when creating solution file on Ubuntu 16.04",
      "P-task": "jetbrain rider hang creat solut file ubuntu 16 04",
      "F_verb": "create",
      "P-body": "I was able to bypass this problem by choosing \"ASP.NET Web Application\" instead of \"Empty Solution\". .  ",
      "P-tags": "ubuntu-16 04 rider",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "au_62845",
      "task": "How to hide window title and menu bar in GNOME Shell?",
      "P-task": "hide window titl menu bar gnome shell",
      "F_verb": "hide",
      "P-body": "To answer you directly - no its not \"easy\" for gnome-shell to have unity's global menu. .  However, there is an alpha quality gnome-shell global unity patch available (patch below). .  As to redisplaying the minimize-maximize and close decoration back-into gnome-shell - just use gconf-editor and change the key shown - note the position of the close - minimize - maximize buttons .   .  Compile Gnome-Shell global menu open GNOME Tweak Tool (install it in Ubuntu: \"sudo apt-get install gnome-tweak-tool\") and enable the Global Menu extension .  Now open Dash and search for Startup Applications .  Add an entry \"gnome-globalmenu-manager\" .  Complete the installation: .  not tested by myself - original source and updated instructions .  ",
      "P-tags": "globalmenu gnome usabl uniti",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V NP in NP"
    },
    {
      "id": "so_30118490",
      "task": "How to quickly disable a single job in crontab",
      "P-task": "quickli disabl singl job crontab",
      "F_verb": "disable",
      "P-body": "The quickest way would be to edit the crontab file and simply comment the job you want disabled. Comment lines in crontab start with a \"#\". .  ",
      "P-tags": "linux cron crontab",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP in NP"
    },
    {
      "id": "so_7512309",
      "task": "How can I insert a variable containing a backslash in sed?",
      "P-task": "insert variabl contain backslash sed",
      "F_verb": "insert",
      "P-body": "If it's only backslash that is \"eaten\" by sed and escaping just that is enough, then try: .  Confusing enough for you? \"\\\\\" represents a single \\ since it needs to be escaped in the shell too. The inital \"//\" is similar to the \"g\" modifier in \"s/foo/bar/g\", if you only want the first occurring pattern to be replaced, skip it. .  The docs about \"${parameter/pattern/string}\" is available here: http://www.gnu.org/s/bash/manual/bash.html#Shell-Parameter-Expansion .  Edit: Depending on what you want to do, you might be better of not using sed for this actually. .  ",
      "P-tags": "backslash escap sed bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_10097672",
      "task": "Merging data.frames leads to out-of-memory error",
      "P-task": "merg data frame lead out-of-memori error",
      "F_verb": "merge",
      "P-body": "Switching to \"data.table()\" as @Chase suggested in the comments above, and deleting used objects liberally allowed me to process the first merge. It turned out, a later merge that was causing trouble was actually doing a Cartesian join somewhere I didn't expect due to the second dataset having non-unique keys, so I had to drop that entirely. .  I temporarily got around this by subsetting data, but I had a similar error later when trying to apply a model fit to a forecast. .  The moral of the story is that R functions use a lot more memory than the size of the incoming vector itself, as suggested by @Justin above, measured with \"object.size\". Similarly for functions running out of RAM during processing operations. .  ",
      "P-tags": "data tabl linux memory-manag r",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP"
    },
    {
      "id": "so_11032902",
      "task": "bash - Directly returning the return value from calling a function",
      "P-task": "bash - directli return return valu call function",
      "F_verb": "return",
      "P-body": "In these modifications of your example, I change the argument to \"foo\" to make it easier to distinguish the result of one from the other. .  The preceding will output \"2\". The \"echo\" in \"foo\" is used as the return value of \"bar\". The range of values that \"return\" (and \"exit\") can handle is 0 to 255. .  The second version will first output 2 since that's what \"foo\" does then a 1 will be output since that's the return value of \"bar\" having been propagated from the return value of \"foo\". .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from S_ING"
    },
    {
      "id": "ul_504550",
      "task": "Rename files with zero padded numbers while keeping extension using \"rename\" command",
      "P-task": "renam file zero pad number keep extens use renam command",
      "F_verb": "rename",
      "P-body": " This would probably do what you intended. Instead of putting the Perl code inside the substitution, we run it before the substitution. .  The regular expression \"[^.]*\" would match any length string up to (but not including) the first dot in the filename. .  To match up to the last dot, use \".*\\.\" instead, and insert the dot on the replacement side: .  Note that this would also rename directories. .   Alternatively, using a simple shell loop, assuming you would want to enumerate the files in the order they are expanded by the \"*\" shell glob, and that you use \"bash\": .  This additionally skips any name that does not refer to a regular file (or a symbolic link to one). Apart from that, it follows very closely the Perl \"rename\" variation above in that it keeps a counter (\"n\") and a zero-filled variant of the counter (\"zn\"). .  The variable \"n\" is a simple counter, and \"$zn\" is has the same value as \"$n\", but as a zero-filled three-digit number. .  The value of \"$zn.${filename##*.}\" would expand to the zero-filled number, followed by a dot and the final filename suffix of the original filename. If more than one dot is present in the original filename, everything up to the last dot will be replaced by the zero-filled number. Change \"##\" to \"#\" to replace up to the first dot. .  This assumes that you run the loop on files in the current directory only. .  ",
      "P-tags": "renam command-lin",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_19920035",
      "task": "awk script: find and print max value and file name containing max value",
      "P-task": "awk script : find print max valu file name contain max valu",
      "F_verb": "find",
      "P-body": "awk script: .  use as \"awk -f <file.awk> sample-file*\". .  Could probably be more efficient with \"nextfile\" after the \"fn\" assignment in the FNR block or similar mechanisms to short-circuit the rest of the other lines in each input file. .  zcat and shell .  ",
      "P-tags": "sed awk shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_144692",
      "task": "How can I disable a part of the screen in X.Org",
      "P-task": "disabl part screen x org",
      "F_verb": "disable",
      "P-body": "You can use \"xrandr\". .  I have tested this breathy on a single monitor. .  First look at current resolution and subtract 228 from X. Replace X and Y below for new resolutions Y=y, X=x-228. note in the text below lower case x is a literal x). Run \"xrandr\" to get output name. .  Then \"xrandr --fb XxY --output OUTPUT_NAME --transform 1,0,-228,0,1,0,0,0,1\" .  ",
      "P-tags": "linux i3 xorg",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_17808790",
      "task": "How can I specify the type of a parameter when the object type is from a web service?",
      "P-task": "specifi type paramet object type web servic",
      "F_verb": "specify",
      "P-body": "Do you try with \"[object]\" or \"[psbject]\" ? .  ",
      "P-tags": "powershel powershell-3 0",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP when S"
    },
    {
      "id": "so_52089427",
      "task": "Get-ADUser Filter parameter matching second time around",
      "P-task": "get-adus filter paramet match second time around",
      "F_verb": "get",
      "P-body": "Using the filter is a little finicky within AD. It is actually \"-filter <string>\" .  \"where-object\" is the other type of filter syntax you were attempting to use. E.G. \"where-object {UserPrincipalName -like \"$user*\"}\" .  ",
      "P-tags": "powershel active-directori",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_1074419",
      "task": "Cannot change keyboard backlight with dbus-send",
      "P-task": "chang keyboard backlight dbus-send",
      "F_verb": "change",
      "P-body": "As you said you are using \"0.99.8-2\" version of \"upower\" package. .  In the last update of \"upower\" many distribution users, like Debian unstable, Arch linux, Ubuntu cosmic, have encountered this problem. .  For example this issue is related yours, has opened in \"upower\" GitLab page. .  According to that link, this method should be solve your problem (which has solved my problem on debian sid): .  1.Make override configuration for \"upower\" service: .  2.Write these lines in it: .  3.Check the changes by this command: .  If you see this output, you did it right: .  For more details about \"ProtectKernelTunables=\" parameter, you can see this link. .  4.Reboot your system (also you can restart \"upower\" and \"dbus\" services but its better reboot system to restart all services completely). .  5.Check your keyboard backlight. Now you should not see somethigs like this, in the output of \"journalctl | grep -i upowerd\" command: .  And your keyboard backlight should be change with Fn + F3 and Fn + F4 key combinations or dbus command: .  ",
      "P-tags": "backlight shortcut-key bright keyboard keyboard-layout",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP with NP"
    },
    {
      "id": "so_39507729",
      "task": "How to make a script connect and and run some command to EC2?",
      "P-task": "make script connect run command ec2",
      "F_verb": "make",
      "P-body": "you can do it this way .  and have a local file \"your_script.sh\" with all the command you want to run on the ec2 instance .  ",
      "P-tags": "amazon-web-servic ubuntu-16 04",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_35191776",
      "task": "Using sed to find-and-replace in a text file using strings from another text file",
      "P-task": "use sed find-and-replac text file use string anoth text file",
      "F_verb": "find",
      "P-body": "Just to complete your set of options, you can do this in pure bash, slowly: .  Note that this likely won't work as expected if you include places that are inside other places, for example \"niagara on the lake\" which is in \"on\": .  Instead, you might want to do more targeted pattern matching, which will be much easier in awk: .  This works for me using the data in your question: .  You may have a problem if your places file contains an actual non-province comprising two letters. I'm not sure if such things exist in Canada, but if they do, you'll either need to tweak such lines manually, or make the script more complex by handling provinces separately from cities. .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP using NP from NP"
    },
    {
      "id": "so_688152",
      "task": "Powershell . Declare generic list with class defined using 'Add-Type'",
      "P-task": "powershel\ndeclar gener list class defin use add-typ",
      "F_verb": "declare",
      "P-body": "This is a bug in New-Object. This will help you create them more easily: http://www.leeholmes.com/blog/2006/08/18/creating-generic-types-in-powershell .  UPDATE: PowerShell added support for this in Version 2: .  ",
      "P-tags": "gener collect powershel",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "so_30330859",
      "task": "Creating HTTP site on llinux",
      "P-task": "creat http site llinux",
      "F_verb": "create",
      "P-body": "You probably have to change the permissions of the document. Try the chmod command to change the permissions to be accessible to the web. .  See https://serverfault.com/questions/357108/what-permissions-should-my-website-files-folders-have-on-a-linux-webserver for more details .  ",
      "P-tags": "http linux apach",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_608927",
      "task": "rsync --compare-dest, not expedted result",
      "P-task": "rsync -- compare-dest expedt result",
      "F_verb": "compare",
      "P-body": " Is there a way to only copy the files that are the diff between the directories? .   Yes. In your case all that's missing is that the comparison directory is relative to the destination. The same issue applies to link directories. The solution here is to use an absolute path .  Scenario .  Test run, copying files from \"testdiff1\" to \"changed\", but only those that are neither up-to-date in \"testdiff2\" nor in \"changed\" .  Output .  Evidence .  Note that if you copy between directories that look like they are on the local system, \"rsync\" will effectively degrade to making full copies (or none). If you run \"rsync\" across a network connection it can run an instance of itself at each end and you'll get the benefit of having only changes transferred. .  ",
      "P-tags": "cento rsync",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "so_42200016",
      "task": "Using sed, can I make changes only to the regex match portion of a line?",
      "P-task": "use sed make chang regex match portion line",
      "F_verb": "make",
      "P-body": "If \"perl\" is available: .   \"g\" modifier to replace all occurrences of matched text \"e\" evaluation modifier allows to use Perl code in replacement section of substitute \"$&=~s|this|that|gr\" expression to perform substitution only in matched text, \"r\" modifier gives back result without changing value of \"$&\"  Further reading: .   http://perldoc.perl.org/perlrequick.html http://perldoc.perl.org/perlrun.html#Command-Switches  ",
      "P-tags": "awk centos7 regex bash sed",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "so_30900385",
      "task": "How To Restore a Missing Redis Service",
      "P-task": "restor miss redi servic",
      "F_verb": "restore",
      "P-body": "Do you want to remove redis old package you can use yum remove command as below. .  then check it still available as below  .  and also check files  .  if its there you can remove as below. .  (or you can mention package full name with versions) .  then you can install new version which you want. .  then run .  or you can download rpm and install it as below .  but better to use yum because its going with all dependences. .  ",
      "P-tags": "redi linux cento",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP"
    },
    {
      "id": "ul_450153",
      "task": "tar --exclude '*/logs' doesn't work",
      "P-task": "tar -- exclud log work",
      "F_verb": "exclude",
      "P-body": "With GNU tar (v. 1.29), it works for me with \"tar cvf foo.tar --exclude \"*/logs\" servers\". .  It seems that the \"--exclude\" option only applies to paths listed after it on the command line, so this would not exclude \"a/logs\": .  I can't see that mentioned explicitly in the man page though (but the synopsis lists options before files, as usual). .  ",
      "P-tags": "tar",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_290059",
      "task": "How to load custom Linux kernel module that is not Linux kernel version dependant using RPM",
      "P-task": "load custom linux kernel modul linux kernel version depend use rpm",
      "F_verb": "load",
      "P-body": "Instead of a service to do the \"insmod\" you could provide a \"/lib/modprobe.d/mymodule.conf\" with the line .   I tried this and it worked ok on a fedora 22 using as an example the existing \"slip\" module. .  ",
      "P-tags": "kernel-modul modprob",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP that S using NP"
    },
    {
      "id": "ul_604667",
      "task": "building DNS server on linux redhat 7.x",
      "P-task": "build dn server linux redhat 7 x",
      "F_verb": "build",
      "P-body": "So your question is around \"want to be sure that we choose the best and the right DNS server for rhel 7.x\". .  This seems to be an opinion based question. .  My opinion is that as you've paid for RHEL license, might as well use the \"bind\" RPMs that come with RHEL. .  You've got commercial support there, you can raise support cases with RH vendor directly, plus RH will be shipping fixes to the product throughout the RHEL 7 lifecycle. .  ",
      "P-tags": "resolv conf rhel dn resolut",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "so_62358247",
      "task": "nodejs failed but bash doesn't stop even I have set -e",
      "P-task": "nodej fail bash stop even set -e",
      "F_verb": "stop",
      "P-body": "Your node.js file failed, though bash script executed it succesfully. Read and compare status code: .  ",
      "P-tags": "node js npm jenkin bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V even S"
    },
    {
      "id": "ul_127585",
      "task": "Can I use two sets of I/O devices for two user sessions on one computer?",
      "P-task": "use two set devic two user session one comput",
      "F_verb": "use",
      "P-body": "There is a guide on Linux Gazette for a six-headed X11 system. .  It works by giving a different \"ServerLayout\" in the \"xorg.conf\", grouping the different screen, mouse, keyboard. Each screen has its own GDM instance/session.  .  ",
      "P-tags": "linux multiseat consol xorg",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of NP for NP on NP"
    },
    {
      "id": "so_46475126",
      "task": "Can't update version tag in docker compose file with sed",
      "P-task": "updat version tag docker compos file sed",
      "F_verb": "update",
      "P-body": "Just made a small change(moved colon): .  ",
      "P-tags": "awk sed bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_9217185",
      "task": "How do I use grep to search the current directory for all files having the a string \"hello\" yet display only .h and .cc files?",
      "P-task": "use grep search current directori file string hello yet display h cc file",
      "F_verb": "search",
      "P-body": " This reads: search recursively (in all sub directories also) for all .cc OR .h files that contain \"hello\" at this \".\" (current) directory  .  From another stackoverflow question .  ",
      "P-tags": "linux grep unix bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP for NP"
    },
    {
      "id": "so_13334238",
      "task": "Bash: add object to a json file",
      "P-task": "bash : add object json file",
      "F_verb": "add",
      "P-body": "\"ed\" is the standard text editor. .  Don't know why you want to use bash for that, though, there are much better tools around! .  Done. .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_14505797",
      "task": "Jenkins failed build: I Want it to pass",
      "P-task": "jenkin fail build : want pass",
      "F_verb": "build",
      "P-body": "\"command || exit 1\" means \"If \"command\" failed, then \"exit 1\" (i.e with failure) .  You just said that you want build to fail if your command was successful, so you need: \"command && exit 1 || exit 0\" .  Above, if \"command\" is successful, then build is marked as failed, else (if \"command\" was not successful), mark the build as success .  Here is the console output for the job: .  This is the build steps in my configuration: .  ",
      "P-tags": "rubi jenkin cucumb bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP to NP"
    },
    {
      "id": "su_1067128",
      "task": "How to find & replace a pattern with string in ruby?",
      "P-task": "find replac pattern string rubi",
      "F_verb": "find",
      "P-body": " ",
      "P-tags": "rubi shell regex",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_23022455",
      "task": "AWK Include Whitespaces in Command",
      "P-task": "awk includ whitespac command",
      "F_verb": "include",
      "P-body": "To execute the sum command .  ",
      "P-tags": "awk solari command unix",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP in NP"
    },
    {
      "id": "so_61129142",
      "task": "When use write-through cache policy for pages",
      "P-task": "use write-through cach polici page",
      "F_verb": "use",
      "P-body": " Can every cache (L1, L2, LLC) work in either write-back or write-through mode? .   In most x86 microarchitectures, yes, all the data / unified caches are (capable of) write-back and used in that mode for all normal DRAM. Which cache mapping technique is used in intel core i7 processor? has some details and links. Unless otherwise specified, the default assumption by anyone talking about x86 is that DRAM pages will be WB. .  AMD Bulldozer made the unconventional choice to use write-through L1d with a small 4k write-combining buffer between it and L2. https://www.realworldtech.com/bulldozer/8/). This has many disadvantages and is I think widely regarded (in hindsight) as one of several weaknesses or even design mistakes of Bulldozer-family (which AMD fixed for Zen). Note also that Bulldozer was an experiment in CMT instead of SMT (two weak integer cores sharing an FPU/SIMD unit, each with separate L1d caches sharing an L2 cache) https://www.realworldtech.com/bulldozer/3/ shows the system architecture. .  But of course Bulldozer L2 and L3 caches were still WB, the architects weren't insane. WB caching is essential to reduce bandwidth demands for shared LLC and memory. And even the write-through L1d needed a write-combining buffer to allow L2 cache to be larger and slower, thus serving its purpose of sometimes hitting when L1d misses. See also Why is the size of L1 cache smaller than that of the L2 cache in most of the processors? .  Write-through caching can simplify a design (especially of a single-core system), but generally CPUs moved beyond that decades ago. Write-back vs Write-Through caching?). IIRC, some non-CPU workloads sometimes benefit from write-through caching, especially without write-allocate so writes don't pollute cache. x86 has NT stores to avoid that problem. .   So if the page attribute is set to write-through, then they all will be write-through? .   Yes, every store has to go all the way to DRAM in a page that's marked WT. .  The caches are optimized for WB because that's what everyone uses, but hopefully do support passing on the line to outer caches without evicting from L1d. So WT doesn't necessarily turn stores into something like \"movntps\" cache-bypassing / evicting stores. But check on that; apparently on some CPUs, like Pentium Pro family at least, a WT store hit in L1 updates the line, but a WT hit in L2 evicts the line instead of bringing it in to L1d.) .   When should a page be set to write-through? What are the advantages to that? .   Basically never; (almost?) all CPU workloads do best with WB memory. .  OSes don't even bother to make it easy (or possible?) for user-space to allocate WC or WT DRAM pages. Although that certainly doesn't prove they're never useful.) e.g. on CPU cache inhibition, I found a link about a Linux patch that never made it into the mainline kernel that added the possibility of mapping a page WT. .  WB, WC, and UC are common for normal DRAM, device memory (especially GPU), and MMIO respectively. .  I have seen at least one paper that benchmarked WT vs. WB vs. UC vs. WC for some workload (googled but didn't find it, sorry). And people testing obscure x86 stuff will sometimes include it for completeness. e.g. The Microarchitecture Behind Meltdown is a good article in general (and related to what you're reading up on). .  One of the few advantages of WT is that stores end up in L3 promptly where loads from other cores can hit. This may possibly be worth the extra cost for every store to that page, especially if you're careful to manually combine your writes into one large 32-byte AVX store. Or 64-byte AVX512 full-line write.) And of course only use that page for shared data. .  I haven't seen anyone ever recommend doing this, though, and it's not something I've tried. Probably because the extra DRAM bandwidth for writing through L3 as well isn't worth the benefit for most use-cases. But probably also because you might have to write a kernel module to get a page mapped that way. .  And it might not even work quite this way, if CPUs evict from outer caches on an L2 or L3 hit for a WT store, like @Lewis comments that PPro is documented to do. .  So maybe I'm wrong about the purpose of WT, and it's intended (or at least usable) for device-memory use-cases, like maybe parts of video RAM that GPU won't modify. .  ",
      "P-tags": "page-t cpu-cach cpu-architectur linux-kernel x86",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP"
    },
    {
      "id": "au_684106",
      "task": "Ubuntu 14.4.3 how to fix wifi on lenovo yoga 2 11",
      "P-task": "ubuntu 14 4 3 fix wifi lenovo yoga 2 11",
      "F_verb": "fix",
      "P-body": "Install the proprietary BROADCOM Linux drivers.  .  Open a terminal and execute:  .  When you don't have Internet access or cannot connect to a router via Ethernet adapter - install BROADCOM Wireless Linux STA drivers offline, following this guide from @Pilot6: offline install .  ",
      "P-tags": "broadcom wireless",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "so_11829470",
      "task": "Create and execute an R script just like perl -e to script R in a shell such as bash?",
      "P-task": "creat execut r script like perl -e script r shell bash",
      "F_verb": "create",
      "P-body": "Yes there is. You can use \"Rscript\": .  ",
      "P-tags": "perl r bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP to NP in NP as NP"
    },
    {
      "id": "so_35314602",
      "task": "Compile and run java program with mutiple external jar files",
      "P-task": "compil run java program mutipl extern jar file",
      "F_verb": "compile",
      "P-body": "If you want to add directory while contains all the required jars for running/ compiling your Java file you can use below command: .  In Windows: .   java -classpath \".;c:\\lib*\" MainClass .   In UNIX/ Linux .   java -classpath \".:/lib/*\" MainClass .   Note: In windows \";\" (semicolon) is the separator, while in UNIX/ Linux \":\" (colon) is the separator for multiple jar for directory .  \".\" (dot) represents current directory .  ",
      "P-tags": "javac linux java javacompil apache-poi",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP with NP"
    },
    {
      "id": "so_64761222",
      "task": "Can two IoT applications access a cellular modem at the same time so I don't have to kill ModemManager and lose my internet connection?",
      "P-task": "two iot applic access cellular modem time kill modemmanag lose internet connect",
      "F_verb": "kill",
      "P-body": "I think I've mostly figured it out now, without having to kill ModemManager (which risks killing the internet connection on the IoT remote gateways). .  The main answer is that I'm simply not getting a GPS fix (permissions issues aside). .  I wasn't doing anything wrong in my Python code, and sometimes ModemManager was using the AT port I was sending commands to (either \"/dev/ttyUSB2\" or \"/dev/ttyUSB3\")... Upgrading ModemManager to v1.10.0 also might work, but I'm reluctant to do that on a live gateway working in the field. .  @rm5248 suggested using the dedicated NMEA port at \"/dev/ttyUSB1\" on a SIMCom 7600 like mine, and he was right, I think. .  I installed GPSD (GPSDaemon) and the various clients for it (e.g. cgps and gpsmon) using this documentation. GPSD and its clients are excellent for getting GPS info, if the GPS has a fix. .  How to test the GPSD software: https://gpsd.gitlab.io/gpsd/installation.html#_how_to_test_the_software .  Then run one of the following two clients and watch the dedicated NMEA port on \"/dev/ttyUSB1\", as opposed to an \"AT\" port at \"/dev/ttyUSB2\" or \"/dev/ttyUSB3\": .  On a working gateway \"cgps\" works like this:  .  And \"gpsmon /dev/ttyUSB1\" works like this:  .  But on a non-working gateway \"cgps\" looks like this, showing \"NO FIX\":  .  ",
      "P-tags": "serial-port linux python modem gp",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "so_55780390",
      "task": "How to pass encrypted message and passphrase when using `os.system` to call gpg?",
      "P-task": "pass encrypt messag passphras use os system call gpg",
      "F_verb": "pass",
      "P-body": "To input the encrypted string, you can \"echo\" it out first then pipe in the \"gpg\" command.  .  To input the passphrase, there are a number of ways depending on your env and gpg version. What worked on my Ubuntu 18.04.2 with gpg 2.2.4 was to use \"--pinentry-mode=loopback\" and then passing in \"--passphrase\": .  The Python code will then look something like this: .  But putting the actual \"--passphrase-yourpassphrase\" is very insecure. An alternative is to put the passphrase in some file then use \"--passphrase-file\" option instead. .  I don't know where you got the encrypted message, but I usually work with encrypted files. If the encrypted input is from a file, just replace \"echo <string>\" with \"cat <filepath>\": .  ",
      "P-tags": "gnupg ubuntu encrypt python-3 x",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP when S"
    },
    {
      "id": "so_63168815",
      "task": "producer / consumer task. Problem with correct writing to shared buffer",
      "P-task": "produc consum task\nproblem correct write share buffer",
      "F_verb": "share",
      "P-body": "It is not fun to try and unravel uncommented code someone else has written, so instead, I'll explain a verified working scheme. .  (Note that comments should always explain programmer intent or idea, and never what the code does; we can read the code to see what it does. The problem is, we need to first understand the programmer idea/intent first, before we can compare that to the implementation. Without comments, I would need to first read the code to try and guess at the intent, then compare that to the code itself; it's like double the work.) .  (I suspect OP's underlying problem is trying to use semaphore values as buffer indexes, but didn't pore through all of the code to be 100% certain.) .  Let's assume the shared memory structure is something like the following: .  and we have \"struct shared *mem\" pointing to the shared memory area. .  Note that you should, at runtime, include \"<limits.h>\", and verify that \"MAX_ITEMS <= SEM_VALUE_MAX\". Otherwise \"MAX_ITEMS\" is too large, and this semaphore scheme may fail. \"SEM_VALUE_MAX\" on Linux is usually \"INT_MAX\", so big enough, but it may vary. And, if you use \"-O\" to optimize when compiling, the check will be optimized completely away. So it is a very cheap and reasonable check to have.) .  The \"mem->lock\" semaphore is used like a mutex. That is, to lock the structure for exclusive access, a process waits on it. When it is done, it posts on it. .  Note that while \"sem_post(&(mem->lock))\" will always succeed (ignoring bugs like \"mem\" being NULL or pointing to uninitialized memory or having been overwritten with garbage), technically, \"sem_wait()\" can be interrupted by a signal delivery to an userspace handler installed without \"SA_RESTART\" flag. This is why I recommend using a static inline helper function instead of \"sem_wait()\": .  In cases where signal delivery should not interrupt waiting on the semaphore, you use \"semaphore_wait()\". If you do want a signal delivery to interrupt waiting on a semaphore, you use \"sem_wait()\"; if it returns \"-1\" with \"errno == EINTR\", the operation was interrupted due to signal delivery, and the semaphore wasn't actually decremented. Many other low-level functions, like \"read()\", \"write()\", \"send()\", \"recv()\", can be interrupted in the exact same way; they can also just return a short count, in case the interruption occurred part way.) .  The \"semaphore_post()\" is just a wrapper, so that you can use \"matching` post and wait operations. Doing that sort of \"useless\" wrappers does help understand the code, you see. .  The \"item[]\" array is used as a circular queue. The \"num_items\" indicates the number of items in it. If \"num_items > 0\", the next item to be consumed is \"item[next_item]\". If \"num_items < MAX_ITEMS\", the next item to be produced is \"item[(next_item + num_items) % MAX_ITEMS]\". .  The \"%\" is the modulo operator. Here, because \"next_item\" and \"num_items\" are always positive, \"(next_item + num_items) % MAX_ITEMS\" is always between \"0\" and \"MAX_ITEMS - 1\", inclusive. This is what makes the buffer circular. .  When a producer has constructed a new item, say \"item_type newitem;\", and wants to add it to the shared memory, it basically does the following: .  The above is often called enqueue, because it appends an item to a queue (which happends to be implemented via a circular buffer). .  When a consumer wants to consume an item (\"item_type nextitem;\") from the shared buffer, it does the following: .  This is often called dequeue, because it obtains the next item from the queue. .  I would recommend you first write a single-process test case, which enqueues \"MAX_ITEMS\", then dequeues them, and verifies the semaphore values are back to initial values. That is not a guarantee of correctness, but it takes care of the most typical bugs. .  In practice, I would personally write the queueing functions as static inline helpers in the same header file that describes the shared memory structure. Pretty much .  and .  but note that I wrote these from memory, and not copy-pasted from my test program, because I want you to learn and not to just copy-paste code from others without understanding (and being suspicious of) it. .   Why do we need separate counters (\"first_item\", \"num_items\") when we have the semaphores, with corresponding values? .   Because we cannot capture the semaphore value at the point where \"sem_wait()\" succeeded/continued/stopped blocking. .  For example, initially the \"room\" semaphore is initialized to \"MAX_ITEMS\", so up to that many producers can run in parallel. Any one of them running \"sem_getvalue()\" immediately after \"sem_wait()\" will get some later value, not the value or transition that caused \"sem_wait()\" to return. Even with SysV semaphores you cannot obtain the semaphore value that caused wait to return for this process.) .  So, instead of indexes or counters to the buffer, we think of the \"more\" semaphore as having the value of how many times one can dequeue from the buffer without blocking, and \"room\" as having the value of how many times one can enqueue to the buffer without blocking. The \"lock\" semaphore grants exclusive access, so that we can modify the shared memory structures (well, \"next_item\" and \"num_items\") atomically, without different processes trying to change the values at the same time. .  I am not 100% certain that this is the best or optimum pattern, this is one of the most commonly used ones. It is not as robust as I'd like: for each increment (of one) in \"num_items\", one must post on \"more\" exactly once; and for each decrement (of one) in \"num_items\", one must increment \"next_item\" by exactly one and post on \"room\" exactly once, or the scheme falls apart. .  There is one final wrinkle, though: .   How do producers indicate they are done? How would the scheduler tell producers and/or consumers to stop? .   My preferred solution is to add a flag into the shared memory structure, say \"unsigned int status;\", with specific bit masks telling the producers and consumers what to do, that is examined immediately after waiting on the \"lock\": .  which return \"ENOMSG\" to the caller if the caller should stop. When the state is changed, one should of course be holding the \"lock\". When adding \"STOP_PRODUCING\", one should also post on the \"room\" semaphore (once) to start a \"cascade\" so all producers stop; and when adding \"STOP_CONSUMING\", post on the \"more\" semaphore (once) to start the consumer stop cascade. Each of them will post on it again, to ensure each producer/consumer sees the state as soon as possible.) .  There are other schemes, though; for example signals (setting a \"volatile sig_atomic_t\" flag), but it is generally hard to ensure there are no race windows: a process checking the flag just before it is changed, and then blocking on a semaphore. .  In this scheme, it would be good to verify that both \"MAX_ITEMS + NUM_PRODUCERS <= SEM_VALUE_MAX\" and \"MAX_ITEMS + NUM_CONSUMERS <= SEM_VALUE_MAX\", so that even during the stop cascades, the semaphore value will not overflow. .  ",
      "P-tags": "linux process semaphor c parent-child",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_1305998",
      "task": "I continually get an error when trying to \"make\" suckless terminal",
      "P-task": "continu get error tri make suckless termin",
      "F_verb": "get",
      "P-body": "You have to install necessary development packages for fontconfig.pc, freetype2.pc and X11: .  And then retry compilation. .  ",
      "P-tags": "compil make",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "so_54836187",
      "task": "Find distinct length of string field using mongo shell",
      "P-task": "find distinct length string field use mongo shell",
      "F_verb": "find",
      "P-body": "You can do this with an aggregation pipeline by using \"$strLenCP\" within a \"$group\": .  Output: .  ",
      "P-tags": "mongo-shel mongodb-queri",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP using NP"
    },
    {
      "id": "so_19339110",
      "task": "Why does lseek allow me to set a negative file position?",
      "P-task": "lseek allow set neg file posit",
      "F_verb": "allow",
      "P-body": "I managed to reproduce your \"erroneous\" behaviour. You must include \"unistd.h\" to get the proper prototype. With this include, \"lseek\" behaves as described. .  When you miss this include, the compiler passes an int \"-10\" instead of an off_t \"-10\". This results in your observed behaviour. .  Update: .  The complete list of needed includes is .   \"open(2)\" .   \"lseek(2)\" .   \"printf(3)\", \"perror(3)\" .    ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_67723479",
      "task": "Best way to store large number of outputs from numerical simulations",
      "P-task": "best way store larg number output numer simul",
      "F_verb": "store",
      "P-body": "It's a bit orthogonal, but based on how context-dependant any answer to your question has to be, I think this is appropriate here. .  Considering your hesitation, I would strongly recommend adding a layer of indirection so that you can easily support various formats and/or stuff like having a dedicated file output thread interchangeably. .  Something along those lines should do: .  A few notes: .   The \"final\" keyword. It's useful here to remove the virtual call overhead when using the sink subclasses directly, or when the compiler uses devirtualization. \"DataSink\" is designed to encourage streaming the results as they are generated, as opposed to gathering all data and dumping it at the end of the simulation, which is something you almost certainly want regardless of the final file format. If you want to get fancier, you can also template \"DataSink\" on the \"StepData\" type, as well as templating a simulation run on the sink type.  ",
      "P-tags": "c++ linux databas",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "ul_293844",
      "task": "How to recover a failed KDE4 desktop without deleting the entire ~/.kde4 directory?",
      "P-task": "recov fail kde4 desktop without delet entir kde4 directori",
      "F_verb": "recover",
      "P-body": "No elevated permissions are required, and reboot is unnecessary. .   Kill KDE with \"Ctrl-Alt-Backspace\". Use \"Ctrl-Alt-F2\" (or another Function key as needed) to get a console. Log on as the user that triggered the problem. For safety, backup \"~/.kde4/share/apps/kscreen/????????????????????????????????\" Delete \"~/.kde4/share/apps/kscreen/????????????????????????????????\"  In this specific instance, given the details in the question, the actual file name ws \"cc3277aaebc0a310157f935da894a119\", but the file name changes when the .kde4 folder structure is rebuilt. .  How did I arrive at this conclusion? First, I triggered the desktop failure, killed the KDE with \"Ctrl-Alt-Backspace\", renamed the broken copy of \"~/.kde\", restarted KDE, then diff'd the good directory with a broken one: .  Differences in only one file seemed certain to be related: .  Notice the difference seems small and innocuous: 59.9502 vs. 59.8846 .  Most of other file differences result from a creation date and show no functional difference, or are related to application environment rather than the desktop manager. One mentioned the \"Desktop\", but the difference was only in GUID - hardly likely to be directly related to the problem. .  To test my hypothesis, I saved a good copy of \".kde4/share/apps/kscreen/cc3277aaebc0a310157f935da894a119\", triggered the desktop failure, and instead of deleting the file, I copied the known good file over the one that was changed after the system failed. KDE recovered. .  Next, since most people won't have a good copy of the file on hand, I decided to try deleting it instead of \"fixing\" it. Deleting the file also recovered the desktop. .  ",
      "P-tags": "linux kde4 display-manag display-set",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP without S_ING"
    },
    {
      "id": "au_391794",
      "task": "Convert \"H264 MP4 AVC (part 10) (avc1)\"/\"MPEG AAC 48kHz\" 1080p 23.976000fps videos to 720p, as complete quality as possible",
      "P-task": "convert h264 mp4 avc part 10 avc1 mpeg aac 48khz 1080p 23 976000fp video 720p complet qualiti possibl",
      "F_verb": "convert",
      "P-body": "1. Get \"ffmpeg\" It is always a good idea to use a recent build when encoding with \"ffmpeg\". Development is very active and using a recent build will allow you to avoid fixed bugs while giving you access to the latest features. .  There are two main methods to get \"ffmpeg\" and neither will interfere with packages from the repository including the so-called \"ffmpeg\" package: .  Using a static build This is simply a binary that someone else compiled. All you do is download, extract, and run it (note the \"./\" before \"ffmpeg\"): .  Compiling \"ffmpeg\" When compiling you control exactly how \"ffmpeg\" is configured and also allows you to use certain encoders, such as \"libfdk_aac\", that are not available in the static builds. .  Just follow a step-by-step guide: How to Compile FFmpeg on Ubuntu. If you can copy and paste you can compile \"ffmpeg\". .   2. Encode In this example: .   The \"scale\" filter to resize the video. With \"scale\" you can just declare one dimension, height in this case, and use \"-1\" in the other. \"ffmpeg\" will then automatically calculate the correct value while maintaining the aspect ratio. .  The encoder \"libx264\" will produce H.264 video. Quality is controlled with \"-crf\". The range is a log scale of 0 to 51. 0 is lossless (files will likely be huge), 18 is often considered to be \"visually lossless\", 23 is default, and 51 is worst quality. Generally you use the highest value that still gives you an acceptable quality. .  Video encoding speed/compression efficiency for this encoder is controlled with the \"-preset\". These are: ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow. Default is \"medium\". Generally you use the slowest preset that you have patience for. .  For a set of videos use the same \"-crf\" and \"-preset\" for all of them. .  The audio will be stream copied from the input to the output. Think of it like a copy and paste. .  The Matroska output container will be used. It supports more formats not it is not as widely supported by players and devices as MP4 for example. .   Encoding all videos You can use a bash \"for loop\" to encode all videos in a directory: .   Also see  FFmpeg and x264 Encoding Guide FFmpeg and AAC Encoding Guide  ",
      "P-tags": "ffmpeg hd-video avconv convers",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP as NP"
    },
    {
      "id": "ul_170390",
      "task": "Replace string repeatedly",
      "P-task": "replac string repeatedli",
      "F_verb": "replace",
      "P-body": "With GNU \"sed\": .  or .  or .  or in pure bash: .  Output: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "so_51865524",
      "task": "How do I populate an array with get-process results in powershell",
      "P-task": "popul array get-process result powershel",
      "F_verb": "populate",
      "P-body": "\"Get-Process\" can take wildcards in the \"Name\" parameter. So you just need to loop over the object and output the properties you are looking for. .  You could also get rid of all of the \"Read-Host\" and \"Write-Host\" for a more PowerShelly feel. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_30976609",
      "task": "Jmeter BeanShell - compare between int to counter",
      "P-task": "jmeter beanshel - compar int counter",
      "F_verb": "compare",
      "P-body": "Option 1: use integers everywhere .  Change this line: .  To: .  Option 2: use strings everywhere .  JMeterVariables can be either Strings or Objects, so you need to cast them to the types you need to work with.  .  See How to use BeanShell: JMeter's favorite built-in component guide for essential information on scripting in JMeter and some form of cookbook. .  ",
      "P-tags": "beanshel jmeter",
      "source": "qa",
      "cate": "compare",
      "pat": "V between NP to NP"
    },
    {
      "id": "so_63262249",
      "task": "Cannot bind argument to parameter 'Path' because it is null. poweshell",
      "P-task": "bind argument paramet path null\npoweshel",
      "F_verb": "bind",
      "P-body": "Enclose your variables values with double quotes. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_185193",
      "task": "remove the low version number of file",
      "P-task": "remov low version number file",
      "F_verb": "remove",
      "P-body": "It can be done by GNU \"ls\"+\"awk\" one-liner: .  Explanation: the file names are passed as input to the awk script. The options \"-vr\" cause the file names to be sorted as version numbers in reverse order, so e.g. \"foo-1.9.depot\" comes after \"foo-1.10.depot\". The awk script stores the first part of the name (up to the first \"-\") in the variable \"name\". When the first part of the current name is identical to the first part of the previous name, the script invoked \"rm\" to delete the current file (which is an older version). .  ",
      "P-tags": "rm filenam shell-script bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "so_59939899",
      "task": "Adding If / If Not statement into PowerShell",
      "P-task": "ad statement powershel",
      "F_verb": "add",
      "P-body": "Since you have an array of files that you want to do the same set of commands for. Then use simple loop either using \"foreach\" or \"ForEach-Object\". .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_58811542",
      "task": "get the core file in perl script with backtick",
      "P-task": "get core file perl script backtick",
      "F_verb": "get",
      "P-body": "\"ulimit -c 0\" prevents core files to be written. You need to use \"ulimit -c unlimited\" .  Btw: you should upgrade to a maintained OS. .  ",
      "P-tags": "linux perl unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_66215158",
      "task": "Using awk, subtract with previous row in all columns and print the result",
      "P-task": "use awk subtract previou row column print result",
      "F_verb": "print",
      "P-body": "You may use this \"awk\": .  To make it more readable: .  ",
      "P-tags": "awk linux shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_7088838",
      "task": "mount failed, errno is 20?",
      "P-task": "mount fail errno 20",
      "F_verb": "mount",
      "P-body": "Error 20 is ENOTDIR (http://www-numi.fnal.gov/offline_software/srt_public_context/WebDocs/Errors/unix_system_errors.html). .  I think with MS_BIND, you would need the first argument to be an actual directory somewhere, not a device. See also the man page for mount  .  What you are trying to do would be equivalent to \"sudo mount --bind /dev/sdb /home/abc/work/temp\" which will give you an error too. .  ",
      "P-tags": "mount linux",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "su_1204331",
      "task": "Kubuntu 16.10 GUI cannot load, need console access",
      "P-task": "kubuntu 16 10 gui load need consol access",
      "F_verb": "load",
      "P-body": "As soon as you reach the command line that says \"Ubuntu 16.10 caroline tty1\" press the keyboard combination Ctrl+Alt+F3 as fast as you can to bring up the console screen and then you can login from the console screen. This is impossible to do in one second unless you prepare yourself in advance by placing your fingers over the three keys. Alternatively you can also use Ctrl+Alt+F3 to bring up the console at any time. Try it and see.  .  Once you see the console screen you can exit from the console screen by pressing Ctrl+Alt+F7 or reboot the system with \"sudo reboot\". In Ubuntu 17.10 and later press the keyboard shortcut Ctrl+Alt+F2 to exit from the virtual console.  .  ",
      "P-tags": "ubuntu kubuntu",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_21896203",
      "task": "How can I tell if a process is currently forking at runtime?",
      "P-task": "tell process current fork runtim",
      "F_verb": "tell",
      "P-body": "The POSIX definition specifies: .   From the application's perspective, a fork() call should appear atomic. .   Thus, in theory nothing else (malloc or otherwise) can happen in parallel. .  In practice, using \"pthread_atfork()\" to provide your own callbacks to maintain an \"is_forking\" flag; you can set this flag when the \"prepare\" callback is invoked, and clear it when the \"parent\" or \"child\" callbacks are invoked. .  ",
      "P-tags": "linux fork",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "au_653007",
      "task": "New laptop install not recognising GTX980M",
      "P-task": "new laptop instal recognis gtx980m",
      "F_verb": "install",
      "P-body": "Your new Nvidia adapter needs new drivers. You can install them by running in terminal .  and reboot. .  The driver that comes with Ubuntu 14.04.3 \"nvidia-340\" or the previous \"nvidia-331\" do not support that adapter. .  ",
      "P-tags": "14 04 driver nvidia",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V S_ING"
    },
    {
      "id": "ul_562851",
      "task": "PHP: capture a multiline substring",
      "P-task": "php : captur multilin substr",
      "F_verb": "capture",
      "P-body": "ok, i found a solution to do this: .  Recommendations for improvements are welcome! .  ",
      "P-tags": "string php regular-express",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_50519225",
      "task": "How to run a CMD Through Invoke-Command",
      "P-task": "run cmd invoke-command",
      "F_verb": "run",
      "P-body": " There's no need for creating an explicit session: you can pass the target computer name directly to \"Invoke-Command -ComputerName <computerName>\". .  Invoking a command whose name / path is stored in a variable requires \"&\", the call operator. .  The script block passed to \"Invoke-Command -ComputerName ...\" is executed remotely, so you cannot directly use local variables in it; in PSv3+, the simplest way to solve this problem is to use the \"using\" scope: \"$using:<localVarName>\"  .   Keeping all these points in mind, we get: .  ",
      "P-tags": "invok powershel variabl",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP through NP"
    },
    {
      "id": "ul_17955",
      "task": "How to find human-readable information about file types recognized by `file`?",
      "P-task": "find human-read inform file type recogn file",
      "F_verb": "find",
      "P-body": "The type detection information isn't actually embedded in the file program, the file program just reads the magic file and then searches the signatures in that file to see what matches. .  The magic file exists both as a compiled version, \"magic.mgc\", and as the original source that is human readable and is just called \"magic\". On my Fedora based systems these can be found at: .  More information on the format of the file can be found in the \"magic(5)\" manual page. .  ",
      "P-tags": "file-command freedesktop file",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP about NP by NP"
    },
    {
      "id": "au_1182252",
      "task": "How to make a Bash script to change the format of a date in a CSV file",
      "P-task": "make bash script chang format date csv file",
      "F_verb": "make",
      "P-body": "With miller, using its builtin \"strptime\" and \"strftime\" functions : .  ",
      "P-tags": "script csv text-process bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF of NP in NP"
    },
    {
      "id": "ul_19491",
      "task": "How to specify characters using hexadecimal codes in `grep`?",
      "P-task": "specifi charact use hexadecim code grep",
      "F_verb": "specify",
      "P-body": "Look at grep: Find all lines that contain Japanese kanjis. .  Text is usually encoded in UTF-8; so you have to use the hex vales of the bytes used in UTF-8 encoding. .  and .  are equivalent, and they perform a locale-based matching (that is, matching is dependent on the sorting rules of Devanagari script (that is, the matching is NOT \"any char between \\u0905 and \\0935\" but instead \"anything sorting between Devanagari A and Devanagari VA\"; there may be differences. .  (\"$'...'\" is the \"ANSI-C escape string\" syntax for bash, ksh, and zsh. It is just an easier way to type the characters. You can also use the \"\\uXXXX\" and \"\\UXXXXXXXX\" escapes to directly ask for code points in bash and zsh.) .  On the other hand, you have this (note -P): .  that will do a binary matching with those byte values. .  ",
      "P-tags": "unicod character-encod grep shell",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP using NP in NP"
    },
    {
      "id": "so_55673923",
      "task": "shell job to compress & delete logs, once in a month",
      "P-task": "shell job compress delet log month",
      "F_verb": "compress",
      "P-body": "The first problem to solve is the fact that you want a more generic function that can be run any month and produce the correct result. A good tool to get the information you need(Abbreviated month and last two digits of the year) is \"date\". .  When run on April 1st, 2019 will produce \"Mar\". .  When run on April 1st, 2019 will produce \"Mar19\". .  Now that we know how to get the information we want, placing the \"date\" commands in the \"tar\" command will automatically produce what the result you're looking for. .  The last issue that exists is scheduling, which can be solved using \"cron\". The below statement will run \"/bin/foobar\", on the 5th day of every month when added to your crontab file. \"crontab -e\" to edit your crontab file) .  Combining everything together, you get: .  Don't forget to escape the %'s in the crontab .  ",
      "P-tags": "cron-task unix cron shell bash",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_394973",
      "task": "Why would I want to disable Copy-On-Write while creating QEMU Images?",
      "P-task": "would want disabl copy-on-writ creat qemu imag",
      "F_verb": "disable",
      "P-body": "The performance degradation with VM images on BTRFS is not merely due to a lot of file writes; as far as BTRFS is concerned the writes are to the same file. The issue arises from a lot of random writes to the same file. These are writes which occur throughout the file.  .  In a nutshell, random writes interfere with BTRFS' COW resulting in file fragmentation, which in turn causes read performance degradation. If you have an image file on hand, you can check for file fragmentation with \"filefrag\".  .  Note this is not an issue with just VM images. It affects any file written to at random file offsets, such as the SQLite databases used by Firefox. .  Solutions/work-arounds There are a few things you can do about file fragmentation on BTRFS. Choose one of the following: .   Mount the filesystem with \"nodatacow\", which disables COW through the entire filesystem. Although really, it avoids using COW unless it absolutely has to (such as creating a snapshot). Use \"chattr\" to disable COW on the directory containing the files in question, and then recreate the files since the \"chattr\" doesn't apply to existing files. Periodically run \"btrfs fi defrag\" against the files in question. Mount the filesystem with \"autodefrag\" to automatically defrag the filesystem.  The first two options disables COW while the last two allows COW but cleans things up after-the-fact. The BTRFS COW and the QEMU COW should not interfere, it'd just be extra slow :)  .  My personal experience In my experience with SQLite database files ... .   \"nodatacow\" - Haven't tried it. \"chattr\" - I ended up with fragmented files anyway. \"btrfs fi defrag\" - I did this for a while to test the concept. \"autodefrag\" - I've been using this quite successfully.  For QEMU images, I use LVM volumes instead of image files. So I don't deal with the COW issue at all. .  Resources Recommended reading to get a better sense of how COW works on BTRFS. .   https://btrfs.wiki.kernel.org/index.php/Gotchas#Fragmentation https://btrfs.wiki.kernel.org/index.php/FAQ#Can_copy-on-write_be_turned_off_for_data_blocks.3F https://btrfs.wiki.kernel.org/index.php/SysadminGuide#Copy_on_Write_.28CoW.29  ",
      "P-tags": "btrf qemu",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP while S"
    },
    {
      "id": "ul_487338",
      "task": "Why does libarchive's bsdtar's unzip throw away the permission bits when reading a ZIP-archive from stdin, but not directly?",
      "P-task": "libarch bsdtar unzip throw away permiss bit read zip-arch stdin directli",
      "F_verb": "read",
      "P-body": "Here on the bugtracker of \"libarchive\" is the answer: .   Zip archives contains two different ways to describe the content: .   A per-entry header A central directory at the end of the zip file.  libarchive (and bsdtar by extension) will use the central directory if seeking is possible on the input, otherwise it will fall back to the streaming-only logic. The entries are not necessarily consistent as you found out in your test case. There isn't really much we can or want to do about this. Note that you can replace wget with a plain cat and it will still show the same behavior. .  The short version is that this is an inherent issue with streaming of zip files and something that won't be fixed. .   ",
      "P-tags": "archiv execut zip stdin",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "so_40922461",
      "task": "How to use sed/grep to extract text between two words with condition?",
      "P-task": "use sed grep extract text two word condit",
      "F_verb": "use",
      "P-body": "Maybe you can use this; .  awk command; merge lines between \"<tr>\" and \"</tr>\" in your file. .  first grep ; get text only between Cline and online .  last grep ; get only url parts .  Test;  .  ",
      "P-tags": "awk regex shell extract sed",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF between NP with NP"
    },
    {
      "id": "so_7100919",
      "task": "How to define attribute aliased name to a c++ function?",
      "P-task": "defin attribut alias name c++ function",
      "F_verb": "define",
      "P-body": "From the docs: .   In C++, the mangled name for the target must be used. .   So, you need the mangled name of \"A\", or you need to give \"A\" C linkage so its name doesn't get mangled in the first place. .  ",
      "P-tags": "gcc c++ linux compiler-error",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "au_507496",
      "task": "How to start GUI application with upstart?",
      "P-task": "start gui applic upstart",
      "F_verb": "start",
      "P-body": "The problem you are facing is that when \"upstart\" (or \"systemd\", or the scripts in \"/etc/rc.d/\") are run, there is normally no graphic service (\"the X server\") running.  .  Moreover, the availability of the graphic subsystem in Unix is strictly bond to the concept that a user has done a graphic login, and just this user has the right to use the graphic environment. It is customary NOT to start a graphic subsytem for root --- and the upstart scripts are run by root.  .  To automatically start a graphic application at the start of the system, my approach would be:  .   create a user for this purpose. Set it up so that its session will autostart.  .  set up a startup application for this user with the program you want; choose \"startup application\" in the dash:  .  for restarting the application when it exits/crashes, you can simply embed it in a script:  .    If you use this script, it is really important that the command \"start_myapp.sh\" should not launch the application in background. Otherwise, more complex strategies are required to auto-restart... .  Notice that you can use your normal user in parallel too; just choose \"switch user\" from the panel (adapt to your flavor of Ubuntu) and you will have another graphical login screen; you can switch back-an-forth using CTRL-ALT-F7 and CTRL-ALT-F8... .  ",
      "P-tags": "script upstart",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_207010",
      "task": "Merge two files",
      "P-task": "merg two file",
      "F_verb": "merge",
      "P-body": " join requires sorted input. The '-' specifies that standard input will be used for the second file, which allows the output of sort to be used as input. The '-a 1' specifies that non-matching lines from the first file will be included in the output.  .  ",
      "P-tags": "join shell-script text-process",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_39200327",
      "task": "Is it possible to execute Jenkins jobs from Powershell or Bash or Groovy scripts?",
      "P-task": "possibl execut jenkin job powershel bash groovi script",
      "F_verb": "execute",
      "P-body": "If you are using Groovy in a Postbuild/pipeline step, you can start the job via the Jenkins API. .  For example, something like this for parameterless builds: .  And something like this for parameterized builds: .  You can also use the Jenkins Rest API for the rest. For example, by hitting the following url: .  Parameterless: .  Parameterized: .  ",
      "P-tags": "groovi powershel jenkin bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_52220482",
      "task": "Loading PowerShell module with nested module giving errors",
      "P-task": "load powershel modul nest modul give error",
      "F_verb": "give",
      "P-body": "I ended up creating PowerShell script to load the SharePoint PSSnapin. .  In my PowerShell module manifest I added the following property: .  Whenever the module is imported this script will run and load the SnapIn. When the module is releoded no errors are given .  ",
      "P-tags": "powershel powershell-modul",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_50458245",
      "task": "How to add/use C# libraries in JetBrains Rider?",
      "P-task": "add use c librari jetbrain rider",
      "F_verb": "add",
      "P-body": "\"System.Net.Http\" is not a standard reference included with console applications. You will need to add the reference explicitly to use it. .  You can do this in Rider by right clicking the project in question, selecting Add > Add Reference. This will pop a dialog that will populate the system references. Once populated, find \"System.Net.Http\" and select it. Confirm the dialog. Your using should now work as expected. .  Tested with Rider 2018.1 on windows. .  ",
      "P-tags": "linux c net rider",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_589575",
      "task": "Can I install software in FreeBSD live CD?",
      "P-task": "instal softwar freebsd live cd",
      "F_verb": "install",
      "P-body": "You can do that. But have you considered that you might have better options for your task? .  Rather than the \"Live CD\" you could download the \"memstick\" version. So rather than booting a CD you would boot a USB stick and have a writeable system. And if the system is networked I would PXE boot a minimal image. .  What you do not state but I expect you know is that you could download the \".tbz\" file of the package and do the install using \"pkg_add package-name.tbz\". As it by default tries to install into \"/usr/local/bin\" which is read-only you have the problem. While you could play around with \"@option extract-in-place\" you could easily run into post-install problems. You could also move the pertinent directories to a \"tmpfs\" filesystem. But it is not worth the hassle. .  Your more reasonable options are: .  1. Easy - simple copy If it is a simple binary you could just ftp/sftp the file(s) into your \"/tmp\". Then do a \"chmod +x\" on the executeable and run it from there. .  2. Easy - NFS infrastructure You could setup a NFS share on your network. Mount it from your \"Live CD\" system. Have your executables on that share and run it from there. .  3. Intermediate but effort needed - Build your own. As you note the CD is read-only. But you can prepare your own image. Then you decide which files goes onto the system. To build a system you need to have the FreeBSD source on your system. Then it is as simple as: .  You will then find the release images in \"/var/myrelease\" when done. The hard part is then to understand the system and where to make additions. You will probably need to set \"SRC_CONF\" (see src.conf(5)) and you can learn a lot from release(7) .  If you do not want to make the full release you can simply do \"make cdrom\". .  UPDATE: I just happened by sysutils/packmule which is a tool that helps you do exactly this. I have not tried it myself but it looks quite straightforward. .  4. Intermediate but common - Build mfsbsd Rather than starting with the official FreeBSD Live CD it is very common to use mfsbsd instead. It is a minimal system but very easy to work with. You can download readymade images from the homepage but you can easily build your own. .  It is easy adding packages by copying the \".tbz\" files that should be automatically installed into the \"packages/\" directory. .  Now copy the \"*.tbz\" files to \"~/src/mfsbsd/packages/\" - then... .  This would be my preferred method. .  Alternative: PXE You do not state if you are actually booting from a CD. Or maybe doing a virtual boot with an .iso image in a VM. But for then kind of work you are playing around with it could quickly be worth looking into NFS (networked filesystem) and PXE (Network boot). Depending on your skill level it might be too soon but have a look at PXE Booting Utilities With FreeBSD for a nice full description on how to setup a full environment. At the end it also describes how to boot a full FreeBSD Live system with NFS. This can give you some pointers to further exploration. .  ",
      "P-tags": "freebsd livecd",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_437904",
      "task": "Skype cannot find libsqlite3.so.0",
      "P-task": "skype find libsqlite3 0",
      "F_verb": "find",
      "P-body": "The problem here is that, for some reason, the libsqlite3 i386 library was missing, even though it was installed as per \"apt\" and there are no dependency problems. To fix this, just reinstall the package (\"sudo apt-get install --reinstall libsqlite3-0:i386\"). .  ",
      "P-tags": "apt 64-bit skype shared-librari",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_151252",
      "task": "Prevent transparent font on Termite when using Compton",
      "P-task": "prevent transpar font termit use compton",
      "F_verb": "prevent",
      "P-body": "As I just answered in the other question, the font is also transparent (which is hard to see on a screenshot). \"compton\" (or any other compositor) doesn't distinguish the text from the rest. It simply deals with windows. Thus, that solution only works if you keep a high level of opacity (85% works for me). To have a terminal with a different degree of opacity between the text and the background, this needs to be a feature implemented in the terminal itself, but it may lead to other issues (e.g. with the \"ranger\" feature you were asking about). .  Update Good news! True transparency is supported once again in termite, so compton is no longer required for that. .  ",
      "P-tags": "terminal-emul",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP on NP when S"
    },
    {
      "id": "so_30517925",
      "task": "Cacti Thresholds to Send SNMP Trap",
      "P-task": "cacti threshold send snmp trap",
      "F_verb": "send",
      "P-body": "There is no easy way. You can send a syslog message to an Element Management System and read the syslog on the element management system. Change /etc/syslog.conf to forward alerts t EMS system by doing the following. .   Go to Settings -> Thresholds. Change Syslog Facility to Local 5 Open /etc/syslog.conf Add remote ip address like so Local5.* @@192.1.3.1:514 You can change 514 based on your remote port. Restart syslog. service syslog restart Voila! Check that you are receiving syslog on remote server.  The Hard Way. 1. Open thold_function.php in the thold plugin folder 2. Write a php function to send an alert. 3. Add the function in the logger function. .  function logger($desc, $breach_up, $threshld, $currentval, $trigger, $triggerct, $urlbreach) .  Here is code you can adapt. .  ",
      "P-tags": "ubuntu nagio cacti snmp",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "ul_471824",
      "task": "What is the correct substitute for rc.local in systemd instead of re-creating rc.local",
      "P-task": "correct substitut rc local systemd instead re-creat rc local",
      "F_verb": "create",
      "P-body": "As pointed out elsewhere, it becomes moderately unclean to use \"rc-local.service\" under \"systemd\". .   It is theoretically possible that your distribution will not enable it. I think this is not common, e.g. because disabling the same build option also removes \"poweroff\" / \"reboot\" commands that a lot of people use). The semantics are not entirely clear. Systemd defines \"rc-local.service\" one way, but Debian provides a drop-in file which alters at least one important setting.  \"rc-local.service\" can often work well. If you're worried about the above, all you need to do is make your own copy of it! Here's the magic: .  I don't think you need to understand every single detail[*], but there are two things you need to know here. .   You need to enable this with \"systemctl enable my-startup.service\". .  If your script has a dependency on any other service, including \"network-online.target\", you must declare it. E.g. add a \"[Unit]\" section, with the lines \"Wants=network-online.target\" and \"After=network-online.target\". .  You don't need to worry about dependencies on \"early boot\" services - specifically, services that are already ordered before \"basic.target\". Services like \"my-startup.service\" are automatically ordered after \"basic.target\", unless they set \"DefaultDependencies=no\". .  If you're not sure whether one of your dependencies is an \"early boot\" service, one approach is to list the services that are ordered before \"basic.target\", by running \"systemctl list-dependencies --after basic.target\". Note that's \"--after\", not \"--before\"). .   There are some considerations that I think also applied to pre-systemd \"rc.local\": .   You need to make sure your commands are not conflicting with another program that tries to control the same thing. It is best not to start long-running programs aka daemons from \"rc.local\".   [*] I used \"Type=oneshot\" + \"RemainAfterExit=yes\" because it makes more sense for most one-shot scripts. It formalizes that you will run a series of commands, that \"my-startup\" will be shown as \"active\" once they have completed, and that you will not start a daemon. .  ",
      "P-tags": "rc local systemd",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "su_616407",
      "task": "How to load and execute a Java file when booting on Linux?",
      "P-task": "load execut java file boot linux",
      "F_verb": "load",
      "P-body": "You have to reference your executable in \"/etc/rc.local\" file (or add a system startup service \"/etc/rc2.d\": the Pi boots to runlevel 2). .  There, you put a normal \"java\" invocation with full path (i.e. \"/usr/local/bin/java ...\" or \"/usr/bin/java ...\"). .  If you want the output to be logged to a file, you either leverage \"syslog\" function or redirect the output to a logfile (or two separate logfiles, one for stdout log, one for error log), i.e. .  The first time, run the command from the command line to verify it is properly working. .  ",
      "P-tags": "raspberry-pi linux java",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP when S"
    },
    {
      "id": "so_31268752",
      "task": "Powershell: Re-Install Printer depending on Username",
      "P-task": "powershel : re-instal printer depend usernam",
      "F_verb": "install",
      "P-body": "I agree with arco I like the use of HashTables and your issue is perfect for it. Take a look at my code here it should give you a good point for a Powershell Start. .  If you look at the above this is what takes my CSV file and loads it into the hashtable .  and below if how my code is used, I make it look for the computer name and if the matches then it will return the hashtable value.  .  See if this helps you. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1182912",
      "task": "Can I remove old gcc versions?",
      "P-task": "remov old gcc version",
      "F_verb": "remove",
      "P-body": "The results of \"rmadison gcc\" show that gcc 9 is the default gcc in Ubuntu 19.10. .  You can safely uninstall all the other versions of gcc because you checked that no other installed packages have other versions of gcc as dependencies.  .  In addition to possibly having installed packages that require non-default versions of gcc as dependencies, some developers install multiple versions of gcc alongside each other because different programs that they are developing target different versions of gcc as their GNU C compiler. .  ",
      "P-tags": "gcc apt package-manag 19 10",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_25808024",
      "task": "node.js child process change a directory and run the process",
      "P-task": "node js child process chang directori run process",
      "F_verb": "change",
      "P-body": "cp.exec get the working directory in parameter options http://nodejs.org/docs/latest/api/child_process.html#child_process_child_process_exec_command_options_callback .  Use  .  for running script in the \"path\" directory. .  ",
      "P-tags": "node js extern process bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_6623661",
      "task": "Make Grails listen on external IP address",
      "P-task": "make grail listen extern ip address",
      "F_verb": "make",
      "P-body": "If you really want to run it with run-app, the enter your servers IP address in your command-line, like this: .  But you will probably find that you get a conflict with your Apache server running on the same IP. .  I think you should look into using mod_proxy and mod_proxy_apj to \"hide\" your grails server beghind your Apache server .  ",
      "P-tags": "amazon-ec2 grail ubuntu java",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP on NP"
    },
    {
      "id": "so_49264164",
      "task": "Capture an image from a USB camera and display it in the monitor",
      "P-task": "captur imag usb camera display monitor",
      "F_verb": "capture",
      "P-body": "You will need to get \"Video4Linux\" working anyway because \"OpenCV\" uses that underneath to acquire images, so you could use that to grab the image(s). You could then add text and boxes very simply with ImageMagick and that could be done from command-line with no programming required. You could then display them with \"feh\" or ImageMagick's \"display\" program, or any X11 viewer. .  Let's say you acquired this image: .   .  You could annotate it like this in a bash script at the command line: .   .  \"OpenCV\" can take a lot of configuring and a long time to compile. You could add text and boxes in \"OpenCV\" but the fonts are not very configurable in OpenCV because it is more oriented towards Computer Vision (i.e. identifying objects and faces) rather generating and annotating images. .  Your question is actually rather too broad for this site. Do you actually mean a single image, or a video? What sort of annotations do you mean? Is there a target frame-rate? .  ",
      "P-tags": "embedded-linux camera imag captur",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "au_392226",
      "task": "How to remove all online smart scopes completely and permanently?",
      "P-task": "remov onlin smart scope complet perman",
      "F_verb": "remove",
      "P-body": "I think, the best thing to do is to unintall the packages: .  ",
      "P-tags": "scope",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_24685698",
      "task": "symbol lookup error when using my Qt plugin from inside of shared library",
      "P-task": "symbol lookup error use qt plugin insid share librari",
      "F_verb": "use",
      "P-body": "As I suspected in my own comment to my question, the \"-rdynamic\" passed to linker for EXEC solved the problem. .  ",
      "P-tags": "c++ linux qt",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP of NP"
    },
    {
      "id": "so_59122651",
      "task": "Environmental variables array giving different results",
      "P-task": "environment variabl array give differ result",
      "F_verb": "give",
      "P-body": "They are not the same thing. \"env\" is the array of pointers to strings, which exists somewhere in memory. \"env[0]\" is the address of the first string, just like \"env[1]\" is the address of the second string, which is different to the address of the array where those addresses are stored. .  ",
      "P-tags": "array linux c",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "ul_537958",
      "task": "How to remove domains starting or end or both with single hyphen?",
      "P-task": "remov domain start end singl hyphen",
      "F_verb": "remove",
      "P-body": "Any of the: .  or, with GNU grep: .  ",
      "P-tags": "domain",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "au_21674",
      "task": "Wiped data, and duplicated folders into files",
      "P-task": "wipe data duplic folder file",
      "F_verb": "wipe",
      "P-body": "You can delete all files ending with : with this command: .  You should execute \"find -name *:\" first to check what will be removed. .  ",
      "P-tags": "data-recoveri",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP into NP"
    },
    {
      "id": "ul_43621",
      "task": "Should I change the permissions of binaries?",
      "P-task": "chang permiss binari",
      "F_verb": "change",
      "P-body": "What you're doing is bad. Stop it. .  If the application \"nginx\" is owned by the user \"nginx\" and running as the user \"nginx\" then when the application is exploited it can write over its own files. You don't want this. .  Application binaries should almost always be owned by \"root\". Services should almost always be running as \"nobody\" or another similarly non-privleged account. .  Likewise, you don't want your web content owned by the same user running the web server because that allows an attacker to change your content (i.e., deface your site). .  You want to use as much privilege separation and as few privileges as possible. .   Applications owned by \"root\" (so only \"root\" is allowed to modify them) Services executed by non-privileged users (so they have little or no access to the system) Wherever possible the service user should not own the content for that service  ",
      "P-tags": "permiss",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP"
    },
    {
      "id": "so_61441032",
      "task": "How can I ignore SIGXCPU signal, if I want to run a program for a long period of time?",
      "P-task": "ignor sigxcpu signal want run program long period time",
      "F_verb": "ignore",
      "P-body": "You can ignore SIGXCPU signal: .  This only buys you a little bit more time, though. SIGXCPU starts when you get to the soft CPU limit, and SIGKILL (which you can't ignore) happens once you get to the hard CPU limit. .  But you want to check whether the CPU limit is low and if you can increase it. In bash, you can check with \"ulimit -t\" and change it you could. .  Programmatically, you could change \"RLIMIT_CPU\" via \"setrlimit\". .  However, if the CPU limit is set across the system or for specific users by an administrator (e.g. \"sysctl\" parameters), you'd need super user privileges to change it. .  ",
      "P-tags": "linux signal c",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP if S"
    },
    {
      "id": "au_359540",
      "task": "Securely erase hard drive using the Disk Utility",
      "P-task": "secur eras hard drive use disk util",
      "F_verb": "erase",
      "P-body": "Yes, the disk utility uses a method similar to the one with \"dd\" you describe, or a faster and more secure one more like: .  This introduces a lot more fuzz to the overwriting pattern than zeros only, which should be more difficult to restore but not noticeably slower to perform. .  Some people claim, this is not enough and one should overwrite hard disks multiple times and with more elaborate patterns (\"scrub(1)\" can do both of that as per the other answer), but most will say once is enough, if an attacker wants to restore more than a few bits with a significant chance. .  Edit: Apparently \"/dev/urandom\" peaks at ~13 MiB/s on at least two systems including mine. Therefore simonp suggested a different approach using \"openssl(1)\": .  ",
      "P-tags": "secure-eras gnome-disk-util disk-util",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_446111",
      "task": "Why is my OpenGL renderer shows my CPU?",
      "P-task": "opengl render show cpu",
      "F_verb": "show",
      "P-body": "You need to set DRI_PRIME value before running the programs. Example \"DRI_PRIME=1 glxinfo | grep OpenGL\" This is assumming you already set the proper provider related article : PRIME .  ",
      "P-tags": "ubuntu gpu laptop opengl",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "so_29382452",
      "task": "How to concatenate 2 seperate folders",
      "P-task": "concaten 2 seper folder",
      "F_verb": "concatenate",
      "P-body": "Try this : .  This is like a copy of the folder A .  That should concatenate the folders A and B to another the new folder C. .  ",
      "P-tags": "directori ubuntu command-lin",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "au_1365312",
      "task": "HDMI monitor stops working when lap top lid is closed",
      "P-task": "hdmi monitor stop work lap top lid close",
      "F_verb": "monitor",
      "P-body": "From: Closing lid problem: .   To make Ubuntu do nothing when laptop lid is closed: Open the \"/etc/systemd/logind.conf\" file in a text editor as root, for example .  \"sudo -H gedit /etc/systemd/logind.conf\" .  Add a line \"HandleLidSwitch=ignore\" .  Restart the systemd daemon with this command: .  \"sudo service systemd-logind restart\" .  If that didn't work set the following .  \"IgnoreLid=true\" in \"/etc/UPower/UPower.conf\" .  ",
      "P-tags": "power-manag hdmi multiple-monitor",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V S_ING when S"
    },
    {
      "id": "so_32523894",
      "task": "Android ubuntu HOME is defined but could not find .ini file",
      "P-task": "android ubuntu home defin could find ini file",
      "F_verb": "find",
      "P-body": "I suggest you to run the following command from command line: .  This will start the Android Device Manger, which will list all your configured emulators and their location (usually in the form ~/.android/avd). You can export this location into a system variable called $ANDROID_AVD_HOME, and then run the emulator again. .  For more info about how to export a variable, take a look here. .  If you have troubles using the \"android\" command, your environment may not be set correctly; if this is your case, I suggest you to start from the beginning by following this guide. .  ",
      "P-tags": "android ubuntu android-studio",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_489758",
      "task": "How to make dunst show repeated notifications of the same program as one single notification",
      "P-task": "make dunst show repeat notif program one singl notif",
      "F_verb": "make",
      "P-body": "You should use \"dunstify\" instead of \"notify-send\", because first one allows you to use notification ID and replace older notifications with newer ones. Here is link to info about dunstify, and link to example of creating volume level indicator. .  ",
      "P-tags": "notify-send notif",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP of NP as NP"
    },
    {
      "id": "so_23396492",
      "task": "Shell script to search and display line from file with 3 different options",
      "P-task": "shell script search display line file 3 differ option",
      "F_verb": "search",
      "P-body": "You can try the following Perl script: .  Example run: \"p.pl --date=2014-04-03 --time=15:07:15\" .  ",
      "P-tags": "awk sed grep shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP from NP with NP"
    },
    {
      "id": "au_170971",
      "task": "Install quota stuck on repquota",
      "P-task": "instal quota stuck repquota",
      "F_verb": "install",
      "P-body": "Running command with paramter \"g\" solved my problem: .  ",
      "P-tags": "quota",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1313349",
      "task": "How can I find the mime type without charset using \"file\"?",
      "P-task": "find mime type without charset use file",
      "F_verb": "find",
      "P-body": "From the \"man\" page: .  So by way of example: .  So you want \"file --mime-type dog.jpeg\". .  ",
      "P-tags": "20 10",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP without NP using NP"
    },
    {
      "id": "so_3142400",
      "task": "Split a paragraph into lines in ZSH",
      "P-task": "split paragraph line zsh",
      "F_verb": "split",
      "P-body": "Here's an example of process substitution which will work in zsh and Bash. It uses the Unix/Linux tool \"paste\" to put two calendars side-by-side as a demonstration. .  To answer your question directly: .  Which also works in Bash. .  ",
      "P-tags": "string shell zsh",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP into NP in NP"
    },
    {
      "id": "au_931625",
      "task": "pip is throwing strange error when asked to list outdated packages?",
      "P-task": "pip throw strang error ask list outdat packag",
      "F_verb": "ask",
      "P-body": "I also see this error when using \"pip\" inside a virtualenv for Python 3.6. One way to fix this is to force-reinstall \"pip\": .  ",
      "P-tags": "pip python3",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V S_INF"
    },
    {
      "id": "so_41850352",
      "task": "Php 5.4 Cannot modify header information - headers already sent",
      "P-task": "php 5 4 modifi header inform - header alreadi sent",
      "F_verb": "modify",
      "P-body": "Ok, so your \"outputBody()\" method is being called prior to the code in your functions.php file.  .  It is this \"if\" statement triggering the error; .  The \"PHP_SAPI\" constant has obviously changed values when you've upgraded PHP. This is triggering the \"header()\" method, but becuase \"outputBody()\" in Abstract.php has already ran and echo'd content to the page the headers have been set. Due to it not being possible to reset headers once they've sent, your \"header()\" method fails.  .  Have a look at why \"PHP_SAPI\" has changed and what it's changed to. Fixing this should solve your issue.  .  ",
      "P-tags": "ubuntu apach php",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_546749",
      "task": "Error While Binding Sshd to Port 2222 During Update on Debian 10 \"Buster\"",
      "P-task": "error bind sshd port 2222 updat debian 10 buster",
      "F_verb": "update",
      "P-body": "One may proceed as follows: .  \"$ sudo systemctl disable sshd $ sudo systemctl daemon-reload $ sudo dpkg --configure openssh-server\" .  Then, finally .  \"$ systemctl enable sshd\" .  ",
      "P-tags": "sshd debian ssh",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V on NP"
    },
    {
      "id": "su_1260431",
      "task": "Sed: Append text containing new lines characters after the first line of a file",
      "P-task": "sed : append text contain new line charact first line file",
      "F_verb": "append",
      "P-body": "How about something super basic like: .  ",
      "P-tags": "sed command-lin bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP after NP of NP"
    },
    {
      "id": "so_29241902",
      "task": "reading every file in directories (unix/posix)",
      "P-task": "read everi file directori unix posix",
      "F_verb": "read",
      "P-body": "If you want to list all directories and sub-directories, try something recursive. E.g.: .  Expression like \"printf(\"%*c\", level, '>')\" just make indents for elach level of nesting .  ",
      "P-tags": "posix unix directori c file-io",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "so_17572503",
      "task": "Powershell- Can't reference variable when making a file and setting its name with New-Item",
      "P-task": "powershell- refer variabl make file set name new-item",
      "F_verb": "set",
      "P-body": "You don't say what isn't working, so here are some generic suggestions. If you can post any error messages, or specific things that aren't working, I can be more specific. .  As a commenter stated, \"(Get-Date).ToString()\" returns something like \"7/10/2013 7:38:22 AM\", which may or may not work in a filename. You'll want to format it so that you know it will work in a filename, e.g. \"$fileName = '{0:yyyy-MM-dd-HH-mm-ss}.txt' -f (Get-Date)\". .  Second, PowerShell has an Import-Csv function which will read a CSV file and turn it into objects. You can then process each object, which will have properties for each column of the CSV, returning a string that you want in your destination file. .  Here is an updated script: .  ",
      "P-tags": "variabl powershel",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP with NP"
    },
    {
      "id": "so_24566960",
      "task": "how to combine cut command with arithmetic comparison",
      "P-task": "combin cut command arithmet comparison",
      "F_verb": "combine",
      "P-body": "With \"awk\": .  With \"bash\": .  ",
      "P-tags": "awk cut shell",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP"
    },
    {
      "id": "so_8964012",
      "task": "Cross-compiling Linux kernel for ARM on Windows using Sourcery Toolchain",
      "P-task": "cross-compil linux kernel arm window use sourceri toolchain",
      "F_verb": "compile",
      "P-body": "To cross compile the kernel, you'll need two compilers: One that is able to build tools that run in your build environment, and one that can create executables for your target. .  It seems like you aren't really cross compiling but you have just replaced your compiler. You are now building tools required for the build for ARM and try to run them on Windows. .  You can specify which cross compiler to use: .  You might also have a problem with the filesystem. The filesystem in Windows is case-insensitive and the Kernel build might create files where the case matters. To get support for a case-insensitive filesystem on Windows, you can have a look at Windows Services for UNIX. .  ",
      "P-tags": "embedded-linux linux-kernel codesourceri toolchain arm",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP for NP on NP using NP"
    },
    {
      "id": "au_861052",
      "task": "How can one show the disk read/write speed as number in the panel?",
      "P-task": "one show disk read write speed number panel",
      "F_verb": "show",
      "P-body": "Introduction As indicated in the comments, I've written a custom indicator to display disk i/o usage. It allows displaying total usage in the panel as well as per-device information in the indicator menu. It provides information on i/o usage of only those devices that are mounted and adapts its information when devices are mounted/unmounted. Panel text can be turned on-off, and basic settings can be controlled via \"~/.diskstat_indicator.json\" file.  .  Usage The indicator can be launched as any other application by calling it via Unity Dash or directly via command-line (\"diskstat_indicator\" command). To launch the indicator upon login, one can place copy of \"/usr/share/applications/diskstat_indicator.desktop\" file into \"~/.config/autostart/\" directory. .  Since the ever changing speed of reads and writes total affects the length of text in the panel, it will constantly move other indicators back and forth. This can get annoying really fast, which is why I've added an option into the menu that will disable/enable panel text. The total information still can be seen via the menu. Notice that the information field is a non-selectable menu item simply because there's no action associated with that menu item. It might have something in future, but the primary function of this indicator is to display data, rather than serve as action-oriented indicator.  .  Sample \"~/.diskstat_indicator.json\" : .  Installation The indicator can be obtained from my personal PPA. Use the following steps to add PPA and install the indicator: .   \"sudo add-apt-repository ppa:1047481448-2/sergkolo\" \"sudo apt-get update\" \"sudo apt-get install diskstat-indicator\"  The source code is also available on the project's GitHub repository. .  Technical details, discussion, and further steps The way indicator works is simple: it reads \"/proc/diskstats\" file , cross checks the devices with \"/proc/mounts\", and extracts information only for those devices that are mentioned in the \"/proc/mounts\" file. This is essentially same behavior as \"iotop\" or \"iostat\" programs. In my tests, the data generally agrees with \"iotop\", although with slight variation.  .  It should be mentioned that this is by no means a high-quality tool. It is meant to only get quick idea of what is happening with disk i/o ; there user should be able to take a look and say \"OK, the i/o usage is quite high, so there's clearly something going on\". Every user has different workflow, so it may or may not be suitable for power users. If you need more detailed information, such as per process i/o activity, then probably you want \"iotop\" software package. .  Other indicators that you might find useful in combination with this tool is the Udisks Indicator, which can be used for observing disk space usage and mounting/unmounting partitions.  .  ",
      "P-tags": "panel uniti indic 16 04",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "su_1344062",
      "task": "How to install Chromium masked package on Alpine Linux 3.8?",
      "P-task": "instal chromium mask packag alpin linux 3 8",
      "F_verb": "install",
      "P-body": " Or remove \"@community\" pin from \"/etc/apk/repositories\". It's quite unusual configuration to have the official community repo pinned. .  ",
      "P-tags": "chromium virtualbox vagrant alpine-linux",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_597990",
      "task": "How do I add custom cursor themes in xfce4?",
      "P-task": "add custom cursor theme xfce4",
      "F_verb": "add",
      "P-body": "Cursor themes need to be placed in \"~/.icons\" then they will show up in Settings > Mouse and Touchpad > Theme .  ",
      "P-tags": "cursor-them xfce",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_81763",
      "task": "Problem with pipes. Pipe terminates when reader done",
      "P-task": "problem pipe\npipe termin reader done",
      "F_verb": "terminate",
      "P-body": "As for the cause, use \"strace\". .  The second \"echo echo hello > pToB\" gives me then this: .  So, the second time it tries to write hello\\n, it gets a broken pipe error; that's why you can't read hello (it was never written), and bash quits so that's the end of it. .  You'd have to use something that keeps the pipe open, I guess. .  How about this? .  For more background information, \"man 7 pipe\" may be relevant, it describes the various error cases around pipes. .  ",
      "P-tags": "fifo pipe",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V when S"
    },
    {
      "id": "so_51729607",
      "task": "Replace newline in variable and change back in bash",
      "P-task": "replac newlin variabl chang back bash",
      "F_verb": "change",
      "P-body": "You can use \"$'\\n'\" to represent newline: .   .  Now to change it back to newlines: .   .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_183395",
      "task": "Connect to mpd over Openvpn (without changing internet routing)",
      "P-task": "connect mpd openvpn without chang internet rout",
      "F_verb": "connect",
      "P-body": "Set your client to have a route parameter to only your home LAN. For example if your home LAN was 192.168.2.0, the the parameter would look like this in the .conf file: .  and dont push any routes from the server onto the client. This way when the tunnel comes up all you will route through it is the network you put in the route parameter. .  UPDATE: .  Since your server has these push lines: .  You need to delete them to have the desired effect you are looking for. It would be even better to have two instances of openvpn running on your server. One with the actual config and one with a modified one that you will use when connected from the office. Just have the two configs listening on different ports and connect to them as desired.  .  For example on the actual one put below parameter at end of server config: .  and on the modified one put: .  Then your client can connect to either port depending on your needs. .  ",
      "P-tags": "openvpn mpd",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP over NP without S_ING"
    },
    {
      "id": "au_812592",
      "task": "Connect to Samba Drive Remotely",
      "P-task": "connect samba drive remot",
      "F_verb": "connect",
      "P-body": "You can connect from inside your network? .  You can try an nmap scan from outside to see if the port forwardings are working properly. .  install via .  run scan via .  Than you can try to connect via smbclient using this command: .  install via .  (-L)ist shares via .  ",
      "P-tags": "samba",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "au_799164",
      "task": "WinFF: How to produce 'free' ogv files under Xenial?",
      "P-task": "winff : produc free ogv file xenial",
      "F_verb": "produce",
      "P-body": "A default installation of WinFF under Xenial: .  has no presets to produce ogv files with Theora video and Vorbis sound. A great omission IMHO. .  You can rectify this omission by producing a text file called \"ogv.wff\" on your Desktop and placing the following contents into it: .  Save this file, close it, right click on it and select: 'Open with WinFF' and this is enough to save your new preset in \"~/.winff/presets.xml\". .  And now you can enjoy producing great quality media files with 2 completely free codecs! .  References: .   FFmpeg Wiki: Theora & Vorbis  ",
      "P-tags": "ffmpeg winff free-softwar 16 04",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP under NP"
    },
    {
      "id": "so_30514908",
      "task": "Converting a value to corresponding text",
      "P-task": "convert valu correspond text",
      "F_verb": "convert",
      "P-body": "The file versions which include the revision, might change as updates get installed, but the first 3 numbers should be useful. You can cast as a \"[version]\" or you can just use a simple split or replace to get rid of the build. .  You could then make a hashtable with version numbers as keys and PS versions as values. .  Otherwise, if you've determined that PowerShell remoting is in fact enabled, another way would be to just ask it: .  Alternatives for setting \"$myVer\": String substitution: .  Replace (regular expression): .  Split with range: .  Using \"switch -wildcard\" (credit to Ansgar Wiechers): .  ",
      "P-tags": "powershel powershell-remot",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_39813216",
      "task": "Adding cb_admin to current ChicagoBoss installation",
      "P-task": "ad cb_admin current chicagoboss instal",
      "F_verb": "add",
      "P-body": "I believe you are missing a comma (,) after your .  your error message indicates a syntax error on line 3, and I can see there is no comma between these two dependencies.  .  ",
      "P-tags": "erlang-shel erlang chicagoboss erl git",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_42043598",
      "task": "Get match in text file and pipe to new file",
      "P-task": "get match text file pipe new file",
      "F_verb": "get",
      "P-body": "With \"awk\", you can filter by lines that contain TOTAL, and print the 5th column: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_44234364",
      "task": "Replace string with space using sed",
      "P-task": "replac string space use sed",
      "F_verb": "replace",
      "P-body": " ",
      "P-tags": "sed shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "so_13341893",
      "task": "get script to work on remote servers",
      "P-task": "get script work remot server",
      "F_verb": "get",
      "P-body": "You need to step back for a second an rethink the approach. You are issuing the filesystem commands every time to f:\\temp, which is on your local system.  .  There are two ways to make remote computers perform filesystem tasks. The easiest way is to use UNC paths. That is, \"\\\\server\\share\" format. Assuming you have local admin access: .  Mind you, using UNC path puts some stess on LAN, so this type of testing might or might not be accurate enough. .  The second way would be using Powershell remoting to connect on remote systems and issuing the commands there. Take a look at New-PSSession, Enter-PSSession and Exit-PSSession cmdlets. .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_29288824",
      "task": "How to fix virtualbox unknown filesystem type 'vbox'",
      "P-task": "fix virtualbox unknown filesystem type vbox",
      "F_verb": "fix",
      "P-body": "You made a typo. It should be \"vboxsf\" instead of \"vboxfs\". I did the same and was wondering why it doesn't work. So the full command is: .  To remember the correct type you can think of it as the abbreviation of VirtualBox Shared Folder. .  ",
      "P-tags": "linux virtualbox archlinux",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_22625383",
      "task": "arm-elf-g++: Command not found",
      "P-task": "arm-elf-g++ : command found",
      "F_verb": "find",
      "P-body": "Try something like this: .  \"sudo apt-get install gcc-arm-linux-gnueabi\" .  Here are a couple of links for installing an ARM toolchain on Ubuntu: .   https://askubuntu.com/questions/65630/installing-gnu-arm-toolchain .  https://groups.google.com/forum/#!topic/levana-technologies/MiGqkDn3ARQ .   ",
      "P-tags": "c++ linux",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_21284720",
      "task": "Hide or crop overlapping text in QLabel?",
      "P-task": "hide crop overlap text qlabel",
      "F_verb": "hide",
      "P-body": "Widgets in a layout are always managed not to overlap, so I just see no way that the \"textLabel\" could overlap \"valueLabel\". Most likely your widgets are not managed by the layout, even if they were added to the layout. Perhaps the layout with labels is not a child of another layout, or is not set on a container widget. .  You're not telling us something. A self-contained test case would be good to have. .  If you want a label to elide the text by finishing it with \"...\" instead of abruptly cutting it off, the following elided style can be used. .  ",
      "P-tags": "qlabel linux qt4 c++ qt",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V NP in NP"
    },
    {
      "id": "au_352210",
      "task": "VPS apache config - Invalid command 'PassengerDefaultRuby' after adding latest passenger gem",
      "P-task": "vp apach config - invalid command passengerdefaultrubi ad latest passeng gem",
      "F_verb": "add",
      "P-body": "Got it! .  you need to have a default ruby assigned at root level, the other ones you'll set in \"sites-enabled\" configuration files. For example, in my \"apache2.conf\" file: .  then in \"/etc/apache2/sites-enabled/mysite\" that fires up the app that should work in \"ruby-1.9.3\" I'll add \"PassengerRuby /usr/local/rvm/wrappers/ruby-1.9.3-p194/ruby\": .  for the app that works with \"ruby-2.0\" no need to add \"PassengerRuby\" option as \"ruby-2.0\" is the default one now. .  Also if you have other rvm passenger modules loaded in apache2.config file, like in my case I had: .  you'll need to remove them or comment them as I did, as you'll load the ruby version in \"/etc/apache2/sites-enabled/mysite\" config file. .  ",
      "P-tags": "rubi vp apache2",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_242663",
      "task": "Cannot make ipv6 ULA addresses work",
      "P-task": "make ipv6 ula address work",
      "F_verb": "make",
      "P-body": "Try using fd69::6666 instead. Using fd69:6666:: only sets the network part of the address.  Remember to change the netmask too!  This should be the result: .  /etc/network/interfaces  .  ",
      "P-tags": "ipv6 lan",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_34162503",
      "task": "Ignore HUP signal in Bash script with pipe commands",
      "P-task": "ignor hup signal bash script pipe command",
      "F_verb": "ignore",
      "P-body": "Pipeline commands are run in a subshell The first part of your question is explained by the mechanism through which a shell (in this case Bash) runs commands in a pipeline. .  A pipe is a FIFO (first in, first out) one-way inter-process communication (IPC) channel: it allows bytes to be written at one end (the write-only end) and read from the other (read-only end) without needing to read from or write to a physical filesystem. .  A pipeline allows two different commands to communicate with each other through an anonymous or unnamed (i.e., has no entry in the filesystem) pipe. .  When a simple command is executed by a shell, the command is run in a child process of the shell. If no job control is used, control of the terminal is regained by the shell when the child process terminates. .  When two commands are run in a pipeline, both commands in the pipeline are executed as two separate child processes which run concurrently. .  In Unix systems, pipes are created using the \"pipe(2)\" system call, which creates a new pipe and returns a pair of file descriptors with one referring to the read end and the other to the write end of the pipe. .  With Bash on a GNU/Linux system, the \"clone(2)\" system call is used to create the sub-processes. This allows the child process to share the table of file descriptors with its parent process so that both child sub-processes inherit the file descriptor of the anonymous pipe so that one can read to it and the other can write to it. .  In your case, the \"inotifywait\" command gets a PID of 4425 and writes to the write-only end of the pipe by connecting its \"stdout\" to the file descriptor of the write end. .  At the same time, the right hand side of the pipe command gets the PID, 4426 and its \"stdin\" file descriptor is set to that of the read-only end of the pipe. Since the subshell for the right hand side of the pipe isn\u2019t an external command, the name to represent the child process is the same as that of its parent, \"test.sh\". .  For more info, see \"man 7 pipe\" and the following links: .   Anonymous pipe, Wikipedia article Unix Pipeline, Wikipedia article  Signal handling It took me ages (a couple of hours of research, in fact) to figure out why the trap for the SIGHUP signal wasn\u2019t being ignored. .  All my research indicated that child process created by a \"clone(2)\" system call should also be able to share the table of signal handlers of the parent process. .  The Bash man page also states that .   Command substitution, commands grouped with parentheses, and asynchronous commands are invoked in a subshell environment that is a duplicate of the shell environment, except that traps caught by the shell are reset to the values that the shell inherited from its parent at invocation.  .   It later states that .   Signals ignored upon entry to the shell cannot be trapped or reset. Trapped signals that are not being ignored are reset to their original values in a subshell or subshell environment when one is created. .   This indicates that subshells do not inherit signal handlers that are not ignored. As I understood it, your \"trap ':' HUP\" line meant that the SIGHUP signal was (effectively) being ignored (since the \":\" builtin does nothing except return success) \u2013 and should in turn be ignored by the pipeline\u2019s subshell. .  However, I eventually came across the description of the \"trap\" builtin in the Bash man page which defines what Bash means by ignore:  .   If arg is the null string the signal specified by each sigspec is ignored by the shell and by the commands it invokes. .   Simply changing the \"trap\" command to \"trap '' HUP\" ensures that the SIGHUP signal is ignored, for the script itself \u2013 and any subshells. .  ",
      "P-tags": "pipe pipelin signal shell bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_33286992",
      "task": "How do I execute a query automatically in PostgreSQL when connecting via shell?",
      "P-task": "execut queri automat postgresql connect via shell",
      "F_verb": "execute",
      "P-body": "psql will look for, and execute any commands found in, a couple of places every time it starts up. One is the system-wide psqlrc file, and one is in the home-directory of the login that's running psql, ~/.psqlrc. .  So, you could add the SET command that you always want to be run, to your .psqlrc file, and it'll get executed every time you start up. See the example below:  .  ",
      "P-tags": "postgresql psql shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP when S"
    },
    {
      "id": "au_1131408",
      "task": "SSH accepts key but SSHFS doesn't",
      "P-task": "ssh accept key sshf",
      "F_verb": "accept",
      "P-body": "You're mounting \"sshfs\" from \"root\" or using \"sudo\", while \"ssh\" is called with your normal user. .  So \"sshfs\" Host key is not in \"~/.ssh/known_hosts\", but \"/var/root/.ssh/known_hosts\". .  Remove line 4 of that file and it will work: .  Alternatively, run \"sshfs\" with your normal user without \"sudo\". .  ",
      "P-tags": "network server ssh",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP"
    },
    {
      "id": "so_9403703",
      "task": "Find/Sed not working as expected",
      "P-task": "find sed work expect",
      "F_verb": "find",
      "P-body": "Citate from \"man sed\": .  So \"find / -maxdepth 3 -type f -print0 | xargs -0 sed -e 's/[tT][eE][sS][tT][sS][tT][rR][iI][nN][gG]1/itworked!/g' -i\" will work as you want. .  If you do not like ugly pattern for case insensitive matches, you can use perl instead of sed: \"find / -maxdepth 3 -type f -print0 | xargs -0 perl -pe 's/teststring1/itworked!/ig' -i\" .  ",
      "P-tags": "linux sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "au_498904",
      "task": "Why do I get internet connection without a defined interface?",
      "P-task": "get internet connect without defin interfac",
      "F_verb": "get",
      "P-body": "Interfaces are started automatically during the boot process. This is for for example \"eth0\" for the first ethernet  .  The entries for \"lo (loopback)\" are generally required and may also when using the \"Network Manager\" can not be removed or other graphical configuration tool. .  Generally, \"/etc/network/interfaces\" contains network interface configuration information for the \"ifup\" and \"ifdown\" commands. This is where you configure how your system is connected to the network. .  Unless you manually configured \"/etc/network/interfaces\" with .  \"iface <Interface> <Protocoll> <Method>\" .  Your interface gets DHCP and connects you to the network. .  These two entries: .  are fundamental components of Linux. If these entry's are gone, interfaces can no longer communicate with each other. .  Read More about network interface configuration.  .  Finally, I guess your VM gets a bridge interface from your host. You can list all your interfaces running \"ifconfig -a\" and you can see which interface connecting you to the internet.  .  ",
      "P-tags": "virtual internet virtualbox-network",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP without NP"
    },
    {
      "id": "au_181481",
      "task": "How to create files and directorys in var/www?",
      "P-task": "creat file directori var www",
      "F_verb": "create",
      "P-body": "In a terminal use the next commands: .  cd = Change Directory .  mkdir = Make Directory, this command requires elevated privileges, so run it with sudo or gksudo .  (where foldername is the name of the folder that you wish to create). .  You can create subfolders from within \"/var/www\" without changing to the desired destination by using:  .  cp = Copy one or more files to another destination .  This can be used for any kind of file. .  Note: If you wish to use a GUI for these tasks, you can use Nautilus with elevated privileges, simply hit Alt+F2 and write \"gksudo nautilus\", then Enter after which you will see Nautilus File Browser, press Control+L and write \"/var/www\" and you can copy/paste or drag/drop anything you wish with ease. .  For a comprehensive list of the commands, visit: http://ss64.com/bash/ .  Good luck! .  ",
      "P-tags": "lamp",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_40597774",
      "task": "Exit status set by comparison operator in bash script",
      "P-task": "exit statu set comparison oper bash script",
      "F_verb": "set",
      "P-body": "\"$?\" is explained, though very briefly, in the Special Parameters parameters section of \"man bash\": .    @chepner put it best in his comment: .   The key thing to understand is that each \"[ ... ]\" is a separate foreground pipeline, not part of the if statement's syntax, and they are executed in order, updating \"$?\" as you go along. .   If you want to use an if-else chain, then save the value of \"$?\" in a variable, and use conditions on that variable: .  But in this example, a \"case\" would be more practical: .  ",
      "P-tags": "set statu exit bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V by NP in NP"
    },
    {
      "id": "so_26508028",
      "task": "bash : read a line from a file and interpret this line",
      "P-task": "bash : read line file interpret line",
      "F_verb": "read",
      "P-body": "Just change: .  With: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_580085",
      "task": "sort replacing column values with NA",
      "P-task": "sort replac column valu na",
      "F_verb": "replace",
      "P-body": "See \u03b1\u0493s\u043d\u03b9\u03b7's comment. I expected the NAs to be created by sort; however they were present in the file all along. .  Once the NAs were removed upstream \"> sort -k 1,1 Coch_ATAC_peaks.bed\" works as intended. .  ",
      "P-tags": "sort window",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP"
    },
    {
      "id": "so_54059823",
      "task": "How to delete 1 or more matching line(s) while reading a file in bash script",
      "P-task": "delet 1 match line read file bash script",
      "F_verb": "delete",
      "P-body": "As you mentioned you don't need line which has \"z*\" .  Simply use \"grep -v\" .  I have created one scenario where I have a file which contains .  In my case, I want to remove the line contains \"world\" .  If you want you can redirect your output in another file. .  ",
      "P-tags": "script linux shell bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP while S"
    },
    {
      "id": "so_2329905",
      "task": "Error compiling BASIC \"libnotify\" code",
      "P-task": "error compil basic libnotifi code",
      "F_verb": "compile",
      "P-body": "Sounds like you forgot to pass \"-lnotify\" to actually link against libnotify. .  ",
      "P-tags": "linux compiler-error gcc c linker",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP"
    },
    {
      "id": "so_41597859",
      "task": "Using PowerShell to modify MS Word cell borders",
      "P-task": "use powershel modifi ms word cell border",
      "F_verb": "modify",
      "P-body": "Aha! I found it. I was trying for a way to do it in one line, but I found that if I just edit each row as I'm adding the data to it, then I can get the whole table that way. This is the line I added to my Foreach loop: .  I would still love a link to some good documentation if anyone knows of any! .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "su_684034",
      "task": "Why am I suddenly unable to write to this sshfs volume?",
      "P-task": "suddenli unabl write sshf volum",
      "F_verb": "write",
      "P-body": " Sources: .   https://askubuntu.com/questions/13843/gedit-sshfs-wont-save-vi-saves-fine https://bugs.kde.org/show_bug.cgi?id=158098  ",
      "P-tags": "linux sshf permiss ssh",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP"
    },
    {
      "id": "ul_104094",
      "task": "Is there any way to enable Ctrl+L to clear screen when 'set -o vi' is set?",
      "P-task": "way enabl ctrl+l clear screen set -o vi set",
      "F_verb": "enable",
      "P-body": "Ctrl+L is also bound in \"vi\" command mode but not in insert mode. There's no default binding for \"clear-screen\" in insert mode. Readline bindings should be specified in \"~/.inputrc\", like so: .  This will bind Ctrl+L to clear the screen in both normal and insert mode. Naturally, if you prefer to only use it in one mode, just remove the relevant option. .  If you prefer to set this just for \"bash\" use the following equivalents in \"~/.bashrc\": .  There is an extensive list of readline commands that you can use to customize your bash shell with. .  ",
      "P-tags": "readlin vi-mod bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP S_INF when S"
    },
    {
      "id": "so_68278853",
      "task": "How to extract XML data in shell script?",
      "P-task": "extract xml data shell script",
      "F_verb": "extract",
      "P-body": "This answer may help How to parse XML using shellscript? .  Easier way is, if you know exactly what tag you want you can do .  rg is ripgrep (https://github.com/BurntSushi/ripgrep), a great tool but you need to install .  ",
      "P-tags": "xml shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_38300468",
      "task": "set a Powershell Data Entry to non Resizeable",
      "P-task": "set powershel data entri non resiz",
      "F_verb": "set",
      "P-body": "Set the \"FormBorderStyle\" property of the form to \"Sizable\": .   .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "au_440033",
      "task": "When using Bumblebee, how do I query the current state of the nvidia card?",
      "P-task": "use bumblebe queri current state nvidia card",
      "F_verb": "use",
      "P-body": "You can check that using \"cat /proc/acpi/bbswitch\": .  If for some reason it stays on when you are not using it, check your Bumblebee configuration (stored in \"/etc/bumblebee/bumblebee.conf\"), more precisely the \"PMMethod\" value. .  ",
      "P-tags": "nvidia bumblebe",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_253771",
      "task": "Sanity check (MD5 sums) fails after joining a file",
      "P-task": "saniti check md5 sum fail join file",
      "F_verb": "join",
      "P-body": "@veggieVampire Please always debug script with 'sh -x bash_script.sh' , I fount when the script runs on bash it send command like following. .  use \"sh -c \"cat $filename.* > $newfilename\"\" on 5th line insted of \"cat $filename.* > $newfilename\" .  And again this script cannot be use for text file because when we use 'split' command. All the text lines were spliting to each file in a sluggesh manner. If you cat the file you can see that. .  Thanks. .  ",
      "P-tags": "split cat",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_27916116",
      "task": "Writing a built in object for Linux Kernel?",
      "P-task": "write built object linux kernel",
      "F_verb": "write",
      "P-body": "For example consider that your source is under \"driver/new\" in the linux kernel source tree. You need to modify \"Makefile's\" under \"drivers\" and \"new\" to build your module statically into linux kernel. .  Under \"drivers/Makefile\" add the below line at the end. .  Under \"drivers/new/Makefile\" add the below line at the end. .  After build the linux kernel. And load to see that your module has printed the \"printk\" messages using \"dmesg\" command. .  Note: When building module statically into linux, change .  to .  and change  .  to  .  ",
      "P-tags": "linux c linux-kernel",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP for NP"
    },
    {
      "id": "au_774867",
      "task": "How to: automatically restart Ubuntu server every 6 months as a scheduled task?",
      "P-task": ": automat restart ubuntu server everi 6 month schedul task",
      "F_verb": "restart",
      "P-body": "You can configure a cron job for this task.  .  Will reboot the computer every 6 months at 12:00  .  ",
      "P-tags": "reboot schedul autom",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP as NP"
    },
    {
      "id": "so_50282612",
      "task": "Rename all files in directory and subdirectory",
      "P-task": "renam file directori subdirectori",
      "F_verb": "rename",
      "P-body": "The following one-liner will likely work for you: .  The following form is likely more correct as it will change only the last \"@\" to \"_\" if there are multiple occurrences of @me01 in the file: .  This latter form is also more flexible and can be built upon more easily as the regex language in sed is much more powerful than rename expressions. .  If rename of directories is also required the following can easily be added... .  Either: .  Or: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_45760692",
      "task": "Separately redirecting and recombining stderr/stdout without losing ordering",
      "P-task": "separ redirect recombin stderr stdout without lose order",
      "F_verb": "redirect",
      "P-body": "Preserving perfect order while performing separate redirections is not even theoretically possible without some ugly hackery. Ordering is only preserved in writes (in O_APPEND mode) directly to the same file; as soon as you put something like \"tee\" in one process but not the other, ordering guarantees go out the window and can't be retrieved without keeping information about which syscalls were invoked in what order. .  So, what would that hackery look like? It might look something like this: .  That said, this remains ugly hackery: It only catches writes direct to FDs 1 and 2, and doesn't track any further redirections that may take place. This could be improved by performing the writes to FIFOs, and using sysdig to track writes to those FIFOs; that way \"fdup()\" and similar operations would work as-expected; but the above suffices to prove the concept). .   Making Separate Handling Explicit Here we demonstrate how to use this to colorize only stderr, and leave stdout alone -- by telling \"sysdig\" to generate a stream of JSON as output, and then iterating over that: .  Because we're keying off the output filenames (\"stdout\" and \"stderr\"), these need to be constant for the above code to work -- any temporary directory desired can be used. .   Obviously, you shouldn't actually do any of this. Update your program to support whatever logging infrastructure is available in its native language (Log4j in Java, the Python logging module, etc) to allow its logging to be configured explicitly. .  ",
      "P-tags": "script linux bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_35580862",
      "task": "device-tree mismatch: .probe never called",
      "P-task": "device-tre mismatch : probe never call",
      "F_verb": "call",
      "P-body": "There are a number of possible ways this might happen, and most of them are well away from the driver code itself. Firstly, a .dtsi fragment alone doesn't tell the whole story - the device tree syntax is hierarchical, so the properties (in particular the \"status\") might still be overridden by the board-level .dts which includes a basic SoC .dtsi file. Secondly, the compiled DTB isn't the last word either, since the bootloader may dynamically modify it before passing it to the kernel - this is typically done for memory nodes and SMP enable methods, but could potentially affect anything. .  This kind of debugging is often best tackled in reverse, by examining the state of the booted system, then working backwards to figure out how things got that way - the specifics of this particular question rule some of this out already, but for the sake of completeness: .   If the kernel knows about the driver, and it's loaded and properly initialised, it should show up somewhere in /sys/bus/*/drivers/ - otherwise, it may be in a module which needs loading, or it may have failed to initialise due to some unmet dependency on some other driver or resource. If the kernel knows about the device, it should show up somewhere in /sys/bus/*/devices/, and if it's correctly bound to a driver and probed then they should both have a symlink to each other. If the device is nowhere to be found, then on a DT-based system the next place to check would be /proc/device-tree/ (dependent on CONFIG_PROC_DEVICETREE on older kernels, and canonically found in /sys/firmware/devicetree/base/ on newer ones) - this will show the view of the DT as the kernel found it, and a bit of poking around there should hopefully make clear any missing nodes or out-of-place properties, such as a disabled node causing the kernel to skip creating a device altogether. Beware that the property files themselves are just the raw data - so you probably want to go snooping with hexdump rather than cat - and that all numeric cells are in big-endian byte order.  ",
      "P-tags": "linux-device-driv arm linux-kernel device-tre",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V"
    },
    {
      "id": "so_10637290",
      "task": "Does RCHAR include READ_BYTES (proc/<pid>/io)?",
      "P-task": "rchar includ read_byt proc pid io",
      "F_verb": "include",
      "P-body": "I can only think of two things: .  http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=blob;f=Documentation/filesystems/proc.txt;hb=HEAD#l1305 .  1: .  I read \"Caused to be fetched from the storage layer\" to include readahead, whatever. .  2: .  Note that this says nothing about \"disk access via memory mapped files\". I think this is the more likely reason, and that your MonetDB probably mmaps out its database files and then does everything on them. .  I'm not really sure how you could check the used bandwidth on mmap, because of its nature. .  ",
      "P-tags": "monetdb linux io linux-kernel procf",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP"
    },
    {
      "id": "so_41196243",
      "task": "PHP Cron Job set but not running",
      "P-task": "php cron job set run",
      "F_verb": "run",
      "P-body": "As far as I can see, your crontab contains the following line: .  The URL is invoked as a shell command as if you entered \"http://example.com/cron/sendsms.php\" in a terminal and pressed Enter. If you want to call the remote PHP script, you should use an HTTP client, e.g. .  The command above sends an HTTP GET request to the URL and prints the response to the null device (a common way to ignore the output). .   As an aside, the way you append entries to crontab is incorrect in many respects. .  You shouldn't be using the shell \"echo\" command, use \"printf\" instead. .  Use \"$(...)\" for the command substitution instead of the back quotes, since a) it is impossible to build a nested command substutition, and b) the \"$(...)\" form is more readable. .  Avoid complex shell constructs in PHP. If you need a complex shell construct, you should create a separate file for the shell script. .  You might append the crontab entry with the help of \"proc_open()\" without the need for the shell pipes. .  ",
      "P-tags": "url php crontab cron shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "su_78917",
      "task": "Ubuntu Firefox it is saying that it is already running but not responding",
      "P-task": "ubuntu firefox say alreadi run respond",
      "F_verb": "run",
      "P-body": "It's probably that your profile is locked; happens on unclean shutdown sometimes. .  See this support page on Mozilla.com, specifically: .   \"pkill firefox\" (or restart your computer). Don't try to start Firefox. Go to your Firefox profile folder - see How to find your profile. Delete the lock file parent.lock  Your profile is in ~/.mozilla/firefox/*.default/ (the * will be a random sequence of 8 letters) .  \"rm parent.lock\" and try again. .  ",
      "P-tags": "ubuntu firefox",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_ING"
    },
    {
      "id": "au_181381",
      "task": "What package creates /usr/lib/jvm/default-java?",
      "P-task": "packag creat usr lib jvm default-java",
      "F_verb": "create",
      "P-body": "You can search for this information using apt-file. You may need to setup apt-file before you can use it. .  It reports that \"default-jre-headless\" is the package you should be looking for. .  You may find this question on Super User useful .  ",
      "P-tags": "11 10 java",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "au_666933",
      "task": "How to install python3-django in 14.04?",
      "P-task": "instal python3-django 14 04",
      "F_verb": "install",
      "P-body": "If you wish to install the latest version of Django globally, a better option is to use pip, the Python package manager. First, you need to install the pip package manager. Refresh your apt package index: .  Now you can install pip. If you plan on using Python version 3, install using the following commands: .  Now that you have pip, we can easily install Django. If you are using Python 3, you can type: .  You can verify that the installation was successful by typing: .  The Source. .  ",
      "P-tags": "14 04 django python3",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1120452",
      "task": "How can I safely remove snap without breaking apparmor",
      "P-task": "safe remov snap without break apparmor",
      "F_verb": "remove",
      "P-body": "The AppArmor profile is located in /etc/apparmor.d/usr.lib.snapd.snap-confine.real file, which came from \"snapd\" package. .  So you should use \"apt purge\" instead \"apt remove\" (see \"man apt\" for details): .   Small note: for me the snippet below looks better - .  ",
      "P-tags": "apparmor 18 10 snap",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_56056002",
      "task": "Suppress blank line from robocopy in PowerShell",
      "P-task": "suppress blank line robocopi powershel",
      "F_verb": "suppress",
      "P-body": "You can filter empty lines with command like below: .  ",
      "P-tags": "powershel robocopi",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_2399724",
      "task": "Using a filename with spaces with scp and chmod in bash",
      "P-task": "use filenam space scp chmod bash",
      "F_verb": "use",
      "P-body": "It turns out that what is needed is to escape the path which will be sent to the remote server. Bash thinks the quotes in SERVER:\"/var/www/tmp/$1\" are related to the $1 and removes them from the final output. If I try to run: .  Echoing we see it is trying to execute: .  If instead the quotes are escaped literals then the scp command looks more like you'd expect: .  With the addition of some code to truncate the path the final script becomes: .  ",
      "P-tags": "scp ssh bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_44700502",
      "task": "How to determine if a variable is returning a comparable statement",
      "P-task": "determin variabl return compar statement",
      "F_verb": "determine",
      "P-body": "Faced this problem before where the \"if\" returns \"true\" if the variable exists, and is set to a non-false value (not necessarily to true, but some value). .  Do this: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "au_984051",
      "task": "How do I install packages to TeXstudio?",
      "P-task": "instal packag texstudio",
      "F_verb": "install",
      "P-body": "I think you should install only these packages: .   \"texstudio\" for TeXstudio 2.10.8  \"texlive-latex-extra\" for placeins.sty and sectsty.sty  with .   One can always find needed packages by using search on https://packages.ubuntu.com using Search the contents of packages section - see example for \"placeins.sty\". .  ",
      "P-tags": "16 04 latex",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_65519588",
      "task": "Make a table out of array elements in Bash",
      "P-task": "make tabl array element bash",
      "F_verb": "make",
      "P-body": "Use \"printf\" for printing four elements per line, then align columns with \"column\". .  You can also use a simple function to generate the format string for \"printf\" if the number of columns is dynamic. .  ",
      "P-tags": "array multiple-column bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_25837184",
      "task": "Where are we supposed to look for C++ constants? (that appear in MSDN documentation)",
      "P-task": "suppos look c++ constant\nappear msdn document",
      "F_verb": "look",
      "P-body": "The very link you posted has the answer: .   Header \"Shlobj.h\" .   You'll find the constants in the header file. The headers are distributed with the SDK. .  ",
      "P-tags": "c++ c net shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V for NP that S"
    },
    {
      "id": "so_17294405",
      "task": ".m file to executable file in linux to run in another linux machine",
      "P-task": "file execut file linux run anoth linux machin",
      "F_verb": "run",
      "P-body": "You can run the created files on other linux machines by \"sh run_newfile.sh\". You cannot create exe-files for windows machines on linux machines. For creating windows-executable Exe-Files you have to use a windows machine. .  ",
      "P-tags": "matlab linux",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP"
    },
    {
      "id": "ul_462336",
      "task": "With gnu find, what is the difference between -print0 and -printf \"%p\\0\"",
      "P-task": "gnu find differ -print0 -printf p 0",
      "F_verb": "find",
      "P-body": "There should be no difference. Pipe the output through \"cat -v\" which will escape non-printable characters. .  Perhaps you have some special locale settings, which modifies what \"-print0\" does. At least with my en_US.UTF-8 settings there is no difference. Perhaps add the output of \"locale\" to your question. .  Possibly your test with ruby causes ruby to interpret the \"\\0\" itself, and \"find\" is not even executed. .  ",
      "P-tags": "rubi null find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V what S"
    },
    {
      "id": "so_62878819",
      "task": "SQL Error: Only a SQL server provider is allowed on this instance",
      "P-task": "sql error : sql server provid allow instanc",
      "F_verb": "allow",
      "P-body": "As I mentioned in the comment, SQL Server on Linux does not support Linked servers for anything other than other SQL Servers. From the documentation Editions and supported features of SQL Server 2017 on Linux: .   Unsupported features & services The following features and services are not available SQL Server 2017 on Linux. The support of these features will be increasingly enabled over time. .   Notice that it specifically states \"Linked Servers to data sources other than SQL Server\". If you need a linked server to a different source, you will need to use SQL Server on Windows at this time. .  ",
      "P-tags": "sql-server-on-linux sql-server",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V on NP"
    },
    {
      "id": "so_3127638",
      "task": "Tips to write thread-safe UNIX code?",
      "P-task": "tip write thread-saf unix code",
      "F_verb": "write",
      "P-body": "The simple thing to do is read a little. The following list contains some stuff to look at and research. .   Spend time reading the Open Group Base Specification particularly the General Information section and the subsection on threads. This is the basis information for multithreading under most UN*X-alike systems. Learn the difference between a mutex and a semaphore Realize that everything that is shared MUST be protected. This applies to global variables, \"static\" variables, and any shared dynamically allocated memory. Replace global state flags with condition variables. These are implemented using \"pthread_cond_init\" and related functions.  Once you understand the basics, learn about the common problems so that you can identify them when they occur: .   Lock inversion deadlocks Priority inversion - if you are interested in a real life scenario, then read this snippet about the Mars Pathfinder  ",
      "P-tags": "thread-safeti multithread c unix",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "ul_409393",
      "task": "How to grep all value starting with \"sg\" in my case",
      "P-task": "grep valu start sg case",
      "F_verb": "grep",
      "P-body": "Try this: .   \"[^ ]*\" means other than space character. You can also use \"[0-9a-f]\" if you know they consist of only hex characters pipe it to \"sort -u\" or \"sort | uniq\" or \"awk '!seen[$0]++'\" to remove duplicates   \"sg*\" means match \"s\" followed by \"g\" zero or more times .  ",
      "P-tags": "grep sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_23269690",
      "task": "How to use grep with two patterns?",
      "P-task": "use grep two pattern",
      "F_verb": "use",
      "P-body": "This should work for you: .  NOTE: I couldn't find any words ending in \"sx\" on the dictionary I've used. .  ",
      "P-tags": "command-lin bash shell regex",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_361923",
      "task": "How can I identify a strange character?",
      "P-task": "identifi strang charact",
      "F_verb": "identify",
      "P-body": "Your file contains two bytes, EB and 0A in hex. It\u2019s likely that the file is using a character set with one byte per character, such as ISO-8859-1; in that character set, EB is \u00eb: .  Other candidates would be \u03b4 in code page 437, \u00d9 in code page 850... .  \"od -x\"\u2019s output is confusing in this case because of endianness; a better option is \"-t x1\" which uses single bytes: .  \"od -x\" maps to \"od -t x2\" which reads two bytes at a time, and on little-endian systems outputs the bytes in reverse order. .  When you come across a file like this, which isn\u2019t valid UTF-8 (or makes no sense when interpreted as a UTF-8 file), there\u2019s no fool-proof way to automatically determine its encoding (and character set). Context can help: if it\u2019s a file produced on a Western PC in the last couple of decades, there\u2019s a fair chance it\u2019s encoded in ISO-8859-1, -15 (the Euro variant), or Windows-1252; if it\u2019s older than that, CP-437 and CP-850 are likely candidates. Files from Eastern European systems, or Russian systems, or Asian systems, would use different character sets that I don\u2019t know much about. Then there\u2019s EBCDIC... \"iconv -l\" will list all the character sets that \"iconv\" knows about, and you can proceed by trial and error from there. .  (At one point I knew most of CP-437 and ATASCII off by heart, them were the days.) .  ",
      "P-tags": "unicod character-encod",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_43004441",
      "task": "How to get unicode input from xcb without further ado",
      "P-task": "get unicod input xcb without ado",
      "F_verb": "get",
      "P-body": "Not sure if it will be of any help, but... .  You are probably looking for a family of X*LookupString functions: .  http://www.xfree86.org/current/Xutf8LookupString.3.html .  Now, I had the same problem as you, that is, I needed to port an application using WinAPI's \"WM_CHAR\" to one that uses \"xcb\" coupled with \"X11\" (as such coupling is necessary for an OpenGL window). I didn't exactly need Unicode, but I was still lost because there was nothing to let me obtain composed input from the keystrokes (e.g. pressing \"shift\" and \"7\" should result in \"&\") .  Unfortunately, to quote xcb's to-do list: .   Current status .  Currently, XCB only implements the bits given in the X Window System Protocol, and even this support is not complete compared to Xlib (character encoding, no XLookupString()...). .   So, if you have to use \"xcb\", it makes things all the harder, as there are no equivalent \"X*LookupString\" functions for the key press event returned by xcb - \"xcb_key_press_event_t\". What you need to do is to convert it to \"XKeyEvent\" understandable by, for example, \"XLookupString\".  .  Now, looking at the source of \"XLookupString\" , we can see it only ever uses three fields of \"XKeyEvent\": .   \"display\" - your \"Display\" \"keycode\"- the pressed key \"state\" - the state of the modifier keys, e.g. shift or caps lock   It just so happens that there are corresponding fields in \"xcb_key_press_event_t\" that are pretty much identical to the ones we need. What I did to make my particular application work was this:  .  It also looks like \"XLookupString\" outputs a keysym correspondent to the composed character, via its in-out \"KeySym *keysym_return\" argument. As you say that you also need keysyms, you might want to use it. .  I'm not doing a professional application, so this is all I needed, and I'm not really sure what's the course of action for full Unicode support, but if I ever get to it, I'll let you know. .  ",
      "P-tags": "xcb unicod linux input keyboard",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP without NP"
    },
    {
      "id": "au_1043752",
      "task": "iptable matching rule for STUN/TURN traffic",
      "P-task": "iptabl match rule stun turn traffic",
      "F_verb": "turn",
      "P-body": "The iptables u32 module offsets are referenced to the packet minus the ethernet wrapper (minus the source and destination MAC, 6 bytes each, and the ether type, 2 bytes. Therefore your wireshark offset of 46 needs to adjusted by 14, and should be 32. .  Now, for a sanity check, find the type of service byte, which we know from the u32 area of the man pages for iptables-extensions is at offset 9 and we also know is 0x11 (17) for UDP. It is at byte 0x17 (23) of your wireshark screenshot. Counting from there, we also get 32 as the offset you should be using. .  EDIT 1: Since the protocol is UDP, you also need to adjust that part of your iptables command. So: .  EDIT 2: In your example wireshark screen shot, the destination port is 5004, not 443. So the iptables command still will not work for your particular packet example. Maybe this: .  ",
      "P-tags": "nat iptabl",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "ul_92911",
      "task": "what is \"play\" command/package available by default in Linux Mint and how to remove it",
      "P-task": "play command packag avail default linux mint remov",
      "F_verb": "remove",
      "P-body": "You can find out which package it belongs to by using \"dpkg\": .  This will give you output that looks something like this: .  If you have no use for this package, you can then remove that package with \"apt-get remove\", or \"apt-get purge\" if you want to purge the configuration files, too. .  If you instead get \"no path found matching pattern\", this file is not owned by any package, in which case you should carefully consider your options. You could remove it manually, but perhaps some installed package that was not installed by your package manager requires it. .  You can also override the \"play\" binary that is called by putting your preferred binary at a location earlier in your \"PATH\". To do that, you would invert the order of concatenation in your \"export PATH\" statement: .  ",
      "P-tags": "package-manag linux-mint command",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_10928659",
      "task": "Simultaneously execute two queries on a shell script",
      "P-task": "simultan execut two queri shell script",
      "F_verb": "execute",
      "P-body": "Use \"&\" to background the queries, then \"wait\" to wait for all subprocesses to finish, and then the c++ thing that processes the results. Code: .  ",
      "P-tags": "sql shell oracl",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_343890",
      "task": "replace full stop by comma",
      "P-task": "replac full stop comma",
      "F_verb": "replace",
      "P-body": " ",
      "P-tags": "awk linux sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP by NP"
    },
    {
      "id": "so_14589543",
      "task": "Powershell compare huge directory tree of docs and only move new and updated",
      "P-task": "powershel compar huge directori tree doc move new updat",
      "F_verb": "compare",
      "P-body": "look at /D parameter of xcopy : .  Copy files changed on or after the specified date. If no date is given, copy only files whose source date/time is newer than the destination time. .  ",
      "P-tags": "powershel robocopi",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP of NP"
    },
    {
      "id": "so_48452697",
      "task": "remove all autogenerated ._* duplicates from a repository",
      "P-task": "remov autogener _ duplic repositori",
      "F_verb": "remove",
      "P-body": "This works on Linux:  .  Try it first without the \"|xargs rm\" part, just to validate that the find will actually list the files you want deleted.  .  ",
      "P-tags": "git linux svn maco",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_454962",
      "task": "Mounting volume/partition with permissions for user",
      "P-task": "mount volum partit permiss user",
      "F_verb": "mount",
      "P-body": "If it's in \"/etc/fstab\" then it will mount at boot. As only \"root\" has write permissions then you you'll need to modify it so that the user has those permissions. The best way is: .  If the \"root\" group has write permission as well and you want another group to have it then you can use: .  If the \"root\" group doesn't have write access, then you can use \"chmod\" next: .  That will give write permission to the group if it's not there and read and execute to everyone else. You can modify the \"775\" to give whatever permissions you want to everyone else as that will be specified by the third number. .  To better cover what you asked in your comment below: .  You can add the \"user\" option to \"/etc/fstab\" but that only allows the file system to be mounted by any user. It won't change the permissions on the file system which is why you need \"chown\" and/or \"chmod\". You can go ahead and add the \"user\" option so that a regular user without \"sudo\" can mount it should it be unmounted.  .  For practicality, the best option here is \"chown\" as it gives the user the needed permissions instantly. The \"chmod\" command can be used afterwards if the permissions need to be modified for others. .  ",
      "P-tags": "mount permiss",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP with NP for NP"
    },
    {
      "id": "so_42261900",
      "task": "Powershell: Save entire command into variable during script",
      "P-task": "powershel : save entir command variabl script",
      "F_verb": "save",
      "P-body": "Assign the variable as usual like this: .  then  .  The other way, is, wrap it all up into a variable itself, similar to the above: .  Invoke it like this: .  The first example would be more beneficial for different environments where this can be deployed to, multiple times over, especially, in cases of like, for example,Octopus Deploy, run the script block across multiple machines with tentacles, that is one such example that springs to mind. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP into NP"
    },
    {
      "id": "so_22277892",
      "task": "Wait for Network Interface Before Executing Command",
      "P-task": "wait network interfac execut command",
      "F_verb": "wait",
      "P-body": "This command should wait until it can contact google or it has tried 50 times: .  The \"for i in {1..50}\" loops 50 times or until a \"break\" is executed. The \"ping -c1 www.google.com\" sends 1 ping packet to google, and \"&> /dev/null\" redirects all the output to null, so nothing is outputed. \"&& break\" executes break only if the previous command finished successfully, so the loop will end when \"ping\" is successful. .  ",
      "P-tags": "network shell bash",
      "source": "qa",
      "cate": "wait/await/sleep",
      "pat": "V for NP before S_ING"
    },
    {
      "id": "ul_123908",
      "task": "How to get CPU Percentage as a Counter?",
      "P-task": "get cpu percentag counter",
      "F_verb": "get",
      "P-body": " (uptime-(idle_time/num_core)) .   May give an idea of how long the system has been busy, in seconds. Multipling that by 100 makes it centiseconds -- is that your intention? .  IMO it would make more sense to consider how many processor seconds in total were available, and subtract the idle time from that: .  A utilization metric might be: .  E.g., if the system has been up for 10 seconds on 4 cores with 5 seconds of idle_time: .  87.5% utilization. .  Or: .  Same thing, saves an operation. .    Is there a better way to get CPU utilization as a counter? .   I've done this in a system diagnostics C++ library by parsing the first line of \"/proc/stat\", which is a combined total for all cores. The first three fields are user time, low priority (aka nice) time, and system time. The total of these is the amount of active time (note the unit here is not seconds, see \"/proc/stat\" under \"man proc\"). .  If you poll this over 5 seconds, assuming a USER_HZ of 100, where \"total_a\" is the first sample (user + nice + sys) and \"total_b\" is the second sample: .  If you multiply that by 100, you have a percentage indicating an average over the 5 second interval. .  Here's the logic: .   \"total_b - total_a\" = active time between samples .  Divided by the duration of the sample, 5 seconds. .  Divided by the units per second of the measurement (USER_HZ) .  Divided by the number of cores .   USER_HZ is almost certainly 100. To check: .  Compile: \"gcc whatever.c\", run \"./a.out\".  .  It will be hard to get an accurate duration for this with shell tools, so you could either keep an increasing measure of the total active time (I think that is your intention) or use a fairly long interval, e.g. 30+ seconds.  .  ",
      "P-tags": "monitor cpu linux",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP as NP"
    },
    {
      "id": "so_4378931",
      "task": "Perl preamble that will run under Windows or Linux",
      "P-task": "perl preambl run window linux",
      "F_verb": "run",
      "P-body": "I doubt that you can get windows to accept a shbang (\"#!\"). So if you can run with the default shell (in my case bash), then this works in bash: .  This required an executable in my NIX path called \"'@REM'\". .  ",
      "P-tags": "linux window perl shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V under NP"
    },
    {
      "id": "au_1139840",
      "task": "How to display a value with zenity?",
      "P-task": "display valu zeniti",
      "F_verb": "display",
      "P-body": "The problem is \"result = \"(1+1/$szAnswer)^$szAnswer\" | bc -l\" line. It reads: .   execute command \"result\" with parameters \"=\" and \"\"(1+1/$szAnswer)^$szAnswer\"\" connect the \"stdout\" stream of the \"result\" command to \"bc\" command's \"stdin\" stream  Probably you're wondering why \"result\" is a command in this case. That's because variable assignments in shell scripting are made without spaces separating variable name and assigned value. You also want to send \"\"(1+1/$szAnswer)^$szAnswer\"\" to \"stdin\" of \"bc -l\" command,so you need something capable of writing to \"stdout\" .  What should be done is .  Now you have \"result\" variable being assigned output of \"echo \"(1+1/${szAnswer})^${szAnswer}\" | bc -l\" pipeline. The \"$(...)\" structure is called command substitution, and is generally used when command's output has to be reused in place of the command itself.  .  ",
      "P-tags": "zeniti sh bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP with NP"
    },
    {
      "id": "so_45233381",
      "task": "awk merged two files with 2 columns based on string character comparison",
      "P-task": "awk merg two file 2 column base string charact comparison",
      "F_verb": "merge",
      "P-body": "Here is one shot at it in awk: .  Any better than that would require rules on processing the underscores and dashes in the names or approximate pattern matching with approriate algorithms (see for example Levenshtein distance). .  ",
      "P-tags": "awk linux bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "so_53661152",
      "task": "Compare CreationTime and user input",
      "P-task": "compar creationtim user input",
      "F_verb": "compare",
      "P-body": "This would be the answer: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "so_35863887",
      "task": "Job quits unexpectedly",
      "P-task": "job quit unexpectedli",
      "F_verb": "quit",
      "P-body": "Simultaneously writing to the same output file from different jobs is going to create a race condition unless you have a scheduler in place to coordinate write access. Also, if you want to read a log from an UNC path you need to provide the path as \"\\\\server\\share\\file\". .  Try something like this: .  Note that if you're still using PowerShell v2 you need to replace \"$jobs.State\" with \"@($jobs | Select-Object -Expand State)\", because PowerShell doesn't automatically unroll arrays on property access prior to v3. .  ",
      "P-tags": "powershel start-job concurr",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V"
    },
    {
      "id": "ul_671216",
      "task": "What is the correct way to merge two ASCII art files side by side while preserving alignment?",
      "P-task": "correct way merg two ascii art file side side preserv align",
      "F_verb": "merge",
      "P-body": "The trouble is each line has a different length. The easiest solution is to give a large enough width to \"pr\": .  If you want the caption text to get closer, I suggest .   \"n\" is the number of lines of the caption file. \"l\" is the length of the longest line between the first \"n\" lines of the art file. \"printf\" right-pads the art file with spaces so that it all its lines have \"l\" length. \"getline\" then gets a line from the caption file and prints it next to the just printed art line.  Note that you can add or subtract to the value of \"l\" in \"printf\" to ad-hoc adjust the spacing. .  ",
      "P-tags": "ascii-art linux pr past",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP by NP while S"
    },
    {
      "id": "so_27340598",
      "task": "RPM build errors:Bad exit status from /var/tmp/rpm-tmp.32XJLX (%install)",
      "P-task": "rpm build error : bad exit statu var tmp rpm-tmp 32xjlx instal",
      "F_verb": "build",
      "P-body": "The \"make -p $RPM_BUILD_ROOT/usr/local/bin\" line is your problem. .  While not the problem you almost certainly don't want \"-p\" on that line. As it doesn't do anything useful for you during compilation and your rpm build process has no need to see the make database of rules. .  The real problem is that you are telling make that you would like it to build the \"$RPM_BUILD_ROOT/usr/local/bin\" target which it is incredibly unlikely that make actually knows how to build (thus causing make to fail to build it and giving you an error). Removing the \"-p\" will help you see the actual error that make is spitting out as it will not also spit out the rule database stuff. .  I think you meant \"mkdir -p\" there instead. Which should be available as the \"%{__mkdir_p}\" macro.) .  ",
      "P-tags": "rpm-spec rpmbuild rpm bash cento",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "so_39882886",
      "task": "How to change filenames of files with no type in bash",
      "P-task": "chang filenam file type bash",
      "F_verb": "change",
      "P-body": "It works for pattern \"*.jpg\" because there are no \"jpg\" files in the folder you're running \"find\" on and the shell passes \"*.jpg\" unexpanded to the \"find\" command which passes it unexpanded to \"rename\" and it works. .  But when you do: .  the \"*\" is expanded with all files from current dir and passed to \"rename\" as-is, and that's not what you want. .  Do that instead: .  (that's also better for \".jpg\" files BTW :)) .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP with NP in NP"
    },
    {
      "id": "so_39016703",
      "task": "How to connect to Oracle database from another machine?",
      "P-task": "connect oracl databas anoth machin",
      "F_verb": "connect",
      "P-body": "Here's an example TNSNAMES.ORA from one of our servers: .  You also need to make sure that the LISTENER.ORA has been configured correctly and that both database and listener services are running.  .  After installing SQL*plus or SQL Developer, also make sure that on the client machine the TNSNAMES.ORA matches the server configuration, then try: .  and you should receive an \"OK\" as a result. .  Here's an article with more information (taken from \"dummies.com\", shouldn't be any insult ;-) ): .  http://www.dummies.com/how-to/content/how-to-connect-to-the-oracle-12c-database-instance.html .  ",
      "P-tags": "oraclecli tnsname linux oracle12c redhat",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP from NP"
    },
    {
      "id": "su_1281866",
      "task": "Can I reliably use `dd` to wipe the root filesystem on a running Linux server?",
      "P-task": "reliabl use dd wipe root filesystem run linux server",
      "F_verb": "use",
      "P-body": "Yes, this is absolutely possible, but it requires some work. .  Most of the answer is available on StackExchange, but I'll summarize here with links to the sources which have much more detail and deserve credit for excellent information. .   Build an in-memory base Linux environment and switch to it using \"pivot_root\". Ensure you can access the server from the outside using \"ssh\". Wipe the root device. .  \"# nohup dd if=/dev/urandom of=/dev/sda bs=512 > wipe.log &\" .  At intervals, feel free to check the progress of \"dd\", since it doesn't usually give you any indication of progress. .  \"# kill -USR1 [ddpid]\" .  Come back later and verify the process has completed (check log file). Have a look at the disk to verify it's got random junk on it instead of a real filesystem. Wipe it a second (or third) time if you'd like. .  Decide what to do next. .  If you want, you can simply stop here and walk away. When the machine powers down, you'll have a non-bootable device that is as secure as you decide \"dd\" can make it. .  What I decided to do next is try something I haven't done before: build a Linux base system remotely. So I continued: .  Use \"fdisk\" to re-partition the root device as desired, and use \"mkfs\" to create filesystems on those partitions. .  Use \"debootstrap\" to install a base Debian environment on the (future) root filesystem. \"chroot\" to the new base environment, install additional packages (e.g. \"sshd\") a kernel, and a bootloader (e.g. \"grub\" -- make sure the boot loader actually gets installed to the device -- don't just install the package). Use \"root_pivot\" to switch to the new environment in the same way you did in step #1 above. Bring-up all services (e.g. \"sshd\") to ensure you'll be able to access the server e.g. through \"ssh\". Reboot. Your fresh OS should be ready to go.  ",
      "P-tags": "wipe linux secur filesystem",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF on NP"
    },
    {
      "id": "ul_430309",
      "task": "How to grep an XML tag and get only the value inside the quotes after it?",
      "P-task": "grep xml tag get valu insid quot",
      "F_verb": "grep",
      "P-body": "This works for me: .  ",
      "P-tags": "xmllint linux grep",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_38034845",
      "task": "Windows failed to install flask-manager",
      "P-task": "window fail instal flask-manag",
      "F_verb": "install",
      "P-body": "\"flask-manager\" is alpha software, meaning it is in a ver early state of development. You should not expect alpha software to work 100%ly. .  In this case the \"setup.py\" references a file \"DESCRIPTION.rst\" which is not included in the distribution archive. Also the instructions on the website how to install (\"pip install https://github.com/hellupline/flask-manager.git\") are not working.  .  If you really want to try \"flask manager\", you can check it out from git hub and copy or symlink the \"flask_manager\" subfolder into your \"PYTHONPATH\". .  We aware that alpha software ist not considered to be production ready. .  ",
      "P-tags": "powershel python flask",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_52620378",
      "task": "rm -rf not deleting directories through python fork execl script",
      "P-task": "rm -rf delet directori python fork execl script",
      "F_verb": "delete",
      "P-body": "You need to pass the arguments separately. As \"-r\" and \"f\" are separate arguments to \"rm\". .  ",
      "P-tags": "python-2 7 python-3 x linux python bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP through NP"
    },
    {
      "id": "so_51595576",
      "task": "Set title based off employeeid",
      "P-task": "set titl base employeeid",
      "F_verb": "set",
      "P-body": "Based off your example looks like you are wondering how to do the If statement efficiently. TheIncorrigible1 pointed out in the comments that calling Get-ADUser in a foreach is extremely inefficient. You can call Get-AdUser once and pipe the output to a \"If\" that looks for Contains against the EmployeeID property. .  But when i read the full post I saw that you wanted to change the Title in AD to correspond to the Title in the CSV file. The Diffrence is instead of a if we will go to a foreach-object statement put the AD-Users into a var called $Users and then do a where statement on the CSV variable. At that point we will set the title using a Set-ADUser and output the information to the console. .  ",
      "P-tags": "array powershel import-csv",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_54404172",
      "task": "Change the current directory pwd, from the python script itself",
      "P-task": "chang current directori pwd python script",
      "F_verb": "change",
      "P-body": "The only way I can think of is actual workaround. Where you pick up the output of your script in current shell. Otherwise eveything gets executed in subshell. .  myprogram.py  In linux shell: .  ",
      "P-tags": "python bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_106131",
      "task": "PAM - required and sufficient control flag",
      "P-task": "pam - requir suffici control flag",
      "F_verb": "require",
      "P-body": "PAM proceeds through the items on the stack in sequence. It only keeps the memory of what state it's in (success or denied, with success meaning success so far), not of how it reached that state. .  If an item marked \"sufficient\" succeeds, the PAM library stops processing that stack. This happens whether there were previous \"required\" items or not. At this point, PAM returns the current state: success if no previous \"required\" item failed, otherwise denied. .  Similarly, if an item marked \"requisite\" fails, the PAM library stops processing and returns a failure. At that point, it's irrelevant whether a previous \"required\" item failed. .  In other words, \"required\" doesn't necessarily cause the whole stack to be processed. It only means to keep going. .  ",
      "P-tags": "pam authent",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_64366569",
      "task": "Read each word separated by comma",
      "P-task": "read word separ comma",
      "F_verb": "read",
      "P-body": "Change the field separator \"IFS\" to comma. .  And don't reuse the variable \"$username\" for both the file and your iteration variable. .  ",
      "P-tags": "unix bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP by NP"
    },
    {
      "id": "ul_23778",
      "task": "Printing the current date/time with sub-second precision",
      "P-task": "print current date time sub-second precis",
      "F_verb": "print",
      "P-body": "If you have a modern-enough Perl interpreter handy (\"Time::HiRes\" is bundled since 5.7.2), you could use some variation of this: .  Sample output: .  If you don't have perl (or don't want to use it), but you do have a C compiler, you could use this: .  ",
      "P-tags": "osx bsd",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP with NP"
    },
    {
      "id": "so_37594273",
      "task": "Powershell regex replace specific case/characters",
      "P-task": "powershel regex replac specif case charact",
      "F_verb": "replace",
      "P-body": "I would use a positive lookbehind and lookahead to find the position of the \"TO\" and replace it with \"to\": .   .  Regex Demo. .  PowerShell: .  ",
      "P-tags": "powershel regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "so_37652277",
      "task": "how to run topic model on 20000 documents at once?",
      "P-task": "run topic model 20000 document",
      "F_verb": "run",
      "P-body": "You are missing an asterisk: .  The above will list iterate over each file in \"bydocafterseg2\". You can change it to all \".txt\" files with: \"\"bydocafterseg2/\"*\".txt\"\" .  ",
      "P-tags": "mallet topic-model bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP at NP"
    },
    {
      "id": "so_10748575",
      "task": "How to replace the unit values with shell scripting",
      "P-task": "replac unit valu shell script",
      "F_verb": "replace",
      "P-body": "If you prefer perl: .  ",
      "P-tags": "string-pars shell bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP"
    },
    {
      "id": "so_34488716",
      "task": "Is there a way to store a logical operator in a Bash script variable",
      "P-task": "way store logic oper bash script variabl",
      "F_verb": "store",
      "P-body": "You can do this inside the \"[\" command: .  But you need to use \"-a\" for \"and\" (\"&&\") and \"-o\" for \"or\" (\"||\"). .  It is vitally important the you quote variable expansions when using \"[\". If you don't quote the expansion and the variable is empty or undefined, the test expression will have incorrect syntax. For example, if \"$var1\" is undefined, \"[ -n $var1; ]\" will be evaluated as \"[ -n ]\" which is always true. .  ",
      "P-tags": "script bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_19709",
      "task": "Use different authentication methods for OpenSSH server depending on client IP",
      "P-task": "use differ authent method openssh server depend client ip",
      "F_verb": "use",
      "P-body": "Use a \"Match\" directive in \"/etc/sshd_config\". .  You can restrict this to a few users (who you trust not to choose terrible passwords), for better security. .  ",
      "P-tags": "openssh ssh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "su_774554",
      "task": "Linux, Unable to get usb wifi drivers to work or compile",
      "P-task": "linux unabl get usb wifi driver work compil",
      "F_verb": "compile",
      "P-body": "The Vendor+Product code 148f:7601 displayed by lsusb is info enough. By looking up WikiDevi, we can see your dongle is a TP-Link TL-WN727N v4, or a Shenzhen Ogemray Technology GWF-7A05. In any case, rt2800usb is not the appropriate driver: the command .  which searches for Vendor and Product code of your dongle among those for which rt2800usb is loaded, yields no output. Hence you need a different driver. This explains why, even after a successful compilation and installation of rt2800usb, your interface has not come up yet.  .  The same Wikidevi page suggests mt7601u_sta as the most likely Linux module. You can get it from here. This is surely the driver you are looking for: in the file DPO_MT7601U_LinuxSTA_3.0.0.4_20130913/common/rtusb_dev_id.c, you can find the line .  which is what will appear in the output of modinfo mt7601u_sta. .  This, however, is the end of the good news: it does not compile on either my Arch or my Debian Jessie systems. Also, Googling around it appears no one has managed to make it compile successfully on a recent kernel. I have seen reports for 3.12 to 3.15.  .  Just to be on the safe side, I also checked whether the newest backports, here, support this card. They do not, and you can check it yourself by compiling and installing the wifi defconfig, then trying modinfo on the newly minted rt2800usb. No luck.  .  ",
      "P-tags": "wireless-network driver linux network",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V"
    },
    {
      "id": "au_303305",
      "task": "External sound card stops functioning after suspend",
      "P-task": "extern sound card stop function suspend",
      "F_verb": "suspend",
      "P-body": "Try the following command .  Try it a few times if it doesn't work .  ",
      "P-tags": "soundcard suspend sound 12 04 external-soundcard",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V"
    },
    {
      "id": "ul_552413",
      "task": "how to make a module install in linux",
      "P-task": "make modul instal linux",
      "F_verb": "make",
      "P-body": "\"make this module to install\", and .  \"how to make a module install\"  .  could combine into \"make modules_install\", which is a special make target. These other two targets are included in \"make\" (if in the linux source dir): .  That means \"make modules\" would compile all the configured modules. .  But do you mean that kind of \"making a module\"?  .  Maybe it is enough to \"modprobe v4l2loopback\", after you have installed the package. That would be inserting, or adding, a module to the kernel, manually.  .  ",
      "P-tags": "linux kernel-modul software-instal",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "su_906692",
      "task": "Why I can't access to this directory after that I use the chown command?",
      "P-task": "access directori use chown command",
      "F_verb": "access",
      "P-body": "If you have execute without read permission on a directory, you can include it in a path, but you cannot see its contents, so if you are in \"/var/www\" you can for instance see the contents of the \"html\" subdirectory with \"ls html\", even though you cannot see \"html\" with a simple \"ls\". You need to run: .  It's possible that you may not need \"sudo\": you can certainly first try it without. .  ",
      "P-tags": "linux file-permiss ubuntu chown permiss",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V to NP that S"
    },
    {
      "id": "ul_359974",
      "task": "Unable to create a user in FreeBsd: pw: user name or id required",
      "P-task": "unabl creat user freebsd : pw : user name id requir",
      "F_verb": "require",
      "P-body": "The fine manual for \"pw(8)\" shows: .  What happens when you copy the exact syntax indicated in the manual? E.g. .  or .  ",
      "P-tags": "freebsd",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V"
    },
    {
      "id": "so_69736274",
      "task": "docker can't connect to docker daemon but socket is created",
      "P-task": "docker connect docker daemon socket creat",
      "F_verb": "connect",
      "P-body": "It looks like you have a container configured to bind mount \"/var/lib/docker.sock\" and the daemon restarted that container before creating the socket. There's been some tweeks to packaging in recent releases to reduce this chance. Otherwise you may want to mount the entire directory instead of a single file. .  To fix, try stopping docker, deleting the empty directory, and restarting docker to see if the socket gets created first (it's a race condition). .  ",
      "P-tags": "ubuntu docker",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_58813347",
      "task": "how can I find and replace the string with quote?",
      "P-task": "find replac string quot",
      "F_verb": "find",
      "P-body": "Try: .  Changes to the OP code: .   Use \":\" for sed's delimiter to avoid escaping slashes in \"NEWDIR\" Use \"sed \"...\"\" instead of \"sed '...'\" to allow parameter expansion  test it with a here-string: .  ",
      "P-tags": "awk script shell bash sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "au_678100",
      "task": "batch rename zip files based on contained file names",
      "P-task": "batch renam zip file base contain file name",
      "F_verb": "rename",
      "P-body": " How it works This command has the form: .  This searches for .zip file in the current directory and all subdirectories under it. For each such file found the bash command in single quotes is executed. The name of the file found is supplied at argument one, \"$1\", to the bash command. In our case, the bash command has two parts. The first extracts the csv file name and saves it in bash variable \"name\": .  The above uses command substitution: the command inside \"$(...)\" is run and its standard out is captured. In this case, we assign it to the variable \"name\". The command \"unzip -qql \"$1\" '*_IPC.csv'\" quietly extracts all file names from the zip file that match the glob \"*_IPC.csv\". We don't need to limit to the glob \"*_IPC.csv\" but, if the zip file has many files in it, this may speed things up. .  The grep command, \"rep -oE '[[:digit:]]{8}_IPC.csv'\" further selects only those name that start with 8 digits. The \"head -n1\" command selects the first such name found. If there was only one such name, \"head -n1\" wouldn't be needed. But, keeping \"head\" could speed things up because it causes the pipeline to terminate after the first match. .  The second part tests that we succeeded in getting a non-empty \"name\" and, if so, renames the zip file: .  The above uses suffix removal to change the csv file name to a zip file name. \"${name%csv}\" returns \"$name\" after having removed the suffix \"csv\". \"${name%csv}zip\" adds a zip suffix. .  ",
      "P-tags": "command-lin batch-renam zip perl bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1085552",
      "task": "Make sourced .bash_profile works immediately in current ssh session",
      "P-task": "make sourc bash_profil work immedi current ssh session",
      "F_verb": "make",
      "P-body": "Just source the file by running \". .bash_profile\" will do the job. .  ",
      "P-tags": "ssh command-lin bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "so_32290490",
      "task": "How to convert the output to a variable?",
      "P-task": "convert output variabl",
      "F_verb": "convert",
      "P-body": "It's treating it as a string instead of a floating point number. You'll need to cast it: .  Or: .  Or: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_33019844",
      "task": "In python, execute multiple terminal commands on a same file and save all the changes once",
      "P-task": "python execut multipl termin command file save chang",
      "F_verb": "save",
      "P-body": "You can glue both \"sed\"s in one using \";\" : .  They will go one after another. .  ",
      "P-tags": "python sed bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "ul_257892",
      "task": "What service executes that sets up the real time clock",
      "P-task": "servic execut set real time clock",
      "F_verb": "execute",
      "P-body": "Usually that is \"ntp\" (the daemon named \"ntpd\") for Network Time Protcol. .  For example: .   Network Time Protocol daemon (Arch) RHEL7: How to set up the NTP service.  In Fedora, you may be looking for .  which is related to this package: .  ",
      "P-tags": "time linux systemd servic",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V that S"
    },
    {
      "id": "so_63592464",
      "task": "Github New Project but using same existing project",
      "P-task": "github new project use exist project",
      "F_verb": "use",
      "P-body": "Sounds like you want to fork your own project. In that case, you can simply make a local copy of your git repository and push it to a new github project. .   Create a new github project, name it whatever .   Make a copy of project A's directory on your computer, name it B. .   In the local copy of your git project, (directory B), change git's remote URL to the new github URL. .    where \"new-url\" is the new URL github tells you to push to when you created the new project. .   Finally push your project to github \"git push origin master\"  ",
      "P-tags": "github git-bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_32872912",
      "task": "How do I check if an array contains anything else than a specific value in bash?",
      "P-task": "check array contain anyth els specif valu bash",
      "F_verb": "check",
      "P-body": "As long as you're not using space in Array elements you can use: .  Testing: .  ",
      "P-tags": "array bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_14466414",
      "task": "Bash run a jar file on text files in a folder",
      "P-task": "bash run jar file text file folder",
      "F_verb": "run",
      "P-body": "Use a shell for loop: .  You can see what this is going to do by adding \"echo\" before \"java\" to show the command instead of running it: .  ",
      "P-tags": "jar bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP in NP"
    },
    {
      "id": "su_1284773",
      "task": "How can I add text to a file in front of a specific word from the Linux command line?",
      "P-task": "add text file front specif word linux command line",
      "F_verb": "add",
      "P-body": "It is better to give us an example of your /etc/mkinitcpio.conf file. .  You can use the following command to change the file assuming that there is only one instance of: () .  To change it back, just do the opposite: .  Assuming there are multiple instances of it, you can do the following: .  7 would be the number of the line where the instance that you want to change appears. .  ",
      "P-tags": "linux command-lin",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP in NP from NP"
    },
    {
      "id": "so_67948521",
      "task": "How to store daemon processes?",
      "P-task": "store daemon process",
      "F_verb": "store",
      "P-body": " how can I store the daemon processes .   There are as many approaches as stars in the sky. Let's say we differentiate two generic ways: .  Decentralized Every process is independent and separate. The handles are stored in some known static absolute location. .  System services typically store pid or other data about daemons in \"/var/run\". User services use \"/tmp\" or keep it somewhere in \"~/.somewhere\" or in \"~/.cache/somewhere/\". .  For example, \"screen\" multiplexer. On my system \"screen\" keeps sockets to running screen session at \"/var/run/screens/S-username/here\". When you run \"screen -list\" it uses the sockets located at the constant absolute location at \"/var/run/screen/S-username/there\" to communicate with other screen sessions and list available screen sessions. Similar with \"tmux\". .  Centralized Have a daemon running all the time that is responsible for collecting and keeping all the information. .  For example mentioned docker. The \"dockerd\" daemon runs all the time on the system as a system deamon and clients do \"docker something\" which only sends some HTTP data via tcp or via a file socket to the master docker daemon, then the master deamon does all the work transferring state to clients so it is displayed to users. Similar with NetworkManager which uses DBus to communicate. .  ",
      "P-tags": "unix daemon process bash c",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "ul_620642",
      "task": "keep xinput settings after mouse wakeup",
      "P-task": "keep xinput set mous wakeup",
      "F_verb": "keep",
      "P-body": "Unfortunately the name of most (if not all) options of \"libinput\" differs between \"xinput\" and \"xorg.conf\". The equivalent to \"Coordinate Transformation Matrix\" would be \"TransformationMatrix\". So putting something like the following into \"/etc/X11/xorg.conf.d/50-bt-mouse.conf\" should do the trick: .  \"Identifier\" may be chosen freely, whereas \"MatchProduct\" has to match the product name as shown by \"xinput\". If you want to apply this transformation to all your pointing devices, you could also replace the \"MatchProduct\" directive with \"MatchIsPointer \"on\"\". Also note that your own X.org configuration should be placed in \"/etc/X11/xorg.conf.d\" and not be made to files in \"/usr/share/X11/xorg.conf.d\", as the latter might be overwritten (without backup) on a system update. .  After making changes to the configuration you need to at least restart X.org in order for them to take effect (or reboot the system to be sure). Afterwards X.org will apply the options automatically everytime a matching device is discovered, be it at first start or when the mouse re-connects after being in power-save mode. .  ",
      "P-tags": "linux xinput mous x11",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP after NP"
    },
    {
      "id": "so_55507022",
      "task": "How to make cpuset.cpu_exclusive function of cpuset work correctly",
      "P-task": "make cpuset cpu_exclus function cpuset work correctli",
      "F_verb": "make",
      "P-body": "i believe it is a mis-understanding of cpu_exclusive flag, as i did. Here is the doc https://www.kernel.org/doc/Documentation/cgroup-v1/cpusets.txt, quoting: .  so one possible reason you have \"bash: echo: write error: Invalid argument\", is that you have some other cgroup cpuset enabled, and it conflicts with your operations of \"echo 1 > my_cpuset/cpuset.cpu_exclusive\" .  please run \"find . -name cpuset.cpus | xargs cat\" to list all your cgroup's target cpus.  .  assume you have 12 cpus, if you want to set cpu_exclusive of \"my_cpuset\", you need to carefully modify all the other cgroups to use cpus, eg. 0-7, then set cpus of \"my_cpuset\" to be 8-11. After all these cpus configurations , you can set cpu_exclusive to be 1. .  But still, other process can still use cpu 8-11. Only the tasks that belongs to the other cgroups will not use cpu 8-11 .  for me, i had some docker container running, which prevents me from setting my cpuset \"cpu_exclusive\" .  with kernel doc, i do not think it is possible to use cpus exclusively by cgroup itself. One approach (i know this approach is running on production) is that we isolate cpus, and manage the cpu affinity/cpuset by ourselves .  ",
      "P-tags": "ubuntu-16 04 centos7 linux-kernel cgroup cpuset",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP of NP"
    },
    {
      "id": "so_32582048",
      "task": "Replace 2 lines in a file using sed command",
      "P-task": "replac 2 line file use sed command",
      "F_verb": "replace",
      "P-body": "don't escape \"{ or }\" in your pattern/address part. sed uses BRE by default. With BRE, chars like \"{ ( + ..\" don't have special meaning, you have to escape them to give them special meaning. .  In your case, you want to match literal \"{ or }\", then don't escape them. .  EDIT I guess you want to remove the last comma, so that change: .  into .  then you can try: .  test with your file: .  ",
      "P-tags": "bash sed regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "so_49253032",
      "task": "Parsing JSON file using JQ and export it to CSV-BASH",
      "P-task": "pars json file use jq export csv-bash",
      "F_verb": "export",
      "P-body": "\"jq\" solution: .  The output: .  ",
      "P-tags": "json jq bash",
      "source": "qa",
      "cate": "export",
      "pat": "V NP to NP"
    },
    {
      "id": "au_653355",
      "task": "Wireless connected but no internet access",
      "P-task": "wireless connect internet access",
      "F_verb": "connect",
      "P-body": "Well, I ask at ubuntu forums and they answer very fast and it worked. .  (I just tested on ubuntu 15, down in the comments, some people said that version 16 seems not work) .  ",
      "P-tags": "15 04 network internet wireless",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "ul_61866",
      "task": "Why would I want to create more partitions if RHEL will only recognize up to 16?",
      "P-task": "would want creat partit rhel recogn 16",
      "F_verb": "create",
      "P-body": "There was a bit of discussion about that topic in an old bug report on exactly that limit: .    They used to reside in different (smaller) disks (and may go back). Several partitions give me more flexibility to move them around using labels. I wasn't using ext3 before, so smaller partitions made shorter fscks in the case of power-downs. I'm too lazy to use quotas to limit dept. disk usage   But even then the short answer was: \"anyone who needs even 16 partitions is insane, :)\". .  Nowadays we have LVM and those limits do not matter anymore. :) .  ",
      "P-tags": "linux partit rhel",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP if S"
    },
    {
      "id": "so_34395934",
      "task": "replacing text in multiple elements in an XML file",
      "P-task": "replac text multipl element xml file",
      "F_verb": "replace",
      "P-body": "What @PetSerAl is trying to tell you is that the \"-replace\" operator doesn't update the \"address\" nodes. You need to assign the modified value back to the node to actually change your XML data. Also, depending on the structure of your XML, dot-notation may not work for you (if a parent node contains several address nodes, \"$i\" would contain a list of these nodes). I'd recommend using \"SelectNodes()\" with an XPath expression to be on the safe side. .  ",
      "P-tags": "powershel xml",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_19443732",
      "task": "Configure cron job to run every 15 minutes on Jenkins",
      "P-task": "configur cron job run everi 15 minut jenkin",
      "F_verb": "configure",
      "P-body": "Your syntax is slightly wrong. Say: .  \"*\" indicates that the cron expression matches for all values of the field. .  \"/\" describes increments of ranges. .  ",
      "P-tags": "jenkin cron unix",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF on NP"
    },
    {
      "id": "au_602741",
      "task": "Installing GitLab on 15.04 gives Upstart Error",
      "P-task": "instal gitlab 15 04 give upstart error",
      "F_verb": "give",
      "P-body": "Ubuntu 15.05 no longer uses Upstart. It uses SystemD. GitLab hasn't been updated to check for this at the time of writing. .  The rules that deal with this are in \"/opt/gitlab/embedded/cookbooks/runit/recipes/default.rb\" .  So one can amend the Debian rule: .  to .  NB: Yes, I answered my own question as I was stuck on this and wanted to share. .  ",
      "P-tags": "git 15 04",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_30915406",
      "task": "Execute an shell program with node.js and pass node variable to the shell command",
      "P-task": "execut shell program node js pass node variabl shell command",
      "F_verb": "pass",
      "P-body": "From: http://www.dzone.com/snippets/execute-unix-command-nodejs .  To execute shell commands: .  From: Run shell script with node.js (childProcess), .  To run a program bar.sh in your home folder with the argument 'foo': .  ",
      "P-tags": "node js shell paramet",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_316814",
      "task": "What is the right way to expand these bash strings to the right Git commands?",
      "P-task": "right way expand bash string right git command",
      "F_verb": "expand",
      "P-body": "Taking the \"r\" case as an example, with .  followed by .  \"git\" sees three arguments, \"-C\", the value of \"d\", and \"remote show origin\", instead of the five it expects (\"remote\", \"show\" and \"origin\" separately instead of \"remote show origin\"). .  With \"bash\", simply removing the quotes will fix this: .  With Zsh, you need to split the string using .  (thanks ilkkachu and Gilles!). .  ",
      "P-tags": "bash-expans shell-script bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP to NP"
    },
    {
      "id": "so_17352655",
      "task": "How do I atomically create a locked file in Linux?",
      "P-task": "atom creat lock file linux",
      "F_verb": "create",
      "P-body": "The race exists anyway. If the file may or may not exist then you have to test for its existence before trying to lock it. But if the file is your mutex, then you can't possibly do that and the space between \"if file exists already\" (false) and \"download to newly created file\" is unconstrained. Another process could come by and create the file and start downloading before your download begins, and you would clobber it. .  Basically don't use fcntl locks here, use the existence of the file itself. \"open()\" with O_CREAT and O_EXCL will fail if the file already exists, telling you that someone else got there first. .  ",
      "P-tags": "linux flock fcntl file-io",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_54877177",
      "task": "Using bash to copy every 2nd line from one document to the beginning of every 2nd line of another",
      "P-task": "use bash copi everi 2nd line one document begin everi 2nd line anoth",
      "F_verb": "copy",
      "P-body": "A more portable version of TenG's solution: .   \"g\" - replace pattern space with (empty) hold \"n\" - print pattern space then replace with next line and implicitly print that \"-d '\\0'\" - paste uses \"\\0\" to mean \"don't insert a delimiter\" not as NUL  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP from NP to NP of NP"
    },
    {
      "id": "so_2332861",
      "task": "Terminating because of 6 signal",
      "P-task": "termin 6 signal",
      "F_verb": "terminate",
      "P-body": "It's probably talking about signal 6, which is SIGABRT, i.e. abort. The code itself most likely called \"abort()\", or perhaps an assert failed. .  You can list the signal numbers from the command line using .  HTH. .  ",
      "P-tags": "gcc c++ unix",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP of NP"
    },
    {
      "id": "su_162924",
      "task": "chmod 777: how to make all files become \"RWX\"",
      "P-task": "chmod 777 : make file becom rwx",
      "F_verb": "make",
      "P-body": "chmod -cR 777 *  .  Will change all the files including subdirectories recursively (R option) including subdirectories, but also report on when it makes a change (c option). .  Rather than changing all the files with too wide permissions, you might want to change the ownership instead. .  The line above changes owndership to a tomcat application server, you need to figure out which user your webserver is using. You can easily see that by doing .  (The h option is for changing the owndership of a symbolic link if encountered, but not the files it linkes to) .  ",
      "P-tags": "linux command-lin chmod",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "ul_131535",
      "task": "Recursive grep vs find / -type f -exec grep {} \\; Which is more efficient/faster?",
      "P-task": "recurs grep vs find -type f -exec grep effici faster",
      "F_verb": "find",
      "P-body": "I'm not sure: .    is really what you meant. That would mean grep recursively in all the non-hidden files and dirs in \"/\" (but still look inside hidden files and dirs inside those). .  Assuming you meant: .  A few things to note: .   Not all \"grep\" implementations support \"-r\". And among those that do, the behaviours differ: some follow symlinks to directories when traversing the directory tree (which means you may end up looking several times in the same file or even run in infinite loops), some will not. Some will look inside device files (and it will take quite some time in \"/dev/zero\" for instance) or pipes or binary files..., some will not. It's efficient as \"grep\" starts looking inside files as soon as it discovers them. But while it looks in a file, it's no longer looking for more files to search in (which is probably just as well in most cases)  Your: .  (removed the \"-r\" which didn't make sense here) is terribly inefficient because you're running one \"grep\" per file. \";\" should only be used for commands that accept only one argument. Moreover here, because \"grep\" looks only in one file, it will not print the file name, so you won't know where the matches are. .  You're not looking inside device files, pipes, symlinks..., you're not following symlinks, but you're still potentially looking inside things like \"/proc/mem\". .  would be a lot better because as few \"grep\" commands as possible would be run. You'd get the file name unless the last run has only one file. For that it's better to use: .  or with GNU \"grep\": .  Note that \"grep\" will not be started until \"find\" has found enough files for it to chew on, so there will be some initial delay. And \"find\" will not carry on searching for more files until the previous \"grep\" has returned. Allocating and passing the big file list has some (probably negligible) impact, so all in all it's probably going to be less efficient than a \"grep -r\" that doesn't follow symlink or look inside devices. .  With GNU tools: .  As above, as few \"grep\" instances as possible will be run, but \"find\" will carry on looking for more files while the first \"grep\" invocation is looking inside the first batch. That may or may not be an advantage though. For instance, with data stored on rotational hard drives, \"find\" and \"grep\" accessing data stored at different locations on the disk will slow down the disk throughput by causing the disk head to move constantly. In a RAID setup (where \"find\" and \"grep\" may access different disks) or on SSDs, that might make a positive difference. .  In a RAID setup, running several concurrent \"grep\" invocations might also improve things. Still with GNU tools on RAID1 storage with 3 disks, .  might increase the performance significantly. Note however that the second \"grep\" will only be started once enough files have been found to fill up the first \"grep\" command. You can add a \"-n\" option to \"xargs\" for that to happen sooner (and pass fewer files per \"grep\" invocation). .  Also note that if you're redirecting \"xargs\" output to anything but a terminal device, then the \"greps\"s will start buffering their output which means that the output of those \"grep\"s will probably be incorrectly interleaved. You'd have to use \"stdbuf -oL\" (where available like on GNU or FreeBSD) on them to work around that (you may still have problems with very long lines (typically >4KiB)) or have each write their output in a separate file and concatenate them all in the end. .  Here, the string you're looking for is fixed (not a regexp) so using the \"-F\" option might make a difference (unlikely as \"grep\" implementations know how to optimise that already). .  Another thing that could make a big difference is fixing the locale to C if you're in a multi-byte locale: .  To avoid looking inside \"/proc\", \"/sys\"..., use \"-xdev\" and specify the file systems you want to search in: .  Or prune the paths you want to exclude explicitly: .  ",
      "P-tags": "grep find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_494344",
      "task": "How to compare the content inside a txt file?",
      "P-task": "compar content insid txt file",
      "F_verb": "compare",
      "P-body": "Confirmed in \"bash\": .  -The variable \"file\" is assigned to the path of wherever output.txt is located. .  -In the \"if\" statement, \"awk\" uses \",\" as the delimiter and prints and compares the second values of the second column on each line. .  -If the values are equal, then it prints the second column of the second line which is \"5.5\" .  -If the values are not equal, then it prints \"The value is different\". .  I tested this with two files with the values that you specified. You can change the value of the \"file\" variable in the script to work with others. .  ",
      "P-tags": "shell-script text-process",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_22909908",
      "task": "Where can I find .curlrc file on UBUNTU?",
      "P-task": "find curlrc file ubuntu",
      "F_verb": "find",
      "P-body": " make sure you run this command as root .  or you could... .  This is where it should be. .  I do believe by default though, there is no curlrc file. You might have to create your own .  ",
      "P-tags": "linux curl",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_164886",
      "task": "How to prevent grep from excessive unnecessary memory usage",
      "P-task": "prevent grep excess unnecessari memori usag",
      "F_verb": "prevent",
      "P-body": "You run out of memory because \"grep\" matches line by line, and you've explicitly removed all newlines in your pipeline: .  I assume that what you want to do is to find the byte offset of the particular hexadecimal string within the output of \"xxd\", and to be sure that you find it if it's present, you remove newlines (the string may otherwise straddle two lines). .  The following \"awk\" script will match a pattern across consecutive lines and print the position of the first character of the match to the terminal. It assumes that the input is exactly 60 characters wide (just like the output from \"xxd -p\" is). .  Or, alternatively (but equivalently): .  Testing it on random input data (the search strings that I'm using further down are highlighted in the data): .  Running this on a 1 terabyte large file will be slow, no matter what. It may (possibly) be sped up by giving the \"-c 256\" option to \"xxd\" (and changing 60 to 256 in the \"awk\" script accordingly) to reduce the number of pattern matches, but the data on each line will by necessity be matched twice none the less (once together with the previous line, and once together with the next line). .  ",
      "P-tags": "linux grep",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_144490",
      "task": "Get specific line from command output in awk",
      "P-task": "get specif line command output awk",
      "F_verb": "get",
      "P-body": "try to pipe it to \"grep\": .  to get rid of the first \"|\" and the last \"|\": .  \"-E\" to access the extended regular expression syntax .  \"-o\" is used to only output the matching segment of the line, rather than the full contents of the line. .  ",
      "P-tags": "awk shell pipe",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_1327598",
      "task": "How to change the default folder of 'Files' to \"Starred\"?",
      "P-task": "chang default folder file star",
      "F_verb": "change",
      "P-body": "You can change the default startup folder of nautilus by editing the \".desktop\" launcher for Files, as detailed in this anwser. It boils down to copying the system wide launcher to your private \".local/share/applications\" folder, and then editing the copy in that local folder. Edit it such that the \"Exec=\" lines read like .  In contrast to what is indicated in the related answer, you need to remove both \"--new-window\" and \"%U\" for this to work. .  Users that wish to autostart in the \"Recent\" folder can supply \"recent:///\". .  ",
      "P-tags": "20 10 gui",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "au_1163116",
      "task": "Give Ubuntu Linux Mint's color scheme System-wide?",
      "P-task": "give ubuntu linux mint color scheme system-wid",
      "F_verb": "give",
      "P-body": "Gnome has a very good tool that will help you create a custom theme of your own. It is much similar to how we edit CSS using \" Inspect Element \" in your browser. It is called \"GTK Inspector\" .  https://wiki.gnome.org/Projects/GTK/Inspector .  Once you enable it, you can click on any element whose colour you want to change and then replace it using the CSS window available in the \"GTK Inspector\" tool. .  It will take some trial and error to learn. In the end, it is very simple to theme Ubuntu yourselves with a few clicks and some CSS. Good luck. .  This is how it works .   .  ",
      "P-tags": "theme mint",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_44016084",
      "task": "Does bash shell script leave its command history?",
      "P-task": "bash shell script leav command histori",
      "F_verb": "leave",
      "P-body": "No, it does not: https://www.gnu.org/software/bash/manual/html_node/Bash-History-Facilities.html .   9.1 Bash History Facilities .  When the \"-o history\" option to the set builtin is enabled (see The Set Builtin), the shell provides access to the command history, the list of commands previously typed. .   To get current settings, use \"set -o\" command. In interactive shells (with \"-i\" option of bash or in usual bashes from login or terminal) it prints \"history on\". When used in scripts (\"bash -c 'set -o'\" or when you did \"ssh machine bash\" without tty allocation) it is unset: \"history off\". .  https://www.gnu.org/software/bash/manual/html_node/Interactive-Shell-Behavior.html .   6.3.3 Interactive Shell Behavior - When the shell is running interactively, it changes its behavior in several ways. .   Command history (see Bash History Facilities) and history expansion (see History Interaction) are enabled by default. Bash will save the command history to the file named by $HISTFILE when a shell with history enabled exits.   History can be enabled in script with several commands: https://askubuntu.com/questions/546556/how-can-i-use-history-command-in-a-bash-script / https://unix.stackexchange.com/questions/5684/history-command-inside-bash-script - set HISTFILE and (optionally) HISTTIMEFORMAT, enable with \"set -o history\" and then use \"history\" command. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "so_20507494",
      "task": "Linux: start a script after another has finished",
      "P-task": "linux : start script anoth finish",
      "F_verb": "start",
      "P-body": "Perhaps you didn't notice that the scripts you found were written for bash, not csh, but you're trying to process them with the csh interpreter.  .  It looks like you've misunderstood what the original code was trying to do -- it was intended to monitor an already-existing process, by looking up its process id using the process name.  .  You seem to be trying to start the first process from inside the \"ps\" command. But in that case, there's no need for you to do anything so complicated -- all you need is: .  Unless you go out of your way to run one of the scripts in the background, the second script will not run until the first script is finished.  .  Although this has nothing to do with your problem, csh is more oriented toward interactive use; for script writing, it's considered a poor choice, so you might be better off learning bash instead. .  ",
      "P-tags": "linux shell csh",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP after NP"
    },
    {
      "id": "so_51216194",
      "task": "How to suppress the error message: \"Error in `./hubbard.exc': corrupted size vs. prev_size\"?",
      "P-task": "suppress error messag : error\nhubbard exc : corrupt size vs prev_siz",
      "F_verb": "suppress",
      "P-body": "You may use \"export LIBC_FATAL_STDERR_=1\" to let this backtrace go to stderr, then use \"2>/dev/null\" to drop that error message, which like .  , see glibc backtrace - can't redirect output to file for more detail. .  ",
      "P-tags": "ubuntu python error-suppress bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "ul_621241",
      "task": "Why does $ echo \"Testing\" | write user pts/0 | at now + 1 min execute instantly?",
      "P-task": "echo test write user pt 0 + 1 min execut instantli",
      "F_verb": "echo",
      "P-body": "Because you're piping the output of the write command to \"at\", not giving \"at\" the write command. Try: .  ",
      "P-tags": "manjaro linux bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP at NP"
    },
    {
      "id": "so_28836042",
      "task": "How to hide a shell script running in the background from ps -ef",
      "P-task": "hide shell script run background ps -ef",
      "F_verb": "hide",
      "P-body": "As this is only to prank your roommate here it goes: .  Backup you \"ps\" binary: .  Create a impostor \"ps\": .  Don't forget to make it executable: .  The above example I am hiding thunderbird but could be anything really. .  ",
      "P-tags": "hide process shell bash",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "so_54348148",
      "task": "How to remove a storage account from Azure through Azure DevOps",
      "P-task": "remov storag account azur azur devop",
      "F_verb": "remove",
      "P-body": "that happens because its asking to confirm deletion (\"##[error]Windows PowerShell is in NonInteractive mode. Read and Prompt functionality is not available\"), you are missing: `. .  just retested it, it works without prompts if you supply \"-Force\" .  ",
      "P-tags": "azur azure-powershel azure-devop",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP through NP"
    },
    {
      "id": "so_33842387",
      "task": "Scope of variables executing functions in a subshell",
      "P-task": "scope variabl execut function subshel",
      "F_verb": "execute",
      "P-body": "What you are observing has nothing to do with functions. Subshells get all the environment, even the un-exported variables. To illustrate, let's define two variables: .  Observe that a subshell has access to both: .  If we start a new process, though, it only sees the exported variable: .  Documentation \"man bash\" documents subshells as follows: .   (list) list is executed in a subshell environment (see COMMAND EXECUTION ENVIRONMENT below). Variable assignments and builtin commands that affect the shell's environment do not remain in effect after the command completes. The return status is the exit status of list. .   If we go look at the \"COMMAND EXECUTION ENVIRONMENT\", we find that it includes .   shell parameters that are set by variable assignment or with set or inherited from the shell's parent in the environment. .   In other words, it includes variables whether or not they have been exported. .  If we read further, we find that this is in contrast to \"a simple command other than a builtin or shell function.\" Such commands only receive the exported variables. .  ",
      "P-tags": "shell subshel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_5311583",
      "task": "TMUX: how to make new window stay when start shell-command quits?",
      "P-task": "tmux : make new window stay start shell-command quit",
      "F_verb": "make",
      "P-body": "\"tmux\" has an option for this: \"remain-on-exit\": .  ",
      "P-tags": "tmux shell",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP when S"
    },
    {
      "id": "au_19320",
      "task": "How to enable or disable services?",
      "P-task": "enabl disabl servic",
      "F_verb": "disable",
      "P-body": "There are services that can be enabled/disabled using the GUI (like the \"startup\" application) or the terminal. .  For the Terminal you have several options. First, open a terminal (Type \"terminal\" in the dash, for example, and open it). Then: .  Temporary enabling/disabling services To stop and start services temporarily (Does not enable / disable them for future boots), you can type \"service SERVICE_NAME [action]\". For example: .   \"sudo service apache2 stop\": Will STOP the Apache service until Reboot or until you start it again. \"sudo service apache2 start\": Will START the Apache service assuming it was stopped before. \"service apache2 status\": Will tell you the STATUS of the service, if it is either enabled/running of disabled/NOT running. \"sudo service apache2 restart\": Will RESTART the service. This is most commonly used when you have changed, a config file. In this case, if you changed either a PHP configuration or an Apache configuration. Restart will save you from having to stop/start with 2 command lines \"service apache2\": In this case, since you did not mention the ACTION to execute for the service, it will show you all options available for that specific service. This aspect varies depending on the service, for example, with MySQL it would only mention that it is missing a parameter. For other services like networking service it would mention the small list of all options available.  Systemd Starting with Ubuntu 15.04, Upstart will be deprecated in favor of Systemd. With Systemd to manage the services we can do the following (through the \"systemctl action SERVICE\" pattern): .   \"sudo systemctl start SERVICE\": Use it to start a service. Does not persist after reboot \"sudo systemctl stop SERVICE\": Use it to stop a service. Does not persist after reboot \"sudo systemctl restart SERVICE\": Use it to restart a service \"sudo systemctl reload SERVICE\": If the service supports it, it will reload the config files related to it without interrupting any process that is using the service. \"systemctl status SERVICE\": Shows the status of a service. Tells whether a service is currently running. \"sudo systemctl enable SERVICE\": Turns the service on, on the next reboot or on the next start event. It persists after reboot. \"sudo systemctl disable SERVICE\": Turns the service off on the next reboot or on the next stop event. It persists after reboot. \"systemctl is-enabled SERVICE\": Check if a service is currently configured to start or not on the next reboot. \"systemctl is-active SERVICE\": Check if a service is currently active. \"systemctl show SERVICE\": Show all the information about the service. \"sudo systemctl mask SERVICE\": Completely disable a service by linking it to \"/dev/null\"; you cannot start the service manually or enable the service. \"sudo systemctl unmask SERVICE\": Removes the link to \"/dev/null\" and restores the ability to enable and or manually start the service.  Upstart (Deprecated Since 15.04) If we want to use the official Upstart way (Note that, for the moment, not all services have been converted to Upstart), we could use the following commands: .  \"status SERVICE\" - This will tell us if a converted service is running or not. Note that this is deprecated in favor of \"start\", \"stop\", \"status\" & \"restart\". It will also tell us if a service has not yet been converted to upstart: .  A converted service would typically output the current status (Starting, Running, Stopping...) and process ID. A non converted service would give an error about an unknown job. .  Some shortcuts may only work with the \"service\" command above but not with the commands below unless they are 100% converted to upstart services: .   \"sudo start mysql\": Start \"sudo stop mysql\": Stop \"sudo restart mysql\": Restart \"sudo status smbd\": Status  Enabling / Disabling a service To toggle a service from starting or stopping permanently you would need to: .  where the stanza \"manual\" will stop Upstart from automatically loading the service on next boot. Any service with the \".override\" ending will take precedence over the original service file. You will only be able to start the service manually afterwards. If you do not want this then simply delete the \".override\". For example: .  Will put the MySQL service into \"manual\" mode. If you do not want this, afterwards you can simply do .  and Reboot for the service to start automatically again. Of course to enable a service, the most common way is by installing it. If you install Apache, Nginx, MySQL or others, they automatically start upon finishing installation and will start every time the computer boots. Disabling, as mentioned above, will make use of the service \"manual\". .  ",
      "P-tags": "upstart servic",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "au_681214",
      "task": "How to enable -keystroke option of unclutter in unity?",
      "P-task": "enabl -keystrok option unclutt uniti",
      "F_verb": "enable",
      "P-body": "You can use \"xbanish\" to do this. It is well known that the \"unclutter\" keystroke function has been broken for quite some time. I have tested this solution and it works well. .  First, install \"git\" if it's not already installed: .  Then, clone the repo and install \"xbanish\": .  Now, set an \"alias\" for \"xbanish\": .  You can now run xbanish by simply running the following command: .  or .   Additionally, here's a helpful tip that has helped me so much when it comes to \"no such file\" errors.  .  You can use \"apt-file search\" to find out what package contains a file you are looking for. Here's an example: \"apt-file search X11/X.h\"  .  However, \"apt-file\" needs to be installed and you must run \"sudo apt-file update\" before you can use it:  .  and then run:  .  ",
      "P-tags": "autohid mous keyboard",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_45861011",
      "task": "Metadata export error when running on large directory structures",
      "P-task": "metadata export error run larg directori structur",
      "F_verb": "run",
      "P-body": "Test to see how long the filepaths are. .  If the filepaths are more than 248 characters... That may be why you are getting the error. .  To check to see if any come back with more than 248 characters you can do .  ",
      "P-tags": "file directori metadata powershel window",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V on NP"
    },
    {
      "id": "au_1345376",
      "task": "How to add persistent IP routes in Ubuntu 20.04 server",
      "P-task": "add persist ip rout ubuntu 20 04 server",
      "F_verb": "add",
      "P-body": " Hello mate, i cannot comment so i will try to answer here. There are few options to create a scheduled process to solve that problem. Here are two options:  crontab - wich is less fitting your problem. making a service - wich is fitting your problem perfectly. there might be more and a better ways to solve that problem.   About crontab:  The crontab is a list of commands that you want to run on a regular schedule. To add a command you want to schedule run you have to edit the crontab file with the command \"crontab -e\". you can use this site to help you calculate the interval you want to execute a specific command crontabCalculator you can use this guide to figure your own crontab file crontabGuide   The better option for my opinion is to create your own service.  when you create a service you can run it just as all the other services, that means that you can enable, disable, restart, start and all other options that coming with \"systemctl\" command. you have to create your service as a text file and name it myServiceName.service. then you have to locate that service in \"/etc/systemd/system/.\" use this guide to have a service template howToMakeAServiceGuide. after creating the service and locating him in the specific directory you can enable and start him by this commands: \"systemctl enable serviceName.service\" and \"systemctl start serviceName.service\". the service should start on any reboot so it might solve your problem.   Edited after comments.  create a script with \"sudo nano /usr/local/sbin/SCRIPT_NAME.sh\" example for a script with your commands: \"#/bin/bash!\" \"ip rule add from 185.230.125.107 table 128\" \"ip route add table 128 185.230.125.107/32 dev eno0\" \"ip route add table 128 default via 185.230.125.254\" now give the script a execute permissions with \"chmod a+x SCRIPT_NAME.sh\" now create a service with \"sudo nano /systemd/system/SERVICE_NAME.service\" use that template: in the ExecStart field execute your script     Edited after comments two: To make sure your service is configured correctly follow this steps:  locate the service in \"/etc/systemd/system/LOCATE_HERE.service\" give your script that running by the service the execute permission with \"sudo chmod a+x yourscript.sh\" execute the command \"sudo systemctl daemon-reload\" to reload the new service. execute the command \"sudo systemctl enable serviceName.service\" execute the command \"sudo systemctl start serviceName.service\" execute the command \"sudo systemctl status serviceName.service\" if the service is running reboot your system. after the reboot execute the command \"sudo systemctl status serviceName.service\" to check if the service is running. images:   if all that solution is not working there might be a problem with the file type - check for solution here solutionForFileTypeError    ",
      "P-tags": "vpn network server",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_720565",
      "task": "rsync to download (in one way) files from one server to another",
      "P-task": "rsync download one way file one server anoth",
      "F_verb": "download",
      "P-body": "Say you have a script with such an example code on Server A: .  Keep in mind: Always use \"-c\" for building a checksum, especially if you copy remotely, even it is slower. If you have spaces in the pathname escape it with a \\ (backslash) like this \"/path/with/a/space\\ here\". But try to avoid EDIT: spaces, (not backslashes) ;-D. .  Make it executable with \"chmod u+x /path/to/script/with/name.sh\" .  Now, if you run this script, it will first upload all files in \"/folder_to_copy\" to server B in \"/path/to/store\". And then remove (recursively) all files and folders from that directory. .  Now you can make a cron job for this script so it will run every night at 3pm e.g. .  Always think about what you do, try to understand the given commands and test everything. man-pages are your friend .  ",
      "P-tags": "server rsync download",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_42956640",
      "task": "Regex with lookaround to find group of numbers is inconclusive",
      "P-task": "regex lookaround find group number inconclus",
      "F_verb": "find",
      "P-body": "You don't need to worry about criteria 4 and 5 the way you are. As long as the leading bracket is followed by digits and the last bracket is also preceeded by digits you should be fine. .  Matches the outside braces as well as 4 groups of digits and a trailing caret as well as one last group of digits. If you are looking to match level 3 then change the 4 to 2 in the above regex. .  It there was leading or trailing carets they would not be matched. .  Named Matches Depending on how you are using these values later it might be beneficial to looks at named matches in PowerShell. What we are going to do it build a custom regex match string based on the number of levels that you are trying to match against. .  For each of those levels (1 to 5 in the example above) we make a named match called level_n_ where n is the position of the caret delimited number. So then we you look at matches you will get named matches that you can use later in your code. .  Cool but might be overboard. .  Split result A simple trim and split would get something simlar just not with the fancy names. .  So \"$levels\" is an array with 5 elements corresponding to the level of you system. .  Note this logic fails for level 1 only matches. .  ",
      "P-tags": "powershel regex",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "su_599729",
      "task": "Cannot find what exports CDPATH",
      "P-task": "find export cdpath",
      "F_verb": "find",
      "P-body": "Your \".profile\" will be read when you log in not when you start a new shell. This includes when you log in to a graphical display manager, which I assume you are doing (\"every time I launch the terminal\"). If you're in a graphical interface, log completely out of that and back in to get a fresh environment. .  EDIT: For future reference, I recommend putting stuff like that in a \".bashrc\" file instead of \".profile\". The \".bashrc\" is read every time a shell is started. This page does a good job of explaining the difference in more detail. .  ",
      "P-tags": "linux-mint bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_169642",
      "task": "Adding a new path in PATH",
      "P-task": "ad new path path",
      "F_verb": "add",
      "P-body": "It doesn't look messed up, and you put the directory at the end of your PATH, so commands in that directory cannot mask some system command. .  Here are a few additional things you can check: .   Are there any strange commands in the directory that have nothing to do with \"git\", in particular ones that look like mistyped \"common\" commands (e.g. \"mroe\" as mistyped \"more\"). The write permissions on the directory should be for root only Reconsider why you need \"root\" to use \"git\", if it is for revision control of e.g. the \"/etc\" directory then that is fine. If you do normal software development, you should reconsider setting that up so you can do that as normal user.  ",
      "P-tags": "path",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_12274118",
      "task": "How can I run a shell command in perl scipt and return the result to a variable in my perl script(without returning the result to the unix)",
      "P-task": "run shell command perl scipt return result variabl perl script without return result unix",
      "F_verb": "run",
      "P-body": "Use the backticks: .  The 'qx' delimiter is a synonym for this: .  This is documented here in the perlop man page. .  Alternately, you can use \"open\" with '|' like so: .  In this case, you're opening a filehandle to a pipe attached to the command's output (basically treating the output as a file). This is handy if the command takes a long time or produces more output than you want to store in memory at a time. This is documented in the Perl open manual. .  ",
      "P-tags": "command perl unix",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_68927975",
      "task": "Can't put output of beeline \"show partitions\" command into array in BASH",
      "P-task": "put output beelin show partit command array bash",
      "F_verb": "put",
      "P-body": "Consider replacing: .  with: .  Which should generate: .  Another option, especially if each line from \"${PARTITIONS}\" may include white space: .  ",
      "P-tags": "if beelin bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP into NP in NP"
    },
    {
      "id": "so_41962306",
      "task": "Adb shell gives root acess instead of shell access",
      "P-task": "adb shell give root acess instead shell access",
      "F_verb": "give",
      "P-body": "Run \"su shell\". More information regarding the \"su\" command here: http://man7.org/linux/man-pages/man1/su.1.html .  ",
      "P-tags": "android shell adb",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_112346",
      "task": "Is it possible to install a linux desktop environment from a live cd?",
      "P-task": "possibl instal linux desktop environ live cd",
      "F_verb": "install",
      "P-body": "Yes it is. Either by using the CD as a repository, or by booting into the live session and downloading the package manually and then installing from your normal OS or even by setting up a \"chroot\" environment. IN the examples below, I am using \"apt-get xfce\" as the command you will want to run but \"dpkg-reconfigure\" or whatever else would work as well. .  1. Use the CD as a repository. Say that you've screwed up your desktop and are booting to a command line with no internet access (which shouldn't happen, you can have internet even without a GUI). OK, you can put your CD in your drive and then run .  If all goes well, that should detect your CD, mount it and parse it for packages. Once that's done, run \"sudo apt-get update\" to refresh your sources and install your desktop normally. For example: \"apt-get install xfce4-desktop\". .  NOTE: I have not tested this but it is relatively well documented. See, for example, here. .  2. Boot into the live session and get the packages you want. This one requires that you actually have a working internet connection in the live CD environment. First, boot into your normal (broken) OS and install \"apt-offline\". If your system is already broken, you can download the package here (make sure you also get the dependencies) and install with .  Once you have it installed run .  Then, take the file that was just generated (\"xfce-offline.sig\"), boot into the live session and run .  Now, boot back into your local system to install it: .  That should result in a list of \".deb\" files that you can then install manually. .  I also found something called keryx which might be worth checking out: .   Keryx is a free, open source application for updating Linux. The Keryx Project started as a way for users with dialup, or low-bandwidth internet to be able to download and update packages on their debian based distribution of linux. Mainly built for Ubuntu, Keryx allows users to select packages to install, check for updates, and download these packages onto a USB portable storage device. The packages are saved onto the device and are then taken back to the Linux box that it originated from and are then installed. .   Finally, you can also do all this manually with \"apt-get\" from the live session: .  The command above will download all \".deb\" files needed to install \"xfce\". See my answer here for more details on how that works. .  References  https://help.ubuntu.com/community/InstallingSoftware#Installing_packages_without_an_Internet_connection http://ubuntuforums.org/showthread.php?t=1637309&p=10198406#post10198406  3. Use the live CD to set up a \"chroot\" environment. Setting up the \"chroot\" is explained in more detail here but the basic procedure is (replace \"/dev/sda1\" with whichever partition has your \"/\"): .  You have now tricked your system into thinking it is booted into your installed OS and you can use \"apt-get\" normally. Once you've finished, exit the \"chroot\" with \"exit\" and reboot. .  ",
      "P-tags": "livecd ubuntu package-manag",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_56756344",
      "task": "Linux/ALSA: Callback when frame is written to sound card",
      "P-task": "linux alsa : callback frame written sound card",
      "F_verb": "write",
      "P-body": "You can either use .   blocking mode (the default), in which \"snd_pcm_write*()\" returns only when all the data has been written into the ring buffer (or when an error has occured), or non-blocking mode (enabled with \"SND_PCM_NONBLOCK\" when opening, or \"snd_pcm_nonblock()\"), in which you can use \"poll()\"/\"epoll()\" etc. to get a notification.  Using an ALSA async handler works only with certain devices, and has all the drawbacks of signal handlers; it is deprecated. .  ",
      "P-tags": "c++ linux alsa",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP"
    }
  ],
  "4": [
    {
      "id": "ul_538198",
      "task": "Why blocking read() on a pty returns when process on the other end dies?",
      "P-task": "block read pti return process end die",
      "F_verb": "block",
      "P-body": "On Linux, a \"read()\" on the master side of a pseudo-tty will return \"-1\" and set \"ERRNO\" to \"EIO\" when all the handles to its slave side have been closed, but will either block or return \"EAGAIN\" before the slave has been first opened. .  The same thing will happen when trying to read from a slave with no master. For the master side, the condition is transient; re-opening the slave will cause a \"read()\" on the master side to work again. .  On *BSD and Solaris the behavior is similar, with the difference that the \"read()\" will return \"0\" instead of \"-1\" + \"EIO\". Also, on OpenBSD a \"read()\" will also return \"0\" before the slave is first opened. .  I don't know if there's any standard spec or rationale for this, but it allows to (crudely) detect when the other side was closed, and simplifies the logic of programs like \"script\" which are just creating a pty and running another program inside it. .  The solution in a program which manages the master part of a pty to which other unrelated programs can connect is to also open and keep open a handle to its slave side. .  See related answer: read(2) blocking behaviour changes when pts is closed resulting in read() returning error: -1 (EIO) .   Why the \"read()\" exits when process which opened slave side of the pty exits? .   When a process exits, all its file descriptors are automatically closed. .  ",
      "P-tags": "linux pti pseudotermin c tti",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP on NP when S"
    },
    {
      "id": "au_1075116",
      "task": "Mount a USB Drive Questions",
      "P-task": "mount usb drive question",
      "F_verb": "mount",
      "P-body": " Am I in error attempting to mount /dev/sdd ? Should it be one of the partitions? .   Yes, your drive sdd (like most drives) is partitioned. Unpartitioned drives do exist, but aren't very common, and make things harder to change/move in the future. .  PS. there are good GUI's for this stuff, like Disks / \"gnome-disk-utility\", try it instead. Or \"lsblk\" is handy too. .  ",
      "P-tags": "partit usb mount",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_68673221",
      "task": "WARNING: Running pip as the 'root' user",
      "P-task": "warn : run pip root user",
      "F_verb": "run",
      "P-body": "The way your container is built doesn't add a user, so everything is done as root. .  You could create a user and install to that users's home directory by doing something like this; .  ",
      "P-tags": "ubuntu pip docker python django",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP"
    },
    {
      "id": "ul_124468",
      "task": "How do I resolve an apparent hanging update process",
      "P-task": "resolv appar hang updat process",
      "F_verb": "resolve",
      "P-body": "You are in a pager program, where you can scroll through the change logs of the packages that you are installing. Ubuntu's default pager (like most unices out there, except some embedded or antique systems which have the more primitive \"more\") is less. .  The installation process is not hung: it's waiting for you to read the changes. You can use arrow or page keys to scroll through the file. Pressing Space goes down by one page and pressing Return goes down by one line. Eventually you'll get to the \"(END)\". You can press Q at any time to quit. .  Once you quit the pager, you'll be asked whether to confirm or cancel the upgrades. .  The intent of showing you the change logs is that you can cancel the upgrade if some change looks like it might break your system. This is useful for people who use a bleeding-edge distribution such as Debian unstable \u2014\u00a0and even there, it is not terribly useful. If you use the stable distribution, you'll only get security and major stability updates which you always should apply as soon as possible. .  This behavior is caused by the apt-listchanges package. You can uninstall the package in your favorite package manager; on the command line, run \"apt-get remove apt-listchanges\" (e.g. \"sudo apt-get remove apt-listchanges\" if you use \"sudo\"). .  ",
      "P-tags": "upgrad apt linux",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "au_1040162",
      "task": "Error location HDF5 libraries, earlier it was locating them just fine, i recently installed gcc7.2 environment? PS. error message and configure",
      "P-task": "error locat hdf5 librari earlier locat fine recent instal gcc7 2 environ\nps\nerror messag configur",
      "F_verb": "locate",
      "P-body": "Make sure that you have installed necessary HDF-related development packages .  and if they are not installed, install them with: .  ",
      "P-tags": "python software-instal cmake",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_185537",
      "task": "Combining zsh\u2019s tab completion with case insensitivity",
      "P-task": "combin zsh tab complet case insensit",
      "F_verb": "combine",
      "P-body": "Enabling the option \"MENU_COMPLETE\" will skip the correction and immediately insert the first possible match. .  ",
      "P-tags": "autocomplet zsh",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_244859",
      "task": "HOWTO: Fix \"Cannot parse sensitivity level in s0\" error when attempting to start a KVM VM after a major OS upgrade",
      "P-task": "howto : fix pars sensit level s0 error attempt start kvm vm major os upgrad",
      "F_verb": "parse",
      "P-body": "Googling around I found this RHEL error report. Now, I know pretty little about SELinux but I do remember seeing a SELinux relabel taking place after upgrading my OS distribution, my SELinux issues casually happened after a kernel upgrade and the error report suggested trying a forced autorelabel by creating an empty file on the system root directory called \".autorelabel\". .  So I created that file, restarted my computer, waited for the autorelabel to complete, and tried running a VM again. My VMs now start normally and the problem is fixed. .  ",
      "P-tags": "rhel kvm selinux qemu",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP in NP when S"
    },
    {
      "id": "au_219494",
      "task": "Where are the keyrings folder located in Ubuntu 12.10?",
      "P-task": "keyr folder locat ubuntu 12 10",
      "F_verb": "locate",
      "P-body": "On 12.10 those are located on \"~/.local/share/keyrings\" .  ",
      "P-tags": "keyr 12 10",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP"
    },
    {
      "id": "ul_5264",
      "task": "As we call `#!/bin/perl` 'shebang', what we call `-*- perl -*-`?",
      "P-task": "call\nbin perl shebang call - - perl - -",
      "F_verb": "call",
      "P-body": "Those are called modelines, at least in vim. See \":help modeline\" -- not exactly slang, but at least it's something to call them. .  ",
      "P-tags": "emac vi terminolog vim",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "so_62401583",
      "task": "C programming: how to ignore an input?",
      "P-task": "c program : ignor input",
      "F_verb": "ignore",
      "P-body": "You can use a ternary: .  In order to avoid repeating the command, you can also use: .  Also, notice that \"test\" is a command, consider using another name for your program. .  ",
      "P-tags": "linux c bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "so_48002485",
      "task": "Add line after matching a pattern",
      "P-task": "add line match pattern",
      "F_verb": "add",
      "P-body": "With sed: .  If the line could contain \"AIX\": .  Edit: .  To append the hostname after the matching line, try the \"a\"(append) command: .  ",
      "P-tags": "awk echo sed bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP after S_ING"
    },
    {
      "id": "so_33141371",
      "task": "How to log an eventlog only when the script gives a red error?",
      "P-task": "log eventlog script give red error",
      "F_verb": "log",
      "P-body": "One way is to clear \"$Error\" before your statemtent, then check if an error occurred: .  Or you could turn all errors into terminating errors and use a \"try..catch\" statement: .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP when S"
    },
    {
      "id": "su_382008",
      "task": "Sending Packets to tap0 interface",
      "P-task": "send packet tap0 interfac",
      "F_verb": "send",
      "P-body": "The \"tap\" is meant for bridged tunneling under OpenVPN - you're supposed to junction it into a bridge such as \"br0\" using \"brctl\".  .  The idea is you can put \"tap0\" and \"eth0\", for example, into a bridge \"br0\" - then broadcast traffic traverses across this bridge. Broadcast traffic coming in from \"tap0\" will be forwarded to \"eth0\" and vice versa whereas in a routed, standard situation it would not.) Your OpenVPN tunnel via \"tap0\" is then \"switched\" into \"eth0\" instead of \"routed\" into it. The entire \"br0\" gets an IP and you deal with \"br0\" instead of \"eth0\" or \"tap0\".  .  Completely possible to have a bridge with only one interface and add/remove additional interfaces with \"brctl\" as needed. .  So either put \"tap0\" into a bridge and deal with the bridge interface instead, or use \"tun\" interfaces. .  It's also possible \"iptables\" rules are interfering.  .  Update - look here: http://backreference.org/2010/03/26/tuntap-interface-tutorial/ - particularly this excerpt: .   The difference between a tap interface and a tun interface is that a tap interface outputs (and must be given) full ethernet frames, while a tun interface outputs (and must be given) raw IP packets (and no ethernet headers are added by the kernel). Whether an interface functions like a tun interface or like a tap interface is specified with a flag when the interface is created. .   So looks like if you don't send full ethernet frames to tap0 it won't work as your expect because of this above. .  ",
      "P-tags": "socket linux ubuntu network openvpn",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_20624863",
      "task": "Google-chrome can't locally view my webGL Three.js webpages in Ubuntu",
      "P-task": "google-chrom local view webgl three js webpag ubuntu",
      "F_verb": "view",
      "P-body": "The issue is Chrome doesn't allow web pages to read local files. Otherwise the bad guys could make HTML pages, ask you to save them and load them locally and then upload your local files to their sever. .  You can override this but I don't recommend it. Rather run your own server. The simplest way is to use python then open a terminal and type .  Then go to  .  At some point you'll likely find that has limits (like doesn't support video well) in which case see this answer. .  What is a faster alternative to Python's http.server (or SimpleHTTPServer)? .  ",
      "P-tags": "google-chrom javascript webgl ubuntu-12 04",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_31935828",
      "task": "Building executable for linux",
      "P-task": "build execut linux",
      "F_verb": "build",
      "P-body": "Linux distributions use packages, which are usually deployed in repositories. .  So you have two ways of distributing a python app. .   Creating a python package, and uploading it to PyPI, so that users can install it with \"pip install yourapplication\". Creating linux distribution packages (.deb for debian based, rpm for redhat, ...).  I recommend reading the excellent Python Packaging user guide for understanding how does python packages work. .  For linux distribution packages, well that is going to be different for every distribution, but for debian based distributions, have a look at stdeb which converts python packages into debian packages. .  ",
      "P-tags": "python-2 7 linux python",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "so_47764433",
      "task": "How to insert a complex linux terminal command's output to mysql database table",
      "P-task": "insert complex linux termin command output mysql databas tabl",
      "F_verb": "insert",
      "P-body": "I think your generated sql do not have the right quotations around the data. Try the following: .  For my ubuntu vm it worked fine.  .  ",
      "P-tags": "termin mysql linux databas output",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_22960044",
      "task": "How to find all IP addresses within a specific range?",
      "P-task": "find ip address within specif rang",
      "F_verb": "find",
      "P-body": " What should I do to fix this? .   You should make use of a tool that can perform comparisons: .  EDIT: As mentioned in the comments, in order to perform this for all files you can use \"find\": .  ",
      "P-tags": "linux regex",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP within NP"
    },
    {
      "id": "so_20556499",
      "task": "generating petsc binary file using python",
      "P-task": "gener petsc binari file use python",
      "F_verb": "generate",
      "P-body": "For illustration, let's take a small excerpt of that bash script: .  In a bash single-quoted string, as you have here, the characters \"\\n\" represent a backslash followed by \"n\". Python sees this as an \"extra backslash\" even though you meant \"\\n\" to be interpreted as a newline character. This is what generates errors of the type .  To fix this, try instead: .  Bash treats \"$'...'\" strings specially and will, among other things, replace \"\\n\" sequences with new line characters which python will understand and know how to process. .  (The above will still give an error because \"file\" does not have a \"shape\" attribute. More on this below.) .  There are other issues. Take, for example, this excerpt: .  After bash does quote removal, python sees:  .  This won't work because python needs \"PETSC_DIR\" and \"bin\" and \"pythonscripts\" to be quoted (with either single or double-quotes: python doesn't care). Try instead: .  python -c 'sys.path.append(os.path.join(os.environ[\"PETSC_DIR\"],\"bin\",\"pythonscripts\"))' .  When bash sees double-quotes inside single quotes, it leaves them alone. Thus, python will receive quoted strings where it needs them. .  In sum, it looks to me like the error is caused not by your python code but by what bash does to your python code before passing it to python. .  ADDENDUM: As for the \"print walls.shape()\" error where \"walls\" is a file handle, the error means what it says: file handles do not have \"shape\" attributes. Possibly you want to use the \"os.path.getsize(path)\" function from the \"os.path\" module to get file size in bytes? .  ",
      "P-tags": "petsc linux python bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "so_15324770",
      "task": "imagemagik convert files by directory",
      "P-task": "imagemagik convert file directori",
      "F_verb": "convert",
      "P-body": "+1 for \"Splitting up the problem into 1) finding the files, 2) deciding what to do with a file and 3) process the file. Making it modular will split the problem into parts which you can tackle separately.\" as previously suggested. This allow a more scalable approach for adding more processings.  .  This way, you don't need to pass the files by extensions. Is that what you want, passing the files by extensions? Do you have to do that?  .  Also, .   Use \"-iname '*.jpg'\" instead of \"-name '*.jpg'\" so as to do a case-insensitive search. Use more \"-iname\" parameters on the find to find all other extensions that you want. E.g.,  .  \"find cdn/ \\(-iname '*.jpg' -o -iname '*.jpeg' -o -iname '*.png' -o -iname '*.gif' \\) -print\" .   I.e., you find all the files you want in one-pass, instead of using find over and over to find different extension files.  .  ",
      "P-tags": "imagemagick linux",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP by NP"
    },
    {
      "id": "so_53139591",
      "task": "`dotnet new command` in openSuse causes `No usable version of the libssl was found` error",
      "P-task": "dotnet new command opensus caus usabl version libssl found error",
      "F_verb": "find",
      "P-body": "Can you install the \"libopenssl1_0_0\" packages? .NET Core should pick it up and use it. .  A slightly longer explanation for anyone who is curious: .  OpenSSL is one of the most common cryptographic libraries used on Linux. It has multiple versions. Version 1.0 is kind of old, but heavily used. 1.1 is the newer version that was (relatively) recently released. 1.0 and 1.1 are not compatible. An application that expects 1.0 can not build against 1.1, nor run against it.  .  .NET Core 2.1, and all earlier versions only support OpenSSL 1.0. .  Many Linux distributions are starting to make OpenSSL 1.1 the new default. But most of them still have a package for 1.0. So you just need to find and install that. On Fedora it's \"compat-openssl10\". For openSuSE, it's \"libopenssl1_0_0\". Then .NET Core will find it, pick it up and use it automatically. .  Edit: As of March 2019, this shouldn't be required. We have updated .NET Core 2.1 and later to pick up and work with either OpenSSL 1.1 or 1.0 (whatever is available). So this problem should no longer happen with recent releases of .NET Core.  .  ",
      "P-tags": "opensus linux net-cor libressl",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_18580135",
      "task": "Creating firewall rules using iptables",
      "P-task": "creat firewal rule use iptabl",
      "F_verb": "create",
      "P-body": "Yes and no.  .  No because: iptables works by defining how to treat packets based on their categorization into chains (INPUT, OUTPUT, FORWARD, ...) first and only then also on specific characteristics (source or destination address, protocol type, source or destination port, etc). You can never define an iptable rule that does not apply to a specific chain. .  INPUT, OUTPUT, and FORWARD are the default chains of the iptables system. INPUT addresses everything with destination localhost (i.e. that is addressed to your network device); OUTPUT applies to everything with source localhost (i.e. that comes from your computer). .  Yes because: You can define custom chains. You can do that like so .  then you can send packets from both the INPUT and the OUTPUT (and if you like the FORWARD) chain to MYCHAIN, for instance all the TCP packages from INPUT: .  or all the packages from OUTPUT .  and then you can define any rule you want for mychain, including .  which should be more or less the rule you wanted .  However, one might argue that it does indeed make sense to keep INPUT and OUTPUT chains seperate. Most users will want to apply much stricter rules on INPUT and FORWARD than on OUTPUT. Also, iptables can be used for routing in which case it makes a fundamental difference if you have an incoming or an outgoing package. .  ",
      "P-tags": "linux firewal iptabl",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "so_65419520",
      "task": "linux bash saved variable is empty",
      "P-task": "linux bash save variabl empti",
      "F_verb": "save",
      "P-body": "You have to add a shebang at the first line https://en.wikipedia.org/wiki/Shebang_(Unix) and make sure that there are no spaces after and before \"=\" .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_59598275",
      "task": "ifstream very strange behaviour when attempting to read unsigned char between 9 and 13",
      "P-task": "ifstream strang behaviour attempt read unsign char 9 13",
      "F_verb": "read",
      "P-body": "The Python script is creating a binary file whose content is bytes 0..19. Your C++ code is then reading that file in binary mode and outputting the numeric value of the bytes it reads. The problem is it is not reading what you are expecting. .  There are two problems with your C++ code: .   you are using \"eof()\" incorrectly. .  \"operator>>\" performs a formatted read, which is not what you want in this situation. \"operator>>\" ignores whitespace, and bytes 9..13 represent whitespace characters, which is why you don't see them being output. You need an unformatted read instead, such as by the steam's \"get()\" method .   Try this: .  Live Demo .  ",
      "P-tags": "c++ ubuntu",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP between NP"
    },
    {
      "id": "au_1204571",
      "task": "How to install Chromium without snap?",
      "P-task": "instal chromium without snap",
      "F_verb": "install",
      "P-body": "You can use Chromium from the Debian \"buster\" repository. For example, if your Ubuntu release is Eoan (19.10): .   Remove Ubuntu chromium packages: .   Add Debian \"buster\" repository. Create a file \"/etc/apt/sources.list.d/debian.list\" with the following content: .   Add the Debian signing keys: .   Configure apt pinning. Create a file \"/etc/apt/preferences.d/chromium.pref\" with the following content: .   Install Chromium again .    This should install the latest chromium from the \"debian-security\" repository and look like this: .  As you can see, only Chromium related packages are fetched from the Debian repository, but all others like \"libminizip1\" still come from your Ubuntu repository. .  ",
      "P-tags": "chromium ppa package-manag snap",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP without NP"
    },
    {
      "id": "so_48181169",
      "task": "shell script to display overview of steps instead of printing all logs to console",
      "P-task": "shell script display overview step instead print log consol",
      "F_verb": "display",
      "P-body": "You could redirect stdout and stderr of each individual command to /dev/null or, better, to a log file, and only echo a description to your steps to the console, i.e.: .  I personally would however do it like this: .  The reason is that when a git command fails, we usually do get error information on stderr, and in this case, we want to see the error message. .  Another way (which I would not recommend, but still would fit your requirement) is to redirect the output of the whole script to a log file, and print your status messages explicitly to the console: .  This means, however, that this script can only be sensibly used interactively, i.e. when you do have a console. .  ",
      "P-tags": "git unix shell bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP of S_ING to NP"
    },
    {
      "id": "su_376477",
      "task": "Combine tail -f with grep?",
      "P-task": "combin tail -f grep",
      "F_verb": "combine",
      "P-body": "You almost wrote the answer, which is :  .  That's it. .  ",
      "P-tags": "tail linux grep",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_324215",
      "task": "Reading only 1GB using dd command",
      "P-task": "read 1gb use dd command",
      "F_verb": "read",
      "P-body": "Your command is incorrect, you tell \"dd\" to read by 1 GB chunks, but an unlimited number of times. To only measure the time spent to read 1 GB, you need to tell \"dd\" to read only one block: .  Note that buffering will make that command run faster if the device has previously be read. .  ",
      "P-tags": "dd",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP using NP"
    },
    {
      "id": "so_57185672",
      "task": "What should I do with the loop variable to increase it by 1 per loop in Linux Shell?",
      "P-task": "loop variabl increas 1 per loop linux shell",
      "F_verb": "increase",
      "P-body": "The syntax for assigning values to variables in bash does not accept spaces around the \"=\" sign. .  In your case, replace that line with \"loop=$(($loop +1))\". .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP by NP in NP"
    },
    {
      "id": "ul_612016",
      "task": "How to list attributes (esp. date) of a symbolic link's target file?",
      "P-task": "list attribut esp\ndate symbol link target file",
      "F_verb": "list",
      "P-body": "add options \"-dLl\" to ls. .  \"-L\" tells \"ls\" do show target. \"-d\" tells it to not enter a directory (only makes a difference if the file is a directory). \"-l\" says to do a long list (with detail). .  ",
      "P-tags": "ls date symlink",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP of NP"
    },
    {
      "id": "au_1159862",
      "task": "Is it possible to make gnome's \"run command\" show real time suggestion?",
      "P-task": "possibl make gnome run command show real time suggest",
      "F_verb": "make",
      "P-body": "if you use Supera instead of AltF2it shows the list of all applications and then in the \"Type to Search\" dialogue, it will present all application beginning with what you have typed (such as Firefox, Files etc). .  Here is a link to other useful Gnome keyboard shortcuts. .  ",
      "P-tags": "gnome",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_8344859",
      "task": "How to check if a file exists on a server with bash",
      "P-task": "check file exist server bash",
      "F_verb": "check",
      "P-body": "How about this? .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "ul_627582",
      "task": "When I compute the average from a set of data in a file can I skip the first line",
      "P-task": "comput averag set data file skip first line",
      "F_verb": "compute",
      "P-body": "Yes, something like \"NR!=1\", or \"NR > 1\": .  If you want to do this over multiple files, use \"FNR\" instead: .  (I find the inequality clearer: to me it indicates explicitly that we\u2019re interested in records after a specific record.) .  ",
      "P-tags": "awk text-process",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_1365530",
      "task": "I am having this issue while running 'sudo apt-get update', \"Problem with MergeList\" or \"status file could not be parsed or opened.\"",
      "P-task": "issu run sudo apt-get updat problem mergelist statu file could pars open",
      "F_verb": "open",
      "P-body": "The source file that references the Xenial repository will need to be edited. You can find it via the command line like this: .   Open Terminal (if it's not already open) Go to the \"apt\" directory:  Identify the file referencing the bad repository via \"grep\":  Using \"sudo\", edit the file that is mentioned in the output with your preferred text editor, commenting out (or removing) the line. You can comment-out the line by putting a \"#\" at the front. Save the file and exit. Update \"apt\":   ",
      "P-tags": "apt updat package-manag software-cent",
      "source": "qa",
      "cate": "open",
      "pat": "V"
    },
    {
      "id": "su_157996",
      "task": "Utilities for find & open linux /usr/share/docs?",
      "P-task": "util find open linux usr share doc",
      "F_verb": "find",
      "P-body": "Each application is responsible for providing their own tool for reading the docs in \"/usr/share/doc\". There is no universal mechanism for handling it. .  ",
      "P-tags": "linux user-experi",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_28330022",
      "task": "Using a class for my webapp on Tomcat (JSP), \"The import my_matrix cannot be resolved\"",
      "P-task": "use class webapp tomcat jsp import my_matrix resolv",
      "F_verb": "use",
      "P-body": "The class is defined as .  and you're importing like this: .  Java cannot import classes in the default package on classes within one. So make sure you have the \"matrix\" class in the correct classpath: \"/test/WEB-INF/classes/my_matrix/matrix\" and import using the class name: \"<%@page import=\"my_matrix.matrix\"%>\" .  Additionaly, take into account that just importing a class won't invoke its \"main()\" method automatically. .  ",
      "P-tags": "tomcat ubuntu jsp java apach",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "so_64757171",
      "task": "Trying to disable inactive AD Computers using Powershell using dsquery",
      "P-task": "tri disabl inact ad comput use powershel use dsqueri",
      "F_verb": "disable",
      "P-body": "If you're using dsquery to find the computers, why not use dsmod/dsmove to complete the task? .  Note To use this in a batch file you need to double up % .  To answer your specific question, you'd need to construct an object before piping as powershell expects objects to come down the pipeline. It's probably easier to just use the text through a \"Foreach-Object\" loop .  Note The double quotes that dsquery adds to the distinguished name need to be removed. That is why \"-Identity ($_ -replace '\"')\" is present .  ",
      "P-tags": "powershel active-directori",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP using NP"
    },
    {
      "id": "so_38680195",
      "task": "How can I use sed to delete line with square brackets?",
      "P-task": "use sed delet line squar bracket",
      "F_verb": "delete",
      "P-body": "IMHO, you can't do it with just one \"sed\" but below might be an approach .  Note A backup of original file is placed in 38680195.backup .  Edit .  A smarter approach may be  .  In this case if none of the lines contain \"[]\", the sed part wont be executed because it is logically \"AND\"ed (See \"&&\"). .  ",
      "P-tags": "bracket sed bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "so_59837848",
      "task": "How can I put a timeout on a powershell command?",
      "P-task": "put timeout powershel command",
      "F_verb": "put",
      "P-body": "I have finally found the solution. The Start-Job script starts in a default home folder, different from the script location. So it works if I use an absolute path. I like this code much better than custom made loops: .  ",
      "P-tags": "powershel timeout start-job",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_60746903",
      "task": "Is it possible to create a virtual symlink?",
      "P-task": "possibl creat virtual symlink",
      "F_verb": "create",
      "P-body": "You can bind-mount \"/var/www/custom\" onto \"/var/www/html/www.example.com/wp-content/themes/exampletheme/custom\". .  Mount points cannot be deleted, only unmounted, and that (a) requires root privileges and (b) not something programs usually resort to when they can't delete something. So that should work. .  ",
      "P-tags": "linux symlink filesystem",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_39731551",
      "task": "JVM System Property - how to treat as string literal",
      "P-task": "jvm system properti - treat string liter",
      "F_verb": "treat",
      "P-body": "Bash requires the curly braces to be escaped, as in: .  The other option is to try surrounding the entire string in single quotes. Bash won't do any expansions inside single quotes: .  I don't know which option will be easier to make compatible with your windows environment. .  ",
      "P-tags": "jvm linux properti java bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V as NP"
    },
    {
      "id": "au_942646",
      "task": "Problem with sudo apt-get each time I log on",
      "P-task": "problem sudo apt-get time log",
      "F_verb": "get",
      "P-body": "This is probably the auto-update functionality of Ubuntu. Try waiting a few minutes after logging in and it should now run correctly. .  To prevent this from happening at all, uninstall the \"unattended-upgrades\" package (which is kicking off those updates) with the following command: \"sudo apt purge unattended-upgrades\" .  After a reboot the problem you are facing should be gone. .  ",
      "P-tags": "dpkg apt lock",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_15381602",
      "task": "Optional argument to replace variable in bash script",
      "P-task": "option argument replac variabl bash script",
      "F_verb": "replace",
      "P-body": "How about replace:  .  with: .   \"$#\" is the number of command line arguments This is less elegant as \"getopt\" but easy to understand and extend.  ",
      "P-tags": "variabl linux host bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_23041",
      "task": "How do I set Keyboard and profile preferences when connecting to Solaris via SSH?",
      "P-task": "set keyboard profil prefer connect solari via ssh",
      "F_verb": "connect",
      "P-body": "A Solaris machine has ksh as the default shell, I believe. Ksh doesn't have the sophisticated interactive feature you may be used to if you've used bash or zsh before. If you want a comfortable environment, install zsh or at least bash on the Solaris machine. If bash or zsh is already installed by the system administrator, use \"chsh\" to switch to it. If you install it yourself, you won't be allowed to use \"chsh\", but instead you can switch shells inside your \".profile\" (make this the last thing): .  If you decide to stick with ksh, its configuration file is \"~/.kshrc\", that's where you would define aliases. Note that aliases are for each shell instance, not for a session, so they don't belong in \"~/.profile\"). .  The Backspace key should work out of the box if everybody left things well alone. Unfortunately, many OSes ship with settings that make double sure everything works as long as you're using the same OS everywhere, but break the automation that would otherwise make things work across remote logins. I don't know which of Solaris or OSX is the culprit. If you don't feel like investigating, you can tell the Solaris shell that the \u201cDEL character\u201d deletes to the left with this command in your \"~/.profile\" (this will do the wrong thing if you log in from a machine where BackSpace sends \"^H\"). .  The Escape key doesn't normally quit any text mode application. The usual man page viewer is \"less\", and its quit command is bound to \"q\". .  ",
      "P-tags": "solari alia ssh keyboard profil",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP via NP"
    },
    {
      "id": "so_47928211",
      "task": "Inner join two files based on one column in unix when row names don't match with sort",
      "P-task": "inner join two file base one column unix row name match sort",
      "F_verb": "join",
      "P-body": "We haven't seen a sample of your original \"gene2accession\" file yet but let's assume it's a tab-separated field with \"accession\" in the 2nd column and \"gene\" in the 16th (since that's what your \"cut\" is selecting) with a header line. Let's also assume that your \"Accessions\" file isn't absolutely enormous. .  Given that, this script should do what you want: .  but you could try this to see if it's faster: .  and if it is and you want an intermediate file for the output of the \"sort\" to use in subsequent runs:  .  ",
      "P-tags": "awk python unix r",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP on NP in NP when S"
    },
    {
      "id": "so_63025267",
      "task": "crontab remove file which's path contain %",
      "P-task": "crontab remov file path contain",
      "F_verb": "remove",
      "P-body": "You need to backslash the \"%\" character, so: .  From \"man 5 crontab\": .   The 'sixth' field (the rest of the line) specifies the command to be run. The entire command portion of the line, up to a newline or % character, will be executed by /bin/sh or by the shell specified in the SHELL variable of the crontab file. Percent signs (%) in the command, unless escaped with backslash (), will be changed into newline characters, and all data after the first % will be sent to the command as standard input. There is no way to split a single command line onto multiple lines, like the shell's trailing \"\". .   ",
      "P-tags": "linux cron shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP which S"
    },
    {
      "id": "so_57207935",
      "task": "Docker doesn't download recommended packages",
      "P-task": "docker download recommend packag",
      "F_verb": "download",
      "P-body": "\"apt-get update\" should not install anything. The only thing \"apt-get update\" should do is update the local description of what packages are available. That does not download those packages though -- it just downloads the updated descriptions. That can take a while. .  \"apt-get install\" will of course install packages. In order to install those packages, it needs to download them. Using \"--no-install-recommends\" tells \"apt-get\" to not install \"recommended packages\". For example, if you install \"vim\", there are many plugins that are also recommended and provided as separate packages. With that switch, those vim plugins will not be installed. Of course, installing the packages you selected can also take a while. .  What you're doing, using \"&& \\\" is to put all of that into a single docker command. So every time you rebuild your image, you will have to do that every time because the list of packages changes every day, sometimes even multiple times per day. .  Try moving \"pip install -r requirements.txt\" to its own \"RUN\" command after you've run \"apt-get\" stuff. If that then does what you want, then I suggest reading and learning more about how Docker works under the hood. In particular, it's important to understand how each single command adds a new layer and how any dynamic information in a single layer can cause long build times because the layer will frequently change with large amounts of changes. .  Additionally, you might want to move \"ADD . /abc\" to after the \"RUN\" commands. Any changes you've made to the files being added (source code, I assume) will invalidate the layer which represents the \"apt-get\" command that has been executed. Since it's been invalidated, it will need to be rebuilt. If you're actively working on and developing those projects, that can easily cause \"apt-get\" to be executed every time you build your image. .  There are plenty of resources you can search for which discuss how to optimize your time when using Docker. I won't recommend any specific one and will leave it to you for learning. .  ",
      "P-tags": "docker-compos linux dockerfil docker",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_9372431",
      "task": "How can i add StdOut to a top of a file (not the bottom)?",
      "P-task": "add stdout top file bottom",
      "F_verb": "add",
      "P-body": " same as shellter's .  and sed in one line. .  this will insert to file1 inplace. the sed example i referred to .  ",
      "P-tags": "linux gnu bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "au_726776",
      "task": "set nginx server_name variable from command",
      "P-task": "set nginx server_nam variabl command",
      "F_verb": "set",
      "P-body": "Your global \"/home/dokku/VHOST\" file must have been overwritten with \"dokku.me\". Check that, as well as the \"/home/dokku/APP/VHOST\" file. .  ",
      "P-tags": "nginx command-lin docker",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP from NP"
    },
    {
      "id": "so_39976679",
      "task": "Convert plain string to MAC Address format",
      "P-task": "convert plain string mac address format",
      "F_verb": "convert",
      "P-body": "Think about it in terms of smaller units. You actually want to insert \":\" after every two characters (except at the end of the string) instead of trying to capture every single character and forcing it into the desired format. .  This regex matches two characters at a time and replaces them by the same characters (\"$&\" in a replacement string represents the match) followed by \":\". Except at the end of the string, which is done via a negative lookahead preventing a match at the end of the string. This works because the regex engine won't look for matches that extend backwards into previous matches. So after the first two characters have been matched, the next match can only occur after that first one. This implicitly gives you groups of two characters to replace. .  Instead of \".\" you can also use \"[0-9a-f]\" if you really want, but I think input validation is a different problem than output formatting here. The output code should be able to trust that the string indeed contains only hexadecimal digits. .  Validation can be done as simply as .  And it's actually easier to detect a malformed string this way than by detecting whether the replacement did nothing. .  ",
      "P-tags": "powershel mac-address regex",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_603758",
      "task": "Is it possible to split a command in tmux.conf across multiple lines?",
      "P-task": "possibl split command tmux conf across multipl line",
      "F_verb": "split",
      "P-body": "According to \"man tmux\": .   Each command is terminated by a newline or a semicolon (;). .   Thus it may seem that it's not to insert a newline in a command. .  However, command arguments may contain contain newlines, which can be used to span a command over multiple lines: .  \"' ... \\\" or \"\" ... \\\": .    (\"{ ... }\"): .    Example: .  ",
      "P-tags": "termin tmux debian shell",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP in NP"
    },
    {
      "id": "so_55191913",
      "task": "Appending multiple csv files in to a single csv file using shell scripts",
      "P-task": "append multipl csv file singl csv file use shell script",
      "F_verb": "append",
      "P-body": "Something like this using awk: .  This: Treats the first line of the first file as a header line to print out, skips the first lines of all further files, and prints the remaining lines of all files, appending a column with the current filename to each one. .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP using NP"
    },
    {
      "id": "so_51180971",
      "task": "Linux grep expression stop matching until find a windows carriage return character",
      "P-task": "linux grep express stop match find window carriag return charact",
      "F_verb": "stop",
      "P-body": "To simplify, lets consider this file: .  The problem that you are running into is not \"^M\". It is that standard \"grep\" processes only one line at a time. .  Using sed To get everything from the line containing \"/id D4333F9F\" to the end of the file, there are several standard tools that you can use. For example, try \"sed\": .  Here \"/\\/id D4333F9F/,$ p\" tells sed to print any lines starting with a line matching \"/id D4333F9F\" and ending with the last line (\"$\"). .  Using awk Try \"awk\": .  Here, \"/\\/id D4333F9F/{f=1}\" tells awk to set the variable \"f\" to one when the first line that matches \"/id D4333F9F\" is found. The last \"f\" is shorthand that tells awk to print if \"f\" is true (meaning nonempty or nonzero). .  Using grep with GNU extensions Lastly, if your \"grep\" has the \"-P\" extension (this requires GNU grep), then try: .  This grep code is explained in detail here. .  ",
      "P-tags": "linux bash grep regex",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V S_ING"
    },
    {
      "id": "au_548661",
      "task": "How can I run a bash script without affecting the file system?",
      "P-task": "run bash script without affect file system",
      "F_verb": "run",
      "P-body": "Try using an overlay, with a \"chroot\". First, decide the path you want to chroot to, and make sure it exists, and similarly for the path you will overlay on \"/\" (which is where modifications will go): .  I chose a directory in \"/tmp/\" as it's a \"tmpfs\" on my system (possibly unadvisable, but OK for me), so no changes should reach the disk. You can use a \"squashfs\" and mount it somewhere, and use that as the overlay, but that has the problem of being read-only, I think. .  Now: .  If you make the \"upperdir\" independent of a physical disk (perhaps by using \"tmpfs\"), this should protect the \"lowerdir\". .  Note the creation of a \"root\" folder - that's for my \".bash_history\". A copy was made of the original \".bash_history\", and then appended to. .  ",
      "P-tags": "script bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without S_ING"
    },
    {
      "id": "su_130305",
      "task": "How do you set up Ubuntu to see Windows Network?",
      "P-task": "set ubuntu see window network",
      "F_verb": "set",
      "P-body": "In Linux machine check \"/etc/samba/smb.conf\".If you have in your shares option \"browseable = no\" this means that you can mount the share but you can't see it on your network ,it's like invisible share. You'll need to edit these..  .  Then try to run \"nmblookup \\*\" .  and do sudo \"gedit /etc/nsswitch.conf\" . Look for a line starts with hosts:. if the line doesnt contain the word \"wins\" change the line to: \"hosts: files wins dns\" .  You may also need to grant share permissions on the Window machine. It works better when this is an intentionally shared folder and not a default share or a \"Shared Documents\" folder. In Vista and some XP you have to actually find the \"Permissions\" button on the Sharing tab and grant everyone permission. This is different than NTFS file permissions on the Security tab and can be a pain to figure out on the \"Home\" versions. .  take a look at File and Printer Sharing in Windows. .  ",
      "P-tags": "linux ubuntu-9 10 windows-network",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_10076741",
      "task": "How to redirect standard input and output with Bash",
      "P-task": "redirect standard input output bash",
      "F_verb": "redirect",
      "P-body": "The most likely explanation is that the output you're seeing is from \"stderr\", not \"stdout\". To redirect both of them to a file, do this: .  or .  ",
      "P-tags": "io bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP with NP"
    },
    {
      "id": "au_257905",
      "task": "How can I tell which package an executable came from?",
      "P-task": "tell packag execut came",
      "F_verb": "tell",
      "P-body": "install apt-file .  update apt-file .  search the package a file belongs to .  find path of executable .  search package .  the package name is: \"util-linux\" .  ",
      "P-tags": "dpkg apt",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V which S"
    },
    {
      "id": "ul_165765",
      "task": "Why does Debian prefer a temp file replacing the original over modifying bytes in original file?",
      "P-task": "debian prefer temp file replac origin modifi byte origin file",
      "F_verb": "replace",
      "P-body": "Your question suggests that Debian uses temp files for all writes, which isn't the case. This is simply the default for \"mp3gain\". .  In version 1.4.3-2, the package maintainer (Stefan Fritsch) decided that as writing to a temp file is much quicker on ReiserFS, then this would be the default on Debian. This was sourced from the patch at https://packages.debian.org/source/squeeze/mp3gain .  Package maintainers on other distros presumably didn't agree with Stefan and therefore didn't change the default of not using temp files. .  ",
      "P-tags": "write tmp debian file filesystem",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP over S_ING in NP"
    },
    {
      "id": "au_903780",
      "task": "How to resize the / partition",
      "P-task": "resiz partit",
      "F_verb": "resize",
      "P-body": "Your best bet is to boot into Windows like Organic Marble said. .  1. Use Windows Disk Manager to resize your Windows partition (most likely labeled as \"C:\"). This will ensure you don't inadvertently lose any data in the Windows partition when you resize it.  .  2. Once you have resized this to your liking, live boot back into Ubuntu (or whatever OS you used to access gparted in your screenshot) and remove your swap partition.  .  3. Once the swap partition has been removed, you should be able to extend SDA6 to encompass the unallocated \"free\" space you created when you were in Windows.  .  4. Once you have done this resize your SDA6 partition one more time to free up about 4-8 GiB of free space.  .  5. Once that has been completed recreate your swap partition using the free space you created in the previous step.  .  By manipulating your disk in this manner you will keep your root partition within a contiguous partition on your disk. You really don't need to worry too much about manipulating your swap partition. This is used for additional \"RAM\" space so to speak. It functions the same way as a page file in Windows.  .  ",
      "P-tags": "gpart",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_55191638",
      "task": "Jest doesn't run -- hangs indefinitely",
      "P-task": "jest run -- hang indefinit",
      "F_verb": "run",
      "P-body": "I'm not sure WHY this worked, but it did. I reinstalled some global packages on my system: .  \"npm update npm -g\" (to 6.9.0) .  this updated: parcel-bundler to 1.12.3 .  updated watchman: \"brew update watchman\" (to 4.9.0) .  ",
      "P-tags": "ubuntu-16 04 jestj yarnpkg node js create-react-app",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_11585231",
      "task": "How to run script on BITS download completion",
      "P-task": "run script bit download complet",
      "F_verb": "run",
      "P-body": "I would suggest using the BitsTransfer module as it exposes native PowerShell methods for working with BITS jobs. To get started, you simply instruct PowerShell to load the BITS module: .  Running Get-Command to see what new BITS cmdlets have been added shows: .  The one you will most likely be interested in would be Start-BitsTransfer: .  The cmdlet will show a progress bar on the screen and wait for the download to finish - the next command in your script won't execute until the download has finished. .  For async tasks, you can add the \"-Asynchronous\" parameter to the Start-BitsTransfer cmdlet, which will queue up the download and let it run in the background. You can manage those downloads with the Get-BitsTransfer and Complete-BitsTransfer cmdlets. .  ",
      "P-tags": "powershel bits-servic microsoft-bit",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_15407336",
      "task": "Supply a string variable instead of a filepath as a command line argument",
      "P-task": "suppli string variabl instead filepath command line argument",
      "F_verb": "supply",
      "P-body": "Process substitution of the form \"<(...)\" sends the stdout of the commands in parenthesis to a special temporary file, and returns the path to that file. This is so that commands that only take a filename as an argument can read the output of other commands. You can see this by just echo'ing a substitution: .  So if you wanted the contents of that special file to be the string \"privatekeystuffdis88s8dsf8h8hsd8fh8d\", you would want to do: .  UPDATE .  The \"special temporary file\" is really just the file descriptor of the read end of a \"pipe(7)\" created by the shell. \"/dev/fd\" is a symlink to \"/proc/self/fd\", so in the above example, the real \"file\" is actually \"/proc/self/fd/63\", which would look something like \"lr-x------ 1 user group 64 Mar 14 12:26 63 -> pipe:[1955808]\" in a long listing. .  What's important here is that it's not a regular file. It's a named pipe, which means that once data is read from the pipe, it's removed from the pipe. This is a problem for your use-case because it appears that \"ssh\" opens/closes the identity file multiple times: .  Which means it's going to get different and incomplete data the second time it tries to open and read. So it would appear that you cannot use process substitution in this case. .  ",
      "P-tags": "command-lin posix maco bash",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP of NP as NP"
    },
    {
      "id": "so_45450559",
      "task": "Application shows as 'Microsoft Accounts' as publisher but not show up through powershell",
      "P-task": "applic show microsoft account publish show powershel",
      "F_verb": "show",
      "P-body": "You could use \"Get-AzureADServicePrincipal\" to get \"PublisherName\". .  Here is the result: .   .  You also could refer to this similar question. .  ",
      "P-tags": "azur powershel",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V as NP as NP through NP"
    },
    {
      "id": "so_62620766",
      "task": "Why am I not able to use -o or --format with ps command to control the output format?",
      "P-task": "abl use -o -- format ps command control output format",
      "F_verb": "use",
      "P-body": "Git Bash is a terminal for Windows that emulates the Linux bash (shell) functionality. It is not 100% compatible to a \"real\" bash shell. As you've empirically seen, its \"ps\" executable doesn't support all the flags you're used to from Linux. The \"--help\" option will show you what flags are supported. .  ",
      "P-tags": "linux git-bash ps",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP S_INF"
    },
    {
      "id": "so_33445815",
      "task": "Getting a user ID and a process group ID from a task_struct and a pid_namespace",
      "P-task": "get user id process group id task_struct pid_namespac",
      "F_verb": "get",
      "P-body": "You should be able to use \"task_struct->cred->uid\" or \"task_struct->real_cred->uid\". That being said, I have not tested this and this is just from a cursory reading of LXR (include/linux/sched.h line 1508 and include/linux/cred.h line 127). .  If you want the PGID, try \"pid_vnr(task_pgrp(task_struct))\". This code is from kernel/sys.c line 990. .  ",
      "P-tags": "process-group userid process linux-kernel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_47713201",
      "task": "What's the correct way to get a list of users in this bash script?",
      "P-task": "correct way get list user bash script",
      "F_verb": "get",
      "P-body": "You can use \"glob\" loop like this: .  \"*/\" only lists directories. .  ",
      "P-tags": "variabl bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_26597926",
      "task": "Install MySQL with ansible on ubuntu",
      "P-task": "instal mysql ansibl ubuntu",
      "F_verb": "install",
      "P-body": "When \"mysql-server\" is installed headlessly, there's no password. Therefore to make \".my.cnf\" work, it should have a blank password line. Here's what I tested with for a \".my.cnf\": .  It's also slightly strange to put \".my.cnf\" in your \"vagrant\" user directory as owned by root and only readable as root. .  After ensuring the password was blank in \".my.cnf\", I was able to properly set the password for root in those four contexts. Note that it fails to run after that, since \".my.cnf\" would need to be updated, so it fails the idempotency test. .  There's a note on the ansible mysql_user module page that suggests writing the password and then writing the \".my.cnf\" file. If you do that, you need a \"where\" clause to the \"mysql_user\" action (probably with a file stat before that). .  Even more elegant is to use \"check_implicit_admin\" along with \"login_user\" and \"login_password\". That's beautifully idempotent. .  As a third way, perhaps \"check_implicit_admin\" makes it even easier. .  Here's my successful playbook showing the above, tested with a few fresh servers. Kinda proud of this. Note \".my.cnf\" is unnecessary for all of this. .  (edit- removed my.cnf) .  ",
      "P-tags": "ubuntu mysql ansibl vagrant",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "au_826890",
      "task": "apt build-dep fails, unable to locate source package, despite deb-src lines present in the /etc/apt/sources.list.d folder",
      "P-task": "apt build-dep fail unabl locat sourc packag despit deb-src line present etc apt sourc list folder",
      "F_verb": "build",
      "P-body": "You need to uncomment the \"deb-src\" lines in the main sources file \"/etc/apt/sources.list\", not the extra files in \"/etc/apt/sources.list.d\" .  For example, change: .  to .  Then update the local database: .  and proceed :) .  ",
      "P-tags": "compil software-sourc apt 16 04 emac",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V"
    },
    {
      "id": "so_2051994",
      "task": "How do I free memory obtained by sbrk()?",
      "P-task": "free memori obtain sbrk",
      "F_verb": "obtain",
      "P-body": "You need to use \"brk\" or \"sbrk\" again to shrink.  .  In the end the only way you have to modify the amount of memory(apart from mmap like syscalls), is to increase or decrease the heap, so you move it up with \"sbrk\" or \"brk\" and you move it down with \"brk\" or \"sbrk\" with a negative increment. .  ",
      "P-tags": "c memory-manag sbrk unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V by NP"
    },
    {
      "id": "so_6117329",
      "task": "Best way to recursively ignore a file or directory pattern in SVN without globally ignoring",
      "P-task": "best way recurs ignor file directori pattern svn without global ignor",
      "F_verb": "ignore",
      "P-body": "Using \"find\" might be nicer. Something like: .  Or pass in the pattern as an argument to the function. Replace my \"echo somethings\" with your work-logic. It just avoids the actual recursion, to use \"find\" this way. .   Of course, really you should adjust your flow to generate files somewhere else, or at least in just one \"output\" folder, for tidiness, wherever possible, so you're not needing to ignore an ever-growing list of files. .  But yeah, some tools aren't so tidy as we'd like, alas. .  ",
      "P-tags": "svn version-control bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "au_998735",
      "task": "How to properly install Microsoft Office in Ubuntu 14.04 with wine?",
      "P-task": "properli instal microsoft offic ubuntu 14 04 wine",
      "F_verb": "install",
      "P-body": "PlayOnLinux - for Microsoft Office 2010 and higher I've figured out with a wine GUI called Playonlinux. WORKS FOR ANY VERSION OF UBUNTU .  It comes with the addequate configuration for multiple applications and games, you have to have only the installer and then follow the program instructions.  .  For installing it run the following commands: .  To add the repository that contains the program .  And to install it: .  Then I installed Microsoft Office Pack 2010 following steps below: .   Install \"winbind\" dependency with \"sudo apt-get install winbind\" Open PlayOnLinux, click Install, search for Microsoft Office 2010, browse for setup.exe and wait it to finish (on Ubuntu 16.04 LTS will download Wine 1.7.52 and dependencies, will create virtual drive as ~/.PlayOnLinux/wineprefix/Office2010/, report success of installation and will create shortcuts). You can access MSO 2010 applications from Dash or other Applications menu.  WineTricks - for Microsoft Office 2007 and lower  Install WineTricks from repository with \"sudo apt-get install winetricks\" Prepare OFFICE12.iso with complete Microsoft Office 2007 installation media, mount it with Disk Image Mounter (see this Q&A). Create empty wine-prefix and install MSO 2007 here with: .   Wait setup to finish. .  As the result you will get MSO 2007 installed with shortcuts and file-associations (in my experience PlayOnLinux does not do so with MSO 2007).  ",
      "P-tags": "14 04 microsoft-offic wine",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_69162047",
      "task": "remove cron jobs along with their comment, environment which were created by Puppet by awk/sed",
      "P-task": "remov cron job along comment environ creat puppet awk sed",
      "F_verb": "remove",
      "P-body": "You would be well advised to use Puppet to remove the crontab entries that were created by Puppet. .  If you have to do it via a manual-ish shell command, however, then you can do it via this \"sed\" command: .  Explanation .  The command assumes that each group of lines to delete starts with a \"Puppet Name:\" comment and continues up to and including the next line that is neither blank (but for whitespace), nor a comment, nor an environment variable assignment. It modifies the specified file in place (\"-i\"), with auto-printing disabled (\"-n\"). The expression (\"-e\") does the following: .   If the next line read does not start with the text \"\"# Puppet Name:\"\" then print that line and start the next cycle (\"{p;d}\"). Otherwise, this point in the expression is labelled \"p\" (\":p\"); silently (because auto-print is disabled) read the next line of input (\"n\"); if the current line is blank, is a comment, or is an environment setting then branch to label p (\"b p\"); else the end of the expression is reached. Silently (because auto-print is disabled) start the next cycle.  ",
      "P-tags": "awk puppet cron shell sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP which S"
    },
    {
      "id": "so_19261045",
      "task": "curl PUT data from a huge file?",
      "P-task": "curl put data huge file",
      "F_verb": "put",
      "P-body": "You can use a file as data by passing \"-d @/path/to/file\" (or \"-d @-\" to read from stdin). .  ",
      "P-tags": "curl bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_10124721",
      "task": "Is there a kernel module that returns exactly what a simple 'ifconfig' does?",
      "P-task": "kernel modul return exactli simpl ifconfig",
      "F_verb": "return",
      "P-body": "You can get all of that information through the \"struct net_device\" one way or another. As Albert Veli said, you can get this \"struct net_device\" pointer using \"__dev_get_by_name()\". .  If you tell us what information you need specifically we might even be able to point you to the correct fields. .  Finding the MAC address is fairly simple: .  Finding the IP address is rather harder, but not impossible: .  (None of this was compile tested, so typos are possible.) .  ",
      "P-tags": "kernel-modul linux network-interfac",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V what S"
    },
    {
      "id": "so_46659340",
      "task": "BASH - Taking next element in for loop with file names",
      "P-task": "bash - take next element loop file name",
      "F_verb": "take",
      "P-body": "You could access the previous element instead of the next: store the current file name of an iteration and reuse it in the next one. Something like: .  Note: if you really want to enclose variable names, use the curly braces (as in the code above), not the parentheses (as in your code): \"${file}\" evaluates as the value of variable \"file\" while \"$(file)\" calls command \"file\" without an argument, and returns an error message. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "ul_193072",
      "task": "How to set Timeout for an ssh command and also get back the result of remote commands",
      "P-task": "set timeout ssh command also get back result remot command",
      "F_verb": "get",
      "P-body": "Use GNU Parallel to parallelize your collection: .  Put the nodes in \"~/.parallel/rhel-nodes\". .  \"--tag\" will prepend the output with the name of the node. \"--timeout 1000%\" says that if a command takes 10 times longer than the median to run, it will be killed. \"--onall\" will run all commands on all servers. \"--retries 3\" will run a command up to 3 times if it fails. \"::: bash bc perl\" are the packages you want to test for. If you have many packages, use the \"cat packages | parallel ...\" syntax instead of the \"parallel ... ::: packages\". .  GNU Parallel is a general parallelizer and makes is easy to run jobs in parallel on the same machine or on multiple machines you have ssh access to. .  If you have 32 different jobs you want to run on 4 CPUs, a straight forward way to parallelize is to run 8 jobs on each CPU: .   .  GNU Parallel instead spawns a new process when one finishes - keeping the CPUs active and thus saving time: .   .  Installation .  If GNU Parallel is not packaged for your distribution, you can do a personal installation, which does not require root access. It can be done in 10 seconds by doing this: .  For other installation options see http://git.savannah.gnu.org/cgit/parallel.git/tree/README .  Learn more .  See more examples: http://www.gnu.org/software/parallel/man.html .  Watch the intro videos: https://www.youtube.com/playlist?list=PL284C9FF2488BC6D1 .  Walk through the tutorial: http://www.gnu.org/software/parallel/parallel_tutorial.html .  Sign up for the email list to get support: https://lists.gnu.org/mailman/listinfo/parallel .  ",
      "P-tags": "rhel timeout ssh bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP"
    },
    {
      "id": "so_21097638",
      "task": "I want to open git bash in a linux server using putty. How will I do that?",
      "P-task": "want open git bash linux server use putti",
      "F_verb": "open",
      "P-body": "Actually Windows gitbash is an emulation of a bash command interpreter designed for UNIX systems. On many Linux distributives bash is a default command shell. So, when you're connecting to a Linux via putty, you're actually entering a bash shell. There's nothing more you need. You can use it the similar way as you're using windows gitbash. In a nutshell, just omit the first item in the spet 5 of your tutorial: you probably already in the bash shell. .  To check out which shell you're using, run this command: \"ps -p $$\". It will output something like this: .  The CMD field is the shell name you're using. .  ",
      "P-tags": "git linux putti",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "ul_324680",
      "task": "how to apply a patch in a debian package?",
      "P-task": "appli patch debian packag",
      "F_verb": "apply",
      "P-body": "Starting with the situation you have: .  will apply the patch. Before building, add a NMU changelog entry (this will avoid having your patched version of \"dpkg\" overwritten by \"apt\" & co., but will ensure your version is upgraded to the next \"dpkg\" release when that's available): .  This will rename the current directory (because \"dpkg\" is a native package), so you need to change directories again: .  To build, I tend to use .  That will produce the various \".deb\" files in the parent directory; you can install them using \"dpkg\" as usual. .  (Calling \"debian/rules\" targets explicitly works too; but you shouldn't use \"fakeroot\" for \"debian/rules build\", just for \"debian/rules clean\" and \"debian/rules binary\".) .  Adding a NMU changelog entry also ensures that the source you've downloaded is left untouched, which addresses your backup concerns. It also means that reinstalling version 1.18.15 will restore the Debian version, without your patch. .  ",
      "P-tags": "package-manag debian compil patch",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_574080",
      "task": "Where is the file contains log for last command (Ubuntu)",
      "P-task": "file contain log last command ubuntu",
      "F_verb": "contain",
      "P-body": "You can check which files are opened by a given program with strace like that: .  The file you're looking for is \"/var/log/wtmp\". You can read more about it in \"man 5 wtmp\". .  ",
      "P-tags": "linux ubuntu",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP"
    },
    {
      "id": "au_590027",
      "task": "How to set python 3 as default interpreter in Ubuntu 14.04",
      "P-task": "set python 3 default interpret ubuntu 14 04",
      "F_verb": "set",
      "P-body": "There would be multiple ways of doing this. First, change the sym-links around so that the \"python\" in \"/usr/bin/\" would actually be pointing to the same location as the \"/usr/bin/python3\" sym-link. However, this is a bad idea (as I explain below). .  The second option would be to create a user-specific command alias - this is definitel the better option of the two. .   Changing Sym-links is bad Python is used throughout much of Ubuntu for system scripts and software, and software relies on having Python (and the commands to start Python) in a certain spot. See here (Ubuntu Wiki - rather outdated) and here (Debian Wiki) for more information as to what Ubuntu/Debian use Python for. .  Now, while Python 3 (3.4.0 in your case) is the newest and the suggested version of Python, there's still a lot of code still out there that hasn't been ported to Python 3. .  By default, as you've seen, running \"python\" runs the Python 2.7 interpreter - and that's what the software on your computer is going to expect. .  So, if you change the command to run Python 3, you're going to cause all sorts of havoc and code breakage because you'll be trying to run Python 2.7 code (which is written in Python 2.7 syntax and uses Python 2.7 libraries) using the Python 3.4 interpreter (which expects Python 3.4 syntax and Python 3.4 libraries.) .   Safer, alias-creating method However, what you can do, is create an alias for your personal use. This can be accomplished easily by adding the following line: .  or .  /in the \"~/.bash_aliases\" file - which you can edit via \"sudo nano ~/.bash_aliases\". Then, close and reopen the terminal and you should be able to use the \"python\" command for your own personal use without it affecting the rest of the system. .  However, this, again, isn't suggested because although you won't break any of the system-wide code that relies on proper placement of Python interpreters, I've heard it can cause other issues (that I don't know/remember.) .   Proper method that doesn't require changing the Python interpreter at all If you're writing syntax-correct Python, you should include what is known as a Shebang. See also here, and here.) .  If included properly, this would allow you to run a Python script simply via \"./SCRIPT-NAME.py\" after making the script executable via \"sudo chmod +x ./SCRIPT-NAME.py\". You could also totally forgo having the \".py\" file type and just type the code into an empty file and save it as \"SCRIPT-NAME\" and then run \"sudo chmod +x ./SCRIPT-NAME\" and run it via \"./SCRIPT-NAME\". .  Granted, this does take a bit more work - but it will make sure that your code is executed using the correct interpreter. .  And, really. How hard is it to type \"python3\" to run the code correctly? I'm not trying to be mean, and I can kinda see why you would want to do this, but it isn't that hard just to run \"python3\" instead of \"python\". .  ",
      "P-tags": "14 04 python amazon-ec2",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "so_65238443",
      "task": "for each Name from CSV write to each output file replacing the word 00000 to name for example 1 output Henry and so on",
      "P-task": "name csv write output file replac word 00000 name exampl 1 output henri",
      "F_verb": "write",
      "P-body": "I think you want to do: .   read a template file \"c:\\Config.txt\" which contains \"\"00000\"\" as placeholder read a csv file \"C:\\Something-PREP.csv\" which contains among others a column called \"Name\" use those names to replace the \"\"00000\"\" placeholders in the template output new files \"C:\\Henry.txt\", \"C:\\Magy.txt\" etcetera  If that assumption is correct, try .  P.S. Make sure the CSV you are importing uses the comma as delimiter character. If this is some other character, add \"-Delimiter '<yourCharacter>'\" to the cmdlet. .  ",
      "P-tags": "powershel for-loop replac",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP S_ING to NP"
    },
    {
      "id": "so_45636761",
      "task": "Linux command run cpp and jar",
      "P-task": "linux command run cpp jar",
      "F_verb": "run",
      "P-body": "To run your java program even when you exit out of your shell, Nohup is the simplest way. .  It'll detach a process you run from your current console and let it continue when you close the terminal. Run something like this. .  By default, it will pipe the output to nohup.out, so if you don't want that you could try: .  ",
      "P-tags": "linux ubuntu jar background-process",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_23951346",
      "task": "Is there a subshell created when I run `sh -c \"command\"`, a new shell or none of these?",
      "P-task": "subshel creat run sh -c command new shell none",
      "F_verb": "create",
      "P-body": "I think that with examples it's possible to understand the situation (in my case \"sh\" is a symbolic link to \"/bin/dash\"). I did this tests for \"sh\": .  Three different \"PID\", three different \"shell\". If there are different shells, there is not a subshell spawn). .   In a similar way for \"BASH\" .  Three different \"$BASHPID\" no different \"$BASH_SUBSHELL\" (see note below for differences between \"$$\" and \"$BASHPID\"). If we were in a subshell that do not require to be reinitialized, then \"$$\" and \"$BASHPID\" should be different. In the same way \"$BASH_SUBSHELL\" is not incremented, it is always \"0\". So 2 clues to say again that no new subshell are spawned, we have only new shells. .   From \"man bash\" (4.2.45(1)-release) I report some pertinent parts about when a subshell is spawned:  .   Each command in a pipeline is executed as a separate process (i.e., in a subshell). .  If a command is terminated by the control operator &, the shell executes the command in the background in a subshell. The shell does not wait for the command to finish, and the return status is 0. .  Commands separated by a ; are executed sequentially; the shell waits for each command to terminate in turn. The return status is the exit status of the last command executed. ... .  ( list ) list is executed in a subshell environment { list; } list is simply executed in the current shell environment. .  A coprocess is a shell command preceded by the coproc reserved word. A coprocess is executed asynchronously in a subshell... .  $ Expands to the process ID of the shell. In a () subshell, it expands to the process ID of the current shell, not the subshell. .   Notes:  .   \"BASHPID\" Expands to the process ID of the current bash process. This differs from \"$$\" under certain circumstances, such as subshells that do not require bash to be re-initialized.  \"BASH_SUBSHELL\" Incremented by one each time a subshell or subshell environment is spawned. The initial value is 0.  .  For the differences between the use of single quote \"''\" an double quote \"\"\"\" you can see this question. Let we remember only that if you write the commands within double quote\"\"\"\" the variables will be evaluated via parameter expansion from the original shell, if extquote is enabled as it is by default from \"shopt\".(cfr. 4.3.2 The shopt builtin in the Bash Reference Manual)  .   \"*extquote*\" If set, $'string' and $\"string\" quoting is performed within ${parameter} expansions enclosed in double quotes. This option is enabled by default. .    For further references you may find useful e.g.  .   \"man bash\". The section \"Shell Expansions\" of the bash manual.  The double quote section or  the Parameter Expansion of Shell Command Language as defined in The Open Group Base Specifications Issue 6 IEEE Std 1003.1, 2004 Edition.  ",
      "P-tags": "command-lin bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V when S"
    },
    {
      "id": "so_21249419",
      "task": "How do I programatically detect if my laptop is plugged in or not? (osx)",
      "P-task": "programat detect laptop plug\nosx",
      "F_verb": "detect",
      "P-body": "You could use \"pmset\": .   \"-g\" ps / batt displays status of batteries and UPSs. .   Saying: .  would tell you if the laptop is running on AC power or using battery power. .  To translate into a condition, something like the following should work: .  ",
      "P-tags": "shell maco",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "au_637003",
      "task": "Delete lines between 2 strings",
      "P-task": "delet line 2 string",
      "F_verb": "delete",
      "P-body": "Using \"sed\": .   \"< inputfile\": redirects the content of \"inputfile\" to \"sed\"'s \"stdin\" \"> outputfile\": redirects the content of \"sed\"'s \"stdout\" to \"outputfile\"  \"sed\" command breakdown: .   \"1,/::=/d\": deletes all the lines between the first one and the first one matching the \"::=\" regex inclusive   Using \"awk\": .   \"< inputfile\": redirects the content of \"inputfile\" to \"sed\"'s \"stdin\" \"> outputfile\": redirects the content of \"sed\"'s \"stdout\" to \"outputfile\"  \"awk\" command breakdown: .   \"NR==1,/::=/ {next}\": skips the record if between the first one and the first one matching the \"::=\" regex inclusive \"{print}\": prints the record   Using Perl: .   \"-0777\": slurps the whole file at once instead of one line at the time \"-p\": places a \"while (<>) {[...]}\" loop around the script and prints the processed file \"-e\": reads the script from the arguments  Perl command breakdown: .   \"s\": asserts to perform a substitution \"/\": starts the pattern \"^(.*\\n)*?::=.*\\n\": matches any character zero or more times at the start of the file greedily within the current line (i.e. the (\".\") pattern will be matched the most times as possible within the current line) and a newline, zero or more times lazily within the current file (i.e. the \"(.*\\n)\" pattern will be matched the least times as possible within the current file) before a \"::=\" string, matching then any character zero or more times greedily within the current line and a newline \"/\": stops the pattern / starts the replacement string \"/\": stops the replacement string / starts the modifiers  ",
      "P-tags": "awk grep command-lin bash sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP between NP"
    },
    {
      "id": "so_22357418",
      "task": "Less dimwitted shell required",
      "P-task": "less dimwit shell requir",
      "F_verb": "require",
      "P-body": "Original Bourne supported \"^\" as the pipe operator. This was dropped in the Korn shell (from which the POSIX sh spec derived), and is thus a feature available in Bourne but not in POSIX sh. .  Thus, this code tests for pre-POSIX Bourne shells. .  ",
      "P-tags": "linux ubuntu sh shell",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V"
    },
    {
      "id": "so_6760099",
      "task": "Zip - Add files and folders that are newer, remove old ones",
      "P-task": "zip - add file folder newer remov old one",
      "F_verb": "add",
      "P-body": "I would suggest you use \"java.util.zip\" instead of 7zip if you really want to do this in Java. .  A better solution might be to do \"7z -u\" and then play around with the options. .  http://sevenzip.sourceforge.jp/chm/cmdline/switches/update.htm .  ",
      "P-tags": "7zip linux pseudocod java window",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP that S"
    },
    {
      "id": "so_42916500",
      "task": "\\1 not defined in the RE",
      "P-task": "1 defin",
      "F_verb": "define",
      "P-body": "Backslash followed by a number is replaced with the match for the Nth capture group in the regexp, but your regexp has no capture groups. .  If you want to replace the entire match, use \"&\": .  You don't need to use \".+\" to find non-empty lines -- the fact that it has a character at the beginning that doesn't match \"#\" means it's not empty. And you don't need \"+\" after \"[^#]\" -- all you care is that the first character isn't \"#\". You also don't need the \"g\" modifier when the regexp matches the entire line -- that's only needed to replace multiple matches per line. .  And since your replacement string contains \"/\", you need to either escape it or change the delimiter to some other character. .  ",
      "P-tags": "bash sed regex",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V in NP"
    },
    {
      "id": "so_29978076",
      "task": "Networking in C ; does bind() need its argument alive?",
      "P-task": "network c bind need argument aliv",
      "F_verb": "bind",
      "P-body": "No, it does not. The contents of the \"address\" parameter are copied by the kernel; you can reuse or free that memory as soon as the call returns. .  In fact, it's possible to make a more general statement here: unless the documentation specifically says otherwise, arguments passed to the kernel by pointer reference only need to be kept 'alive' for the duration of the system call. Their values will be copied by the kernel if needed. .  ",
      "P-tags": "linux c socket",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP"
    },
    {
      "id": "so_14480591",
      "task": "get virtual memory size of process in AIX in program",
      "P-task": "get virtual memori size process aix program",
      "F_verb": "get",
      "P-body": "I have found partially solution that is suitable for me. .  I ran small test app and see that \"pi_dvm\", the member of \"procentry64\" structure, will increase if we allocate memory on stack (for example: \"char arr[1024];\") for size of allocated object and some overhead. Noiw, we want to calculate used heap size. We should use \"mallinfo()\" function from \"malloc.h\" that returns \"mallinfo\" struct. We are interested in two fields of \"mallinfo\" structure: \"usmblks\" and \"uordblks\" (about this fields you could read here). Some example code: .  P.S. I don't know Why we sum \"pi_tsize\" (if anybody knows, please tell us). I get this idea from pg_top sources, but there is a bug, they multiply \"pi_tsize\" by 4, but it's incorrect, because \"pi_tsize\" is in bytes. I hope this solution may help someone :) .  ",
      "P-tags": "unix virtual-memori aix c++ c",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_523106",
      "task": "Does using plughw plugin in ALSA introduce latency?",
      "P-task": "use plughw plugin alsa introduc latenc",
      "F_verb": "use",
      "P-body": "These conversions involve some CPU processing, but it's done in real time when the samples are written to the buffer, so the latency is not affected by any noticeable amount. .  Only the \"dmix\" plugin can delay samples, but it is not one of the plugins selected by \"plug\". .  ",
      "P-tags": "audio linux alsa",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "au_281323",
      "task": "When mounting a foreign filesystem how does Ubuntu match up users?",
      "P-task": "mount foreign filesystem ubuntu match user",
      "F_verb": "mount",
      "P-body": "Permissions are granted based on the user ID in /etc/password. The names are just a convenience. BTW, that is also the way it is done on windows). .  Example:  .  Local system 'A' had a disk with this setup: .  Files created by Joe get user ID 500. .  Now I move that disk to system 'B' System B has two users: .  Files which were owned by user 500 (Joe) on system 'A' will now be accesable by user 500 on system 'B'. The owner will be listed as 'Janette' .  This is the main reason why people keep their UIDs the same on all systems they log into. Esp. when NFS is involved. .   (To be complete: Fles owner by 'Jane' will now show up as owned by 'slartibartfast', and files owned by 'Job' will just be listed by ID 502, since there is not matching name.) .  If you like an analogy, think of uids as social security numbers. Your name can change (e.g. when you marry), but that number will always be the same. .   .  [Edited a bit to answer the questions directly] .   If I mount a filesystem that's been part of another Ubuntu installation (systemB let's call it) how does my system (systemA) work out permissions? .   The system works out permission by checking if the active user has rights on the file, or if the active user is in a group which has rights on that file. Everywhere I wrote active user you need to realise that the user is just a number. The ID). And this ignores extra restrictions set by SE-Linux. .   Specifically: Does userA on my system get access to userA's files in the foreign filesystem from systemB just because they have the same name? .   No. Only if they have the same uid. .   Must the passwords match?  .   No password checking it done when you access file. You authenticate once (when you log in). Afterward you have rights on files which you own or which are in the same groups you are in. .   That implies to me that the filesystem must store user+password together somewhere so they can travel with the filesystem. .   No password checking is done on accessing files, so this is not relevant. .   What happens if there is a userB on systemB and no matching user on my system? .   If there is no user with the same uid then it is not possible to translate the uid to a name. Thus the raw numeric value is show. .   Who can access his files from systemA? Can root? .   Every user with the same uid, or with uid 0. .  ",
      "P-tags": "filesystem",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_862063",
      "task": "tar does not create backup",
      "P-task": "tar creat backup",
      "F_verb": "create",
      "P-body": "You are getting the error because you are asking it to archive /mnt, and then telling it to exclude /mnt with the option \"--exclude=/mnt\" which excludes everything, hence there is nothing in the archive and you get the error message. .  If i understand what you are doing correctly, you should drop the \"--exclude=/mnt\" option. .  ",
      "P-tags": "tar lvm backup",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_14678709",
      "task": "How usecs_to_jiffies transforms usecs to jiffies if jiffies are in resolution of msecs?",
      "P-task": "usecs_to_jiffi transform usec jiffi jiffi resolut msec",
      "F_verb": "transform",
      "P-body": "When in doubt, read the code! .  Here it is (a version of it can be found here): .  So, it does some stuff to check if there is a shortcut, and if nothing else works, figures it out with some 64-bit math. .  But 5usec will be one jiffies, no matter which bit of code it runs. .  ",
      "P-tags": "linux c linux-kernel timer",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP if S"
    },
    {
      "id": "au_1023436",
      "task": "How to recover ext4 partition deleted by WinXP?",
      "P-task": "recov ext4 partit delet winxp",
      "F_verb": "recover",
      "P-body": "I didn't know, deleting one partition could delete several partitions at once (till now)! .  I ran \"sudo mke2fs -n /dev/sdb5\" and the whole procedure as described in HOWTO: Repair a broken Ext4 Superblock in Ubuntu several times with reboot, but that did NOT help. .  The following section of the guide actualy helped me to solve my issue: TestDisk Step By Step - A partition is still missing: Deeper Search .   I ran deep scan / search again using \"TestDisk\" and this time (not sure what I've missed when I ran it the first time) it gave another output. Highlighting the partition and pressing the \"p\" button on my keyboard I've managed to find all the partitions that contained files. \"Linux Swap\" obviously doesn't contain any files, but has to be included too. Changing \"D\" to \"L\" (or \"P\") includes the partition.  The end result looked like this: .   Writing changes and rebooting got everything back again.  ",
      "P-tags": "partit data-recoveri debian",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP by NP"
    },
    {
      "id": "so_33112608",
      "task": "Get remaining disk space from df's output",
      "P-task": "get remain disk space df output",
      "F_verb": "get",
      "P-body": "use \"grep\" to take only the /home line, and \"awk\" to get only the field you want: .  ",
      "P-tags": "diskspac unix shell linux-disk-fre",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_27822108",
      "task": "Importing my own classes when compiling and running Java file on Windows powershell",
      "P-task": "import class compil run java file window powershel",
      "F_verb": "compile",
      "P-body": "I finally could compile it. All the directories and package names were, right, what I needed to do was to use the following command from my root directory: .  and then, to run: .  Thanks for the ones who tried to help! .  ",
      "P-tags": "powershel noclassdeffounderror java",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V on NP"
    },
    {
      "id": "su_834672",
      "task": "Linux: not able to see all options for `tree` command",
      "P-task": "linux : abl see option tree command",
      "F_verb": "see",
      "P-body": "I don't have the reputation to comment, so I'll put this here.  .  It almost looks like the \"tree\" command is aliased to \"sed\" on your machine. When I run \"tree -C\" on my machine, I get the expected behavior. When I run \"sed -C\" on my computer, I get the exact same output that you get when you run \"tree -C\".  .  Is there any entry in your \"~/.bashrc\" file that defines an alias like that? .  ",
      "P-tags": "tree linux command-lin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP for NP"
    },
    {
      "id": "au_631163",
      "task": "Can't compile a simple C++ program using g++",
      "P-task": "compil simpl c++ program use g++",
      "F_verb": "compile",
      "P-body": "It looks like (at least) file \"/usr/include/x86_64-linux-gnu/bits/byteswap.h\" have been somehow corrupted. Open it with a text editor and check whether it looks like a normal C++ header file. .  If this is the case reinstall package libc6-dev with the command \"sudo apt-get --reinstall install libc6-dev\" .  If this is not the case you will need to post here the full content of file post_test_5.cpp as well as the full output of the compilation. .  ",
      "P-tags": "14 04 c++ compil g++",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_565366",
      "task": "Grep to match the pattern exactly",
      "P-task": "grep match pattern exactli",
      "F_verb": "match",
      "P-body": "The issue is that with the (non-standard) option \"-w\", \"grep\" will require a word boundary before and after the pattern. A \"word boundary\" is a transition between a word and a non-word. A \"word\" is a string that contains word characters, like \"a\", \"b\", etc., while a non-word is a string that contains characters like space, \"/\", \"?\", etc. .  Since \"/\" is not a \"word character\", there can be no word boundary before it (unless it is immediately preceded by a word character). Some versions of \"grep\" would therefore not be able to match the string in your data, ever. Other versions would be able to perform the match. .  Since you seem to want to match the path on a line where it is immediately preceded \"# file:\u00a0\", and since we know that the path is followed by \"\u00a0# owner:\" on the same line, we can use these strings as delimiters for the given path: .  ",
      "P-tags": "grep",
      "source": "qa",
      "cate": "match",
      "pat": "V NP"
    },
    {
      "id": "so_40069516",
      "task": "Shell that reads line by line",
      "P-task": "shell read line line",
      "F_verb": "read",
      "P-body": "After the line  .  there remains a \"newline\" in the input buffer, and this is read by the line .  Although the format \"%d\" (and most formats) ignore any leading whitespace in the input buffer, \"%c\" does not, unless you insert a \"space\" like this: .  ",
      "P-tags": "array fget scanf shell c",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP by NP"
    },
    {
      "id": "ul_151659",
      "task": "Compile source with later libraries on one server and use the binary on an older server",
      "P-task": "compil sourc later librari one server use binari older server",
      "F_verb": "compile",
      "P-body": "If the program requires newer features that aren't available on your server, then those features won't be available at runtime and so your program probably won't run. .  You can link the library statically. This has the downside that you can't upgrade the library separately from the program. If a security vulnerability is found in that version of the library, you'll need to rebuild the program. Replace \"-lpcre3\" in the linker command line by \"/usr/lib/libpcre3.a\". .  You can link dynamically and copy the library to the same directory where you install your software. Start the software through a wrapper script that sets the library load path to include that additional directory. .  ",
      "P-tags": "ubuntu compil software-instal",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "au_545655",
      "task": "Backup your home directory with rsync and skip useless folders",
      "P-task": "backup home directori rsync skip useless folder",
      "F_verb": "skip",
      "P-body": "The exclude list may only contain filenames, foldernames and lines starting with \"#\". A comment behind the foldername is not allowed. I created a Git repository with all known files and folders that are superfluous: .  Download this ignorelist to /var/tmp/ignorelist .  Then start the rsync with .  Note: In the ignorelist there is a commented section at the start with folders, that are probably not worth a backup either. Uncomment those, you don't need. .  ",
      "P-tags": "rsync backup",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP"
    },
    {
      "id": "so_15433774",
      "task": "Hidapi unable to compile any code under ubuntu",
      "P-task": "hidapi unabl compil code ubuntu",
      "F_verb": "compile",
      "P-body": "Those are linker errors : .   collect2: ld returned 1 exit status .   I initially thought that you were not linking your code with the hidapi library, but the only way I accidentally managed to reproduce the exact errors you had was by putting the gcc parameters in the wrong order. This fails with the same output : .  Your object file needs to appear before the library in the gcc arguments for the linking stage. .  The following works just fine : .  Note that I have to use -I, -L and LD_LIBRARY_PATH because I did not install hidapi, I did everything from the hidapi source folder. .  ",
      "P-tags": "hidapi c++ linux ubuntu",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP under NP"
    },
    {
      "id": "ul_52887",
      "task": "Can I start my main desktop graphical session remotely?",
      "P-task": "start main desktop graphic session remot",
      "F_verb": "start",
      "P-body": "You can start a console GUI session remotely: run \"startx\". However, that's likely not to work because you'll lack the permission. On most setups, only the user physically logged in on the console is allowed to use the console. .  Different distributions have adopted different mechanisms to control who can start an X session on the console. I believe that on RHEL this is done through systemd, but I don't know how. .  If you start an X application on the console display, you won't be able to interact with it remotely. There are a few exceptions such as Emacs that are capable of connecting to multiple displays, but in general X applications open a connection to the X display when they start and never look back. You can use Xmove or Xpra to mediate between the X server and the application; an X application started inside Xmove or Xpra can be moved to a different X server (like detaching and attaching a screen session). .  Another option once you've started the console X session would be to interact with it remotely. You can use X11vnc for that, and access the remote session with a VNC client. .  ",
      "P-tags": "rhel remot x11 consol",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_53699165",
      "task": "Visual Studio C++ program cannot find the include folder even when specified",
      "P-task": "visual studio c++ program find includ folder even specifi",
      "F_verb": "find",
      "P-body": "That's because you've written \"#include <someFile.h>\". What you should've done is use \"#include \"someFile.h\"\". .  When using <> you tell the compiler to search its own directory for includes. When using \"\" you are telling the compiler to search the specified include path. .  Edited for clarity: Simply specify the -I flag for gcc with your include folder. For you it would be something like this \"g++ -I include -g mains/SimpleMCMain1.cpp -o SimpleMCMain1.out && clear && ./SimpleMCMain1.out\" .  ",
      "P-tags": "visual-studio-cod ubuntu header-fil c++ include-path",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP when S"
    },
    {
      "id": "so_36999322",
      "task": "User in sudoers doesn't have write permissions",
      "P-task": "user sudoer write permiss",
      "F_verb": "write",
      "P-body": "This fails because current shell is doing the redirection not \"echo\". Since current user doesn't have permission to write to the file \"/etc/hosts\" hence \" permission denied error\". Do this way: .  ",
      "P-tags": "linux permiss",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_34611795",
      "task": "Mac air: IOError: [Errno 13] Permission denied",
      "P-task": "mac air : ioerror : errno 13 permiss deni",
      "F_verb": "deny",
      "P-body": "Run your command with \"sudo\" for elevated privileges. Run: .  in order to execute your previous command (that caused the error) with \"sudo\". .  Alternatively you can use \"sudo chown -R $USER /Library/Python\" (or \"/var/log\" if you wish). If all fails (very unlikely), try \"sudo chmod -R +xw /var/log/\". .  ",
      "P-tags": "linux unix",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "ul_482569",
      "task": "Debian 10 Buster | update-grub | command not found",
      "P-task": "debian 10 buster update-grub command found",
      "F_verb": "update",
      "P-body": "Solutions (best ones first)  \"su - root\" instead of \"su root\" - nicest solution (thanks to Rui) extend path of the regular user in /etc/enviroment or ~/.bashrc or similar config file call commands explicitly; using this solution would require that one modifies all scripts that happens to call another command from sbin (this is not practical, nevertheless there is an example of it in the troubleshooting section)  Findings This happened because the PATH works in a really strange way (actually works as designed). .   \"regular user login\" -> environment PATH doesn't contain /usr/sbin => opinion: works as designed, quite logical \"su root\" -> admin rights, but the environment is lacking /usr/sbin:/sbin => opinion: works as designed, but illogical, because an account with root level of access should be able to execute commands from sbin without adding the path to the binaries manually \"su - root\" -> admin rights, /usr/sbin on the path => opinion: works as designed, quite logical  Some more background .  There are two PATH defined in /etc/login.defs, but unless I start \"su -\" or \"su - root\", I'm going to get the ENV_PATH. I know that this has been designed this way, to keep the environment of the actual user, but in this single case, it really boggles my mind, why not add automatically \"/usr/sbin\" and \"/sbin\" to thew path of a \"regular user\" after a successful \"su root\" .   Troubleshooting I've found that there is an \"update-grub\" command in \"/usr/sbin\". .  Ran it, just to get the next error message. .  Searched for \"grub-mkconfig\" and found it under \"/usr/sbin/grub-mkconfig\". Then it came to me, let's see how the \"update-grub\" script looks like? .  Modified /usr/sbin/update-grub in order to call \"grub-mkconfig\" by it's explicit path ... .  ... then called \"update-grub\" with it's explicit path and tada, it worked! .  Conclusion .  This must be something about the PATH .  ",
      "P-tags": "grub debian",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "ul_664714",
      "task": "Ubuntu 20.04.x errors using CIS Ensure loopback traffic is configured UFW security configuration",
      "P-task": "ubuntu 20 04 x error use ci ensur loopback traffic configur ufw secur configur",
      "F_verb": "ensure",
      "P-body": "Your tutorial has an error. .  From man page: .   \"ufw [--dry-run] [rule] [delete] [insert NUM] allow|deny|reject|limit [in|out\"\"[on INTERFACE]\"\"]\" \"[log|log-all] [proto PROTOCOL]\"\"[from ADDRESS\"\"[port PORT | app APPNAME ]] [to ADDRESS [port PORT | app APPNAME ]] [comment COMMENT]\" .   Use: .  ",
      "P-tags": "secur linux ubuntu network ufw",
      "source": "qa",
      "cate": "confirm/ensure",
      "pat": "V NP"
    },
    {
      "id": "so_40081053",
      "task": "What does a ELF64 File look like?",
      "P-task": "elf64 file look like",
      "F_verb": "look",
      "P-body": "If you want to see the entire structure of your executable try: .  and if you want to see your file in hex format do: .  or .   can i directly write a linked file in plain-text? .   Well... Theoretically you can if you know exactly the instructions of the executable and you write them in binary to a plaintext file. .  For example, for any given executable exe_file you can do this: .  The plaintext_file will be an executable exactly the same as your exe_file. If between steps 2 and 3 you modify the temp_file you are directly modifying the executable by hand, although it is not very likely to change something \"specific\", unless you have very deep understanding of elf64 format (which I don't and I'm not sure what can be achieved with this). .  Note: I know step 1 is redundant, I used it for demonstrating that you are starting with 2 simple plaintext files. .  ",
      "P-tags": "linux compiler-construct assembl 64-bit elf",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_37054597",
      "task": "What is the most efficient way to find rows of a CSV not containing duplicate entries across the fields of that row (excluding blank entires)?",
      "P-task": "effici way find row csv contain duplic entri across field row exclud blank entir",
      "F_verb": "find",
      "P-body": "Using \"perl\": .  Uses: .   \"-F,\" to set field separator to \",\" \"-l\" to automatically handle linefeeds \"-a\" to autosplit \"-n\" to wrap it in a \"while ( <> ) {\" loop.  \"-e\" to specify code to exec.   Incoming data is autosplit on \",\" into \"@F\" and we use a \"%s\" hash to spot if there's a dupe.  .  If \u2014 based on your comment \u2014 you need to skip empty fields (which this would count as dupes): .  This includes a ternary operator to test if a field is empty.  .  Testing with Windows (which isn't quite the same, because of quotes): .  If written longhand, it looks more like this: .  You could use the \"Text::CSV\" module to parse it, but I would suggest not doing so, unless you're specifically dealing with quoting/embedded linefeeds etc.  .  E.g.: .  ",
      "P-tags": "awk csv python perl bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP across NP of NP"
    },
    {
      "id": "su_695357",
      "task": "updating Touchegg to latest version",
      "P-task": "updat touchegg latest version",
      "F_verb": "update",
      "P-body": "It is saying you are missing a library called libgeis.so. You should first of all search your system to check whether you do have such a library, somewhere in your system: .  If you cannot find it, then you should install a package called libgeis-dev,  .  which should install the library in /usr/lib/x86_64-linux-gnu/libgeis.so, or likewise for i686. If it still cannot find it, you should learn how to teach your compiler/loader to search for libraries in non-standard directories. Should you really feel lazy, this: .  will do it for you (careful if you have a 32bit system). .  ",
      "P-tags": "touchpad linux ubuntu",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_322900",
      "task": "Is it possible to write to the crontab from a multipurpose script?",
      "P-task": "possibl write crontab multipurpos script",
      "F_verb": "write",
      "P-body": "Per Ipor Sircer's answer about the usage of \"cron\", i.e. .   man crontab: .   this means that you send the lines you want in your crontab file, to the stdin of this command:  .  \"crontab\" will recreate a new cron file containing those commands. .   The script will first print your existing crontab using \"crontab -u $user -l 2>/dev/null\". you will need to assign the value of your user to \"$user\" or use \"$USER\" if its in your environment. .  It will print the new lines you want and capture the aggregated result into a pipe connected to stdin of \"crontab -\". .    Here's how it should look like in your general-purpose script: .  ",
      "P-tags": "cron shell-script",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP from NP"
    },
    {
      "id": "so_68952749",
      "task": "I can't install pychecker on my ubuntu 21.04",
      "P-task": "instal pycheck ubuntu 21 04",
      "F_verb": "install",
      "P-body": "\"pychecker\" is no longer included as a package in Ubuntu and Debian because it is unmaintained: the latest version is from 2011, and that version will not work with current versions of Python. From here: .   Please consider moving away from Pychecker in favor of an alternative like Pylint [1]. Pychecker is basically unmaintained upstream. Also, it is only supported for Python 2, so it will reach its end of life along with Python 2 sometime in 2020. .  ... .  Now is the time to convert. Pylint does everything that Pychecker used to do. The main effort required is to create your new configuration file and weed out warnings that you want to ignore. .  [1] https://www.pylint.org/ .   Other alternatives include flake8. .  ",
      "P-tags": "python-3 x ubuntu python pycheck ubuntu-21 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_36579401",
      "task": "Execute a RESTAPI request from Powershell using the credentials of the user logged into the windows machine(AD Credential's)",
      "P-task": "execut restapi request powershel use credenti user log window machin ad credenti",
      "F_verb": "execute",
      "P-body": "Try using WebClient class: .  The main thing here is to set \"UseDefaultCredentials\" property of \"WebClient\" to \"true\". Method \"DownloadString\" is just an example of how to use \"WebClient\". There are plenty of other methods which you can use depending on your REST endpoint. You can find full list here. .  ",
      "P-tags": "single-sign-on active-directori rest powershell-4 0",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP using NP of NP into NP"
    },
    {
      "id": "so_11145561",
      "task": "Alias to open git conflicts in textmate",
      "P-task": "alia open git conflict textmat",
      "F_verb": "open",
      "P-body": "You can try  .  where \"textmate\" is your command to run TextMate. .  ",
      "P-tags": "git textmat alia bash",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_595042",
      "task": "CentOS 7.7 not able to upgrade docker-ce latest package",
      "P-task": "cento 7 7 abl upgrad docker-c latest packag",
      "F_verb": "upgrade",
      "P-body": "I found /etc/yum.conf file had exclude list for docker package. I used this command to install the package .  \"yum --disablerepo=* --enablerepo=docker-ce-stable upgrade --disableexcludes=all docker-ce\" .  Thanks .  ",
      "P-tags": "cento yum docker",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_42627603",
      "task": "Yocto/Qt5.6: Unable to build a sample Qt Application",
      "P-task": "yocto qt5 6 : unabl build sampl qt applic",
      "F_verb": "build",
      "P-body": "The mkspec pointed to by your kit seem to be the wrong one (\"linux-g++\"), quoting from your build log .  When building for a nitrogen6x, it should likely be \"linux-oe-g++\" instead. This is either set by default in the Qt version you selected, or can be set by modifying the Kit itself, in QtCreator's options, under \"mkspec\". .  The error your's seeing is probably due to the fact the that the ABI & architecture of the libraries pointed are not compatible with the x86/64 code you compiled. .  Also make sure to source Yocto's environment file before starting QtCreator if you encounter problems (namely compile error about \"C\" not found). This will setup the path to the cross-compiler. Example: .  ",
      "P-tags": "linux qt5 qt yocto",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_53855038",
      "task": "Create a hash with multiple values from 2 arrays in powershell",
      "P-task": "creat hash multipl valu 2 array powershel",
      "F_verb": "create",
      "P-body": "Use the modulo operator (\"%\") to \"wrap around\" at the end any value that exceeds the length of the smallest array: .  ",
      "P-tags": "powershel data-partit",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP from NP in NP"
    },
    {
      "id": "so_32675717",
      "task": "Rename all the files in the directory, increasing part of the filename by 1",
      "P-task": "renam file directori increas part filenam 1",
      "F_verb": "rename",
      "P-body": "rename.sh .  output .  ",
      "P-tags": "renam linux bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_22250445",
      "task": "get X11 window id of terminal from shell",
      "P-task": "get x11 window id termin shell",
      "F_verb": "get",
      "P-body": "I know very little of X11, but running the \"env\" command in my terminal, I spotted an environment variable \"WINDOWID\", that shows the same number in different tabs of the same terminal, but a different number in another terminal. Perhaps that's what you need? .  It does appear to be an \"Xterm\" thing (and probably any terminal that mimicks \"Xterm\"s behaviour. The \"xterm(1)\" man page only says: .   ENVIRONMENT .   Some other possibly relevant questions with answers: .   https://unix.stackexchange.com/questions/3197/how-to-identify-which-xterm-a-shell-or-process-is-running-in .  Get X window id from process in bash .   ",
      "P-tags": "x11 shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "su_1267172",
      "task": "LUKS - Detached header - where is encryption key stored?",
      "P-task": "luk - detach header - encrypt key store",
      "F_verb": "detach",
      "P-body": "I'm quite sure the actual keys are stored in the kernel's keyring, where they're stored safely & isolated from other users. At least as safe as anything on the computer, a user/process with root access can read anything too). .  The mapper knows where the device is & how big it is, and the key. You can see general parameters with \"losetup\" and \"cryptsetup status\", and attempt to see the kernel keyring with \"keyctl\". .  You don't really need the header again unless you want to add/delete/edit a key. I doubt you'd need the header again to close the device, since \"closing\" it just forgets the key & stops decrypting it. .  ",
      "P-tags": "linux encrypt luk dm-crypt",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_330439",
      "task": "How do I install and use Galera and MariaDB 10.1 on RHEL or CentOS with SELinux Enabled",
      "P-task": "instal use galera mariadb 10 1 rhel cento selinux enabl",
      "F_verb": "use",
      "P-body": "Assumptions  You are not using RHEL 7 SCL (software collections) or rh-mariadb101{,-galera} You have RHEL 7 / CentOS 7 servers with EPEL already installed SELinux is required, running, and enforcing Firewalld is running and blocks by default Your 3 host IPs are 1.2.3.4, 1.2.3.5, and 1.2.3.6  Firewall Configuration The ports required for Galera & MariaDB to function properly are TCP ports 4444, 4567, and 4568 and UDP port 4567. MariaDB requires TCP port 3306. In this configuration we assume hosts 1.2.3.4, 1.2.3.5, and 1.2.3.6 are permitted to be part of the cluster, as well as a future host IP 1.2.3.7. This configuration also assumes any host is allowed to connect on port 3306. Login and \"su -\" to root. Run the following commands. .  SELinux Policy Preparation Login and \"su -\" to root. Run or perform the following steps. The last line is only required for a non-default data location. Note that if you set a data location within \"/home\" or \"/usr\" systemd will prohibit MariaDB from writing and MariaDB will fail. To work around this, set \"ProtectSystem=false\" in the unit file \"/lib/systemd/system/mariadb.service\". Then run \"systemctl daemon-reload\". .  MariaDB Repository Addition, Package Installation, Configuration Download https://yum.mariadb.org/RPM-GPG-KEY-MariaDB. Ensure that web server giving you this key is trustworthy; the security of your new repository depends on this. .  Once you\u2019ve got the packages installed, you must configure MariaDB per normal procedure before creating the cluster. The first line below is only necessary if you wish to use a different data location from the default. .  Check to see if MariaDB + Galera is running. If so, you can configure the next two hosts. Install the SELinux rules and software packages as before, but immediately add the following lines to the [galera] section in /etc/my.cnf.d/server.cnf. Assumes the original galera server\u2019s IP is 1.2.3.4 and its peers will be 1.2.3.5 and 1.2.3.6. Set the cache size to something appropriate for your systems. .  At this point, logs should indicate that data has replicated from the first server to the current server. Repeat these steps on the remaining server(s).  .  Now stop MariaDB on the original server and add the galera configuration to \"/etc/my.cnf.d/server.cnf\". Restart MariaDB on the original server. Verify that data is synchronizing between the peers. .  Enable TLS This optional section assumes that you have already generated an X.509v3 certificate and corresponding private key. Both the certificate and key should be stored in unencrypted PEM format. For this example the filenames are assumed to be \"server.crt\" and \"server.key\" respectively. .  Add the following lines into \"/etc/my.cnf.d/server.cnf\" in the \"[mysqld]\" section: ssl_cert=/etc/pki/tls/certs/server.crt ssl_key=/etc/pki/tls/private/server.key .  Create \"/etc/systemd/system/mariadb.service.d/TLS.conf\" with the following content: .  Systemd is as systemd does, so run \"systemctl daemon-reload\" again to read the new configuration. .  Server restart is required in order for MariaDB to accept TLS connections. Note that TLS is available, but not required at this stage of configuration. .  Check the logs to verify that MariaDB loaded with TLS enabled: \"journalctl _SYSTEMD_UNIT=mariadb.service\". Failure to start TLS is only logged as a [Warning] :^( .  This is my first pass at this. I'll be happy to incorporate improvements :^) .  ",
      "P-tags": "mariadb rhel selinux ssl cento",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP with NP"
    },
    {
      "id": "ul_438822",
      "task": "Recovering lost information",
      "P-task": "recov lost inform",
      "F_verb": "recover",
      "P-body": "What's happened here is that you don't have \"/dev/sdc1\", which contains half of the volume group \"VG\". Without it you cannot activate \"VG\", which in turn means you cannot access the logical volume \"LV\". .  Currently you no access to any of your data on \"VG/LV\". It might be stored on the missing disk, or you might be lucky and enough of it might be on the disk that's present. .  Non-invasive steps I would recommend you take: .   Power off your system. Carefully check all the connectors for disk \"/dev/sdc\" to ensure it is fully connected. Restart. Run \"fdisk -l /dev/sdc\" to see if the partition even exists. Look in \"/etc/lvm/lvm.conf\" to see if there's a filter blocking access to your \"/dev/sdc1\". Ignore all lines beginning with \"#\". None of the rest should have a keyword that mentions \"filter\".  Invasive steps I would not recommend you take unless everything else has failed: .   Run \"vgchange -ay /dev/VG --activationmode partial\" .  THIS \u2191 \u2191 MAY DESTROY YOUR DATA. On the other hand it may let you recover it. .  Run \"mount -o ro,noload /dev/VG/LV /HFT\" to mount what filesystem it can find and see if any of the data is present. If it is, copy it to a safe place and rebuild your LVM volume group. The mount is read-only so you won't be able to change anything in the LV. .    As an aside, if you have important data there are two things you can do to mitigate its potential loss .   Take regular automated backups. Preferably to a separate location. I use a cloud storage provider.) Use RAID 1 to mirror data across two same-sized disks. You'll need 2x 3TB disks to store 3TB data but it's worth it. Really it is. You can do this either using the \"mdadm\" RAID toolset or directly in LVM.  ",
      "P-tags": "ubuntu storag lvm",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP"
    },
    {
      "id": "so_50980516",
      "task": "Shell script for post-commit hook gives - Not a git repository error",
      "P-task": "shell script post-commit hook give - git repositori error",
      "F_verb": "commit",
      "P-body": "Just to be sure, set \"GIT_DIR\" and \"GIT_WORK_TREE\" environment variables in order to be sure any \"git\" command runs in the right context: .  ",
      "P-tags": "virtualenv git githook shell",
      "source": "qa",
      "cate": "commit/submit/upload",
      "pat": "V"
    },
    {
      "id": "au_55325",
      "task": "How to use \"grep\" command to find text including subdirectories",
      "P-task": "use grep command find text includ subdirectori",
      "F_verb": "use",
      "P-body": "It would be better to use  .  where  .   \"-r\" (or \"--recursive\") option is used to traverse also all sub-directories of \"/path\", whereas  \"-l\" (or \"--files-with-matches\") option is used to only print filenames of matching files, and not the matching lines (this could also improve the speed, given that \"grep\" stop reading a file at first match with this option).  ",
      "P-tags": "grep command-lin",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_42687366",
      "task": "WebSocket client can't connect to cloud server through corporate proxy except for web browsers! (ETIMEDOUT)",
      "P-task": "websocket client connect cloud server corpor proxi except web browser\netimedout",
      "F_verb": "connect",
      "P-body": "node does not automatically use any form of configuration for making HTTP requests through proxies -- ie, node does not read the \"PROXY\" or \"HTTPS_PROXY\" environment variables. \"npm config set proxy\" only affects npm itself. .  In other words, node programs always try to access servers directly. It appears your network requires HTTP requests to go through a proxy, and direct connections are being silently dropped. .  If you want your program to make HTTP requests through proxies, you must do so manually. The http-proxy-agent module can help you do this. .  ",
      "P-tags": "javascript linux websocket node js proxi",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP through NP for NP"
    },
    {
      "id": "so_21679369",
      "task": "RunOnce to rename a Computername with a random name on reboot",
      "P-task": "runonc renam computernam random name reboot",
      "F_verb": "rename",
      "P-body": "You can generate a random name using the Get-Random cmdlet.  .  You can change a computer name with the cmdlet Rename-Computer. And to set it to run once, the easiest way would be to add an entry to the registry key  .  that will invoke PowerShell with your script. .  ",
      "P-tags": "runonc hostnam batch-fil powershel window",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "so_15657393",
      "task": "bash file renaming adding string in a specific location",
      "P-task": "bash file renam ad string specif locat",
      "F_verb": "add",
      "P-body": "if i understand you wish to change any \"hell.*_NNN.txt\" to \"hel.*o_NNN.txt\" (keeping the .* between \"hell\" and \"_NNN.txt\" (NNN being any number).  .  then:  .  I added the LC_COLLATE=C during sed invocation so you can rely on the \"[0-9]\" matching only digits '0' or '1' or ... or '9'  .  (If you wonder why adding the LC_COLLATE: with some locales \"[A-Z]\" could match every letters A-Z or a-y (except 'z'!) as in such locales letters appears in this order: 'A' 'a' 'B' 'b' ... 'Z' 'z'. And with other locales, who knows?) .  (note: you could also replace \"[0-9]\" with the \"[[:digit:]]\" notation, but it could be less portable : \"old\" version of sed won't know about this notation and will try to match any of '[' or ':' or ... or 't' or ':', followed by a ']' (*, so 0,1 or more times) ... That's why I don't like using those special [[:things:]] with sed, tr, etc : i see them as less portable. Use perl instead if you prefer to use those?)  .  ",
      "P-tags": "string unix bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_29550153",
      "task": "Why do I get bash integer expression error from [ ${guess[0]} -eq num ]?",
      "P-task": "get bash integ express error guess 0 -eq num",
      "F_verb": "get",
      "P-body": "To make only the minimum number of changes necessary for this code to run correctly: .  Notes: .   Since you're reading only a single value, no compelling reason to use an array -- just as easy to take out the \"-a\" argument to \"read\"; doing this also makes your code compatible with POSIX sh, and thus with \"#!/bin/sh\" on all systems with POSIX-compliant shells. You need to expand your variables when using \"test\" (or \"[\"). \"$num\", not bare \"$num\"; the latter is only possible in a numeric context, whereas \"test\" is a regular command as much as the parser is concerned -- it doesn't create any special context at a syntax level. Because \"[\" is a regular command, you need spaces after it, just like any other command name. Because \"[\" is a regular command, you need spaces before the \"]\" it expects as its last argument -- same as when passing arguments to anything else. If your shell were bash (your script started with \"#!/bin/bash\"), you could use a math context: \"if (( guess == num ))\", or \"if (( guess > num ))\". This is a math context, and has special parsing rules.  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_48911522",
      "task": "powershell replace command if line starts with a specific character",
      "P-task": "powershel replac command line start specif charact",
      "F_verb": "replace",
      "P-body": "You can use a look-behind (\"(?<=pattern)\") to assert that the preceding characters include a \"y\" following the start of the string: .  ",
      "P-tags": "if-stat powershel replac",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP if S"
    },
    {
      "id": "ul_483979",
      "task": "Download just one port from the Ports Collection of FreeBSD",
      "P-task": "download one port port collect freebsd",
      "F_verb": "download",
      "P-body": "\"extract\" You can't do it with \"portsnap\". If you've already a snapshot (you downloaded it already) you can \"extract\" only parts of ports tree (\"portsnap extract databases/postgresql11-server\"), see \"man portsnap\": .    \"svn\" If you don't want fetch these big files you can use \"svn\" instead of \"portsnap\": .  See the relevant part of handbook. .  The \"svn\" is part of the base system (\"/usr/bin/svnlite\" - you can use an alias or replace \"svn\" to \"svnlite\") so you don't have to install devel/subversion. .  ",
      "P-tags": "freebsd download bsd-port",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP of NP"
    },
    {
      "id": "so_7142938",
      "task": "How do I know if wget actually downloaded a file?",
      "P-task": "know wget actual download file",
      "F_verb": "download",
      "P-body": "You can try the following .  ",
      "P-tags": "wget shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_35834751",
      "task": "Error with \"swift build\" in Ubuntu 14.04",
      "P-task": "error swift build ubuntu 14 04",
      "F_verb": "build",
      "P-body": "This is because \"swift build\" expects to find a \"main.swift\" file in the \"Sources\" folder. .  Rename your \"testregex.swift\" file to \"main.swift\" and it will build properly. .  You can have as many \".swift\" files as you want in the Sources folder, but there has to be one \"main.swift\" file. .  ",
      "P-tags": "ubuntu nsregularexpress swift ubuntu-14 04",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V in NP"
    },
    {
      "id": "au_452540",
      "task": "How to download the iso file of ubuntu in command line?",
      "P-task": "download iso file ubuntu command line",
      "F_verb": "download",
      "P-body": "\"wget \"http://web address for direct download of the iso\"\" .  Example : \"wget http://releases.ubuntu.com/14.04/ubuntu-14.04-desktop-amd64.iso\" .  ",
      "P-tags": "putti system-instal",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_210225",
      "task": "Scanning no: of characters of a file and write it that file itself",
      "P-task": "scan : charact file write file",
      "F_verb": "scan",
      "P-body": "Use this: .  The command \"wc -m <file.txt\" will give the number of characters in the file and then we are putting the desired formatted string at the end of the file. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP of NP"
    },
    {
      "id": "au_430702",
      "task": "Remove a terminal command",
      "P-task": "remov termin command",
      "F_verb": "remove",
      "P-body": "A better way would be to redirect the output of the command to \"/dev/null\". That way, the command will 'be there' but will show no results. .  Example: the \"ls\" command.  .   Make an alias \"alias ls = \"ls > /dev/null\"\" Running \"ls\" now will not show any results.   EDIT: Thanks to @scai In the answer above, the command will still show errors because we have redirected \"stdout\" but not \"stderr\" plus a more serious issue, it will still run the command. .  Quoting @scai: .   If the command in question does things you don't like, for example creating or deleting files, changing settings, painting your nose blue, then this alias won't stop it from doing these things. .   For the workaround, we will just alias the command to an empty string, then just redirect the resulting error to \"/dev/null\". .  That's much better now. .   EDIT 2: Thanks to @scai again :-) This is a temporary solution. To revert back to the original function of the command (in our case \"ls\"), just run \"unalias ls\". .  ",
      "P-tags": "gnome-termin",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_407815",
      "task": "A fast way to duplicate a website (Wordpress) on my Nginx server environment?",
      "P-task": "fast way duplic websit wordpress nginx server environ",
      "F_verb": "duplicate",
      "P-body": "This is not fast, but the following code describes the approach I took. Copy paste to test, and if worked, run as one piece by putting the code in a block: .  The code ",
      "P-tags": "script",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP on NP"
    },
    {
      "id": "su_856979",
      "task": "can we open gitbash from atom text editor",
      "P-task": "open gitbash atom text editor",
      "F_verb": "open",
      "P-body": "Install https://atom.io/packages/terminal-plus .  Then in package options .  Shell Override: \"C:\\Program Files\\Git\\bin\\bash.exe\" .  Shell Arguments: \"-l -i\" .  Use git >= 2.7.3 for windows, bash starts up much faster. .  ",
      "P-tags": "atom-editor git-bash",
      "source": "qa",
      "cate": "open",
      "pat": "V NP from NP"
    },
    {
      "id": "au_11327",
      "task": "Retrieving the Names of Files in a txt file",
      "P-task": "retriev name file txt file",
      "F_verb": "retrieve",
      "P-body": "You can execute .  this will redirect the output in the file with the filename given. .  For the content of a folder: .  ",
      "P-tags": "command-lin",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_34651545",
      "task": "Get return code and status from bash script into Java file",
      "P-task": "get return code statu bash script java file",
      "F_verb": "get",
      "P-body": "In order to execute shell command from java we need to use some library, in your case you are using SSHExec, in this jar you can have the result/exit code that is returned from the shell script. .  when the above scripts executes an exit code will be thrown from here and you can have this exit code in your java application something like this: .  ",
      "P-tags": "shell javafx java bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP into NP"
    },
    {
      "id": "so_59874039",
      "task": "how to iterate $TwitterStatuses as an array or as Objects?",
      "P-task": "iter twitterstatus array object",
      "F_verb": "iterate",
      "P-body": "Your query is good already. You don't need to cast to array. What you get from \"Get-TwitterStatuses_UserTimeline\" is already an array of results. .  You can check which type is an object by calling the \".GetType()\" method on them. .  \"$TwitterStatuses.GetType()\" .   .  (The \"Get-Type\" method is available for all objects)  .  You can inspect the members available using \"Get-Member\" on the object you want to inspect. .  \"$TwitterStatuses | Get-Member\" .   .  Then, in your foreach, you need to precise what you actually want to display.  .  Example  .  If only one of the property interest you, you can even get the results directly by accessing the property name . The collection will be iterated and results displayed in the console.  .  \"$TwitterStatuses.text\" .   .  References .  Get-Member .  .GetType() .  ",
      "P-tags": "array net-cor loop powershel iter",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP as NP"
    },
    {
      "id": "au_326378",
      "task": "Qt5 with Qt 4.7 on Ubuntu 13.04. How to install it both without conflicts?",
      "P-task": "qt5 qt 4 7 ubuntu 13 04 instal without conflict",
      "F_verb": "install",
      "P-body": "I found solution. I can install both libraries and when I'm making: .  or .  ",
      "P-tags": "qt qt5 13 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP without NP"
    },
    {
      "id": "so_25438729",
      "task": "Find string inside of an anchor tag from cURL response using bash",
      "P-task": "find string insid anchor tag curl respons use bash",
      "F_verb": "find",
      "P-body": "You need a space:  .  ",
      "P-tags": "curl bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "au_1094823",
      "task": "How to have sshfs disk without auto-mount?",
      "P-task": "sshf disk without auto-mount",
      "F_verb": "mount",
      "P-body": "The \"fstab\" manpage lists a useful option: .   noauto do not mount when \"mount -a\" is given (e.g., at boot time) .   Could you try that option? .  ",
      "P-tags": "mount sshf fstab ssh",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "so_67936157",
      "task": "Authenticate a local Spring Boot service with Google Cloud",
      "P-task": "authent local spring boot servic googl cloud",
      "F_verb": "authenticate",
      "P-body": "I used systemd, it allows me to set any environment variable on service start. .   place the executable jar and the application.properties in a folder, like \"/opt/<name>\" or \"/home/<user>/<name>\" sudo nano \"/etc/systemd/system/<name>.service\" Content:   Reload systemctl configs: \"sudo systemctl daemon-reload\" Set the service to start after system boot: \"sudo systemctl enable <name>.service\" Start the service with \"sudo systemctl start <name>.service\"  Status: \"sudo systemctl status <name>.service\" .  Follow the stdout: \"sudo journalctl -u <name>.service --follow\" .  ",
      "P-tags": "ubuntu init java spring-boot google-cloud-platform",
      "source": "qa",
      "cate": "validate/authenticate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_31007209",
      "task": "Shell remove string including newlines",
      "P-task": "shell remov string includ newlin",
      "F_verb": "remove",
      "P-body": "sed is for simple substitutions on individual lines, for anything else you should be using awk: .  The above uses GNU awk for multi-char RS to read the whole file as a single string (with other ask you just build up the string line by line and process in the END section) and relies on your file not containing any NUL (\"\\0\") characters. .  The first \"gsub()\" changes every \"*/\" to one char (a NUL) so the 2nd \"gsub()\" can negate it in a bracket expression as part of your desired regexp and then the third \"gsub()\" restores any remaining NULs to \"*/\"s. .  With non-gawk you need to build up the string: .  and it sounds like your awk requires the \"/\"s in the bracket expressions escaped so it doesn't see them as the terminating char of the RE: .  If your awk doesn't like NUL chars then use some control character, e.g. where every \"^C\" is a literal control-C character): .  or use the pre-defined \"SUBSEP\" control char that awk uses to separate array indices (note you now need to double-up the backslashes in the REs that are concatenation of literal strings with SUBSEPs since they are now dynamic regexps instead of constant regexps, see http://www.gnu.org/software/gawk/manual/gawk.html#Computed-Regexps for details): .  ",
      "P-tags": "sed bash shell regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_49894798",
      "task": "How to explicitly start one version of postgres on startup?",
      "P-task": "explicitli start one version postgr startup",
      "F_verb": "start",
      "P-body": "One solution is to remove 9.1 .  and change the port in the config file for 9.6 to 5432 .  change the port to 5432 and write and close the config file .  ",
      "P-tags": "ubuntu-12 04 postgresql",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP of NP on NP"
    },
    {
      "id": "ul_669976",
      "task": "How to concatenate lines of several associated files into one line, and append that to an output file",
      "P-task": "concaten line sever associ file one line append output file",
      "F_verb": "concatenate",
      "P-body": "Assuming that your input doesn't contain fringe cases, the following shell loop in connection to an \"awk\" program should do: .  This will loop over all \"tmp1.tsv\" files and generate the corresponding filename for the \"tmp2.tsv\" file. If the second file turns out not to exist, the filename will be set to the empty string. .  It will then call an \"awk\" program with both associate TSV files, which will print - all on the same line .   all fields, excluding the last one, of the first line of each input file (but preceded by an additional OFS in case of the second input file, characterized by \"FNR\", the per-file line counter, no longer being equal to \"NR\", the global line counter), the last field of each line until line 3, when no input file remains, a closing record separator (defaults to newline)  and appends the output to \"template.tsv\". This will also work if the second template file doesn't exist, because the empty string token will not be recognized as input file by \"awk\" in the first place, so the \"END\" section printing the newline will be reached after the first file already. .  ",
      "P-tags": "awk shell-script text-process",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP of NP into NP"
    },
    {
      "id": "ul_137183",
      "task": "How do you \"disable\" oh-my-zsh (and zsh) without uninstalling it?",
      "P-task": "disabl oh-my-zsh zsh without uninstal",
      "F_verb": "disable",
      "P-body": "The wording of your question is ambiguous, so I can't tell if you mean you want to stop using \"zsh\" or you want to stop using \"oh-my-zsh\". I will cover both. .  Disabling \"zsh\" Simply run \"chsh\" and select whatever shell you were using before. If you don't know what shell you were using before, it is almost certainly \"bash\". This command changes the \"login shell\" that is associated with your user. Essentially, it changes your default shell. .  You will need to open a new terminal window for changes to take effect. If this does not work, you will need to log out and log back in again to reinitialize your environment. .  Disabling only \"oh-my-zsh\"  Check if \"~/.zshrc.pre-oh-my-zsh\" exists. It probably does. This file will have been created when the \"oh-my-zsh\" installation script moved your previous \".zshrc\" out of the way. \".zshrc\" is a startup file of \"zsh\", similar to \".bashrc\" for \"bash\".) If it does, do \"mv ~/.zshrc ~/.zshrc.oh-my-zsh\". This will put the \"oh-my-zsh\"-created \".zshrc\" out of the way, so we can restore the original, by doing \"mv ~/.zshrc.pre-oh-my-zsh ~/.zshrc\". If it does not exist, open \"~/.zshrc\" in a text editor. Find the line that says \"source $ZSH/.oh-my-zsh\" and either comment it out or remove it. This will disable the initialization of \"oh-my-zsh\".  You will need to restart your shell for changes to take effect. .  ",
      "P-tags": "oh-my-zsh zsh",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_46445246",
      "task": "Arch Linux: make - no such file or directory",
      "P-task": "arch linux : make - file directori",
      "F_verb": "make",
      "P-body": "[Reputation is too low to post comment] .  Use uname -r to make sure which version of the kernel you use. .  If it's \"4.9.43\" : you have newer version of the kernel and this confuse your installer. You should reboot on the 51 one .  If it's \"4.9.51\" : You messed up your installation step and are trying to compile for an old target. You should review the compilation process and change every mention of the \"4.9.43\" to \"4.9.51\" since it's the version you use. .  If you upgrade your kernel, you may have to rebuild the thing again (You may like to have script in the future ;) ) with the new kernel version. .  ",
      "P-tags": "build linux compil archlinux",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_232836",
      "task": "Getting specific 'Out of memory!' message when running very involved Perl script",
      "P-task": "get specif memori\nmessag run involv perl script",
      "F_verb": "get",
      "P-body": "Instead of fighting with perl optimization, use a wrapper like this: .  \"wrapper.sh\" .  Use it as follows: .  So instead of the perl script looping through 7k of files in one run, it is a fresh start for each file. .  I also suggest you redirect the output into a file instead of the screen. It is possible that the terminal (xterm, gnome-term, etc) used up all your memory if set to unlimited buffer/lines. .  ",
      "P-tags": "memori command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "au_1120262",
      "task": "ln -s fail to create a symbolic to directory",
      "P-task": "ln -s fail creat symbol directori",
      "F_verb": "create",
      "P-body": "This looks like 3rd form according to documentation: .   ln [OPTION]... TARGET... DIRECTORY (3rd form) ... In the 3rd and 4th forms, create links to each TARGET in DIRECTORY.  .   So it reads as \"create link to a directory \"Books\" (which is in your current working directory) and put that link in specified directory \"~/Books\"\". Of course, if \"Books/\" doesn't exist in current working directory - you'll have a symlink pointing to itself, which will result in too many symlink levels error .  Now, I would suggest using first form with \"-T\" flag: .  ",
      "P-tags": "symbolic-link",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP to NP"
    },
    {
      "id": "so_53443415",
      "task": "Running tensorflow_model_server from bash is throwing 'command not found error'",
      "P-task": "run tensorflow_model_serv bash throw command found error",
      "F_verb": "run",
      "P-body": "\"model_base_path\" should be a directory, the parent folder of the version folder of \"saved_model.pb\" and \"variables\\\", not a file. For example, for the following directory, \"model_base_path\" should be \"path_to_versions\\versions\". .  ",
      "P-tags": "protocol-buff python tensorflow bash tensorflow-serv",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "au_769554",
      "task": "My wifi once worked, but now it doesnt after restart",
      "P-task": "wifi work doesnt restart",
      "F_verb": "restart",
      "P-body": "You probably received a newer kernel version in an update. After the requested reboot, you must recompile: .  Or wherever you cloned the package, if not your desktop .  Your wireless should again be working. .  ",
      "P-tags": "network 16 04",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V"
    },
    {
      "id": "so_29168059",
      "task": "querying the request of cpp-netlib HTTP server",
      "P-task": "queri request cpp-netlib http server",
      "F_verb": "query",
      "P-body": "You can get the following fields from the server's request object (https://github.com/cpp-netlib/cpp-netlib/blob/0.11-devel/boost/network/protocol/http/impl/request.hpp#L126): .   \"request.destination\" -- a string, the \"uri\" \"request.method\" -- the method, \"POST\", \"GET\", etc. \"request.headers\" -- a vector of header objects, with .name and .value members \"request.body\" -- the body of the request, all in.  If you're using the asynchronous version of the server's API, you can also get the body streaming by following the documentation from http://cpp-netlib.org/0.11.1/reference/http_server.html#connection-object -- this allows you to read chunks of the incoming request's body and then respond by setting the status of the response, add headers, etc. .  In your example, you can get what you want by doing this: .  Alternatively, using the objects directly: .  ",
      "P-tags": "c++11 linux cpp-netlib",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "so_23224607",
      "task": "How do I include Linux header files like linux/getcpu.h?",
      "P-task": "includ linux header file like linux getcpu h",
      "F_verb": "include",
      "P-body": "Short answer: usually, you don't include those headers directly. .  Most OS/Machine specific headers in there are automatically included for you by a more general header. Those that are not are linux only features which may or may not be available for the version you are running. .  As to \"getcpu\", there is a more standardised version called \"sched_getcpu\" which is found in \"sched.h\" and has the same function. .  Alternatively you can test wether that system call is available on your system and call it manually: .  The variable errno (\"#include <errno.h>\") gives the error code, if syscall returns -1. .  ",
      "P-tags": "linux c include-path",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP"
    },
    {
      "id": "so_45320371",
      "task": "Delete multi-line pattern starting on first line of file only",
      "P-task": "delet multi-lin pattern start first line file",
      "F_verb": "delete",
      "P-body": "So after posting, I figured out how to do this in \"sed\" with the following command: .  \"sed -e '/<%/{1!b;:x;$!N;/%>/!bx;s/<%.*%>//}' -i \"file\"\" .  An explanation of the command: .  ",
      "P-tags": "bash sed regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP on NP of NP"
    },
    {
      "id": "ul_131778",
      "task": "How do you change the color for all the items in the status bar in the i3 WM?",
      "P-task": "chang color item statu bar i3 wm",
      "F_verb": "change",
      "P-body": "The extent to which each element in the statuses responds to color_good/degraded/bad in the \"i3status.conf\" file is not entirely clear but this is not how you set a default color for all the items. To supply a uniform1 default color for all the elements in the status, you just need add a color block to the bar section of your \".i3/config\" file instead (defaults used here except for the statusline item): .  Then use mod1+Shift+r to restart which reloads the configuration. .   1. Note that even as you do so an item like ethernet will show the color_good color from the \"i3status.conf\"file instead. ?) .  ",
      "P-tags": "i3",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP for NP in NP in NP"
    },
    {
      "id": "au_406238",
      "task": "How To Uninstall Failed 'dpkg -i xorg_7.6+12ubuntu1_amd64.deb' Command",
      "P-task": "uninstal fail dpkg -i xorg_7 6+12ubuntu1_amd64 deb command",
      "F_verb": "uninstall",
      "P-body": "Try the below command on Virtual console(ctrl+alt+F1), .  It's safe to do the above commands in tty. .  ",
      "P-tags": "dpkg 12 04 apt",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_16447623",
      "task": "Prevent a command in a shellscript from being executed inside another shellscript",
      "P-task": "prevent command shellscript execut insid anoth shellscript",
      "F_verb": "prevent",
      "P-body": "You can define an alias like this in your script: .  By default aliases work only in interactive shells, so you must change this behaviour with: .  in your script and source the other script (the one you cannot change): .  or .  This will work unless the other script runs \"rm\" in a sub-shell. .  Another, safer method is to create your own \"rm\" command which does nothing (or just prints out its argument so you know what's going on), put it into a directory and put this directory as the first one in the \"PATH\" environment variable like this (Korn shell syntax): .  ",
      "P-tags": "delete-fil command unix shell",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP from S_ING inside NP"
    },
    {
      "id": "so_32004691",
      "task": "find and replace a String in vi editor on linux?",
      "P-task": "find replac string vi editor linux",
      "F_verb": "replace",
      "P-body": "I'd guess the reason you're getting that error message is because you intend to replace the string on all lines, not just the current one. In order to search all lines, add a \"%\" to your command: .  ",
      "P-tags": "unix linux replac vi shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP on NP"
    },
    {
      "id": "ul_669728",
      "task": "find the greatest number of lines in a group separated by empty line & return the last word of that group. Bash",
      "P-task": "find greatest number line group separ empti line return last word group\nbash",
      "F_verb": "find",
      "P-body": "Add the following command to your pipe: .  The value of \"RS\" (record separator) is set to null to get the \"block mode\" where a blank line separates records. The value of \"FS\" (field separator) is set to newline only (\"\\n\"). .  That will make the number of fields equal to the number of lines (watch out for filenames with new lines). .  Then, the record with the max number of lines is found and its last field (last line) is recorded and later printed. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP in NP by NP"
    },
    {
      "id": "so_66403041",
      "task": "Remove double quotes from path variable in PowerShell",
      "P-task": "remov doubl quot path variabl powershel",
      "F_verb": "remove",
      "P-body": "What you describe trailing quote not removed means there is some invisible character like a space trailing the quote. .  To get rid of that too, use \"Trim('\" ')\" or chain two Trim's together like .  The first removes all whitespace characters from both sides of the string (not just spaces, but also tabs, newlines etc.), followed by the second one to remove the quotes. .  P.S. We cannot see what your function does exactly, but maybe you can use PowerShell's own Get-ItemPropertyValue for that? .  ",
      "P-tags": "c string powershell-5 1 powershel windows-10",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "ul_105423",
      "task": "Changing hostname doesn't change the terminal name",
      "P-task": "chang hostnam chang termin name",
      "F_verb": "change",
      "P-body": "The default PS1 prompt behavior is to display the hostname up to the first '.' as noted in this excerpt from the bash man page: .   PROMPTING When executing interactively, bash displays the primary prompt PS1 when it is ready to read a command, and the secondary prompt PS2 when it needs more input to complete a command. Bash allows these prompt strings to be customized by inserting a number of backslash-escaped special characters that are decoded as follows: .  snip .   \\h the hostname up to the first \u2018.\u2019 .  \\H the hostname .    You can correct this by changing how your PS1 prompt is displayed in \"/etc/bashrc\" .  This CentOS website details methods for customizing your bash prompt, including this: .   System-wide Configuration .  System-wide configuration is done in /etc/bashrc. Comment out the default settings and add your customization below: .  # [ \"$PS1\" = \"\\s-\\v\\\\$ \" ] && PS1=\"[\\u@\\h \\w]\\$ \" .  PS1='\\u@\\H:\\w\\$ ' .   ",
      "P-tags": "prompt hostnam bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_42101839",
      "task": "How do I send a message to my socket.io websocket from the command line in linux?",
      "P-task": "send messag socket io websocket command line linux",
      "F_verb": "send",
      "P-body": "You can write a simple client like this (let's name it \"client\" with no extension): .  with a very basic \"package.json\" .  Then run \"npm install\", give \"client\" permissions to be executed and you can run it with (for example) \"./client message testControl\" .  What do you think? ;) .  ",
      "P-tags": "linux websocket socket io bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP from NP in NP"
    },
    {
      "id": "so_66409811",
      "task": "lua run a shell command with parameters doesn't work",
      "P-task": "lua run shell command paramet work",
      "F_verb": "run",
      "P-body": "You're not providing spaces between the arguments: you're trying to execute .  Do this: .  It's often easier to build the command up as a table, and the concat it for execution: .  ",
      "P-tags": "python shell lua",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_47814258",
      "task": "Rename files with function",
      "P-task": "renam file function",
      "F_verb": "rename",
      "P-body": "Here, .  the command substitution is unquoted, so it gets expanded in the command line, before \"find\" sees it. The resulting command that runs is .  and then \"find\" replaces both copies of \"{}\" with the current file name. The same happens if the command substitution is double-quoted. .  If it's single-quoted, however, then \"find\" will expand the \"{}\" within it, and run commands like \"mv ./somefile $(echo ./somefile)\", which will not work unless the directory \"$(echo .\" exists. .  The main point here is that \"find -exec\" doesn't run through a shell.  .  You need to ask for a shell there explicitly. Either once per each file .  or one shell for multiple files and a loop to deal with them all .  Of course, if \"urlencode\" is an alias, you'll have to jump through hoops to get it to work in a noninteractive shell. It's probably better to put it as a script in the \"PATH\", or as an exported function (in which case, run \"bash -c\" instead of \"sh -c\"). .  ",
      "P-tags": "python bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP"
    },
    {
      "id": "so_50153623",
      "task": "Run a shell command automatically and directly after restarting and keep it running",
      "P-task": "run shell command automat directli restart keep run",
      "F_verb": "restart",
      "P-body": "Solution 1: .  Solution 2: .  Make a script name it \"whatever.sh\".  .  Put the file in your /etc/init.d/ directory.  .  Change the permission of your file by.  .  ",
      "P-tags": "startup linux command shell",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V"
    },
    {
      "id": "au_678830",
      "task": "what causes this error by `apt-get update`",
      "P-task": "caus error apt-get updat",
      "F_verb": "get",
      "P-body": "Whenever we add a repository for installing packages we also need a GPG key used by apt to authenticate packages for security reasons.  .  When adding a Launchpad hosted PPA this key will automatically be downloaded to use. So we do not have to do anything in addition. .  This is different when adding an external repository such as the Oracle repository for Virtual Box. We then have to manually download and add the signing key. To do this the following steps are involved: .   add the repository to our sources download the GPG key add this key for authentication update our apt cache install the desired software package  There are many different ways to achieve this, from command line or with graphical tools which I will not further elaborate here. .  For adding the key there is a single-line command from the Virtual Box download page which always had worked for me: .  ",
      "P-tags": "apt virtualbox",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_42352544",
      "task": "How can I pass negative numbers to a net files call in PowerShell",
      "P-task": "pass neg number net file call powershel",
      "F_verb": "pass",
      "P-body": "File IDs can't be negative. The software that lists the file IDs is showing you an int32 (signed integer) when it should have used uint32, so the bit to the left (32th bit)'s value of \"1\" makes the number negative instead of adding \"2147483648\". .  You need to convert it, ex: .  Output: .  The output is an error, but it's the right kind of error, as a negative id would give you syntax error. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_34980412",
      "task": "REST API call to get the list of SQL databases from Azure",
      "P-task": "rest api call get list sql databas azur",
      "F_verb": "get",
      "P-body": "I think you can use cURL instead of wget. But, before you use cURL, you need to create and upload a certificate. .  First, you need to install openssl and curl in your machine. And then you can create a .pem file with the following command: .  Note: openssl will ask you to input a lot of things. .  this is for local usage. From the .pem file, you can create a .cer file which will be uploaded to Azure. Use the following command to create one. .  Go the the classic portal of Azure, in the Management certificates page of Settings, click upload, and choose the .cer file created above. .  Wait for a few seconds, and after the certificate is created, you can use the following command to get a list of SQL Database in some SQL server. .  If you want to delete an SQL Database, you can use the following command. .  The output of these commands are XML code which is hard to read. So, I recommend you to use Azure CLI instead. But, if you insist, and need more information about cURL with HTTP Jobs, see here. If you need more information about Azure REST API, see here .  ",
      "P-tags": "azur azure-sql-databas bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "au_163579",
      "task": "Run shell script on every new shell",
      "P-task": "run shell script everi new shell",
      "F_verb": "run",
      "P-body": "For interactive login shells, as you've found, you can put commands in scripts located inside: .  You can also accomplish that, in a somewhat less desirable way, by editing the global configuration file: .  For \"bash\" (which is the default interactive shell), there is a corresponding file where you can put commands to be run by all interactive non-login shells: .  Just as \"/etc/profile.d\" and \"/etc/profile\" correspond to \"~/.profile\", \"/etc/bash.bashrc\" corresponds to \"~/.bashrc\". .  This does not apply to non-interactive shells. But it's rather unlikely that you have commands you want run by non-interactive shells. Then they would run every time any script was run.) .  ",
      "P-tags": "configur command-lin bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_3676012",
      "task": "I need to backup and then recover multiple files in different directorys with /bin/sh",
      "P-task": "need backup recov multipl file differ directori bin sh",
      "F_verb": "recover",
      "P-body": "The bash shell parameter expansion doesn't work in sh. Try this: .  Don't forget to add a loop around that find output if you intend to process multiple .bak files. .  ",
      "P-tags": "sed sh awk copi",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "ul_483121",
      "task": "How to use the awk output to construct the command",
      "P-task": "use awk output construct command",
      "F_verb": "use",
      "P-body": "Just pipe the commands through a while loop. .  For the second command, we create and array of the \"ABC\", \"DEF\", \"GHI\", strings first, then read from this incrementally. .  ",
      "P-tags": "awk shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_60483901",
      "task": "Prepend then redirect",
      "P-task": "prepend redirect",
      "F_verb": "redirect",
      "P-body": "You can use a process substitution. .  Or with old shells with broken process substitution support: .  Here we save \"prog\"'s stdout to fd 3, pipe its stderr to sed and at the end restore fd 3 back to stdout. .  ",
      "P-tags": "pipe io-redirect bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V"
    },
    {
      "id": "so_16448153",
      "task": "awk - how to delete first column with field separator",
      "P-task": "awk - delet first column field separ",
      "F_verb": "delete",
      "P-body": "Assuming your original CSV file is named \"orig.csv\": .  ",
      "P-tags": "awk linux shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "au_1043650",
      "task": "Dash, command substitution not inserting newline?",
      "P-task": "dash command substitut insert newlin",
      "F_verb": "insert",
      "P-body": "This behavior is actually part of the POSIX specification for command substitution: .   The shell shall expand the command substitution by executing command in a subshell environment (see Shell Execution Environment) and replacing the command substitution (the text of command plus the enclosing \"$()\" or backquotes) with the standard output of the command, removing sequences of one or more characters at the end of the substitution. Embedded characters before the end of the output shall not be removed; however, they may be treated as field delimiters and eliminated during field splitting, depending on the value of IFS and quoting that is in effect. If the output contains any null bytes, the behavior is unspecified. .   So the normal quoting rule \"\"$(...)\"\" only preserves non-trailing newlines. .  Some suggestions for preserving trailing newlines are given in shell: keep trailing newlines ('\\n') in command substitution .  See also When printing a variable that contains newlines, why is the last newline stripped? for discussion of the rationale behind the specification. .  ",
      "P-tags": "dash-shel command-lin",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_28028321",
      "task": "How to cut a variable to sub variable",
      "P-task": "cut variabl sub variabl",
      "F_verb": "cut",
      "P-body": "You can separate \"$result\" into the different variables you describe by using \"read\": .  Example: .  You can also use \"read\" to prompt a user for input: .  This will store the value entered in the variable \"$SOLDUNITS\". You can then use this to alter \"$QUANTITY\" and \"$UNIT\" as desired. To do (integer) arithmetic in \"bash\", you can use the \"$((expression))\" construct: .  Or: .  ",
      "P-tags": "awk cut shell",
      "source": "qa",
      "cate": "cut/slash/separate/clip/crop",
      "pat": "V NP to NP"
    },
    {
      "id": "su_296398",
      "task": "how to install vmware tools on Ubuntu 11.04?",
      "P-task": "instal vmware tool ubuntu 11 04",
      "F_verb": "install",
      "P-body": "RPM is for Red-Hat like package management, and therefore not suitable for Ubuntu. Just untar the \".tar.gz\" file. .  and then see the corresponding Readme- or Installation-files for help. If I'm not completely wrong, there is an installer script. Just \"cd\" to the newly extracted directory and run the installer script with \"root\" permissions: .  Finally, open the \"vmware-toolbox\": .  This is what I gathered from my memory and the Ubuntu documentation, so if they haven't changed anything, it should work like this. .  ",
      "P-tags": "ubuntu windows-7 vmware",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_28966124",
      "task": "How to count rows greater than a value and write the count to a text file in Linux",
      "P-task": "count row greater valu write count text file linux",
      "F_verb": "count",
      "P-body": "Awk solution: .  Or a more general solution with respect to the number of columns: .  ",
      "P-tags": "awk linux",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V to NP in NP"
    },
    {
      "id": "su_816690",
      "task": "How to be able to resolve multiple domains using /etc/resolv.conf on Linux?",
      "P-task": "abl resolv multipl domain use etc resolv conf linux",
      "F_verb": "resolve",
      "P-body": "After following @webmarc and @dan-hook, it wasn't working until I removed the \"domain\" line which I still quite don't fully understand. .  According to this answer, the \"domain\" becomes the first \"search\" string. I find it easier to just not use the \"domain\" string. .  Steps: .   All \"search\" domains are put on a single line \"domain\" line(s) were removed New company domains were placed before the old company names  This is my new \"/etc/resolv.conf\" and it works perfectly. .  Also if your \"/etc/resolv.conf\" will be overwritten then modify \"/etc/network/interfaces\" .  If the new company has a new dns server IP, make sure that IP also comes before the old company's so that the new dns servers get queried first. .  ",
      "P-tags": "dn linux domain nameserv search",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP using NP on NP"
    },
    {
      "id": "so_23437362",
      "task": "How to kill process group zombies",
      "P-task": "kill process group zombi",
      "F_verb": "kill",
      "P-body": "If the parent process terminates, its children will be reassigned to the \"init\" process. It will \"wait\" for them so they shouldn't become zombies. .  ",
      "P-tags": "linux c error-handl multithread",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "so_37260431",
      "task": "How to test if a kinit is needed?",
      "P-task": "test kinit need",
      "F_verb": "test",
      "P-body": "You could try \"klist -s\". From the man page: .  \"causes klist to run silently (produce no output), but to still set the exit status according to whether it finds the credentials cache. The exit status is \u20180\u2019 if klist finds a credentials cache, and \u20181\u2019 if it does not or if the tickets are expired.\" .  ",
      "P-tags": "hadoop kerbero bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_42744154",
      "task": "Powershell: xml reading using XML-object not retrieving values if there is only one element",
      "P-task": "powershel : xml read use xml-object retriev valu one element",
      "F_verb": "read",
      "P-body": "you don't seem to have an attribute on the server object called 'name'. I believe you could do the following to achieve your desired outcome: .  Alternatively, if you do not want to use the string formatting (but less readable in my experience): .  Of course if you wanted to display the website of the XML node, then you can replace $server.ip with $server.website. .  ",
      "P-tags": "powershel xml",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V using NP if S"
    },
    {
      "id": "so_12600545",
      "task": "linux command not running in Java application",
      "P-task": "linux command run java applic",
      "F_verb": "run",
      "P-body": "I got the Answer .Need to give in the following way. .  ",
      "P-tags": "linux unix java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP"
    },
    {
      "id": "so_8501835",
      "task": "Making an \"and\" statement to match more than 1 value",
      "P-task": "make statement match 1 valu",
      "F_verb": "make",
      "P-body": "Logical and is done using \"-and\" in powershell: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_1371042",
      "task": "Ubuntu 21.10 install stuck with lenovo Thinkpad e15 gen2 because of elan error",
      "P-task": "ubuntu 21 10 instal stuck lenovo thinkpad e15 gen2 elan error",
      "F_verb": "install",
      "P-body": "I have managed to fix the issue: .    In the grub boot menu choose \"UEFI firmware settings\". In there turn off the pad and tracker in the settings. This by the way will not make them stop working, for some reason.) Restart and install Ubuntu regularly.   ",
      "P-tags": "kernel boot elantech thinkpad",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP of NP"
    },
    {
      "id": "so_44987925",
      "task": "How to type memory instructions/opcodes properly for writing/modifying memory address while debugging kernel in GDB",
      "P-task": "type memori instruct opcod properli write modifi memori address debug kernel gdb",
      "F_verb": "write",
      "P-body": "Since you already know the opcodes, it's pretty simple. You just use \"set\" to set whatever bytes you want at that address. The only trick is that you want to set 4 bytes at a time, so you'll need to instruct \"set\" to treat the address as a pointer to a DWORD. You can do this with a C-style cast: .  (This, obviously, assumes that an \"unsigned int\" is a 4-byte type on your platform. If it isn't, change it as appropriate.) .  ",
      "P-tags": "embedded-linux debug gdb linux-kernel assembl",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP while S"
    },
    {
      "id": "so_52122629",
      "task": "Is there is a specific capability to read a serial port?",
      "P-task": "specif capabl read serial port",
      "F_verb": "read",
      "P-body": "Normally ttys belong to a group called something similar to \"dialup\". This is used mainly for old \"cu\" programs. .  One thing you can use (and I do) is to include yourself in the \"dialup\" group, as you'll see that unused ttys have write permission to owner and group they belong to. .  Don't forget to logout and relogon when you test this, as to get the group id for the \"dialup\" group in the list of groups you belong to requires to pass through the \"login(1)\" program. .  NOTE On my system (a FreeBSD 11.x) the gps belongs to group \"operator\", and I (my account) belongs to that group. I can open the gps (bluetooth device with pseudo terminal over a pseudotty) .  In linux, I use \"/dev/rfcomm0\" (bluetooth) serial device. In debian, \"/dev/ttyS0[0-3]\" belong to the \"dialout\" group. You can use that group. .  ",
      "P-tags": "capabl linux serial-port",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_680138",
      "task": "sudo doesn't request a password after installing PiNet",
      "P-task": "sudo request password instal pinet",
      "F_verb": "request",
      "P-body": "Apparently, installing PiNet created the \"teachers\" group, added your user to it and also created the file in \"/etc/sudoers.d\". This line: .  Gives the right to all members of the \"teachers\" group to run \"sudo\" commands without providing a password. So, simply delete it and you should be fine: .  PiNet seems to be a program to facilitate administrating a classroom full fo Pis and, apparently, believes that all teachers should have passwordless sudo rights. .  If you do actually want to keep that setup, just remove your user from the \"teachers\" group: .  ",
      "P-tags": "password sudo command-lin",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP after S_ING"
    },
    {
      "id": "ul_329554",
      "task": "Install a package manager on a terramaster NAS",
      "P-task": "instal packag manag terramast na",
      "F_verb": "install",
      "P-body": "The source code for the GPL components used on TerraMaster NAS devices is apparently available, so you could poke around that to figure out what C library is used etc. and thus replicate a build environment elsewhere that could produce compatible libraries and binaries. Then you could use a \u201cpackage manager\u201d designed to work in situations where it doesn\u2019t control the complete system, something like Stow perhaps. .  But in your situation I suspect the simplest solution is a \"chroot\"-based approach, e.g. using Debootstrap: download the tarball from the \"debootstrap\" package page (version 1.0.87 currently), extract it on the NAS, create a directory for the distribution, and run it from the extracted directory (see the \"README\" file in the tarball for details): .  Someone has apparently managed to run Gentoo on the NAS, so it might well be possible to completely replace the system software with your distribution of choice \u2014 but that might not be advisable... .  ",
      "P-tags": "linux package-manag",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_727227",
      "task": "GNOME Terminal: Connect via SSH from Ubuntu Desktop 14.04 into Ubuntu Server 14.04 Virtual Box Guest Host",
      "P-task": "gnome termin : connect via ssh ubuntu desktop 14 04 ubuntu server 14 04 virtual box guest host",
      "F_verb": "connect",
      "P-body": "If you have a different username on the system you are connecting to, you have to specify it: .  If you don't specify any username, SSH assumes your current username. .  ",
      "P-tags": "network server ssh",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V via NP from NP into NP"
    },
    {
      "id": "so_9228682",
      "task": "java.io.IOException: Permission denied with Wake on Lan",
      "P-task": "java io ioexcept : permiss deni wake lan",
      "F_verb": "deny",
      "P-body": "It's late but here is a patch for classpath 0.99: .  This solves the problem. .  ",
      "P-tags": "linux wake-on-lan java jamvm busybox",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V with NP"
    },
    {
      "id": "su_881815",
      "task": "how to control users login on Linux machine according to configuration file",
      "P-task": "control user login linux machin accord configur file",
      "F_verb": "control",
      "P-body": "There is nothing wrong in your configuration. .  Write your configuration in first line of \"/etc/pam.d/sshd\" like this  .  That is because PAM will check all these configuration line by line , if you put your configuration in last line then any other condition will pass before checking your condition , That's why all users all able to login . Check this and let me know. .  Be careful while trying this  .  Before changing anything take a backup of file.  .  if you configure like this  .  And condition fails still PAM will check remaing rules.  .  if you configure like this  .  And above condition fails , PAM will not check remaing rules.  .  required .  requisite .  So in your case may be below condition giving permission  .  You are entering correct password while ssh.  .  ",
      "P-tags": "sshd linux authent shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP to NP"
    },
    {
      "id": "au_776522",
      "task": "How to disable cache in Firefox?",
      "P-task": "disabl cach firefox",
      "F_verb": "disable",
      "P-body": "This option was actually removed in Firefox 43 because it caused this bug. .  But there are still the following options available through the \"about:config\" section: .   \"browser.cache.disk.enable\" (The disk cache is used in normal mode (non Private Browsing mode) and stores persistent data on the hard drive.) \"browser.cache.memory.enable\" (The memory cache is used in normal mode and in Private Browsing mode and is purged when you close Firefox.)  The first should be what you want. It is inadvisable to also disable the second one though as Firefox needs some sort of cache to function properly. Information taken from here. .  ",
      "P-tags": "secur configur set cach firefox",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP in NP"
    },
    {
      "id": "so_58006373",
      "task": "Convert a stringified PSCustomObject back to a PSCustomObject",
      "P-task": "convert stringifi pscustomobject back pscustomobject",
      "F_verb": "convert",
      "P-body": " is working for me .  ",
      "P-tags": "powershel powershell-4 0",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_33049089",
      "task": "Using awk to read and create files in all subdirectories",
      "P-task": "use awk read creat file subdirectori",
      "F_verb": "create",
      "P-body": "Given that you want the output file created in the directory where the README was found, the simplest way is to use the POSIX standard \"dirname\" command: .  This code is not safe if there are spaces or newlines in the directories, but assuming you stick with the portable file name character set (letters, digits, dot, dash and underscore), there'll be no major problems. It wasn't safe before I made any changes; it still isn't safe. It isn't safe because you used \"FILES=$(find \u2026)\" and while you do that, it is pretty much guaranteed to remain unsafe for names with blanks, tabs, newlines in them. There are ways to fix that, but they involve more major surgery.) .  If you want, you can study the Bash parameter expansion mechanisms to see how to do it without using \"dirname\". .  ",
      "P-tags": "awk bash script shell subdirectori",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_62307349",
      "task": "making a Hotel management system in BashScript",
      "P-task": "make hotel manag system bashscript",
      "F_verb": "make",
      "P-body": "First, you're missing a \"; then\" here: .  Second, you're getting a \"syntax error near unexpected token '}'\" because you did not close every statement. Just add a last \"fi\" after the current final one (inside the \"roombooking\" function also): .  ",
      "P-tags": "linux ubuntu shell bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "au_952362",
      "task": "How to remove JDK and keep JRE in ubuntu 16.04",
      "P-task": "remov jdk keep jre ubuntu 16 04",
      "F_verb": "keep",
      "P-body": "Just do: .  ",
      "P-tags": "apt openjdk java jdk jre",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "au_187165",
      "task": "Bash script to remove line breaks?",
      "P-task": "bash script remov line break",
      "F_verb": "remove",
      "P-body": "Try doing this: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_32274163",
      "task": "How to set root password on Yocto / Poky image?",
      "P-task": "set root password yocto poki imag",
      "F_verb": "set",
      "P-body": "Here is what you have to do in your recipe. .  where p@ssw0rd is the password you want root user to have. .  This link may help you. .  As \"debug-tweaks\"'s goal is to set root's password empty, you must remove it from your EXTRA_IMAGE_FEATURES. .  ",
      "P-tags": "embedded-linux yocto",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP"
    },
    {
      "id": "so_10517409",
      "task": "Replacing a pattern in a text file with a random value",
      "P-task": "replac pattern text file random valu",
      "F_verb": "replace",
      "P-body": "The best way I know how to do this is with a perl in-place edit: .  E.g. myfile.txt contains: .  Run the in-place edit: .  myfile.txt now contains: .  Obviously adjust \"2000\" to your requirements. .  EDIT: If you wish to use incrementing identifiers use: .  ",
      "P-tags": "awk text regex bash sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_31535097",
      "task": "How to prevent writing new line while read line in bash",
      "P-task": "prevent write new line read line bash",
      "F_verb": "prevent",
      "P-body": "Use \"echo \"hi\\c\"\" instead of \"echo -n \"hi\"\" or \"printf\" if avaliable , example \"printf \"hi\"\". .  In your example, this should work: .  Or you can use a better tool: .  If everything fails \"tr\" brute force: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V S_ING while S"
    },
    {
      "id": "ul_462312",
      "task": "rsync: if a module is not found, what can I check?",
      "P-task": "rsync : modul found check",
      "F_verb": "find",
      "P-body": "You are both allowing and denying all possible hosts from that module. .  Remove the \"hosts deny = *\" line and it should work. .  You do have a \"secrets file\" defined, I hope, which contains the allowed user and the corresponding password. It looks like you don't, but perhaps you redacted some of the rsyncd.conf contents without telling us. .  ",
      "P-tags": "rsync",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_20533745",
      "task": "Cannot terminate a shell command with Ctrl+c",
      "P-task": "termin shell command ctrl+c",
      "F_verb": "terminate",
      "P-body": "It works to trap the \"INT\" signal (sent by \"Ctrl-C\") to kill the \"tail\" process. .  (I use a random value on the PID file name to at least mostly allow multiple instances to run) .  ",
      "P-tags": "sigint termin shell bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP with NP"
    },
    {
      "id": "so_15075673",
      "task": "How to set up a loop with BASH to find a directory with write permissions?",
      "P-task": "set loop bash find directori write permiss",
      "F_verb": "set",
      "P-body": "Are you required to do this with a loop? This seems like a natural fit for \"find\". In particular, the \"-perm\", \"-gid\", and \"-type\" tests would be useful here. .  Can you explain your environment in a little more detail? Are you looking for files named \"public_html\" in users' home directories? Or are you looking for files/folders in the current directory? Or something else entirely? .  Some hints for using \"find\": .   Use the \"-type d\" test to limit your results to folders Use the \"-name\" test to limit your results to things named 'public_html' Use the \"-gid\" test to limit your results to things that are in your group (the \"id -g\" command should report your group ID) Use the \"-perm -g+w\" test to limit your results to things that are group-writable  Combine all of these, and you should be able to filter out exactly what you're looking for. The man page that I linked to has an \"Examples\" section at the bottom that shows how to use the various arguments. You might also want to check out this \"find\" tutorial for more examples with explanation. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP with NP S_INF with NP"
    },
    {
      "id": "so_38059954",
      "task": "Closing pipe does not interrupt read() in child process spawned from thread",
      "P-task": "close pipe interrupt read child process spawn thread",
      "F_verb": "interrupt",
      "P-body": "This problem is caused by two fundamental principles of how \"fork\" and pipes work in Unix. a) the pipe description is reference counted. The pipe is only closed, if all pipe file descriptors pointing at its other end (referencing the descriptions) are closed. b) \"fork\" duplicates all open file descriptors of a process. .  In the above code, the following race condition might happen: If a thread switch occurs and fork is called between the \"pipe\" and \"fork\" system calls, the pipe file descriptors are duplicated, causing the write/read ends to be open multiple times. Remember that all duplicates must be closed for the EOF to be generated \u2013 which will not happen if there is another duplicate astray an unrelated process. .  The best solution is to use the \"pipe2\" system call with the \"O_CLOEXEC\" flag and to immediately call \"exec\" in the child process after a controlled duplicate of the file descriptor is created using \"dup2\": .  Note that the \"FD_CLOEXEC\" flag is not copied by the \"dup2\" system call. This way all child processes will automatically close all the file descriptors they should not receive as soon as they reach the \"exec\" system call. .  From the man-page on \"open\" on \"O_CLOEXEC\": .   O_CLOEXEC (since Linux 2.6.23) Enable the close-on-exec flag for the new file descriptor. Specifying this flag permits a program to avoid additional fcntl(2) F_SETFD operations to set the FD_CLOEXEC flag. .  Note that the use of this flag is essential in some multithreaded programs, because using a separate fcntl(2) F_SETFD operation to set the FD_CLOEXEC flag does not suffice to avoid race conditions where one thread opens a file descriptor and attempts to set its close-on-exec flag using fcntl(2) at the same time as another thread does a fork(2) plus execve(2). Depending on the order of execution, the race may lead to the file descriptor returned by open() being unintentionally leaked to the program executed by the child process created by fork(2). This kind of race is in principle possible for any system call that creates a file descriptor whose close-on-exec flag should be set, and various other Linux system calls provide an equivalent of the O_CLOEXEC flag to deal with this problem.) .   The phenomenon of all child processes suddenly exiting when one child process is killed can be explained by comparing this issue to the dining philosophers problem. In the same way as killing one of the philosophers will solve the deadlock, killing one of the processes will close one of the duplicated file descriptors, triggering an EOF in another child process which will exit in return, freeing one of the duplicated file descriptors... .  Thank you to David Schwartz for pointing this out. .  ",
      "P-tags": "pipe linux multithread c++ c",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "ul_184124",
      "task": "On Ctrl+C, kill the current command but continue executing the script",
      "P-task": "ctrl+c kill current command continu execut script",
      "F_verb": "kill",
      "P-body": "The \"continue\" keyword doesn't mean whatever you think it means. It means continue to the next iteration of a loop. It makes no sense outside of a loop. .  I think you're looking for .  Since you don't want to do anything upon reception of the signal (beyond killing the foreground job), put no code in the trap. You need a non-empty string, because the empty string has a special meaning: it causes the signal to be ignored. .  ",
      "P-tags": "trap signal shell bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "su_582669",
      "task": "Internet sharing between windows 7 (connected over wifi) and unbuntu (tethered over mobile phone)",
      "P-task": "internet share window 7 connect wifi unbuntu tether mobil phone",
      "F_verb": "connect",
      "P-body": "Sorry for taking a bit to be back: .   Share from Ubuntu .   Click the Network Icon (mine: ) .  Click \"Edit\" .    .   Highlight your \"Wired Connection\" (It's your ethernet), select \"Edit\"   .   Select the \"IPv4 Settings\" tab, change the \"Method\" to \"Shared to other computers\"   .  Then all you need to do is connect an Ethernet between Ubuntu and whatever computer/object with an Ethernet that needs connectivity. Should have all the other settings already in place for that. .  ",
      "P-tags": "wireless-network ubuntu windows-7",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V over NP"
    },
    {
      "id": "au_497749",
      "task": "make the line bold or highlight on find command on vim",
      "P-task": "make line bold highlight find command vim",
      "F_verb": "make",
      "P-body": "The easiest way to do this is may be to toggle cursorline: .  and perhaps turn it off when you are done searching. To turn it off issue: .  In the vimtips pages you will find more ideas including setting up a function key or other keyboard shortcut to do the above. .  This is for the part where you say \".. and the cursor points to ..\". To highlight all the lines where foo occurs in the document you might consider using ack.vim. It may take a little bit of time to figure out how to install it, but you can do something like: .  and a new window will open with all the lines where foo appears. .  ",
      "P-tags": "vim",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP on NP on NP"
    },
    {
      "id": "so_42632940",
      "task": "sort command not working as expected for uppercase letters followed by underscore",
      "P-task": "sort command work expect uppercas letter follow underscor",
      "F_verb": "follow",
      "P-body": "Underscore is ASCII \"95\" and that comes after all the uppercase letters (\"A-Z\") i.e. \"65-90\". So in sorting uppercase letters will always come before \"_\". .  If you want to delimit at \"_\" then you can use \"-t _\" to get your expected output: .  Reason why your \"sort\" command worked with lowercase letters is because lowercase letters come after \"_\" i.e. \"97-122\" .  ",
      "P-tags": "sort collat collat bash",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V by NP"
    },
    {
      "id": "ul_225247",
      "task": "sed command to delete variable number of lines",
      "P-task": "sed command delet variabl number line",
      "F_verb": "delete",
      "P-body": "Your variable syntax is wrong. A variable is dereferenced as \"${n}\". Hence, try .  ",
      "P-tags": "sed shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "au_976821",
      "task": "\"sudo apt-get purge mysql\" Failing on Ubuntu 16.04 LTS",
      "P-task": "sudo apt-get purg mysql fail ubuntu 16 04 lt",
      "F_verb": "get",
      "P-body": "I had the same issue as you. For me the solution was to remove package using dpkg: .  Hope it helps you... .  ",
      "P-tags": "dpkg apt package-manag mysql",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_20206677",
      "task": "Bash scripting: find variable with lowest value",
      "P-task": "bash script : find variabl lowest valu",
      "F_verb": "find",
      "P-body": "From your question I don't think your values are in an array and that you want to know which index in the array is smallest - I think your values are in individual variables and you want to know the name of the variable containing the smallest value. If that is really what you are asking try this: .  ",
      "P-tags": "variabl min bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "so_61940170",
      "task": "PowerShell - What is the difference between the `begin` block and anything outside?",
      "P-task": "powershel - differ begin block anyth outsid",
      "F_verb": "begin",
      "P-body": "See is these provide any edification: .   About Language Keywords .  Piping Objects to Functions .  You can control how a function processes input from the pipeline using Begin, Process, and End keywords. .  Windows PowerShell Cookbook, 3rd Edition by Lee Holmes .   Like pipeline-oriented functions, the Foreach-Object cmdlet lets you define commands to execute before the looping begins, during the looping, and after the looping completes: .   Understanding PowerShell Begin, Process, and End blocks .  Advanced PowerShell Functions: Begin to Process to End .   One more thing:  .   as per Don Jones a PowerShell mvp, he says, then PROCESS block is only used when the command is run using pipeline input. In that case, objects are bound to input parameters one at a time, and PROCESS is executed. If you just run the script straight, meaning with no pipeline input, then PROCESS is ignored. .   So, if we look at the defined goals of the implementation specifics, we have: .   Begin  .  This block is used to provide optional one-time pre-processing for the function. The PowerShell runtime uses the code in this block one time for each instance of the function in the pipeline. .  Process  .  This block is used to provide record-by-record processing for the function. This block might be used any number of times, or not at all, depending on the input to the function. For example, if the function is the first command in the pipeline, the Process block will be used one time. If the function is not the first command in the pipeline, the Process block is used one time for every input that the function receives from the pipeline. If there is no pipeline input, the Process block is not used. .  A Filter is a shorthand representation of a function whose body is composed entirely of a process block. .  This block must be defined if a function parameter is set to accept pipeline input. If this block is not defined and the parameter accepts input from the pipeline, the function will miss the values that are passed to the function through the pipeline. .  Also, if the function/cmdlet supports confirmation requests (the -SupportsShouldProcess parameter is set to $True), the call to the ShouldProcess method must be made from within the Process block. .  End  .  This block is used to provide optional one-time post-processing for the function. .   ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "au_262941",
      "task": "How do I completely remove phpmyadmin?",
      "P-task": "complet remov phpmyadmin",
      "F_verb": "remove",
      "P-body": "You might want to try \"sudo dpkg-reconfigure phpmyadmin\" .  ",
      "P-tags": "phpmyadmin php",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_440364",
      "task": "How to resolve 'System has not been booted with systemd as init system (PID 1). Can't operate'",
      "P-task": "resolv system boot systemd init system pid 1\noper",
      "F_verb": "resolve",
      "P-body": "To start and stop services without having to worry about which init system is in use, you should use \"service\": .  will use whatever command is appropriate to start the \"openvas\" service. .  ",
      "P-tags": "systemd",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_50229374",
      "task": "How can I install libstdc++6 for my app on Heroku?",
      "P-task": "instal libstdc++6 app heroku",
      "F_verb": "install",
      "P-body": "I got it. .  Upgraded Heroku app to latest stack ( \"heroku-18\" instead of default \"heroku-16\" ) using Heroku CLI .  Then I had to make a git push so that the app is rebuilt with new stack. .  Now it works. .  Yes, \"heroku-18\" is beta, but as long as it works, I don't mind. .  ",
      "P-tags": "execut lib heroku linux sudo",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "ul_631630",
      "task": "Removing multiple files with same prefix (argument list too long)",
      "P-task": "remov multipl file prefix argument list long",
      "F_verb": "remove",
      "P-body": "Lets assume we have this test data set of test files: .  Delete all files starting with \"index.php\": .  Then test files looks like: .  Delete those with something added after \".php\" extension (like \"lindex.php.foo\") but keep \"index.php\": .  Then test data shows: .  Instead using \"-delete\" option you can also choose \"xargs\" to delete files in parallel. Sometimes for big file collection to delete this can speedup whole process but not always. .  Run \"rm\" command on every core/cpu with max \"100\" files per \"rm\" invocation: .  ",
      "P-tags": "file-manag command-lin",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_239415",
      "task": "How to convert awk one-liner to standalone script?",
      "P-task": "convert awk one-lin standalon script",
      "F_verb": "convert",
      "P-body": "Syntax is unchecked and unexamined, so i have no idea what it does or if it works. I have just reformatted the one-liner as a standalone awk script and added some whitespace to improve readability. If the original one-liner worked, this should too. if not, it won't. .  Save it to a file (e.g. \"myscript.awk\"), make it executable (\"chmod +x myscript.awk\") and run it as: .  ",
      "P-tags": "awk gawk",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_26114207",
      "task": "How to move right or left by 'x' characters in Bash?",
      "P-task": "move right left x charact bash",
      "F_verb": "leave",
      "P-body": "What about ditching emacs mode and switching to vi mode editing? .  and you have all the power of vi-like command line editing, like \"3l\" to go left three characters and \"5B\" to go back 5 words. The Pos 1 key then becomes \"0\" and End becomes \"$\". .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V by NP in NP"
    },
    {
      "id": "au_944239",
      "task": "\"google-chrome <file>\" downloads the file instead of opening it",
      "P-task": "google-chrom file download file instead open",
      "F_verb": "download",
      "P-body": "The original answer: .  The browser itself cannot run PHP code. You need a web server to interpret a PHP file as web page, that can be displayed through the browser.  .  If it is a \".html\" file, it will be displayed. Try to create simple HTML file as next and call it \"index.html\", for example: .  Then run: .  Something more, if you type \"google-chrome ind\" and then press Tab the rest part of the file name (\"ex.html\") will be autocomplete. But if it is \"index.php\" the autocompletion will not work. .   More detailed answer: .  The browsers their-self cannot run PHP code. Mainly they work with HTML and some scripting languages as JS. That we see in the browser's window is a result of the interaction between the web server on the one hand and the client's web browser on the other hand.  .  The PHP code is executed onto the server side and there must be installed interpretation program - so called \"php\". Within Ubuntu, with installed \"php\", if we have a simple PHP scenario, to display it into the browser's window we don't need a web server: .   Let's assume we have this file: .   The output of its interpretation is: .   So, we can redirect the output to a new file and then we can run this new file via the browser: .  * In my case it is \"chromium-browser\" instead of \"google-chrome\". .  The result will be: .   .    Partly related topic: How can i display php/html code output into terminal not browser? .  ",
      "P-tags": "google-chrom",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of S_ING"
    },
    {
      "id": "au_379090",
      "task": "How to disable screen lock timeout from a script?",
      "P-task": "disabl screen lock timeout script",
      "F_verb": "disable",
      "P-body": "Partial answer (I didn't try to change configuration)  .  I think that new Ubuntu(s) use \"dconf\" and not \"gconf\" --- try to look for parameters in \"dconf-editor\" (settable via command line with the confusing-named \"gsettings\").  .  I think that the relevant schemas are around \"org.gnome.desktop.screensaver\", at least for gnome. I do not have Unity installed so I think you need to research a bit around to adapt...  .  ",
      "P-tags": "script lock-screen",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP from NP"
    },
    {
      "id": "au_1177275",
      "task": "add accented character to american keyboard",
      "P-task": "add accent charact american keyboard",
      "F_verb": "add",
      "P-body": "following the below posts and warnings in it.. proceed with your own.. .  remap Caps + L to dash Keyboard (including on screen keyboard) doesn't work .  you need to edit your symbols like below in the file \"/usr/share/X11/xkb/symbols/us\" after taking backup of the same.. .  gnome-shell refresh with Alt+F2rEnter or Logout & Login may be required..not tested.. .  then you need to choose which key is for level3 from \"gnome-tweaks\" or via \"dconf-editor\" or via \"command line\" .  Gnome-Tweaks way  .  Dconf-Editor way  .  Command line: .  ",
      "P-tags": "key-bind keyboard",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_2206946",
      "task": "How can I tell bash to properly escape expanded strings?",
      "P-task": "tell bash properli escap expand string",
      "F_verb": "tell",
      "P-body": "you put quotes in your variables. this way you preserve the space. Also, there's no need to use external command \"basename\". the shell can do that for you. assuming you are using bash) .  ",
      "P-tags": "escap bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_428958",
      "task": "find can't list all files",
      "P-task": "find list file",
      "F_verb": "find",
      "P-body": "If you\u2019re looking for all files whose paths contain \"x86-64-linux-gnu\", you need to use \"-path\", not \"-name\": .  \"-name\" only matches against the base file name, whereas \"-path\" matches against the full path (as constructed by \"find\", so starting with one of the initial paths given on the command line). Looking at the output of your first command will illustrate this: .  You\u2019ll see files and directories matching \"x86_64-linux-gnu\" themselves, such as \"/usr/include/x86_64-linux-gnu\", \"/usr/lib/ccache/x86_64-linux-gnu-g++\", \"/usr/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so\", but not \"/usr/include/x86_64-linux-gnu/curl\" which your \"grep\" variant or the \"-path\" variant above do match. .  These two expressions and their appropriate use are discussed in detail in the \"find(1)\" manpage (as always, look at \"man find\" on your own system first). .  ",
      "P-tags": "grep find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_154838",
      "task": "Where should I mount a disk to store backups?",
      "P-task": "mount disk store backup",
      "F_verb": "mount",
      "P-body": "For a permanently attached disk for storing backups of other hosts, \"/var/bacula\" is fine; \"hier(7)\" says \"/var\" is for \"multi-purpose log, temporary, transient and spool files\" (emphasis mine). Backups by their very nature change over time, making \"/var\" a good choice. \"MySQL\", on some platforms, is configured to use \"/var\" as its primary storage, for example. .  Alternatively, you could mount it at \"/usr/local/bacula\" to follow the FreeBSD convention of putting software installed from ports, and its associated configuration and data files, under \"/usr/local\". On the other hand, I have my backups stored under a new top-level directory, \"/data\", which also contains my NFS and SMB shares. .  ",
      "P-tags": "mount directory-structur bacula freebsd",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP to NP"
    },
    {
      "id": "so_33888815",
      "task": "How to start Access from Commandline in regular mode",
      "P-task": "start access commandlin regular mode",
      "F_verb": "start",
      "P-body": "Problem 1: To not open the database read-only, don't specify the \"/ro\" switch. :) .  Problem 2: A general suggestion is to avoid macros as far as possible. Generally, a database should have one macro, that is \"AutoExec\". .  Although with a quick test the /x switch worked for me, even if the database has a \"AutoExec\" macro. \"AutoExec\" runs first, then the /x macro. .  An alternative is the \"/cmd\" switch. You pass a string that you read in your AutoExec function with the \"Command()\" function. .  ",
      "P-tags": "command-lin ms-access excel vba shell",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_15931129",
      "task": "Sending void* object through message queue[linux]",
      "P-task": "send void object messag queue linux",
      "F_verb": "send",
      "P-body": "You specify the amount of data you are putting in the queue with the third argument of mq_send. In your case it's: .  Assuming that buf is initialized somewhere along the lines of .  Then the expression \"sizeof(buf)\" means: the size of the pointer called \"buf\". While it may work on some architectures, the proper way would be .  which means, the size of a float, multiplied by the amount of floats stored in the array. .  In which case you would put the whole array in the queue. You would also avoid the iteration and use only a constant number of messages, instead of a linear number. .  ",
      "P-tags": "c mqueue unix",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP through NP"
    },
    {
      "id": "ul_12059",
      "task": "Forcing an 'added' alias to every command",
      "P-task": "forc ad alia everi command",
      "F_verb": "force",
      "P-body": "You can record the time a command line is started and the time a prompt is displayed. Bash already keeps track of the starting date of each command line in its history, and you can note the time when you display the next prompt. .  This only gives you second resolution, and only the wall clock time. If you want better resolution, you need to use an external \"date\" command that supports the \"%N\" format for nanoseconds, and the \"DEBUG\" trap to call \"date\" before running the command to time. .  Even with the \"DEBUG\" trap, I don't think there's a way of automatically displaying processor times for each command, or being more discriminating than prompt to prompt. .   If you're willing to use a different shell, here's how to get a time report for every command in zsh (this doesn't generalize to other tasks): .  You can set \"REPORTTIME\" to any integer value, the timing information will only be displayed for commands that used more than this many seconds of processor time. .  Zsh took this feature from csh where the variable is called \"time\". .  ",
      "P-tags": "alia monitor time bash date",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_52896957",
      "task": "Provide private key passhprase (password) for Posh-SSH New-SSHSession",
      "P-task": "provid privat key passhpras password posh-ssh new-sshsess",
      "F_verb": "provide",
      "P-body": "Posh-SSH will use \"password\" to decrypt encrypted private key. .  Key passphrase and password are provided the same way (bad design, imo). I'm afraid that using two-factor key+password authentication in Posh-SSH might be difficult, if possible at all. .  ",
      "P-tags": "sftp posh-ssh private-key ssh powershel",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP for NP"
    },
    {
      "id": "so_69647261",
      "task": "PowerShell - how to escape {} in JSON string for a REST call",
      "P-task": "powershel - escap json string rest call",
      "F_verb": "escape",
      "P-body": "Let Powershell do all the work for you and don't build the JSON string yourself, use an object: .  All special characters will be escaped automatically. .  Credits to @Hazrelle, of course you don't even have to convert anything in this case, as \"Invoke-WebRequest\" will do that for you: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V in NP for NP"
    },
    {
      "id": "so_46682714",
      "task": "How does this function return its value?",
      "P-task": "function return valu",
      "F_verb": "return",
      "P-body": "It's .  StreamReader.ReadToEnd() method outputs string and since it's result is not assigned to variable it will be the function output. .  Idiomatic way would be to write it like this: .  ",
      "P-tags": "powershel function",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_367853",
      "task": "How to repair GRUB from backup?",
      "P-task": "repair grub backup",
      "F_verb": "repair",
      "P-body": "First, try disabling Secure Boot. If it's enabled, some versions of GRUB can't boot Windows. This is a GRUB bug. .  If that doesn't help, try installing my rEFInd boot manager. You can try the USB flash drive or CD-R image without installing it, if you like; or dive in all the way by installing the Debian-package version in Ubuntu. Note that the USB flash drive/CD-R version will boot Ubuntu correctly only if you do not have a separate \"/boot\" partition or if you manually edit your kernel options.) rEFInd is less finicky about booting Windows than is GRUB, so it's more likely to work if GRUB gives you problems. .  If you prefer to stick to GRUB, that may be possible, but you'll need to provide more details about what's not working, like any error messages you're getting, whether you see a Windows logo appear, etc. .  Sometimes this problem can be caused by a missing Windows boot loader. Typically you'll get some variety of \"file not found\" message, or rEFInd won't show a Windows option at all, if this is the case.) You'll need to either restore the Windows boot loader files from a backup or use a Windows emergency disc to re-install the files to fix this problem. .  ",
      "P-tags": "uefi boot-repair grub-efi grub2",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_71481",
      "task": "How to use socks proxy for commands in Terminal such as youtube-dl?",
      "P-task": "use sock proxi command termin youtube-dl",
      "F_verb": "use",
      "P-body": "Youtube-dl doesn't support a SOCKS proxy. There's a feature request for it, with links to a couple of working proposals. .  Youtube-dl supports HTTP proxies out of the box. To benefit from this support, you'll need to run a proxy on \"myserver.com\". Pretty much any lightweight proxy will do, for example tinyproxy. The proxy only needs to listen to local connections (\"Listen 127.0.0.1\" in \"tinyproxy.conf\"). If the HTTP proxy is listening on port 8035 (\"Port 8035\"), run the following ssh command: .  and set the environment variables \"http_proxy\" and \"https_proxy\": .  ",
      "P-tags": "http-proxi sock proxi ssh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP in NP as NP"
    },
    {
      "id": "so_36657425",
      "task": "Content is not allowed in prolog - exception happens in Unix but not in Windows with same code",
      "P-task": "content allow prolog - except happen unix window code",
      "F_verb": "allow",
      "P-body": "Sounds like a character-set issue, the XML prolog might be .  and if your *nix install, for whatever reason, doesn't support UTF then the file is not going to be formatted correctly. Could it be when you created/copied the document to *nix that the character set got screwed up and isn't the UTF-8 you expected? Might make sense to examine the file with a hex editor on both platforms. .  I know I've run into this before, though usually the other way, but I don't have a current example where it doesn't work, just know it was a character set issue. .  ",
      "P-tags": "unix sax dom pars java",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V in NP"
    },
    {
      "id": "au_30655",
      "task": "What keyboard layout allows me to type \u00e7?",
      "P-task": "keyboard layout allow type",
      "F_verb": "allow",
      "P-body": "Using keyboard layout \"USA - intl (AltGr dead keys)\", I can get \u00e7 or \u00c7 by pressing: .   AltGr + ,: \"\u00e7\" AltGr + Shift + ,: \"\u00c7\"  ",
      "P-tags": "keyboard-layout",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_282597",
      "task": "how to bind a command when fish shell is started",
      "P-task": "bind command fish shell start",
      "F_verb": "bind",
      "P-body": "You want to put your bindings in \"fish_user_key_bindings\". See this answer for some more detailed instructions. .  ",
      "P-tags": "fish",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP when S"
    },
    {
      "id": "so_52293871",
      "task": "powershell performance: Get-ChildItem -Include vs. Get-ChildItem | Where-Object",
      "P-task": "powershel perform : get-childitem -includ vs get-childitem where-object",
      "F_verb": "get",
      "P-body": "\"Get-ChildItem\" is a provider cmdlet - that means that a bulk of its actual work is offloaded to an underlying provider, likely the \"FileSystem\" provider in your case. .  The provider itself doesn't actually support the \"-Include\"/\"-Exclude\" parameters, that's one of the few things that the cmdlet takes care off - and for the file system provider this is ultra heavy double-work, because the cmdlet needs to recurse down through the file system hierarchy to figure out whether it needs to apply an exclusion or an inclusion based on a parent directory name, you can see how this is implemented here. .  So by using \"-Include\" against the file system provider, you're asking PowerShell to do an immense amount of double work. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_1709",
      "task": "How to fix Ctrl + arrows in Vim?",
      "P-task": "fix ctrl + arrow vim",
      "F_verb": "fix",
      "P-body": "Figure out exactly what escape sequence your terminal sends for Ctrl+arrow by typing Ctrl+V, Ctrl+arrow in insert mode: this will insert the leading \"ESC\" character (shown as \"^[\" in vim) literally, followed by the rest of the escape sequence. Then tell vim about these escape sequences with something like .  I seem to recall that Putty has a default setting for Application Cursor Keys mode that's inconvenient (I forget why), you might want to toggle this setting first. .  Note that although escape sequences vary between terminals, conflicts (i.e. an escape sequence that corresponds to different keys in different terminals) are rare, so there's no particular need to try to apply the mappings only on a particular terminal type. .  ",
      "P-tags": "linux putti vim keyboard",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "su_840361",
      "task": "How to recover from an \"umount -a -l\"",
      "P-task": "recov umount -a -l",
      "F_verb": "recover",
      "P-body": "After Booting live, I mounted my partition /dev/sda6 .  then I saw with \"du\" a 9.0G file called /mnt/dev/sda. .  \"head /mnt/dev/sda | cat -e\" revealed that it was full of \"^@\" which is null in caret notation .  This file was the result of my fail. .  In fact when I ran \"dd if=/dev/zero of=/mnt/sdb2\" I did something wrong (mistype, \"of=/dev/sda\", ...) and filled my disk with zeros .  after removing this file everything was ok since disk was not full. .  ",
      "P-tags": "linux umount",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V from NP"
    },
    {
      "id": "so_6520215",
      "task": "Where is this script going wrong",
      "P-task": "script go wrong",
      "F_verb": "go",
      "P-body": "because of .  ",
      "P-tags": "awk bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP"
    },
    {
      "id": "au_1291126",
      "task": "Binding google-chrome tabs to certain workspaces in i3-wm",
      "P-task": "bind google-chrom tab certain workspac i3-wm",
      "F_verb": "bind",
      "P-body": "What worked for me was using the class and instance(string before the comma in WM-CLASS when using xprop) when binding the tab(instance) to a workspace. .  For netflix for example, I first went to netflix and clicked on the 3 dots next to the address bar in google-chrome and then More tools>Create shortcut. This creates a shorcut of the instance of google-chrome for the URL on your desktop. .  You can check the properties of the dektop shortcut using any file manager and copy the contents of the command section and paste it in your key-binding line after exec in your i3config like so: .  Use the binding to summon the instance, run xprop in the terminal and click on the instance window to pull the details. Mine returned: .  Then simply use the string before the comma as the instance and the string following the comma as the class, like so: .  Hope this helps who was just as stuck as I was. :) .  ",
      "P-tags": "google-chrom tile i3-wm",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_8140439",
      "task": "Why would it be impossible to fully statically link an application?",
      "P-task": "would imposs fulli static link applic",
      "F_verb": "link",
      "P-body": "Function calls that need access to NSS or iconv need access will open other libs dynamically, since NSS needs plugins to work (the helper modules like pam_unix.so). When the NSS system dlopens these modules, there will be two conflicting versions of glibc - the one your program brought with it (statically compiled in), and the one \"dlopen()\"ed by NSS dependencies. Shit will happen. .  This is why you can't build static programs using getpwnam_r and a few other functions.  .  ",
      "P-tags": "static-link linux linker",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "au_678361",
      "task": "Run node js server in ubuntu",
      "P-task": "run node js server ubuntu",
      "F_verb": "run",
      "P-body": "From our discussion here .  After installing \"node.js\" and \"npm\" .  Create a symbolic link for node: .  Now verify commands working with .  Run it by using, .  \"node hello.js\" .  In order to test the application, open another terminal session and connect to your web server. Be sure to substitute in the app server's private IP address for APP_PRIVATE_IP_ADDRESS, and the port if you changed it: .  \"curl http://APP_PRIVATE_IP_ADDRESS:8080\" .  reference here .  ",
      "P-tags": "software-instal nodej",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_56493882",
      "task": "Executing multiple commands over SSH \"exec\" channel on firewall device with Java JSch does not work",
      "P-task": "execut multipl command ssh exec channel firewal devic java jsch work",
      "F_verb": "execute",
      "P-body": "The \"exec\" channel on your device seems to be implemented incorrectly. So you cannot use your code with the \"exec\" channel. As you can \"ssh\" to the device, it seems that the \"shell\" channel is fully working. Try talking to your server administrator, to get the server fixed. .  If fixing the server is not feasible, you will have to revert to using the \"shell\" channel, although it is generally not the correct way to implement command automation. See What is the difference between the 'shell' channel and the 'exec' channel in JSch .  JSch by default enables terminal emulation for the \"shell\" channel, what will bring lot of unwanted side effects (see Getting unwanted characters when reading command output from SSH server using JSch). You may need to disable that by calling \"setPty\". .  ",
      "P-tags": "shell ssh java jsch",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP with NP"
    },
    {
      "id": "so_48011959",
      "task": "How to run a TestNG.xml through a Shell Script in Jenkins?",
      "P-task": "run testng xml shell script jenkin",
      "F_verb": "run",
      "P-body": " I referred to the link for setting classpath syntax as above. .  This is the command I have given in the Execute Shell Command field for the Jenkins Configuration and it did work! .  ",
      "P-tags": "testng batch-fil jenkin shell java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP through NP in NP"
    },
    {
      "id": "ul_126075",
      "task": "Getting 256 colors to work in terminal multiplexer",
      "P-task": "get 256 color work termin multiplex",
      "F_verb": "get",
      "P-body": "Well as you quite correctly guessed \"setf\" is not correct capability for setting foreground color in context of \"xterm-256color\"(\"screen-256color\") terminfo entry. You should use \"setaf\" (set foreground color using ANSI escape). .  Note: .   you should not need to do \"alias tmux='TERM=xterm-256color tmux'\", make sure your terminal emulator when started reports correct value of \"TERM=xterm-256color\" if (1) is true then \"tmux\" will correctly set your \"TERM\" to \"screen-256color\" inside it, also it will for example correctly set it if you are running on linux console to \"screen.linux\", there might be case you need to manipulate it but generaly not  ",
      "P-tags": "color termin tmux gnu-screen",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF in NP"
    },
    {
      "id": "ul_296247",
      "task": "When I redirect the output of ls to a file, the filename is included in that file. How can I avoid this?",
      "P-task": "redirect output ls file filenam includ file\navoid",
      "F_verb": "redirect",
      "P-body": "As you've noticed, the file is created before \"ls\" is run. This is due to how the shell handles its order of operations. In order to do .  the shell needs to create \"file\" and then set stdout to point to that and the finally run the \"ls\" program. .  So you have some options. .   Create the file in another directory (eg \"/tmp\") and then \"mv\" it to the final directory Create it as a hidden file (\".file\") and rename it Use \"grep\" to remove the file from the output Cheat :-)  The cheat would be something like .  This causes the output of \"ls\" to be held in a variable, and then we write that out. .  ",
      "P-tags": "ls command-lin io-redirect shell",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "so_7480500",
      "task": "Interpreting gdb output",
      "P-task": "interpret gdb output",
      "F_verb": "interpret",
      "P-body": "Are \"filename1\" and \"filename\" both valid pointers to null-terminated strings? The most common reason you might get a segfault with that is if your pointer wasn't properly initialized or if one of the strings isn't null-terminated (possibly because of a buffer overflow) and thus is resulting in \"strlen()\" trying to read past the size of the allocated memory. .  ",
      "P-tags": "linux c gdb",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_69837759",
      "task": "XML Powershell get and remove element node",
      "P-task": "xml powershel get remov element node",
      "F_verb": "get",
      "P-body": "Use the \"local-name()\" XPath function to filter on the \"xsi:type\" attribute by it's local name (\"type\"): .  ",
      "P-tags": "powershel xml",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "su_1067532",
      "task": "Rsync --checksum does not catch changed files",
      "P-task": "rsync -- checksum catch chang file",
      "F_verb": "catch",
      "P-body": "\"--checksum\" on its own is not enough, and only worked when using rsyncd.  .  I figured out how to do delta transfers with rsync over ssh using these three parameters. works great now, fixing corrupt transfers. .  \"rsync -av --checksum --inplace --no-whole-file user@server:/source/ /destination/\" .  ",
      "P-tags": "ubuntu rsync maco",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP"
    },
    {
      "id": "so_60982134",
      "task": "Failied to :make install: Linux kernel module SSL error",
      "P-task": "faili : make instal : linux kernel modul ssl error",
      "F_verb": "make",
      "P-body": "Seems there is some SSL error in default KDE's linux kernel. When i upgraded to newer custom kernel I hadn't ssl error .  also this may help you .  ",
      "P-tags": "linux-device-driv linux openssl linux-kernel",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_1332498",
      "task": "code-server cannot find nodejs",
      "P-task": "code-serv find nodej",
      "F_verb": "find",
      "P-body": "I found this question searching the same. .  I fixed it copying my node installation in the path that code-server search node. .  I have code-server in \"/usr/lib/code-server/bin/code-server\" (because I used the installation script), if I search my node installation with \"whereis node\", reports \"node: /usr/bin/node\". .  Such my error was \"/usr/lib/code-server/bin/code-server: 36: exec: /usr/lib/code-server/lib/node: not found\", I copied \"/usr/bin/node\" in \"/usr/lib/code-server/lib/node\" and it works now. .  Maybe for you works \"sudo cp /usr/bin/nodejs /usr/lib/node\" .  ",
      "P-tags": "raspberrypi server visual-studio-cod nodej",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "au_1089610",
      "task": "Disabling desktop icons in Ubuntu 18.04",
      "P-task": "disabl desktop icon ubuntu 18 04",
      "F_verb": "disable",
      "P-body": "GConf is obsolete and it has been replaced by \"dconf\"/\"gsettings\". To disable desktop icons run the following command in Terminal. .  For a GUI alternative use \"dconf-editor\" instead of \"gconf-editor\", navigate to \"/org/gnome/desktop/background/\", and disable \"show-desktop-icons\" option. .  Alternatively, use GNOME Tweaks (\"gnome-tweaks\") to turn off the \"Show Icons\" option in the Desktop tab. .   .  ",
      "P-tags": "icon 18 04 configur gnome-shel",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP in NP"
    },
    {
      "id": "au_972489",
      "task": "Arc Menu GNOME extension won't install in Ubuntu 17.10",
      "P-task": "arc menu gnome extens instal ubuntu 17 10",
      "F_verb": "install",
      "P-body": "Arc Menu depends on \"gir1.2-gmenu-3.0\" package. Install it first by running the following command in Terminal .  ",
      "P-tags": "gnome-shell-extens 17 10 gnome-shel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V in NP"
    },
    {
      "id": "ul_516931",
      "task": "How do I install Wine on Fedora 20?",
      "P-task": "instal wine fedora 20",
      "F_verb": "install",
      "P-body": "Try first adding repositories  .  If not work try upgrading to latest fedora it supports lot of new libraries .  ",
      "P-tags": "fedora wine",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_8211844",
      "task": "Get exit code for command in bash/ksh",
      "P-task": "get exit code command bash ksh",
      "F_verb": "get",
      "P-body": "Below is the fixed code: .  Now if you look into this code few things that I changed are: .   use of \"typeset\" is not necessary but a good practice. It make \"cmnd\" and \"ret_code\" local to \"safeRunCommand\" use of \"ret_code\" is not necessary but a good practice to store return code in some variable (and store it ASAP) so that you can use it later like I did in \"printf \"Error : [%d] when executing command: '$command'\" $ret_code\" pass the command with quotes surrounding the command like \"safeRunCommand \"$command\"\". If you dont then \"cmnd\" will get only the value \"ls\" and not \"ls -l\". And it is even more important if your command contains pipes. you can use \"typeset cmnd=\"$*\"\" instead of \"typeset cmnd=\"$1\"\" if you want to keep the spaces. You can try with both depending upon how complex is your command argument. eval is used to evaluate so that command containing pipes can work fine  NOTE: Do remember some commands give 1 as return code even though there is no error like \"grep\". If \"grep\" found something it will return 0 else 1.  .  I had tested with KSH/BASH. And it worked fine. Let me know if u face issues running this. .  ",
      "P-tags": "ksh exit unix bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_31769432",
      "task": "Parse /proc/mounts and substitude only one field",
      "P-task": "pars proc mount substitud one field",
      "F_verb": "parse",
      "P-body": "fix .    use printf ( to avoid the implicit linefeed ) add whitespace to separate the printf from the gsub output   adjusted command .  input.txt .  output .  ",
      "P-tags": "awk substitut bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_10019466",
      "task": "how do you search for a particular keyword within a php file?",
      "P-task": "search particular keyword within php file",
      "F_verb": "search",
      "P-body": " ",
      "P-tags": "cento linux ssh",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V for NP within NP"
    },
    {
      "id": "so_60027858",
      "task": "MERGE 2 csv files removing duplicates using BASH or Awk",
      "P-task": "merg 2 csv file remov duplic use bash awk",
      "F_verb": "merge",
      "P-body": "If you don't care about output order then using GNU sort for \"-s\": .  If you do care then you'd have to tell us what that output order should be as it's not obvious in your question. .  ",
      "P-tags": "awk csv merg shell bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP using NP"
    },
    {
      "id": "so_50013031",
      "task": "Compare files content and delete shorter ones",
      "P-task": "compar file content delet shorter one",
      "F_verb": "compare",
      "P-body": "Anybody interested in such Perl script will be happy. I assume that we have the script in current folder with *.txt files. If the file is the same as any other but longer or shorter, so there is some data in one of the files that makes it longer but not different for the front part, then the shorter file will be removed. For 1.3MB and 1300 files it took Cygwin Perl under 2 minutes to go through all files. Files are compared line by line. Script below: .  Please be aware that encoding of the files and line endings may differ, so all the files, for example, should be UTF-8 encoded and line endings should be the same - LF. .  ",
      "P-tags": "file cygwin linux",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "so_18854354",
      "task": "How to deny access to port 80 of the server to everyone except ip 192.168.0.36?",
      "P-task": "deni access port 80 server everyon except ip 192 168 0 36",
      "F_verb": "deny",
      "P-body": "You may try like this:- .  ",
      "P-tags": "linux network iptabl",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP to NP of NP to NP"
    },
    {
      "id": "ul_210766",
      "task": "Why does sed replace all occurrences instead of only the first occurrence?",
      "P-task": "sed replac occurr instead first occurr",
      "F_verb": "replace",
      "P-body": "sed processes input line by line. The \"/g\" modifier influences whether it replaces all the occurrences on a line, or only the first one: .  To replace only the first occurrence in the file, use something like the following: .  ",
      "P-tags": "sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP of NP"
    },
    {
      "id": "so_2182468",
      "task": "Run cronjob as user to change desktop background in Ubuntu",
      "P-task": "run cronjob user chang desktop background ubuntu",
      "F_verb": "run",
      "P-body": "bug: https://bugs.launchpad.net/ubuntu/+source/gconf/+bug/285937 .  my version: .  and it's works on Fedora 12 .  ",
      "P-tags": "cron shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP S_INF in NP"
    },
    {
      "id": "ul_609919",
      "task": "Unable to decrypt a file with the public signature",
      "P-task": "unabl decrypt file public signatur",
      "F_verb": "decrypt",
      "P-body": "\"cert.pem\" is a certificate. A certificate contains a public key, but it is not a public key. You need to extract the public key from the certificate. .  Alternatively, use \"pkeyutl\", which has two benefits: it also works on other public key schemes (e.g. ECDSA), and it has an option to extract the public key from the certificate. .  ",
      "P-tags": "openssl",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP with NP"
    },
    {
      "id": "so_15138782",
      "task": "How to extract the first column from a file with tab-separated columns",
      "P-task": "extract first column file tab-separ column",
      "F_verb": "extract",
      "P-body": "You could use .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP with NP"
    },
    {
      "id": "au_793932",
      "task": "How to assign a certain keyboard shortcut to paste specific item?",
      "P-task": "assign certain keyboard shortcut past specif item",
      "F_verb": "assign",
      "P-body": "The command to get a fixed string into the clipboard is very easy, it's simply .  or if you want to read the string from a file .  or from a command output .   Directly writing a fixed string by emulating keypresses is not much more complex though .  or if you want to read the string from a file .  or from a command output .   You can simply create a custom shortcut in the System Settings \u2192 Keyboard \u2192 Shortcuts configuration and assign a command to the key combination you wish. .  But take care that the shortcut interpreter is not Bash or a similar shell, so our \"<<<\" (\"here string\" syntax) or \"|\" pipes will not work. To solve this anyway, we simply enclose our shell command with \"bash -c \"INSERT COMMAND HERE\"\". Just pay attention that you don't use double quotes inside the command then. .  Here are the commands how you would have to enter them into the shortcut settings: .   Copy \"my string\" to clipboard: .   Copy content of \"my-file.txt\" to clipboard: .   Copy output of \"my-command\" to clipboard: .   Directly paste/write \"my string\": .   Directly paste/write content of \"my-file.txt\": .   Directly paste/write output of \"my-command\": .     Please note that neither \"xsel\"nor \"xvkbd\" are installed by default, so you probably need to install them first using this command: .  ",
      "P-tags": "shortcut-key custom clipboard",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_355047",
      "task": "Add image to 3GP file and convert it to MP4 using avconv por ffmpeg",
      "P-task": "add imag 3gp file convert mp4 use avconv por ffmpeg",
      "F_verb": "add",
      "P-body": "i find answer ; it is the same thing such as MP3 file , however you should use \"-oac pcm\" instead of \"-oac copy\" .  the output file is;  .  ",
      "P-tags": "ffmpeg avconv soundconvert",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_21959944",
      "task": "Implementing a simple shell",
      "P-task": "implement simpl shell",
      "F_verb": "implement",
      "P-body": "First of all, your \"fgets\" is reading to a single character \"buff\". You should read into a buffer of characters. Second, \"fgets\" keeps the newline at the end of the read string, so you may want to remove it first, e.g.: .  You must also replace all references to \"&buff\" with \"buff\". .  In addition to this, your \"malloc\" is also wrong, and allocates one character less than is required (\"strlen\" is without the terminating NUL): .  Correspondingly your \"strncpy\" was copying one character less than required. This is what made your original code accidentally work for a single-word input because it had the effect of removing the trailing \"'\\n'\" for you in that case, but in every other case it removed the last character of the word itself. .  And the second argument to \"execvp\" should be just the \"comand\" (sic) array: .  ",
      "P-tags": "string fork shell c execvp",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_67852413",
      "task": "PIP Install file not found on Linux Servers",
      "P-task": "pip instal file found linux server",
      "F_verb": "install",
      "P-body": "I have Ubuntu 20.04.02 as well and there pip already came installed! Specifically for python3.8 and python3.9. .  When I want to install a specific library I just run that following command .  When I don't specify \"python3.8\", (and just write \"python\") it defaults to python 2.7.1 on my rig and that indeed doesn't have pip installed for some reason, but it looks like you want to install pip on python3.8. .  ",
      "P-tags": "ubuntu linux python pip",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_466584",
      "task": "Add space to partition",
      "P-task": "add space partit",
      "F_verb": "add",
      "P-body": "Yes, it's possible to merge unallocated space with \"/dev/sda1\". .   Boot from Ubuntu live disk or gparted live disk. .  Note that your unallocated space is just outside of your extended partition. Open gparted partition editor, right-click on the \"extended partition\"(\"/dev/sda2\") and select Resize/Move option. .  Move the right-arrow to extreme right, so that the unallocated space will comes under your extended partition(just below to your swap partition). .  Now right-click on your swap partition and select Resize/Move option. Move the dragger to the extreme right, so that the unallocated space would come before to your swap partition(just above to your swap). .  After that, you can be able to get out of the unallocated space from that extended partition by right-clicking on the extended partition(\"/dev/sda2\") and selecting Resize/Move option. Then shrink it's space, so that the unallocated space present inside your extended partition will get out of that. .  After doing the above step, now your unallocated space would come just above to your \"/dev/sda2\" extended partition. .  Finally, now you can be able to resize(increase the space of) your \"/dev/sda1\" partition. .   NOTE: Make sure that all the partitions are unmounted before doing the above operations. .  ",
      "P-tags": "partit 12 04 server gpart",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_58730113",
      "task": "Python cannot run in console mode",
      "P-task": "python run consol mode",
      "F_verb": "run",
      "P-body": "I think here has something to do with \"git-bash\" GUI. I cannot run it in \"git-bash\", but I can run it in windows \"cmd\". .  ",
      "P-tags": "python window consol git-bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP"
    },
    {
      "id": "so_33753245",
      "task": "How the processor itself assumes the execution time of any program?",
      "P-task": "processor assum execut time program",
      "F_verb": "assume",
      "P-body": "As commented below, apparently Linux does not have a job control scripting language, so you should probably remove that tag, as well as the C tag. .  On systems with job scheduling, there's some type of job control scripting language where the estimated run time is included in the information needed to run the job.  .  Example Wiki articles: .  http://en.wikipedia.org/wiki/Job_Control_Language .  In this case, the estimated time is specified as a job parameter:  .  for a time estimate of 10 minutes. On this web page, scroll down to the TIME parameter description: .  http://www-01.ibm.com/support/knowledgecenter/SSLTBW_2.1.0/com.ibm.zos.v2r1.ieab600/iea3b6_Parameter_definition5.htm .  Based on the description, if the time is exceeded, the operator is notified. I'm not sure what happens on unattended systems. .  ",
      "P-tags": "linux c schedul",
      "source": "qa",
      "cate": "assert/assume/guess",
      "pat": "V NP of NP"
    },
    {
      "id": "so_35559546",
      "task": "unix: Can I delete files in a directory that do not contain text?",
      "P-task": "unix : delet file directori contain text",
      "F_verb": "delete",
      "P-body": "Assuming your script is using \"#!/bin/bash\", I'd do .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP that S"
    },
    {
      "id": "ul_258293",
      "task": "how can I build Radeon proprietary drivers for CentOS 7?",
      "P-task": "build radeon proprietari driver cento 7",
      "F_verb": "build",
      "P-body": "You're missing (at least) rpmbuild tool: .  This (according to CentOS wiki) should be in \"rpm-build\" package which can be installed by running \"yum install rpm-build\". .  ",
      "P-tags": "cento proprietary-driv radeon",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "so_38771516",
      "task": "NodeJs installed but cant execute it. Messed it up with bash script",
      "P-task": "nodej instal cant execut\nmess bash script",
      "F_verb": "execute",
      "P-body": "In your script, you are trying to redirect the output of \"command -v node\" to the file \"/usr/bin/node\". That's not what you want. The script should be: .  Read more about \"/dev/null\" here: http://man7.org/linux/man-pages/man4/null.4.html .  It seems you have already overwritten the binary file \"/usr/bin/node\" with the content of the command \"command -v node\". Look at the output for the command: \"file /usr/bin/node\". It should be an \"ELF\" file. If you have \"ASCII text\" in the output, then you have indeed replaced the binary. .  ",
      "P-tags": "node js linux shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_1452496",
      "task": "Converting shell script to Objective-C CLI",
      "P-task": "convert shell script objective-c cli",
      "F_verb": "convert",
      "P-body": "If you're just moving/copying/deleting files, have you considered using \"NSFileManager\"? .  ",
      "P-tags": "command-lin objective-c shell command-line-tool nstask",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "au_60799",
      "task": "How do I install Gournal?",
      "P-task": "instal gournal",
      "F_verb": "install",
      "P-body": "Gournal looks like it stopped development in 2005 - thus the dependency in your question cannot be satisfied by the Natty packages. .  As such, you will need to download the source package (the .tar file) and extract it. .  In the folder you will see \"install\" - run this in a terminal .  This will install the perl \"gournal\" packages. .  However the application still will not start without the \"gnome2::print\" perl module.  .  You could install this from CPAN - my brief experiment with this threw-up lots of compilation issues - but the application did start. Just dont press the \"print\" button. My guess is this section in \"gournal\" will need to be rewritten/updated to use newer supported perl print routines. .  pre-requisites .  install missing perl module .  Now start the application by running \"gournal\": .   .  ",
      "P-tags": "depend perl 11 04 instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_62779284",
      "task": "PowerShell script trying to copy folders that do not exist",
      "P-task": "powershel script tri copi folder exist",
      "F_verb": "copy",
      "P-body": "Those folders exist. You can view them with \"Get-ChildItem -Path $env:USERPROFILE\\Documents -Force\". Output (excerpt): .  As you can see, they are hidden system symbolic links to directories. You cannot tell \"Copy-Item\" to omit them, but you can do it using \"robocopy\": .   \"/e\" equivalent to \"-Recurse\" (to deep copy) \"/xj\" will exclude junctions (aka symbolic links)  Read more about \"robocopy\". .  ",
      "P-tags": "powershel window",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP that S"
    },
    {
      "id": "au_633278",
      "task": "how to see specific established connections?",
      "P-task": "see specif establish connect",
      "F_verb": "see",
      "P-body": "You need to parse the output of \"netstat\". On my system, \"netstat\" doesn't display the string \"Google\" when listing hosts. So, instead of simply using \"netstat -t | grep -i Google\", you would need to lookup the name of the host. Something like: .  Explanation  \"sudo netstat -tn\" : run \"netstat\" showing only tcp connections (-t) and numerical IPs (\"-n\"); \"awk '/EST/{print $5}'\" : print the 5th field (the IP) if this line matches \"EST\" (show only established connections); \"sed 's/:.*//'\" : remove the port, leaving only the IP; \"while read ip; do ...; done\" : iterate over each IP found; \"whois $ip | grep -qi google\" : lookup the IP and search the output for \"google\". The \"-i\" means case insensitive searching and the \"-q\" suppresses output.  \"&& echo \"$ip\"\" : if the \"grep\" was successful, print this IP.  ",
      "P-tags": "network command-lin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "so_69712649",
      "task": "Bash iterate through every file but start from 2nd file and get names of 1st and 2nd files",
      "P-task": "bash iter everi file start 2nd file get name 1st 2nd file",
      "F_verb": "get",
      "P-body": "You could make it work like this: .  Not exactly sure about the call to \"function_python\" though, I have never seen that tool before (can't ask since I can't comment yet). .  ",
      "P-tags": "python loop bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_53172202",
      "task": "Issue with getting value and concatenation in PowerShell",
      "P-task": "issu get valu concaten powershel",
      "F_verb": "get",
      "P-body": "try this: .  ",
      "P-tags": "key-valu powershel concaten",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_33586465",
      "task": "is it necessary to call pthread_exit()",
      "P-task": "necessari call pthread_exit",
      "F_verb": "call",
      "P-body": "You are not required to call \"pthread_exit\". The thread function can simply return when it's finished.  .  From the man page: .   An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function's return value serves as the thread's exit status. .   ",
      "P-tags": "linux pthread c multithread",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "so_45124795",
      "task": "Executing a shell script with arguments from a python script",
      "P-task": "execut shell script argument python script",
      "F_verb": "execute",
      "P-body": "You can use .  If your string argument is multiple words, it should work fine. .  As long as the multiple words are in one string in the list passed to \"subprocess.Popen()\", it is considered one argument in the argument list for the command. .  You should not use \"shell=True\" unless you have a good reason. It can be a security problem if you aren't very careful how it is used.  .  ",
      "P-tags": "python shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP from NP"
    },
    {
      "id": "so_6441509",
      "task": "how to write a process-pool bash shell",
      "P-task": "write process-pool bash shell",
      "F_verb": "write",
      "P-body": "I chanced upon this thread while looking into writing my own process pool and particularly liked Brandon Horsley's solution, though I couldn't get the signals working right, so I took inspiration from Apache and decided to try a pre-fork model with a fifo as my job queue. .  The following function is the function that the worker processes run when forked. .  You can get a copy of my solution at Github. Here's a sample program using my implementation. .  Hope this helps! .  ",
      "P-tags": "sh multiprocess multiprocess shell bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_47224241",
      "task": "Is there any way to be notified when another process receives a signal?",
      "P-task": "way notifi anoth process receiv signal",
      "F_verb": "notify",
      "P-body": "Not in standard Unix or POSIX, you cannot be notified for signals sent to another process. See signal(7) and signal-safety(7). .  However, waitpid(2) and friends can tell you if a child process has terminated with a signal. And killpg(2) sends a signal to a process group (and kill(2) does also that with a negative target pid). And getrusage(2) can count signals (recieved by some other process). You could also use proc(5) to query information about other processes. And you might use signalfd(2) or ptrace(2) etc.... .  Signals are a very limited and poor form of inter-process communication. There are better ways. .  BTW, sigaction(2) can be used with \"SA_SIGINFO\" and then your handler gets a pointer to \"siginfo_t\" and another to \"ucontext_t\" so you get a lot of information. .  Notice that process groups and sessions are related. See also setpgid(2), setsid(2), credentials(7) and also related to terminals and pseudo-ttys (read the tty demystified and about job control).  .  I guess that your other question is about these. But you don't mention any of them there. .  ",
      "P-tags": "signal unix",
      "source": "qa",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V when S"
    },
    {
      "id": "au_1023808",
      "task": "Wine: Show the \"system menu\" of a window?",
      "P-task": "wine : show system menu window",
      "F_verb": "show",
      "P-body": "Run \"winecfg\", go to \"Graphics\", and either uncheck \"Allow the window manager to decorate the windows\" or check \"Emulate a virtual desktop\". Either way, once you've done that, close and reopen Wine, and your program will then have a Windows-style title bar, which you can right-click to get this menu. .  ",
      "P-tags": "wine",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP"
    },
    {
      "id": "so_9802247",
      "task": "script within a Makefile to find out path to a toolchain genericaly",
      "P-task": "script within makefil find path toolchain genericali",
      "F_verb": "find",
      "P-body": "There are plenty of GNU Make funcions to retrieve for example a directory name. .  Also note the use of the \":=\" assignement to compute it only once and thus avoid running the \"which\" command repeatedly. .  ",
      "P-tags": "makefil shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V out NP to NP"
    },
    {
      "id": "so_36209715",
      "task": "Compare Date from CSV Import To Get-Date",
      "P-task": "compar date csv import get-dat",
      "F_verb": "compare",
      "P-body": "Definitely some room for simplification here. .  Just cast the \"Item Date\" string as a \"[DateTime]\" with the \"-as\" operator and then compare that to your \"$CheckDate\" in the \"Where-Object\" call. .  ",
      "P-tags": "powershel csv date",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_36708306",
      "task": "How to capture a process Id and also add a trigger when that process finishes in a bash script?",
      "P-task": "captur process id also add trigger process finish bash script",
      "F_verb": "add",
      "P-body": "You can use the bash util \"wait\" once you start the process using \"nohup\" .  ",
      "P-tags": "unix background-process shell bash trigger",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP when S"
    },
    {
      "id": "so_15380838",
      "task": "Simple RSync EXCLUDE option?",
      "P-task": "simpl rsync exclud option",
      "F_verb": "exclude",
      "P-body": "i got it solved by myself after i've learned and tested many times. The real problem was the understandable (for me) \"--exclude\" option usage format. .  I don't know how others are doing but i just found out that: .   \"--exclude\" path CAN NOT be the full absolute path!  Because i was using the path(s) like: \"--exclude /var/www/html/text.txt\" which caused the thing DOES NOT work. So i used like: .  .. and it WORKS! .  ",
      "P-tags": "linux rsync",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_27906134",
      "task": "bash regexp \"find anything between last slash and dot\"",
      "P-task": "bash regexp find anyth last slash dot",
      "F_verb": "find",
      "P-body": "You can use: .  ",
      "P-tags": "bash regex",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP between NP"
    },
    {
      "id": "au_425591",
      "task": "Recovering a degraded RAID array",
      "P-task": "recov degrad raid array",
      "F_verb": "recover",
      "P-body": "First things first: I would recommend making a bit copy of the disk, e.g. using ddrescue, and then working on the disk image, not on the physical disk. This might save you some headache if the disk suddenly dies on you - if it hasn't been used for a while, I would consider its fitness questionable at best. .  That said, RAID 1 is a mirroring scheme - in other words, all the disks contain all the data; thus it is possible to recover data even if only a single functional disk is present. .  What you see here is \"mdadm\" complaining that the array is supposed to contain 2 disks, therefore it marks the array degraded (there's something wrong with it, namely, only 1 disk is present out of 2). However, since the available disk seems to contain good data (it says \"sync\", meaning \"this disk is synced correctly to the current state of the array\") you can still assemble it in degraded mode by adding the \"--force\" parameter: .  This should assemble the array even with a single disk; then you can mount the array normally, and access the data as you usually would. .  ",
      "P-tags": "data-recoveri raid",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP"
    },
    {
      "id": "so_24812585",
      "task": "gnu/unix sort numerical only using first column?",
      "P-task": "gnu unix sort numer use first column",
      "F_verb": "use",
      "P-body": "Sadly you haven't missed anything. This apparently simple task - split lines into fields and then sort numerically on all of them - can't be done by the unix sort program. You just have to figure out how many columns there are and name them all individually as keys. .  What's happening when you specify \"-n\" no other options is that the whole line is being passed to the \"convert string to number\" routine, which converts the number at the start of the line and ignores the rest. The split into fields is not done at all. .  Your first example, without \"-n\", is also doing whole-line comparison. It's not comparing \"a\" to \"a\" then \"b\" to \"c\". It's comparing \"a b\" to \"a c\". .  ",
      "P-tags": "numer gnu unix sort field",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_39812882",
      "task": "python subprocess.call() cannot find Windows Bash.exe",
      "P-task": "python subprocess call find window bash exe",
      "F_verb": "find",
      "P-body": "For 32-bit programs running in the WOW64 subsystem, the \"System32\" directory gets redirected to \"SysWOW64\". The WSL bash.exe loader is distributed as a 64-bit executable, so from 32-bit Python you need to use the virtual \"SysNative\" directory. For example: .  Note that currently Windows pipes aren't bridged to WSL pipes, so if you try to use \"stdout=PIPE\" or \"subprocess.check_output\", the WSL bash loader will fail. You could read the console output directly via \"ReadConsoleOutputCharacter\" (e.g. see this answer). Or, more simply, you can redirect output to a temporary file, passing the temporary file's path translated as a WSL path. For example: .   Edit: As of Windows build 14951, you should be able to use \"stdout=PIPE\". See the WSL blog post Windows and Ubuntu Interoperability. .  ",
      "P-tags": "subprocess python window bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_565696",
      "task": "find + delete files bigger than 2G and when there's less than X available space",
      "P-task": "find + delet file bigger 2g less x avail space",
      "F_verb": "find",
      "P-body": "Assuming GNU \"df\", you can add a condition on the available disk space using for example .  You can adapt this as necessary, for example to delete files as long as the available space is less than 100\u00a0GiB: .  (Note that this will loop endlessly if deleting these files doesn\u2019t free up enough space.) .  Instead of \"df\", you can also use \"findmnt\": replace \"df --output=avail -B1 /grid/sdf | tail -n 1\" with \"findmnt -nbo AVAIL /grid/sdf\" (no need for \"tail\"). .  ",
      "P-tags": "linux shell-script find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP when S"
    },
    {
      "id": "ul_463287",
      "task": "Is there a shorter equivalent to long/path/**/^*.(complex|pattern)~long/path/(bad-1|bad-2)/*(.) that doesn't require repeating long/path/?",
      "P-task": "shorter equival long path\ncomplex pattern long path bad-1 bad-2\nrequir repeat long path",
      "F_verb": "require",
      "P-body": "Got it! Double slashes to mark the prefix: .  Sometimes you don't realize something is a feature until you find a use for it. I can't believe the fact that contiguous slashes are equivalent to one can actually be this useful. :) .  ",
      "P-tags": "wildcard zsh",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V S_ING"
    },
    {
      "id": "ul_336999",
      "task": "Does `mv --context` (for selinux, a.k.a. -Z) correctly apply labels recursively to directory contents?",
      "P-task": "mv -- context selinux k\n-z correctli appli label recurs directori content",
      "F_verb": "apply",
      "P-body": "Yes. .   This also introduced the possibility that moving a directory within a single filesystem will fail part-way through. I.e. due to lack of disk space when changing the labels. The impact of this is mitigated as the relabel happens as a second step. The initial move operation is still by a single atomic \"rename\". This means the labels would be inconsistent, but the files will be consistent in every other way. It should be simple to fix the labels once space becomes available. .  ",
      "P-tags": "recurs mv selinux",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP to NP"
    },
    {
      "id": "so_59239840",
      "task": "Where are downloaded files from code saved when run as a service using systemd",
      "P-task": "download file code save run servic use systemd",
      "F_verb": "save",
      "P-body": "By default, wget downloads files in the current working directory where it is run. .  A systemd service working directory can be set with \"WorkingDirectory=\" directive. From the link we can read: .   If not set, defaults to the root directory when systemd is running as a system instance and the respective user's home directory if run as user.  .   If your service file has the default WorkingDirectory set and is run as a system instance, the file most probably ends up in the root directory. .  ",
      "P-tags": "embedded-linux c wget",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V when S"
    },
    {
      "id": "so_40688245",
      "task": "python executing a remote script in a different directory",
      "P-task": "python execut remot script differ directori",
      "F_verb": "execute",
      "P-body": "Use the \"cwd\" argument: .  ",
      "P-tags": "python shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_474456",
      "task": "Linux find exec - output to a different directory",
      "P-task": "linux find exec - output differ directori",
      "F_verb": "find",
      "P-body": "The \"{}\" is replaced with the full path. This works in the first command, because there there the path is just \"./file.csv\". In the second command, the name is \"./01_delimiters/file.csv\", so it tries to create \"./02_encoding/./01_delimiters/file.csv\". .  You can .   \"mkdir /02_encoding/./01_delimiters\", then your output files will be placed in that directory. Combine both operations into one after you verified that the first one is working. Even if something is wrong, you didn't delete the original files. Change the second command to .   Just use the shell .    ",
      "P-tags": "linux ubuntu exec find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP to NP"
    },
    {
      "id": "so_48348769",
      "task": "Delete folder older than 30 minutes with Cron",
      "P-task": "delet folder older 30 minut cron",
      "F_verb": "delete",
      "P-body": "I actually found out that the best method is to divide the commands in Cron in 2 parts, and use the \"-delete\" argument .   Code .    Explanations .   \"30 * * * *\": execute every 30mn all the time \"sudo find /my/folder/* -type f -mmin +45 -delete\" : delete all files and subfiles that are older than 45 minutes \"&&\" : do only if first command has successfully run \"sudo find /my/folder/* -type d -empty -mmin +45 -delete\" : delete all empty folders that are older than 45 minutes  .  Working on Ubuntu 16.04 .  ",
      "P-tags": "ubuntu cron shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "so_12559129",
      "task": "How to Get a Return Value of a Java Class in UNIX",
      "P-task": "get return valu java class unix",
      "F_verb": "get",
      "P-body": "Two recommendations: .  Put the output of your program on the standard output .  To echo the result in your unix script .  ",
      "P-tags": "shell unix java",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_70191906",
      "task": "How to apply Excel Table Style using Powershell",
      "P-task": "appli excel tabl style use powershel",
      "F_verb": "apply",
      "P-body": "Assuming you want to try out the \"ImportExcel\" module. .   Install it first: \"Install-Module ImportExcel -Scope CurrentUser\"  Then the code would look like this: .  The author has a youtube channel where he used to upload tutorials and there is also online documentation and tutorials over the internet if you want to learn more. .  ",
      "P-tags": "excel powershel powershell-2 0",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP using NP"
    },
    {
      "id": "so_59810438",
      "task": "Remove characters between two patterns using sed",
      "P-task": "remov charact two pattern use sed",
      "F_verb": "remove",
      "P-body": "This might work for you (GNU sed): .  Keep everything upto and including \"cflags\" on a line and remove any \"\\\",\"/\" or \"\"\" characters thereafter. .  If it must only amend the line between the second pair of square brackets, use: .  ",
      "P-tags": "awk sed shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP between NP using NP"
    },
    {
      "id": "au_1194620",
      "task": "How would you separate fields with multiple spaces and store them in an array?",
      "P-task": "would separ field multipl space store array",
      "F_verb": "separate",
      "P-body": "Moving my comment, based on this source, to just show a particular column on multiple-spaces based table: .  Note that this won't work if you use double quotes. .  I found it particularly useful to find duplicates, using something like: .  ",
      "P-tags": "awk tr cut-command bash sed",
      "source": "qa",
      "cate": "cut/slash/separate/clip/crop",
      "pat": "V NP with NP"
    },
    {
      "id": "so_16536331",
      "task": "how to remove unnecessary chars from date command output in python",
      "P-task": "remov unnecessari char date command output python",
      "F_verb": "remove",
      "P-body": "Thomas's answer is correct, but I feel more explanation is necessary. .  I always \".decode('utf8')\" the result of \"p.communicate()\" or \"check_output()\" et al. This is because stdout/stdin is always opened in binary mode, unless you explicitly provide a file handle, so you always receive/send bytes, not str. .  In this case, I suggest just using \"check_output(['date','+%m/%d/%y'])\" rather than creating a Popen object which you then basically throw away :) .  So, I would suggest rewriting this to: .  On a more meta level, there is a question of whether you even need to use \"subprocess\" for this task. After all, there is \"time.strftime()\" for formatting dates/times. This: .  achieves the intended effect of your entire program in a much simpler way. .  Also from tink's comment: .  ",
      "P-tags": "linux python shell command",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_49983438",
      "task": "Get-ItemProperty inside a loop",
      "P-task": "get-itemproperti insid loop",
      "F_verb": "get",
      "P-body": "Did you try to search for it? .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_68862574",
      "task": "Determining the number of lines in a notification, depending on width and height",
      "P-task": "determin number line notif depend width height",
      "F_verb": "determine",
      "P-body": "Okay I have it. I missed the fact that Pango uses Pango Units, not Pixels. So in order to get the Pango unit size, the pixels have to be multiplied with the \"Pango.SCALE\" constant. .  ",
      "P-tags": "pango gnome-shell-extens gj",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP in NP on NP"
    },
    {
      "id": "ul_180087",
      "task": "Why pressing Ctrl-h in xterm + tmux sends \"^?\"?",
      "P-task": "press ctrl-h xterm + tmux send",
      "F_verb": "send",
      "P-body": "The reason is that in your xterm, \"^H\" is the \"erase\" character, and \"tmux\" apparently translates the \"erase\" character to the corresponding control character (\"^?\") for the terminal it emulates, so that erasing works as expected in cooked mode (for instance, what happens when you just type \"cat\"). The translation is needed in case you use a terminal with \"^?\" as the erase character (generated by the Backspace key), then resume the session with a terminal that uses \"^H\" as the erase character (generated by the Backspace key). Unfortunately this has visible side effects in some cases, e.g. if you type Ctrl+H. .  The only good remedy is to make sure that all your terminals (real or in tmux) use the same \"erase\" character, which should be \"^?\" (this is standard nowadays). It seems that your xterm is badly configured. This is not the default configuration, AFAIK. .  In any case, you need to make sure to use a \"TERM\" value for which \"kbs=\\177\". However this is not the case for \"xterm-256color\" from the official ncurses. So, you either need to select a different \"TERM\" value or you need to fix the \"kbs\" entry for \"xterm-256color\" (this can be done by the end user with: \"infocmp > file\", modify \"file\", then \"tic file\"). Some Linux distributions do not have this problem; for instance, Debian has fixed this problem via a \"debian/xterm.ti\" file in its \"ncurses\" source package, giving: .  You should also have: .  Note that you can do \"stty erase '^?'\" in xterm (before doing anything else), but this is just a workaround (and it may break the behavior of the Backspace key). You should actually have \"erase = ^?\" (as shown by \"stty -a\") by default! .  In case problems with Backspace and/or Delete remain, I recommend the Consistent BackSpace and Delete Configuration document by Anne Baretta. .  ",
      "P-tags": "gnome-termin xterm tmux gnu-screen",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "so_14995936",
      "task": "How to detect whether tomcat and ant are installed on linux machine",
      "P-task": "detect whether tomcat ant instal linux machin",
      "F_verb": "detect",
      "P-body": "Generally, you can check whether they are on the $PATH, if they are not on the $PATH, install one.  .  For ant: .  \"ant -v\" stands for verbose, \"ant -version\" prints out its version. .  For tomcat: .  if tomcat/bin is on the $PATH variable, version.sh will print out the version.  .  ",
      "P-tags": "tomcat linux ant version apach",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V whether S"
    },
    {
      "id": "so_65790304",
      "task": "Cron - bad minute errors in crontab file, can't install",
      "P-task": "cron - bad minut error crontab file instal",
      "F_verb": "install",
      "P-body": "Your file \"sms.cron\" seems to contain lines with 3 backticks .  before and after the line shown in the question. Remove these additional lines. .  ",
      "P-tags": "symfoni linux cron php",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_32941866",
      "task": "Redirect domain URI via htaccess",
      "P-task": "redirect domain uri via htaccess",
      "F_verb": "redirect",
      "P-body": "Try: .  ",
      "P-tags": "redirect linux apach htaccess",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP via NP"
    },
    {
      "id": "so_35160443",
      "task": "In Ubuntu, how do I find all photos of the Raw format taken after Jan 1, 2015, and if they total less than 30G, put them on an external drive?",
      "P-task": "ubuntu find photo raw format taken jan 1 2015 total less 30g put extern drive",
      "F_verb": "put",
      "P-body": "You have a bunch of questions to ask and answers to find before you can even get started.  .  First, you need to know WHERE the files are stored because that is the first parameter for \"find\", e.g. .  or  .  Second, you need to know the extension of the RAW files the camera creates, it may be \".CR2\" on a Canon or \".TIF\" or \".DNG\" or \".NEF\" on a Nikon, or \".mrw\" on a Minolta. Then you can get the second parameter for \"find\": .  Good, now you can get a list of the files. But you want to know when they were shot. Unfortunately, Ubuntu isn't going to know that, on its own, though it will know when files were created, so you may find it better to let Ubuntu weed out old files so you don't have to pass them to the next step which will be slower. So, how do we get Ubuntu to only find files newer than 1 Jan 2015 (since files put on disk before then were presumably not shot since January 2015). .  Well, one way would be to create a file dated 1 January 2015, and then to tell \"find\" to only find newer files. So, let's try that: .  Now add an extra parameter to \"find\" like this: .  Next, if you want the actual shooting date, you will need to install ImageMagick, or \"ufraw\" or \"dcraw\" or somesuch to parse your raw files and get the date. Let's say you write a script called \"CheckIfFileIsNew\" and make it executable with .  then you will be able to run that script for all the files: .  Then you need to learn how to \"grep\" the date out of a raw file. Then you need to learn how to run \"stat\" on a file to find its size. Then you need to learn some \"awk\" to total up all the file sizes to see if they exceed 30GB, then you can decide if you want to copy the files to the new place and if you do, you can replace the \"exec\" in the original \"find\" command with a \"cp\" command. .  Your script \"CXheckIfFileIsNew\" will look something like: .  Note that the \"identify\" command above may be pretty slow if you have a hi-res camera. You could try a command like \"strings\" on a couple of your RAW files to see if you can find the date in there that way and it will be miles faster: .  ",
      "P-tags": "ubuntu shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_69769707",
      "task": "How to use SED to extract string",
      "P-task": "use sed extract string",
      "F_verb": "use",
      "P-body": "Using \"jq\" is a better solution, but by \"sed\" you should apply this: .  ",
      "P-tags": "sed shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_25993545",
      "task": "build tshark 1.10.7 fails on luaL_openlibs",
      "P-task": "build tshark 1 10 7 fail lual_openlib",
      "F_verb": "build",
      "P-body": "With the help of sifflejoe i was able to track down that the libdl detection did somehow not completely work.  .  did solve the issue for us. .  ",
      "P-tags": "slackwar tshark lua wireshark linux",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "so_62480062",
      "task": "Grabbing only text/substring between 4th and 7th underscores in all lines of a file",
      "P-task": "grab text substr 4th 7th underscor line file",
      "F_verb": "grab",
      "P-body": " Output: .  ",
      "P-tags": "awk substr sed bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP between NP in NP of NP"
    },
    {
      "id": "so_26517567",
      "task": "Powershell script: create loop for ResponseTime",
      "P-task": "powershel script : creat loop responsetim",
      "F_verb": "create",
      "P-body": "I'll chime in late, not because the other answer are wrong by any means, they are both functional, but more so because nobody has pointed out that you are recreating the wheel. .  You test the connection, and specify an erroraction for it that silently continues leaving your variable null. Then you have to test to see if the variable has results, and treat it one way, or if it doesn't treat it another way. What you have just done is made your own Try/Catch scenario. If you actually use the error to stop you can use the built in Try/Catch. Consider this approach: .  That tries to ping the server, and if it can it adds a custom object to the $collection array with the desired information. If the ping fails it also adds an object to the $collection showing that the server was unreachable. .  Also, you had \"$collection = $()\". I assume you were trying to create an empty array, which is correctly done \"$collection = @()\" (corrected in my suggested code). Now, I commented out the Export-CSV so I could see the results. This is what I saw: .  Amazon didn't let me ping it, so it shows as unreachable. .  Moving on to why your desired results are not practical... What you describe shows you pinging your servers and getting results from them at non-consecutive times. To do that you would have to do \"-count 1\", and loop through the ForEach loop twice, so it would ping server 1 for 1 result, then server 2 for 1 result, then server 3 for 1 result. Then it would go back and ping server 1 for a second result, then server 2 for a second result, and then server 3 for a second result. If you wanted to do that you could I suppose, and it should give you your desired results, you would have to do something like this: .  That will give you your desired results, but it is slower. If you have to run this against more than a few servers it will be noticeably slower. For just those three servers listed it made the entire process go from taking 3.7240945 seconds to taking 7.6104075 seconds (roughly double). .  ",
      "P-tags": "powershel script",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "so_66050075",
      "task": "Replace tab with variable amount of spaces, maintaining the alignment",
      "P-task": "replac tab variabl amount space maintain align",
      "F_verb": "replace",
      "P-body": "The POSIX utility pr called as \"pr -e -t\" does exactly what you want and AFAIK is present in every Unix installation. .  and with the tabs visible as \"^I\"s: .  ",
      "P-tags": "awk tab whitespac bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP of NP"
    },
    {
      "id": "so_17348885",
      "task": "Getting a single digit integer for RHEL version using SED or AWK",
      "P-task": "get singl digit integ rhel version use sed awk",
      "F_verb": "get",
      "P-body": "Or use \"int()\" function: .  ",
      "P-tags": "rhel integ convert bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP using NP"
    },
    {
      "id": "su_1113429",
      "task": "Disable PowerShell beep on backspace",
      "P-task": "disabl powershel beep backspac",
      "F_verb": "disable",
      "P-body": "The beep is provided by the \"PSReadline\" module, which shipped with Windows 10. You need to change the \"PSReadline\" option to disable the bell: .  If you want this change for all future PowerShell sessions, then you need to add this command to your PowerShell profile. For example, to set the option for \"Current User, Current Host\" (\"$Profile\"): .  The first line allows your profile run a startup script when PowerShell opens (About Execution Policies). The second line tests to see if you already have a startup script defined for \"Current User, Current Host\". The third line adds the bell option to your startup script. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP on NP"
    },
    {
      "id": "su_858427",
      "task": "Apache2 still shows default page after trying to configure it",
      "P-task": "apache2 still show default page tri configur",
      "F_verb": "show",
      "P-body": "The default configuration file for Apache will provide a definition for your default website. It's files will be at \"/var/www/html/\". If you don't want that site to show up then you need to remove its configuration file (\"rm /etc/apache2/sites-available/000-default.conf\"). .  One more thing that you'll want to do is fix your new file. I strongly suggest that you begin simple and work your way up. Try this one first: .  You'll notice that your configuration doesn't include a \"DocumentRoot\". This directive is very important for each vhost. .  ",
      "P-tags": "ubuntu apache-http-serv",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP after S_ING"
    },
    {
      "id": "ul_370085",
      "task": "Migrating from Debian sid/unstable to testing",
      "P-task": "migrat debian sid unstabl test",
      "F_verb": "migrate",
      "P-body": "If you want to track the testing distribution, I would strongly recommend running a mixture of testing and unstable: that will allow you to pull in updated packages from unstable if necessary (e.g. for security fixes). To do this, ensure both testing (named as such, rather than the specific release name) and unstable are available in your configured repositories; then set up pinning, e.g. in \"/etc/apt/preferences\": .  This will result in packages being tracked in testing if they\u2019re available there, unstable if they\u2019re not, or if they\u2019re installed in a version newer than what\u2019s available in testing. As Debian transitions from preparing Stretch to preparing Buster, and packages migrate from unstable to testing, your local installation will progressively start tracking Buster instead of unstable. This avoids needing to downgrade anything, and hopefully should result in a Buster setup in relatively short order after Stretch is released since testing and unstable haven\u2019t yet diverged too much. This will change very quickly after Stretch releases, so make sure you set this up before then.) .  This kind of setup avoids issues with packages disappearing from testing for sometimes long periods. It also makes it easy to track security uploads to unstable, using Paul Wise\u2019s patch to \"debsecan\". I\u2019ve been running this on my main setup for years without issue (but then again, I\u2019m intimately familiar with the inner workings of Debian). The annoyances Fahim mentions in his answer mostly concern new installations of packages, which can be troublesome in pure testing; in practice they\u2019re not much of an issue on a running system. .  The usual caveats to running testing and/or unstable apply. You should make sure you\u2019re familiar with the best practices. In particular, make sure you\u2019re aware of all the changes \"apt-get\" wants to make on upgrades before letting it loose. .  ",
      "P-tags": "upgrad debian",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V from NP to NP"
    },
    {
      "id": "so_34414336",
      "task": "how to create node app listen on host entry domain ?",
      "P-task": "creat node app listen host entri domain",
      "F_verb": "create",
      "P-body": "You can use ng-rok for this purpose. Follow these steps to achieve this : .   Install rgrok globally from NG-ROK This is a module by which you can server your local server over the Internet. It will generates a temporary url for your server and forward all the requests to your node server. .  Now you have to start your node server(Assuming you have started already). .  Now you have to map your server port with command : \"ngrok http <<YOUR_PORT_NUMBER>>\" .  You will get a temporary URL for this server. Now repeat the same 2nd & 3rd step for all of you servers.  .   ",
      "P-tags": "node js linux javascript express",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "so_62107668",
      "task": "How can I make a cross-OS sh script for Docker usage?",
      "P-task": "make cross-o sh script docker usag",
      "F_verb": "make",
      "P-body": "Using inspo from How to detect the OS from a Bash script?, (thanks Richard Barber for link), I managed to come around my problem using the OSTYPE variable to diff which OS that's in use. .  For windows, simply use a bash terminal and the settings for either Linux or MacOS would work. .  ",
      "P-tags": "linux maco docker devop window",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP for NP"
    },
    {
      "id": "so_24144036",
      "task": "How can I set 664 (or custom) permission on files created or rotated with rails Logger.new?",
      "P-task": "set 664 custom permiss file creat rotat rail logger new",
      "F_verb": "create",
      "P-body": "My colleague pointed out that this can be done a lot more easily, by setting the File.umask for the current process, as follows .  See http://ruby-doc.org/core-1.9.3/File.html#method-c-umask .  ",
      "P-tags": "linux ruby-on-rail",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V with NP"
    },
    {
      "id": "so_30557888",
      "task": "set default python version when run the program as executable ./xxx.py - on linux",
      "P-task": "set default python version run program execut\nxxx py - linux",
      "F_verb": "set",
      "P-body": "To tell python what version to use and to make it executable on Linux you have to do the following steps: .  Add \"#!\" to the python script .  Add permissions to run it .  ",
      "P-tags": "python-2 7 python-3 x linux ubuntu python",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP when S"
    },
    {
      "id": "so_67369755",
      "task": "Why my bash if statement keeps on returning true?",
      "P-task": "bash statement keep return true",
      "F_verb": "keep",
      "P-body": "The output of the modprobe command contains a trailing space. .  Try: .  or: .  or (I think this is all you are trying to accomplish): .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V on S_ING"
    },
    {
      "id": "ul_250398",
      "task": "How do I keep the lines with the highest number where a pattern is matched?",
      "P-task": "keep line highest number pattern match",
      "F_verb": "keep",
      "P-body": "I don't have an osx \"awk\" to try this on, but it works on my linux gnu awk: .  On each line we look for the starting index in the line of the regexp pattern that is a number with optional trailing whitespace. We split the line at that index into the word part and the number part. The number string is converted to a number by adding 0 to it. An associative array indexed by the word keeps hold of the biggest number. .  ",
      "P-tags": "text-process",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP with NP where S"
    },
    {
      "id": "so_12633394",
      "task": "Call a local function inside if Statement in bash",
      "P-task": "call local function insid statement bash",
      "F_verb": "call",
      "P-body": "All functions must be declared before they can be used, so move your declarations to the top. .  Also, you need to have a space on either side of the \"=\" in your string comparison test. .  The following script should work: .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP inside if S"
    },
    {
      "id": "ul_672712",
      "task": "Remove null variable name and value both while echoing in a single string",
      "P-task": "remov null variabl name valu echo singl string",
      "F_verb": "remove",
      "P-body": "You could use the \"${parameter:+word}\" expansion, you just need to put the static part, the variable name, in the right-hand side too: .  Note that the way you showed that in the question, you have an additional problem: the commas. You could use \"\"${emp_name:+emp_name:$emp_name}\"\", but if you do that to all the variables, you'll have a trailing comma at the end of the line. You could remove that with \"${str%,}\" if you store the string in the variable \"str\" first. .  Doing that for all the variables is a bit repetitive, though. If you're using Bash, you could use namerefs to point to the variables, and collect the text to a string variable: .  With your values, that prints \"emp_name:Sid,emp_id:1234,emp_likes:swimming\". There's usually no difference between string variables and numeric variables in the shell, and if you want quotes or such around the values, you'll have to do something else. In Bash, you could use \"printf %q\", or \"${var@Q}\" to get the value in a format that's suitable for shell input, i.e. with all embedded quotes properly escaped, too. .  You could also use an associative array there instead of the pile of independent variables. .  (Bash has \"declare -i\" to make a variable into an integer, but it still prints the same as a string, and I don't think there's an easy way to determine if the variable is a string or an integer.) .  ",
      "P-tags": "shell program",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP while S"
    },
    {
      "id": "so_8171902",
      "task": "How to use Router inside a shell script?",
      "P-task": "use router insid shell script",
      "F_verb": "use",
      "P-body": "IF you want to import the routes try  .  ",
      "P-tags": "cakephp cakephp-1 3 shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_12102483",
      "task": "How do I put this string with braces and brackets into a variable in a bash script?",
      "P-task": "put string brace bracket variabl bash script",
      "F_verb": "put",
      "P-body": "One error is near the end: .  There is an unclosed \"\"\". .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP into NP in NP"
    },
    {
      "id": "so_17489651",
      "task": "Can't modify document root's value on apache - keep getting /var/www",
      "P-task": "modifi document root valu apach - keep get var www",
      "F_verb": "modify",
      "P-body": " after editing your config, type this in your ubuntu terminal: .  \"sudo a2dissite mysite && sudo a2ensite mysite\" .  then .  \"sudo service apache2 restart\" .  ",
      "P-tags": "php linux config virtualhost apach",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "so_24178972",
      "task": "Cannot get if to evaluate the result of $? correctly",
      "P-task": "get evalu result\ncorrectli",
      "F_verb": "get",
      "P-body": "\"echo $? #2&>1\" will reset the value of \"$?\" .  You need .  ",
      "P-tags": "grep bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V if S_INF OF NP"
    },
    {
      "id": "ul_533060",
      "task": "ignore specific command from zsh completion",
      "P-task": "ignor specif command zsh complet",
      "F_verb": "ignore",
      "P-body": "You can do: .   If you needed to do more than one ignored pattern, you would do it like this: .  ",
      "P-tags": "autocomplet zsh",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP from NP"
    },
    {
      "id": "so_49922860",
      "task": "Bash script, domain expiration date with email sending",
      "P-task": "bash script domain expir date email send",
      "F_verb": "send",
      "P-body": "Look no further than the \"date\" command, it has everything you need ! .  Here is a straightforward solution using \"date -d\" to parse the date : .  Good luck ! .  ",
      "P-tags": "whoi domainexpir bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V"
    },
    {
      "id": "ul_378856",
      "task": "How can I check if a group does not have users and delete it?",
      "P-task": "check group user delet",
      "F_verb": "delete",
      "P-body": "Getting the members of a group in Linux isn't as easy as one might think. In my opinion the easiest way would be using the \"lid\" command. Install it using .  then you should try if it works using .  If it says command not found try  .  And for your script  .  Edit .  Since you can't install the package I wrote a little script that should solve your problem .  This is the base you need. You can change the ending and beginning to your needs.  .  ",
      "P-tags": "script linux group",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_405043",
      "task": "xdg-open opens a specified htm file but ignores the tag (#) location within the page",
      "P-task": "xdg-open open specifi htm file ignor tag locat within page",
      "F_verb": "specify",
      "P-body": "Solution found thanks to pointers from @Ignacio Vazquez-Abrams. .  The issue was actually in the way \"xdg-open\" passes an argument to the default application. .  If the default application is registered in kde desktop so as to expect a url (%u) .  then the whole argument passed to \"xdg-open\" is used as a url and the browser navigates to the tag. .  if the %u is omitted then the argument passed to \"xdg-open\" is tested to see if it is a file and then stripped of information from the # in the url (from the \"xdg-open\" script) .  and the page is only opened at the top. .  In my case firefox had been registered with %u and seamonkey without, which is why I had different behaviour in the two browsers. .  ",
      "P-tags": "xdg-open shell-script browser",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP within NP"
    },
    {
      "id": "au_1119938",
      "task": "Audio volume doesn't change",
      "P-task": "audio volum chang",
      "F_verb": "change",
      "P-body": "EDIT: \"pactl load-module module-alsa-sink control=PCM\" should result in pulseaudio seeing a new output device that will control the PCM volume. If changing this device allows for proper control of audio output volume, you can add a line \"load-module module-alsa-sink control=PCM\" to \"/etc/pulse/default.pa\"  .  PCM (pulse code modulation) occurs at ALSA kernel level, and is responsible for sampling and conversion of digital signals from software to analog ones heard out of your hardware (PCM Playback channel), as well as analog ones coming in from your microphone (PCM Capture) to their digital form. .  Linux audio output and volume control allows for a lot of versatility, but it can make thinks more complicated and more difficult to troubleshoot as well. For output, the flow is more or less like this: .   I think \"pactl\" from pulseaudio package should get you started and on the right track, please try .  \"$pactl set-sink-volume $(pactl info | grep -i Sink | cut -d ':' -f2) 25%\" .  and let us know if the audio volume gets set to 1/4 of the range, or again jumps to 100%. .  ",
      "P-tags": "driver asu 18 10 sound",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V"
    },
    {
      "id": "so_53348321",
      "task": "Get xargs to word-split placeholder {}",
      "P-task": "get xarg word-split placehold",
      "F_verb": "get",
      "P-body": "Sort of. .  Outputs: .  ref: https://stackoverflow.com/a/35612138/1563960 .  Also: .  Outputs: .  ",
      "P-tags": "xarg bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_30201735",
      "task": "creating alias for a bash script with a wild card option in the argument",
      "P-task": "creat alia bash script wild card option argument",
      "F_verb": "create",
      "P-body": "Aliases don't handle arguments via \"$1\" and the like; they just prepend their text directly to the rest of the command line. .  Either use: .  ...or a function: .  ...though if your script is named \"log_list\", marked executable, and located somewhere in the PATH, that alias or function should be completely unnecessary. .   Now, that said, your proposed implementation of \"log_list\" also has a bunch of bugs. A cleaned-up version might look more like... .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP with NP in NP"
    },
    {
      "id": "so_42614375",
      "task": "Creating a oneliner to import database",
      "P-task": "creat onelin import databas",
      "F_verb": "create",
      "P-body": " ",
      "P-tags": "awk grep linux ubuntu cut",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_115107",
      "task": "Is there a shutdown/restart command for x11VNC? - Linux (Debian)",
      "P-task": "shutdown restart command x11vnc\n- linux debian",
      "F_verb": "restart",
      "P-body": "If you're using \"systemd\" you should be able to set it up as a service. I found this thread which shows a similar task of setting up \"x11vnc\" as a Systemd service. The thread is titled: Index\u00bb Newbie Corner\u00bb how to enable x11vnc at startup using systemd ?. .  From a comment in that thread .   Create the file: \"/etc/systemd/system/x11vnc.service\" .   Create the file: \"/etc/systemd/system/graphical.target\" .   Enable Systemd service .  This should create a link like this: .   /etc/systemd/system/default.target -> /etc/systemd/system/graphical.target .   Reboot .   ",
      "P-tags": "shutdown x11vnc debian display",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP for NP"
    },
    {
      "id": "so_2352378",
      "task": "a.out replaced by ELF file format?",
      "P-task": "replac elf file format",
      "F_verb": "replace",
      "P-body": "The \"a.out\" format forced shared libraries to occupy a fixed place in memory. If you wanted to distribute an a.out shared library, you had to register its address space. This was good for performance but it didn't scale at all. See for yourself how tricky it was (linuxjournal). .  By contrast, in ELF, shared libraries can be loaded anywhere in memory, and can even appear to be at different addresses to different applications running on the same computer (with the code still effectively loaded in only one place in physical memory)! In order to achieve this, in the IA-32 architecture, a register (%ebx) has to be sacrificed. A more comprehensive reference showing that shared libraries got more complicated in ELF, but that was compiler-side complexity, as opposed to programmer-side. .  ",
      "P-tags": "unix linux coredump file-format elf",
      "source": "qa",
      "cate": "replace",
      "pat": "V by NP"
    },
    {
      "id": "so_25722292",
      "task": "ERROR: Failed to build gem native extension message (Linux) installing rubygems",
      "P-task": "error : fail build gem nativ extens messag linux instal rubygem",
      "F_verb": "build",
      "P-body": "So running this worked for me:  .  Suppose the \"-dev\" package was needed?  .  ",
      "P-tags": "json ruby-on-rail linux-mint gem",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "au_978677",
      "task": "Why is my ubuntu trying to fetch aarch64 packages on x86_64 system",
      "P-task": "ubuntu tri fetch aarch64 packag x86_64 system",
      "F_verb": "fetch",
      "P-body": "\"aarch64\" is listed as a foreign architecture. This is not an architecture name in ubuntu. Open a terminal and run: .  ",
      "P-tags": "apt updat package-manag 64-bit update-manag",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1109463",
      "task": "Setting correct size for \"cryptsetup: WARNING: Option 'size' missing in crypttab for plain dm-crypt mapping root\" message",
      "P-task": "set correct size cryptsetup : warn : option size miss crypttab plain dm-crypt map root messag",
      "F_verb": "set",
      "P-body": "Add the size like \"size=256\" to \"/etc/crypttab\" configuration:  .  ",
      "P-tags": "ecryptf 18 10 encrypt cryptsetup",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_864013",
      "task": "What is the closest thing to grep that comes standard on a Windows install?",
      "P-task": "closest thing grep come standard window instal",
      "F_verb": "install",
      "P-body": "\"findstr\": .  ",
      "P-tags": "command-lin window grep shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_2775009",
      "task": "kill a process in bash",
      "P-task": "kill process bash",
      "F_verb": "kill",
      "P-body": "To interrupt it, you can try pressing ctrl c to send a SIGINT. If it doesn't stop it, you may try to kill it using \"kill -9 <pid>\", which sends a SIGKILL. The latter can't be ignored/intercepted by the process itself (the one being killed). .  To move the active process to background, you can press ctrl z. The process is sent to background and you get back to the shell prompt. Use the \"fg\" command to do the opposite. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_484872",
      "task": "Skip identical values in nestled for loops",
      "P-task": "skip ident valu nestl loop",
      "F_verb": "skip",
      "P-body": "Note: The loops below run from 1 to 9 using brace expansions. Use \"{1..3}\" or \"1 2 3\" to do exactly as in the question. .  Compare \"$i\" and \"$j\" to make sure that they are different before creating the directory: .  The \"-ne\" test tests for arithmetic inequality. If you are looping over strings, use \"!=\" instead. If the test is true (\"$i\" and \"$j\" are different), the directory is created with \"mkdir\". .  \"[ \"$i\" -ne \"$j\" ] && mkdir \"$i$j\"\" is a short-cut way of writing .   To delete all directories that have names like \"11\", \"22\" etc.: .  This assumes that the directories are empty. Use \"rm -rf \"$i$i\"\" if they are not empty. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP in NP"
    },
    {
      "id": "so_57512291",
      "task": "How can I compile an application that can use the read/write hints in kernel?",
      "P-task": "compil applic use read write hint kernel",
      "F_verb": "compile",
      "P-body": "The simplest solution is to define the \"_GNU_SOURCE\" macro before \"#include <fcntl.h>\". As there may be other interactions, it is better to define it before any \"#include\" directives: .  open_file_fcntl.c .  Alternatively, the \"#define _GNU_SOURCE\" can be removed from the source code (open_file_fcntl.c above) and the macro defined on the compiler command line: .  ",
      "P-tags": "c linux-kernel",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP that S"
    },
    {
      "id": "so_29929534",
      "task": "Docker error: Unable to locate package git",
      "P-task": "docker error : unabl locat packag git",
      "F_verb": "locate",
      "P-body": "This is happening because the apt repository is not yet updated, it is common practice to clean your apt repositories and tmp files after creating an image, which your base image is probably doing. .  To fix this, you are going to want to run \"apt-get update\" prior to installing git, it is good practice to combine the update and install command at the same time to bust cache on the update if the install line changes: .  Using \"-y\" is convenient to automatically answer yes to all the questions. .  ",
      "P-tags": "git apt ubuntu docker",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "au_237845",
      "task": "How to increase size of primary partition?",
      "P-task": "increas size primari partit",
      "F_verb": "increase",
      "P-body": "Download this file Now from your terminal do following. For example we want to make it 20 GB then: .  Reference:  .  ",
      "P-tags": "filesystem wubi",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP of NP"
    },
    {
      "id": "so_59802867",
      "task": "How to create a config file bash script with variables inside",
      "P-task": "creat config file bash script variabl insid",
      "F_verb": "create",
      "P-body": "If \"MONGO_PART\" is set, the here-document is subject to parameter expansion and you'll get the parameter value in your file. .  Use \"tee\" instead of \"cat\", which can open the output file itself: .  ",
      "P-tags": "variabl config-fil bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP inside"
    },
    {
      "id": "so_12195264",
      "task": "replace with inverted commas using sed",
      "P-task": "replac invert comma use sed",
      "F_verb": "replace",
      "P-body": "You can probably include double quotes inside your double-quoted command line by escaping them with a backslash: .  However, I would caution that what you're doing here is probably NOT the best way to achieve your real goal, whatever that is. This sounds suspiciously like an XY problem. .  What's the bigger picture here? What are you really trying to do? .  ",
      "P-tags": "sed php unix",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "su_321816",
      "task": "Find command taking too long on ubuntu 10.10",
      "P-task": "find command take long ubuntu 10 10",
      "F_verb": "find",
      "P-body": "for the \"find\" command, disk IO is likely to be a much more significant bottleneck than CPU time. .  compare your .  with the equivalent  .  or .  or (fastest for finding location of commands on your path) .  ",
      "P-tags": "time linux ubuntu-10 10 command-lin",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP on NP"
    },
    {
      "id": "su_160390",
      "task": "Ubuntu 10.04 won't mount USB hard drive (not even in /dev)",
      "P-task": "ubuntu 10 04 mount usb hard drive even dev",
      "F_verb": "mount",
      "P-body": "The module you're looking for is \"usb-storage\". Try probing it and inserting your devices after. .  ",
      "P-tags": "usb ubuntu-10 04 hard-driv",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "au_744662",
      "task": "Unable to mount my external hard disk",
      "P-task": "unabl mount extern hard disk",
      "F_verb": "mount",
      "P-body": "If you read the error properly, you will get clue about the problem and that is how you can get it solved. .  The last part of the error message is: \"mount: unknown filesystem type 'exfat'\". First of all it tells us this HDD was being mounted as \"exfat\" so it has nothing to do with \"ntfs\". It also simply means your system does not recognize this file system. .  If you are sure that the file system of the drive is \"exfat\", you need to install \"exfat-fuse\" and \"exfat-utils\" using this command: .  ",
      "P-tags": "mount",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_236775",
      "task": "How to move title bar buttons to the left in Pantheon/Gala?",
      "P-task": "move titl bar button left pantheon gala",
      "F_verb": "move",
      "P-body": "First you need to install \"dconf-editor\". .  Open \"dconf\" and navigate to: \"org -> pantheon -> desktop -> gala -> appearance\" .  Change \"button-layout\" from \"close:maximize\" to \"close,minimize:maximize\" or \"close,minimize,maximize:\" depending on whether or not to want to keep the maximize button on the right.  .   .  If you want to move the buttons to the right, like in Gnome or KDE, change the value of \"button-layout\" to \":maximize,minimize,close\"  .    .  ",
      "P-tags": "window-button pantheon titlebar",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "ul_236579",
      "task": "Find pattern between special characters",
      "P-task": "find pattern special charact",
      "F_verb": "find",
      "P-body": " ",
      "P-tags": "shell-script text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP between NP"
    },
    {
      "id": "so_37134221",
      "task": "delete wget yum source sublime2",
      "P-task": "delet wget yum sourc sublime2",
      "F_verb": "delete",
      "P-body": "Delete the file \"/etc/yum.repos.d/sublime.repo\" (or any other file with similar name) , then it should work. .  If you don't find any such file. Then grep for sublime in /etc/yum.repos.d directory. And delete the file. .  Another temporary solution is to disable to repository every time you run yum. .  ",
      "P-tags": "linux wget sublimetext2 yum",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_260967",
      "task": "Linux + how to verify the CPU performance",
      "P-task": "linux + verifi cpu perform",
      "F_verb": "verify",
      "P-body": "The \"98.2%id\" means that most of the time, CPU does nothing (The CPU is in idle state). .  To determine how is used the CPU over time, you can use \"uptime\" command that will gives you the load average. .  ",
      "P-tags": "cpu linux top",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_43125230",
      "task": "How can I place a dot before the last three digits in a terminal output",
      "P-task": "place dot last three digit termin output",
      "F_verb": "place",
      "P-body": "You are trying to get values of \"Available\" and \"Use%\" sections from \"df\" command output for a certain mounted file system. Use the following \"sed\" approach: .  ",
      "P-tags": "termin linux sed regex",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP before NP in NP"
    },
    {
      "id": "so_59319994",
      "task": "How to add or subtract from date with format DDMMYYYY in bash?",
      "P-task": "add subtract date format ddmmyyyy bash",
      "F_verb": "subtract",
      "P-body": "From \"man date\" .   The --date=STRING is a mostly free format human readable date string such as \"Sun, 29 Feb 2004 16:21:42 -0800\" or \"2004-02-29 16:21:42\" or even \"next Thursday\". [...] The date string format is more complex than is easily documented here but is fully described in the info documentation. .   tl;dr: Seems like you cannot specify the format of the input. Use one of the known formats, for instance .  To automatically convert a date from \"DDMMYYYY\" format to \"YYYY-MM-DD\" you can use \"sed\" ... .  ... or bash ... .  ",
      "P-tags": "command-lin date unix shell",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V from NP with NP in NP"
    },
    {
      "id": "so_58379019",
      "task": "Sed converting underscore string to CamelCase fails on numbers",
      "P-task": "sed convert underscor string camelcas fail number",
      "F_verb": "convert",
      "P-body": "Loop through it manually and replace up until there is nothing more to replace. .  I have added \"A-Z\" in the first regex to handle cases like: .  After the first match it becomes \"thisIsA_simple\", so in the second loop we want to match \"A_simple\". .  Maybe a better version would be: .  Because regex is greedy, this will replace from the end, so \"this_is_a_simple\" at first becomes \"this_is_aAimple\", then \"this_isASimple\", then \"thisIsASimple\". .  ",
      "P-tags": "script replac shell bash sed",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP on NP"
    },
    {
      "id": "ul_216749",
      "task": "Determine the tmux session a shell session belongs to?",
      "P-task": "determin tmux session shell session belong",
      "F_verb": "determine",
      "P-body": "Try executing this inside your \"tmux\" session: .  \"tmux display-message -p '#S'\" .  ",
      "P-tags": "shell-script tmux zsh",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP to"
    },
    {
      "id": "au_124699",
      "task": "Why does gnome-terminal freeze when an SSH session gets disconnected?",
      "P-task": "gnome-termin freez ssh session get disconnect",
      "F_verb": "get",
      "P-body": "The session will eventually time out and disconnect; this will happen faster if you configure \"ServerAliveInterval\" and \"ServerAliveCountMax\" in \"~/.ssh/config\". To force an immediate disconnect, Return~.. .  ",
      "P-tags": "ssh gnome-termin command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "su_1351469",
      "task": "What is the equivalent to the Linux Install command for Windows?",
      "P-task": "equival linux instal command window",
      "F_verb": "install",
      "P-body": "No, there isn't equivalent for GNU's \"install\". However you can probably replace it just by copying the binaries and updating \"%PATH%\" variable accordingly. .  ",
      "P-tags": "linux window command-lin",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP"
    },
    {
      "id": "so_43493484",
      "task": "Replacing characters with diacritics in a string",
      "P-task": "replac charact diacrit string",
      "F_verb": "replace",
      "P-body": "Oh! You were so close! Removing the \"$\" sign in the \"\"\u00c5$\"\" worked for me.  .  Try it yourself... .  As pointed out in the comments \"$\" means the end of the string in regex. Since only the final \"\u00f6\" satisfies this in your sample, it was the only one getting replaced. .  Also pointed out, \"-replace\" is case-insensitive so you've effectively duplicated your work. If you want to replace everything, you only need  .  If you need to only replace either upper or lower case, then use the \"-creplace\". .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_30954990",
      "task": "how to open (create if not exists) a file while acquiring exclusive lock avoiding races",
      "P-task": "open creat exist file acquir exclus lock avoid race",
      "F_verb": "open",
      "P-body": "No, it is not possible as a basic operation supported by Linux/UNIX. .  The O_CREAT|O_EXCL technique in the answer you referenced can work here. Instead of exclusively creating the target file, you exclusively create a lockfile whose name is predictably derived from the target file. E.g., \"os.path.join(\"/tmp\", hashlib.md5(target_filename).hexdigest() + \".lock\")\". .  However, as others have suggested, it's not clear that you need to protect both the target file creation and its checksumming + possible replacement. An \"fcntl\" advisory lock will suit your needs. .  ",
      "P-tags": "linux python lock multithread",
      "source": "qa",
      "cate": "open",
      "pat": "V NP while S"
    },
    {
      "id": "so_4165736",
      "task": "How to shorten this?: read first|| exit 1; (echo \"$first\"; cat) | $foo",
      "P-task": "shorten\n: read first exit 1 echo first cat foo",
      "F_verb": "read",
      "P-body": " I removed the pipe, it has no added value in your example. Strictly, this doesn't let the diff fail, it's just not executed. .  ",
      "P-tags": "diff shell pipe",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_57463917",
      "task": "How to apply string formatting to a bash command (incorporated into Python script via subprocess)?",
      "P-task": "appli string format bash command incorpor python script via subprocess",
      "F_verb": "apply",
      "P-body": "TL;DR: Don't shell out to awk! Just use Python. But let's go step by step... .   Your instinct of using triple quotes here is good, then at least you don't need to escape both single and double quotes, that you need in your shell string. .  The next useful device you can use is raw strings, using \"r'...'\" or \"r\"...\"\" or \"r\"\"\"...\"\"\"\". Raw strings don't expand backslash escapes, so in that case you can leave the \"\\n\"s intact. .  Last is the \"%s\", which you need to escape if you use the \"%\" operator, but here I'm going to suggest that instead of using the shell to redirect input, just use Python's subprocess to send stdin from the file! Much simpler and you end up with no substitution. .  I'll also recommend that you use \"subprocess.check_output()\" instead of \"Popen()\". It's much simpler to use and it's a lot more robust, since it will check that the command exited successfully (with a zero exit status.) .  Putting it all together (so far), you get: .  But here you can go one step further, since you don't really need a shell anymore, it's only being used to split the command line into two arguments, so just do this split in Python (it's almost always possible and easy to do this and it's a lot more robust since you don't have to deal with the shell's word splitting!) .  The second string in the list is still a raw string, since you want to preserve the bacsklash escapes. .  I could go into how you can do this without using \"printf()\" in awk, using \"print\" instead, which should get rid of both \"\\n\"s and \"%\"s, but instead I'll tell you that it's much easier to do what you're doing in Python directly! .  In fact, everything that awk (or sed, tr, cut, etc.) can do, Python can do better (or, at least, in a more readable and maintainable way.) .  In the case of your particular code: .  Isn't this better? .  And you can put this into a function, into a module, and reuse it anywhere you'd like. It's easy to store the result in a string, save it into a variable if you like, much more flexible... .  Anyways, if you still want to stick to shelling out, see my previous code, I think that's the best you can do while still shelling out, without significantly changing the external command. .  ",
      "P-tags": "subprocess linux python bash",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP to NP into NP via NP"
    },
    {
      "id": "so_33406050",
      "task": "Assembly x86, print new line after each word in a string",
      "P-task": "assembl x86 print new line word string",
      "F_verb": "print",
      "P-body": "Since you appear to be using NASM on Linux. \"nwln\" is a macro that is part of an Assembler Tutorial based on the code from the book Guide to Assembly Language Programming in Linux. The library is made up of a macro called \"nwln\" that prints the LineFeed(LF) character \"0x0a\" to standard output. You can download the files \"io.mac\" and \"io.o\" from the link above. They are contained inside the ZIP file for NASM/Linux. You copy \"io.mac\" and \"io.o\" to your project directory. You have to include the macro file at the top of your program. Your code would look something like: .  To compile and link in a 32-bit environment you'd use something like: .  You need to add \"io.o\" as a linker object to resolve the functions that are needed by the macros. .  If you don't wish to rely on \"io.o\" the code below contains the equivalent macro and function that will implement \"nwln\" a similar way: .  You can then compile with something like: .  ",
      "P-tags": "nasm system-cal linux assembl x86",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP after NP in NP"
    },
    {
      "id": "so_4740698",
      "task": "Powershell Receive-Job: Quota violation when invoking command as a job",
      "P-task": "powershel receive-job : quota violat invok command job",
      "F_verb": "receive",
      "P-body": "Looks like this has nothing to do with the fact that you're using jobs; it seems to be with the size of the input being passed to test-connection. I can reproduce the quota violation with this code: .  Seems to be something internal to test-connection, which ends up creating Win32_Ping WMI objects methinks. I can also get the code to work by slicing out part of the input array: .  Note that 650 does not appear to be a magic number - I can query up to about 800 hostnames without encountering the error. .  Since the exception is a Management exception and not a PowerShell internal exception, I'd say you've found one of the many magical limits of WMI. Also sounds like something that test-connection should manage internally, but doesn't. I've logged an issue on Connect here, if you want to upvote it: test-connection throws quota exception when passed large list of computernames .  I would try your job code as-is, but slice the list of hostnames into smaller segments: .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "au_963950",
      "task": "Massive SSDP flood, how to find the cause",
      "P-task": "massiv ssdp flood find caus",
      "F_verb": "find",
      "P-body": "Use \"sudo lsof -n -P -i +c 13 | grep 1900\" to find the process doing this. .  From \"man lsof\": List open files .   An open file may be a regular file, a directory, a block special file, a character special file, an executing text reference, a library, a stream or a network file (Internet socket, NFS file or UNIX domain socket.) A specific file or all the files in a file system may be selected by path. .    \"-n\": inhibits the conversion of network numbers to host names for network files. Inhibiting conversion may make lsof run faster. It is also useful when host name lookup is not working properly. .  \"-P\": inhibits the conversion of port numbers to port names for network files. Inhibiting the conversion may make lsof run a little faster. It is also useful when port name lookup is not working properly. .  \"-i [i]\": selects the listing of files any of whose Internet address matches the address specified in i. If no address is specified, this option selects the listing of all Internet and x.25 (HP-UX) network files. .  \"+c w\": defines the maximum number of initial characters of the name, supplied by the UNIX dialect, of the UNIX command associated with a process to be printed in the COMMAND column. The lsof default is nine.) .    It list the files opened by processes on your system and uses those listed options above to modify what is presented to you. For example I used: .  Result: .   Slower without \"-n\", and  .  Conversion of network numbers to host names  .    But using: .  Results: .   Faster, and none conversion of network numbers to host names .    Here I just used \"-n\", doing network number conversion takes more time without option \"-n\" makes the search faster, remove to see host names. Play around with the other option to see the different outputs. By and large those options improves the search ans makes it faster. .  ",
      "P-tags": "firewal servic",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_8798855",
      "task": "How to create partition in NAND flash in am335x evm?",
      "P-task": "creat partit nand flash am335x evm",
      "F_verb": "create",
      "P-body": "We will be adding our own partition by its name and offset in kernel/arch/arm/mach-omap2/board-am335xevm.c .  ",
      "P-tags": "partit linux",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_5163647",
      "task": "Figuring out Write in Unix",
      "P-task": "figur write unix",
      "F_verb": "write",
      "P-body": "I would think that should be \"packed[j] = ...\", not \"packed[i]\". And as chrisaycock notes, you can just write the whole packed array, you don't need a loop: \"write(openWriteFile, packed, sizeof packed);\" And you should avoid all those literals ... you have 3 instances of 7, one instance of 8, and one instance of 6, when you should have a single defined constant and use that + or - 1 as appropriate. Also jCount is uninitialized. .  EDIT: Here's some code without those problems: .  ",
      "P-tags": "c unix",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in NP"
    },
    {
      "id": "so_28950650",
      "task": "Which config file converts the login password raw text to hash in linux?",
      "P-task": "config file convert login password raw text hash linux",
      "F_verb": "convert",
      "P-body": "On your average Linux distro with PAM, the password is validated against the shadow file by \"pam_unix.so\". This library leverages \"libcrypt.so\" to do the actual hashing.  .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_61519222",
      "task": "Hello, world in assembly language with Linux system calls?",
      "P-task": "hello world assembl languag linux system call",
      "F_verb": "call",
      "P-body": "How does $ work in NASM, exactly? explains how \"$ - msg\" gets NASM to calculate the string length as an assemble-time constant for you, instead of hard-coding it. .   I originally wrote the rest of this for SO Docs (topic ID: 1164, example ID: 19078), rewriting a basic less-well-commented example by @runner. This looks like a better place to put it than as part of my answer to another question where I had previously moved it after the SO docs experiment ended. .   Making a system call is done by putting arguments into registers, then running \"int 0x80\" (32-bit mode) or \"syscall\" (64-bit mode). What are the calling conventions for UNIX & Linux system calls on i386 and x86-64 and The Definitive Guide to Linux System Calls. .  Think of \"int 0x80\" as a way to \"call\" into the kernel, across the user/kernel privilege boundary. The kernel does stuff according to the values that were in registers when \"int 0x80\" executed, then eventually returns. The return value is in EAX. .  When execution reaches the kernel's entry point, it looks at EAX and dispatches to the right system call based on the call number in EAX. Values from other registers are passed as function args to the kernel's handler for that system call. e.g. eax=4 / \"int 0x80\" will get the kernel to call its \"sys_write\" kernel function, implementing the POSIX \"write\" system call.) .  And see also What happens if you use the 32-bit int 0x80 Linux ABI in 64-bit code? - that answer includes a look at the asm in the kernel entry point that is \"called\" by \"int 0x80\". Also applies to 32-bit user-space, not just 64-bit where you shouldn't use \"int 0x80\"). .   If you don't already know low-level Unix systems programming, you might want to just write functions in asm that take args and return a value (or update arrays via a pointer arg) and call them from C or C++ programs. Then you can just worry about learning how to handle registers and memory, without also learning the POSIX system-call API and the ABI for using it. That also makes it very easy to compare your code with compiler output for a C implementation. Compilers usually do a pretty good job at making efficient code, but are rarely perfect. .  libc provides wrapper functions for system calls, so compiler-generated code would \"call write\" rather than invoking it directly with \"int 0x80\" (or if you care about performance, \"sysenter\"). In x86-64 code, use \"syscall\" for the 64-bit ABI.) See also \"syscalls(2)\". .  System calls are documented in section 2 manual pages, like \"write(2)\". See the NOTES section for differences between the libc wrapper function and the underlying Linux system call. Note that the wrapper for \"sys_exit\" is \"_exit(2)\", not the \"exit(3)\" ISO C function that flushes stdio buffers and other cleanup first. There's also an \"exit_group\" system call that ends all threads. \"exit(3)\" actually uses that, because there's no downside in a single-threaded process. .  This code makes 2 system calls: .   \"sys_write(1, \"Hello, World!\\n\", sizeof(...));\"  \"sys_exit(0);\"  I commented it heavily (to the point where it it's starting to obscure the actual code without color syntax highlighting). This is an attempt to point things out to total beginners, not how you should comment your code normally. .  Notice that we don't store the string length in data memory anywhere. It's an assemble-time constant, so it's more efficient to have it as an immediate operand than a load. We could also have pushed the string data onto the stack with three \"push imm32\" instructions, but bloating the code-size too much isn't a good thing. .   On Linux, you can save this file as \"Hello.asm\" and build a 32-bit executable from it with these commands: .  See this answer for more details on building assembly into 32 or 64-bit static or dynamically linked Linux executables, for NASM/YASM syntax or GNU AT&T syntax with GNU \"as\" directives. Key point: make sure to use \"-m32\" or equivalent when building 32-bit code on a 64-bit host, or you will have confusing problems at run-time.) .   You can trace its execution with \"strace\" to see the system calls it makes: .  Compare this with the trace for a dynamically linked process (like gcc makes from hello.c, or from running \"strace /bin/ls\") to get an idea just how much stuff happens under the hood for dynamic linking and C library startup. .  The trace on stderr and the regular output on stdout are both going to the terminal here, so they interfere in the line with the \"write\" system call. Redirect or trace to a file if you care. Notice how this lets us easily see the syscall return values without having to add code to print them, and is actually even easier than using a regular debugger (like gdb) to single-step and look at \"eax\" for this. See the bottom of the x86 tag wiki for gdb asm tips. The rest of the tag wiki is full of links to good resources.) .  The x86-64 version of this program would be extremely similar, passing the same args to the same system calls, just in different registers and with \"syscall\" instead of \"int 0x80\". See the bottom of What happens if you use the 32-bit int 0x80 Linux ABI in 64-bit code? for a working example of writing a string and exiting in 64-bit code. .   related: A Whirlwind Tutorial on Creating Really Teensy ELF Executables for Linux. The smallest binary file you can run that just makes an exit() system call. That is about minimizing the binary size, not the source size or even just the number of instructions that actually run. .  ",
      "P-tags": "nasm system-cal linux assembl x86",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V"
    },
    {
      "id": "so_45406930",
      "task": "Select yes in the terminal via Bash when using iptables-save",
      "P-task": "select ye termin via bash use iptables-sav",
      "F_verb": "save",
      "P-body": "I tried this solution: https://askubuntu.com/questions/339790/how-can-i-prevent-apt-get-aptitude-from-showing-dialogs-during-installation/340846 and it seems to work. .  ",
      "P-tags": "iptabl bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V"
    },
    {
      "id": "su_1569208",
      "task": "PowerShell replace $env:USERPROFILE in prompt",
      "P-task": "powershel replac env : userprofil prompt",
      "F_verb": "replace",
      "P-body": "This will do the replace you're looking for: .  ",
      "P-tags": "prompt powershel find-and-replac command-lin",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    }
  ],
  "5": [
    {
      "id": "ul_523804",
      "task": "How to create files from a list which contain space",
      "P-task": "creat file list contain space",
      "F_verb": "create",
      "P-body": "With the GNU implementation of \"xargs\", you can specify newline as the separator with the \"-d\"/\"--delimiter\" option: .  With short options: .  ",
      "P-tags": "touch xarg",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP which S"
    },
    {
      "id": "so_58881333",
      "task": "how to run commands (print $_siginfo, x/i $pc) in gdb batch mode?",
      "P-task": "run command print _siginfo x pc gdb batch mode",
      "F_verb": "run",
      "P-body": "You need to escape the \"$\" characters as \"\\$\", or use \"''\" quotes instead of \"\"\"\". Otherwise, \"$eip\" is expanded by the shell, typically resulting in the empty string. .  ",
      "P-tags": "gdb shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_61978114",
      "task": "how to show only filename when cut cmd is not working?",
      "P-task": "show filenam cut cmd work",
      "F_verb": "show",
      "P-body": "Try this: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP when S"
    },
    {
      "id": "au_245008",
      "task": "What is the \"right\" way to debianize software that uses the scons build-system?",
      "P-task": "right way debian softwar use scon build-system",
      "F_verb": "use",
      "P-body": "The \"debian/rules\" file is a Makefile. Anything you might want to do in a \"fake\" Makefile, you can just do there. The \"dh\" command  is a helper that will run most build systems with Debian defaults for you. I believe it supports \"scons\" If so, all you need is: .  You can override its default behavior if you need to pass custom options (or if it doesn't really support \"scons\"). Then your rules file might look like: .  Sometimes, the best way to learn how to do something is to look at how other packages do it. The command: .  will list all packages that Build-Depend on \"scons\" Grab their source and see the different ways they build. .  ",
      "P-tags": "packag compil",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_398041",
      "task": "How to set Qalculator as default calculator?",
      "P-task": "set qalcul default calcul",
      "F_verb": "set",
      "P-body": "I solved it following the link in this comment by @Wilf to this Ubuntu Forums thread  .  Ubuntu 13.10 uses the calculator tool \"gnome-caculator\". So instead of messing with the system, the easiest is to fake this shortcut with a symbolic link bound to \"qalculator\" tool.  .  The shortcut works instantly.  .  ",
      "P-tags": "default-program 13 10",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP as NP"
    },
    {
      "id": "so_21668926",
      "task": "Powershell | Unable to perform command with space character",
      "P-task": "powershel unabl perform command space charact",
      "F_verb": "perform",
      "P-body": "Use the \"&\" operator together with quotes: .   From \"help about_operators\": .    ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_15573",
      "task": "How to Optimize an IPTABLES script?",
      "P-task": "optim iptabl script",
      "F_verb": "optimize",
      "P-body": "\"iptables -L -n -v\" .  See also this article: http://greenmice.info/en/node/127, there are some other tips. .  ",
      "P-tags": "linux iptabl",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_57566384",
      "task": "How do I pass a command containing \"-c\" to a remote machine using SSH?",
      "P-task": "pass command contain -c remot machin use ssh",
      "F_verb": "pass",
      "P-body": "you can wrapped it with double quote. .  \"ssh myhost \"$PATHTOPLEXSCANNER -c 3 -s\"\" .  ",
      "P-tags": "ssh command-lin argument shell",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP using NP"
    },
    {
      "id": "so_64937534",
      "task": "Convert JSON to CSV in PowerShell",
      "P-task": "convert json csv powershel",
      "F_verb": "convert",
      "P-body": "I was able to produce the results I wanted in CSV for using the following code. If there is a more efficient way I am glad to learn it. .  ",
      "P-tags": "powershel jira-rest-api export-to-csv hashtabl",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "au_1291778",
      "task": "How can I manage a snap application permissions using command line?",
      "P-task": "manag snap applic permiss use command line",
      "F_verb": "manage",
      "P-body": "Through interfaces (plugs/slots) .  You can manually control connection: .  References: .   https://ubuntu.com/blog/a-guide-to-snap-permissions-and-interfaces https://snapcraft.io/docs/supported-interfaces https://snapcraft.io/docs/interface-management  ",
      "P-tags": "gnome-termin snap permiss command-lin",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP using NP"
    },
    {
      "id": "au_1193306",
      "task": "Debug desktop environment run",
      "P-task": "debug desktop environ run",
      "F_verb": "debug",
      "P-body": "Now I know how to: .  ",
      "P-tags": "pantheon display-manag desktop-environ lightdm",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_13563503",
      "task": "print a big, landscape PDF drawing to a3 LaserJet4 (portrait) using ghostscript 9.0",
      "P-task": "print big landscap pdf draw a3 laserjet4 portrait use ghostscript 9 0",
      "F_verb": "use",
      "P-body": "I found a solution: .    gs -q -sDEVICE=ljet4 -sOutputFile=out.pcl -dFIXEDMEDIA -dPDFFitPage -sPAPERSIZE=a3 \\-c \"\"<</Install {-1 -1 scale -843 -1192 translate}>>\" setpagedevice\" -f SamplePDFnewStamp.pdf -c quit .   ",
      "P-tags": "print ghostscript linux shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_69036374",
      "task": "Take ownership of a folder and set inheritance with PowerShell",
      "P-task": "take ownership folder set inherit powershel",
      "F_verb": "take",
      "P-body": "We will end up using this, even though it's not handling the long file paths correctly. .  ",
      "P-tags": "powershel active-directori",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_17557755",
      "task": "compare string with Regular Expressions in if statement",
      "P-task": "compar string regular express statement",
      "F_verb": "compare",
      "P-body": "One way with \"awk\" .  Output .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "au_419419",
      "task": "How to create shortcut on ubuntu to open a terminal with some folder?",
      "P-task": "creat shortcut ubuntu open termin folder",
      "F_verb": "create",
      "P-body": "The command to open a terminal in a specific folder is .  One can create a \".desktop\" file containing the following details to have a shortcut for this, .  Give it execution permission, as .  It will create a shortcut named \"MyTerminal\", now double click on it to open a terminal in your desired location. .  ",
      "P-tags": "shortcut command-lin",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP S_INF with NP"
    },
    {
      "id": "au_1228801",
      "task": "How can I select an output and set my configuration for pulse audio volume control from the terminal?",
      "P-task": "select output set configur puls audio volum control termin",
      "F_verb": "select",
      "P-body": "Basicaly you have to move your audio stream from one output to another. .  List available outputs .  \"$ pactl list short sinks\" .  List all running audio stream .  \"$ pactl list short sink-inputs\" .  Move each stream to new output using :  .  Enjoy :) .  ",
      "P-tags": "hdmi multiple-monitor sound alsa pulseaudio",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP"
    },
    {
      "id": "so_24326651",
      "task": "How can I use an Environmental Variable as a start of a directory location in powershell?",
      "P-task": "use environment variabl start directori locat powershel",
      "F_verb": "use",
      "P-body": "You'd need to make it a string, otherwise it's interpreting the entire path as a variable. .  or .  ",
      "P-tags": "powershel cmd",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP of NP in NP"
    },
    {
      "id": "au_1000127",
      "task": "If I format Windows drives, will it affect Ubuntu (after I install Ubuntu alongside Windows10)?",
      "P-task": "format window drive affect ubuntu instal ubuntu alongsid windows10",
      "F_verb": "install",
      "P-body": "The data is stored in a separate partition You won't find the Ubuntu system data in Windows. They are in a separate partition completely hidden from Windows 10. .  A drive, a hard disk drive (HDD) or a solid state drive (SSD) is a physical object. What Windows people call a drive, such as \"C:\\\" drive or \"D:\\\" drive are partitions.in either inside a single drive or in two separate drives. .  Ubuntu (any Linux) uses a different partition naming scheme Ubuntu uses \"/dev/sda1\" or \"/dev/sda2\" for two partitions on the same drive or \"/dev/sda1\" or \"/dev/sdb1\" for two partitions in two different drives. A default Ubuntu installation may use one or two partitions.  .  Windows 10 does not know anything about Ubuntu partitions These partitions are formatted differently as compared with Windows partitions in a format called \"ext4\". Windows cannot see partitions formatted this way. In a default Ubuntu installation a partition (it may be \"/dev/sda1\", \"/dev/sda5\" or \"/dev/sdb1\" etc.) is mounted at the mount point \"/\". To the user, the system partition is \"/\". This is something similar to \"C:\\\" in Windows. .  If you have C D E F partitions... If you have a 1TB drive and 4 partitions C, D, E, F in Windows 10 each partition 250GB each, then you don't have any space to install Ubuntu. You will have to delete at least one of these partitions (not C, as you want Ubuntu along side Windows) or shrink one or more of them to make some unallocated space in your disk drive. Ubuntu installation will find that empty unallocated space and create the partition(s) it needs there. .  After you install Ubuntu, formatting any of the Windows partitions C, D, etc. will not delete any data or system files in the Ubuntu partition \"/\". .  See Ubuntu Installation Root partition for more on the \"/\" partition. .  See What is the meaning of the default directories in the Linux filesystem hierachy? for how the system files and personal data folders are structured within Ubuntu. .  See What are the advantages and disadvantages of mounting various directories on separate partitions? for why one may mount various system folders as separate partitions. .  Hope this helps .  ",
      "P-tags": "dual-boot partit system-instal boot grub2",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP alongside NP"
    },
    {
      "id": "so_53373991",
      "task": "Bash if statement to check for like 1 letter and 2 numbers",
      "P-task": "bash statement check like 1 letter 2 number",
      "F_verb": "check",
      "P-body": "Square brackets introduce character classes, so .  matches any of the three characters: \"f\", \"|\", or \"F\". .  Similarly, .  matches \"1\", \"0\" to \"9\", and \"9\", which is equivalent to \"[0-9]\" or \"[0123456789]\". .  So, you need .  Note that this works with plain \"=\", too, no need to use regular expressions, as the right hand side is interpreted as a pattern unless quoted: .  ",
      "P-tags": "digit if-stat regex bash alphabet",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V for NP"
    },
    {
      "id": "ul_44130",
      "task": "Is it safe to resize partition on /?",
      "P-task": "safe resiz partit",
      "F_verb": "resize",
      "P-body": "If you are using \"/dev/sda1\" as your current system root, you will be unable to unmount it, and doing so would prevent you from running parted from it anyway. .  \"resize2fs\" is able to enlarge ext3/4 filesystems while mounted on newer kernels, but not shrink them. .  Your best bet is probably to use the gparted live CD or gparted included with System Rescue CD. These will let you boot Linux on a CD and then resize your hard drive's partition without mounting it. .  If this is not an option, you will need to have a separate Linux installation on another partition or device that you can boot for resizing; or go through the long painful process of backing up, re-creating the partition from scratch, and restoring the backup. .  ",
      "P-tags": "mount disk ubuntu",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "au_299802",
      "task": "migrate git repositories",
      "P-task": "migrat git repositori",
      "F_verb": "migrate",
      "P-body": "You can simply copy the directory with the normal filesystem tools, or run a \"git clone\" on the new machine to copy, since you seem to already have the exiting machine set up as a server. .  ",
      "P-tags": "git server",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_43707685",
      "task": "`set -u` (nounset) vs checking whether I have arguments",
      "P-task": "set -u nounset vs check whether argument",
      "F_verb": "check",
      "P-body": "\"$#\" contains the number of arguments, so you can test for \"$1\", \"$2\", etc. to exist before accessing them. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V whether S"
    },
    {
      "id": "au_107119",
      "task": "Why is my new user being asked for a sudo password?",
      "P-task": "new user ask sudo password",
      "F_verb": "ask",
      "P-body": "The \"ubuntu\" user on a live CD is configured with a blank (empty) password. Once you have installed ubuntu you will want to then configure sudo. .  Please note that many people, myself included, consider making this change to be a security risk (see the rootsudo page for details) .  use sudoers to make the chages .  Add in a line at the bottom of the file,  .  See Ubuntu wiki rootsudo and man sudoersfor details. .  As an alternate, especially over ssh, I simply open a root shell .  Yes I still have to enter a root password, but only once. This maintains both security and convenience.  .  When working over ssh, you might also be interested in screen ;) .  ",
      "P-tags": "secur sudo user",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V for NP"
    },
    {
      "id": "so_63529392",
      "task": "Remove-Item or Rename-Item that contains [ and/or ]",
      "P-task": "remove-item rename-item contain",
      "F_verb": "rename",
      "P-body": "The string \"[abc]\", in the context of path resolution in PowerShell at least, is interpreted as a wildcard pattern. It has the same meaning as it does in regex, \"any one of these characters\". .  So, if you do \"Get-Item -Path 'file[test].txt'\", \"Get-Item\" attempts to resolve it to any file named \"filet.txt\", \"filee.txt\", or \"files.txt\". .  Use the \"-LiteralPath\" parameter with the provider cmdlets to suppress wildcard expansion in paths: .  ",
      "P-tags": "powershel bracket",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP that S"
    },
    {
      "id": "so_64928694",
      "task": "Writing and reading named pipes",
      "P-task": "write read name pipe",
      "F_verb": "read",
      "P-body": "\"doing nothing\" is very different than \"has runtime error\". If you run \"./write\" and the program blocks, that is expected behavior. The \"fopen\" will not return until some other process has opened the fifo for reading. .  Open a second terminal and execute your consumer while the producer is running. .  ",
      "P-tags": "pipe named-pip linux mkfifo c",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_38757594",
      "task": "Cross compiling portAudio for Intel Edison",
      "P-task": "cross compil portaudio intel edison",
      "F_verb": "compile",
      "P-body": "I also ran into this issue and the easiest way is to source the environment file again after doing a sudo su on the same command line and then do a make install. .  Here are the steps I followed to cross compile portaudio for intel edison: .   Download the cross compiler edison-toolchain-20150120-linux64.tar.bz2 and the script toolchain-20140724-linux64.sh from this link .  Extract the toolchain, run the script (you can put it in your home directory somewhere if you wish) and set up the cross-compile environment .      Check the environment on your shell:    Configure, compile and install portaudio: .    ",
      "P-tags": "cross-compil linux intel-edison portaudio linker",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP for NP"
    },
    {
      "id": "so_64945919",
      "task": "Getting args[1] from linux terminal in Assembly",
      "P-task": "get arg 1 linux termin assembl",
      "F_verb": "get",
      "P-body": "Ok I was able to fix it, this is the current way tp get argv[1]: .  I move word to ebx, since I want to get the first 2 chars from the argv[1] (the '-c' flag) .  ",
      "P-tags": "nasm linux assembl x86",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_62267714",
      "task": "bash check if the outputs (.txts) in multiple directories contained certain string",
      "P-task": "bash check output txt multipl directori contain certain string",
      "F_verb": "contain",
      "P-body": "\"for i in *\" will only process the files under the directory where your script is called from. It will not go down directories recursively. .  If you want to process the current directory, and all sub-directories, you should use \"find\" to do such a task. Like this: .  This will return a list of all files that do not contain \"finished without error\". .  Details: .   \"find .\": will run the find on the current directory (\".\") \"-type f\": will only perform the action on files. Directories are traversed, but the grep will not be attempted on those. \"-exec SOMETHING \\;\": will execute SOMETHING for each file that matches the \"find\" condition. Here the only one is \"-type f\". So it will execute SOMETHING for each file. \"\\;\" is to let \"find\" that the arguments to \"-exec\" are complete. Here SOMETHING is: \"grep -L \"finished without error\" {}\". \"-L\" of \"grep\" lists the filename if the search does not find what you searched for. \"{}\" tells the \"find\" command to execute the \"grep\" command on the current file it found.  So it will traverse your directories, find each file and run the \"grep\" on each of those files. \"grep\" will output the filenames that do not contain the text. .   For your script, you can put your code in https://www.shellcheck.net/, it will let you know your syntax errors and propose solutions. Like \"$finished\" should probably not have the \"$\" in there. I guess it is simple text. Unless you have a \"$finished\" variable defined somewhere, but in the code you put here, it is not initialized. Same for \"$parentdir\" .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_379524",
      "task": "find syntax error",
      "P-task": "find syntax error",
      "F_verb": "find",
      "P-body": "You're missing the trailing semicolon, which has to be escaped from the shell, such as: \"\\;\" or \"';'\". .  The find man page says this: .   -exec command ; .  Execute command; true if 0 status is returned. All following arguments to find are taken to be arguments to the command  .   ... .  Attention here: .   until an argument consisting of ';' is encountered. .   ... .   The string '{}' is replaced by the current file name being processed everywhere it occurs in the arguments to the command, not just in arguments where it is alone, as in some versions of find. Both of these constructions might need to be escaped (with a '\\') or quoted to protect them from expansion by the shell.  .   ... .  ",
      "P-tags": "find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_36826189",
      "task": "Convert XML to Dictionary",
      "P-task": "convert xml dictionari",
      "F_verb": "convert",
      "P-body": "You have to load the content using the Get-Content cmdlet and cast it to \"[xml]\". Use the \"SelectNodes\"cmdlet and a \"xpath\" expression to select all descendants and convert it to a hashtable: .  Output: .  Edit: Here is a working example with a dictionary: .  ",
      "P-tags": "xml powershell-2 0 powershel dictionari powershell-3 0",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "su_1209515",
      "task": "Linux: \"Password reset by root is not supported\"...so how do I reset passwords?",
      "P-task": "linux : password reset root support reset password",
      "F_verb": "reset",
      "P-body": "The clues start with knowing that the \"/etc/nsswitch.conf\" file on the system is used to configure the Name Service Switch facility in Linux. From wikipedia: .   The Name Service Switch (NSS) is a facility in Unix-like operating systems that provides a variety of sources for common configuration databases and name resolution mechanisms. These sources include local operating system files (such as /etc/passwd, /etc/group, and /etc/hosts), the Domain Name System (DNS), the Network Information Service (NIS), and LDAP. .   This line from the \"/etc/nsswitch.conf\" file lets us know that the Linux \"System Security Services\" (sss) is the provider for user passwords and related functions. .  The next clue comes from the contents of \"/etc/sssd/sssd.conf\". The man page for this configuration file tells us about the \"chpass_provider\" entry, and for me that is ipa: .  And this line lets us know what server(s) are responsible for running the ipa services: .  Finally, I just had to log on to \"ipa1.sub.domain.mycompany.com\", where I see that \"ipa\" is indeed installed, as well as LDAP. A couple judicious internet searches led me to this Redhat page pertaining to managing passwords via IPA, that gave me these helpful steps: .  Voila, done! Lesson learned: My lab system is kind of a hodge-podge of servers configured in a (perhaps) non-standard way, but a couple knowledgeable people can give you some clues to point you in the right direction, and following the bread crumbs and doing some Internet searches will hopefully reveal the answer. .  ",
      "P-tags": "linux password password-manag",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP"
    },
    {
      "id": "so_7506644",
      "task": "Using Declare Inside a Function in Bash",
      "P-task": "use declar insid function bash",
      "F_verb": "declare",
      "P-body": "Did you try using export? .  ",
      "P-tags": "global-vari shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V inside NP in NP"
    },
    {
      "id": "su_1408438",
      "task": "Avoid opening the same file in multiple Okular instances",
      "P-task": "avoid open file multipl okular instanc",
      "F_verb": "open",
      "P-body": "Here is a quick and dirty trick : it is a Python script that just checks for an existing instance. .  To use it, rename \"/usr/bin/okular\" to \"/usr/bin/okular.real\" and save this script as \"/usr/bin/okular\". .  ",
      "P-tags": "okular linux",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP"
    },
    {
      "id": "so_32487465",
      "task": "Linux command (Calculating the sum)",
      "P-task": "linux command calcul sum",
      "F_verb": "calculate",
      "P-body": "You can use \"awk\" piped to \"sort\": .  \"sums[$1] += $2\" is adding value of \"$2\" in an array \"sums\" that is indexed by field #1 (\"$1\").  .  \"sort -rnk2\" is reverse sorting numerically output of \"awk\" on field 2  .  ",
      "P-tags": "linux command shell",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP"
    },
    {
      "id": "so_54386420",
      "task": "Angular 7 does not launch prompts when enter \"ng new myProject\"",
      "P-task": "angular 7 launch prompt enter ng new myproject",
      "F_verb": "launch",
      "P-body": "You typed \"mg new myProject\" instead of \"ng new myProject\".  .  \"mg\" Documentation: http://manpages.ubuntu.com/manpages/xenial/man1/mg.1.html .  UPDATE: It seems that \"ng\" has been wrongly mapped. Running the below command, will solve the issue: .  Then install \"angular-cli\": .  ",
      "P-tags": "ubuntu-18 04 angular-cli",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP when S"
    },
    {
      "id": "so_13711855",
      "task": "linux script to kill java process",
      "P-task": "linux script kill java process",
      "F_verb": "kill",
      "P-body": "You can simply use \"pkill -f\" like this: .  EDIT: To kill a particular java process running your specific jar use this regex based pkill command: .  ",
      "P-tags": "linux kill-process bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "so_46900542",
      "task": "How to manage custom libraries in a similar way to VS solutions (where VS builds dependencies automatically)?",
      "P-task": "manag custom librari similar way vs solut vs build depend automat",
      "F_verb": "manage",
      "P-body": "Using the structure you laid out in your comment, it could be something like this .  Note that there is no special dependencies between C and D, since static libraries are often nothing more than simple archives of object files. Static libraries are not really linked themselves, you need to provide all static libraries when linking the executable, even if any of them is not used directly by the application. .  If the libraries are shared then it's a little different: .  Shared libraries are linked and very similar to executable targets. Therefore the target \"A\" doesn't need to specify the indirect dependency on \"D\", since it's linked into \"C\". .  [Note: The CMake commands shown above might not the exact syntax and arguments needed. Read the documentation for the exact syntax.] .  ",
      "P-tags": "linux c++ dependency-manag development-environ clion",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP to NP where S"
    },
    {
      "id": "so_63282702",
      "task": "Can't build SSDL from the source code of the book C++ for the Lazy Programmers",
      "P-task": "build ssdl sourc code book c++ lazi programm",
      "F_verb": "build",
      "P-body": "Just because they both have \"SDL\" in the name does not mean they are part of the same library. If you search for \"SDL_ttf.h\" on packages.ubuntu.com (\"contents of packages\"), it will tell you that you want the \"libsdl2-ttf-dev\" package .  This is also mentioned in the accompanying documentation. .  ",
      "P-tags": "ssdl c++ ubuntu",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP of NP"
    },
    {
      "id": "au_69099",
      "task": "How do I remove the shutdown confirmation menu?",
      "P-task": "remov shutdown confirm menu",
      "F_verb": "remove",
      "P-body": "For 11.10 Run \"dconf-editor\" (either Alt+F2 or from terminal, must be installed first) .  uncheck \"logout-prompt\" .  I still haven't found a way to return restart to the menu and suppress that confirmation. thanks for the edit fossfreedom) .  ",
      "P-tags": "shutdown notif menu",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_116737",
      "task": "How do I pick up a previous modification in VIM?",
      "P-task": "pick previou modif vim",
      "F_verb": "pick",
      "P-body": "You can use \":reg\" to view all actions in \"vim\" then paste that deleted lines by pressing \"2 ctrl + p .  Read more  .  ",
      "P-tags": "vim",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V up NP in NP"
    },
    {
      "id": "ul_383645",
      "task": "How to activate AP mode in configuration files?",
      "P-task": "activ ap mode configur file",
      "F_verb": "activate",
      "P-body": "I ended up putting in \"/etc/rc.conf\": .  It worked. .  ",
      "P-tags": "freebsd",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP in NP"
    },
    {
      "id": "su_368231",
      "task": "Automatic versioning upon file change (modify/create/delete)",
      "P-task": "automat version upon file chang modifi creat delet",
      "F_verb": "modify",
      "P-body": "1. General purpose method using bazaar & inotify This is untested by me but I found this write up that makes use of \"bzr\" (bazaar) & \"inotifywait\" to monitor a directory and version control the files in it using bazaar. .  This script does all the work of watching the directory for changes: .  2. Managing /etc For the special case of managing your system's \"/etc\" directory, you can use the app etckeeper. .   etckeeper is a collection of tools to let /etc be stored in a git, mercurial, darcs, or bzr repository. It hooks into apt (and other package managers including yum and pacman-g2) to automatically commit changes made to /etc during package upgrades. It tracks file metadata that revison control systems do not normally support, but that is important for /etc, such as the permissions of /etc/shadow. It's quite modular and configurable, while also being simple to use if you understand the basics of working with revision control. .   Here's a good tutorial to get you started with it. .  3. Using git and incron This technique makes use of \"git\" and \"incron\". For this method you need to do the following: .  A. Make a repo .  B. Create a \"$HOME/bin/git-autocommit\" script .  C. Add an entry to incrontab .  4. Using Flashbake Another option is to use a tool like Flashbake. Flashbake is the version control system that Cory Doctorow (of BoingBoing fame) uses to write his books. .  Flashbake uses git under the hood to track changes but is somewhere between doing automated backups and using a plain version control system yourself. .   Cory wanted the version to carry prompts, snapshots of where he was at the time an automated commit occurred and what he was thinking. I quickly sketched out a Python script to pull the contextual information he wanted and started hacking together a shell script to drive git, using the Python script\u2019s output for the commit comment when a cron job invoked the shell wrapper. .   Resources  Automatic file revision on upload  ",
      "P-tags": "version linux version-control",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_54312527",
      "task": "Powershell Get-ChildItem -Depth property issues",
      "P-task": "powershel get-childitem -depth properti issu",
      "F_verb": "get",
      "P-body": "The usage of \"-Depth\" seems to exclude the usage of \"-Include\" or even a wildcard in the \"-Path\" parameter.  .  Let \"-Filter\" do the work, in this sample tree: .  This one liner: .  returns: .  ",
      "P-tags": "powershel get-childitem",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_36496212",
      "task": "How to search a collection with an array in Powershell",
      "P-task": "search collect array powershel",
      "F_verb": "search",
      "P-body": "I would flip that array on its head and create a hashtable from it. Then use the first matching search term as a lookup key for the category: .  ",
      "P-tags": "array powershel powershell-3 0",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_666254",
      "task": "How to get just the number from units?",
      "P-task": "get number unit",
      "F_verb": "get",
      "P-body": "With \"GNU Units version 2.19\": .  BSD implementation of \"units\" doesn't have \"--one-line --compact\" but you can use awk: .  ",
      "P-tags": "unit command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "au_1078877",
      "task": "Disable python versions for certain users without uninstalling python",
      "P-task": "disabl python version certain user without uninstal python",
      "F_verb": "disable",
      "P-body": "I did this by using the \"acl\" permissions. I just removed access to wrong python versions for my target user group. simple as that, nothing is broken(can't believe anyone suggested this). .  Install acl Remount system disk with acl support Edit \"fstab\": .  Add \"acl\" support if not there already, for example changing from .  To: .  Remount the root: .  Set access rights Create symbolic link for python3 so that both python and python3 works for my target user group: .  Update acl permissions so that access is removed from system python versions for user group \"blocked\": .  ",
      "P-tags": "python",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP for NP without S_ING"
    },
    {
      "id": "so_12799559",
      "task": "How do I kill a Bash script if it can't find or read a file?",
      "P-task": "kill bash script find read file",
      "F_verb": "kill",
      "P-body": "Just before reading, check if the file exists: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP if S"
    },
    {
      "id": "so_26419068",
      "task": "How to find Logstash is at EOF?",
      "P-task": "find logstash eof",
      "F_verb": "find",
      "P-body": "I have achieved my goal by comparing size of file with offset provided in sincedb file. .  yields current offset of file logstash's file pointer in logfile. While .  yields total size in bytes. So comparing it .  ",
      "P-tags": "eof logstash bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP at NP"
    },
    {
      "id": "ul_301247",
      "task": "Why doesn't setuid work with mount?",
      "P-task": "setuid work mount",
      "F_verb": "mount",
      "P-body": "Unix has the concept of real and effective UIDs (and GIDs for that matter). .  When you run a setuid program then the effective ID of the process is set to the owner of the file. .  So in the case of \"mount\" you have an effective ID of \"root\". But you still have a real ID of \"user\". .  Programs such as \"passwd\" or \"su\" or \"mount\" can check the real ID to see who is running it and act differently accordingly. For \"passwd\" this allows the \"root\" user to change another's password; for \"su\" it allows switching users without knowing the password. .  For \"mount\" it allows users to mount their own filesystems if they are defined in \"/etc/fstab\" and have the \"user\" attribute associated with them .  eg in my Debian \"fstab\" I have: .  This means a non-root user can run \"mount /dev/sr0\" or \"mount /media/cdrom0\" and it will attempt to mount the CD/DVD. .  This is logic built into the \"mount\" program itself; it checks the real ID of the caller. .  ",
      "P-tags": "mount linux setuid",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "au_659427",
      "task": "Can't access VirtualBox shared folder",
      "P-task": "access virtualbox share folder",
      "F_verb": "access",
      "P-body": "Add your user to the vboxsf group: .  ",
      "P-tags": "virtualbox",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP"
    },
    {
      "id": "so_21048123",
      "task": "How to pass a command from Shell script to command line",
      "P-task": "pass command shell script command line",
      "F_verb": "pass",
      "P-body": "Tell \"ssh\" to send them to the remote shell to be executed. .  ",
      "P-tags": "ssh linux shell bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "ul_291054",
      "task": "Find and Replace with command line",
      "P-task": "find replac command line",
      "F_verb": "replace",
      "P-body": "To add the specified text to a line in the file - if that line is the only one that starts with \"mynetworks\", you can do this: .  ",
      "P-tags": "awk grep sed text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V with NP"
    },
    {
      "id": "so_35519307",
      "task": "How to get all information with all images in site",
      "P-task": "get inform imag site",
      "F_verb": "get",
      "P-body": "You can try this : .  It works with your example and should do the trick on your html if the code related to product and image is always structured the same way. .  But a web-scraping library like BeautifulSoup in python would be a better choice. .  A BeautifulSoup python code looks like this : .  ",
      "P-tags": "imag download curl bash wget",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_570886",
      "task": "To grab descriptor from a file",
      "P-task": "grab descriptor file",
      "F_verb": "grab",
      "P-body": "Replace the new line with the delimiter you wish, .   \"tr '\\n' '\\t'\" will replace the newline char with tab.  and remove \"echo '/t';\" in the script. .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_69437733",
      "task": "Compare 2 CSVs using PowerShell",
      "P-task": "compar 2 csv use powershel",
      "F_verb": "compare",
      "P-body": "By default, \"Compare-Object\" outputs only the value that it compared on. .  In order to make it copy all input properties to the ouput, use the \"-PassThru\" parameter: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP using NP"
    },
    {
      "id": "so_53274365",
      "task": "How to extract value from XML payload using Shell script",
      "P-task": "extract valu xml payload use shell script",
      "F_verb": "extract",
      "P-body": "You could use the following xmlstarlet and sed command: .  \"-T\": raw test (without XML node). \"-t\": template \"-c\": Xpath expression .  \"[@status='FAIL']\" is the test on the attribute \"status\". .  \"value[contains(.,'testId')]\" tests if the \"value\" node contains that specific string. .  The \"sed\" command extracts the wanted string. .  ",
      "P-tags": "shell unix java",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "so_11068623",
      "task": "Too large hierarchy tree using Recursion , makes file searching to crash",
      "P-task": "larg hierarchi tree use recurs make file search crash",
      "F_verb": "make",
      "P-body": "You can remove the recursion (i.e. convert to an iterative solution) by storing the directories as you see them (instead of processing them immediately) and then coming back around to them on some later iteration. However, you might not get precisely identical output (things may be ordered differently). .  The way this method works is by having a list of directories to process, and you go through this list (adding any child directories to it as you go). .  In psuedocode/Python: .  A stack can be implemented as a singly linked list fairly easily. Note that special handling is required if \"path\" is not a directory, and that this isn't recursive. .  ",
      "P-tags": "recurs linux ubuntu file c",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "su_1612484",
      "task": "Why do I see strange characters when using \u201ccat\u201d on a zlib compressed file?",
      "P-task": "see strang charact use cat zlib compress file",
      "F_verb": "see",
      "P-body": "When used on a very basic level \u2014 such as \"cat filename\" \u2014 the \"cat\" command simply takes the contents of a file and writes them to standard output until the end of the file is reached. .  A compressed document is effectively a binary file. Compression of text files makes them smaller in size but they are no longer text files after compression; they are now binary files. .  So when you run a basic \"cat\" command against a binary file it will display the raw contents of that file directly and that is what the \"xK??OR04d?H????/?I;{<%\" is; compressed binary contents of a now compressed text file. .  That said, in the case of binary files one can pipe the output of \"cat\" to another program that expects/uses binary input. .  For example, if I have a text file named \"textfile.txt\" and I compress it with Gzip so the filename is now \"textfile.txt.gz\", I can run this command to \"cat\" the file contents to \"gzip\" so I can read in in the terminal as a decompressed text file. .  ",
      "P-tags": "compress unix",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP when S"
    },
    {
      "id": "ul_479486",
      "task": "Does sudo restrict on which users can acquire superuser privileges?",
      "P-task": "sudo restrict user acquir superus privileg",
      "F_verb": "restrict",
      "P-body": "\"sudo\" does NOT automatically grant privs if the user password is correct.  .  It will always request the user password, THEN verify whether it is appropriate for the user to attain privileges (as per the \"/etc/sudoers\" file as edited by \"visudo\" by the \"root\" user). If the user fails to get privs, it is logged and if configured the administrator gets an email. .  This method offers some type of security in that you cannot tell what privs the user has unless the user enters the proper account password. .  Thus if the user is NOT in the \"sudoers\" file then unless the user has the \"root\" password and uses the \"su\" command, then the user cannot acquire superuser privs. There are ways to protect this type of access as well. .  ",
      "P-tags": "sudo",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V on which S"
    },
    {
      "id": "so_54101292",
      "task": "Run some commands as one user, and access variables set by another user",
      "P-task": "run command one user access variabl set anoth user",
      "F_verb": "run",
      "P-body": "A slight modification of your first example should work: .  \"-H\" is needed to set the \"$HOME\" variable of the user based on this. .  Regarding the backslashes, the distinction here between \"\\$HOME\" and \"$ROOT_VAR\" is quite tricky. When the command is parsed, \"$ROOT_VAR\" is actually expanded to it's real value. In other words, the value of \"cmd\" is the following: .  You need to use backslashes to avoid parsing of \"whoami\" and \"$HOME\" in the root's environment and instead pass on the execution of the command to the user's bash itself. .  ",
      "P-tags": "linux multilin ubuntu-18 04 bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP"
    },
    {
      "id": "su_1651965",
      "task": "Is there a way to chunk/split up a redirected file into several files?",
      "P-task": "way chunk split redirect file sever file",
      "F_verb": "split",
      "P-body": "If you have GNU split you can use something like .  See man split for more options. .  With POSIX split you would have to use alphabetic suffixes instead of numeric ones. .   At the time of this answer, the question does not tell how long or for how much data the command will run or how the resulting files will be used. This simple solution might not be sufficient if the pipeline is expected to run for a long time. .  Possible problems that may require additional thoughts: .   Terminated processes might need to be restarted. Handle file switching in a program that processes the data. Remove old output files if the number or total size exceeds a limit. The numeric suffix generated by \"split\" might overflow or wrap around when it reaches a certain limit.  ",
      "P-tags": "linux command-lin",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V up NP into NP"
    },
    {
      "id": "so_30712738",
      "task": "Getting linux system UUID which changes after reboot",
      "P-task": "get linux system uuid chang reboot",
      "F_verb": "get",
      "P-body": "The solution: .  I found it while searching for systemd's \"boot id\". There was a DBus bug report referencing the file: https://bugs.freedesktop.org/show_bug.cgi?id=23679 .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP which S"
    },
    {
      "id": "su_324874",
      "task": "Execute a terminal command without saving it to .bash_history on OS X?",
      "P-task": "execut termin command without save bash_histori os x",
      "F_verb": "execute",
      "P-body": "Add the following line to ~/.bashrc .  Then \"source ~/.bashrc\" to refresh the settings .  This should enable that feature in bash. If it doesn't work, you might have to add it to ~/.bash_profile instead of ~/.bashrc since OS X loads them a bit differently than linux I think. .  ",
      "P-tags": "termin command-lin maco histori bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without S_ING to NP on NP"
    },
    {
      "id": "so_66987357",
      "task": "Powershell not capturing colorized Git output",
      "P-task": "powershel captur color git output",
      "F_verb": "capture",
      "P-body": "This is not a PowerShell issue but actually with Git. Git changes the output depending on how the output is processed. In GNU/Linux, for example: .  If I pipe it through \"cat\" for example then the output changes to: .  It wasn't just the colour in your example as the parantheses were removed as well. .  What you are seeing in PowerShell is the same behaviour: .  And then piped through something: .  And so to fix the problem you need to tell Git to generate output in a specific way, e.g. .  ",
      "P-tags": "git powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_6757149",
      "task": "Bash - Convert sub.site.com in to com_site_sub?",
      "P-task": "bash - convert sub site com com_site_sub",
      "F_verb": "convert",
      "P-body": "You can mess with \"$IFS\" to change how things like \"read\" parse text: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in to NP"
    },
    {
      "id": "so_24858704",
      "task": "phpredis errors Class Redis not found in Linux",
      "P-task": "phpredi error class redi found linux",
      "F_verb": "find",
      "P-body": "The command line probably does not use the same php.ini file than the web server. Use \"phpinfo();\" to know which configuration file is loaded in both cases and then declare your extension in the ini file used by your web server. .  ",
      "P-tags": "nginx redi php linux phpredi",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP"
    },
    {
      "id": "so_46687607",
      "task": "Reading values from CSV files and storing in local variable in PowerShell",
      "P-task": "read valu csv file store local variabl powershel",
      "F_verb": "read",
      "P-body": "The script block after the \"ForEach-Object\" cmdlet has to start on the same line. Otherwise PowerShell won't connect them together. .   Another problem, that your will face eventually, is that your code does process only the last line in the CSV file. .  You most probably actually want to process the parsed out values within the \"ForEach-Object\" script block. Like this: .  ",
      "P-tags": "sftp powershel csv winscp",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP in NP in NP"
    },
    {
      "id": "au_109530",
      "task": "How do I restore my KDE desktop to default?",
      "P-task": "restor kde desktop default",
      "F_verb": "restore",
      "P-body": "To reset you user's KDE modifications to defaults open a terminal and type .  Log off and log back in and all the KDE settings will be recreated fresh. .  That will move the folder where KDE keeps his settings in to another folder with \".old\" in the end of the name. When you log in KDE will create a new \".kde4\" folder and all the settings used will be the default. .  If you want to restore the previous settings you need to have a backup in your home folder inside the \".kde4.old\" folder. .  ",
      "P-tags": "kubuntu kde",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_4527",
      "task": "Program that passes STDIN to STDOUT with color codes stripped?",
      "P-task": "program pass stdin stdout color code strip",
      "F_verb": "pass",
      "P-body": "You'd think there'd be a utility for that, but I couldn't find it. However, this Perl one-liner should do the trick: .  Example: .  Or, if you want a script you can save as \"stripcolorcodes\": .  If you want to strip only color codes, and leave any other ANSI codes (like cursor movement) alone, use .  instead of the substitution I used above (which removes all ANSI escape codes). .  ",
      "P-tags": "color filter pipe",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "au_1023674",
      "task": "Ubuntu doesn't add hard drive to media folder",
      "P-task": "ubuntu add hard drive media folder",
      "F_verb": "add",
      "P-body": "Yes you can. Create a folder in the \"/media\" folder: .  Then get your \"UUID\" of the drive to be mounted: .  Take note of the \"UUID=\" like \"UUID=\"98b0a711-18a1-4303-b374-0c8d31bae473\"\". Also, take note of the \"TYPE=\" as this will be used when creating the line used in \"/etc/fstab\" .  Then add an entry to your \"/etc/fstab\" file with the \"UUID=\": .  Now, every time you boot the computer up that drive should mount at the same point. .  Hope this helps! .  ",
      "P-tags": "boot ssd hard-driv dual-boot",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_74957",
      "task": "Is there a PowerShell \"string does not contain\" cmdlet or syntax?",
      "P-task": "powershel string contain cmdlet syntax",
      "F_verb": "contain",
      "P-body": "If $arrayofStringsNotInterestedIn is an [array] you should use -notcontains: .  or better (IMO) .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_59301387",
      "task": "how to jump from one directory to another on the unix path",
      "P-task": "jump one directori anoth unix path",
      "F_verb": "jump",
      "P-body": "You can use \"Alt + F\" to go forward and \"Alt + B\" to go backawards in a path. .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V from NP to NP on NP"
    },
    {
      "id": "so_2355148",
      "task": "Run a string as a command within a Bash script",
      "P-task": "run string command within bash script",
      "F_verb": "run",
      "P-body": "You can use \"eval\" to execute a string: .  ",
      "P-tags": "command-line-argu shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP within NP"
    },
    {
      "id": "so_66138699",
      "task": "Rewrite curl so that quotes inside variable are allowed",
      "P-task": "rewrit curl quot insid variabl allow",
      "F_verb": "rewrite",
      "P-body": "Based on a comment, credits to @Benjamin W. : .  That works perfectly. Maybe we can improve by avoiding a temporary variable. .  Thanks. .  ",
      "P-tags": "bot double-quot one-lin curl bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP that S"
    },
    {
      "id": "au_1021922",
      "task": "How to identify an existing NFS or CIFS mount, is a hard or soft mount?",
      "P-task": "identifi exist nf cif mount hard soft mount",
      "F_verb": "identify",
      "P-body": "Check the respective manpages. \"man mount.nfs\" points to \"man 5 nfs\" for details, which says: .  So the default unless specified otherwise for NFS is hard. .  And \"man mount.cifs\" says: .  And the default for CIFS is soft. .  ",
      "P-tags": "mount nf cif",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_22976776",
      "task": "convert scientific notation to decimal (not integer) in bash/perl",
      "P-task": "convert scientif notat decim integ bash perl",
      "F_verb": "convert",
      "P-body": "As Jim already proposed, one way to do this is to simply treat the number as a string and do the translation yourself. This way you're able to fully maintain your significant digits. .  The following demonstrates a function for doing just that. It takes in a number that's potentially in scientific notation, and it returns the decimal representation. Works with both positive and negative exponents: .  ",
      "P-tags": "decim scientific-not perl bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_13526130",
      "task": "get-childitem System.OutOfMemoryException",
      "P-task": "get-childitem system outofmemoryexcept",
      "F_verb": "get",
      "P-body": "did you try using \"dir /b LotsOfFiles\" ? .  ",
      "P-tags": "windows-server-2003 powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_41006555",
      "task": "Exclude directory when grepping with zsh globbing",
      "P-task": "exclud directori grep zsh glob",
      "F_verb": "exclude",
      "P-body": "This should work: .  Explanation:  \"^build\": anything not named \"build\" \"^build/\": any directory not named build. It will not match any other file type \"(^build/)#\": any directory path consisting out of elements that are not named \"build\". Again, this will not match a path where the last element is not a directory \"(^build/)#*\": Any path where all but the last element must not be named \"build\". This will also list files. It also assumes that it would be ok, if the file itself were named \"build\". If that is not the case you have to use \"(^build/)#^build\" \"(^build/)#*(.)\": Same as before, but restricted to only match normal files by the glob qualifier \"(.)\"  ",
      "P-tags": "linux glob oh-my-zsh zsh",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP when S"
    },
    {
      "id": "so_7962283",
      "task": "How do I calculate the log of a number using bc?",
      "P-task": "calcul log number use bc",
      "F_verb": "calculate",
      "P-body": "Invoke \"bc\" with the \"-l\" option (to enable the math library) like so .  Use the \"l\" function which is the natural log. Take the log of the number you are interested in then divide by the natural log of 10. .  ",
      "P-tags": "bc unix",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP of NP using NP"
    },
    {
      "id": "so_921661",
      "task": "Run lynx -dump in background?",
      "P-task": "run lynx -dump background",
      "F_verb": "run",
      "P-body": "Lynx wants to talk to your terminal, but can't, so it does a SIGSTP (tty input) and waits for you to foreground the process. .  As mgb said above: use wget. \"wget -O tmpfile http://example.com\" does the same thing as what you're doing with lynx above. .  ",
      "P-tags": "lynx job-control background-process bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "au_271123",
      "task": "How can I turn off the nvidia splash on startup?",
      "P-task": "turn nvidia splash startup",
      "F_verb": "turn",
      "P-body": "in your xorg.conf you can enable the following option .  it will disable the boot screen as long as the configuration file doesn't change. Worked on my alienware m11x and macbook pro .  ",
      "P-tags": "12 10 nvidia",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_122853",
      "task": "problem with text added to pdf under Xournal after exporting to pdf",
      "P-task": "problem text ad pdf xournal export pdf",
      "F_verb": "add",
      "P-body": "This seems like a fairly old bug with Xournal. I found this thread describing the exact same issue as well, titled: \"copy text from pdf problem (xournal). Using the latest version (0.47), I was able to reproduce the issue as well.  .  \u00a0\u00a0\u00a0 .  I then exported the annoted PDF as a new PDF and then copied the annotated string \"This is some extra text.\" and attempted to paste it in \"vim\". Doing so I got this string: \"8LMW MW WSQI I\\XVE XI\\X\". .  I can continuously repeat this problem over and over. It's definitely an issue with the annotation done by Xournal. The pre-existing text, \"PDF 3\" worked fine when I copy and pasted it. .  Alternative? You might want to try using Okular which can also annotate PDF files. .  \u00a0\u00a0\u00a0 .  ",
      "P-tags": "pdf",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V to NP under NP after S_ING to NP"
    },
    {
      "id": "ul_550783",
      "task": "fdisk shows the partition table of a device, but udev doesn't create the device",
      "P-task": "fdisk show partit tabl devic udev creat devic",
      "F_verb": "show",
      "P-body": "For some reason the Linux kernel isn't recognizing the partition table, so it doesn't know there should be an \"sdh1\". Unless you've done something weird (like compiling a kernel w/o DOS partition table support), that probably means the partition table format isn't exactly as expected by the kernel (\"fdisk\" is a different implementation of parsing the partition table, so that could be why fdisk is OK with it). Likely re-writing the partition table with \"fdisk\" (etc.) would fix it. .  However, if you want to mount the partition w/o re-writing the table (e.g., to not modify the disk), then you can manually feed the partition details to the kernel with \"addpart\": .  After running that (and waiting a tiny bit for udev), you should have a \"/dev/sdh1\", which you can go ahead and mount. .  ",
      "P-tags": "mount",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP"
    },
    {
      "id": "so_25102607",
      "task": "run command in interactive opend bash with python",
      "P-task": "run command interact opend bash python",
      "F_verb": "run",
      "P-body": "This can be done with pure pipes, but it's going to be hard. And even harder if you use \"os.popen()\" instead of using \"subprocess\". .  The right way to script an interactive program is to use a higher-level library that's designed to make it easy, like \"pexpect\". Then you just write something like: .   However, a much better solution is to not run VLC in interactive mode; just run it in batch mode and pass it commands. Going out of your way to have it treat your input as a TTY just so you can try to figure out how to act like a human at a TTY is making things harder for no good reason. .  Or, even better, use libVLC instead. As you can see from that link, there are Python bindings for it. .   If you really want to do it interactively, and you want to do it manually over pipes, you will have to be very careful. If you don't mind just deadlocking on any unexpected results, you can do something like this: .  As you can see, this is a lot less fun. .   And if you insist on using \"os.open\" instead even though it's deprecated and even more painful to use, you obviously can't write to it if you open the pipe in the default \"'r'\" mode, just like any other file-like object, and of course tacking \".read()\" on the end means you don't even have the \"popen\" object anymore, you just stored the first buffer it gave you and then leaked the handle. If you change that to open in \"'r+'\" mode, if that works on your platform, and you store the \"popen\" object itself, you can use it similarly to the \"subprocess.Popen\" object above, using \"child.write\" and \"child.read\" instead of child.stdin.write\"and\"child.stdout.read`. .  ",
      "P-tags": "python os system shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_21778701",
      "task": "Replace a statement with another one with shell script",
      "P-task": "replac statement anoth one shell script",
      "F_verb": "replace",
      "P-body": "Try this approach: .  When you're happy with the output change the sed-command to \"sed -i.bak\" instead to do inline-replace. .  Explanation: .   The \"find\" command searches recursively from the current folder and down for all files named \".html\" a bash while-read loop read one line at a time of the output from the find-command \"sed\" is then used for searching for the desired pattern and the pattern \"\\(...\\)\" is called a caption-group that stores the matching text in a variable that can accessed using \"\\1\" which is called a back-reference.  The proper way to read and operate on each line of a file in bash is to use .  In our case, we don't have a file, instead we'd like to operate on each line of the output of a command, enter process substitution \"<(...)\" You can of course redirect the find-command to a file using redirection \"find ... > file\" and then operate on that. .  Update: .  As pointed out by @tripleee the while-loop can be dropped completely: .  The \"sed '...' $(find...)\" construct executes the part in \"$()\" in a subshell, delivering all the matching files as parameters to the sed-command as seen below .  If you have a lot of html-files, the shell might throw an error due to too long command-line; if that is the case \"xargs\" is your friend (man xargs). .  ..or (Linux is full of TMTOWTDI), let \"find\" execute the sed-part for all matching files (one at a time), in that way you don't risk the problem of getting a too long command line: .  ",
      "P-tags": "sed bash shell regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP with NP"
    },
    {
      "id": "so_57341677",
      "task": "How can I run an expect script to SSH in a server and set a value inside a bash script",
      "P-task": "run expect script ssh server set valu insid bash script",
      "F_verb": "run",
      "P-body": "expect is built atop tcl which is a fully functional scripting language with datetime facilities built-in. You don't need to pass a shell variable into the expect body here: .  ",
      "P-tags": "expect ssh bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF in NP"
    },
    {
      "id": "au_420855",
      "task": "How to create a HDR file from set of image files?",
      "P-task": "creat hdr file set imag file",
      "F_verb": "create",
      "P-body": "You can use Luminance HDR. .   .  Supported features .   Create an HDR file from a set of images (formats: JPEG, TIFF 8bit and 16bit, RAW) of the same scene taken at different exposure setting; Save load HDR images; Rotate, resize and crop HDR images; Tonemap HDR images; Copy exif data between sets of images; Supports internationalization.   Tnstall Luminance HDR in ubuntu .  Source and more information .  ",
      "P-tags": "12 04 jpeg",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP of NP"
    },
    {
      "id": "au_745737",
      "task": "Windows 10 randomly kicks out my GRUB, how do I reinstall it?",
      "P-task": "window 10 randomli kick grub reinstal",
      "F_verb": "reinstall",
      "P-body": "Boot from Ubuntu installation media.  .  Select 'Try Ubuntu without installing'.  .  On desktop open a terminal, execute:  .  Note:  .  \"sda\" = disk | \"sda2\" = efi partition | \"sda7\" = system partition  .  Boot into BIOS - select Ubuntu as default operating system. .  ",
      "P-tags": "dual-boot partit boot uefi grub2",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "au_495920",
      "task": "php5enmod returns command not found",
      "P-task": "php5enmod return command found",
      "F_verb": "find",
      "P-body": "\"php5enmod\" was introduced in Debian in version \"5.4.0~rc6-2\" of the package \"php5\" (see the changelog, Ctrl+F is your friend). Since Ubuntu packages are imported from Debian, it is only available in PHP 5.4+ packages in Ubuntu as well. .  ",
      "P-tags": "12 04 php",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_47377306",
      "task": "Rename the most recent file in each group",
      "P-task": "renam recent file group",
      "F_verb": "rename",
      "P-body": "Selecting the latest entry in each group You can use \"sort\" to select only the latest entry in each group: .  First, sort all files in reversed lexicographical order (so that the latest entry appears first for each group). Then, by sorting on group name only (that's second field \"-k2,2\" when split on underscores via \"-t_\") and printing unique groups we get only the first entry per each group, which is also the latest. .  Note that this works because \"sort\" uses a stable sorting algorithm - meaning the order or already sorted items will not be altered by sorting them again. Also note we can't use \"uniq\" here because we can't specify a custom field delimiter for \"uniq\" (it's always whitespace). .  Copying with prefix To add prefix to each filename found, we need to split each path \"find\" produces to a directory and a filename (basename), because we need to add \"prefix\" to filename only. The \"xargs\" part above could look like: .  Path splitting is done with shell parameter expansion, namely prefix (\"${1##*/}\") and suffix (\"${1%/*}\") substring removal. .   Note the use of \"NUL\"-terminated output (paths) in \"find\" (\"-print0\" instead of \"-print\"), and the accompanying use of \"-z\" in \"sort\" and \"-0\" in \"xargs\". That way the complete pipeline will properly handle filenames (paths) with \"special\" characters like newlines and similar. .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_27932737",
      "task": "Split a string containing fixed length columns",
      "P-task": "split string contain fix length column",
      "F_verb": "split",
      "P-body": " This can be done with RegEx matching, and creating an array of custom objects. Something like this: .  That will take each line, match by how many characters are specified, and then create an object based off those matches. It collects all objects in an array and could be exported to CSV or whatever. The 'Col1', 'Col2' etc are just generic column headers I suggested due to a lack of better information, and could be anything you wanted. .  Edit: Thank you iCodez for showing me, perhaps inadvertantly, that you can specify a language for your code samples! .  ",
      "P-tags": "string split pars powershel",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP"
    },
    {
      "id": "so_41556592",
      "task": "How can I treat a string as a sequence of hexadecimal values in PowerShell?",
      "P-task": "treat string sequenc hexadecim valu powershel",
      "F_verb": "treat",
      "P-body": "Simples: .  (ToInt16 can be used too, but the built-in Int type is actually a shorthand for Int32) .  ",
      "P-tags": "hex char powershell-2 0 type-convers powershel",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP as NP of NP in NP"
    },
    {
      "id": "so_41640381",
      "task": "I want to get the first 3 octets of my default gateway",
      "P-task": "want get first 3 octet default gateway",
      "F_verb": "get",
      "P-body": " ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_13130836",
      "task": "Ruby On rails : need to run /bin/bash before any rails command",
      "P-task": "rubi rail : need run bin bash rail command",
      "F_verb": "run",
      "P-body": "This looks like a path issue to me. When you run \"rails\" the first time, it's finding a global rubygems installation before your local \"rvm\" copy.  .  After you run \"/bin/bash\" from the command line, you are starting an interactive shell, which sources (executes) \"~/.bashrc\". My guess is that that contains the rvm initializations that are failing to run when you login with a login shell. .  Take a look at \"~/.bash_profile\" and \"~/.bashrc\". Here is what the latest RVM installer generates: .  If this is what you've got, then you're somehow logging in through an interactive shell and not a login shell (how???). You should be able to fix both issues with \"source ~/.bash_profile\" (\".bash_login\" in OS X). .  ",
      "P-tags": "linux ruby-on-rail bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP before NP"
    },
    {
      "id": "so_44582224",
      "task": "Azure Search set ReplicaCount by Automation graphical runbook",
      "P-task": "azur search set replicacount autom graphic runbook",
      "F_verb": "set",
      "P-body": "Following commenters, I ended up by making PowerShell runbook. .  I uploaded powershell source code to below link; .  https://gallery.technet.microsoft.com/scriptcenter/Azure-Search-change-c0b49c4c .  Let me attach the code as below; .  ",
      "P-tags": "azur powershel azure-cognitive-search azure-autom",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP by NP"
    },
    {
      "id": "so_39220449",
      "task": "How to run ubuntu command on specific time",
      "P-task": "run ubuntu command specif time",
      "F_verb": "run",
      "P-body": " Login to your server with terminal .   Type \"sudo -s\" to become sudoer .   Type \"crontab -e\" to edit your crontab .   Add \"0 14 * * * /etc/init.d/openfire restart\" to restart Openfire everyday at 2 PM .   Save your file .   Recheck with \"crontab -l\" .  Depending on your version, you could use \"/bin/systemctl\" to restart service instead of /etc/init.d .    ",
      "P-tags": "ubuntu",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_11459324",
      "task": "Is there a way to suppress the \"extra\" output from Write-Error cmdlet?",
      "P-task": "way suppress extra output write-error cmdlet",
      "F_verb": "suppress",
      "P-body": "I think isn't possible limit the output of an error but you can workaround like this: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP from NP"
    },
    {
      "id": "au_230967",
      "task": "Eclipse ide unable to locate files in localhost",
      "P-task": "eclips ide unabl locat file localhost",
      "F_verb": "locate",
      "P-body": "I'm guessing you haven\u2019t made any changes to the default apache config so the apache server is looking for your files in /var/www/ .  You need to learn about Apache and configuring it there is an abundance of info out there. .  the quick and easy way to fix this for development use only is:  .  \"sudo ln -s /path/to/project /var/www\" .  ",
      "P-tags": "php eclips",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_14849421",
      "task": "Use of get-date in powershell to create a log string",
      "P-task": "use get-dat powershel creat log string",
      "F_verb": "get",
      "P-body": "Try: .  The \"$()\" expand value from functions or from variable's property es: $($myvar.someprop) when they are inside a string. .  ",
      "P-tags": "getdat powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V"
    },
    {
      "id": "so_28921823",
      "task": "Parsing git log with readarray bash script",
      "P-task": "pars git log readarray bash script",
      "F_verb": "parse",
      "P-body": "The \"here-string\" syntax (\"<<<\") is a bash extension; it is not present in basic shells. It's not strictly bash; many other shells use it, too.) The same is true of arrays, and the \"readarray\" command. .  So you need to make sure that you are using \"bash\" to run the script. Your shebang line (\"#!/bin/sh\") tells the system to use a basic shell, and if the basic shell on your system is not bash, it may well not have \"<<<\". .  Try changing the shebang line to .  (Make sure that is the correct path to \"bash\". You can verify with \"which bash\".) .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP with NP"
    },
    {
      "id": "so_25007345",
      "task": "Create table of two user's AD groups",
      "P-task": "creat tabl two user ad group",
      "F_verb": "create",
      "P-body": " Try this, tested successfully on PS2: .  ",
      "P-tags": "array powershel format",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_108653",
      "task": "Why does \"ls\" require a separate process for executing?",
      "P-task": "ls requir separ process execut",
      "F_verb": "require",
      "P-body": "The answer is more or less that \"ls\" is an external executable. You can see its location by running \"type -p ls\". .  Why isn't \"ls\" built into the shell, then? Well, why should it be? The job of a shell is not to encompass every available command, but to provide an environment capable of running them. Some modern shells have \"echo\", \"printf\", and their ilk as builtins, which don't technically have to be builtins, but are made so for performance reasons when they are run repeatedly (primarily in tight loops). Without making them builtins, the shell would have to fork and exec a new process for each call to them, which could be extremely slow. .  At the very least, running \"ls\", an external executable, requires running one of the exec family of system calls. You could do this without forking, but it would replace the primary shell that you are using. You can see what happens in that instance by doing the following: .  Since your shell's process image is replaced, the current shell is no longer accessible after doing this. For the shell to be able to continue to run after running ls, the command would have to be built into the shell. .  Forking allows the replacement of a process that is not your primary shell, which means you can continue to run your shell afterwards. .  ",
      "P-tags": "ls cd-command fork",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_67555332",
      "task": "Powershell Forms Progressbar not updated correctly",
      "P-task": "powershel form progressbar updat correctli",
      "F_verb": "update",
      "P-body": "Okay, I think Windows Forms is a little flaky, but despite my comment above, it seems to be more reliable if you don't set the value, but set the Step instead, because you are moving the bar a set figure each time. This then uses \"PerformStep()\" to increase the bar. Doing both i.e. setting the value and using \"PerformStep()\" was confusing matters. .  Like this: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_49884752",
      "task": "Shortest way to print last file modified in bash?",
      "P-task": "shortest way print last file modifi bash",
      "F_verb": "print",
      "P-body": "Use tail -1 to get the last line. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "su_1584415",
      "task": "Powershell regular expressing to match over multiple lines and replace a small part of what it finds in multiple documents",
      "P-task": "powershel regular express match multipl line replac small part find multipl document",
      "F_verb": "match",
      "P-body": "@TessellatingHeckler had the answer I needed. This is my working solution, simply adding both \"-Raw\" and \"(?s)\" .  ",
      "P-tags": "powershel find-and-replac regex",
      "source": "qa",
      "cate": "match",
      "pat": "V over NP"
    },
    {
      "id": "so_31571225",
      "task": "Create executable file for comand line Linux",
      "P-task": "creat execut file comand line linux",
      "F_verb": "create",
      "P-body": "You can add a shell function in your \".bashrc\" and restart your terminal: .  Whenever you want to go to that directory, you just run \"csf\".  .  ",
      "P-tags": "linux shell command-lin",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "so_55295558",
      "task": "How do I use Function in PowerShell to execute from Command Line?",
      "P-task": "use function powershel execut command line",
      "F_verb": "execute",
      "P-body": "You have to call your function inside your script. The script code is like your \"main\" function in C# or Java. .  PowerShell.ps1 content : .  ",
      "P-tags": "powershel cmd",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V from NP"
    },
    {
      "id": "su_214855",
      "task": "Show names of created virtual consoles in screen (Linux)",
      "P-task": "show name creat virtual consol screen linux",
      "F_verb": "create",
      "P-body": "You can use the caption command with several Screen-specific escape codes. .  For example, try appending this to your \".screenrc\", and restartng \"screen\": .  ",
      "P-tags": "linux gnu-screen",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_9460140",
      "task": "gpg encrypt file without keyboard interaction",
      "P-task": "gpg encrypt file without keyboard interact",
      "F_verb": "encrypt",
      "P-body": "As David intimated, the problem here is that gpg doesn't trust the public key you're using to encrypt. You could sign the key as he explained. .  An alternative--especially if the key might be changing occasionally--would be to tack on \"--trust-model always\" to your gpg command. .  Here's the relevant bit from the man page: .    ",
      "P-tags": "crontab gnupg bash",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP without NP"
    },
    {
      "id": "so_47202582",
      "task": "How the checkpoint in JBD2 is managed when kernel needs to free memory urgently?",
      "P-task": "checkpoint jbd2 manag kernel need free memori urgent",
      "F_verb": "manage",
      "P-body": "Q1) The \"buffer_head\" is not freed until the checkpoint is performed, because it is much more expensive freeing the buffer, then loading it back from disk to memory rather than keeping the \"buffer_head\" in memory to checkpoint in a short delta time. .  Q2) Checkpoint can be delayed or can be performed before a commit due to no free blocks in journal area on disk, so checkpoint is started to release blocks to be used by the upcoming commit. .  ",
      "P-tags": "ext4 c filesystem linux-kernel",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V when S"
    },
    {
      "id": "au_976797",
      "task": "How do I install a keyboard layout?",
      "P-task": "instal keyboard layout",
      "F_verb": "install",
      "P-body": "First you should give the layout variant a name; see \"/usr/share/X11/xkb/symbols/se\" for examples. Then add it to \"/usr/share/X11/xkb/symbols/se\" and add a corresponding entry to \"/usr/share/X11/xkb/rules/evdev.xml\". .  Edit: .  I tested the steps in the \"update\" section of your question, and it worked fine for me after having rebooted. The layout is shown in a submenu of Swedish (Sweden). .  For testing subsequent changes, rebooting isn't necessary, but this command should suffice: .  Edit II: .  I have a theory (untested) on why the layout isn't working as robustly as you would wish. Try to change the two first lines in \"svorak-a5\": .  to .  ",
      "P-tags": "keyboard-layout",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_66499387",
      "task": "SHELL SCRIPT LINUX set password using user input",
      "P-task": "shell script linux set password use user input",
      "F_verb": "set",
      "P-body": "\"$username:$password\" should be the input to the \"chpasswd\" command. You're piping the output of \"chpasswd\" to a command formed from that. Since the username:password isn't the name of a command, you get an error. .  What you want is: .  ",
      "P-tags": "linux script shell",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_359611",
      "task": "I would like to find the largest file in each directory recursively",
      "P-task": "would like find largest file directori recurs",
      "F_verb": "find",
      "P-body": "Combining \"find\" and \"awk\" allows the averages to be calculated too: .  Laid out in a more readable manner, the AWK script is .  This expects null-separated input records (I stole this from muru\u2019s answer); for each input record, it .   stores the size (for later use), removes everything before the first character in the path (so we at least handle filenames with spaces correctly), extracts the directory, extracts the filename, adds the size we stored earlier to the sum of sizes in the directory, increments the number of files in the directory (so we can calculate the average), if the size is larger than the stored maximum size for the directory, or if we haven\u2019t seen a file in the directory yet, updates the information for the biggest file.  Once all that\u2019s done, the script loops over the keys in \"SUMSIZES\" and outputs the directory, average size, largest file\u2019s name and size. .  You can pipe the output into \"sort\" to sort by directory name. If you want to additionally format the sizes in human-friendly form, you can change the \"printf\" line to .  and then pipe the output into \"numfmt --field=1,2 --to=iec\". You can still sort the result by directory name, you just need to sort starting with the third field: \"sort -k3\". .  ",
      "P-tags": "size file find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_27273998",
      "task": "why elasticsearch won't run on Ubuntu 14.04?",
      "P-task": "elasticsearch run ubuntu 14 04",
      "F_verb": "run",
      "P-body": "Elasticsearch service init script doesn't print any error information on console or log file when it fails to startup, instead it ridiculously shows \"[OK]\". .  You have to run elaticsearch manually with the same user and same parameters as what the init script does to check what's going wrong. The error message will be printed on console. .  On my Ubuntu 14.10 with elasticsearch-1.4.1.deb installed, without any path changed, the command to run elastisearch is: .  I just added a line into \"/etc/init.d/elasticsearch\" to print out the above command: .  ",
      "P-tags": "ubuntu elasticsearch",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V on NP"
    },
    {
      "id": "so_14387231",
      "task": "subprocess.call() does not return when using pydev",
      "P-task": "subprocess call return use pydev",
      "F_verb": "return",
      "P-body": "I'm not 100% here, but doesn't \"exit\" just kill the script? To return a value when you exit to script, use \"return\".. so Try this PS script instead: .  ",
      "P-tags": "pydev powershel python",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V when S"
    },
    {
      "id": "au_218377",
      "task": "Install/Remove Language show only English, no other choice",
      "P-task": "instal remov languag show english choic",
      "F_verb": "install",
      "P-body": "Something appears to be missing. It's not the fact that you might have skipped language support at the time of installation as I have an EeePC that I installed without a network connection and I can indeed get to a full language selection screen by clicking the Install/Remove Languages button as per the instructions below. .  The only things I can think for you to do at the moment is install the languages individually as suggested by Mowgli, or try to re-install the gnome language selector and see if that fixes the problem: .  You then need to open the language selector from system settings and click on the button Install/Remove Languages. You will get a separate window that opens where you can select additional languages to install. .   .  ",
      "P-tags": "language-support 12 10",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_788027",
      "task": "How to create backup CDs of my audio CD collection from the command line?",
      "P-task": "creat backup cd audio cd collect command line",
      "F_verb": "create",
      "P-body": "To back up my audio CD collection from the commandline I start by installing the \"cdrtools\" package rather than use the Debian fork \"cdrkit\". This replaces parts of the \"cdrkit\" package so just be aware that some adjustment may be required with other burning applications. To install Brandon's burning PPA: .  Next to test for the exact address of my CD drive: .  On my system this gives \"0,0,0\" so this address is used to rip the CD and also perform a CDDA lookup: .  Then all that is required is to burn the files to a new, blank CD: .  And repeat, until I have safely backed up my collection. I have used \"cdrdao\" in the past but this technique has worked flawlessly for some time now... .  References: .   YoLinux Tutorial: Burning a CD or DVD  ",
      "P-tags": "16 04 burn command-lin",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_7104711",
      "task": "How to extract the lines between patterns?",
      "P-task": "extract line pattern",
      "F_verb": "extract",
      "P-body": "This assumes you are using bash as your shell. For other shells, the actual solution can be different. .  Assuming your data is in \"data\": .  Change \"[PATTERN]\" by your actual separation pattern. .  This will create files \"file.1\", \"file.2\", etc. .  Edit: responding to request about an awk solution: .  The idea is to open a new file each time the \"[PATTERN]\" is found (skipping that line - \"next\" command), and writing all successive lines to that file. If you need to include \"[PATTERN]\" in your generated files, delete the \"next\" command. .  Notice the escaping of the \"[\" and \"]\", which have special meaning for regular expressions. If your pattern does not contain those, you do not need the escaping. The \"^\" and \"$\" are advisable, since they tie your pattern to the beginning and end of line, which you will usually need. .  ",
      "P-tags": "grep script shell bash sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP between NP"
    },
    {
      "id": "so_36582692",
      "task": "How to run the mongo shell on Ubuntu",
      "P-task": "run mongo shell ubuntu",
      "F_verb": "run",
      "P-body": "I think I solved the connectivity problem based on this question: .  Then I run as indicated in the link shown above the commands: .  An now all seems to be working ok. .  ",
      "P-tags": "mongodb ubuntu",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "au_508844",
      "task": "Why does hitting Control + C when in an application launched from a script, break the script?",
      "P-task": "hit control + c applic launch script break script",
      "F_verb": "break",
      "P-body": "When you send a signal like \"SIGINT\" (CtrlC) or \"SIGSTOP\" (CtrlZ) from a terminal, the signal is sent to the foreground process group. That is, the group comprising of the foreground job (your script), and any child processes it has in the foreground (the \"tail\" command). This causes all these processes to exit (or do whatever it is they do by handling the signal). You can test the difference by sending a signal using the \"kill\" command: .  In one terminal, execute this script (I'm calling it \"test\" in the following commands): .  In another, execute these commands: .  The output of the commands would be something like this: .  (The actual numbers and programs may vary, but the first init will always have pid 1.) As you can see, the \"yes\" command wasn't killed, and got attached to \"init\" because its parent was killed. It's still merrily printing \"y\"s on the first terminal. So kill it with \"pkill -f yes\". Now repeat the experiment, with one change. Instead of \"pkill -f test\", do: .  Note the leading \"-\". In Linux, for the \"kill\" command, \"-25165\" is the process group, whose leader has pid \"25165\". Thus, this command is the equivalent of sending an interrupt from the terminal. .  Of course, the exact behaviour depends on the configuration of the TTY, the login shell and so on. This is as far as my understanding goes. Further reading: .   Sending and Trapping Signals Preventing propagation of SIGINT to Parent Process The TTY demystified   I suggest: .   Sending the \"tail\" to the background Trap the signal Kill the background process. Remove the trap  An example: .  This can become very powerful, by using different functions for trapping, and each doing their own clean up work. .  ",
      "P-tags": "script bash",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP"
    },
    {
      "id": "so_16558185",
      "task": "Assign a header to multiple files, Linux",
      "P-task": "assign header multipl file linux",
      "F_verb": "assign",
      "P-body": "run this code once to preserve the original files without the header information: .  run this code every time your header file changes .  where myfile1, myfile2 and myfile3 are the 3 original files you were referring and header is the file containing the ever changing header information. .  ",
      "P-tags": "awk cat grep linux sed",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "so_21264178",
      "task": "awk Replace second field with millisecond from first field",
      "P-task": "awk replac second field millisecond first field",
      "F_verb": "replace",
      "P-body": "With bash: .  ",
      "P-tags": "awk sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP from NP"
    },
    {
      "id": "ul_515574",
      "task": "extract lines containing patterns file and save them in different files grep, sed, awk, print",
      "P-task": "extract line contain pattern file save differ file grep sed awk print",
      "F_verb": "contain",
      "P-body": "Given a \"patterns\" file: .  Then .  results in the following files: .  ",
      "P-tags": "awk grep text-process bash sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_998610",
      "task": "Remove certain fields from a line",
      "P-task": "remov certain field line",
      "F_verb": "remove",
      "P-body": "Maybe like this: .  Or you can do the second part with \"cut\": .  Notes  \"-r\" use ERE \"s|old|new|\" replace \"old\" with \"new\" \"[^/]*\" any number of characters that are not \"/\" \"$\" end of line \"/?\" zero or one \"/\" \"(pattern)\" save \"pattern\" to reference later with \"\\1\" \".*\" any number of any characters \"|\" (unquoted) shell pipe - passes output of left hand side command to right hand side command \"cut -d '/'\" use \"/\" as delimiter \"-f 1,2,3\" print the first three fields  ",
      "P-tags": "command-lin text-process script cut-command rsync",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_18919576",
      "task": "How to enforce the type of a global variable?",
      "P-task": "enforc type global variabl",
      "F_verb": "enforce",
      "P-body": "try declaring it like this: .  If I do this: .  I got an error. I can't replicate your issue. .  ",
      "P-tags": "type variabl powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_79718",
      "task": "Get 'less' to display filename",
      "P-task": "get less display filenam",
      "F_verb": "get",
      "P-body": "Why pipe \"less\" into anything? That turns it into \"cat\". The obvious answer is .  You'll get output of the form .  If you pass the option \"-n\" to \"grep\", you also get line numbers: .  Many editors have some form of file search built in, with the search results appearing in a window where you can select a line to open the corresponding file at the corresponding location. In Emacs, run \"M-x grep\" or one of its variants. In Vim, run \":grep\" or one of its variants. .  ",
      "P-tags": "arch-linux less grep",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_41965909",
      "task": "Using awk to iterate unix command nm and sum output through multiple files",
      "P-task": "use awk iter unix command nm sum output multipl file",
      "F_verb": "iterate",
      "P-body": "You need to put the read $filename in a while; do; done loop and feed the output of the entire loop to awk. .  e.g. .  the awk {print $0} will print each file's line so you can see each one. .  ",
      "P-tags": "awk nm bash",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP through NP"
    },
    {
      "id": "so_58359548",
      "task": "How to write automake files to recursive build subdirectories?",
      "P-task": "write automak file recurs build subdirectori",
      "F_verb": "write",
      "P-body": "You say you're interested in .   how to create makefile.am files for each subdirectories so that autotool can build the project in the build directory .   , but this is not an appropriate goal, as this example itself demonstrates. It is rarely useful or appropriate to have a \"Makefile.am\" that does not define any targets to be built. You have stipulated that you don't want to build Pet as a library, so what target would a \"Makefile.am\" in its directory define? Similar applies to \"Dog\" if you want to avoid building it as a library. There is little or no point to using recursive \"make\" in this situation. .  I do note, however, that Automake has the concept of a \"convenience library\", which is an intermediate target that is never itself installed, but contains object code that can be linked into an executable or a larger library. I will demonstrate this later, as it's the most sensible way to set up the makefile-per-directory structure you are asking for in this particular case. .  Additionally, with respect to directing the output to a specific directory in the source tree: this can be done, but it is probably a waste of effort. The Autotools already provide a convenient method for out-of-source building that more easily accomplishes the goal of separating the build results from the source in the event that the person building the project wishes to do that. .  NEVERTHELESS, the basics of recursive builds with the Autotools are pretty simple. There are two main things to do: .   each \"Makefile.am\" that wants to express a recursion into one or more subdirectories does so by listing the relative paths to each of those subdirectories in the variable \"SUBDIRS\". .  the project \"configure.ac\" must designate of the \"Makefile\"s to be built via its \"AC_CONFIG_FILES\" macro. .   That's all you need to do to set up the recursion generally, and the details of how to set up specific targets and options are project-specific. .    Is that possible we build the hello.exe at \"build\" directory instead of \"build/HelloWorld/\" directory? To do this, do I have to put the \"bin_PROGRAMS\" at the \"./Makefile.am\"   Yes, you can specify building into \"build/hello\" rather than \"build/HelloWorld/hello\". You might not strictly have to put the corresponding \"bin_PROGRAMS\" into the top-level \"Makefile.am\", but you definitely should put it there or in a \"build/Makefile.am\" file. I urge you to avoid trying to have any makefile build targets outside the tree rooted at the directory where that particular makefile resides. .    I do not want to build Pet as librarys, I'm wondering whether there is a way I can just tell automake to find source codes in different locations.   You can absolutely specify source files in a different directory from the \"Makefile.am\". Just provide the appropriate path, relative to the makefile's directory. This makes more sense for sources in the same tree as the makefile, but using sources located elsewhere is not as much of an issue as trying to build targets elsewhere. .    I know that using non-recursive makefile would be easier. But I just want to learn how to create recursive makefiles for multiple directories.   Non-recursive makefiles are not necessarily easier than recursive ones, but they are generally better, because they express the whole target / prerequisite tree as a unit instead of chopping it up into pieces. \"make\" can make better build decisions when it has all the information at once. .   I just started learning automake things, and I know these codes do not work at all. .   My answer to your related question provides a recursive solution to a related problem. It demonstrates one of the key principles that you seem to be missing: the variables specifying a target's sources and other build properties need to appear in the same \"Makefile.am\" file in which the target itself is defined. Each \"Makefile.am\" corresponds to a separate makefile. To a first approximation, data are not shared between makefiles, so all the information needed to build a given target needs to appear in the same one. .  The other thing that seems to distinguish this question from your other is that you want (however wrongheadedly) to specify a particular output directory in your makefile. Do remember that wherever the built files initially go, it is a staging area -- it doesn't much matter, because they get put in their final destination by \"make install\". Even so, you can specify a target residing in a different directory by giving the correct relative path to it. Of course, such a change to the target name needs to be reflected in the names of the variables derived from the target name. .  Here, then, is a recursive Automake setup that should build your example project using one makefile per source directory: .   Makefile.am .  Pet/Makefile.am .  HelloWorld/Makefile.am .  HelloWorld/Dog/Makefile.am .   Your \"configure.ac\" ought to work with that as-is. .  Note this does not rely on \"VPATH\"; it builds specifically into the \"build/\" subdirectory of the build tree, including when you build directly in the source tree. .  ",
      "P-tags": "linux autotool automak autoconf",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_467779",
      "task": "samba - permission denied when share in another users home directory",
      "P-task": "samba - permiss deni share anoth user home directori",
      "F_verb": "deny",
      "P-body": "You've got a classic ownership/permissions problem here. You've told SAMBA to allow access to \"/home/hoster/sharetest\" only to \"equah\" but your underlying filesystem permissions deny access to that user (\"drwx------ 19 hoster hoster 4096 Sep 8 20:20 /home/hoster\"). .  Allow \"equah\" access to the directory and it should be ok .  Or force the access by \"equah\" to be performed by \"hoster\" .  In general this kind of problem can be diagnosed using \"log level = 3\" and looking in the SAMBA server log files. .  ",
      "P-tags": "permiss samba",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V when S"
    },
    {
      "id": "so_63996283",
      "task": "Custom systemd service to run Gunicorn not working",
      "P-task": "custom systemd servic run gunicorn work",
      "F_verb": "run",
      "P-body": "Your systemd service is setup to execute the script from behalf of \"django\" user. In the meantime: .  \"ls -lah /home/django\" .  As you can see: .  and .  which means: .   \"/home\" directory belongs to \"root:root\" \"/home/django/bin\" belongs to \"root:root\"  To let \"systemd\" execute a bash script from behalf of \"django\" user: .   That script should be executable All parent directories should have execution rights All those directories and the script should be available for \"django\" user  The quickest solution: .  Also you could play with group and group rights as well. .  ",
      "P-tags": "django ubuntu-18 04 server gunicorn",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_ING"
    },
    {
      "id": "au_285543",
      "task": "How do I install and configure a Security Card (CAC) Reader for Ubuntu 13.04",
      "P-task": "instal configur secur card cac reader ubuntu 13 04",
      "F_verb": "configure",
      "P-body": "#Install packages .  #Install CacKey Cackey is available at https://software.forge.mil/sf/projects/community_cac  Ironically enough, it requires CAC access to login. .  If you cannot access DISA's Forge.mil website, (Because it requires CAC access) .  You can Download the 32bit Deb file here. .  Or, the 64 bit Deb here. .  Download .deb  Use Software Center to install by double-clicking on the .deb You will get a warning about the package being of low quality. Just continue. .  After it finishes installing, open a terminal and run \"pcsc_scan\" to test the card reader. .  *** Note: For 13.10 I had to create a /usr/lib64 directory before CACkey would install. The command to use is \"sudo mkdir /usr/lib64\" . After creating that directory it installed fine. *** .  #Download DoD certs http://dodpki.c3pki.chamb.disa.mil/rootca.html  Click on each link to download. You will get warnings about these not being approved, just click \"OK\" .  #Add CAC Module to Firefox as a Security Device 1.Edit > Preferences Menu .  2.Advanced Section .  3.Certificates Tab .  4.Security Devices Button .  5.Load Button .  In the Dialoge box that pops up enter \"CAC Module\" as the module name, & enter \"/usr/lib64/libcackey.so\" as the module filename. .  #Test your set-up You can test your set-up by logging into a site that requires CAC access such as https://www.us.army.mil .  You should be prompted for the \"Master Password\". This is simply your PIN associated with your card. .  For what it's worth this has worked flawlessly for me in 13.04. Even Enterprise E-mail OWA, which I could not get to work under 12.10. *** Update: Tested with 13.10 works great, including access to OWA. *** .  ",
      "P-tags": "secur",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "au_646052",
      "task": "No firefox update ubuntu 14.04",
      "P-task": "firefox updat ubuntu 14 04",
      "F_verb": "update",
      "P-body": "It will be updated, when maintainers decide. .  Stable 39 has been released on July 2. .  Next version can be installed from ppa .  This is an Official Firefox PPA .  Note: Generally this ppa contains next beta version of Firefox. I do no recommend keeping this ppa always connected. It can be removed by .  but packages installed from this ppa will stay. No new updates will be done. .  Update: Firefox 39 is already available from standard Ubuntu repositories. .  ",
      "P-tags": "14 04 updat firefox",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_524480",
      "task": "Why does delete work but not arrow keys in terminal?",
      "P-task": "delet work arrow key termin",
      "F_verb": "delete",
      "P-body": "Because the line editing capabilities of the terminal driver are quite primitive and do not include things like moving the insertion point left and right. .  What they do include: .   deleting the last char (\"VERASE\" / \"erase\", BackSpace) deleting the last word (\"VWERASE\" / \"werase\", Control-W) deleting the whole line (\"VKILL\" / \"kill\", Control-U)  They're also not able to bind multiple key sequences (as the escapes sent by the left- and right-arrow keys usually are) to its special actions. .  And of course, \"VERASE\" and \"VWERASE\" are not Unicode-aware; Linux has a perfunctory \"IUTF8\" flag (which works with simple data and is better than nothing), but it doesn't know about zero-width modifiers, directional marks, etc. .  Look into the \"stty(1)\" and \"termios(3)\" manpages for more details. .  ",
      "P-tags": "termin linux arrow-key keyboard",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_600539",
      "task": "SSH service running on multiple ports with custom rules in Linux",
      "P-task": "ssh servic run multipl port custom rule linux",
      "F_verb": "run",
      "P-body": "Initially, the SSH service can be made to listen to multiple ports by adding the following line to \"/etc/ssh/sshd_config\". .  In this scenario, you cannot define different rules for different ports. .  One of the solutions I could find is to create a new service to run SSH service on port 5522 and then running the service as daemon. .  To do so please follow the steps below:- .   create a copy of the SSH service and name it, here I named the copy as \"sshd_config_custom\"   Similarly, create a copy of the service too.   open \"/lib/systemd/system/sshd-custom.service\" using any comfortable editor and change  to .  And .  to .  Save and exit the file. .   Now you can add the line Port 5522 in /etc/ssh/sshd_config_custom and can make any required changes to this conf file. .   Enable and start the custom service that we have created. .    Let me know if there are any other suggestions .  ",
      "P-tags": "servic ubuntu systemd ssh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V on NP with NP in NP"
    },
    {
      "id": "so_23670550",
      "task": "When opening Terminal posts export 'not a valid identifier' for Python source activate",
      "P-task": "open termin post export valid identifi python sourc activ",
      "F_verb": "activate",
      "P-body": "This line: .  Should be  .  ",
      "P-tags": "termin python bash-profil bash",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V"
    },
    {
      "id": "au_718676",
      "task": "Multiple files as input to ffmpeg not found",
      "P-task": "multipl file input ffmpeg found",
      "F_verb": "find",
      "P-body": "Your input file names lack zero padding, so use \"-i picture%d.yuv\". .  Other stuff: .   Make sure there are no missing file or breaks in your sequence. .  Your output options \"-f mp4\", \"-s qvga\", \"-an\", and \"-threads 0\" are superfluous in this case. .   ",
      "P-tags": "ffmpeg video",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "ul_11234",
      "task": "Where should I copy-paste-install software to?",
      "P-task": "copy-paste-instal softwar",
      "F_verb": "paste",
      "P-body": "If you are the only user of it, just slap it in \"/home\". If not, \"/opt/intellij\".  .  Avoid \"/usr\", which should only be used by distro-managed software. Many source installers use \"/usr/local\" by default, but the advantage of \"/opt/intellij\" is that you can wipe the entire directory if you no longer have a use for it. Putting it under \"/usr/local\", the stuff would get distributed all over the place, adding the need to track where those are installed; there's tools for that, but don't bother. Any decent installer should create all directory structures for your installation to work, wherever you choose to install to. .  ",
      "P-tags": "directory-structur intellij software-instal",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP"
    },
    {
      "id": "so_61183861",
      "task": "Run a command before and after running an interactive command",
      "P-task": "run command run interact command",
      "F_verb": "run",
      "P-body": "You can create a function \"intr-cmd\", which replaces the general \"intr-cmd\" command, as explained here. .  I should like like: .  (Obviously you need to fill in the right path.) .  I tried to flag your question as a duplicate, but as the link refers to another StackExchange forum, this wasn't allowed, hence this answer. .  ",
      "P-tags": "termin shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_194957",
      "task": "Deleted gitweb folder, don't know how to reinstall it",
      "P-task": "delet gitweb folder know reinstal",
      "F_verb": "delete",
      "P-body": "Using \"dpkg -c [gitweb-package.deb]\" in \"/var/cache/apt/archive/\" I've noticed that contents of this package does not contain the files I was looking for, so I've checked the contents of \"git\" package and that is where I've found it, so the final solution is to reinstall the \"git\" package itself. .  ",
      "P-tags": "git",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_26991943",
      "task": "Prevent expansion of `~`",
      "P-task": "prevent expans",
      "F_verb": "prevent",
      "P-body": " The paths are already expanded at this point. If you don't want that, escape them or quote them. .  Of course, then you can't use them, because you prevented the shell from expanding '~': .  You can expand the tilde later in the command using \"eval\" (always try to avoid \"eval\" though!) or a simple substitution: .  ",
      "P-tags": "variable-expans bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "so_9689756",
      "task": "How to set Play's \"current directory\" to the app's homedir?",
      "P-task": "set play current directori app homedir",
      "F_verb": "set",
      "P-body": "The solution was adding \"--chdir $HOME\" to the \"start-stop-daemon\" line. Quite trivial to be frank. .  ",
      "P-tags": "playframework ubuntu",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "so_7920967",
      "task": "Enter into a directory through an alias in Mac OS X terminal",
      "P-task": "enter directori alia mac os x termin",
      "F_verb": "enter",
      "P-body": "you can make symbolic links to it just like in unix .  e.g. .  creates a symbolic link to the Documentation folder hidden in your ~/Library folder. .  ",
      "P-tags": "termin alia unix",
      "source": "qa",
      "cate": "enter",
      "pat": "V into NP through NP in NP"
    },
    {
      "id": "au_42829",
      "task": "Can't view files on partitioned external drive",
      "P-task": "view file partit extern drive",
      "F_verb": "view",
      "P-body": "If you suspect that the drive is failing and you want to recover as much data as possible and have 60GB free, then \"ddrescue\" is your best bet. The instructions here should help: .  https://help.ubuntu.com/community/DataRecovery .  While I would suggest reading through that entire page, the basic steps you'll want to do are: .   Unmount the partitions. Use \"ddrescue\" to take a copy of each partition (\"/dev/sdc1\" to \"/dev/sdc3\") to somewhere on another disk. See the above link for suggested parameters. Mount the images via loopback with a command like \"mount -o loop,ro -t vfat sdc1.img /mnt\" and then copy files from there.  By recovering the files out of an image of the file system, you won't receive read errors. However, your image may be missing some data depending on how successful \"ddrescue\" was. .  You can run \"ddrescue\" repeatedly to attempt to recover more data, but I'd suggest trying to get an initial image of all three partitions before doing so. .  ",
      "P-tags": "partit data-recoveri external-hdd",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP on NP"
    },
    {
      "id": "so_10986516",
      "task": "How to get around not being able to use using namespace std; in C++",
      "P-task": "get around abl use use namespac std c++",
      "F_verb": "get",
      "P-body": "This sucks, but you can do this: .  Defines from here, and I have no way to verify. .  ",
      "P-tags": "gcc c++ linux hp-ux",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF using NP in NP"
    },
    {
      "id": "su_676233",
      "task": "Shrink/Remove dual boot partition Windows XP(or 7)/ RHEL",
      "P-task": "shrink remov dual boot partit window xp 7 rhel",
      "F_verb": "shrink",
      "P-body": "This operation is easy and painless to perform, provided you follow three simple rules.  .  The first rule is \"Back up your data\". The second rule is \"Back up your data\". The third rule is \"Back up your data\". I kid you not.  .  The simplest way to proceed is to use a Linux live distribution, like Ubuntu's. You download to your pc the installation iso file for Ubuntu, you put it onto a USB stick (you can use a utility called unetbootin which exists in both Windows and Linux versions), boot from the USB stick, choose the option \"Try Ubuntu\" instead of \"Install Ubuntu\", open a terminal, issue the commands: .  and select the disk to be re-partitioned. Now you can you select the operations as you see fit (resize the Linux partition, first, then resize the Windows partition), and when you are done you give the command \"Apply selected operations\" or some such thing. If you prefer to remove the RHEL partition altogether, you can simply delete it, leave it empty, and then let the Windows partition grow into the free region adjoining it (the former RHEL partition).  .  Then you wait for a substantial amount of time (depending on the partition size, might even last several hours), until gparted has worked its magic.  .  Now you are nearly done, except that most likely your system won't boot. If you have erased the RHEL partition this is certain, because you have removed the partiton containing grub, which controlled the booting process. In this case you will have to use the Windows installation disk to boot from, and then select \"Repair installation\", and the disk will take it from here. If instead you have decided to keep the RHEL partition, you proceed as follows: from the ubuntu terminal, mount the partition containing the RHEL system, .  where X is the appropriate number for the RHEL partition. Now do this: .  Turn off the pc, and you are done. But please, remember the three Golden Rules of partitioning which I wrote at the beginning.  .  ",
      "P-tags": "multi-boot partit linux windows-xp windows-7",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_19473973",
      "task": "To remove undesired lines using linux command",
      "P-task": "remov undesir line use linux command",
      "F_verb": "remove",
      "P-body": "Using \"grep\" to filter lines: .  ",
      "P-tags": "linux unix",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "so_42606941",
      "task": "Install Yarn Ubuntu 16.04 (Linux Mint 18.1)",
      "P-task": "instal yarn ubuntu 16 04 linux mint 18 1",
      "F_verb": "install",
      "P-body": "On Ubuntu Linux, you can install Yarn via Debian package repository. You will first need to configure the repository: .  Then you can simply: .  More information here .  ",
      "P-tags": "node js yarnpkg ubuntu-16 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_14551204",
      "task": "Any way to make LD record shared library name only, no subdirs?",
      "P-task": "way make ld record share librari name subdir",
      "F_verb": "make",
      "P-body": "If don't want to change the name of your library, you can use the soname option when you create it.  .  For example:  .  build the library  .  build the program  .  (Don't forget the colon after the -l option)  .  ",
      "P-tags": "linux ld shared-librari",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_77444",
      "task": "How to synchronize entire thunderbird profile with Ubuntu-One?",
      "P-task": "synchron entir thunderbird profil ubuntu-on",
      "F_verb": "synchronize",
      "P-body": "I have not used Ubuntu One (I use Dropbox), but this should be possible: Open the file manager (Nautilus), enable viewing hidden files and folders, right click on the \".thunderbird\" folder in your home directory, and enable syncing to Ubuntu One. .  If you are using Thunderbird on two (or more) machines and sync both the profiles to Ubuntu One, there could be problems with both machines performing conflicting writes on the profile. But as long as it's synced from only one machine, it should be fine. Do keep in mind the storage space limit on Ubuntu One. .  ",
      "P-tags": "sync ubuntu-on thunderbird",
      "source": "qa",
      "cate": "synchronize/sync/synchronise",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_106140",
      "task": "Gives access to root user for a period of time",
      "P-task": "give access root user period time",
      "F_verb": "give",
      "P-body": "Since you can add and remove users at will from sudoers, all you need is a way to schedule it. .  One way you could do this is to do something like this with sudoers: .   Edit \"/etc/sudoers\" using \"sudo visudo\", and add a statement for that user with a unique string on the end:   Schedule this line to be removed in one month. My preferred way would be to use \"at\" if you have it (it's bundled with \"atd\"), but you can also schedule it manually using \"cron\":  ",
      "P-tags": "root user",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP to NP for NP of NP"
    },
    {
      "id": "so_5077550",
      "task": "PowerShell: single point where I can catch all exceptions",
      "P-task": "powershel : singl point catch except",
      "F_verb": "catch",
      "P-body": "You can install a \"trap\" handler in \"b.ps1\" to handle errors in \"c.ps1\" if you dot source \"b.ps1\" so that it is running in the same scope as \"a.ps1\" e.g.: .  Update: Indeed that doesn't work. It seems that PowerShell isn't honoring the notion of running in a.ps1's scope by dot sourcing. Not sure that you will be able to do anything better than this: .  It looks like the trap handler needs to be in a.ps1 but you can define a trap handling function in b.ps1. Still, don't think you can control the disposition (break or continue) of the error in this function. .  ",
      "P-tags": "powershel exception-handl",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP"
    },
    {
      "id": "ul_354102",
      "task": "Bash get input while flag present?",
      "P-task": "bash get input flag present",
      "F_verb": "get",
      "P-body": "You typically use \"getopts\" as: .  The \"shift\" above discards all option arguments (including the trailing \"--\" if any) processed by \"getopts\". .  ",
      "P-tags": "option paramet shell-script bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP while S"
    },
    {
      "id": "so_15802491",
      "task": "Is it possible to run two different versions of tmux simultaneously?",
      "P-task": "possibl run two differ version tmux simultan",
      "F_verb": "run",
      "P-body": "You can run multiple instances of tmux (even different versions), but it may not work like you are expecting: they will be completely independent (different sessions, windows, panes, option values, etc.). The \"-L\" or \"-S\" option is used to specify a server socket name or pathname. .  The default socket and the \"-L\" sockets live in \"$TMPDIR/tmux-$UID/\", but you can use \"-S\" if you want to specify the full pathname yourself. .  When you are \u201cinside\u201d a tmux session, the TMUX environment variables specifies the path to the server socket, so you generally do not need to specify the socket (path)name if you are just talking to the \u201csurrounding\u201d server: you can just use \"tmux neww\" to create a new window in the current session (no matter what socket pathname it is using). .  However, there is another issue with trying to run two significantly different versions of tmux though. The tmux binary and the running server must speak the same \u201cprotocol version\u201d. Due to some internal changes, the 1.6 and 1.8 versions use different protocol versions. This means that you can not use the 1.6 binary to talk to the a 1.8 server (i.e. a server started using the 1.8 binary), or vice versa. So, even though you might not need to specify the socket name (when running commands \u201cinside\u201d\u00a0a session), you will probably need to specify the binary when trying to talk to your different servers. .  You might be able to simplify things a bit by setting an environment variable and using a shell function (or a script, though take care not to create an infinite loop). .  ",
      "P-tags": "tmux unix",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of NP"
    },
    {
      "id": "so_67855618",
      "task": "Linux Dependency Errors (can't install Stella)",
      "P-task": "linux depend error instal stella",
      "F_verb": "install",
      "P-body": "The \"stella\" version you downloaded is not compatible with the official \"libsdl2\" packet versions of your Ubuntu version. If you just want to use \"stella\", it is available to install as a compatible version through \"apt\": .  ",
      "P-tags": "sdl dpkg apt-get linux ubuntu",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_20429995",
      "task": "Is that possible to get backup from VPS by Shell access?",
      "P-task": "possibl get backup vp shell access",
      "F_verb": "get",
      "P-body": "I wonder if this might help. Compress your file using zip/tar utilities and then You can use scp to transfer those files on to your local machine. In case you prefer GUI tools you can also use WinSCP (a Windows GUI based client) to transfer your files. .  To zip directory called pics in your home directory (/home/you/pics), type the following command: .  Using tar: .  Explanation: .  ",
      "P-tags": "gzip vp kloxo ssh shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP by NP"
    },
    {
      "id": "so_69096691",
      "task": "How can i define variable for default values in MariaDB structure?",
      "P-task": "defin variabl default valu mariadb structur",
      "F_verb": "define",
      "P-body": "You can use dynamic query like this: .  Sample Data: .  Result: .  So the first item had 10 as default value and second item has been changed to 20. You see that it works. .   For multiple values, you cannot put multiple queries inside one statement: Doc .   The text must represent a single statement, not multiple statements. .   So you can create another procedure for convenience: .  Use it like this: .  ",
      "P-tags": "mysql mariadb linux databas set",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "ul_77356",
      "task": "How long is the password for executing a command with sudo cached?",
      "P-task": "long password execut command sudo cach",
      "F_verb": "execute",
      "P-body": "\"man 5 sudoers\" informs us that there is an option \"timestamp_timeout\": .   Number of minutes that can elapse before sudo will ask for a passwd again. The timeout may include a fractional component if minute granularity is insufficient, for example 2.5. The default is 5. Set this to 0 to always prompt for a password. If set to a value less than 0 the user\u2019s time stamp will never expire. This can be used to allow users to create or delete their own time stamps via \u201csudo -v\u201d and \u201csudo -k\u201d respectively. .   So yes, it can be configured via \"/etc/sudoers\", and by default it expires after 5 minutes. .  Also, please remember to use \"visudo\" to make any edits to \"/etc/sudoers\". When saving your edits \"visudo\" will run validity checks before actually overwriting the sudoers file. This protects you from a painful recovery process if you lock yourself out of \"sudo\" access. .  ",
      "P-tags": "password timestamp sudo",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_53452824",
      "task": "read, fread partial reads",
      "P-task": "read fread partial read",
      "F_verb": "read",
      "P-body": "The general idea of \"read\" is that it returns as soon as some data is available\u00b9. From an application's perspective, that's all you can assume. .  If you're implementing the \"read\" callback in a kernel driver, it's up to you when \"read\" decides to return some data. But applications will\u00b2 expect that \"read\" calls may be partial, and they should call \"read\" in a loop if they really need a certain number of bytes. Some applications want \"read\" not to block, so it would be a bad idea to block in a \"read\" call if some data is available. .  The \"fread\" function blocks until it's read as many bytes as were requested, until it's reached the end of the file, or until an error occurs. It works by calling \"read\" in a loop. .  \u00b9 Whether and when \"read\" may return 0 bytes is beyond the scope of this answer.  \u00b2 Or at least should. Buggy applications do exist.   .  ",
      "P-tags": "linux c system-cal fread",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_768606",
      "task": "MAAS Upgrade from 2.0.0 beta 3 to 2.0.0 beta 4",
      "P-task": "maa upgrad 2 0 0 beta 3 2 0 0 beta 4",
      "F_verb": "upgrade",
      "P-body": "Basically you should follow http://maas.ubuntu.com/docs/install.html#maas-packages-and-repositories with a slight change: .  If you'll be able to drop PPA source any time later with: .  ",
      "P-tags": "upgrad maa 16 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V from NP to NP"
    },
    {
      "id": "ul_664027",
      "task": "How do I set and then unset environment variables while running a program?",
      "P-task": "set unset environ variabl run program",
      "F_verb": "set",
      "P-body": "In Bourne-like or \"rc\"-like shells, to pass environment variables just to one invocation of one command, you'd do: .  Though note that in some shells, if \"some-command\" is a special builtin (such as \"export\", \"set\", \"eval\") or a function, the variables remain set (though not always exported) afterwards. .  The csh or tcsh shells have no equivalent though in those (or any shell for that matters), you can always use the \"env\" command: .  You'll also want to use \"env\" in Bourne-like shells if you want to pass environment variables whose name is not a valid shell variable name (though using such variables is not recommended) such as: .  Note that in csh, \"set var=value\" sets a shell variable, not an environment variable for which you need \"setenv var value\". .  In the \"fish\" shell, you can use \"set -lx\" in a \"begin...end\" statement to limit the scope of the variable while still exporting it to the environment: .  You can do the same in \"zsh\" using an anonymous function: .  Or: .  Though you'd only prefer that over the standard \"VAR1=value VAR2=other-value some-command with its args\" syntax if there's more than one command you want to run in that environment. .  In any Bourne-like shell, you can also limit the scope of variable assignments using a subshell: .  POSIX shells (not the Bourne shell, though the Bourne shell is a thing of the past) can also do the assignment in the arguments to the \"export\" special builtin: .  That approach can also be used in \"(t)csh\": .  To run more than one command in an environment primed with variables whose name are not valid shell variable names, you can always have \"env\" start \"zsh\", \"bash\", \"csh\" or any other shell which doesn't strip those variables from the environment: .  Also beware that \"unset\"ting a variable (which you do with \"unset var\" in (t)csh and most Bourne-like shells, \"unset -v var\" in \"bash\", \"var = ()\" in \"rc\"-like shells, \"set -e var\" in \"fish\") is not the same as restoring the old variable value. After all the example codes above, the variables end up being unset only if they were initially unset. .  ",
      "P-tags": "environment-vari",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP while S"
    },
    {
      "id": "so_14782869",
      "task": "Finding files older than X hours using Ruby",
      "P-task": "find file older x hour use rubi",
      "F_verb": "find",
      "P-body": "One liner: .  Though I would prefer it spelled out a bit more: .  ",
      "P-tags": "rubi shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP using NP"
    },
    {
      "id": "so_23233910",
      "task": "Can't resolve rubygems.org (too many redirects)",
      "P-task": "resolv rubygem org mani redirect",
      "F_verb": "resolve",
      "P-body": "So from the comments, apparently there is a DNS caching issue, where \"::ffff:67.215.65.145\" was coming back as a valid address for rubygems. \"54.245.255.174\" is a valid address, as \"dig @8.8.8.8 ANY rubygems.org\" would reveal. .  ",
      "P-tags": "rubi linux vagrant rubygem",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_15260562",
      "task": "How to create a tar.gz without all the folders",
      "P-task": "creat tar gz without folder",
      "F_verb": "create",
      "P-body": "I believe this is what you wanted to do: .  ",
      "P-tags": "linux ubuntu file directori bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP without NP"
    },
    {
      "id": "so_50005182",
      "task": "Deleting a line containing a string stored in variable not working in sed",
      "P-task": "delet line contain string store variabl work sed",
      "F_verb": "delete",
      "P-body": "Your idea is right, but for the variable \"domain\" to be expanded, it needs to be present inside double-quotes. The shell expands the variables before passing the arguments to \"sed\", without the right quoting, the pattern \"$domain\" is interpreted as a literal string. You could nest the quotes as follows .  ",
      "P-tags": "sed sh shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP S_ING in NP"
    },
    {
      "id": "so_35468339",
      "task": "how to compile TCP_cubic.c",
      "P-task": "compil tcp_cubic c",
      "F_verb": "compile",
      "P-body": "Make your changes, go to the linux directory (top level of the kernel source), and do .  ",
      "P-tags": "linux tcp congestion-control",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP"
    },
    {
      "id": "au_850495",
      "task": "Bind9 does not respond (only) over TCP",
      "P-task": "bind9 respond tcp",
      "F_verb": "respond",
      "P-body": "This server was upgraded from 12.04 and i don't know it was the problem or it is ubuntu 16.04 default behavior . .  The problem was caused by dnsmasq . Actually the dnsmasq was listening on the port 53 . .  /etc/default/dnsmasq .  Then .  Solved my problem . .  ",
      "P-tags": "bind network 16 04",
      "source": "qa",
      "cate": "respond",
      "pat": "V over NP"
    },
    {
      "id": "ul_446818",
      "task": "What do you call the calling convention behind `int 0x80`?",
      "P-task": "call call convent behind int 0x80",
      "F_verb": "call",
      "P-body": "You question covers a number of topics, I\u2019ll try to address them all. .   I\u2019m not sure there\u2019s a single, canonical term for the way in which system calls are invoked, even less so for a specific way in which system calls are invoked (interrupt 0x80 as opposed to \"SYSENTER\" or \"SYSCALL\"). On x86-64, the documented system call interface, using \"SYSCALL\", is described in the System V x86-64 ABI, but that\u2019s informative only, not normative. Likewise, while most people would understand what you were talking about if you referred to it as the \u201ci386 Linux kernel ABI\u201d (replacing \u201ci386\u201d with whatever architecture you\u2019re talking about), that could be confusing too since \u201ckernel ABI\u201d has another meaning (in the context of kernel modules), and again that\u2019s not limited to interrupt 0x80. .  In practice most people shouldn\u2019t be concerned about the specifics down to this level of detail anyway, especially since they can evolve: interrupt 0x80, \"SYSCALL\" etc. as you mention, but also the vDSO which introduces its own subtleties and is the preferred entry point for all system calls on x86 nowadays... Of course this doesn\u2019t mean that there can\u2019t be a term to refer to a specific calling convention, but I\u2019m not sure it would be all that useful. .  Windows also supports using an interrupt for its system call interface, 0x2E, but its \u201ccalling convention\u201d is quite different: arguments are pushed on the stack, the requested system call is given by EAX, and EBX points to the arguments on the stack. .  Current x86 kernels define the system call interface in \"arch/x86/entry\": \"entry_32.S\" contains the i386 interface, \"entry_64.S\" the x86-32 and x86-64 interface, \"entry_64_compat.S\" the 32-bit x86-64 interface (for backward compatibility), \"syscalls/syscall_32.tbl\" the i386 system call table, \"syscalls/syscall_64.tbl\" the x86-32 and x86-64 system call table. .  The comments in those files document the interface, in particular how arguments are passed: for 32-bit calls, EAX contains the system call number, and its parameters are placed in EBX, ECX, EDX, ESI, EDI, and EBP (the parameter itself for \"SYSENTER\", a pointer to the user stack containing the parameter for interrupt 0x80); for 64-bit calls, RAX contains the system call number, and its parameters are placed in RDI, RSI, RDX, R10, R8, and R9 (see also Why did the system call registers and order change from Intel 32bit to 64bit?). There\u2019s a nice summary with diagrams in \"calling.h\". .   As a side note, historical comparisons often refer to the MS-DOS call interface, which primarily used interrupt 0x21; it also included the multiplex interrupt, 0x2F, which provided an extensible mechanism for adding system services (typically involving TSRs; device drivers mostly used a different interface). .  ",
      "P-tags": "kernel linux convent assembl",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "so_55482354",
      "task": "Ignore commas within a bash variable that is sent to a csv file",
      "P-task": "ignor comma within bash variabl sent csv file",
      "F_verb": "ignore",
      "P-body": "The wrangling of temporary files is completely unnecessary anyway. .  Generally speaking, you cannot nest double quotes: \"\"\"foo\" is just an unquoted \"foo\" with an empty quoted string to its left (which of course disappears entirely by the time the shell is done parsing this expression). .  Notice also how moving the redirection after the \"done\" improves legibility and efficiency. Because you only redirect once, you can write instead of append (assuming you don't need to append for other reasons, of course) and you don't open, seek to the end of the file, write, and close every time through the loop, so you save a fair bit on the I/O overhead. .  ",
      "P-tags": "csv bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP within NP that S"
    },
    {
      "id": "so_53223091",
      "task": "Redirect stdout and stderr to a file and also to console in linux",
      "P-task": "redirect stdout stderr file also consol linux",
      "F_verb": "redirect",
      "P-body": "The \"tee\" command can help you out. It reads from standard input and writes to standard output and files. .  So the following command will do: .  Manpage: http://man7.org/linux/man-pages/man1/tee.1.html .  ",
      "P-tags": "linux unix ubuntu-14 04",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_30590620",
      "task": "Why does execl require me to hit \"Enter\" after running a process?",
      "P-task": "execl requir hit enter run process",
      "F_verb": "require",
      "P-body": " At this point I will need to hit ENTER so that I return to bash prompt. .   Actually, you're already back to the prompt, you just did not realize it. .  To elaborate, the problem you facing here is, the parent does not wait for the child to exit and returns beforehand the child finishes execution. So, the shell prompt comes back, and then the output from the chlid process (output of \"ls\") gets printed on the output. .  If you notice properly, You've already got the prompt back, and your output appears later. .  Above, please note the \"****\" marked line. There, you got your shell prompt back. .  ",
      "P-tags": "linux c execl bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF after S"
    },
    {
      "id": "au_59946",
      "task": "How to copy file to another machine through terminal?",
      "P-task": "copi file anoth machin termin",
      "F_verb": "copy",
      "P-body": "Is there possibility to connect via SSH? Maybe you should consider \"scp\" utitlity. It's very simple, look to the manual page: .  The very basic usage: .  and vice versa: .  ",
      "P-tags": "ssh",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP to NP through NP"
    },
    {
      "id": "au_135573",
      "task": "GConf Error: No D-BUS daemon running?! How to reinstall or fix?",
      "P-task": "gconf error : d-bu daemon run\nreinstal fix",
      "F_verb": "run",
      "P-body": "SirCharlo's answer worked for me. Same problem on ubuntu 12.04 (precise pangolin). Yeah, I use su (root) also. Shame, shame. Same problem starting emacs too. .  The problem seems to be that DBUS_SESSION_BUS_ADDRESS retains its value when you su instead of picking up the value in /root/.dbus/session-bus/ .  from man dbus-launch: .  Use sudo, suedit, gksu. .  Or if you MUST use su, then try adding this to your /root/.bashrc: .  ",
      "P-tags": "dbu system servic",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "ul_383688",
      "task": "How to list directories with specified file in them has specified content?",
      "P-task": "list directori specifi file specifi content",
      "F_verb": "list",
      "P-body": "The easiest is to look for those files and print their parent directory if their content match. For instance with something like: .  If your \"awk\" implementation doesn't support \"nextfile\", that would print the name of the directory for each occurrence of those lines in the file. .  ",
      "P-tags": "find grep command-lin",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_288553",
      "task": "I just wanted to find where xdg-mime was looking for associations. What the hell is it _doing_?",
      "P-task": "want find xdg-mime look associ\nhell _doing_",
      "F_verb": "find",
      "P-body": "\"xdg-mime\" is a shell script, so you'll get a more manageable trace by asking the shell. .  The first complex action after parsing the command line is to detect your desktop environment, using a combination of methods: environment variables, detecting the Gnome session manager through D-Bus, and querying properties of the root window. This is done so that e.g. you get to read PDF files in Evince on Gnome and Okular on KDE. .  After that, \"xdg-mime\" looks for programs registered as XDG applications in locations that depend on the detected desktop environment. .  ",
      "P-tags": "xdg",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V where S"
    },
    {
      "id": "so_14416808",
      "task": "UBUNTU C++ compiler not finding header files",
      "P-task": "ubuntu c++ compil find header file",
      "F_verb": "find",
      "P-body": " This tell the compiler to find the header files on the current directory, and not only in the default directories (/usr/include and /include). .  I suggest you for compiling this trivial example to use GNU Make. The standard rules will work for you. .  Maybe, if you have the same issue (file.h not found) you can set CXXFLAGS=-I. .  ",
      "P-tags": "ubuntu-12 04 c++ ubuntu",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_10291936",
      "task": "Generate a new row, with a new GUID, from the MongoDB shell",
      "P-task": "gener new row new guid mongodb shell",
      "F_verb": "generate",
      "P-body": "Try this instead: .  You can also do: .  ",
      "P-tags": "mongodb mongodb-shel nosql",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP from NP"
    },
    {
      "id": "so_65124244",
      "task": "Regex to list all rows",
      "P-task": "regex list row",
      "F_verb": "list",
      "P-body": "Something like this ? .  But actually you may use an other method than regex, json or something... .  RESPONSE TO UPDATE .  ",
      "P-tags": "sh regex",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP"
    },
    {
      "id": "so_12432525",
      "task": "How to write \"start /b /min FeedDemon.exe\" in powershell",
      "P-task": "write start b min feeddemon exe powershel",
      "F_verb": "write",
      "P-body": "The \"/b\" argument to \"start\" indicates that the program should run without popping a new console window. The direct translation to powershell would be .  If that doesn't work, just call it the old fashioned way, from Powershell .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "au_178262",
      "task": "Setting up JAVA_HOME and CLASSPATH correctly on 12.04",
      "P-task": "set java_hom classpath correctli 12 04",
      "F_verb": "set",
      "P-body": "If I understand correctly the problem is not with java. The problem is in your log4j.xml file. .  Inside the class org.apache.fop.util.ContentHandlerFactoryRegistry it would have a : logger.error(\"Error Message/Exception\") or logger.debug . . .  .  something along these lines and it is trying to write it to your logger that you have set up. .  Essentially, you want to have something like .  in your log file that will pick up logging messages from that class. .  if you have multiple appenders then add .  underneath the level tag. .  ",
      "P-tags": "openjdk environment-vari java",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP"
    },
    {
      "id": "au_413259",
      "task": "No sound (no sound card detected)",
      "P-task": "sound sound card detect",
      "F_verb": "detect",
      "P-body": "I am running ubuntu 14.04 on a msi z170a motherboard. This my fourth ubuntu 14.04 and all my hardware is different. I also run fvwm2 as my window manager so I don't use the gnome or unity desktops. What that means is I run gnome-'setup-stuff' from an xterm or gnome-terminal. .  I have spent hours and hours trying to get my sound to work. What has been and worked for my latest build is something like this. .  From a terminal logged in as root. or you can sudo commands I believe the following solved my problem. .  As root I ran gnome-control-center sound Then I did  .  The ls -l was just to see the files and permissions .  The permission for the files above were different when I first looked at /dev/snd. To get a list of file and dirs  .  Write the above to a file. xen2:~> ls -l /dev/snd >> /root/reboot_fixes .  Then I edited /root/reboot_fixes with chmod 777 for all directoies and chmod 666 for all files. .  ever time I reboot I have to run /root/reboot_fixes. but this is the only way I could get sound to work. I've read dozens of do this and none worked. This works for me.  .  ",
      "P-tags": "driver soundcard sound lubuntu",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V"
    },
    {
      "id": "au_90013",
      "task": "How do I enable syntax highlighting in nano?",
      "P-task": "enabl syntax highlight nano",
      "F_verb": "enable",
      "P-body": "The nano editor provides syntax highlighting for a few languages and scripts by itself. Check out \"/usr/share/nano/\" .  Link them to your user's nano configuration file (present at \"~/.nanorc\", \"${XDG_CONFIG_HOME}/nano/nanorc\", or \"~/.config/nano/nanorc\", whichever is encountered first) with something similiar to this line: .  Now, syntax highlighting is enabled in nano for whatever file you linked (You could also link multiple files) .   .  Note: Sometimes you might get a \"segmentation fault\" after you have edited your \"~/.nanorc\" file. If such an error occurs, unsetting the LANG environment variable helps. You can unset it with \"unset LANG\" in the terminal. Solution obtained from here) .  There are also other solutions if you are not satisfied with your bash highlighting. One example of such can be found here .  You can also write \"include /usr/share/nano/*\" to the ~/.nanorc file to enable all languages to be highlighted if your nano version supports it. .  ",
      "P-tags": "nano syntax-highlight",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "so_21930616",
      "task": "startup.sh does not show Tomcat/TomEE startup failure error messages",
      "P-task": "startup sh show tomcat tome startup failur error messag",
      "F_verb": "show",
      "P-body": " Why don't you close the tag? Don't know if this is the problem, but may be... I mean the backslash after ....AbstractSecurityService$Group .  ",
      "P-tags": "xml tomcat linux apache-tome jakarta-e",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "so_46413409",
      "task": "How to Edit and Save XML nodes with PowerShell",
      "P-task": "edit save xml node powershel",
      "F_verb": "save",
      "P-body": "The code you posted should throw a bunch of errors, because \"Get-Content\" (without the parameter \"-Raw\") produces an array of strings, each of which is invalid XML by itself. Feeding that into \"Select-Xml\" doesn't work. Also, your use of the \"[xml]\" type accelerator and \"Write-Host\" is wrong. .  Rule of thumb: .   If you want to use \"Select-Xml\" let it read the file by itself (via its \"-Path\" parameter): .   If you want to use \"Get-Content\" and the \"[xml]\" type accelerator use the \"SelectNodes()\" method: .    However, that alone won't allow you to achieve your desired result, because you want to manipulate XAML files. Please don't omit such crucial information from your questions. I'm only aware because I was just about to respond to your previous question when you deleted it. .  XAML files are always using namespaces, so you must use a namespace manager to take care of that, like this: .  or like this: .  Since you want to modify the XML data I'd probably go with the latter approach. That allows you to add an attribute like this: .  Save the modified XML via the \"Save()\" method: .  ",
      "P-tags": "powershel xml",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP with NP"
    },
    {
      "id": "so_45322225",
      "task": "Content not deleting properly",
      "P-task": "content delet properli",
      "F_verb": "delete",
      "P-body": "This should get your work done:  .  Assuming $Event_Logs_Content is having proper values which you want to set it in the file. Because I am not seeing the event logs retrieval code. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V"
    },
    {
      "id": "ul_473852",
      "task": "why leafpad cannot display compose contents from /usr/share/X11/locale/en_US.UTF-8",
      "P-task": "leafpad display compos content usr share x11 local en_u utf-8",
      "F_verb": "display",
      "P-body": " .  The first 48 lines are empty, you can check that with \"hexdump\": .  ",
      "P-tags": "compose-key debian text-process",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP from NP"
    },
    {
      "id": "so_5898431",
      "task": "is it safe to use \"ls\" in for loop in bash",
      "P-task": "safe use ls loop bash",
      "F_verb": "use",
      "P-body": "If you want all subdirectories in \"/home\", use .  Note the trailing slash and the quoted variables. .  Edit: .  With directories and file .  This gives me the output .  where .  gives me the output .  (\"test\" is a file) .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "su_1457358",
      "task": "I get different results with hd and hexdump, aren't they the same?",
      "P-task": "get differ result hd hexdump",
      "F_verb": "get",
      "P-body": "This is closely related to this answer on Unix and Linux. .  \"\"hd\" is a synonym for \"hexdump -C\"\" .  They are very similar, but you are actually calling very slightly different things with each command. .  ",
      "P-tags": "linux ubuntu bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_328273",
      "task": "i have a file with random numbers. i need to convert all numbers from 2000-4000 to xyzw",
      "P-task": "file random number\nneed convert number 2000-4000 xyzw",
      "F_verb": "convert",
      "P-body": "Since it's just to run a regular expression, you could do it directly and faster with \"sed\": .  Note that I updated it, considering @roaima's comment. .  ",
      "P-tags": "perl",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_6003460",
      "task": "Bash scripting: using sed and cut to output a specific format",
      "P-task": "bash script : use sed cut output specif format",
      "F_verb": "cut",
      "P-body": " the steps .   delete what is not number expand 1 or 2 digit (hours) into 4 digit HHmm ignore last two charactes (minutes)  ",
      "P-tags": "cut sed bash",
      "source": "qa",
      "cate": "cut/slash/separate/clip/crop",
      "pat": "V S_INF"
    },
    {
      "id": "su_1140650",
      "task": "How I can specify a separate file for my aliases in oh-my-zsh?",
      "P-task": "specifi separ file alias oh-my-zsh",
      "F_verb": "specify",
      "P-body": "All you need to do is to remove the alias definitions from \"~/.zshrc\" into the file \"~/.zsh_aliases\" and replace the multiple alias commands in \"~/.zshrc\" by: .  You can use the same technique for other sections of \"~/.zshrc\": for instance, you may find it convenient to move any function definitions into \"~/.zsh_functions\". .  ",
      "P-tags": "oh-my-zsh zsh maco shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_66131723",
      "task": "How to call a C# script from PowerShell and pass arguments",
      "P-task": "call c script powershel pass argument",
      "F_verb": "pass",
      "P-body": "You're trying to access the \"$csharp\" variable, but it's not in scope within the child \"ScriptBlock\", so it automagically gets set to \"$null\" as per PowerShell's default lax rules for variable initialization and reference. You can verify this by using \"Set-StrictMode\" to prevent and warn about this default behaviour: .  Output: .  To fix, you need to explicitly pass the value of \"$csharp\" to the \"ScriptBlock\": .  Of course, now you get different errors, but those are outside the scope of this question! .  ",
      "P-tags": "powershel c",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "so_27002769",
      "task": "How to use tab separators with grep in ash or dash script?",
      "P-task": "use tab separ grep ash dash script",
      "F_verb": "use",
      "P-body": "You can use \"awk\" here: .  PS: I am doing \"var \"\"\" to make sure \"var\" is treated as a string instead of as a number. .  ",
      "P-tags": "script ash dash-shel shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_59764580",
      "task": "How to log output of first command and then execute next command in PHP?",
      "P-task": "log output first command execut next command php",
      "F_verb": "log",
      "P-body": "Here is a code change that I made to solve the issue. .  For readability purpose I have assigned commands to variables and using ';' I have executed the both commands one after the other.  .  ",
      "P-tags": "command yii php consol shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP of NP"
    },
    {
      "id": "so_60120353",
      "task": "Method invocation failed because [System.Object[]] does not contain a method named \u2018op_Division\u2019",
      "P-task": "method invoc fail system object contain method name op_divis",
      "F_verb": "contain",
      "P-body": "Whenever something works outside a function, but does not work inside the function, look at how you are calling the function and the type/value of the passed parameters. .  In this case, part of the problem is the way you are calling the function in the Write-Host line. By putting the parameters inside parens and separating them with commas, you are telling PowerShell that those two values are a 2 element array of integers, and should be passed to the 1st parameter. Since you did not declare the type of your variables in the function, that was accepted, and your 2nd parameter remains empty. .  I've added two Write-Host statements for you to see the values of your parameter variables after they are passed, and a \"right\" and \"wrong\" way of calling the function. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_29842246",
      "task": "How to install x86 architecture for java using Ansible",
      "P-task": "instal x86 architectur java use ansibl",
      "F_verb": "install",
      "P-body": "This should work for you. .  ",
      "P-tags": "ansible-playbook ubuntu-14 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP using NP"
    },
    {
      "id": "so_25481040",
      "task": "Monitoring disk usage in CentOS using 'du' to output JSON",
      "P-task": "monitor disk usag cento use du output json",
      "F_verb": "use",
      "P-body": " Quick and dirty (posix version so \"--posix\" on GNU sed).  .  Take the 3 argument and place them (\"s/../../\") into a 'template\" using group (\"\\( ...\\)\" and \"\\1\"). Include header at 1st line (\"i \\...\") and append footer ant last (\"a \\...\"). \"[:space:]\" may be \"[:blank:]\" .  ",
      "P-tags": "json awk linux bash sed",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_19195560",
      "task": "What's wrong with vfs_stat() call?",
      "P-task": "wrong vfs_stat call",
      "F_verb": "call",
      "P-body": "\"vfs_stat()\" is defined as: .  and \"__user\" is defined as: .  In other words, \"vfs_stat()\" only supports using filename that is pointer into user space, and should not be dereferenced inside kernel space. Note that \"\"/bin/ls\"\" does NOT point into user space, but into kernel space, and thus cannot be used here. .  Actually, error message 14 (bad address) tells this issue right into your face :) .  ",
      "P-tags": "kernel linux linux-kernel stat c",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V"
    },
    {
      "id": "so_33162299",
      "task": "Curl - Request with wp_remote_get() responds 500, curl_exec responds 200",
      "P-task": "curl - request wp_remote_get respond 500 curl_exec respond 200",
      "F_verb": "respond",
      "P-body": "OK, after a bit of debugging, I believe the issue is the default User-Agent string Wordpress sets in \"wp-includes/class-http.php\", set when creating an http request for \"wp_remote_get()\". .  The option has a filter, but the default is created like so: .  So in my case, the 'user-agent' header value was: \"\"Wordpress/4.3.1; http://myurl.com\"\" .  When I hook into the filter \"http_headers_useragent\" and return an empty string, or even a different user-agent string such as: \"'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8) AppleWebKit/535.6.2 (KHTML, like Gecko) Version/5.2 Safari/535.6.2'\", the request will return a successful 200 response. .  Not sure if the semicolon is the true culprit, but if I remove it and set the user-agent string to just \"\"Wordpress/4.3.1\"\", the request is successful as well. .  ",
      "P-tags": "php wordpress ubuntu-14 04 php-curl curl",
      "source": "qa",
      "cate": "respond",
      "pat": "V NP"
    },
    {
      "id": "so_22405191",
      "task": "Parse a two values from the file",
      "P-task": "pars two valu file",
      "F_verb": "parse",
      "P-body": "You can use \"grep\" for this: .  It used a look-behind that checks what comes after \"Job start/end time=\" in the given file. .  And to store into a variable, use .  ",
      "P-tags": "text-pars string-pars sed bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP from NP"
    },
    {
      "id": "so_64056577",
      "task": "Using bash to take the average of all numbers on a line and all lines in a file",
      "P-task": "use bash take averag number line line file",
      "F_verb": "take",
      "P-body": "Bash is a shell for high-level tasks, and is not the best choice for typical programming, reading files and doing arithmetics. awk is the standard bash tool for this task. Here is a script for this: .  Usage and output: .  \"FS\" is the field separatot to be used. The \"BEGIN {}\" section is executed before reading the first line. awk is reading the file line by line and for every input line the main body \"{}\" is executed. The code inside there is self-explanatory and very similar to standard programming languages. After reaching the end of file the \"END {}\" is executed. .  ",
      "P-tags": "averag unix bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP on NP in NP"
    },
    {
      "id": "so_13838658",
      "task": "Extract string which is separated by dots followed by another string",
      "P-task": "extract string separ dot follow anoth string",
      "F_verb": "follow",
      "P-body": "Since it's the last field in the line, you can do: .  It prints the lines which checks whether the it is \"Firefox\" and prints the version followed. .   Simply do echo on \"line\" and get the version. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V by NP"
    },
    {
      "id": "so_23519542",
      "task": "Bash Script: using if with -o and printing ONLY true evaluations",
      "P-task": "bash script : use -o print true evalu",
      "F_verb": "use",
      "P-body": "One method: .  You could also \"simplify\" a little: .  Simplify is quoted there, because a very good argument can be made that this is complicating things rather than simplifying, and I definitely prefer the first, but if the number of variables grows it doesn't scale well. You can certainly use an array instead of a flat string to keep track of the variables that satisfy the constraint, but that is less portable. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_179869",
      "task": "How to get binary representations of strings in Shell?",
      "P-task": "get binari represent string shell",
      "F_verb": "get",
      "P-body": "You can't store binary data (binary data generally refers to data with arbitrary byte values, not only byte values that form valid characters but is not special otherwise) in \"bash\" variables as \"bash\" doesn't support storing the \"0\" byte value in its variables (and remember you can't pass such strings in arguments to commands as those are NUL delimited strings). .  You can in \"zsh\" though. Also remember that command substitution strips trailing newline characters (0xa bytes, maybe different on Cygwin), so it's probably better to use \"read\" here: .  See how that contains both a 0 byte and newline character (0xa) .  Note again that you can only pass that variable to builtin commands (\"printf\"...). .  Now, if all you want is hash it again, then it's just .  no need for a variable. .  ",
      "P-tags": "shell-script binari openssl java shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_11748571",
      "task": "Listing the instruction sets used by a compiled object - for ARM and X86",
      "P-task": "list instruct set use compil object - arm x86",
      "F_verb": "list",
      "P-body": "The following code snippet is only my quick and dirty solution to your problem (only for Intel mnemonics). .  ",
      "P-tags": "linux disassembl",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP by NP for NP"
    },
    {
      "id": "au_147762",
      "task": "How to resize /dev/root partition?",
      "P-task": "resiz dev root partit",
      "F_verb": "resize",
      "P-body": "Well you could try \"du -h / --max-depth=1\" to see where your space is going. By the looks of it you used LVM ??? If so then it's easy. If not then it's hard. .  If you are using one physical disk then you will have to shrink the \"/home\" partition first to give you some disk space you can use to make the root partition bigger. You will also have to do this from a Live CD as your root partition can not be mounted when you resize it.  .    Unmount both the \"/\" and \"/home\" partitions Shrink the \"/home\" partition file system Shrink the \"/home\" partition logical volume Increase the \"/\" partition logical volume Increase the \"/\" partition file system   You will need to read up on LVM management commands as I can't remember those off the top of my head. You should make a back up first as you are playing with the root partition and you can easily wreck your system and make it unbootable. .  First check if any log files have gone crazy and you can easily get some space back which should make things go a bit quicker. .  Or the Live CD might have \"gparted\" installed already under tools so you could use that for a graphical way. .  ",
      "P-tags": "partit disk resiz",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_18221096",
      "task": "How can Powershell consume WCF REST Service through IIS?",
      "P-task": "powershel consum wcf rest servic ii",
      "F_verb": "consume",
      "P-body": "The New-WebServiceProxy creates a \"web service\" proxy to web services (such as .asmx in .NET). These kinds of services are WS-I-Basic Profile 1.1 services. In other words, there's an expectation of WSDL. .  Your WCF service has only one endpoint, which is a WebHttpBinding endpoint. This kind of endpoint is used for HTTP clients (non-soap) and are typically consumed by REST clients because they only use protocols of the web (HTTP and appropriate verbs such GET, POST, ...). When you tested this using your browser, it worked because browsers are just HTTP clients. When you tested it using your proxy from New-WebServiceProxy, it is trying to interpret the response as WSDL instead of just a string because that is the kind of client New-WebServiceProxy creates. .  To make your WCF Service work for Web Service clients (such as New-WebServiceProxy), you need to add another endpoint for those clients using a binding they understand, which is the basicHttpBinding.  .  This will at least get it working for the two types of clients (minus the security). .  For the security, create a BindingConfiguration for the basicHttpBinding and one for the webHttpBinding. In there, you can specify the client credential type to be Windows. .  ",
      "P-tags": "iis-7 5 c wcf powershell-3 0",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP through NP"
    },
    {
      "id": "au_1240914",
      "task": "How do I set keyboard layout per window on Ubuntu 20.04?",
      "P-task": "set keyboard layout per window ubuntu 20 04",
      "F_verb": "set",
      "P-body": "Below picture is self explanatory.. .  Go to system settings, Region & Language, Input Sources, Settings Icon, Choose \"Allow Different Sources for each window\" .   .  Or if you wish to make it via command line .  to reset .  ",
      "P-tags": "window gnome keyboard keyboard-layout",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP"
    },
    {
      "id": "so_62826596",
      "task": "How do I bundle/include and use files into an executable in C - linux?",
      "P-task": "bundl includ use file execut c - linux",
      "F_verb": "use",
      "P-body": "You can use the linker to do such embedding .   The object file will have three symbols in it, .    To use them from C, declare some \"extern\" variables .   Then you can link the generated object file ,the same can be used for text files .  ",
      "P-tags": "linux c file",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP into NP in NP"
    },
    {
      "id": "au_766864",
      "task": "I screwed up! Sound didn't work tried to fix... lost a large amount of my system settings",
      "P-task": "screw\nsound work tri fix lost larg amount system set",
      "F_verb": "fix",
      "P-body": "Basic system software packages like \"ubuntu-desktop\", \"unity-control-center\" and \"unity-control-center-signon\" depend on the \"pulseaudio\" package. If you uninstall \"pulseaudio\", those packages will be removed too, leaving your system pretty empty. To fix this, you could reinstall those packages using the package manager: .  ",
      "P-tags": "bluetooth system-set sound 14 04 pulseaudio",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_61845449",
      "task": "Delete files and folders in a directory which don't match a text list",
      "P-task": "delet file folder directori match text list",
      "F_verb": "match",
      "P-body": "Another option is to avoid the loop, just save the files in an array. using \"mapfile\" aka \"readarray\" which is a bash4+ feature. .  checkout out the output of \"grep -Fvwf list.txt <(printf '%s\\n' \"${files[@]}\")\" .  Remove the \"echo\" before the \"rm\" if you think the output is correct .  ",
      "P-tags": "script linux shell bash",
      "source": "qa",
      "cate": "match",
      "pat": "V NP"
    },
    {
      "id": "so_22850698",
      "task": "How to count overall size of files in directory",
      "P-task": "count overal size file directori",
      "F_verb": "count",
      "P-body": "\"du\" command is what you are looking for. .  Type : \"du -hs folder/*\" .  \"-s\" calculate total size in folder \"-h\" makes it human readable .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "au_289324",
      "task": "How do I start KeePass2 (portable) from Nautilus in Ubuntu 13.04?",
      "P-task": "start keepass2 portabl nautilu ubuntu 13 04",
      "F_verb": "start",
      "P-body": "This is functionality that was removed from versions of Ubuntu @ 11.10 and beyond. The 'Add' for adding a custom opener no longer exists. If you would like to do this open a terminal and change to your KeePass directory. .  Then type: .  You will see that there will be options asking what you want the default open to be, you will select the number that has the option 'Other' and when prompted: .  This should allow it into the Open With list. I hope this helps! .  ",
      "P-tags": "nautilu mono keepass",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_1030097",
      "task": "How to assign variable to PROMPT_COMMAND",
      "P-task": "assign variabl prompt_command",
      "F_verb": "assign",
      "P-body": "It works with .  after you open a new shell (or source .bashrc by calling \". ~/.bashrc\". .  ",
      "P-tags": "prompt bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "au_528375",
      "task": "lost access to executable file (file not found)",
      "P-task": "lost access execut file file found",
      "F_verb": "find",
      "P-body": "Maybe you had the command in your \"PATH\" after the setup, but a setup can not make the change to your \"PATH\" permanent. .  Edit \".bashrc\" in your home directory and add the following line: .  This will add that directory to the \"PATH\" environment variable permanently. .  ",
      "P-tags": "execute-command command-lin",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_34955002",
      "task": "Can't install opencv w/ npm",
      "P-task": "instal opencv w npm",
      "F_verb": "install",
      "P-body": "OP here. This ended up being multiple things. .   the install instructions for OpenCV (help.ubuntu.com/community/OpenCV) reference outdated packages and therefore do not install properly, and if you're not watching it, you'll miss the fail messages, as the script attempts to continue despite the failed installs.  after you get the script to run & install successfully, you'll notice that it installs the latest version of OpenCV, 3.1.0 which is perfectly acceptable.  According to the .readme on the node-opencv github, \"You'll need OpenCV 2.3.1 or newer installed before installing node-opencv.\" you'll end up noticing this statement is partially untrue. In reality, you need any version between 2.3.1 and 2.4.11. Any version after 2.4.11 will result in a failed npm install  ",
      "P-tags": "cloud9-id opencv ubuntu npm node js",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_1013528",
      "task": "how set read and write permissions for a directory",
      "P-task": "set read write permiss directori",
      "F_verb": "write",
      "P-body": "First change the ownership: .  (the \":\" after the username means in fact the user default group, so it resets the group too at the same time) .  Now you do not need sudo anymore you can operate under your normal user account. .  First get yourself read and write access to all content: .  Which means Read and Write access for User (the user owning the files, so that is you), but only Read for Group and Other. The \"=\" means to set the right, whatever it is now, you can also use \"+\" and \"-\" to respectively add or remove the given permission. .  You can prefer: .  or even: .  And the result should be clear from the explanation above (I do not know why people absolutely continue to use octal encoding to do the same thing, it has no superior value, but anyway if needed, Read is 4, Write is 2 and eXecute is 1, and you have to add the values. So my last example would be 660) .  There is only one remaining step. You need to put the eXecute right on each directory and subdirectory otherwise \"cd\" will not work. .  For that you can do: .  The \"find\" command like it says will find, starting at \"directory\" every object that is of type d, d meaning directory here, and the \"xargs\" command will apply the following (\"chmod u+x\") on all of them, and based on the previous explanations, the \"u+x\" part should be straightforward. .  Also, next time, if you start the copy directly under your username, the permissions should be ok from the beginning. If not it means you may have strange permissions on the top directory where you do the copy. .  ",
      "P-tags": "permiss",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_218335",
      "task": "How to create gcov files for a project in a different dir?",
      "P-task": "creat gcov file project differ dir",
      "F_verb": "create",
      "P-body": "You have the commands, so put them in a script! .  To run a bunch of commands on different data, put the changing data in a variable. .  To run \"gcov\" and \"mv\" on all the files, there are several possible methods, including: .   Run \"gcov\" on all files, then move them. Run \"gcov\" on one file, then move its output. Run \"gconv\" on the files in a directory, then move them.  The first approach doesn't work because \"gcov\" needs to be executed in the directory containing the source files. The third directory-based approach is in fact the most complicated of the three: the simplest method would be to run \"gcov\" on one file at a time. .  In bash, you can enumerate all the C files in a directory and its subdirectories recursively with the wildcard pattern \"**/*.c\". The \"**\" wildcard needs to be enabled with the \"globstar\" option. To iterate over the files, use a \"for loop\". .  To change into a directory just to run one command, run \"cd\" and that command in a subshell: \"(cd \u2026 && gcov \u2026)\". .  You need one more type of shell construct: a bit of manipulation of file names to extract the directory part. The parameter expansion construct \"${x%/*}\" expands to the value of the variable \"x\" with the shortest suffix matching the pattern \"/*\" removed. In other words, that's the directory part of the file name stored in \"x\". This wouldn't work if \"x\" consisted only of a file name with no directory part (i.e. \"foo\" as opposed to \"bar/foo\"); it so happens that there's no \".c\" file at the root of the OpenSSL source tree, but a simple way to make sure the file name starts with \"./\", which designates the current directory. .  Invoke this script at the root of the OpenSSL source tree, after running \"./config\" with your desired options. .  To avoid having to move the \".gcov\" files, an alternative approach would be to create a forest of symbolic links to the compilation directory, and run \"gcov\" in the \"gcovdata\" directory. With GNU coreutils (i.e. on non-embedded Linux or Cygwin), you can do that with \"cp -al\". .  ",
      "P-tags": "compil script shell-script openssl file",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_29896541",
      "task": "Running a python script within a bash file with php",
      "P-task": "run python script within bash file php",
      "F_verb": "run",
      "P-body": "You can modify the shell script like this: .  to always be run on the directory containing the script. Or if the name.py is in another directory, then change the \"cd\" command accordingly. .  ",
      "P-tags": "python php bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP within NP with NP"
    },
    {
      "id": "au_162639",
      "task": "How do I get Ubuntu to recognize my nvidia graphics card?",
      "P-task": "get ubuntu recogn nvidia graphic card",
      "F_verb": "get",
      "P-body": "Ok, as you haven't mentioned in your question that you have optimus enabled laptop and as per the interaction with other users it is clear that you are into a mess. A fresh install is required, Let me explain it to you. .  \"optimus\" isn't supported by nvdia drivers in linux. So if you install nvidia drivers from any repo. You won't be able to boot into GUI. The linux driver page of nvidia has a warning like \"The driver won't work with few models\" (few means optimus enabled graphics cards) .  So there is some unofficial work to get the power save feature at least (i.e. to turn off the discrete GPU). The first success was by \"mj-casalogic\".(I don't know his name) His first project named as \"bumblebee\" then he updated it and renamed it \"ironhide\". .  However ironhide wasn't well designed and it has lot of problems. It is now abandoned project. .  Bumblebee 3.0 was a fork of original bumblebee project. It has more stability and whole code was re written a C. Now a daemon runs from the startup. Disable the discrete GPU automatically and use it only when required. But this is not compatible with \"ironhide\" or earlier \"bumblebee\". You have to do a lot of things to get this working. Its easier to reinstall ubuntu.  .  After clean installation of ubuntu, do the following  .  Instruction for installing Bumblebee to turn off discrete GPU and enable only when required .   Type the following in terminal: .   To install Bumblebee using the proprietary nvidia driver: .  For 12.04 - 13.04  .  And for 13.10: .   Reboot. .    If you just want to disable nvidia card, no need to learn followings .  Usage Instruction : .  To run a program with nvidia card, use \"optirun\" command prefixed in terminal. Like to run \"glxspheres\" with nvidia card type .  To run firefox type : \"optirun firefox &\" .   To get the graphics card model, install mesa-utils .Remember the graphics card model won't be nvidia one. It will be intel, because in nvidia optimus the nvidia card isn't exposed directly. Nvidia card is wired via the intel one .  Linked Questions: .  How well will Nvidia Optimus cards be supported in 12.04? .  Is a NVIDIA GeForce with Optimus Technology supported by Ubuntu? .  Can't use nvidia card/driver on optimus notebook .  ",
      "P-tags": "nvidia-optimu nvidia samsung",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_424036",
      "task": "Remove line from file",
      "P-task": "remov line file",
      "F_verb": "remove",
      "P-body": " Explanation  \"awk <commands> file.txt\": run awk on \"file.txt\". \"$2 >= prev\": check if the second field \"$2\" is greater or equal than the contents of variable \"prev\". This is unset for the first line.) If this is true, then awk defaults to printing the entire line. i.e. if it is less, then delete the line.) \"{prev=$3}\": store the contents of the third field \"$3\" in the variable \"prev\".  This then repeats for the next line. awk will compare the second field with \"prev\", which now contains the third field from the line before. A couple of things to note: .   I'm not sure what you wanted for the first line, so I'd just manually include/exclude it as you see fit. If the data are actually tab delimited, just add the following flag to awk to let it know: \"-F'\\t'\".  ",
      "P-tags": "awk",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_21542983",
      "task": "Can't make node.js ubuntu 13.10",
      "P-task": "make node js ubuntu 13 10",
      "F_verb": "make",
      "P-body": "I've had problems with g++ 4.8 compiling v8 (which Node uses), and a bunch of other stuff, so I use 4.7. First install g++-4.7 using \"apt-get\" (which I trust you know how to do), and then: .  ",
      "P-tags": "makefil linux ubuntu g++ node js",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_28104086",
      "task": "How to build a project using Crypto++ library in kdevelop",
      "P-task": "build project use crypto++ librari kdevelop",
      "F_verb": "build",
      "P-body": "Adding the following piece of code to cmake file helped me: .  If \"pthread library\" is needed, also add it in the cmake file. This worked for me. Got the solution from https://forum.anope.org .  ",
      "P-tags": "crypto++ build ubuntu-14 04 kdevelop4 cmake",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP in NP"
    },
    {
      "id": "au_708133",
      "task": "Are the terms 'shell prompt' and 'command prompt' interchangeable?",
      "P-task": "term shell prompt command prompt interchang",
      "F_verb": "prompt",
      "P-body": "The command prompt usually refers to the one Windows is using (\"cmd.exe\") while a shell usually refers to the one Linux is using (usually \"bash\" or \"sh\"). The command prompt (\"cmd.exe\") is also a shell, but the term \"shell\" gets used a lot more in Linux. And both of these are text-based (CLI) shells. \"explorer.exe\" is also a shell, although it's a graphical shell. Confusing, isn't it? .  Basically, the Linux shell is more advanced than the command prompt. It gives users way more flexibility in commands and scripts than the command prompt. .  Examples include but not limited to: way more complex commands (completely achieveable with \"cmd\"), way more complex string manipulation, more diverse built-in tools .  Remember: we also have Powershell in Windows which IMO is Microsoft's attempt to be as good as \"bash\". Yes, we have a lot of shells. .  ",
      "P-tags": "command-lin",
      "source": "qa",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V NP"
    },
    {
      "id": "so_51015016",
      "task": "Am I using the pointer class properly in this generic unique_ptr<>() deleter?",
      "P-task": "use pointer class properli gener unique_ptr delet",
      "F_verb": "use",
      "P-body": "The issue seems to be due to libstdc++ implementation of \"unique_ptr::operator*\". Here it is in a very simplified, pared-down way: .  Now it is abundantly clear that libstdc++ cannot possibly work with your implementation of \"pointer\", because it returns a reference to a local temporary object from \"operator*\". Any \"pointer\" that stores its own pointee will have the same issue. .  Standard-wise, this doesn't seem to be a bug in libstdc++. The standard specifies that \"unique_ptr::operator*()\" returns \"*get()\", which libstdc++ faithfully does. .  If anything, this is a defect in the standard. .  An immediate fix is to stop defining \"operator*\" in your \"pointer\" class. \"unique_ptr\" doesn't need it (NullablePointer is not required to provide it).  .  Since \"pointer\" is in fact nothing more than a wrapper around \"T\" that provides value-initialisation to a given constant, it would make more sense to define an \"operator T()\" for it, and use \"get()\" to \"dereference\" the corresponding \"unique_ptr\". .  ",
      "P-tags": "ubuntu-16 04 unique-ptr c++ g++ templat",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_44421118",
      "task": "How to write a dynamic string replacement in git bash?",
      "P-task": "write dynam string replac git bash",
      "F_verb": "write",
      "P-body": "\"-i\" doesn't work on Windows builds of \"perl\". .  That feature uses anonymous files, which aren't supported by Windows. That said, you're not using a Windows build of \"perl\" but a cygwin build or similar. It could be that your unix emulation environment emulates anonymous files, so that might not be the the problem.  .  But if it is the problem, replacing \"-i\" with \"-i.bak\" will solve it. Feel free to follow up with \"rm config/app.php.bak\".) .   By the way, you are generating Perl code, which is fragile. Tag names containing \":\", \"\\\", \"$\" or \"@\" will cause the code to fail.) I recommend one of the following instead: .  or .  ",
      "P-tags": "linux perl bash git sed",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "so_31254601",
      "task": "How to use powershell to return all exchange distribution groups for a user",
      "P-task": "use powershel return exchang distribut group user",
      "F_verb": "use",
      "P-body": "That's what you need: .  \"Get-DistributionGroup\" are not recognize/expand the filter when it's in a {ScriptBlock} .  You should create a \"$Filter\" Variable that is not in a \"{ScriptBlock}\" but it's inside a \"\"Quotes\"\" from the outside and \"\"\"DoubleQuotes\"\"\" inside for the variable to expand. .  ",
      "P-tags": "powershel office365",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF for NP"
    },
    {
      "id": "so_46572163",
      "task": "Where did the ubuntu wily sources go?",
      "P-task": "ubuntu wili sourc go",
      "F_verb": "go",
      "P-body": "The \"wily\" version is in \"EOL\" (End of Life): no longer supported. .  You must follow these steps to use apt-get, by setting the use of oldversion repositories: .  https://help.ubuntu.com/community/EOLUpgrades .  1) modify with \"sudo\" the file \"/etc/apt/sources.list\", e.g.: .  2) put into: .  3) save the file .  4) do: \"sudo apt-get update\" .  ",
      "P-tags": "aptitud ubuntu",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V"
    },
    {
      "id": "au_877485",
      "task": "How do i find out what pulseaudio module does what?",
      "P-task": "find pulseaudio modul",
      "F_verb": "find",
      "P-body": "All modules loaded in a default Ubuntu installation do make sense and there should not be any need to remove them. Having said that it is of course near impossible to be ready for all special requirements we may have. Defaults are just what most people need. Before we adapt our defaults we need some basic understanding what a given module will do, and how we are able to restore our default settings in case anything went wrong. .  How do I load a module? Here is an official list of all supported modules: .   Pulseaudio Modules  All modules can be loaded or unloaded for testing to a running pulseaudio sound server with the following commands in a terminal: .  For example we can load a module that will switch audio output to a newly connected headset by this: .  In case we are happy we can add this module to our \"default.pa\" file to load it everytime the sound server restarts. .  How do I reset to default? Any modules loaded at runtime with \"pactl\" can also be unloaded by restarting the pulseaudio sound server. This will load all modules defined in the \"default.pa\" file. This is done with .  We may not want to use the system-wide defaults from \"/etc/pulse/default.pa\" but use our own setting valid only for one user instead. We can store this in our home directory in \"~/.config/pulse/default.pa\". On boot or on restarting pulseaudio settings there will override the system-wide settings. .  To make our own \"default.pa\" file there just start with .  We can then easily edit this file with any editor. .  In case anything goes wrong we just delete the \"~/.config/pulse\" directory, and restart pulseaudio to load the previous system-wide defaults (and re-create a vanilla \"~/.config/pulse\"). .  ",
      "P-tags": "bluetooth command-lin sound driver pulseaudio",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V what S"
    },
    {
      "id": "so_20333236",
      "task": "Make - Make Install and Linux update",
      "P-task": "make - make instal linux updat",
      "F_verb": "update",
      "P-body": "Installing programs from tarballs: .  You really do not want to install packages from .tar.gz when they are in the repositories. It is much harder to update or remove it manually than you could do with \"apt-get\". .  If you really have to compile the program yourself use checkinstall instead of \"make install\". This creates a package you can install it via the package management and later remove using \"apt-get\". This is much cleaner. .  Also you may want to type .  instead of the commands you wrote. This way the program is only compiled if the configuration succeeded. The package is only built if the compilation succeeded. With \";\" instead of \"&&\" all processes would be attempted no matter if its prerequisites are matched. .  Graphical package managers .  You can install your packages from GUI programs. Kubuntu uses for example uses \"muon\" for this, but the programs vary between distributions. .  ",
      "P-tags": "makefil linux",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_56790309",
      "task": "want to sort my log file on this timestamp 2019-06-29T12:39:23.428Z using sort command but confused as there are multiple delimeter",
      "P-task": "want sort log file timestamp 2019-06-29t12:39:23 428z use sort command confus multipl delimet",
      "F_verb": "sort",
      "P-body": "You can manually pick out each field to sort with -k .  from man: .  So something like this should sort your output: .  However: a simple sort should solve your issue. .  ",
      "P-tags": "linux sort shell bash",
      "source": "qa",
      "cate": "sort",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "ul_251709",
      "task": "How can I backup all my software in files to reinstall on another Linux system?",
      "P-task": "backup softwar file reinstal anoth linux system",
      "F_verb": "reinstall",
      "P-body": "Backing up system files on UNIX type systems is generally not done on a file by file basis. .  If you are trying to migrate a system to new hardware, just boot the old machine with a live image such as knoppix and use \"dd\" to image your hard drive partitions to a remote machine over the network or to an external hard drive. Then you can boot the live image on the new machine and use \"dd\" to write the disk images to the new partitions. Note that the new machine will have the same configuration as the old machine, so if you are trying to \"clone\" a system while leaving the old system up then you will need to change a few configuration settings such as the hostname and any static IP addresses. Depending on what software you are using there may be other small changes that you need to make if both of the systems are to be used concurrently. .  If fully cloning a system is not what you are after, and the new system is the same Linux distribution as the old system, then use the package manager to get a list of installed software. That list can then be used by the package manager on the new system to install all of the software and libraries. After that just copy the data and configuration files from the old machine to the new one. Here is a URL describing this process for various distributions. .  Any software that was installed without using the package manager will need to be copied manually. In which case \"scp\" or \"rsync\" are the tools you are looking for. Such software is usually installed in \"/opt\" (for older \"legacy\" software) or under \"/usr/local/\". You could clone the whole system this way, but if you miss anything important you will run into issues (hence why the previous two methods I mentioned are preferred). On Debian based distributions all of the important files should be contained in the following folders: \"/bin\", \"/etc\", \"/home\", \"/lib\", \"/lib64\", \"/lib32\", \"/opt\" (if it isn't empty), \"/root\", \"/srv\", \"/sbin\", \"/usr\", and \"/var\". It is also a good idea to boot from a live image to do this as well since it will ensure that none of the files are being modified (especially in \"/var/log\") while you are trying to copy them. This would look something like: .  ",
      "P-tags": "package-manag backup",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V on NP"
    },
    {
      "id": "so_23363003",
      "task": "How to produce cartesian product in bash?",
      "P-task": "produc cartesian product bash",
      "F_verb": "produce",
      "P-body": "Combine two brace expansions! .  This works by using a single brace expansion: .  and then combining with another one: .  ",
      "P-tags": "seq bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_21916467",
      "task": "Bash, change a file name based on a known keyword in a script",
      "P-task": "bash chang file name base known keyword script",
      "F_verb": "change",
      "P-body": "This is a best-practices implementation (for recursive use; use cases can use globs rather than \"find\" are simpler) -- using a NUL-delimited stream of filenames, and thus being safe even with unusual names (such as those containing literal newlines): .  See also BashFAQ #30. .  ",
      "P-tags": "renam bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP on NP in NP"
    },
    {
      "id": "so_44935252",
      "task": "ffmpeg is reading SDP from RTSP stream but unable to save a screenshot. is it network or utility issue?",
      "P-task": "ffmpeg read sdp rtsp stream unabl save screenshot\nnetwork util issu",
      "F_verb": "read",
      "P-body": "It was a problem with firewall. Did \"service ufw stop\" and now ffmpeg works fine! .  ",
      "P-tags": "ffmpeg ubuntu",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "so_35237737",
      "task": "AWK to to find first occurrence of string and assign to variable for compare",
      "P-task": "awk find first occurr string assign variabl compar",
      "F_verb": "find",
      "P-body": "Your code, expanded: .  The output of this appears merely to split the line according to the first colon. From the sample data you've provided, it seems that your lines contain two fields, which are separated by the first colon found. This means you can't safely use awk's field separator to find your data (though you can use it for field names), making \"index()\" a reasonable approach. .  One strategy might be to place your input into an array, for assessment: .  ",
      "P-tags": "awk linux sh bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "so_22920448",
      "task": "Trying to run a bash script with source from another script running as source",
      "P-task": "tri run bash script sourc anoth script run sourc",
      "F_verb": "run",
      "P-body": "You can clear the positional parameters using \"set --\" when you're done with them: .  script1.sh: .  script2.sh: .  Now \"script1.sh foo bar\" will print .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V as NP"
    },
    {
      "id": "ul_44551",
      "task": "Changing the IP Address in Solaris 11",
      "P-task": "chang ip address solari 11",
      "F_verb": "change",
      "P-body": "According to the Solaris 11 network interfaces manual in chapter 8 \u201cConfiguring an IP Interface\u201d: .  \"eth0\" is the name of the Ethernet interface (listed by \"ipadm show-if\"). \"staticip\" is a name that you can choose. .  ",
      "P-tags": "solari ping ip",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1083504",
      "task": "How to disable the advertisements when sshing into an Ubuntu machine",
      "P-task": "disabl advertis sshing ubuntu machin",
      "F_verb": "disable",
      "P-body": "When logging into a computer with SSH, a lot of text is displayed before reaching the command prompt. This comes from the motd (message of the day) process. The text can be somewhat overwhelming in volume. .  To reduce or mostly eliminate this text, edit \"/etc/default/motd-news\" and change \"ENABLED=1\" to \"ENABLED=0\". .  ",
      "P-tags": "motd ssh",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP when S"
    },
    {
      "id": "so_36872604",
      "task": "How to add a constant number to all entries of a row in a text file in bash",
      "P-task": "add constant number entri row text file bash",
      "F_verb": "add",
      "P-body": "Use simple awk like this: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP of NP in NP in NP"
    },
    {
      "id": "au_703911",
      "task": "Keep NumLock always on",
      "P-task": "keep numlock alway",
      "F_verb": "keep",
      "P-body": "The cleanest would be of course to fix the bug, but as a workaround, the background script below will do the job: .  How to use  Copy the script above into an empty file, save it as \"NM_on.py\" Test-run it in the background with the command: .   If all works fine, add it to Startup Applications: Dash > Startup Applications > Add, add the command: .    Explanation We can get the current \"Num Lock\"state in more than one way: .   running the command: .  which will give an output like:  .  or with the command: .  which simply returns \"'on'\", \"'off'\" or \"'unknown'\". .  Since the latter is extremely light weight, we can very well use it in a background script to check once per second, and set the value to \"'on'\", if necessary, with the command:  .    and so it does... .   Edit For some reason, I missed your last paragraph, in which you referred to another answer with a similar solution.  .  Purely theoretically, I always have a problem with scripts that blindly (re-) apply settings, without checking the current state. There could be an argument to do so, if the command .  to get the current value, would be more demanding that simply run .  to (re-)set \"numlockx on\". Looking at the time both commands need to finish (which is at least an indication) it is however the other way around; the command .  seems to be more \"light-weight\". .  Running a background script a bad idea? Of course, if you have no reason to run a background script, then don't. At the same time, if a background script is well- written, thoroughly tested, procedures are smartly optimized, and if it does not add any noticeable effect on the processor occupation, it would be silly not to use as a workaround if it adds important functionality or saves you time. .  I constantly have at least 4-8 background scripts running. Most of them for weeks without a restart. Never noticed any effect, on my elderly system(s). Keep in mind your system is running numerous loops anyway. .  ",
      "P-tags": "numlock uniti",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_13669175",
      "task": "How to build a project using MAKE, on Windows? (It builds output from source JS files)",
      "P-task": "build project use make window\nbuild output sourc js file",
      "F_verb": "build",
      "P-body": "That Makefile uses a lot of more-complex constructs that Windows's \"cmd.exe\" can't handle. I'd advise trying to run it in MinGW or Cygwin if you need it to run on Windows. .  ",
      "P-tags": "makefil linux javascript window",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "so_63826026",
      "task": "How to import package in bash without ModuleNotFoundError",
      "P-task": "import packag bash without modulenotfounderror",
      "F_verb": "import",
      "P-body": "Place an (empty) \"__init__.py\" into your package root as well as all subdirectories. Then you can call the script as a module out of \"dir_1\": .  test.sh: .  Output: .  Have a look at the Packages-docs for more details. .  ",
      "P-tags": "python importerror bash",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP in NP without NP"
    },
    {
      "id": "so_24182112",
      "task": "Shell script to find OSX version",
      "P-task": "shell script find osx version",
      "F_verb": "find",
      "P-body": "This is the way to do it: .  ",
      "P-tags": "shell version maco",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_10256707",
      "task": "Avoiding \"Setting Locale Failed\" Message While Calling Perl",
      "P-task": "avoid set local fail messag call perl",
      "F_verb": "set",
      "P-body": "\"UTF-8\" is not a locale name. Set the \"LC_CTYPE\" environment variable to a locale that's recognized by your system. It should probably look like \"en_US.UTF-8\". You can get a list of valid locales by running the command \"locale -a\". .  ",
      "P-tags": "unix linux perl messag stderr",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "ul_653831",
      "task": "sudo pacman -S reflector returns \"target not found reflector\" on artix linux",
      "P-task": "sudo pacman -s reflector return target found reflector artix linux",
      "F_verb": "find",
      "P-body": "Looks like you don't have the \"community\" repositories enabled. At least on my Arch system, that's where \"reflector\" is: .  I just had a look at Artix's documentation and found: .   As of June 2021, all Arch repositories are disabled by default. To enable them, install \"artix-archlinux-support\" and follow the on-screen instructions to activate the Arch repositories you want, most likely extra, community and multilib, which contain packages not yet in Artix repositories. Do not enable community alone as it contains packages dependent on others in extra. .   So, according to that, you should run: .  Then follow whatever prompts that gives you to enable at least \"extra\" and \"community\" and likely also \"multilib\". Once you have done that, run \"pacman -Sy\" to load the new sources and then you should be able to install as expected with: .  ",
      "P-tags": "pacman",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_253015",
      "task": "apt-get install bluez only installing documentation",
      "P-task": "apt-get instal bluez instal document",
      "F_verb": "get",
      "P-body": "The \"bluez\" package doesn't install a \"bluez\" binary, so it's perfectly normal that your shell can't find one; it installs the \"bluetoothd\" daemon and a number of different tools, \"bccmd\", \"bluemoon\", \"bluetoothctl\", \"btmon\", \"ciptool\", \"gatttool\", \"hciattach\", \"hcitool\", \"hex2hcd\", \"l2ping\", \"l2test\", \"mpris-proxy\", \"rctest\", \"rfcomm\" and \"sdptool\", along with manpages which explain how to use them. .  To see what was installed, run \"dpkg -L bluez\". .  ",
      "P-tags": "bluetooth kali-linux python raspberry-pi bluez",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_22350",
      "task": "How to save Ubuntu from restarting on a laptop with malfunctioning video card?",
      "P-task": "save ubuntu restart laptop malfunct video card",
      "F_verb": "save",
      "P-body": "Start the computer in recovery mode, when you get to the selection screen you need to select \"root with networking\". .  Once on the command line you can install and run the openssh-server: .  Although this won't help you with your graphics problem, it will let you get access to the machine. .  ",
      "P-tags": "kubuntu intel-graph",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP from S_ING on NP with NP"
    },
    {
      "id": "au_897628",
      "task": "How to restore after accidentally apt-get remove python",
      "P-task": "restor accident apt-get remov python",
      "F_verb": "restore",
      "P-body": "Managed to get it done this afternoon. .  After a whole day of adventures in the deepest pits of the internet, these commands worked for me.  .  python-dnspython and samba was still missing after the first command, \"--reinstall python-dnspython\" pulled samba in as well. Autoremove removed the needless dependencies. .  ",
      "P-tags": "apt python 16 04",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V after S"
    },
    {
      "id": "su_1517572",
      "task": "systemd service not executing script?",
      "P-task": "systemd servic execut script",
      "F_verb": "execute",
      "P-body": "If you run a systemd with \"Type=simple\", then you want to run that service in foreground, which means it should block while the service is alive, rather than forking a background daemon and exiting. .  The autossh \"-f\" option puts it in background, so it's doing the opposite of what you want. Drop that option and this should work. .  Additionally, you'll want to launch autossh from the shell script using the \"exec\" command, which will replace the shell with autossh in the same process. This makes it so that autossh is a direct child process of systemd, so whenever systemd tries to interact with it (for example, send it a signal when trying to stop it), it will be sending the signal directly to the autossh process and not to a shell that's running it. .  Putting it all together, you should modify your shell script to read: .  Note that you don't really need a separate shell script for this command-line, it doesn't use any features of the shell that are not supported or work differently in systemd... So you could simply use that directly in the \"ExecStart=\" of your unit file: .  ",
      "P-tags": "systemctl linux systemd ssh bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_39921501",
      "task": "How to using pipe in loop, is mine correct?",
      "P-task": "use pipe loop mine correct",
      "F_verb": "use",
      "P-body": "In the case of pipe, the write blocks if pipe is full.  .  Note that the data written into the write-end of pipe is buffered in kernel until it is read from the read-end of the pipe. .  \"child :\" The pfd[1] can be closed in child as it is not used in child. But, it is not required to close pfd[0] if it shall be used by child subsequently. .  \"parent :\" Similarly, the pfd[0] can be closed in parent as it is not used in parent. But, it is not required to close pfd[1] if it shall be used by parent subsequently. .  ",
      "P-tags": "posix unix pipe fork c",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_23075605",
      "task": "How to exit out of the shell script if the files are missng in both the machines?",
      "P-task": "exit shell script file missng machin",
      "F_verb": "exit",
      "P-body": "As per your solution it should work .  \"scp\" returns 0 only when it succeeds. so you can write like this: .  Now let first you check retrun code of each command like as follows .  Same for second command. Now in both case if you get non zero value then your solution must work. .  ",
      "P-tags": "unix scp linux shell bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V of NP if S"
    },
    {
      "id": "ul_612285",
      "task": "How to disable BTRFS copy-on-write updates for a subvolume using btrfs-property instead of chattr",
      "P-task": "disabl btrf copy-on-writ updat subvolum use btrfs-properti instead chattr",
      "F_verb": "disable",
      "P-body": "In October 2020, it seems that only \"ro\" (read-only), \"label\", and \"compression\" are the only properties available via \"btrfs property ...\" at this time. .  ",
      "P-tags": "btrf copy-on-writ",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP for NP using NP of NP"
    },
    {
      "id": "au_522833",
      "task": "How to dump ALL dconf/gsettings so that I can compare them between two different machines?",
      "P-task": "dump dconf gset compar two differ machin",
      "F_verb": "dump",
      "P-body": "Use the \"dump\" command of \"dconf\" (https://developer.gnome.org/dconf/unstable/dconf-tool.html): .  As always you can use output redirection to save the output to a file for later use: .  ",
      "P-tags": "dconf gnome wine keyboard",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP that S"
    },
    {
      "id": "so_45779305",
      "task": "Unable to add txt file of computers into SCCM collection",
      "P-task": "unabl add txt file comput sccm collect",
      "F_verb": "add",
      "P-body": "You must have made a mistake following my hints, both do work: .  If you wanted to split the extension a better way is to simply use BaseName instead of Name .  ",
      "P-tags": "powershel sccm",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP into NP"
    },
    {
      "id": "so_52183847",
      "task": "How to prepend all the output of tar -tf",
      "P-task": "prepend output tar -tf",
      "F_verb": "prepend",
      "P-body": "Try this: .  ",
      "P-tags": "linux tar bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP of NP"
    },
    {
      "id": "so_68896929",
      "task": "PowerShell Keeping track of updated and rejected rows while cleaning up files",
      "P-task": "powershel keep track updat reject row clean file",
      "F_verb": "keep",
      "P-body": "Nested arrays/lists are great, but you'll have to consider how you want to store and display your data. .  A CSV file, like a table, doesn't properly handle nested objects like lists or arrays. This can be fine if you know your data, and don't mind converting your \"RejectReason\" field from/to a delimited string when you read it. For example, you could use \"Where-Object\"'s filter block to find all the entries in \"$outputRejected\" with a specific reason: .  For what you are doing, this usually works just fine. You have to be careful of your additional separator characters, but since you're defining the \"RejectCode\" yourself, it shouldn't be an issue. .   For anything more complicated, I tend to create a \"PSCustomObject\" from each \"$row\" and set each property to what I need. This tends to work a little better for me than using \"Add-Member\": .  Just be aware that powershell's CSV commands tend to squish properties into the unhelpful \"system.object[]\" text when your properties aren't simple values like strings or ints. A better option for saving nested objects like this is a structured format like JSON. e.g.: \"$report | ConvertTo-Json | Out-File $path\". .  ",
      "P-tags": "powershel csv",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP of NP while S"
    },
    {
      "id": "so_36181613",
      "task": "How to configure Java 7 OR Java 8 dependency in Debian deb package?",
      "P-task": "configur java 7 java 8 depend debian deb packag",
      "F_verb": "configure",
      "P-body": "To check for \"ANY\" Java/JDK package, you can use the pipe symbol (\"\"|\"\") in the \"Depends:\" line. For example, here's the line for the \"tomcat7-common\" package in Jessie: .  However, note that if you use a \"Depends:\" line, \"dpkg\" will only consider it satisfied by packages that it knows about. If someone installs Oracle Java, or some other vendor's JDK, without using \"dpkg\", or if the \".deb\" doesn't list the right keywords in a \"Provides:\" line, it won't work. So, you might be better off with a \"Suggests:\" or \"Recommends:\" line. .  ",
      "P-tags": "dpkg deb linux debian java",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_45088882",
      "task": "Powershell - Remove from string",
      "P-task": "powershel - remov string",
      "F_verb": "remove",
      "P-body": "A \"-replace\"-based solution: .  Note how you can use an array directly as the LHS of the \"-replace\" operation. .  The above yields: .   \"-split\" is an option too, but to avoid additional complexity you need an explicit loop: .  It is possible to avoid an explicit loop, but that's probably not worth doing - for reasons of both performance and readability; it does show PowerShell's flexibility, however: .  ",
      "P-tags": "json powershel window script",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_25227782",
      "task": "sqlite3 - keep open handler VS, open database when need",
      "P-task": "sqlite3 - keep open handler vs open databas need",
      "F_verb": "keep",
      "P-body": "You should keep it open. .  Open and close file is more expensive then keep one file handler opened. .  You can simulate the cost by running 1000 same queries in loop, 1st when open and close are inside the loop and then when you move them out. .  Usually a multi-threaded application should use connection pool. The size of the pool should be calculated. .  EDIT: synchronizing writes to DB can be done by \"TRANSACTION\". in sqlite you use \"BEGIN TRANSACTION\" and \"END TRANSACTION\" sqls (or just \"BEGIN\" & \"END\"). \"BEGIN\" can be use as mutex lock in a loop, \"END\" can be use as unlock. it can protect you from altering the DB from other process. .  EDIT2: more solution is connection per thread. .  EDIT3: You can also implement or use a message queue to write to the DB. .  EDIT4: I think separating read & write is not so good idea, because write should be in higher priority than read. the problem is that in sqlite you can't lock a single table, you lock the entire DB. .  When I used sqlite I used a wrapper class with a single handle to the DB, all the read and write from/to the DB by high level functions, I had a write queue, and also kept track for each table if it had unwritten change pending, so for every read function I could test if I have the updated data or should wait. .  ",
      "P-tags": "sqlite c++ unix",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_1334090",
      "task": "mounting usb stick -says path to stick doesn't exist or isn't a directory",
      "P-task": "mount usb stick -say path stick exist directori",
      "F_verb": "mount",
      "P-body": "In Ubuntu, there should not be a need to mount a USB stick using the terminal. By default, USB sticks are automounted when you plug them in. .  That a stick does not automount rather points to an issue with the stick. It could designate problems with the file system. Thus, before attempting anything else, have your file system checked. You can check it with \"fsck\". If the file system is not too badly damaged, linux will recognize it is a FAT32 formatted system (as you also see in the first output you posted), and invoke \"fsck.vfat\" to check it. .  Your drive is known as \"/dev/sdf\". The partition that is existing on it, is known as \"/dev/sdf1\". You should only check a partition that is not in use, so to be safe, you first unmount it, as administrator: .  Then you can check it: .  This will report on any issues and inconsistencies that may be there. In order to effectively repair the file system, allowing the system choose what to do, you execute the command again with the \"-a\" option (see \"man fsck.vfat\" to learn about all possible options). .  Once that is done, wait a few seconds and then unplug the USB. Plug it back in - it should automount. .  Your question actually was on how to mount it on the terminal. Again, prefer to rely on the automatic system, but if you really wish to mount manually, then you can using the \"mount\" command executed as administrator. .  Here, indeed, you state you want to mount the partition \"/dev/sdf1\" on the folder \"/media/USB-drive\". For this command to proceed, the folder that will be the mount point must already exist. If needed, create it with the command \"sudo mkdir /media/USB-drive\". .  ",
      "P-tags": "mount usb",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_31626133",
      "task": "How to iterate dynamically in an array in bash",
      "P-task": "iter dynam array bash",
      "F_verb": "iterate",
      "P-body": "As Eric Renouf said, modifying the list you're working on can be tricky. As long as you're only appending new elements (to the end of the list), and just want those new elements included in the iteration, you can use something like this: .  Since the length of the list (\"${#list[@]}\") is recalculated every time around, the loop will include new elements. Also, the \"+=( )\" syntax guarantees you're always strictly appending. .  ",
      "P-tags": "array linux shell bash",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_33916085",
      "task": "Powershell Add Output of Select to Variable",
      "P-task": "powershel add output select variabl",
      "F_verb": "add",
      "P-body": "You can create and array ($Servers for example) then add each result into it: .  ",
      "P-tags": "pipelin output syntax powershel variabl",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "so_35875319",
      "task": "get rid of integer expression expected in script",
      "P-task": "get rid integ express expect script",
      "F_verb": "get",
      "P-body": "Error is due to the fact that bash only supports integer mathematics and your script is comparing \"5.4\" with \"1\". .  You can fix your script by using: .  \"${MEM%.*}\" will strip part after decimal point and since you're just comparing it with \"1\" there is no need to have decimal point in variable \"MEM\". .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_47050589",
      "task": "Create URL friendly slug with pure bash?",
      "P-task": "creat url friendli slug pure bash",
      "F_verb": "create",
      "P-body": "I'm using this function, in my bash profile: .  Based on: https://gist.github.com/oneohthree/f528c7ae1e701ad990e6 .  ",
      "P-tags": "parameter-expans slug bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_108396",
      "task": "how to check if the kernel support for ip alias?",
      "P-task": "check kernel support ip alia",
      "F_verb": "check",
      "P-body": "You can find out which module a device is using through these 2 methods. Note: Alias interfaces are also called virtual interfaces.  .  In researching this I do not believe there is an actual kernel module that facilitates virtual interfaces on physical ones, rather it's a function that physical drivers provide. .  Using the /sys filesystem If you note which device you're using that has an alias network interface. .  Notice the last line, that's my virtual interface, \"eth1:0\". Now to find out which kernel module is facilitating it. Taking a look at the \"/sys\" file system for this device. The path will be the base device that has the alias attached to it, \"eth1\" in our example. .  So if we \"ls -l\" follow those paths we'll ultimately get the following driver that's being used by the device. .  So we're using the \"natsemi\" driver. .  lshw Another method for finding the driver is to use the tool \"lshw\" and query the network devices. .  Example The key lines in this output are these: .  If you look at the \"configuration:\" line you'll notice the \"driver=natsemi\". This is that same kernel module. .  So then where's /proc/net/ip_alias? This is an older facility in the Linux <2.2 kernels that was removed/depreated in the move to 2.4+ kernels. See the IP-Aliases Howto for example. .  excerpt .    IP Alias is standard in kernels 2.0.x and 2.2.x, and available as a compile-time option in 2.4.x (IP Alias has been deprecated in 2.4.x and replaced by a more powerful firewalling mechanism.)   ",
      "P-tags": "network alia ip",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_12822333",
      "task": "Compare two Directories in Powershell and work with the incomparisons",
      "P-task": "compar two directori powershel work incomparison",
      "F_verb": "compare",
      "P-body": "You could construct the full path for each potential file, rather than relying on a potentially costly recursive wildcard search. .  Each \"$file\" comes from some subdirectory of \"$source\", so the full path (given by \"$file.FullName\") can be shortened to the \"relative\" path by dropping the first \"$source.Length\" chars from \"$file.FullName\". Take your new root path and add it to this relative path, and you've got the new full path. .  ",
      "P-tags": "directori powershel move robocopi",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_244521",
      "task": "How can I replace a literal \\n with a newline character? (on OS X)",
      "P-task": "replac liter n newlin charact\nos x",
      "F_verb": "replace",
      "P-body": " ...should handle the \"\\n\"ewline replacements without misinterpreting backslash escapes - so you can still have a literal \"\\\\n\" in input. I'm a little fuzzy on how you can ever get a \"\\n\" out of your history commands, though. .  I tried w/ \"zsh\" to find out how a \"\\n\"ewline might be read out from the history file without being escaped like that: .   That won't do. So, I tried this instead: .   ...so that's probably what you should be doing instead .  For some reason \"zsh\" escapes \"\\n\"ewlines in \"history\" or \"fc -l\" output in an ambiguous way, but when it hands a history command over to some editor, it gives it the real thing. .  \"zsh\"'s primary means of \"history\" manipulation is \"fc\", and the \"history\" command is not much more than an alias for \"fc -l\". When \"fc\" is called with the \"-l\" option it will list the matching history lines to stdout (after ambiguously escaping any non-printable characters), but \"fc\"'s default behavior is to invoke another utility with one or more temp file arguments into which it has written all history matches for its args. .  \"fc\" derives the name of the utility it invokes from the \"$FCEDIT\" environment variable, or, if it is unset or null, from \"$EDITOR\", or, if likewise unsuccessful, defaults to \"vi\". If the invoked utility returns true, \"fc\" will afterward attempt to run any commands it finds in the (presumably) edited temp files before removing them. .  And so the above command sequence substitutes \"cat\" for any editor command, and inverts its return so that a successful readout of \"fc\"'s tempfiles will return false - to keep \"fc\" from trying to run the commands again. .  A more complete, sort-of drop-in solution which doesn't need to call out to an external utility could look like: .  ...which ought to handle almost transparently any argument list you might expect \"zsh\"'s \"history\" command to do; except that its output is always literal and it never includes history timestamps or event numbers in the output (unless you call it like \"history -l [args]\", in which case it will behave as the builtin \"history\"). .  ",
      "P-tags": "newlin osx sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "au_284440",
      "task": "Why ID card reader is not working in Ubuntu 12.04, 12.10? Using Omnikey3121",
      "P-task": "id card reader work ubuntu 12 04 12 10\nuse omnikey3121",
      "F_verb": "use",
      "P-body": "It WORKS! .  It was not working because the driver is not correct. So I installed this one: https://www.hidglobal.com/drivers/14919 .  And now I have feedback from the card reader directly, where I get ATR values. .  EDIT: .  1) When the system boots run this once as root, so that the service is launched for sure: .  2) then as your normal user run .  3) insert the card and you should see it working .  ",
      "P-tags": "openssh card-read kernel 12 10 12 04",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_711652",
      "task": "Commit changed files, added new files and omit some files to an external server in Subversion on Linux / Ubuntu",
      "P-task": "commit chang file ad new file omit file extern server subvers linux ubuntu",
      "F_verb": "omit",
      "P-body": "So you have two problems, one, that you want to ignore a file that you've changed and two, that you want to add a bunch of files to subversion at once. .  To solve the first problem you should use the previous suggestion of: .  \"svn propedit svn:ignore <dir>\" .  and enter the name of the file into the editor that comes up (depending on the $EDITOR environment variable, this will most likely be emacs, vi, or nano by default). Make sure to save your changes to this file or it won't help. .  To solve the second problem, just loop over the files in your working copy via svn add in a bash equivalent terminal emulator - it won't add something that's already under version control and you can safely ignore the warnings it gives you. The better solution would be to write a quick script to check if something is in svn first and only add it if it's not, but I think for what you're doing it might be a waste of time. So, just: .  \"svn add *\" .  from the root directory of your project and then, after checking \"svn status\" to make sure you're happy with the changes, \"svn commit\". The commit command will find all your changes (minus the ones in svn:ignore) and send them off to your repository. .  ",
      "P-tags": "svn linux version-control",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "su_584397",
      "task": "How to find which ports are blocked?",
      "P-task": "find port block",
      "F_verb": "find",
      "P-body": "When you use \"nmap\", there is a difference between a \"filtered\" and a \"closed\" port. That should show all non-accessible ports as \"filtered\" and those where just no one is listening should be listed as \"closed\". .  If you have a mean router in between which answers TCP requests instead of dropping them, you can find out by binding to all ports (warning, you could run out of system resources doing this! Maybe try with ~1000 ports at a time): .  ",
      "P-tags": "port linux nmap",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V which S"
    },
    {
      "id": "su_283560",
      "task": "How to change terminal to include <time of day> and <pwd>",
      "P-task": "chang termin includ time day pwd",
      "F_verb": "change",
      "P-body": "Put something like this in your .bashrc or .bash_profile (changed from yours, as I wasn't sure how that would make sense!) .  Personally, I use: .  That might give you a hand getting things to look right. .  Once you've added it to your .bashrc file, remember to run \"source ~/.bashrc\" to make it work. .  ",
      "P-tags": "pwd shell",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_69468379",
      "task": "PowerShell different services to run in particular sequence (Remotely)",
      "P-task": "powershel differ servic run particular sequenc remot",
      "F_verb": "run",
      "P-body": "In the first statement: .  You ask PowerShell to stop \"ServiceNameA\" on a remote computer. .  You then call \"WaitUntilServices1\" which attempts to wait for a service of the same name on your local computer - which is obviously not gonna stop any time soon because you requested stopping a service on a different computer. .  Change the function definition to accept a \"-ComputerName\" parameter too and pass that to \"Get-Service\": .  Now we can do: .  ",
      "P-tags": "servic powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP"
    },
    {
      "id": "so_65316430",
      "task": "why defunct process generate when call exec in shell script?",
      "P-task": "defunct process gener call exec shell script",
      "F_verb": "generate",
      "P-body": "It's a parent process' responsibility to \"wait\" for any child processes. The child process will be a zombie from the time it dies until the parent \"wait\"s for it. .  You started a child process, but then you used \"exec\" to replace the parent process. The new program doesn't know that it has children, so it doesn't \"wait\". The child therefore becomes a zombie until the parent process dies. .  Here's a MCVE: .  You can instead do a double fork: .  ",
      "P-tags": "defunct linux exec shell zombie-process",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V when S"
    },
    {
      "id": "so_37622241",
      "task": "Parse JSON Nested SubValues in Powershell to Table",
      "P-task": "pars json nest subvalu powershel tabl",
      "F_verb": "parse",
      "P-body": "try this .  ",
      "P-tags": "json powershel csv parent-child",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP in NP to NP"
    },
    {
      "id": "so_54515648",
      "task": "Can I omit the full path of a \"shebang\" on the first line of shell script?",
      "P-task": "omit full path shebang first line shell script",
      "F_verb": "omit",
      "P-body": "Using interpreter without full path is not supported everywhere. In many cases, kernel does the shebang handling and kernel normally does not know about the environment variables, including PATH. So it needs a full path in order to find the interpreter.  .  That's why \"#!/usr/bin/env bash\" is used - \"bash\" is located and executed by \"env\", so it allows \"bash\" to be anywhere in PATH, while only requiring \"/usr/bin/env\" to be in known location. You can't use just \"#!bash\" or \"#!env bash\", because kernel does not know, where to find them. .  Using plain interpreter may work sometimes - it means that shebang handling is done by something that is aware of the environment, most likely by the active shell itself and not by the kernel. .  There are good answers about the similar question also available: .   https://unix.stackexchange.com/questions/77512/why-not-use-pathless-shebangs https://unix.stackexchange.com/questions/29608/why-is-it-better-to-use-usr-bin-env-name-of-path-to-name-as-my  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP on NP of NP"
    },
    {
      "id": "ul_664789",
      "task": "grep to find files with string having special characters",
      "P-task": "grep find file string special charact",
      "F_verb": "find",
      "P-body": "Use \"grep -e\": .  or .  Escaping or quoting the \">\" tells the shell to pass it literally to \"grep\". But that doesn't help with grep expecting arguments starting with dashes to be options. Explicitly giving the pattern with the \"-e\" option bypasses that issue. .  The man page for GNU grep on my Debian even mentions this: .   \"-e PATTERNS\", \"--regexp=PATTERNS\" Use PATTERNS as the patterns. [...] This option can be used to protect a pattern beginning with \u201c-\u201d. .   ",
      "P-tags": "grep",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "so_36850935",
      "task": "Can you help me get rid of an intermediary output in my imagemagick convert commands?",
      "P-task": "help get rid intermediari output imagemagick convert command",
      "F_verb": "get",
      "P-body": " There was no need to have 3 convert calls. Instead of writing to file you can write to memory-program-register (mpr) and then recall later. The \"+delete\" deletes the original image.  .  ",
      "P-tags": "imagemagick-convert bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_18046284",
      "task": "Why do bash \"set -e\" cause exit after a seeming error-free command?",
      "P-task": "bash set -e caus exit seem error-fre command",
      "F_verb": "cause",
      "P-body": "\"set -e\" will cause the script to exit if any command returns a non-zero exit status. Well, there are a bunch of exceptions, but that's the general rule.) So, \"./NameOfATool\" apparently returns a non-zero exit status. This might mean that it actually thinks there's an error, or it might mean that the program was poorly written and doesn't report an appropriate exit status for success, or it might mean that it uses special exit-status values to report specific things (much like the standard utility \"diff\", which returns 0 for \"same\", 1 for \"different\", and 2 for \"error\"). .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP after NP"
    },
    {
      "id": "so_15087401",
      "task": "Getting latest directory from another server",
      "P-task": "get latest directori anoth server",
      "F_verb": "get",
      "P-body": "You need to encase the file spec with quotes - otherwise the spec will be interpreted by the local shell. .  ",
      "P-tags": "unix shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_21772584",
      "task": "How to find if a file/directory is checked out in clearcase using shell script",
      "P-task": "find file directori check clearcas use shell script",
      "F_verb": "find",
      "P-body": "You need to loop on every line of your File.txt, and for each one describe and grep for \"CHECKEDOUT\". .  Another way is to look for all checkout out folders, and for each one grep it from the \"Files.txt\". .  ",
      "P-tags": "shell clearcase-ucm",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V if S"
    },
    {
      "id": "au_818409",
      "task": "Get USB Device Name In UBUNTU",
      "P-task": "get usb devic name ubuntu",
      "F_verb": "get",
      "P-body": "The command you're looking for is \"lsusb\". It will return information as to what is connected to your computer and on what bus. .  However, it does not (and can not) look at the connected TTYs, as this would require opening a session with the TTY and a few other things. .  ",
      "P-tags": "mount usb command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_37998003",
      "task": "Recursively removing/renaming files using powershell",
      "P-task": "recurs remov renam file use powershel",
      "F_verb": "remove",
      "P-body": "That error only happens when you attempt to rename a directory to the same \"NewName\" as the current name, you can safely ignore it. .  Add \"-ErrorAction SilentlyContinue\" to silently suppress the error message: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "au_244307",
      "task": "How do I deploy units that use the -proposed repository?",
      "P-task": "deploy unit use -propos repositori",
      "F_verb": "use",
      "P-body": "You can tell Juju to used the proposed repository by changing \"juju-origin\" to \"proposed\". .  What I'm doing is just setting up two local environments, so I have a dedicated proposed one for testing.  .  ",
      "P-tags": "juju",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_591220",
      "task": "Cannot uninstall MongoDB",
      "P-task": "uninstal mongodb",
      "F_verb": "uninstall",
      "P-body": "Try  .  This will pretend that mongodb isn't installed already and overwrite the old files. .  Afterwards you should be able to remove it like usual. .  ",
      "P-tags": "uninstal dpkg mongodb software-uninstal",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_62542214",
      "task": "Add Unique ID to CSV with Powershell",
      "P-task": "add uniqu id csv powershel",
      "F_verb": "add",
      "P-body": "You can use Group-Object for this like below: .  ",
      "P-tags": "powershel csv",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP S_INF with NP"
    },
    {
      "id": "so_27039965",
      "task": "How to get the cpu cycles and executed time of one function in my source code or system library",
      "P-task": "get cpu cycl execut time one function sourc code system librari",
      "F_verb": "get",
      "P-body": "Consider the code from SO: Get CPU cycle count? .  and implement a class like the following: .  Finally you can simply use that class in your code with: .  I have some similar code that automatically counts some statistics in different categories. However, mainly in the destructor you have to accumulate the cycles into a statistic class or something else. .  ",
      "P-tags": "linux c time gcc",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_349818",
      "task": "how to get RSA fingerprint of a remote site in Debian?",
      "P-task": "get rsa fingerprint remot site debian",
      "F_verb": "get",
      "P-body": "SSH host key The \"ssh-keyscan\" command is what you need for the host key. It was developed so that users can obtain public host keys without needing to authenticate to the SSH server. From its man page: .   \"ssh-keyscan\" is a utility for gathering the public ssh host keys of a number of hosts. It was designed to aid in building and verifying \"ssh_known_hosts\" files. .   For your particular example, the output of \"ssh-keyscan moszumanska.debian.org\" is .  This corresponds with the published SSH host key. .  SSH host key fingerprint The \"ssh-keygen\" command can then be used to get the fingerprint. I\u2019ve previously written a detailed answer on how both these commands can be combined. .  ",
      "P-tags": "debian ssh",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_33453627",
      "task": "I am getting an syntax error when using expr",
      "P-task": "get syntax error use expr",
      "F_verb": "get",
      "P-body": "With \"expr\", you need to escape the \"*\" to avoid it being expanded as a file glob: .  With arithmetic expressions, this is not an issue: .  ",
      "P-tags": "expr bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "au_376931",
      "task": "How to install CPU Sim",
      "P-task": "instal cpu sim",
      "F_verb": "install",
      "P-body": "How to install CPU Sim 3.9.0 Open a Terminal with Ctrl + Alt + T. Download the CPUSim-Zipfile: .  Install unzip .  Unzip the CPUSim3.9.0.zip-file .  Go into the newly created folder .  If you haven't install a Java JRE or JDK yet, you need to install it now. If you are unsure write \"java -version\". if this results with an error you must install it. .  You need to first enable the universe repository. Then you can install the Java Runtime Environment (JRE). .  Create an executable start script .  Execute the script to run CPU Sim 3.9.0 .  ",
      "P-tags": "software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_49976293",
      "task": "awk simple calculator-function behaving strangely in a working dir containing a one-letter dir",
      "P-task": "awk simpl calculator-funct behav strang work dir contain one-lett dir",
      "F_verb": "contain",
      "P-body": "You've got it wrong. The \"?\" has a special meaning which the shell interprets as, meaning to match a single character. That's why the expansion results in a single character filename, i.e. glob expansion happens before the shell looks up functions or commands. Had there been such files with single character names, it would have expanded to a literal string \"?\" .  From \"man bash\" .   \"Pathname Expansion\" .  After word splitting, unless the \"-f\" option has been set, bash scans each word for the characters \"*\", \"?\", and \"[\". If one of these characters appears, then the word is regarded as a pattern, and replaced with an alphabetically sorted list of filenames matching the pattern .  The special pattern characters have the following meanings: .  \"?\" Matches any single character. .   Would recommend a way to use the \"awk\" import shell variables option \"-v\" to import args than use double-quotes to avoid having to take care of special cases. Also consider using a better function name than any of the shell meta-characters .  But for a use-case for a simple calculator like using the string \"1+2\" inside the expression, you could use double-quotes properly  .  ",
      "P-tags": "awk shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_38338320",
      "task": "Want to put IP address v4 of my specifically named adapter into a variable using Powershell",
      "P-task": "want put ip address v4 specif name adapt variabl use powershel",
      "F_verb": "put",
      "P-body": "simple one liner .  get from enabled network .  only from particular adapter and ipv4 .  ",
      "P-tags": "powershel name adapt ip",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP into NP using NP"
    },
    {
      "id": "so_30943129",
      "task": "Check whether a Kafka topic exists in Python",
      "P-task": "check whether kafka topic exist python",
      "F_verb": "check",
      "P-body": "You can use the \"--list (List all available topics)\" option for \"kafka-topics.sh\" and see if \"self.topic\" exists in the \"topics\" array, as shown below. .  Depending on the number of topics you have this approach might be a bit heavy. If this is the case, you might be able to get away with using \"--describe (List details for the given topics)\" which will likely return empty if the topic doesn't exist. I haven't thoroughly tested this, so I can't say for sure how solid this solution (\"--describe\") is, but it might be worth it for you to investigate a bit further. .  OUTPUT: .  There is also a Broker Configuration available so you don't have to take any of these steps: .   auto.create.topics.enable | true | Enable auto creation of topic on the server. If this is set to true then attempts to produce data or fetch metadata for a non-existent topic will automatically create it with the default replication factor and number of partitions. .   I would take this approach if possible. .  Note that you should set topic configs (\"server.properties\") on your broker for \"num.partitions\" and \"default.replication.factor\" to match your settings in your code snippet. .  ",
      "P-tags": "apache-kafka python bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V whether S"
    },
    {
      "id": "so_63472241",
      "task": "Pulling Pixels that changed between 2 images and saving to a new using image magick convert while keeping the original colors",
      "P-task": "pull pixel chang 2 imag save new use imag magick convert keep origin color",
      "F_verb": "save",
      "P-body": "It is not clear what you want for the result. Here are two different ways in ImageMagick. There is a small blue square added to image 2. .  The following is Unix syntax. Windows syntax is slightly different. If using ImageMagick 7, replace convert with magick. .  Input 1: .   .  Input 2: .   .    Highlight difference in green: .   .  Black out the image except where difference: .    .  ",
      "P-tags": "imagemagick linux",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V to NP while S"
    },
    {
      "id": "so_16045457",
      "task": "How to change the cmd's current-dir using PowerShell?",
      "P-task": "chang cmd current-dir use powershel",
      "F_verb": "change",
      "P-body": "I'm not sure if this meets your needs, but if you set it up so that the only output from your powershell script is your desired new working directory, you could do this: .  ",
      "P-tags": "windows-8 powershel command-line-interfac command-lin",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP using NP"
    },
    {
      "id": "so_2601869",
      "task": "Using Valgrind tool how can I detect which object trying to access 0x0 address?",
      "P-task": "use valgrind tool detect object tri access 0x0 address",
      "F_verb": "detect",
      "P-body": "You don't need to use Valgrind, in fact you want to use the GNU DeBugger (GDB). .  If you run the application via gdb (\"gdb path_to_my_executable_file/executable_file\") and you've compiled the application with debugging enabled (\"-g\" or \"-ggdb\" for GNU C/C++ compilers), you can start the application (via \"run\" command at the gdb prompt) and once you arrive at the SegFault, do a backtrace (\"bt\") to see what part of your program called \"std::string::compare\" which died. .  Example (C): .  So the error I'm interested in is located on crash.c line 5. .  Good luck. .  ",
      "P-tags": "linux gdb c++ g++ valgrind",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V which S"
    },
    {
      "id": "so_63113584",
      "task": "Running a process as a different user from Python *and* print exit code",
      "P-task": "run process differ user python print exit code",
      "F_verb": "run",
      "P-body": "When you're running a script and you want to print its return code, you must wait until its execution is done before executing the print command. The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. http://docs.python.org/library/subprocess.html .  In your case: .  Reference: https://stackoverflow.com/a/325474/13798864 .  ",
      "P-tags": "linux python",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP from NP"
    },
    {
      "id": "so_39288568",
      "task": "How to get EPOCH time in PIG?",
      "P-task": "get epoch time pig",
      "F_verb": "get",
      "P-body": "Use CONCAT to combine your word with the epochtime.You can get the epochtime using ToUnixTime() .  Let's say your shell script is names test.sh .  If your shell script has parameter say param1 .  ",
      "P-tags": "apache-pig epoch shell hadoop",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_9632600",
      "task": "Shell script to find and delete a text pattern from .java files",
      "P-task": "shell script find delet text pattern java file",
      "F_verb": "delete",
      "P-body": "I am on Windows and have no Linux machine handy. I assume you are on a Linux system. What you need is this sed command, available in BASH on Linux. I have not been able to verify this code, but it should work as written, perhaps with a tweak. This assumes the blocks you want deleted begin with \"} catch\" and ends with a \"}\", with no other right curly braces inside that block. Of course, you need to be in the proper directory when you run this code, so use the CD command to get there. If the \u201d in \u2026\u201d is excluded, the loop will run as if \u201cin $@\u201d was given. .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_45369672",
      "task": "shell script to erase backups on ubuntu",
      "P-task": "shell script eras backup ubuntu",
      "F_verb": "erase",
      "P-body": "You have a extra space after \"+\" that is why it is not working .  ",
      "P-tags": "ubuntu eras shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP on NP"
    },
    {
      "id": "so_37557271",
      "task": "Bash script / utility to convert UK English to US spellings in TeX document",
      "P-task": "bash script util convert uk english us spell tex document",
      "F_verb": "convert",
      "P-body": "I think you need to have a list of substitution handy with you and call it for translation. You would have to enrich your dictionary file to efficiently translate text files.  .  Run the above script like:  .  Here is one sample dictionary I used: .  Execution result : .  ",
      "P-tags": "awk spell bash sed latex",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_30479657",
      "task": "Linux bash script removing part of string line by line",
      "P-task": "linux bash script remov part string line line",
      "F_verb": "remove",
      "P-body": "You can use this awk program: .  If the sixth column is not present, it changes spaces to underscores (changing \"PAPU 0\" to \"PAPU_0\"), and otherwise it just prints the sixth column. .  ",
      "P-tags": "awk linux string-pars bash sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP by NP"
    },
    {
      "id": "su_1455319",
      "task": "PermissionError: [Errno 13] Permission denied gets thrown when starting the script in CGI, but not in bash",
      "P-task": "permissionerror : errno 13 permiss deni get thrown start script cgi bash",
      "F_verb": "deny",
      "P-body": "The solution was to allow httpd to connect to the network. I just set \"httpd_can_network_connect\" to \"on\" with \"setsebool\", and it started working. Note, that to make the solution permanent, you need to use the \"-P\" switch too. .  ",
      "P-tags": "httpd centos-7 python cgi bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP when S"
    },
    {
      "id": "so_21143746",
      "task": "Why do we need to create different processes for each client in a concurrent server in C?",
      "P-task": "need creat differ process client concurr server c",
      "F_verb": "create",
      "P-body": "It isn't a concurrent server if you don't either \"fork()\" or process the connection in a (new?) thread. That's the definition of a concurrent server. .  If I'm reading your code correctly, what you've got is a simple sequential server. It can only process one connection at a time. That's fine if the computation required for each response is minimal, as in your example. It's not so good if the computation involves a lot of effort \u2014 access disk or database, for example. .  Note that a sequential server design is completely legitimate. So too is a concurrent server design. They should be applied to different workloads. Generally, though, a concurrent server will handle large traffic volumes better than a sequential server. Imagine if Google used sequential servers for responding to search requests! .  Another design uses a thread pool or process pool with one thread or process farming out the work to other threads or processes. These are trickier to write so they work well. .  ",
      "P-tags": "socket unix network c unix-socket",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP in NP in NP"
    },
    {
      "id": "so_15386556",
      "task": "Odd behavor when selecting ADRecipient.DistinguishedName from Get-MailboxFolderPermission",
      "P-task": "odd behavor select adrecipi distinguishednam get-mailboxfolderpermiss",
      "F_verb": "get",
      "P-body": "Replace $_ with another name, it is null in foreach statements. $_ (current object) is only available inside script blocks. .  ",
      "P-tags": "powershel exchange-serv",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V"
    },
    {
      "id": "ul_593580",
      "task": "How to continue cascaded pipeline commands after a failure",
      "P-task": "continu cascad pipelin command failur",
      "F_verb": "continue",
      "P-body": " This would run your pipeline as usual at first, until \"myscript\" terminates (for whatever reason). At that point, \"cat\" would take over reading from \"tee\" until there in no more data arriving. The data read by \"cat\" is discarded by piping it to \"/dev/null\". .  If \"a-command\" finishes without \"myscript\" ending/failing first, \"myscript\" would fail to read more data and would presumably terminate (?). At the point when \"myscript\" terminates, \"cat\" is started, but as there is no more data to read, it would immediately terminate and the pipeline would be done. .   Addressing TooTea's comment about making sure that we still get the correct exit status for the pipeline: .  ",
      "P-tags": "error-handl pipe bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP after NP"
    },
    {
      "id": "so_66694911",
      "task": "Exceptions during the install through pip3 dynaconf",
      "P-task": "except instal pip3 dynaconf",
      "F_verb": "install",
      "P-body": "Well it turned out that the proxy I am using was causing this problem so the idea iseither to unset the proxy to install it or to use the \"--proxy=[proxy_IP]\"attribute for the installation .  ",
      "P-tags": "ara ubuntu-18 04 python-3 x",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V through NP"
    },
    {
      "id": "ul_238893",
      "task": "How to stop Procmail?",
      "P-task": "stop procmail",
      "F_verb": "stop",
      "P-body": "Is there any reason why \"killall procmail\" doesn't work? .  If it's running as another user, try \"sudo killall procmail\" .  If procmail keeps on being restarted, that is because your Mail Transfer Agent (MTA - e.g. postfix or exim) keeps on invoking it to deliver mail to user inboxes. That's \"procmail\"'s job - it's a Mail Delivery Agent (MDA). .  Some have suggested removing the \"procmail\" package from your system. That will probably break your mail setup because your MTA is configured to use \"procmail\". If you do remove it, you'll also have to change the MTA config so that it doesn't use it. .  A better solution is to examine your procmail rules files to find out which rule is causing procmail to misbehave. You'll want to examine system rule files (e.g. in \"/etc/procmailrcs/\") and in your own \"~/.procmailrc\" file if you have one. .  I can''t be any more specific than that because \"procmail\" is a fairly full-featured mail processing language that's also capable of invoking external commands including other scripting interpreters like \"sh\" or \"perl\", so the possibilities are endless. .  If it's another user's .procmailrc, first find out which user it is with something like \"ps -o pid,user,args -C procmail\". Then either examine and fix (or comment out the broken rule in) their .procmailrc (if you are root) or inform the other user of the problem they are causing and/or inform the mail server admins. .  ",
      "P-tags": "cento procmail",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "au_293722",
      "task": "How to manage music ipod touch 4g ios6 ubuntu 13.04",
      "P-task": "manag music ipod touch 4g ios6 ubuntu 13 04",
      "F_verb": "manage",
      "P-body": "I'm not sure if \"gtkp\" is the same as \"gtkpod\", but I used to use that for managing my iPhone and it worked best of all the things I tried. It's been a while, but I think you need \"ifuse\" with it. .  I would give you more information from their page but it seems to be down at the moment. Otherwise you can try yourself: gtkpod. I had an iPhone 3GS at the time and it handled that fine. .  ",
      "P-tags": "ipod sync music io",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_68359730",
      "task": "Coundn't upgrade ruby to install shopify client",
      "P-task": "coundn upgrad rubi instal shopifi client",
      "F_verb": "upgrade",
      "P-body": "This is due to the fact that .  theme-check library is not working with ruby lower then 2.6. .  Unfortunately installing ruby with the standard way of : .  does install the version: .  ruby 2.5.1p57 (2018-03-29 revision 63029) [x86_64-linux-gnu] .  but an higher version can be installed following the \"rbenv\" method .  after the version of ruby should be .  ruby 3.0.2p107 (2021-07-07 revision 0db68f0233) [x86_64-linux] .  and running .  does install the latest shopify-cli .  if this method does not work, try with the other 2 described here Install Ruby On Rails on Ubuntu 18.04 Bionic Beaver .  ",
      "P-tags": "rubi shopifi ubuntu-18 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_50831244",
      "task": "Docker build fails on mkdir",
      "P-task": "docker build fail mkdir",
      "F_verb": "build",
      "P-body": "Your problem is that you're creating directories without protecting against already-existence of them. .  You've defined APACHE_LOG_DIR = APACHE_RUN_DIR, so, your \"RUN mkdir p $APACHE_RUN_DIR $APACHE_LOCK_DIR $APACHE_LOG_DIR\" command try to create it twice and it fails. .  When you check directory existence, probably you're accesing a container started from another image different than you've tried to build with this docker. .  To protect that, add \"exit 0\" at the end of \"RUN mkdir\", or change one ENV: .  ",
      "P-tags": "imag ubuntu apache2 docker",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "so_57189769",
      "task": "How to \"catch\" non-zero exit-code despite \"set -e\" then echo error code",
      "P-task": "catch non-zero exit-cod despit set -e echo error code",
      "F_verb": "echo",
      "P-body": "Just use a short-circuit: .  Or: .  You cannot do \"if ! asd\", because \"!\" negates the status and will set \"$?\" to 0 if \"asd\" exits non-zero and set \"$?\" to 1 if \"asd\" exits 0. .  But note that in either case best practice is to simply call \"asd\". If it fails, it should emit a descriptive error message and your additional error message is just unnecessary verbosity that is of marginal benefit. If \"asd\" does not emit a useful error message, you should fix that. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "au_1070984",
      "task": "Cannot open terminal on Ubuntu 18.04",
      "P-task": "open termin ubuntu 18 04",
      "F_verb": "open",
      "P-body": "Once you install the Chrome Remote Desktop, all the windows are opened in a virtual desktop/workspace (which you can connect to remotely). The audio is also routed to the same desktop/workspace. After logging out of the current session and logging back in, you assume control over the current active session and everything seems to work. .  If you want a quick solution to get your system working, just switch to a different virtual desktop (CtrlAltF4) and enter  .  after logging in to your account on the virtual desktop. To resume back on the gnome session, use CtrlAltF2. .  Alternatively, MDMower provided a great answer on configuring your Chrome Remote Desktop installation here: https://superuser.com/questions/778028/configuring-chrome-remote-desktop-with-ubuntu-gnome-14-04/#answer-850359 .  ",
      "P-tags": "google-chrom gnome-termin chrome-extens",
      "source": "qa",
      "cate": "open",
      "pat": "V NP on NP"
    },
    {
      "id": "so_10176997",
      "task": "How to get rid of 'GLIBCXX_3.4.9 not found error'?",
      "P-task": "get rid glibcxx_3 4 9 found error",
      "F_verb": "get",
      "P-body": " How do i tell my gcc/g++ to compile/link against an older version of GLIBXX so that my users dont get this error? .   There is no way to do that. Your only choices are: .   build with older \"g++\" version, or link \"libstdc++.a\" statically into your shared library, and hide its symbols (this may also have licensing implications, check with your lawyer). package your version of \"libstdc++.so.6\" together with your library, and ask users who have an older version to arrange to pick up your newer version instead (also has licensing implications, but I believe these are easier to satisfy).  ",
      "P-tags": "depend linux gcc glibc glib",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_163698",
      "task": "Why isn't adding a path to \".profile\" working?",
      "P-task": "ad path profil work",
      "F_verb": "add",
      "P-body": "To add a system-wide path, simply add to the PATH variable defined in \"/etc/environment\". .   Press \"Alt+F2\" and type \"gksudo gedit /etc/environment\" Change the default path: .  by adding your path to it: .    To add this path only to your session (i.e. for your user only), add to \"~/.pam_environment\" instead: .   Related: Please see the Ubuntu Wiki on Environment Variables. .   ",
      "P-tags": "environment-vari lubuntu",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_28389357",
      "task": "How to create files with specific security permissions in Linux? (i.e. the equivalent of Win32 CreateFile+SECURITY_ATTRIBUTES)",
      "P-task": "creat file specif secur permiss linux\ne\nequival win32 createfile+security_attribut",
      "F_verb": "create",
      "P-body": "Most recent file systems under Linux support ACL.  .  However ACL support needs to be enabled via the according entry to \"/etc/fstab\", when mounting the file-system. .  To get and set ACL from the command line use .   getfacl setfacl  On how to access ACL programmatically see \"man 5 acl\". .  ",
      "P-tags": "secur linux acl c winapi",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "au_878932",
      "task": "How do I install PowerShell?",
      "P-task": "instal powershel",
      "F_verb": "install",
      "P-body": "As of February 2017, Microsoft has made these available though a public repository which brings all the repository goodness. Details here. .  Here are the instructions to install the latest version of PowerShell on 16.04.  .  ",
      "P-tags": "powershel software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_14469299",
      "task": "Why are my quotation marks being ignored in my shell script",
      "P-task": "quotat mark ignor shell script",
      "F_verb": "ignore",
      "P-body": "To do what you want, you need to use an array, which will keep your quoted arguments un-split: .  You also need to use a shell that supports arrays: bash/ksh/zsh. Failing that, you have to use \"eval\": .  Note that you don't have to quote strings that don't contain any characters in \"$IFS\" .  ",
      "P-tags": "freebsd script shell",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V in NP"
    },
    {
      "id": "so_63923197",
      "task": "Create a SQL script within a bash script",
      "P-task": "creat sql script within bash script",
      "F_verb": "create",
      "P-body": "Quote your heredoc delimiter, e.g. .  From man bash: .   No parameter and variable expansion, command substitution, arithmetic expansion, or pathname expansion is performed on word. If any characters in word are quoted, the delimiter is the result of quote removal on word, and the lines in the here-document are not expanded. If word is unquoted, all lines of the here-document are subjected to parameter expansion, command substitution, and arithmetic expansion, the character sequence <newline> is ignored, and \\ must be used to quote the characters , $, and `. .   ",
      "P-tags": "linux mysql shell bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP within NP"
    },
    {
      "id": "so_26949854",
      "task": "Command not found, c++ application",
      "P-task": "command found c++ applic",
      "F_verb": "find",
      "P-body": "Your compilation command builds a \"Bingo\" executable. Your execution command tries to run a \"bingo\" program. Case is significant.  .  You really should compile with all warnings and debug info and don't need to pass any header file to the compiler (header which you should \"#include\" inside \"Bingo.cpp\" and \"main.cpp\"): .  Then, edit your code till you got no warnings, and repeat the compilation above. .  Check with  .  that you've got that executable and that its timestamp is newer than the source code. .  Then try to run it: .  if you need to debug it, use \"gdb\" as .  ",
      "P-tags": "c++ linux",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_23362186",
      "task": "Why won't PHP follow symlinks with SELinux enabled?",
      "P-task": "php follow symlink selinux enabl",
      "F_verb": "follow",
      "P-body": "The problem ended up being the way I was trying to set the SELinux type. .  I was running: .  However, I had to run: .  without the trailing slash. Once I did this, everything immediately sprung to life. .  Note: As I didn't have an \"Options\" directive in my apache \"Directory\" config, I didn't have to specify it and it still worked. .  ",
      "P-tags": "cento symlink php selinux",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP with NP"
    },
    {
      "id": "au_811299",
      "task": "SquashFS Errors Post-Install",
      "P-task": "squashf error post-instal",
      "F_verb": "install",
      "P-body": "This issue is often caused by either a hardware failure with your drive (as suggested by Error 5, which is almost always an I/O error), or a problem with the disk image you are using. More rarely, it can be a memory error, but this seems unlikely in your case. .  You can remedy this particular issue by downloading a clean ISO from the official Ubuntu website, and then verifying the MD5 hash of the file using the below command: .  You can find the valid MD5 sums for 16.04.1 below, sourced from this file. Be sure that the results from the command you've run and that file (or below) are the exact same. .  After you've verified that the MD5 hashes are actually EXACTLY as they appear here, you may proceed to actually burn it to a known-good flash drive. You can verify a good flash drive by running the read only check specified in the accepted answer to this question. .  Once you're sure that both the ISO and your flash drive work properly, you can use the Ubuntu ISO Tool or just \"dd\" to burn the ISO to your flash drive. .  ",
      "P-tags": "boot squashf usb",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_51922774",
      "task": "How to pass a variable having a dollar sign to another variable in PowerShell?",
      "P-task": "pass variabl dollar sign anoth variabl powershel",
      "F_verb": "pass",
      "P-body": "Without seeing any sample code, it's a bit hard to tell how your script works.  .  But basically, if you are setting a string literal that contains special characters, you can stop them from being parsed by using single quotes instead of double-quotes. For example, if you execute .  Then the value of password is \"stringwith\".  .  This is because powershell has parsed the string and treated $sign as being the name of a variable and has attempted to insert the value of $sign. But as $sign hasn't been declared, the default value of empty string is used. .  However, if you used single quotes, i.e. .  Then the value of password is \"stringwith$sign\".  .  Subsequently, setting  .  gives $string the value of  .  \"I need to inject my password string from VSTS here \"stringwith$sign\"\" .  ",
      "P-tags": "powershel azure-devop",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "au_754226",
      "task": "Where to enter commands to compile and run C program that resides in gedit?",
      "P-task": "enter command compil run c program resid gedit",
      "F_verb": "run",
      "P-body": "Save the file somewhere as \"program.cpp\" then open a terminal and cd to the directory you saved the file. .  To compile the program with gcc run \"gcc -o program program.cpp\". If there are no errors in the program this will output a binary with your compiled program called \"program\" which you can run with \"./program\" in the terminal. .  ",
      "P-tags": "compil gedit",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_4373518",
      "task": "linux shell : how to call programs after a while",
      "P-task": "linux shell : call program",
      "F_verb": "call",
      "P-body": "\"sleep #\" where # is number of seconds to wait .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP after NP"
    },
    {
      "id": "so_47426486",
      "task": "how to install mongodb on unix server",
      "P-task": "instal mongodb unix server",
      "F_verb": "install",
      "P-body": "Here's a link for that: https://www.digitalocean.com/community/tutorials/how-to-install-mongodb-on-freebsd-10-1 But since links-alone is poor stackoverflow.com protocol, this is essence of what you need to do when logged in on that server: .  P.S. mongo, not mango. .  ",
      "P-tags": "mongodb unix",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_25708907",
      "task": "SSL_library_init cause SIGILL when running under gdb",
      "P-task": "ssl_library_init caus sigil run gdb",
      "F_verb": "run",
      "P-body": " SSL_library_init cause SIGILL when running under gdb... .   It actually does it all the time, and not just under GDB. It is normal behavior in startup code as the library tests for processor features. You can safely ignore it by issuing \"handle SIGILL nostop\". .  See item 17 in the OpenSSL FAQ for more details: When debugging I observe SIGILL during OpenSSL initialization: why?. .  ",
      "P-tags": "linux gdb openssl raspberry-pi c",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V under NP"
    },
    {
      "id": "so_69708778",
      "task": "echo does not print command output as expected",
      "P-task": "echo print command output expect",
      "F_verb": "echo",
      "P-body": "The first example does command substitution for the argument to \"echo\" and is equivalent to the command \"echo **********\". This happens to output a list of directory contents, since \"**********\" seems to be equivalent to \"*\"1 and is expanded by the shell. .  If you want to prevent the shell to expand \"**********\", you need to quote it: .  which is equivalent to \"echo \"**********\"\". .   1don't quote me on that (pun intended) .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP as NP"
    },
    {
      "id": "su_391400",
      "task": "How can I automatically switch my VMs' bridged adapters between eth0 and wlan0 depending on what's active?",
      "P-task": "automat switch vm bridg adapt eth0 wlan0 depend activ",
      "F_verb": "switch",
      "P-body": "It is possible to change the type of the virtual network interface with a command like: .  This will make the first virtual interface in this VM be bridged to eth0. However, it only works when the guest is running. I'm not sure exactly when it will update the persistent configuration, but some testing has shown that the command does nothing if the guest is not running, but if it is, it both changes the immediate state of the interface and updates the configuration.) .  But it can be made to work if you have something running it frequently, specifying the interface you want to bridge to. You can use my NCD programming language to do this automatically. The NCD program below will observe the state of eth0 and wlan0, and will repeatedly invoke a command like above to make sure your VM is bridged the right interface. in particular, the one which has the RUNNING flag; e.g. for wired interfaces this means that the cable is plugged in) .  You can use the above program by running (as your user account, not root): .  Be sure to adjust the interface names in the script, and the VM name. Once you have verified that it works, you can configure your desktop environment to autostart the \"badvpn-ncd\" process. .  ",
      "P-tags": "virtualbox linux network virtual-machin",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP between NP and NP on NP"
    },
    {
      "id": "so_31802277",
      "task": "Datetime compare doesn't match",
      "P-task": "datetim compar match",
      "F_verb": "compare",
      "P-body": "Okay, it's working now. I converted both to strings. .  I hoped I can work with datetimes, but maybe that's not possible. Thank you! .  ",
      "P-tags": "powershel datetim",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "so_40014696",
      "task": "find and move text between boundaries",
      "P-task": "find move text boundari",
      "F_verb": "move",
      "P-body": "Just don't print the \"</text\" line until you see the next \"<text\" line or reach the end of the input file: .  That will work in any awk on any OS and the only memory it'll use is just enough to store the longest \"</text\" line. .  ",
      "P-tags": "awk text regex shell sed",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP between NP"
    },
    {
      "id": "so_25970649",
      "task": "Bash find: command returns 1 in an empty folder",
      "P-task": "bash find : command return 1 empti folder",
      "F_verb": "find",
      "P-body": "You should use \"find . -maxdepth 1\" instead of \"find ./* -maxdepth 0\". .  ",
      "P-tags": "find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_341966",
      "task": "How to parse a string like 20170202 to a date in a bash script?",
      "P-task": "pars string like 20170202 date bash script",
      "F_verb": "parse",
      "P-body": "Use \"-d\" arg of \"date\". .  \"man date\" .    To ease the comparsion, you can use the unixdate format .  ",
      "P-tags": "filenam date",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_65932709",
      "task": "How are device nodes created in Embedded Linux without udev?",
      "P-task": "devic node creat embed linux without udev",
      "F_verb": "create",
      "P-body": "Your system is probably using \"devtmpfs\". It is a pseudo filesystem that is mounted on /dev where the kernel will populate device nodes for devices it knows about. \"udev\" relies on \"devtmpfs\" since commit 220893b3cbdb (\"remove mknod() logic and rely on 'devtmpfs'\") which is 9 years old now. .  ",
      "P-tags": "embedded-linux linux busybox buildroot init",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V in NP without NP"
    },
    {
      "id": "so_7336598",
      "task": "bash find returning path with leading '.' how can I eliminate this character from return string?",
      "P-task": "bash find return path lead\nelimin charact return string",
      "F_verb": "find",
      "P-body": "You can copy all files in one invocation of \"cp\" like this: .  Or just add a slash to your original command: .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "au_746626",
      "task": "Is it safe to pass commands in startup applications",
      "P-task": "safe pass command startup applic",
      "F_verb": "pass",
      "P-body": "If you are absolutely sure the filename/path is correct, I don't see why you shouldn't do it. .  however .  Startup Applications creates a \".desktop\" file in \"~/.config/autostart\". You cannot use relative or variable paths like \"$HOME\" in a \".desktop\" file, the command simply won't run. You need to use absolute paths. .  ",
      "P-tags": "startup",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP in NP"
    },
    {
      "id": "so_47520122",
      "task": "bash - how do you sort within the lines of a text file",
      "P-task": "bash - sort within line text file",
      "F_verb": "sort",
      "P-body": "If you have \"gnu awk\" then it can be done in a single command using \"asort\" function: .  ",
      "P-tags": "text-fil sort bash",
      "source": "qa",
      "cate": "sort",
      "pat": "V within NP"
    },
    {
      "id": "so_20467216",
      "task": "Terminal giving \"Unknown option on the command line: -gf\" error with YouTube video streaming script using youtube-dl and mplayer",
      "P-task": "termin give unknown option command line : -gf error youtub video stream script use youtube-dl mplayer",
      "F_verb": "give",
      "P-body": "The problem is with the definition of \"first_string\". Single quotes prevent parameter expansion which will stop the \"youtube-dl\" command running in a subshell. .  Rather than constructing a string for the shell to execute, it would be a better idea to run the desired command with the correct parameters. Immediately after reading from the prompts: .  ",
      "P-tags": "youtub linux mplayer bash youtube-dl",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_7661491",
      "task": "cursor won't move when using move() or wmove() when using the curses library",
      "P-task": "cursor move use move wmove use curs librari",
      "F_verb": "move",
      "P-body": "I suspect that you are trying to print outside the bounds of the window. .  In particular, I would guess that here: .  ...\"num_rows_res\" is the number of rows in the \"results_scrn\" window - but that means that the valid row coordinates range from \"0\" to \"num_rows_res - 1\". .  If you try to \"move()\" or \"wmove()\" outside the window, the cursor will not actually move; a subsequent \"printw()\" or \"wprintw()\" will print at the previous cursor position. If you try to \"mvprintw()\" or \"mvwprintw()\", the whole call will fail at the point of trying to move the cursor, and so it won't print anything at all. .  Here's a complete demonstration (just printing to \"stdscr\" which has \"LINES\" rows and \"COLS\" columns): .  (In fact the functions do return a result; if you check it, you'll find that it's \"ERR\" in the cases that fail.) .  ",
      "P-tags": "c++ cursor curs unix",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V when S"
    },
    {
      "id": "so_3064998",
      "task": "Using Remove-Item with Credentials",
      "P-task": "use remove-item credenti",
      "F_verb": "remove",
      "P-body": "It's not clear to me if the files are local (you're running the script on the server) or remote (on another machine). If local try running the command using a background job and pass in the credentials to Start-Job: .  If they're remote, try using remoting: .  Note: This requires that you execute Enable-PSRemoting on the remote machine.  .  In general, putting raw passwords in your script isn't a great idea. You can store the password in an encrypted manner using DPAPI and later, only that user account can decrypt the password e.g.: .  ",
      "P-tags": "powershel powershell-2 0 cmdlet",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "so_12005526",
      "task": "Erase multiple packages using rpm or yum",
      "P-task": "eras multipl packag use rpm yum",
      "F_verb": "erase",
      "P-body": "Using \"yum\" List and remove the indicated packages and all their dependencies, but with a \"y/N\" confirmation: .  To bypass the confirmation, replace \"yum\" with \"yum -y\". .  Using \"rpm\" This section builds upon the answers by twalburg and Ricardo. .  List which RPMs are installed: .  List which RPMs which will be erased, without actually erasing them: .  On Amazon Linux, you may need to use \"grep '^D: ========== ---'\" instead. .  If the relevant RPMs are not listed by the command above, investigate errors: .  Erase these RPMs: .  Confirm the erasure: .  ",
      "P-tags": "rpm yum unix",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "au_1301060",
      "task": "Replace only last occurrence of a string using perl command",
      "P-task": "replac last occurr string use perl command",
      "F_verb": "replace",
      "P-body": " \"-n\" reads the input (file or stdin) line by line. Instead of printing each line, you push the lines into a buffer. When you encounter \"mela\", you make \"$i\" to point to its position in the buffer. When you encounter \"mela\" again, you print the first part of the buffer up to the previous \"mela\". At the end of the input, you print the buffer except for the last \"mela\" which is being pointed to by \"$i\". .  Not tested for edge cases (several \"mela\"s following each other, \"mela\" on the first/last line, etc.) .  ",
      "P-tags": "perl text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP of NP using NP"
    },
    {
      "id": "so_55309723",
      "task": "How to adjust this bash script to run telnet commands successfully while being in SSH?",
      "P-task": "adjust bash script run telnet command success ssh",
      "F_verb": "adjust",
      "P-body": "You misunderstand what \"END_SSH\" is. It's not a \"command\" - it's what's called \"Here-document\" in bash. .  Essentially the text between the \"<<END_SSH\" and the \"END_SSH\" is a \"here-document\" that is piped into stdin of \"telnet ${i} 9100\". So, the \"sleep 5\" commands are never actually executed and the input reaches EOF before the connection is even established. .  I don't know what exactly you are trying to accomplish, but I would guess that the following will work better. Oh, and what's with that weird \"IP=(x.x.x.x)\" declaration? Is that supposed to be an array? .  ",
      "P-tags": "bash ssh shell zebra-print telnet",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP S_INF while S"
    },
    {
      "id": "so_37431970",
      "task": "bash: daemonizing by forking process as a new child",
      "P-task": "bash : daemon fork process new child",
      "F_verb": "daemonize",
      "P-body": "I usually do something like this: .  The script effectively restarts itself in the background, while exiting the script started by user. .  To recognize the daemonization status, it uses an environment variable (the \"$_IS_DAEMON\" in the example above): if not set, assume started by user; if set, assume started as part of daemonization. .  To restart itself, the script simply invokes \"$0 \"$@\"\": the \"$0\" is the name of the script as was started by the user, and the \"\"$@\"\" is the arguments passed to the script, preserved with white-spaces and all (unlike the \"$*\"). I also typically call needed shell explicitly, as to avoid confusion between \"/bin/bash\" and \"/bin/sh\" which are on most *nix systems are not the same. .  ",
      "P-tags": "daemon linux bash",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V by S_ING as NP"
    },
    {
      "id": "so_36232276",
      "task": "Grep from file fails but grep with individual lines from the file works",
      "P-task": "grep file fail grep individu line file work",
      "F_verb": "grep",
      "P-body": "This can happen when the input file is in DOS format: each line will have a trailing CR character at the end, which will break the matching. .  One way to check if this is the case is using \"hexdump\", for example (just the first few lines): .    In the ASCII representation at the right, notice the \"..\" after each gene. These dots correspond to \"0d\" and \"0a\". The \"0d\" is the CR character. .  Without the CR character, the output should look like this: .    Just one \".\" after each gene, corresponding to \"0a\", and no \"0d\". .  Another way to see the DOS line endings in the \"vi\" editor. If you open the file with \"vi\", the status line would show \"[dos]\", or you could run the ex command \":set ff?\" to make it tell you the file format (the status line will say \"fileformat=dos\"). .  You can remove the CR characters on the fly like this: .  Or you could remove in \"vi\", by running the ex command \":set ff=unix\" and then save the file. There are other command line tools too that can remove the DOS line ending. .  Another possibility is that instead of a trailing CR character, you might have trailing whitespace. The output of \"hexdump -C\" should make that perfectly clear. After the trailing whitespace characters are removed, the \"grep -f\" should work as expected. .  ",
      "P-tags": "grep bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V with NP from NP"
    },
    {
      "id": "so_23353951",
      "task": "Can't install nuget package because of \"Failed to initialize the PowerShell host\"",
      "P-task": "instal nuget packag fail initi powershel host",
      "F_verb": "install",
      "P-body": "Setting an execution policy to RemoteSigned or Unrestricted should work. It must be changed under an administrator mode via a PowerShell console. Be aware that changes will be applied according to the bit version of the PowerShell console, so 32bit or 64 bit. So if you want to install a package in Visual Studio (32 bit version) which requires a specific policy you should change settings of the policy via PowerShell (x86). .  The command in PowerShell (as administrator) to set the policy to unrestricted (as noted by @Gabriel in the comments) is: .  Having set the policy to unrestricted, you will want to set the policy back to its original after the install is complete. .  ",
      "P-tags": "powershell-2 0 nuget visual-studio-2013 nuget-packag powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_41829119",
      "task": "Using Bash to run 2 python scripts at the same time",
      "P-task": "use bash run 2 python script time",
      "F_verb": "run",
      "P-body": "Looks like you have mixed between python and bash, you don't need the import in the bash script. .  make sure you adding execute permissions to the scripts .  and finally run the script ./your_file.sh .  ",
      "P-tags": "multitask bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP at NP"
    },
    {
      "id": "so_23806169",
      "task": "Bash get n characters before a specified character",
      "P-task": "bash get n charact specifi charact",
      "F_verb": "get",
      "P-body": "You can use this \"grep\": .  Which is the same as: .  or this if you want to make sure you get digits: .  Explanation The idea underlying is to print three characters before \"%\" is found. \"(?=%)\" indicates this and is called a \"look-ahead\". .  With \"-Po\" we indicate grep that it can use Perl regular expressions (\"-P\") and to just print the matches (\"-o\"). .  ",
      "P-tags": "string bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP before NP"
    },
    {
      "id": "ul_505453",
      "task": "Why does cron require MTA for logging?",
      "P-task": "cron requir mta log",
      "F_verb": "require",
      "P-body": "Consider that the traditional \"standard\" way of logging data is syslog, where the metadata included in the messages are the \"facility code\" and the priority level. The facility code can be used to separate log streams from different services so that they can be split into different log files, etc. even though the facility codes are somewhat limited in that they have fixed traditional meanings.) .  What syslog doesn't have, is a way to separate messages for or from different users, and that's something that \"cron\" needs on a traditional multi-user system. It's no use collecting the messages from all users' cron jobs to a common log file where only the system administrator can see them. On the other hand, email naturally provides for sending messages to different users, so it's a logical choice here. The alternative would be for cron to do the work manually, and to create logfiles to each users' home directory, but a traditional multi-user Unix system would be assumed to have a working MTA, so implementing it in cron would have been mostly a futile exercise. .  On modern systems, there might be alternative choices, of course. .  ",
      "P-tags": "log cron email network",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for S_ING"
    },
    {
      "id": "so_46283099",
      "task": "pip install : issue with the ssl certificate",
      "P-task": "pip instal : issu ssl certif",
      "F_verb": "install",
      "P-body": " Uncomment lines 209-212 in Python-3.6.2/Modules/Setup .  \"SSL=/usr/local/ssl _ssl _ssl.c \\ -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\ -L$(SSL)/lib -lssl -lcrypto\" .  Make sure libssl-dev is installed .  Go to your Python directory and do ./configure, make, and make install .  Install packages with the following command: \"pip install --trusted-host pypi.python.org packageName\" .   Hope that helped someone. :D .  ",
      "P-tags": "numpi linux pip python matplotlib",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_30242",
      "task": "How to make `find` output full absolute file names?",
      "P-task": "make find output full absolut file name",
      "F_verb": "make",
      "P-body": "You should call \"find\" with absolute directories' names, for example: .  ",
      "P-tags": "find",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_17046819",
      "task": "Scripts: copy only the part between two specified lines",
      "P-task": "script : copi part two specifi line",
      "F_verb": "specify",
      "P-body": "You can use \"awk\" for this: .  In general, .  so it is a matter of reading \"$file\", \"$first\" and \"$last\" in your script. .   Update: Based on doubleDown comment (thanks!), it can also be done like this: .  and more general: .  ",
      "P-tags": "awk vim bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_24954964",
      "task": "Command to copy code from one file to another",
      "P-task": "command copi code one file anoth",
      "F_verb": "copy",
      "P-body": "i think below should work .  \"fgrep -vxf file2 file1 >>file2\" .  or you can use .  Let's say we have a file. Call it \"version 1\". Then you copy it to another place, and make some edits. Call this \"version 2a\". Then copy it to yet another place, and make some different edits. Call this \"version 2b\". .  Now, the simple way to merge changes from 2a to 2b is to find the difference between 1 and 2a, and apply that to 2b. .  ",
      "P-tags": "linux command shell command-lin",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_25489591",
      "task": "Decreased output with PowerShell multithreading than with singlethread script",
      "P-task": "decreas output powershel multithread singlethread script",
      "F_verb": "decrease",
      "P-body": "It turns out that for some reason the Select-String cmdlet was having problems with the multithreading. I don't have enough of a developer background to be able to tell what is happening under the hood. However I did discover that by using the -quiet option in Select-String, which turns it into a boolean output, I was able to get the results I wanted. .  The first pattern match in each document gives a true value. When I get a true then I return the Path of the document to an array. When that is finished I run the pattern match against the paths that were output from the scriptblock. This is not quite as effective performance wise as I had hoped for but still a pretty dramatic improvement over singlethread. .  The other issue I ran into was the read/writes to disk by trying to output results to a document at each stage. I have changed that to arrays. While still memory intensive, it is much quicker. .  Here is the resulting code. Any additional tips on performance improvement are appreciated: .  ",
      "P-tags": "powershel multithread",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP with NP"
    },
    {
      "id": "so_15829185",
      "task": "Trouble with compiling JNI",
      "P-task": "troubl compil jni",
      "F_verb": "compile",
      "P-body": "you have to add the -shared linker option .  First create the object file: .  Then create the so .  ",
      "P-tags": "java-native-interfac linux java gcc c",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP"
    },
    {
      "id": "so_51939425",
      "task": "How can i make image with php 7.2 and pdo_informix in Docker?",
      "P-task": "make imag php 7 2 pdo_informix docker",
      "F_verb": "make",
      "P-body": "I tried your dockerfile script and found some errors. The docker build output did show traces on unpacking and compiling the PDO module: but was failing with an error during the PDO configure: .  I changed the script that builds the module so INFORMIXDIR is set before it runs the configure. .  Again it was failing somewhere else. Looking at the module build file, it expects the module in the following directories: .  but in the IBM docker image, that file is in: .  So I added a \"ln -s\" to the dockerfile to create the softlink. These are the two files I altered are: .  and .  With those changes I get the module compiled and installed when doing the \"docker build\" command .  PHP using with the apache config loads the module: .  And a simple connection, also appears to work without issues: .  You could just add the softlink creation and the export INFORMIXDIR in the 'install-informixpdo.sh' file. .  EDIT: .  ",
      "P-tags": "php ubuntu docker informix pecl",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_16206359",
      "task": "How to tell which module has requested memory with request_mem_region?",
      "P-task": "tell modul request memori request_mem_region",
      "F_verb": "tell",
      "P-body": "\"/proc/iomem\" is a file that shows the current map of the system's memory for each physical device.  .  ",
      "P-tags": "kernel-modul linux-kernel memory-manag",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V which S"
    },
    {
      "id": "so_30323808",
      "task": "How to get top 10 largest files along with size in MB using \"find\" command",
      "P-task": "get top 10 largest file along size mb use find command",
      "F_verb": "get",
      "P-body": "A quick and easy way to do this would be to pipe the output to awk: .  The first column is divided by 1024 and the \"1\" at the end is a shorthand for \"{print}\", so each line is included in the output. .  ",
      "P-tags": "unix shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP in NP using NP"
    },
    {
      "id": "so_655163",
      "task": "Convert a Static Library to a Shared Library?",
      "P-task": "convert static librari share librari",
      "F_verb": "convert",
      "P-body": "Does this (with appropriate -L's of course) .  Not do it? .  ",
      "P-tags": "linux c static-librari shared-librari",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_57858059",
      "task": "Copy-item exclude Sub-folders",
      "P-task": "copy-item exclud sub-fold",
      "F_verb": "exclude",
      "P-body": "I think this should do what you need: .  Hope that helps .  ",
      "P-tags": "powershel powershell-3 0",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_16100730",
      "task": "Usage of ssehexec task in Jenkins build doesn't stop its execution",
      "P-task": "usag ssehexec task jenkin build stop execut",
      "F_verb": "build",
      "P-body": "It looks like, the ssh executed job is not fully daemonized. Starting with \"nohup\" is not sufficient in many cases.  .  See the discussion that related to it (in a different context) .   The issue is that you are not closing your file descriptors when you push something into the background. The & is fine when you are in a shell, but is not enough when you want to disconnect and leave a process running, you need the process to disconnect from the shell. .   .... Fix to to correct the script. .   If someone writes a naive service script that does not properly detach from the terminal, I want to know the first time that that script is used in a deployment - the SCM changes will enable the breaking change to be quickly identified. .  It is wrong to hide the problem to enable incorrect code to be released to production - and I would not be happy if the first I knew about it was when a production system administrator complained. .   If this is the same problem, you need to daemonize the script .  ",
      "P-tags": "shell ant jenkin java",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_65715761",
      "task": "(xPathHelp) Scrapy not going to next page only scrapes first page",
      "P-task": "xpathhelp scrapi go next page scrape first page",
      "F_verb": "go",
      "P-body": "As mentioned in the comment from \"jwjhdev\", the content is coming from an API. You can see this in the network tab in the dev tools of your browser when reloading the page. The url of the API can be modified to give you more or less objects per page. If we increase to \"150\" in your case, we only get one page of data which means one request: https://production-gameflip.fingershock.com/api/v1/listing?limit=150&kind=item&category=GIFTCARD&platform=starbucks&status=onsale&sort=_score:desc,shipping_within_days:asc,created:desc&accept_currency=USD .  So instead of getting the data from the webpage and having to use xpaths, we can query the api and get structured data that is easier to manipulate. .  I've modified your spider code slightly below to show how we can get data from the API. We'll use the API url above as one of the \"start_urls\" However I noticed that the discount wasn't in the response so I believe that you will have to calculate it in the code. .  ",
      "P-tags": "scrapy-shel python-3 x xpath scrapi web-scrap",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V to NP"
    },
    {
      "id": "su_1116002",
      "task": "What are these warning / error messages which appear at the Arch Linux login prompt?",
      "P-task": "warn error messag appear arch linux login prompt",
      "F_verb": "prompt",
      "P-body": "Those messages are part of the log messages written during the boot process. You can see the complete log messages with the following command: .  ",
      "P-tags": "arch-linux linux consol",
      "source": "qa",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V"
    },
    {
      "id": "so_14265882",
      "task": "create a minimal symlink",
      "P-task": "creat minim symlink",
      "F_verb": "create",
      "P-body": "This will do it if you have Python 2.6 or newer on your system; you may need to modify the quoting if launching from another shell than bash. .  Inspired by this. .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_54573639",
      "task": "For loop to write file names",
      "P-task": "loop write file name",
      "F_verb": "write",
      "P-body": "Try this: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "au_223371",
      "task": "How does landscape calculate memory usage?",
      "P-task": "landscap calcul memori usag",
      "F_verb": "calculate",
      "P-body": "In Landscape \"landscape-sysinfo\" actually gets its data directly from \"/proc/meminfo\": .  The calculation of \"Memory Usage\" in this case would be: .  You can see these calculations in: .  gets its data directly from \"/proc/meminfo\": .  In free The \"free\" utility also gets its data directly from \"/proc/meminfo\": .  Mem  total: \"MemTotal\" used: \"MemTotal\" - \"MemFree\" free: \"MemFree\" buffers: \"Buffers\" cached: \"Cached\"  Buffers/cache  used: \"MemTotal\" - \"MemFree\" - \"Buffers\" - \"Cached\" free: \"MemFree\" + \"Buffers\" + \"Cached\"  Swap  total: \"SwapTotal\" used: \"SwapTotal\" - \"SwapFree\" free: \"SwapFree\"  Total  total: \"MemTotal\" + \"SwapTotal\" used: \"MemTotal\" - \"MemFree\" + \"SwapTotal\" - \"SwapFree\" free: \"MemFree\" + \"SwapFree\"  Corrected cached -- lzap .  ",
      "P-tags": "memori landscap server",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP"
    },
    {
      "id": "ul_402452",
      "task": "How to make hexdump not wait for 16 characters from stdin to display their hex values?",
      "P-task": "make hexdump wait 16 charact stdin display hex valu",
      "F_verb": "make",
      "P-body": "Try \"hexdump -v -e '/1 \"%02X\\n\"'\". That displays one hex byte per line, so the line output buffering won't stop the line from being displayed. .  Then you only have to type A and return to know the hex value for A. You still have to type return, because the shell buffers also does line buffering on the input. .  \"man ascii\" also works. :-) .  ",
      "P-tags": "termin linux hexdump",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP for NP from NP S_INF"
    },
    {
      "id": "su_1433579",
      "task": "How do I replace a string that contain white space and quotes?",
      "P-task": "replac string contain white space quot",
      "F_verb": "replace",
      "P-body": "you have to use escape char of the bash (if you using bash) to escape \"[]\" I give you an example with sed: .  output: .  file contain:  .  ",
      "P-tags": "linux sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP that S"
    },
    {
      "id": "ul_563630",
      "task": "install centos older kernel version",
      "P-task": "instal cento older kernel version",
      "F_verb": "install",
      "P-body": " ... want to downgrade to 3.10.0-957.27.2.el7.x86_64 .   \"kernel-3.10.0-957.27.2.el7.x86_64\" was saved / is stored at CERN : .  https://linuxsoft.cern.ch/cern/centos/7/updates/x86_64/Packages/kernel-3.10.0-957.27.2.el7.x86_64.rpm .  Ref. https://linuxsoft.cern.ch/cern/centos/7/updates/x86_64/repoview/kernel.html ... and ref. Google https://www.google.com/search?q=kernel-3.10.0-957.27.2.el7.x86_64 .  Download ... and install : .  ",
      "P-tags": "kernel cento yum repositori",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_10177916",
      "task": "openSSL: how to initialize keys for public key encryption?",
      "P-task": "openssl : initi key public key encrypt",
      "F_verb": "initialize",
      "P-body": "try this: .  I didnt test but should work. .  ",
      "P-tags": "linux public-key-encrypt ssl openssl c",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_505623",
      "task": "Is there a way to import a layout with multiple partitions into ramdisk?",
      "P-task": "way import layout multipl partit ramdisk",
      "F_verb": "import",
      "P-body": "You can use the \"sfdisk\" output to create the new partition table .  If you're really daring (or old-fashioned), you can also use \"dd\" .  ",
      "P-tags": "sfdisk linux partition-t ramdisk",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP with NP into NP"
    },
    {
      "id": "so_46777959",
      "task": "Use sed find ID in txt file and use ID to rename file",
      "P-task": "use sed find id txt file use id renam file",
      "F_verb": "use",
      "P-body": "Trying to minimize, so fit this into your logic. .  ",
      "P-tags": "maco shell bash wget sed",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_451387",
      "task": ".bash_profile taking in quotes into beginning of alias",
      "P-task": "bash_profil take quot begin alia",
      "F_verb": "take",
      "P-body": "Open your \".profile\" in a text editor, and replace all of the \"\u201c\"s with \"\"\"s, and I think you'll be a happier camper. .  ",
      "P-tags": "alia bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V in NP into NP of NP"
    },
    {
      "id": "so_36742508",
      "task": "How to use sed command to delete lines without backup file?",
      "P-task": "use sed command delet line without backup file",
      "F_verb": "use",
      "P-body": "It does not create a real backup file. \"sed\" is a stream editor. When applied to a file with option \"-i\" it will stream that file through the \"sed\" process, write the output to a new file (a temporary one), when everything is done, it will rename the new file to the original name. .  (There are options to create backup files also, but you didn't give them, so I won't mention that further.) .  In your case you have a very large file and don't want to create any copy, however temporary. For this you need to open the file for reading and writing at the same time, then your \"sed\" process can overwrite the original. After this, you will have to truncate the file at the end of the writing. .  To demonstrate how this can be done, we first perform a test case. .  Create a test file, containing lots of lines: .  Now, lets say we want to remove all lines containing the digit \"4\": .  This will open the file for reading and writing as STDOUT (1), and for reading as STDIN. The \"grep\" command will read all lines and will output only the lines not containing a \"4\" (option \"-v\"). .  This will effectively overwrite the beginning of the original file. .  You will not know how long the output is, so after the output the original contents of the file will appear: .  You can use the Unix tool \"truncate\" to shorten your file manually afterwards. In a real scenario you will have trouble finding the right spot for this, so it makes sense to count the number of bytes written (using \"wc\"): .  (Don't forget to recreate the original \"x\" for this test.) .  This will preform the step above and additionally print out the number of bytes written to the terminal, in this example case the output will be \"3653658\". Now use \"truncate\": .  Now you have the result you want. .  If you want to do this in a script, i. e. without interaction, you can use this: .  I cannot guarantee that this will work for files >2GB or >4GB on your machine; depending on your operating system (32bit?) and the versions of the installed tools you might run into largefile issues. I'd perform tests with large files first (>4GB as this is typically a limit for many things) and then cross your fingers and give it a try :) .  Some caveats you have to keep in mind: .   Of course, nobody is supposed to append log entries to that log file while the procedure is running. Also, any abort during the running of the process (power failure, signal caught, etc.) will leave the file in an undefined state. But re-running the command again after such a mishap will in most cases produce the correct output; some lines might be doubled, but not more than a single line should be corrupted then. The output must be smaller than the input, of course, otherwise the writing will overtake the reading, corrupting the whole result so that lines which should be there will be missing (or truncated at the start).  ",
      "P-tags": "linux vim file redhat sed",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF without NP"
    },
    {
      "id": "so_45220841",
      "task": "localhost socket not connected error with vm",
      "P-task": "localhost socket connect error vm",
      "F_verb": "connect",
      "P-body": "Just remove \"host_ip\", if you're using it with \"127.0.0.1\" you will need to specifically add the \"guest_ip\" of the VM too.  .  Anyway you provide this information when you're running multiple VM and wants to forward on the same port on the host (80 in your example), if its not your case, just remote the \"host_ip\" parameter. .  so all following will work .   if you're running a single VM, the easy solution .   if you're running multiple VM and want to forward on the same host port .    or .  ",
      "P-tags": "socket ubuntu vagrant apach vagrant-window",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP"
    },
    {
      "id": "so_39399848",
      "task": "BASH: Convert Unicode Hex to String",
      "P-task": "bash : convert unicod hex string",
      "F_verb": "convert",
      "P-body": "These are the same literals recognized by \"echo -e\" as representing Unicode characters.  .  ",
      "P-tags": "unicod utf-8 encod bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_359907",
      "task": "Escape unusual characters on filenames with `find . -printf \"%p \\n\"`",
      "P-task": "escap unusu charact filenam find\n-printf p n",
      "F_verb": "find",
      "P-body": "Usually you'd want to use \"find -exec\" to run a command for all file names, or \"find -print0\" to pipe the names to some command that can read entries separated by nul bytes (like \"xargs -0\"). .  If you really want to have quoted strings, Bash has a couple of options to do that:  .  This does require an extra invocation of the shell, but handles multiple file names with one exec. .   Regarding saving the permission bits (not ACL's though), you could do something like this (in GNU find): .  That would output entries with the permissions, a colon, the filename, and a nul byte, like: \"0644:name with spaces\\0\". It will not escape anything, but instead will print the file names as-is (unless the output goes to a terminal, in which case at least newlines will be mangled.) .  You can read the result with a Perl script: .  Or barely in Bash, see comments: .  As far as I tested, that works with newlines, quotes, spaces, and colons. Note that we need to use something other than whitespace as the separator, as setting \"IFS=\" \"\" would remove trailing spaces if any names contain them. .  ",
      "P-tags": "special-charact find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "su_411039",
      "task": "Find and hide file extension",
      "P-task": "find hide file extens",
      "F_verb": "find",
      "P-body": "what's the extra \" in the second sed command doing there? .  ",
      "P-tags": "sed unix bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_44770919",
      "task": "Fetch key value from string linux",
      "P-task": "fetch key valu string linux",
      "F_verb": "fetch",
      "P-body": "You can use \"awk\" like this: .  The key here is to use \",\" as the input record separator. Look how the input records appear to \"awk\" when using \"RS=,\": .  The \"ANSWER: N\" section is a separate record. Now we can simply filter the \"/ANSWER:/\" record by regex and print the second column of that row using \"print $2\". .   PS: A \"sed\" alternative would be: .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_36329989",
      "task": "PowerShell splatting merging to one hashtable",
      "P-task": "powershel splat merg one hashtabl",
      "F_verb": "merge",
      "P-body": "Typically, you'd write all or most of the events from a given script to a common log and source. If you're wanting to avoid code duplication you can set this once for all the events that will be written from the script using $PSDefaultParameters at the beginning of the script: .  Cloning it will create a new copy in the script, inheriting whatever defaults are already set in the parent or global scope without altering the hash table in that scope. The new $PSDefaultParameterValues will be disposed when the script finishes and the settings will revert back to whatever there are in the parent scope. .  If you need to write to some other log or source somewhere in the script you can do that by specifying the LogName and Source for that event, overriding the defaults. .  ",
      "P-tags": "powershel hashtabl",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "au_260174",
      "task": "How can I hide mounted volumes when I still want USB volumes to appear on the desktop?",
      "P-task": "hide mount volum still want usb volum appear desktop",
      "F_verb": "hide",
      "P-body": "Add them to your \"/etc/fstab\" and they will be hidden: .   They need not be mounted at all, \"noauto\" acheives that. Do not mount them under \"/home\" if you use other file managers. They will still appear if you mount them under \"/media\". Useful for eSata bay drives. This behavior is neither xfce nor thunar-specific, it affects all file-managers that employ gvfs.  ",
      "P-tags": "xfce xubuntu 12 10 thunar",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V NP when S"
    },
    {
      "id": "au_1142",
      "task": "How can I stop `gnome-screensaver` from resetting my keyboard to its default layout?",
      "P-task": "stop gnome-screensav reset keyboard default layout",
      "F_verb": "stop",
      "P-body": "At log in the \".Xmodmap\" (set up as user or globally) would read properly. However, when the monitor goes to sleep, and I log back in, it would be reset and keys would work as before \".Xmodmap\" was loaded. No setting worked around until at some point I realized that my keyboard is plugged in to the monitor and thus all sittings are lost when the monitor goes to sleep or is turned off. What helped was to plug in the keyboard directly to the computer tower. Now the initial reading of \".Xmodmap\" right after logging in is maintained independently of the monitor being on or off. .  ",
      "P-tags": "10 04 gnome keyboard-layout",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING to NP"
    },
    {
      "id": "su_776463",
      "task": "Linux permissions on a remote mount",
      "P-task": "linux permiss remot mount",
      "F_verb": "mount",
      "P-body": "This is, unfortunately, one of the most confusing things about file sharing on Unixes. And I'm bad at explaining confusing things. .  What you see in \"ls -l\" output (for example), is the remote user's ID translated from the perspective of the local system. .  When programs like \"ls\" use the standard functions to look up file information, the filesystem driver can only provide them with numeric user IDs, not textual names. So far, not too different from Windows.) To translate the UIDs to names, \"ls\" calls an entirely different OS component, the name service libraries, which have no knowledge about where that UID was obtained from, and therefore can only translate accounts that the operating system knows about, but cannot go back and ask the filesystem driver for help. This is where the difference comes in.) .  As an example, if the server has two files, one owned by root (UID 0), the other owned by Luke (UID 1000), \"ls\" will only know that they're owned by \"0\" and \"1000\", and will look for local accounts that have the same UIDs. \"0\" is always root, but \"1000\" may or may not be Luke. If the UID belongs to an account stored in LDAP or NIS or AD, and if the client OS is actually configured to look in LDAP for user accounts, it'll give the correct username. Otherwise it might actually lie, since local account UIDs (1000, 1001, ...) tend to correspond to different people on different computers. .  (There are ways that the filesystem driver could tell programs the full user name, in the form of \"extended attributes\". Unfortunately, despite various attempts there is no standard way of doing that, and programs like \"ls\" generally try to avoid filesystem-specific tricks. Even more unfortunately, not all network filesystem protocols can transfer the user names: CIFS aka SMB can, NFSv4 can, most other ones cannot.) .  But none of that really matters, since what you can do with the file is always determined by what the server knows, not by what the client sees. For example, if you use \"sshfs\", it logs into the server over SSH using your username (e.g. \"sshfs luke@fileserver\"), and the server won't let you do anything that you're not supposed to do. The same with CIFS, AFS, and so on. .  ",
      "P-tags": "linux permiss",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "au_1135947",
      "task": "Disable alert sounds in 19.04",
      "P-task": "disabl alert sound 19 04",
      "F_verb": "disable",
      "P-body": "Using dconf editor To disable alert sounds on Ubuntu 19.04 you could install \"dconf editor\", either from terminal or from activities/software center. From terminal .  Next, launch \"dconf editor\" and navigate to \"org/gnome/desktop/sound/event-sounds\" and flip the switch to \"off\" - alternatively, click on \"event-sounds\" and set custom value to \"False\" .   Using the terminal From terminal without installing \"dconf editor\" .  ",
      "P-tags": "system-set sound",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP in NP"
    },
    {
      "id": "so_22649755",
      "task": "Unable to install boost ubuntu 13.10",
      "P-task": "unabl instal boost ubuntu 13 10",
      "F_verb": "install",
      "P-body": "At first remove the broken packages with, .  Then upgrade/update the package base, .  Then, .  If the error persists still, then .  This should work probably fine. If still you get an error of broken packages, you have to check for the  .   /var/lib/dpkg/status .   file & check for the package which is broken, then remove it.  .  For more details, check out here. .  ",
      "P-tags": "c++ boost ubuntu",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    }
  ],
  "6": [
    {
      "id": "so_43474338",
      "task": "Script Issues with find -> tar/gzip",
      "P-task": "script issu find - tar gzip",
      "F_verb": "find",
      "P-body": "I've \"rephrased\" your original code a bit. I don't have an AIX machine to test anything, so DO NOT cut and paste this. Using this code, you should be able to address your issues. To wit: .   It make a record of what files it intends to operate on (\"$BFILES\"). This record can be used to check for empty tar files. This record can be used to see why your find is producing \"funny\" output. It wouldn't surprise me to find that xargs hit a space character. This record can be used to delete exactly the files archived.  As a child, I had a serious accident with xargs and have avoided it ever since. Maybe there is a safe version out there. .  ",
      "P-tags": "gzip tar find unix",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_26947586",
      "task": "installing rails with gem , error loading command : install undefined method 'invoke_with_build_args`",
      "P-task": "instal rail gem error load command : instal undefin method invoke_with_build_arg",
      "F_verb": "install",
      "P-body": "For who compile from source, they must checked dependencies. I think you need to install this library : .  Then you must recompiled ruby and everything worked. .  ",
      "P-tags": "debian-bas gem linux rubi ruby-on-rail",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_37954091",
      "task": "How To Remove Single Blank Line Only - Keep Multiple Blank Lines",
      "P-task": "remov singl blank line - keep multipl blank line",
      "F_verb": "remove",
      "P-body": "Using gnu-awk it is pretty simple: .   Using \"-v RS='\\n+'\" we constitute 1 or more line breaks as record separator Using \"length(RT)\" we check how many line breaks are after each record we print \"RT\" (original captured value) if \"length != 2\"  Alternative \"awk\" command: .  ",
      "P-tags": "awk linux regex bash sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_45280230",
      "task": "awk find the second record between two strings / awk search in file",
      "P-task": "awk find second record two string awk search file",
      "F_verb": "find",
      "P-body": "You can use this \"awk\": .  There are 3 condition and actions blocks: .   \"p && /^#end/{ p=0; print lines }\" - when \"p==1\" and we got a line starting with \"#end\". We reset flag \"p\" and print our buffer. \"p{ lines=(lines==\"\"?$0:lines ORS $0) }\" - when \"p==1\" we keep appending all lines into a buffer \"/^#start/{ p=1; lines=\"\" }\" - When we got a line starting with \"#start\", we set flag \"p\" and reset \"lines\" buffer.  ",
      "P-tags": "awk linux shell bash sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP between NP in NP"
    },
    {
      "id": "so_26957408",
      "task": "Start sync gateway service when system restarts",
      "P-task": "start sync gateway servic system restart",
      "F_verb": "start",
      "P-body": "Found the solution. The problem was Sync Gateway service was going to start before Couchbase Server was started. To solve this issue edit the couchbase_init.d file as following: .  \"$ nano /opt/couchbase/etc/couchbase_init.d\" .  look for \"start() {\" section and change it from this: .  to this: .  Then edit the sync-gateway.conf file .  and change this line:  .  to this: .  That will start the sync-gateway service after Couchbase server is started.  .  ",
      "P-tags": "servic startup ubuntu couchbase-sync-gateway",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP when S"
    },
    {
      "id": "ul_436004",
      "task": "Replace line in text file with user input at terminal",
      "P-task": "replac line text file user input termin",
      "F_verb": "replace",
      "P-body": "In \"awk\" the BEGIN block/rule is executing before the first input record is read and only once, for your script and awk to work you need to remove it since that's not required here, then \"awk\" will execute that block for every input/record reads. .  Also personally I use Ternary condition when I only have one action/else statement.  .  ",
      "P-tags": "awk user-input",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP at NP"
    },
    {
      "id": "ul_268359",
      "task": "Bash script calculating average of salaries",
      "P-task": "bash script calcul averag salari",
      "F_verb": "calculate",
      "P-body": "Using \"grep\", \"paste\" and \"bc\": .  \"bc\" is smart enough to discard \"salary\" from addition. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP of NP"
    },
    {
      "id": "so_17148688",
      "task": "How to display newline in ssh",
      "P-task": "display newlin ssh",
      "F_verb": "display",
      "P-body": "Try using the \"-e\" option, e.g., \"echo -e \"Test \\n for newline\"\". .  If your \"echo\" doesn't have a \"-e\" option, then I'd use \"printf\". It's widely available and it does not have nearly as many variations in it's implementations. .  ",
      "P-tags": "newlin linux sh shell",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_48319676",
      "task": "in which cases we need to clear the array in bash script",
      "P-task": "case need clear array bash script",
      "F_verb": "clear",
      "P-body": "Like variables arrays are defined in the shell process environment, unlike variables they can't be exported to be accessed in child processes. .  The first command you give .  initialises the array if files_in_array contained data, it will be cleared. .  As said in comments this is not a safe way to initialise array the way you did because after process expansion \"$(..)\" the result is split on spaces tabs and newlines and a filename may be split into elemnts, a safe way is to use glob file expansion because it occurs after and is not split. So just .  to get all sub path .  before bash 4.0 as said in comments globstar was introduced in bash 4.0, before this another way to do it with find -print0 .  ",
      "P-tags": "array linux bash",
      "source": "qa",
      "cate": "clear/clean/empty/eliminate/unpin/cleanup/unpublish",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_488069",
      "task": "Password history restrictions are written to in system-auth(-ac), but not password-auth(-ac). Why, when every other policy gets written to both?",
      "P-task": "password histori restrict written system-auth -ac password-auth -ac\neveri polici get written",
      "F_verb": "write",
      "P-body": "The \"password-auth\" and \"system-auth\" files are not directly used by any process or service. Instead, they are pulled into other PAM configuration files using the \"include\" directive. The only thing that really cares about password history on a default installation is the \"passwd\" command. It has its own PAM module, and it only pulls in \"system-auth\": .  Account lockouts are recommended for both because services like \"sshd\" pull in \"password-auth\" instead. On the RHEL 7 system I'm looking at right now, \"system-auth\" is mostly pulled into PAM files for things the user would interact with directly (login, password changes, \"su\" and \"sudo\", etc.), while \"password-auth\" is pulled in by running daemons like \"sshd\" and \"crond\". .  You can add the password history setting to \"pam_unix.so\" in \"password-auth\" for consistency, if you want to. It won't harm anything, but neither will it do anything useful. .  ",
      "P-tags": "linux secur pam",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP"
    },
    {
      "id": "ul_189284",
      "task": "AWK get first line",
      "P-task": "awk get first line",
      "F_verb": "get",
      "P-body": "Just exclude the first line: .  ",
      "P-tags": "awk",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_305671",
      "task": "Why the system don't swap?",
      "P-task": "system swap",
      "F_verb": "swap",
      "P-body": "\"echo 100 > /proc/sys/vm/swappiness\" .  https://en.wikipedia.org/wiki/Swappiness .  ",
      "P-tags": "linux ram arm swap",
      "source": "qa",
      "cate": "flip/rotate/permute/swap/transpose/reverse/shuffle",
      "pat": "V"
    },
    {
      "id": "ul_28016",
      "task": "Ignore or catch division by zero",
      "P-task": "ignor catch divis zero",
      "F_verb": "ignore",
      "P-body": "Bash doesn't have a way to trap divisions by 0, nor do ash, ksh93, pdksh or zsh. The only ways to trap divisions by 0 are to detect them before they happen (check every denominator before performing the division) or to do them in a subshell. .  If you do the arithmetic in a subshell, you can use the subshell's exit status to know whether an error (division by 0 or other) happened. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP by NP"
    },
    {
      "id": "ul_495992",
      "task": "Allow certain risky behaviour of a single program in a safe way in SELinux",
      "P-task": "allow certain riski behaviour singl program safe way selinux",
      "F_verb": "allow",
      "P-body": "\"audit2allow\" likely generates a rule to allow \"execheap\" for \"container_t\" type process. You can always first generate the module and inspect it, before you load it. .  A possible problem is, that now any process with \"container_t\" type is now allowed the same operation. To avoid this, you possibly need to create your own custom type (using \"container_t\" as template) and only allow \"execheap\" for this special type. .  This blog post by Dan Walsh explains how to write such custom policy. You can also combine this with \"audit2allow\" to generate the actual rules. The essential steps are: .   Create a basic container policy, for example \"container_execheap\": .  \"virt_sandbox_domain_template\" macro creates the new type \"container_execheap_t\" and creates necessary rules for docker operation that the new type can be used as container domain. .  Compile and load the policy module (necessary development files, including the makefile, should be provided by \"selinux-policy-devel\" package): .  The new type can be configured to be a permissive domain: .  For permissive domains, AVC denials are logged but rules are not enforced. This way it is easy to generate the missing rules later using \"audit2allow\". .  Run your container in this new context, something like \"docker run ... --security-opt label:type:container_execheap_t ...\" .  Generate expected errors. Then run \"audit2allow\" to generate rules allowing those operations for \"container_execheap_t\". You can update the same module \".te\" file (remember to bump up version number) with the new rules. Compile and install the updated module. .  When no more errors generated, put the custom container type back into enforcing mode \"semanage -d container_execheap\". .   ",
      "P-tags": "selinux docker",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP of NP in NP in NP"
    },
    {
      "id": "au_786375",
      "task": "Ubuntu is not sending SIGTERM on shutdown",
      "P-task": "ubuntu send sigterm shutdown",
      "F_verb": "send",
      "P-body": "Unfortunately, it does not quite work this way. Many of those programs that do actually have a signal handler, don't block the signal to show a confirmation dialog. Signal handling is often minimal or missing. .  You can easily try it without having to shutdown. Just send SIGTERM to your running Firefox or LibreOffice process: .  Normally, Firefox might ask if you really want to close it. Also, it usually takes a while to close, especially when it's been running for a long time and using more than 1 GB of RAM - it often takes like a minute for the process to terminate after the its last window has been closed. None of this happens when you send SIGTERM, the process is just terminated instantly. .  However, some desktop environments close all open windows before shutting down. Unlike SIGTERM, closing a window programmatically is like clicking on the X button of that window, or Alt + F4. This is also what the script in the other answer does - it uses wmctrl to close all open windows gracefully. .  When a window is closed, the program is not in a rush and it can close everything within that window, for example open tabs, and it can also show a dialog window if there's unsaved work. Once all open windows of an application have been closed, the process usually terminates shortly after that. .  So it depends on your desktop environment (assuming you use your desktop environment to shutdown and not \"sudo poweroff\"). For example, KDE should wait for open windows to be closed before shutting down, while MATE doesn't. .  Bottom line: Close all open windows manually before shutting down. Or use a desktop environment that waits for all windows to be closed. .  ",
      "P-tags": "shutdown",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_362839",
      "task": "Use AWK to split substring by last n characters in to a new column",
      "P-task": "use awk split substr last n charact new column",
      "F_verb": "split",
      "P-body": "With a POSIX-compliant \"awk\": .  With a POSIX-compliant \"sed\": .  Those modify the lines only if the second field is at least 6 characters long (note that it will happily change \"111,123456,333\" to \"111,,123456,333\" leaving the second field empty). .  ",
      "P-tags": "awk text-process csv-simpl perl sed",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP by NP to NP"
    },
    {
      "id": "au_1273098",
      "task": "Debugging installation of RTL8812BU wifi dongel",
      "P-task": "debug instal rtl8812bu wifi dongel",
      "F_verb": "debug",
      "P-body": "Do this in terminal .  Reboot .  ",
      "P-tags": "wireless network driver usb realtek-wireless",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "so_16360171",
      "task": "Reading program return value in shell using python",
      "P-task": "read program return valu shell use python",
      "F_verb": "read",
      "P-body": "\"exit\" is a shell routine, not a real program. You get an error because the call can not find a program named \"exit\". If you don't set the \"shell\"\u00a0argument to \"True\"\u00a0this makes no sense to executing it. .  To answer your second question, yes you will get an non-zero returning value. Try listing a directory in which you don't have read rights. .  ",
      "P-tags": "python return-valu bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "au_452702",
      "task": "File not created by a python script that runs on boot",
      "P-task": "file creat python script run boot",
      "F_verb": "create",
      "P-body": "Scripts in \"/etc/rc.local\" run in \"/\" afaik. You should change the working directory or provide an absolute path in your python script. .  ",
      "P-tags": "python file",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V by NP that S"
    },
    {
      "id": "su_684652",
      "task": "iptables gives me the error \"can't initialize iptables NAT\"",
      "P-task": "iptabl give error initi iptabl nat",
      "F_verb": "give",
      "P-body": "Make sure you use lowercase for \"nat\". Case matters in the Linux world, so \"NAT\" and \"nat\" are two different tables. .  ",
      "P-tags": "nat linux iptabl",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "ul_65746",
      "task": "Automatically run kpartx during boot",
      "P-task": "automat run kpartx boot",
      "F_verb": "run",
      "P-body": "Solution to the original problem Install \"kpartx\": .  \"sudo aptitude install kpartx\" .  Change these lines in \"/lib/udev/rules.d/60-kpartx.rules\": .  to this: .  Update the initramfs: .  Restart and the partitions should have been detected properly. .  Alternative solution Use mdadm instead of dmraid. Set up the RAID array using the Intel configuration utility (Ctrl+I during boot), and Debian Installer 7 RC1 will detect and activate it automatically. .  ",
      "P-tags": "raid fsck debian fstab gpt",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP during NP"
    },
    {
      "id": "so_36087525",
      "task": "How can i check if $varA contains $varB?",
      "P-task": "check vara contain varb",
      "F_verb": "check",
      "P-body": " Is there a better way to check a if \"$varA\" contains \"$varB\": .   This should be: .  However if \"$varA\" is a filename then use \"grep\": .  Note use of \"-F\" to treat value of \"varB\" as fixed string and use of quotes. .  ",
      "P-tags": "grep if-stat string shell bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_49542079",
      "task": "How to split fixed position file based on conditions in Unix",
      "P-task": "split fix posit file base condit unix",
      "F_verb": "split",
      "P-body": "Using awk Try: .  Example Consider, for example, this input file: .  We run our command: .  When the command finishes, there will two files in the current directory: .  And: .  How it works The condition, \"substr($0, 11, 3)==\"003\"\", checks to see if, on the current line, the three characters starting at position 11 are \"003\". If they are then the current line is printed to \"a.txt\":  .  If they aren't, then the line is printed to \"b.txt\": .  Using grep Using sed ",
      "P-tags": "split unix shell conditional-stat",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP on NP in NP"
    },
    {
      "id": "so_3005457",
      "task": "Combining echo and cat on Unix",
      "P-task": "combin echo cat unix",
      "F_verb": "combine",
      "P-body": "This should work: .  ",
      "P-tags": "shell pipe unix",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP on NP"
    },
    {
      "id": "so_20254328",
      "task": "Executing a command (only) when prior jobs are finished in Bash",
      "P-task": "execut command prior job finish bash",
      "F_verb": "execute",
      "P-body": "You can use \"wait\" without arguments to wait for all previous jobs to complete: .  ",
      "P-tags": "job parallel-process bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "so_8271899",
      "task": "How do I write all of this in assembly",
      "P-task": "write assembl",
      "F_verb": "write",
      "P-body": "You can ask gcc its idea of how to write your code in assembly: \"gcc -S foo.c\" or \"gcc -Wa,-alh=foo.s -c foo.c\". You may want to improve on the results, of course. You will need to do a little extra: use \"%0\" for the parameter that you pass for the assembly chunk, and declare the registers that you've clobbered. Look up Assembler Instructions with C Expression Operands in the GCC manual if you aren't familiar. Here's how this might look like (warning, typed directly into the browser, and don't really know x86 assembly syntax). .  A fancier method would involve figuring out how many bytes each \"movq\"-\"movq\"-\"jmp\" block takes (note: I haven't checked, I use 8) and making a computed jump into it; something like .  ",
      "P-tags": "linux assembl x86 gcc c",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_30461416",
      "task": "Java compilation error : /bin/ld:cannot find -ljvm",
      "P-task": "java compil error : bin ld : find -ljvm",
      "F_verb": "find",
      "P-body": "The jvm shared library will be found in a path under \"$JDK_HOME\", however, you are not adding that path to your \"LDPATH\" make variable. You need to add \"-L${JDK_HOME}/lib\" to \"LDPATH\" (or wherever \"libjvm.so\" is found). .  ",
      "P-tags": "java-native-interfac linux java fuse gcc",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_56078204",
      "task": "getting database table to show in dataGridView in powershell",
      "P-task": "get databas tabl show datagridview powershel",
      "F_verb": "get",
      "P-body": "Here is an example how you could do it: .  In your case you should do something like that: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF in NP in NP"
    },
    {
      "id": "so_50947939",
      "task": "I have to replace a string present between two strings using 'sed' command in unix",
      "P-task": "replac string present two string use sed command unix",
      "F_verb": "replace",
      "P-body": " If you just want to replace \"Mango\" and you know it is \"Mango\", then you just do .   If you want to replace \"Mango<freetext>\" where the freetext does not contain a single quote \"'\", then you do : .  we added the extra quote before \"Mango\" to make sure we exclude strings such as \"'SquashedMangoJuice'\" .  If you want to replace the string between the words \"Apple\" and \"Orange\", then you have to do it a bit different : .  or using back-references .    The reason why your original command is failing is that \"sed\" is greedy. What I mean is that the combination \".*'\" will pick everything until the last quote. That is, it will represent \"Mango'Orange'\". The culprit is the last quote after \"Orange\". Above, we fixed this by replacing your \".\" with \"[^']\". This means all characters except the quote \"'\". .  ",
      "P-tags": "sed unix",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP between NP using NP in NP"
    },
    {
      "id": "su_379718",
      "task": "Compressing a file in place - does \"gzip -c file | dd of=file\" really work?",
      "P-task": "compress file place - gzip -c file dd file realli work",
      "F_verb": "compress",
      "P-body": "Experiment shows that this does not work. .  I created a 2-megabyte file from \"/dev/urandom\", then tried the above command on it. Here are the results: .  Obviously a 2-megabyte random file won't compress to 25 bytes, and in fact running \"gunzip\" on the compressed file yields an empty file. .  I got similar results for a much smaller random file (100 bytes). .  So what happened? .  In this case, the \"dd\" command truncated \"file\" to zero bytes before starting to write to it; \"gzip\" started reading from the newly empty file and produced 25 bytes of output, which \"dd\" then appended to the empty \"file\". An empty file \"compresses\" to a non-zero size; it's theoretically impossible for any compressor to make all input smaller). .  Other results may be possible, depending on the timing of the \"gzip\", \"dd\", and shell processes, all of which are running in parallel. .  There's a race condition because one process, \"gzip\", reads from \"file\", while another parallel process, the shell, writes to it. .  It should be possible to implement an in-place file compressor that reads and writes to the same file, using whatever internal buffering is necessary to avoid clobbering data. But I've never heard of anyone actually implementing that, probably because it usually isn't necessary and because if the compressor fails partway through, the file will be permanently corrupted. .  ",
      "P-tags": "dd linux compress",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_173810",
      "task": "NGINX + PHP-FPM Permission denied",
      "P-task": "nginx + php-fpm permiss deni",
      "F_verb": "deny",
      "P-body": "Check the permissions of directories \"/var/www/vhosts/barelef_art/barelef-art.kiev.ua/\" & \"/var/www/vhosts/barelef_art/\". .  When getting forbidden errors in either Nginx or Apache it is always worth working your way back up the tree of directories to ensure the web server can access at each level. .  ",
      "P-tags": "nginx php",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "ul_137913",
      "task": "How does make continue compilation?",
      "P-task": "make continu compil",
      "F_verb": "make",
      "P-body": "In simple terms, you can think of \"make\" as having a (possibly large) number of steps, where each step takes a number of files as input and creates one file as output. .  A step might be \"compile \"file.c\" to \"file.o\"\" or \"use \"ld\" to link \"main.o\" and \"file.o\" into \"program\"\". If you interrupt \"make\" with CtrlC, then the currently executing step will be terminated which will (or should) remove the output file it was working on. There are usually not any \"half-ready binaries\" left behind. .  When you restart \"make\", it will look at the timestamps of all the input and output files and rerun the steps where: .   an input file has a newer timestamp than the output file the output file does not exist  This generally means that if a step takes a long time to run (it's rare on modern computers, but the \"ld\" step for large programs could easily take many minutes when \"make\" was designed), then stopping and restarting \"make\" will start that step over from the beginning. .  The reality of your average \"Makefile\" is considerably more complicated than the above description, but the fundamentals are the same.  .  ",
      "P-tags": "compil interrupt linux compil make",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_64022855",
      "task": "How do you install an extension into the VS Code Server that's the remote end of Remote-SSH when there is no Internet connection?",
      "P-task": "instal extens vs code server remot end remote-ssh internet connect",
      "F_verb": "install",
      "P-body": "You can download the extension from the Marketplace and upload the extension\"vsix\" file to the remote. .  In the remote VSC use the \"Install from VSIX...\" command on the Extension bar top menu. .  ",
      "P-tags": "linux vscode-remot visual-studio-cod",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP when S"
    },
    {
      "id": "so_63738856",
      "task": "Converting IPAddress array to HTML",
      "P-task": "convert ipaddress array html",
      "F_verb": "convert",
      "P-body": "Unless I'm missing something you shouldn't even be getting that original output you're showing us. Not with how you select your property. .  However, I believe the following does what you are asking. .  Or are you asking on how to exclude IPv6 in your output as well? .  Edited to add a few different variants. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1297425",
      "task": "Server Can't Find: SERVFAIL & Bind9 DNS Server Setup",
      "P-task": "server find : servfail bind9 dn server setup",
      "F_verb": "find",
      "P-body": "So go by these steps it worked for me and I'm sure it will work for you. .  1.Set your hostname equal to one of your ServerNames like: .   server.example.com .    2.configure the interfaces in /etc/network/ like: .  don't forget to restart 'networking'. .  now let's config the bind. You don't need to edit all of the dbs just do it like bellow: .  open /etc/bind/named.conf.local add this at the end of the file: .  now in /etc/bind .  now edit forward.example.com .  now in the same directory \"cp forward.example.com reverse.example.com\" .  now edit reverse zone like bellow: .  forward and reverse zones are configured now. naw follow the command: .  the outputs should show that the zones are loaded and there is no error. .  now restart bind. if there was an error just use journalctl -xe and see the details more times it just a typo and mistakes like that. .  now do these: .  go to /etc/network/interfaces again add this in the end of file: .  after that restart networking with \"sudo systemctl restart networking\" .  nano this file now: /etc/resolv.conf .  add these at the end of the file: .  restart the networking restart the NetworkManager .  now ping/nslookup/dig ns.example.com or server.example.com .  NOW It's WORKING .  ",
      "P-tags": "bind dn server 16 04",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_51356166",
      "task": "want to copy from an txt file to another",
      "P-task": "want copi txt file anoth",
      "F_verb": "copy",
      "P-body": "You can do it by using awk. .   \"-F ';'\" sets the field delimiter to \";\" \"$5\" and \"$8\" are simply the fields you want to print. Add a newline (\"\\n\") between them.  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V from NP to NP"
    },
    {
      "id": "au_735835",
      "task": "Executing bash script via python gives syntax error",
      "P-task": "execut bash script via python give syntax error",
      "F_verb": "execute",
      "P-body": "Your script is in \"csh\" syntax, however \"os.system\" calls the default shell \"/bin/sh\". If you want your script to be properly interpreted, use .  ",
      "P-tags": "script python command-lin",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP via NP"
    },
    {
      "id": "ul_84437",
      "task": "How do I make my laptop sleep when it reaches some low battery threshold?",
      "P-task": "make laptop sleep reach low batteri threshold",
      "F_verb": "make",
      "P-body": "Here's a small script that checks for the battery level and calls a custom command, here \"pm-hibernate\", in case the battery level is below a certain threshold. .  It's a very simple script, but I think you get the idea and can easily adapt it to your needs. The path to the battery level might be different on your system. A little more portable would probably be to use something like \"acpi | cut -f2 -d,\" to obtain the battery level. This script can be scheduled by cron to run every minute. Edit your crontab with \"crontab -e\" and add the script: .  Another solution would be to install a desktop environment like Gnome or Xfce (and change your window manager to i3). Both mentioned destop environments feature power management daemons which take care of powering off the computer. But I assume you deliberately don't use them and are seeking for a more minimalistic solution. .  ",
      "P-tags": "suspend power-manag ubuntu batteri",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP when S"
    },
    {
      "id": "so_32037905",
      "task": "How to import java files from folders in linux?",
      "P-task": "import java file folder linux",
      "F_verb": "import",
      "P-body": "You are getting \"package Filter does not exist\" error because the \"Filter.*\" classes are not present in the class path. .  First compile the java files in side the folder \"Filter\" then compile the \"PlutoMake.java\" using \"javac -cp \"java-json.jar;.\" PlutoMake.java\"  .  I'll advice to use some build tool like Maven or Gradle or Ant .  ",
      "P-tags": "linux eclips java",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_16408",
      "task": "Stack applet was not starting automatically",
      "P-task": "stack applet start automat",
      "F_verb": "start",
      "P-body": "Open up \"~/.config/autostart/stackapplet.desktop\", verify that it is the same as this: .  The problem is likely with the \"Exec\" line, if you used to be using an older version that had a different \"Exec\" command. .  Even if they are the same, try removing that file. Then un-check and re-check the \"Start Stackapplet during login\" checkbox. .  UPDATE: Looking at your \"~/.xsession-errors\", StackApplet needs internet access to work. If you aren't connected to the internet right away on login, you'll need to delay StackApplet from starting before you have connected to the internet. Paste the following in a file called \".stackapplet-start.sh\" in your home folder:  .  Make that file executable: .  Now open System -> Preferences -> Startup Applications, edit the \"StackApplet\" entry and change the \"Command:\" to \"/home/<USERNAME>/.stackapplet-start.sh\". .  ",
      "P-tags": "stackapplet autostart startup applet",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V"
    },
    {
      "id": "so_50013492",
      "task": "Command not found when running Bash script, but works when running command directly",
      "P-task": "command found run bash script work run command directli",
      "F_verb": "find",
      "P-body": "By default, shell functions are only available in the shell they were defined in; they're not inherited by subprocesses. Your .bash_profile is only run by the login shell, not shells that run as subprocesses (e.g. to run scripts). .   Option 1: In bash, you can run \"export -f letsencrypt_webfaction\" in the defining shell (i.e. in your .bash_profile), and it'll be inherited by subprocesses (provided they're also running bash). .  Option 2: You can define the function in your .bashrc instead of .bash_profile, and since you run .bashrc from .bash_profile it'll get defined in all your bash shells. .  Option 3: Just use the full command in the script. This would be my preference, since it makes the script more independent. Having a script depend on a shell function that's defined in a completely different place is fragile (as you're experiencing) and just a bit weird. .   While I'm at it, here are some general scripting recommendations: .   In most contexts, you should put double-quotes around variable references (and strings that contain variable references) to avoid weird effects from word splitting and wildcard expansion. The right side of an assignment is one place it's ok to leave them off (e.g. \"PATH=$PATH:$HOME/bin\" and \"PATH=\"$PATH:$HOME/bin\"\" are both ok), but I tend to recommend using quotes everywhere as it's hard to keep track of where it's safe to leave them off and where it's dangerous. For the same reason, you should almost always use \"\"$@\"\" instead of \"$*\" (as in the \"letsencrypt_webfaction\" function). .  shellcheck.net is really good at spotting errors like this, so I recommend running your shell scripts through it and acting on its suggestions. .  Using the \"function\" keyword to define a function is nonstandard; the standard syntax is to use \"()\" after the function name, like this: .   The function I just gave still may not work right, since it (re)defines \"GEM_HOME\" after using it. The entire line gets parsed (and pre-existing variable definitions expanded), then the variables defined as prefixes to the command get included in the environment of the command. This means that the ruby script gets the updated value of \"GEM_HOME\", but the updated values of \"PATH\" and \"RUBYLIB\" are based on whatever value \"GEM_HOME\" had when the function was run. I'm pretty sure this is not what you intended. .  In the restart apache script, you use a relative path to the \"restart\" command. This will be evaluated relative to the working directory of the process that runs the script, not relative to the script's location. This could be anywhere. .   ",
      "P-tags": "linux apach lets-encrypt bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V when S"
    },
    {
      "id": "au_1184794",
      "task": "apt-file no longer finds or lists most of the content since Ubuntu 19.10 eoan",
      "P-task": "apt-fil longer find list content sinc ubuntu 19 10 eoan",
      "F_verb": "find",
      "P-body": "This was an upstream packaging bug and has been fixed within the last hours. A new \"apt-file update\" and subsequent \"apt-file search /bin/bash\" now delivers the expected results even under Ubuntu eoan. .  ",
      "P-tags": "apt package-manag apt-fil 19 10",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP since NP"
    },
    {
      "id": "au_491518",
      "task": "Ubuntu 14.04 LTS no sound after apt-get upgrade",
      "P-task": "ubuntu 14 04 lt sound apt-get upgrad",
      "F_verb": "get",
      "P-body": "Soundcard driver packages could not have been properly installed. Reinstall them: .  ",
      "P-tags": "sound",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_158963",
      "task": "Launcher shows drives even when they aren't mounted",
      "P-task": "launcher show drive even mount",
      "F_verb": "mount",
      "P-body": "Following command (with force option) could work as well: \"umount -f /media/Snoopy\" You could check what's exactly mounted by: \"mount\" command. .  Try as well: \"unity --reset --verbose\" .  ",
      "P-tags": "mount 12 04 nautilu uniti",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "so_57970542",
      "task": "Get Azure VM size inside on a windows machine",
      "P-task": "get azur vm size insid window machin",
      "F_verb": "get",
      "P-body": "You can use the metada to get the VM information inside the VM like this: .  For more details, see Azure Instance Metadata service. You can also put the output as a variable, then get the special properties. For example: .  Or get the property directly through the request like this: .  ",
      "P-tags": "azur powershel azure-powershel window",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "su_1393001",
      "task": "Deleting user from sudoer",
      "P-task": "delet user sudoer",
      "F_verb": "delete",
      "P-body": "It may not as straight forward as running a command. There is no sudoerlist - the sudoers file is a list of instructions which can provide users - or groups various permissions. You can edit this file using visudo if you are good with vi. If not, you arguably should not be messing with it, but can probably use nano /etc/sudoers (as root). The sudoers file is usually quite well documented. .  Depending on your OS though, you may not actually need to do this. Most distros have a group, and elevated permissions are granted by simply modifying who has access to what group. You may want to look through the sudoers file to see what group/groups there are - In my ubuntu 16.04 there is an \"admin\" group and a \"sudo\" group. \"wheel\" and \"admin\" groups are other common ones. .  As the user is probably already a member of a group with sudo access, typing (as root) grep \"username\" /etc/group\" will show a list of groups the user is a member of. To remove the user you can (as root) edit them out of /etc/group or use a command like  .  or  .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_39609628",
      "task": "Convert signed int number to unsigned whith shell script",
      "P-task": "convert sign int number unsign whith shell script",
      "F_verb": "convert",
      "P-body": "this can help you;  .  ",
      "P-tags": "awk sh shell bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "ul_146934",
      "task": "Is it possible to change what tty a terminal emulator is connected to?",
      "P-task": "possibl chang tti termin emul connect",
      "F_verb": "change",
      "P-body": "Yes and no. You can redirect its child's in/out streams - probably your shell - but \"xterm\" will have little involvement there. \"xterm\" owns the master side of that pty - it does an open on \"/dev/ptmx\" and in the process creates \"/dev/pts/3\". But it gives it away - your shell owns that pty now, as \"xterm\" makes it the session leader. All \"xterm\" does is take the input from the keyboard and pass it to the shell and take output from the shell and pass it to the screen. In this way \"xterm\" performs multiplexing functions - subdividing and redirecting input and output between pseudoterminals, but not much else is relevant here once the pty is up. .  The virtual consoles, though, are another matter. If your user account is assigned the proper filesystem permissions, you can read them and write to them from other processes - or other terminals - in simpler ways - as in, you needn't pass input/output through a master-side to talk a process running on the slave-side. You can easily do these things in almost every way that matters except where \"login\" is concerned. It will kill any listener on that device and will only accept keyboard input. That is its job. .  Still, I suspect you're looking for some authentication solution. You can get virtually the same level of security with:  .  That will securely prompt you for authentication then log you into the machine and exec some process in a new pseudoterminal - you can do that from \"xterm\", say.  .  ",
      "P-tags": "pti termin consol",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V what S"
    },
    {
      "id": "au_1226845",
      "task": "Cannot install wine on ubuntu 19.10/20.04",
      "P-task": "instal wine ubuntu 19 10 20 04",
      "F_verb": "install",
      "P-body": "As you are using modern Ubuntu 20.04 LTS - I would recommend to remove WineHQ repository and install Wine 5.0.3 from universe: .  Below I summarize steps done in the comments:  .  By last command we have determined that there are several locally (previously from some repository) installed packages. We need to replace them with versions from the official repositories: .  And finally install Wine: .  ",
      "P-tags": "depend wine",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_69284530",
      "task": "Node-container is unable to connect to MariaDB-container on Ubuntu 21.04",
      "P-task": "node-contain unabl connect mariadb-contain ubuntu 21 04",
      "F_verb": "connect",
      "P-body": "The solution was to uninstall (\"sudo apt remove docker-compose\") and follow the official Docker documentation. .  After doing that my Node-container can finally resolve the hostname and connect to it. .  ",
      "P-tags": "docker-compos mariadb ubuntu docker digital-ocean",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP on NP"
    },
    {
      "id": "so_35022302",
      "task": "Externally called OpenMP program runs with only one thread if called by another OpenMP program",
      "P-task": "extern call openmp program run one thread call anoth openmp program",
      "F_verb": "call",
      "P-body": "Initialisation of most OpenMP runtime libraries happens in their constructors, which get executed very early in the process lifetime. Hence, it is not possible to prevent the binding effect of \"OMP_PROC_BIND\" on program A, but one could counteract it before spawning program B. There are multiple ways, but two come immediately to my mind: .  1) Use \"taskset\" in the call to \"std::system()\" to override the CPU affinity mask of the child process: .  The \"-c 0-63\" parameter produces a CPU affinity mask with 64 bits set, which should be good for most current generation multicore systems (unless the program runs on Intel Xeon Phi or on some exotic hardware like our Bull Coherent Switch coupled fat nodes). Obviously, it won't work if \"taskset\" is not installed on the system (being part of \"util-linux\", it should be installed by default on many systems). .  2) Use \"sched_setaffinity(2)\" or \"pthread_setaffinity_np(3)\" to reset the CPU affinity mask of A before calling \"std::system()\". Look here for inspiration. .  3) If you can afford external dependencies, the hwloc library has a very nice API that can be used to obtain and manipulate the CPU affinity. It is also cross-platform and will also work on Windows. .  Option 3 is the most clean one as you don't have to hardcode in advance a wide enough mask in the parameter to \"taskset\" or in the CPU set passed to the scheduler functions. .  ",
      "P-tags": "linux process c++ c openmp",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V by NP"
    },
    {
      "id": "au_883404",
      "task": "pip install is not installing executables in /usr/local/bin",
      "P-task": "pip instal instal execut usr local bin",
      "F_verb": "install",
      "P-body": "I had to remove the \"pip\" package that was installed by \"apt\". .  And then install pip again according to instructions on their website - https://pip.pypa.io/en/stable/installing/. .  Looks like \"pip\" from Ubuntu's default repository is not same as one distributed by pypi. .  ",
      "P-tags": "apt python pip",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_45975438",
      "task": "Having problems reading in data from file and using it on the fly using PowerShell",
      "P-task": "problem read data file use fli use powershel",
      "F_verb": "read",
      "P-body": "As Mark already pointed out, \"Get-Content emailconfig.conf | Out-String\" will just output the content of the file, it won't define the variables in your code. For that you'd need to dot-source the file, which requires a file with the extension \".ps1\". .  If you want to stick with a simple config file format I'd recommend changing the file to something like this: .  And importing it into a hashtable via \"ConvertFrom-StringData\": .  The data in the hashtable can be accessed via dot-notation (\"$cfg.emailFrom\") as well as via the index operator (\"$cfg['emailFrom']\"), so your code would have to look somewhat like this: .  ",
      "P-tags": "powershel email config",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V in NP from NP"
    },
    {
      "id": "so_21359905",
      "task": "Bash CLI: Is there a way to simultaneously create and set permissions on a file without repeating the filename?",
      "P-task": "bash cli : way simultan creat set permiss file without repeat filenam",
      "F_verb": "create",
      "P-body": "If you are getting a permissions error when you run your command, that suggests that you do not have permissions to create files where you're trying to create the file. Regarding the rest of your question: .  As BroLow said, you can use \"umask\" to affect the default permissions of files created in your session. However, this can be inconvenient, particularly if you only want the new permissions in effect for a single command. .  You can use the \"install\" command to create and set permissions on a file: .  If you want to create an empty file, you can use \"/dev/null\" as a source: .  ",
      "P-tags": "command-line-interfac bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP without S_ING"
    },
    {
      "id": "au_786978",
      "task": "Command to display an arbitrary message if a particular file exists",
      "P-task": "command display arbitrari messag particular file exist",
      "F_verb": "display",
      "P-body": "Use this simple Bash one-liner: .  The \"-e\" check evaluates to true if \"FILENAME\" exists, no matter what it is (file, directory, link, device, ...). .  If you only want to check regular files, use \"-f\" instead, as @Arronical said. .  ",
      "P-tags": "command-lin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP if S"
    },
    {
      "id": "so_56947177",
      "task": "How can I read the IP of an VM via Powershell in C#?",
      "P-task": "read ip vm via powershel c",
      "F_verb": "read",
      "P-body": "Here is a snippet that works fine for me in a console app - adapt to suit your WinForms setup: .  Note that I've added a very basic RegEx to capture only the IPv4 addresses. Remove it to get the IPv6 addresses as well .  Also, it's often easier to offload the data processing to PowerShell, by sending a more complicated script that returns just the desired information (e.g. using a \"PsCustomObject\"), rather than having to deal with it once your back in your C# app. .  ",
      "P-tags": "powershel hyper-v c",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_151779",
      "task": "How use minimum number of commands to copy all .txt files from all subdirectories to one directory?",
      "P-task": "use minimum number command copi txt file subdirectori one directori",
      "F_verb": "use",
      "P-body": "use command : .  ",
      "P-tags": "file-copi file cp",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of NP S_INF from NP to NP"
    },
    {
      "id": "so_32709075",
      "task": "Docker image error: \"/bin/sh: 1: [python,: not found\"",
      "P-task": "docker imag error : bin sh : 1 : python : found",
      "F_verb": "find",
      "P-body": "Use \"\"\" instead of \"'\" in CMD. Documentation) .  ",
      "P-tags": "ubuntu docker python django dockerfil",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_62972194",
      "task": "Scheduled Task succesfully completes but doesn't get past import-csv",
      "P-task": "schedul task succes complet get past import-csv",
      "F_verb": "get",
      "P-body": "First, to prevent the powershell window from closing, run add the following line to the bottom of the script: .  Second, if you run into issues with params, try explicitly naming the param with a flag: .  Third, make sure that you explicitly declare the delimiter being used if different than a comma. .  ",
      "P-tags": "powershel window taskschedul",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_436133",
      "task": "How to get the substring of a filename that matches a \"*\" glob wildcard?",
      "P-task": "get substr filenam match glob wildcard",
      "F_verb": "get",
      "P-body": "The closest I can think of is \"BASH_REMATCH\", since bash stores the results of a regex text in the that variable: .  As \"(.*)\" is the first group in the regex, it's in \"BASH_REMATCH[1]\". I think this is the behaviour you want, but with globs, I don't think bash makes that available in any way. .  ",
      "P-tags": "wildcard bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP that S"
    },
    {
      "id": "au_57196",
      "task": "How can I use $ and euro buttons",
      "P-task": "use euro button",
      "F_verb": "use",
      "P-body": " This works with my Acer Aspire 8930g laptop: .  Firstly, put in /etc/init.d/local, or whatever startup script your distro uses to run startup commands as root: Code: .  Secondly, execute these commands in your window manager startup (exactly how to do this, differs with every window manager, just to confuse us): Code: .  In my experimentations, xmodmap can be run \"too soon\", which prevents it from taking effect! Try adding \"sleep 5\" before the xmodmap commands, if they don't seem to take effect. .  Not sure if this makes a difference, but in xorg.conf I have: Code: .   Source: http://forums.fedoraforum.org/showthread.php?t=203271 .  ",
      "P-tags": "acer 11 04 keyboard-layout",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_60289993",
      "task": "Create separate MD5 file for each file recursively",
      "P-task": "creat separ md5 file file recurs",
      "F_verb": "create",
      "P-body": "\"find\" is the go-to tool for recursively doing anything with files: .  This picks files (not named '*.md5') and runs the given inlined shell script with the filename as \"$1\". .  ",
      "P-tags": "bash linux md5sum shell checksum",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_139055",
      "task": "How to get text at start up of terminal",
      "P-task": "get text start termin",
      "F_verb": "get",
      "P-body": " Add echo \"----++++some stuff++++----\" to your \".bashrc.\" You might want to have \"/etc/motd\" modified as well. This message will be shown every time you successfully log in.  ",
      "P-tags": "termin shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP at NP of NP"
    },
    {
      "id": "so_17361792",
      "task": "How to create a hidden file in Bash",
      "P-task": "creat hidden file bash",
      "F_verb": "create",
      "P-body": "Files starting with a dot are by default hidden. You can create it simply by .  anyone will still be able to see it using .  If you want files to be properly hidden, you will have to change folder permissions using chmod. For example  .  will prevent users (except the owner and people in the group) from listing the whole directory \"folder_name\". .  ",
      "P-tags": "hidden-fil bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_57330510",
      "task": "Creating AWS Lambda function using boto3",
      "P-task": "creat aw lambda function use boto3",
      "F_verb": "create",
      "P-body": "1) You are creating a zip file that includes your \"main.py\" as well as everything in your virtual environment's \"site_packages\" directory (your pip-installed dependencies). .  2) \"export\" is a bash builtin command that sets a variable in the current environment and the environment of any future child processes. In this case it doesn't seem like it's used in any child process and probably not needed. .  3) Nothing. That \"../../../../$ZIP_FILE\" is the relative path back to where the resulting zip file will be located in your original directory (before the \"cd\" command). .  The key is to make a zip containing your code and dependencies all at the top level of the zip archive, as opposed to having dependencies nested several levels down in \"site_packages\" as they are locally. .  ",
      "P-tags": "python-3 x ubuntu aws-lambda amazon-web-servic python",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "so_61645033",
      "task": "How to replace string with quotes and brackets in file using Powershell",
      "P-task": "replac string quot bracket file use powershel",
      "F_verb": "replace",
      "P-body": "Replacement Operator .   The \"-replace\" operator replaces all or part of a value with the specified value using regular expressions. .   Apply the Regex.Escape(String) Method where necessary, e.g. as follows: .  ",
      "P-tags": "powershel replac",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP in NP using NP"
    },
    {
      "id": "so_45969350",
      "task": "PowerShell to Search Hash Table Values with -notlike or -notmatch",
      "P-task": "powershel search hash tabl valu -notlik -notmatch",
      "F_verb": "search",
      "P-body": "You can nest your \"Where-Object\" statements to accomplish this: .  If any of the items in the individual value array matches \"snagit\", the expression will evaluate to \"$false\" and the hashtable entrt will be skipped. Conversely, if no items match \"snagit\", it will evaluate to \"$true\" .   As Ansgar just reminded me, the nested \"Where-Object\" statement isn't actually necessary when evaluating strings, since \"-like\" doubles as a filter operator on collections: .  ",
      "P-tags": "powershel hash match",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "so_11489041",
      "task": "Find the domain name and replace it - Shell Script",
      "P-task": "find domain name replac - shell script",
      "F_verb": "replace",
      "P-body": "You can do this easily from the command line via .  You can adjust the file set by sending extra parameters to \"find\" and you can do a more sophisticated replacement by adjusting the expression given to \"sed\" (for example, to ensure the matched pattern is a whole word). .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "so_50832071",
      "task": "Multiple -replace issue",
      "P-task": "multipl -replac issu",
      "F_verb": "replace",
      "P-body": "The easiest way to make it more readable is to add whitespace. Put each \"-replace \"foo\",\"bar\"\" on its own line. You will need a backtick at the end of each to tell PowerShell that it should all be parsed as one line. .  If you want to go further, put the substitutions in an array and replace in a loop. This is most useful if you're making similar replacements in many places. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "so_5555018",
      "task": "`watch jobs` doesn't work in linux",
      "P-task": "watch job work linux",
      "F_verb": "watch",
      "P-body": "Job control is managed by the shell and \"jobs\" is a shell builtin function. If you use the command \"which jobs\" you will see there is no binary called jobs anywhere in your $PATH.  .  \"watch\" is doing a system call every two seconds so shell functions aren't available to it. .  You could also try \"watch 'ps awwwux | grep yourusername'\". But its not quite the same as \"jobs\".  .  ",
      "P-tags": "linux csh",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_44169782",
      "task": "Rename files sequentially keeping first part of name",
      "P-task": "renam file sequenti keep first part name",
      "F_verb": "rename",
      "P-body": "Create the new name with sed, saving sections of the filename and swapping them: .  For safety, I put in the echo in front on the mv. If the results look good, take out the echo. Here are my results: .  ",
      "P-tags": "command-lin regex shell bash renam",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP of NP"
    },
    {
      "id": "so_14656722",
      "task": "My very basic command is failing on cron but runs fine otherwise, in bash",
      "P-task": "basic command fail cron run fine otherwis bash",
      "F_verb": "run",
      "P-body": "In addition to escaping the \"%\" sign, as F. Hauri points out, \"cron\" runs commands using \"/bin/sh\", which doesn't necessarily support all the features that bash does. .  Or better yet, put the command into a script with \"#!/bin/bash\" and execute the script from your \"crontab\". .  ",
      "P-tags": "sh debian cron command-line-interfac bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "au_693808",
      "task": "Error when fetch timing using sitespeed.io and firefox",
      "P-task": "error fetch time use sitespe io firefox",
      "F_verb": "fetch",
      "P-body": "Finally i Found this cammand that help me to fetch timing : \"$xvfb-run sitespeed.io -u http://www.sitespeed.io -b firefox\" .  ",
      "P-tags": "server graphit 14 04 firefox websit",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_664393",
      "task": "how to concatenate inside data of two files",
      "P-task": "concaten insid data two file",
      "F_verb": "concatenate",
      "P-body": " also, related question: .  https://stackoverflow.com/questions/3806874/how-to-merge-two-files-line-by-line-in-bash .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V inside NP of NP"
    },
    {
      "id": "su_337787",
      "task": "How to fix my bash prompt with long lines?",
      "P-task": "fix bash prompt long line",
      "F_verb": "fix",
      "P-body": "You forgot to wrap the value of \"$RESET\". .  Bash must know how long the prompt is in order for word-wrap to work correctly, and everything not between \"\\[\" and \"\\]\" is counted. .  ",
      "P-tags": "prompt command-lin bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP"
    },
    {
      "id": "so_34432568",
      "task": "In Git Bash, how can I spawn a new cmd window?",
      "P-task": "git bash spawn new cmd window",
      "F_verb": "spawn",
      "P-body": "Try start - so (trivial exammple) .  ",
      "P-tags": "cmd window git-bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_9504390",
      "task": "Running jQuery on a static HTML file from Bash",
      "P-task": "run jqueri static html file bash",
      "F_verb": "run",
      "P-body": "Xpath is great for querying html. .  Something like this: .  In chrome developer tool you can use the search box in the Elements tab to test the expression. .  Quick run in terminal: .  ",
      "P-tags": "jqueri python bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP from NP"
    },
    {
      "id": "so_36561429",
      "task": "variable to change for finding OpenCV",
      "P-task": "variabl chang find opencv",
      "F_verb": "change",
      "P-body": "As identify by Tsyvarev when you compile opencv and want to install opencv it in an different path the default one (e.g. /usr/local/ on linux) it is better to modify the variable \"CMAKE_INSTALL_PREFIX\" in the \"CMakeFile.txt\" rather than move everything after installation. .  ",
      "P-tags": "opencv3 0 linux configur cmake",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V for S_ING"
    },
    {
      "id": "so_36911534",
      "task": "How to redirect the output of time function to a variable",
      "P-task": "redirect output time function variabl",
      "F_verb": "redirect",
      "P-body": "You can use what How can I redirect the output of 'time' to a variable or file? describes: .  Here we are redirecting stdout to \"/dev/null\" so that we get rid of it and just get stderr. This is a particular case of: .  Test We are going to \"ls\" two files: one that exists (\"myfile\") and one that does not (\"asdfjasdkfl\"). .  ",
      "P-tags": "solari ksh time unix",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "so_52412698",
      "task": "Add registry key on remote computers",
      "P-task": "add registri key remot comput",
      "F_verb": "add",
      "P-body": "You need to pass the variables into the scriptblock using \"-ArgumentList\" and then accept them within the scriptblock via \"param()\". .  Try the following: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_62069740",
      "task": "How are hardware interruptions handled in non-preemtive scheduling?",
      "P-task": "hardwar interrupt handl non-preemt schedul",
      "F_verb": "handle",
      "P-body": "You are confusing interrupts, signals and task scheduling. Those are all very different concepts. .   I press Ctrl+C, how is this interruption handled?  .   CTRL+C has nothing to do with interrupts. It's a key combination that is intercepted by your terminal emulator, which then sends a signal (\"SIGINT\") to the currently running process. Signal delivery is done through the \"kill\" syscall (which, contrary to its name, does not necessarily kill the process). .   Does A finish executing first and then the interruption is handled?  .   What happens when your program receives a \"SIGINT\" signal depends on the specific case. A program can register a signal handler, and decide what to do in case it receives a specific signal. In other words, this \"interruption\" as you call it, happens while the process is running: when the signal is delivered, the kernel will temporarily \"pause\" the normal process code, let the process run its signal handler, and then resume the process from where it left. .  A process can only register handlers for signals that are catchable (\"SIGINT\" is). The only two signals that are uncatchable in Linux are \"SIGKILL\" and \"SIGSTOP\". In case the process has not registered a signal handler, the default handler defined by the kernel will do its job: for \"SIGINT\", the default handler just terminates the process. .  See \"man 7 signal\" for more information. .   Does A get put in the ready queue? .   There is no such thing as a \"ready queue\", I suppose you mean runqueue. If the process gets killed by the signal, then it will cease to exist and will be removed from its runqueue, therefore no runqueue will have A anymore. .  If the process is not terminated, it will still exist in the system, and the kernel will keep executing it along with other processes that are executing on the same CPU. There is one runqueue per CPU, and the scheduler uses it to determine which processes to run when. Processes can also be moved from one runqueue to another (for example for load balancing purposes), but this is a different topic. .  ",
      "P-tags": "linux process linux-kernel operating-system asynchron",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V in NP"
    },
    {
      "id": "so_16140668",
      "task": "Error: Could not find or load main class - Java cygwin",
      "P-task": "error : could find load main class - java cygwin",
      "F_verb": "load",
      "P-body": "Even though you are running under cygwin, the java.exe is still a windows program. .  It needs \";\" as class path delimiter. Try ,  .  or .  You need to escape or quote the classpath correctly so that it is not interpreted by shell. .  ",
      "P-tags": "classpath cygwin linux java",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "ul_339624",
      "task": "How can I run ANY java class file graphically? (Linux Mint/Dolphin)",
      "P-task": "run java class file graphic\nlinux mint dolphin",
      "F_verb": "run",
      "P-body": "You can create a custom handler with a bash script: .  create file \"/usr/local/bin/myhandler.sh\" .  add executable flags \"sudo chmod +x /usr/local/bin/myhandler.sh\" .  In dolphin > right click file > open with > (last entry not sure how it's called in english \"own file, not in list\") > insert \"/usr/local/bin/myhandler.sh\" enable all three checkboxes \"execute in terminal\", second \"keep open after execution\" and last one \"default handler for all files\" .  Back to the \"myhandler.sh\"script: .  \"$1\" is the var keeping the full path to that file clicked in dolphin, you may want to adjust the bash script to something like .  ",
      "P-tags": "dolphin linux-mint java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_284468",
      "task": "How to find match with surrounding words?",
      "P-task": "find match surround word",
      "F_verb": "find",
      "P-body": "\"(\\w+ )\" will match a word or part of word. This means that \"grep\" will treat every character in every word as a potential start-of-match. In your example, it will consider each of .   \"word1\" \"ord1\" \"rd1\" \"d1\" \"1\"  before moving on to the successful match (starting at \"word2\"). .  As you are interested in finding whole words, you can prevent all the attempted mid-word matches by including word boundaries in the pattern: .  Another effect of this is to prevent matching \"123\" when it appears inside a longer word. .  This cut the time by a factor of 100 for me (test case: searching for the word 'me' in Ulysses) .  The \"Pitfalls\" section of http://www.regular-expressions.info/examples.html has some good pointers on what makes regexps slow. .  ",
      "P-tags": "text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "so_14676746",
      "task": "Implement linux command 'rename' using Perl",
      "P-task": "implement linux command renam use perl",
      "F_verb": "implement",
      "P-body": " doesn't magically evaluate the operator, so it should be no surprise that .  doesn't either. If you want to evaluate Perl code, you're going to have to pass it to the Perl interpreter. You can access it using \"eval EXPR\". .  ",
      "P-tags": "linux perl maco",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_625951",
      "task": "Convert text file data to table",
      "P-task": "convert text file data tabl",
      "F_verb": "convert",
      "P-body": "This uses GNU awk for multidimensional arrays: it reads all the data in one pass and emits the output in the END block. This is \"script.awk\" .  then: .  ",
      "P-tags": "awk convers text-process",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_43149444",
      "task": "Execute a java class file that uses class from a jar file",
      "P-task": "execut java class file use class jar file",
      "F_verb": "execute",
      "P-body": "You have to add your current directory to in order to find your class file.  You must run \"java -classpath Jama-1.0.3.jar:. File_2\".  .  ",
      "P-tags": "command-lin ubuntu jar java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP that S"
    },
    {
      "id": "au_58023",
      "task": "How can I make LightDM the default display manager?",
      "P-task": "make lightdm default display manag",
      "F_verb": "make",
      "P-body": " Will prompt you to make it default. More information here: .   https://wiki.ubuntu.com/LightDM  ",
      "P-tags": "display-manag lightdm login-screen",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "ul_126529",
      "task": "where does history timestamp stored before i enable it",
      "P-task": "histori timestamp store enabl",
      "F_verb": "enable",
      "P-body": "Bash always remembers timestamps, the \"HISTTIMEFORMAT\" variable merely determines what gets written to \"~/.bash_history\". So for commands bash reads from its history file, it only knows the timestamps if they have been written to it, but it always knows its \"own\" timestamps. .  ",
      "P-tags": "bash konsol linux ubuntu command-histori",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_27058233",
      "task": "Find and copy files filtered by txt file",
      "P-task": "find copi file filter txt file",
      "F_verb": "copy",
      "P-body": "Something like this should work: .  This would work if your names file had the full filename including extension. Since that is not the case you could do: .  ",
      "P-tags": "filter powershel window",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP by NP"
    },
    {
      "id": "ul_270961",
      "task": "How do I create and automatically sync a \"merged\" directory from multiple other directories without duplicating files?",
      "P-task": "creat automat sync merg directori multipl directori without duplic file",
      "F_verb": "duplicate",
      "P-body": "Dynamically combining the content of several directories is exactly what a union mount (or union filesystem) is about. There are several implementations on Linux, but the usual ones resolve duplication between branches by always preferring one particular branch (e.g. \"dir2/file\" always has precedence over \"dir1/file\" if both exist). However I've just discovered mergerfs which has more flexible policies, and in particular allows picking the newest file on a file-by-file basis. .  The setup: .  Now we mount. We set the \"newest\" policy for file access (\"search\") and metadata modification (\"action\"), and forbid creation (\"create\") (you could make creation pass down to one of the branches, either always the same, or based on available disk space, or even randomly!). .  To unmount: \"fusermount -u merge\" .  ",
      "P-tags": "directori linux debian",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP"
    },
    {
      "id": "au_1203190",
      "task": "vim - running dd range command using command line",
      "P-task": "vim - run dd rang command use command line",
      "F_verb": "run",
      "P-body": "\":norm\" iterates over lines with specific addresses, not over lines with specific marks. .  Suppose you have this file: .  And you execute \":2,4norm! dd\". You probably expect getting this file: .  But in reality, you'll get this file: .  First, \":norm\" executes the \"dd\" command on the line whose address is \"2\"; at that point, the file contains: .  Then, \":norm\" executes the \"dd\" command on the line whose address is \"3\". But since \":norm\" has removed a line in the previous step, all the addresses of the lines below the deleted line have decreased by 1. So the line of address \"3\" is not the one containing the text \"line 3\" anymore, but the one containing the text \"line 4\"; and \":norm\" deletes the latter; at that point, the file contains: .  Finally, \":norm\" executes the \"dd\" command on the line whose address is \"4\". But again, since \":norm\" has removed 2 lines in the previous steps, all the addresses of the subsequent lines have decreased by 2; and the line of address \"4\" is not the one containing the text \"line 4\" anymore, but the one containing the text \"line 6\"; \":norm\" deletes the latter and the file finally contains: .   If for some reason, you really want to use \":norm! dd\", combine it with \":g\" which contrary to \":norm\" does mark the lines on which it operates before executing its command argument: .  Or try to reverse the order of the deletions: .   Always append a bang to \":norm\", unless you really want your custom mappings to be taken into account. .   If your file is folded, make sure folding is temporarily disabled; execute \":setl nofen\" before the deletions, then \":setl fen\" afterward. .  ",
      "P-tags": "dd vim",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_47056",
      "task": "Merge two command results to one line when redirecting stdout",
      "P-task": "merg two command result one line redirect stdout",
      "F_verb": "merge",
      "P-body": "Try simply doing: .  You might want to specify a compact date format to make your log file more easy to parse and to be independent of environment/locale settings (something like \"$(date +\"%Y%m%d %H%M%S\")\" for example). .  ",
      "P-tags": "stdout bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP when S"
    },
    {
      "id": "so_57920991",
      "task": "How do we run tmux from ssh agent using python",
      "P-task": "run tmux ssh agent use python",
      "F_verb": "run",
      "P-body": "\"open terminal failed: not a terminal\" .  Okay well post the tmux bits of the script, by default it will try to attach to the current tty (which doesn't exist hence the error) if you have a new session in there for example you'll need to add a -d param to prevent this .  \"tmux new-session -s username -d\" .  ",
      "P-tags": "linux ubuntu python ssh shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "au_162345",
      "task": "how to increase open file limits (nofile and epoll) in 10.04?",
      "P-task": "increas open file limit nofil epol 10 04",
      "F_verb": "increase",
      "P-body": "In order to set these limits, I did a combination of things found here and here. Since I want to restrict these file limits to the \"hdfs\" and \"mapred\" users, I added each of these users to the \"hadoop\" group on my system and edited \"/etc/security/limits.conf\" to include the line: .  which allows both users to open as many as 16384 files at once, which is apparently important in pseudo-distributed mode. I also had to add the following line to \"/etc/pam.d/common-session\": .  which makes these file limits persist across daemon processes like hdfs and mapred. After restarting the server, everything appears to be working perfectly as hdfs currently has more than the default number (1024) files open: .  ",
      "P-tags": "10 04 file configur hadoop",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP"
    },
    {
      "id": "so_9325263",
      "task": "How to get user input in MySQL?",
      "P-task": "get user input mysql",
      "F_verb": "get",
      "P-body": "If you are on the terminal anyway, why not write a little script around your functions and get the user input there, store it in variables and then send the mysql queries? .  AFAIK there is no native method in MySQL that allows something like this, because SQL is there to query the data, not the user. .  Small example: .  ",
      "P-tags": "linux mysql",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_491784",
      "task": "Remove darkcoin-qt",
      "P-task": "remov darkcoin-qt",
      "F_verb": "remove",
      "P-body": "As long as you didn't run \"sudo make install\", you can just remove the folder, and Darkcoin itself will be removed. If the program stores any configuration settings, you'll need to remove those yourself. They may be in \"~/.darkcoin\" or \"~/.config/darkcoin\" (or similarly-named folders). .  To remove the build dependencies, run \"sudo apt-get purge qt4-qmake libqt4-dev build-essential libboost-dev libboost-system-dev libboost-filesystem-dev libboost-program-options-dev libboost-thread-dev libssl-dev libdb++-dev libminiupnpc-dev\" followed by \"sudo apt-get autoremove\". If you know you use any of the build dependencies listed in other software, remove it from this list. .  ",
      "P-tags": "uninstal bitcoin",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_1712158",
      "task": "Powershell - Get Variable from C# Cmdlet",
      "P-task": "powershel - get variabl c cmdlet",
      "F_verb": "get",
      "P-body": "If you're implementing a PSCmdlet use the \"this\" variable to access it like so: .  ",
      "P-tags": "powershel c cmdlet",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_334335",
      "task": "Fedora 24: how to get the wx-config script detected in openSUSE Build Service?",
      "P-task": "fedora 24 : get wx-config script detect opensus build servic",
      "F_verb": "get",
      "P-body": "\"/usr/bin/wx-config\" is a symlink because of the \"alternatives\" system \u2014 it happens that Fedora has both wxGTK and wxGTK3, both of which can provide \"wx-config\". If you have either \"wxGTK-devel\" or \"wxGTK3-devel\" installed on your system, \"/usr/bin/wx-config\" should exist and point to \"/etc/alternatives/wx-config\", which in turn should point to the appropriate \"/usr/libexec/\"(whatever). If you have both installed, wxGTK3-devel should take precedence.) .  You have \"BuildRequires: wxGTK3-devel\" in your specfile, so this should Just Work. You shouldn't have to (and, basically, therefore just shouldn't) need to make the symlink yourself. However, it appears there was a packaging bug (bugzilla #1077718) in the version of wxGTK3 shipped with Fedora 24. This was fixed in an update, but it looks like OBS doesn't have an option to include updates in your buildroot, so unfortunately you'll need to find a workaround for that. .  ",
      "P-tags": "rpm fedora wxwidget cmake",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_49555495",
      "task": "Create symbolic links for multiple books collected from command `find`",
      "P-task": "creat symbol link multipl book collect command find",
      "F_verb": "create",
      "P-body": "Sorry again. I don't have access to BSD \"ln\" at the moment, but I would assume that '{}' contains the full path, and doing \"'{}' js_books/'{}'\" should get you something like \"/home/.../file js_books//home/.../file\", which is of course nonsense. .  In my version of \"ln\", I don't even need to specify the \"-t\" option, i.e., the following command works: .  If this doesn't work for you, try using \"basename\" to get the file name without the path: .   Sorry. Previous answer didn't work so well. Instead, try using full paths for both source and destination. .   For reference, the previous answer was: .  Use \"ln\"'s \"-t\" option: .  \"-t, --target-directory=DIRECTORY\" \"specify the DIRECTORY in which to create the links\" .  So your command becomes \"find ~ -type f -iregex '.*javascript.*\\.pdf' -print0 -exec ln -s -t js_books/ '{}' \\;\" .  ",
      "P-tags": "ln bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP from NP"
    },
    {
      "id": "au_1075672",
      "task": "VMs get identical IPs",
      "P-task": "vm get ident ip",
      "F_verb": "get",
      "P-body": "I've seen this plenty of times recently, so I'm for now just assuming you are struck by the same and provide it as an answer. If that is not your case at least it might help others. .  Ingredients to the issue: .   clone a system after having it booted (should never be done IMHO) networkd  Now what happens is that on first boot systemd will generate \"/etc/machine-id\" and afterwards networkd will use that to make a client-id in its dhcp requests. .  That will be the preferred unique ID to serve IPs and therefore all machines cloned with the same \"/etc/machine-id\" will conflict. .  There is more than that which is done on first boot/init which is the reasons you should IMHO start with clean cloud images plus a deployment procedues. But for now, please make sure \"/etc/machine-id\" gets deleted. It will generate a new one on boot and the systems can be differentiated by the DHCP server. .  ",
      "P-tags": "dhcp network virtual",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_45001306",
      "task": "Are pseudo-devices implemented as device drivers within the kernel?",
      "P-task": "pseudo-devic implement devic driver within kernel",
      "F_verb": "implement",
      "P-body": "At least classically, all devices \u2014 pseudo or not \u2014 were implemented as device drivers in the kernel. Frequently, the implementations of the support functions were minimal for the pseudo-devices. The write code for \"/dev/null\" does nothing successfully (and the same is likely true of \"/dev/zero\"); the read code for \"/dev/null\" reports 'no data'; the read code for \"/dev/zero\" zeroes the buffer that it is given. And so on. Things may have changed a little over the last 20 years, but that's more or less how it used to be and how I'd expect it still to be (but I live to be surprised). .   On the Linux system I'm using, and maybe on other Linux systems, \"/dev/null\", \"/dev/zero\" and \"/dev/random\" all have the same major number though. .   That needn't be a problem. They have different minor numbers, and as a result can and do do different things from each other, just as different disk drives may share a major number but the minor numbers distinguish different subsections of the main device, or even different drives altogether. .  On a Mac (running macOS Sierra 10.12.5), \"/dev/null\" and \"/dev/zero\" share the same major number, and \"/dev/random\" and \"/dev/urandom\" share the same major number that's different from the other two. .  More intriguing is that there are a number of devices with the same major and minor numbers: .  I'm not sure how those distinguish what they're supposed to do. .  ",
      "P-tags": "driver unix",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V as NP within NP"
    },
    {
      "id": "so_7587487",
      "task": "keeping track of a moving shell script",
      "P-task": "keep track move shell script",
      "F_verb": "keep",
      "P-body": "For clarity, I would probably declare named variables for your common values instead of constantly reusing the ${0} array. It's also good practice to quote variables and strings. .  The only major issue I saw, was running ./script.sh would make $0 equal just the filename, so I add \"./\" to the beginning in that case. .  ",
      "P-tags": "linux unix shell bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP of NP"
    },
    {
      "id": "su_468015",
      "task": "How to update to latest version of SVN server?",
      "P-task": "updat latest version svn server",
      "F_verb": "update",
      "P-body": "\"apt-get\" searches for the updates in the repositories created for your version of Ubuntu. The SVN server version is not likely going to change until you upgrade the whole system. .  ",
      "P-tags": "apt-get linux ubuntu svn package-manag",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V to NP of NP"
    },
    {
      "id": "so_35732899",
      "task": "What is path in android update project --path command",
      "P-task": "path android updat project -- path command",
      "F_verb": "update",
      "P-body": "\"android update project\" is a very old approach. I strongly recommend that you find some newer information on how to use this library, ideally something written within the past 1-2 years. .  That being said \"--path\" is a command-line switch. It indicates where to find your project. In your sample command (\"android update project --path .\"), the value you are giving for the \"--path\" switch is \".\", indicating that the project is in the current working directory. .  ",
      "P-tags": "android linux tesseract",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_52703051",
      "task": "Executing Java Cucumber feature files one by one from bash script and continue execution of feature files after first one has completed",
      "P-task": "execut java cucumb featur file one one bash script continu execut featur file first one complet",
      "F_verb": "execute",
      "P-body": "The error seems to be related to the steps inside your \"build.gradle\" file or the way you call the function in the Bash script. .  A small test set-up. Assume the following structure#!/bin/bash .  run-gradle-loop.sh .  gradle .  file1_Steps.feature and file2_Steps.feature are two empty files, only to fulfill the loop criteria. .  The aim of the test is to check the behavior where \"gradle\" exit with an error code. .  run the main Bash script .  output .  This shows that even \"gradle\" would return with an error code the loop processes all \".*Steps.feature\" files. .  edit One way it might stop after the first error could be that in the \"run-gradle-loop.sh\" script there is a \"set -e\" statement. .  \"man bash\" .   -e Exit immediately if a pipeline (which may consist of a single simple command), a list, or a compound command .   Which means. When the script \"gradle\" fails with an error the control is not returned to \"run-gradle-loop.sh\". The output with above set-up would be .  ",
      "P-tags": "cucumb java bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_11684506",
      "task": "Rename files using shell with occurence more than once",
      "P-task": "renam file use shell occur",
      "F_verb": "rename",
      "P-body": "You're almost there, if you use: .  (two slashes instead of one), then all occurrences will be replaced. .  ",
      "P-tags": "sh shell bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP using NP with NP"
    },
    {
      "id": "so_24521148",
      "task": "run forked process continuously, kill after interval",
      "P-task": "run fork process continu kill interv",
      "F_verb": "run",
      "P-body": "Your wish is my command (at least, when your wish aligns sufficiently with my desires): .    When you run \"phantomjs\", do you run it with \"exec\" or just as a normal process? Does it make any difference if you do use \"exec\"?  The thought behind the questions is that you kill the shell that runs the other process (which, in the case of \"echo\", is the shell), but that doesn't necessarily kill the children of the process. Maybe you need to use something like: .  to send a signal to the process group, rather than just the process. .  Also, consider whether a 'time out' command would make your life easier (\"timeout\" on Linux). .   ",
      "P-tags": "subshel process kill bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_177644",
      "task": "How can I reset tmux's automatic session name numbering?",
      "P-task": "reset tmux automat session name number",
      "F_verb": "reset",
      "P-body": "No, this is not currently possible. .  The only thing you can do about this without restarting the server is to override the name manually when creating a new session by issuing \"tmux new -s 5\", for example: .   The automatic session number is governed by the global variable \"u_int next_session_id\" in \"session.c\" which cannot be accessed from the command line, as grepping the source code reveals. .  \"tmux new-session\" calls \"session_create()\" in \"session.c\" (line 88) and \"next_session_id\" is incremented whenever you create a new session. The argument of \"-s\" flag to \"new-session\" (short \"new\") sets \"name\", otherwise \"next_session_id\" is used. .  ",
      "P-tags": "tmux",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP"
    },
    {
      "id": "so_42633009",
      "task": "Script to show how old are all the files in a directory",
      "P-task": "script show old file directori",
      "F_verb": "show",
      "P-body": "You are using the day of a month to perform absolute item differences, but as you can see, that fails when the current day of this month is less than a later day in the previous month. You should instead use a UNIX timestamp, which measures the number of seconds since a day in 1970, to compute the elapsed time since a file was last modified. Also, I recommend using \"stat\", rather than \"ls\", to get this information. GNU \"stat\" assumed; your local implementation may differ.) .  ",
      "P-tags": "unix backup-strategi display backup bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "su_118200",
      "task": "Syntax for find on Mac OS X",
      "P-task": "syntax find mac os x",
      "F_verb": "find",
      "P-body": "Mac OS X uses BSD find and most Linux distributions come with GNU find. I believe you can install GNU findutils onto Mac OS X. I don't have a Mac handy, but I am sure it was available in MacPorts. .  Looking at the BSD find man page I could make a wild guess and suggest you try looking at the \"-E\" option to enable the modern regular expression library. .  ",
      "P-tags": "unix linux maco find syntax",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V on NP"
    },
    {
      "id": "ul_344157",
      "task": "How do I make FFMPEG check yes while installing OPENCV",
      "P-task": "make ffmpeg check ye instal opencv",
      "F_verb": "make",
      "P-body": "I happen to be reinstalling my OpenCV recently and here are the steps to configure ffmepg. .  1.Download the yum repository here to ~/Desktop https://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpm .  2.Install the repository  .  3.Install FFMPEG .  4.Edit common.h file .  Insert the following code at line:28 .  And It is done .  ",
      "P-tags": "ffmpeg opencv cmake",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP while S_ING"
    },
    {
      "id": "so_58833253",
      "task": "How to find particular file in all subfolders in unix",
      "P-task": "find particular file subfold unix",
      "F_verb": "find",
      "P-body": "find . -name \"name_of_the_file\" .  Example .  Let us say I want to search files with the name \"main.yml\" inside my current directory (.) .  ",
      "P-tags": "unix shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "ul_473260",
      "task": "Are all kernel argument really used by the kernel?",
      "P-task": "kernel argument realli use kernel",
      "F_verb": "use",
      "P-body": "Parameters passed on the kernel command line don\u2019t have to be meaningful for the kernel: the kernel parameters documentation says .   The kernel parses parameters from the kernel command line up to \u201c--\u201d; if it doesn\u2019t recognize a parameter and it doesn\u2019t contain a \u2018.\u2019, the parameter gets passed to init: parameters with \u2018=\u2019 go into init\u2019s environment, others are passed as command line arguments to init. Everything after \u201c--\u201d is passed as an argument to init. .   This doesn\u2019t apply to \"init\" and \"root\" which really are kernel parameters, and are handled by the kernel. They can also be acted upon by user-space, since they appear in \"/proc/cmdline\". Thus for example systemd takes the \"quiet\" kernel parameter into account to reduce its output.) .  When the kernel is booted with an initramfs, the \"root\" parameter isn\u2019t used by the kernel directly, and the \"init\" parameter is only used if \"rdinit\" fails. \"init\" startup is handled in \"kernel_init\", which works as follows: .   if there\u2019s a \u201cramdisk execute command\u201d (either the value given to \"rdinit\" on the kernel command line, or \"/init\") which is accessible, the kernel attempts to run that; if that fails, and there\u2019s an \u201cexecute command\u201d (the value given to \"init\" on the kernel command line), the kernel attempts to run that, and panics if it can\u2019t; as a last resort, the kernel tries to run \"/sbin/init\", \"/etc/init\", \"/bin/init\", and \"/bin/sh\"; if none of those can be run, it panics.  When there\u2019s an initramfs, all of this happens there, and the target volume isn\u2019t mounted by the kernel. What happens after the kernel runs the first \"init\" program (typically, the \"/init\" script in the initramfs) is up to the program, not the kernel. Arguments which aren\u2019t passed to \"init\" are still available in \"/proc/cmdline\" if the \"/proc\" file system is mounted. .  ",
      "P-tags": "linux-kernel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V by NP"
    },
    {
      "id": "ul_667877",
      "task": "Move filesystem to the left after expanding partition to the left",
      "P-task": "move filesystem left expand partit left",
      "F_verb": "expand",
      "P-body": "It's not possible with fsck. In a filesystem, everything has offsets and if you change the start sector, all of these offsets change. fsck simply has no facility to re-write all offsets for everything (superblocks, journals, directories, file segments, etc.). And even if you could do that, it would only work if the new start sector aligns with internal filesystem structures. .  So this is not done. .  Instead, you'd have to shift all data to the left with dd (essentially what gparted does). Only by shifting the filesystem entirely, would the offsets within it remain intact. .  In principle the dd command could work like this. It reads and writes to the same device, at different offsets. This can only work for shifting to the left, so seek (write to) must be smaller than skip (read from). All units in 512b sectors (if you specify \"bs=1M\", your partitions must be MiB aligned and all units in MiB instead) .  However, this is very dangerous. Use it at your own risk. Do take the time to backup your data first. .  Shifting to the right would be more complicated. You'd have to work backwards, otherwise you overwrite data that has yet to be read, and corrupt everything in the process. .   The only tool I know that does it (more or less) without shifting data is \"blocks --lvmify\", which achieves it by converting the existing filesystem partition to LVM. With LVM, you can logically expand to the right while it's physically stored on the left. Without LVM, you could also set up a linear device mapping manually, but then you are stuck with a non-standard solution. .   The most sensible approach to this type of problem (if you don't want to use gparted) would be to backup all data, then make new partitions and filesystems in any layout you like, and then restore your data. .  If this dd image is your approach to a backup solution, consider backing up files instead. Disk images can be hard to handle, especially if you want to transform them afterwards. .   If your main goal is reduce the storage requirement of the image file, what you could do is \"fstrim\" (for loop mounted filesystem - losing all free space), or \"blkdiscard\" (for loop swap partition - losing all data). .  Provided the filesystem that stores the image supports sparse files and hole punching, it would make the dd image use less storage space w/o changing any layout, as any free space within the image would also be freed for the backing filesystem. .  Similarly, this is dangerous, if you discard the wrong parts of the image file, the image file is irrecoverably damaged. The simple act of creating a loop device for an image file, and mounting it, already modifies/damages the image file. .  If the source disk is SSD, and it's already using fstrim regularly, and reads trimmed areas as binary ZERO, you can create an already sparse dd image in the first place using \"dd conv=sparse if=/dev/ssd of=ssd.img\". This way any binary zero area would not take up space in the ssd.img file. Note that \"conv=sparse\" can lead to corrupt results when used in the other direction when restoring to a non-zero target drive. .  ",
      "P-tags": "partit partition-t filesystem move-partit ext4",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_29327",
      "task": "How to detect when a shell is owned by a remote SSH session?",
      "P-task": "detect shell own remot ssh session",
      "F_verb": "detect",
      "P-body": "To detect an SSH session, use \"$SSH_CLIENT\". .  To distinguish between local and remote sessions, there are two possible approaches: client-side or server-side. On the server side, compare \"$SSH_CLIENT\" with the local IP address or routing table; this'll usually tell you whether the connection is from the LAN. On the client side, you may want to put \"ForwardX11\" settings in your \"~/.ssh/config\": set it to \"yes\" for LAN hosts and to \"no\" for WAN hosts. This implies having a different \"~/.ssh/config\" on different sites; that's what I do, and I generate mine with a shell script. .  If X11 forwarding is on for LAN connections and off for WAN connections, then you can set your favorite editor to take \"$DISPLAY\" into account. .  The server-side settings would normally go into your \".profile\" (or \".bash_profile\" if your login shell is bash and you use \".bash_profile\", or \".zprofile\" if your login shell is zsh). .  ",
      "P-tags": "ssh bashrc shell",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V when S"
    },
    {
      "id": "ul_405798",
      "task": "Quickest way to find the largest file in a directory and subdirectories",
      "P-task": "quickest way find largest file directori subdirectori",
      "F_verb": "find",
      "P-body": "GNU \"find\" + \"sort\" + \"head\" solution (for any directory depth level), assuming file paths don't contain newline characters: .   \"%s\" - format specificator pointing to file size (in bytes) \"%p\" - format specificator pointing to file name \"sort -nr\" - sort records numerically in reversed order \"head -1\" - print the TOP first line/record   To get a human-readable file size value - extend the pipeline with GNU \"numfmt\" command (if supported): .  ",
      "P-tags": "sort size shell-script file",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "su_176754",
      "task": "Get a list of open windows in Linux",
      "P-task": "get list open window linux",
      "F_verb": "get",
      "P-body": "\"wmctrl -l\" may be what you're looking for. The wmctrl program can also perform some simple actions on the windows like moving them around and setting their properties. .  ",
      "P-tags": "ubuntu-10 04 linux ubuntu",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_29381347",
      "task": "Run git commands in shell script without change directory to repo",
      "P-task": "run git command shell script without chang directori repo",
      "F_verb": "run",
      "P-body": "you can specify the git working directory and \".git\" location: .  There are also environmental parameter available, please check the manuals .  ",
      "P-tags": "git rvm shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP without S_ING"
    },
    {
      "id": "ul_569680",
      "task": "How can i define variables for All hosts in Ansible?",
      "P-task": "defin variabl host ansibl",
      "F_verb": "define",
      "P-body": "\"all\" is an implicit group with the inventory system. .  You could create \"group_vars/all.yml\" and put the variables in there. .  Several other ways to do it also, I'd think. .  The variables doco says you can use variables from (automatically) included files just like roles does. .  ",
      "P-tags": "ansibl",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_10910906",
      "task": "How to map a path to the corresponding /dev file in UNIX - C++?",
      "P-task": "map path correspond dev file unix - c++",
      "F_verb": "map",
      "P-body": "Calling \"system()\" and parsing the output may well be the more reliable and portable way to do what you are trying to do, because the \"df\" command may use all sorts of system-dependant tricks to resolve device numbers to names in \"/dev\" which you'd have to implement yourself otherwise. .  You can easily get the device NUMBER of the filesystem on which a file is located: it's the \"st_dev\" field of the \"stat()\" structure. But how to find what file in \"/dev\" goes with that number is left as an exercise for the \"df\" command. In particular, remember that not every filesystem is mounted from a file in \"/dev\": think NFS, and special filesystems like \"/proc\". .  Here are some other things you can do: .   Scan every file in \"/dev\" looking for a block device whose \"st_rdev\" is the same number Parse the table of mounted filesystem (\"/etc/mtab\" or \"/etc/mnttab\", it's system-dependant) looking for a mount prefix that looks like it might be a parent of the pathname you're interested in.  ",
      "P-tags": "path c++ unix devic",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_52614207",
      "task": "How to run a python script in a shell script on MAC OS",
      "P-task": "run python script shell script mac os",
      "F_verb": "run",
      "P-body": "F.Leone gave you instructions to fix your problem just add execute rights to your script. Execute in terminal: .  ",
      "P-tags": "shell python maco",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP on NP"
    },
    {
      "id": "so_35994862",
      "task": "simple numerical compare in zsh function always true",
      "P-task": "simpl numer compar zsh function alway true",
      "F_verb": "compare",
      "P-body": "Wrong syntax, plus typing error in the variable name. It should be .  or .  ",
      "P-tags": "shell zsh",
      "source": "qa",
      "cate": "compare",
      "pat": "V in NP"
    },
    {
      "id": "so_15083717",
      "task": "convert batch file to shell script file",
      "P-task": "convert batch file shell script file",
      "F_verb": "convert",
      "P-body": "I am assuming more or less Bourne compatible shell like \"bash\" as this is most common. To get started, here's some differences that you need understand in order to transform your batch script to Bourne style shell script: .   The first difference is that the executed commands are by default not echoed (though you can change this). Comments begin with hash character \"#\". \"cd\" and \"echo\" and \"exit\" also exists in Bourne compatible shells. To test for file existence, you can use \"[ -e\" file-name \"]\". \"IF\" statement becomes \"if\" condition \"; then\" true-statement \"; else\" false-statement \"; fi\" where you can have multiple commands / statements separated by semicolons in place of true-statement and false-statement. \"IF EXIST o%8.out (COPY o%8.out %5.csv) ELSE echo \"Output file does not exists\"\" in Bourne compatible shell would look like .  or with alternative indentation (semicolon can be replaced with new line): .  note that we also quote the arguments to \"cp\" so that we can use spaces in the arguments. .  You can get rid of the \"goto\" by little restructuring. You can refer to this Stack Overflow question (assuming \"bash\" or other Bourne shell style script dialect): Is there a \"goto\" statement in bash?  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_68712132",
      "task": "Passing Variables in CURL GET",
      "P-task": "pass variabl curl get",
      "F_verb": "get",
      "P-body": "Try changing .  to .  I think the error was occurring because shell was trying & failing to execute \"whitelist_tmp.json\" as its own command/function instead of piping the contents of the file to jq. .  You also want to add the -r option to jq in the variables you are going to pass in curl, like so: .  Without the -r option, any strings that jq outputs will be quoted, which could be escaping your script's quotation in the curl command. The -r option tells jq to output the raw string data without any quotation. .  ",
      "P-tags": "jq curl shell bash url-paramet",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V"
    },
    {
      "id": "so_31239904",
      "task": "Running a folder/directory as a whole in Python",
      "P-task": "run folder directori whole python",
      "F_verb": "run",
      "P-body": "Try this: .  ",
      "P-tags": "directori powershel python",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "so_64499540",
      "task": "Linux: Checking if a user has a shell or not",
      "P-task": "linux : check user shell",
      "F_verb": "check",
      "P-body": "You may use \"su\", and check the return code: .  or print the string \"NO_SHELL\": .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "so_5755588",
      "task": "Recently modified files....listed by size?",
      "P-task": "recent modifi file list size",
      "F_verb": "modify",
      "P-body": "This works for regular files: .  This seems to work for folders too: .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_1109085",
      "task": "Any downside of installing Ubuntu in C drive over full format install?",
      "P-task": "downsid instal ubuntu c drive full format instal",
      "F_verb": "install",
      "P-body": "Starting in 17.04 new installations of Ubuntu use a swap file instead of a swap partition, so everything is installed on a single ext4 partition by default including the \"/home\" directory. This makes the most efficient use of valuable disk storage space on SSDs in situations in which Ubuntu is installed on an SSD. In situations where there are multiple hard disks or partitions there are ways listed below of making efficient use of the storage space on the other partition(s) too. .   Suppose Ubuntu ran into some problem, would I be able to retain data in \"/home\" directory if I want to install Windows/Ubuntu again? .   You can reinstall Ubuntu without losing data in \"/home\" even without a separate \"/home\" partition. See the following Ubuntu documentation links. .   Ubuntu documentation Home Folder wiki .  Ubuntu documentation Ubuntu Reinstallation wiki .    Will there be any performance difference if I format all drives and make remaining space as \"/home\" over keeping previous Windows drives?  .   NTFS is not suitable for a home partition, because there are certain type of file system objects (character devices, named pipes, etc.) which are required for certain services but are not supported on NTFS. Quoted from: Using a folder on an ntfs partition as /home  .  You can use custom folders for folders in \"/home\" in order to span your home directory across multiple hard disks.  .  Example (\"xdg-user-dirs-update\" - Update XDG user dir configuration): .  would switch from \"/home/$USER/Downloads/\" to \"/mediaRedman/2nd-HDD/Downloads/\" and downloaded files would then download to the 2nd HDD. The same applies for all the other directories.  .   Both the local \"~/.config/user-dirs.dirs\" and global \"/etc/xdg/user-dirs.defaults\" configuration files use the following environmental variable format to point to user directories: \"XDG_DIRNAME_DIR=\"$HOME/directory_name\"\" An example configuration file looks like this (these are all the template directories): .  Results of \"cat ~/.config/user-dirs.dirs\" : .  As \"xdg-user-dirs\" will source the local configuration file to point to the appropriate user directories, it is therefore possible to specify custom folders. For example, if a custom folder for the \"XDG_DOWNLOAD_DIR\" variable has been named \"$HOME/Internet\" in \"~/.config/user-dirs.dirs\" any application that uses this variable will use this directory. .     What about in case I want to go back to Windows, can I retain \"/home\" data? .   The Windows installer overwrites the entire partition that it is installed on, and will overwrite GRUB on MBR systems preventing Linux operating systems from booting. For this reason it is recommended to install Windows before installing Ubuntu in a dual boot.  .  ",
      "P-tags": "partit 18 04 system-instal windows-10",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "ul_173",
      "task": "How to compile and install programs from source",
      "P-task": "compil instal program sourc",
      "F_verb": "install",
      "P-body": "Normally, the project will have a website with instructions for how to build and install it. Google for that first. .  For the most part you will do either: .   Download a tarball (tar.gz or tar.bz2 file), which is a release of a specific version of the source code Extract the tarball with a command like \"tar zxvf myapp.tar.gz\" for a gzipped tarball or \"tar jxvf myapp.tar.bz2\" for a bzipped tarball cd into the directory created above run \"./configure && make && sudo make install\"  Or: .   Use git or svn or whatever to pull the latest source code from their official source repository cd into the directory created above run \"./autogen.sh && make && sudo make install\"  Both configure and autogen.sh will accept a --prefix argument to specify where the software is installed. I recommend checking out Where should I put software I compile myself? for advice on the best place to install custom-built software. .  ",
      "P-tags": "sourc compil software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP from NP"
    },
    {
      "id": "au_977220",
      "task": "How can I enable horizontal window tiling on Ubuntu 17.10",
      "P-task": "enabl horizont window tile ubuntu 17 10",
      "F_verb": "enable",
      "P-body": "I now have the behavior I want, I can tile my windows left, right, all four corners, top half and bottom half. Here is what I did for anyone who wants to know: .  I installed the ShellTile extension for GNOME Shell. .  After installing that, I faced another issue. ShellTile was working but it's functionality was being replaced by the default tiling behavior. .  This forum post explains how to remove the default tiling behavior, in favor of ShellTile's. .  I was told to type: .  \"gsettings set org.gnome.shell.overrides edge-tiling false\" .  But that didn't work, so I ended up going with the second answer and installed dconf-editor by typing: .  \"sudo apt-get install dconf-editor\" .  Here are the instructions for what to do next: .    You need dconf-editor. Install it per your distribution's recommendations. I'm running Fedora 17 at the moment and this is the command line incantation I used: sudo yum install dconf-editor. Launch dconf-editor. On the left you will see a simple menu with five entries. Click on the plus sign to the left of org. New menu entires will drop down beneath it. Click on the plus sign to the left of gnome. Scroll down, then click on the plus sign to the left of mutter. Click on mutter next to the plus sign to highlight it. Several entries will appear in the large window to the right. If the edge-tiling entry is checked, click it to uncheck it. If it is already unchecked, leave it unchecked. Scroll down the left panel and click on the plus sign to the left of shell. Go to the overrides entry below shell and click on it. Again, you are looking for the edge-tiling entry in the right window. Make sure it is not checked. Close dconf-editor.  Note: This turns off all edge-tiling. The Gnome Shell effect that snaps a window to the left or right side of the screen and opens it to one-half screenwidth will not work after disabling edge-tiling. If you decide to get it back, return to dconf-editor and re-enable it. .   That's basically it. I give thanks to Hi-Angel and pomsky for mentioning ShellTile. I hope this helps someone else who wants the same functionality I wanted. .  Thanks again. .  ",
      "P-tags": "window-manag 17 10 tile",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_574293",
      "task": "After creating a team connection with NetworkManager, on reboot disappear with strange results",
      "P-task": "creat team connect networkmanag reboot disappear strang result",
      "F_verb": "create",
      "P-body": "Solution found, this line .  make the system a little confused and rename the enp1s0(physical) to team0(virtual). Removing this line and redoing the other works fine even on reboot, to get the same ip from dhcp I use this configuration way .  ",
      "P-tags": "bond network networkmanag",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP on NP with NP"
    },
    {
      "id": "ul_273577",
      "task": "Compare 1st column of the 1st file and 2nd column of the 2nd file and get the the output as following",
      "P-task": "compar 1st column 1st file 2nd column 2nd file get output follow",
      "F_verb": "compare",
      "P-body": "With \"awk\": .  If the spacing is important (it isn't to most programs but can be for humans), you can do: .  ",
      "P-tags": "awk text-process",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_449234",
      "task": "How to make my Makefile compatible with Cygwin? (install: invalid user \u2018root\u2019)",
      "P-task": "make makefil compat cygwin\ninstal : invalid user root",
      "F_verb": "make",
      "P-body": " Here is an example of \"Cygwin\" compatible \"Makefile\": .  When you want to install at any other location you can override the variable \"DESTDIR\" or provide one in the \"Makefile\". .  When you run the script as \"sudo\" in \"GNU/Linux\" the \"USER_ID\" is set as root. .  Note: Currently verified it on \"GNU/Linux\". .  Editor's Notes: .   Verified in \"Cygwin\". .  Changed the way \"USER_ID\" and \"GROUP_ID\" are assigned to standard \"shell\" builtin. .  Added long options version with verbosity, in a comment. .  If you want to change the destination, you can simply invoke, for example: .    ",
      "P-tags": "cygwin software-instal make",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP with NP"
    },
    {
      "id": "so_3494492",
      "task": "Creating a shorter version of a bash command",
      "P-task": "creat shorter version bash command",
      "F_verb": "create",
      "P-body": " If you want to make this persistent across sessions, put it in your \".bashrc\" file. Don't forget to run \"source .bashrc\" afterwards to make bash aware of the changes. .  If you want to pass variables, an alias just isn't enough. You can make a function. As an example, consider the command \"lsall\" to list everything in a given directory (note this is just an example and thus very error prone): .  \"$N\"gets replaced with the Nth argument. .  ",
      "P-tags": "command-lin linux shell bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP"
    },
    {
      "id": "so_64108420",
      "task": "Get total number of rows selected or updated in bigquery with bq command",
      "P-task": "get total number row select updat bigqueri bq command",
      "F_verb": "update",
      "P-body": "This is a workaround solution: .  Select Statement: .  Update Statement: .  ",
      "P-tags": "google-bigqueri teradata shell",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP of NP in NP with NP"
    },
    {
      "id": "so_28269523",
      "task": "How to handle spaces in file path",
      "P-task": "handl space file path",
      "F_verb": "handle",
      "P-body": " If your file path contains whitespace, you will need to use a string literal: .  Make sure you use double quotes though so that variables are properly expanded. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_417080",
      "task": "Text Processing - Get 2 lines with exact text between them",
      "P-task": "text process - get 2 line exact text",
      "F_verb": "get",
      "P-body": "To delete back-to-back \"Start\" and \"End\" lines, this should do in GNU sed: .  if we see \"Start\", load the next line with \"N\", then see if the contents of the buffer are just \"Somename:Start\\nSomename:End\" with \"Somename\" same on both lines (\"\\n\" is a newline). If so, delete it. Here, \"\\1\" is a reference to the first group within \"\\(..\\)\", and matches the same string that was encountered there. \".*\" just means any number (\"*\") of any characters (\".\"). .  Using \"sed -e '/Start/,/End/d'\" would indeed delete every single line, since the range matches all lines between the starting and ending patterns. Everything in the input is between \"Start\" and \"End\", so everything is deleted. .  ",
      "P-tags": "awk sed text-process",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP between NP"
    },
    {
      "id": "au_1061474",
      "task": "How to replace a xml file line using sed",
      "P-task": "replac xml file line use sed",
      "F_verb": "replace",
      "P-body": "Insert the required chunk (\"<!--\") at start (\"^\"): .  Example: .   Just to note, to parse structured data like \"xml\", you should use a tool that understands the structure e.g. \"xmlstarlet\". .   Answer to the edited question: .  You can match precise substring at start and end, in the replacement use \"\\0\" to refer the whole match putting desired replacement substrings around: .  Example: .  ",
      "P-tags": "sed xml command-lin text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP using NP"
    },
    {
      "id": "so_42210337",
      "task": "Bash: find and concatenate files",
      "P-task": "bash : find concaten file",
      "F_verb": "find",
      "P-body": " \"find /home/DIR* -name '*csv'\" gives you the files absolute paths.  .  \"xargs cat\" will iterate the files and \"cat\" print the files content .  ",
      "P-tags": "csv bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_8240287",
      "task": "Ubuntu 11.04 - Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (13)",
      "P-task": "ubuntu 11 04 - connect local mysql server socket var run mysqld mysqld sock 13",
      "F_verb": "connect",
      "P-body": "You cannot (absolutely cannot) replace the filesystem pipe \"/var/run/mysqld/mysql.sock\" with a regular file. You need to use \"mkfifo(1)\" to create the \"pipe(7)\" that clients use to communicate with the mysql server. .  The \"(13)\" probably also means that you have a permission denied error return, \"EACCES\" (which usually has the decimal value \"13\" -- yes, I've seen it a lot). .  If the file system permissions are configured correctly, you might be having accesses rejected by a mandatory access control tool such as AppArmor, SELinux, TOMOYO, or SMACK. .  AppArmor comes pre-installed on Ubuntu systems by default, and might be rejecting access to the pipe. Check \"/var/log/syslog\", \"/var/log/audit/audit.log\" or \"dmesg(1)\" output for messages that look something like this: .  (But with \"name=/var/run/mysqld/mysql.sock\" instead.) .  If you have error messages like this, run \"aa-logprof\" as \"root\" and answer the questions. More information on configuration AppArmor can be found in the \"apparmor.d(5)\" manpage, or some various wiki pages. .  ",
      "P-tags": "ubuntu mysql ubuntu-11 04",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP through NP"
    },
    {
      "id": "ul_345106",
      "task": "How to install extenion php_intl in centos7?",
      "P-task": "instal extenion php_intl centos7",
      "F_verb": "install",
      "P-body": "You cannot install a windows \".dll\" on Linux OS .  To install \"php_intl\" on CentOS , you should enable \"remi\" repo . Open the terminal and run the following commands: .  Update your system then install the \"php-intl\": .  To permanently enable \"remi\" repo , open the terminal and run the following command: .  Set \"enabled=1\". .  ",
      "P-tags": "cento remind php7",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_63319",
      "task": "How to run kvm/qemu on a virtual terminal with kms enabled",
      "P-task": "run kvm qemu virtual termin km enabl",
      "F_verb": "run",
      "P-body": "As the error message states, SDL cannot access the mouse. If this error doesn't show as root (using \"sudo\"), this is probably a permissions problem. You should check the permissions of \"/dev/input/mice\". .  It is likely that once the mouse problem is fixed it will show the same behaviour as when run using \"sudo\". It might not be worth the trouble to try getting it running with framebuffer. Without knowing the details I'd say using X might a better solution. .  ",
      "P-tags": "sdl km virtual kvm framebuff",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP with NP"
    },
    {
      "id": "su_634866",
      "task": "Create alias or add path?",
      "P-task": "creat alia add path",
      "F_verb": "create",
      "P-body": "\"Better\" is a somewhat nebulous term, but I'd recommend adding the program's directory to \"$PATH\", because (unlike aliases) that will be inherited by subprocesses of your shell.  .  For example, if you start an editor from your shell and then want to run foo.sh from within the editor, as for example to compile the file you're editing or transform its text, then the editor will know where to find foo.sh; if you instead add an alias, you'd need to specify the full path to foo.sh when running it from the editor. .  ",
      "P-tags": "linux alia path",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "su_1303383",
      "task": "Adjusting Ubuntu filesystem to make use of enlarged partitions",
      "P-task": "adjust ubuntu filesystem make use enlarg partit",
      "F_verb": "adjust",
      "P-body": "As the partition size has changed, you'll need to update the size of the Physical Volume: .  This should output a value that is approximately the same size as the partition. .  Then, resize the Logical Volume: .  If the filesystem is not mounted, you should do a full filesystem check: (you can probably skip this) .  And finally resize the filesystem: .  ",
      "P-tags": "partit ubuntu virtual-machin virtualbox filesystem",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP S_INF of NP"
    },
    {
      "id": "so_50876289",
      "task": "How to escape 3 level in bash (su command, psql, then query)",
      "P-task": "escap 3 level bash su command psql queri",
      "F_verb": "escape",
      "P-body": "Let the shell do the work for you for you. In this case, that means \"printf '%q'\" -- which returns an \"eval\"-safe version of each literal argument. .  By the way, substituting literal text into SQL queries this way is massively insecure -- but if you follow the process above you're prone to only SQL injection bugs, not shell injection bugs. .   To avoid SQL injection bugs as well, you want to avoid textual substitution of values into your queries at all. .  See http://caryrobbins.com/dev/postgres-scripting/ for more on this technique. The classic XKCD linked in its header (also useful as a concrete example of the risks the original code was taking!) has its original source at https://xkcd.com/327/. .  ",
      "P-tags": "su psql escap bash",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP then NP"
    },
    {
      "id": "so_65394615",
      "task": "Homebrew: How to check if a homebrew service is switched on or not",
      "P-task": "homebrew : check homebrew servic switch",
      "F_verb": "check",
      "P-body": "\"brew services list\" gives the status of the services. so something like \"brew services list | grep elastiscearch | awk '{ print $2}'\" should return the status of the elastic search service, whether started or stopped .  ",
      "P-tags": "homebrew elasticsearch curl shell bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "su_1524529",
      "task": "How to fetch Rundeck Job output through terminal?",
      "P-task": "fetch rundeck job output termin",
      "F_verb": "fetch",
      "P-body": "So I got to a conclusion after a little looking around and fiddling the way to fetch the output would be to run this command as a local command: .  This should output the log. .  ",
      "P-tags": "termin script shell-script bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP through NP"
    },
    {
      "id": "ul_288365",
      "task": "On a OS X machine, how can remove a directory that has name \"--crm\"?",
      "P-task": "os x machin remov directori name -- crm",
      "F_verb": "remove",
      "P-body": "TBH this is probably more suited to one of the other .SE's, either Unix &Linux, Ask Different, or even SuperUser. Which is why I assume you've been downvoted. That said... .  The Short Answer The answer is \"rm -r ./--crm\", or better yet, \"rmdir ./--crm\". .   The Real Answer On OS X you're usually using Bash in the terminal, which is important to know: which shell you use helps determine the syntax of the basic statements that let you manipulate files and directories, which includes renaming, removing, or calling on the kernel to execute them. .  Along with \"man rm\", take a few days to read through \"man bash\" and learn some of the concepts there. .  Aside from this, it's a convention for most Unix command-line programs to run with specific arguments which follow the command. Some are obvious and work by passing data to the program. For instance, by running \"rm myfile\", you call the kernel to run the unlinking program on the file \"myfile\". Other arguments act like a set of switched to turn certain options on or off. These, sometimes known as 'flags', instead of passing data control the behavior of the program itself. For instance, \"rm -h\" will remove nothing, but instead prints a short block of helpful text. .  So the problem with removing a file with an unusual name, is that the program doesn't know how to interpret it. Throwing characters at it doesn't help either, and can get you into trouble. .  Using Bash: Why It Didn't Work Bash (your shell) interprets anything in single quotes literally, by stripping the quotes and taking the contents as-is. So by running \"rm '--crm'\", you're effectively running the same thing as \"rm --crm\". Bash specifically treats \"*\" as a special character, doing something we call 'globbing': before the programs you called is run, Bash will expand the argument to every matching pathname you specified. In effect, if you have in your directory .  and then run \"rm *crm\", Bash will first expand this, and then run the expanded version: .  ...so you run the risk of destroying all your files ending in 'crm', plus it simply interprets the first directory as a flag again. .  Using Bash: What Does Work What Bash needs to know, and all it needs to know, in order to treat your directory as a file to be removed, is what \"rm\" always needs: an explicit, fully qualified pathname. For most normal files, like \"myfile\" above, Bash is smart enough to know you normally mean the current working directory\u2014 the one you can change into, or out of, with \"cd\". There are two special characters devoted to helping manage this. \"cd ..\" for instance will take you to the directory 'above' your current one. If you're in /Users/foobar, and you run \"cd ..\", you'll move to /Users. Similarly, there's also the character denoting the current directory, which is simply \".\". Running \"cd .\" will take you... To the directory you're already in. Seems useless, doesn't it? .  But this gives us a method of telling Bash exactly where your unfortunately-named directory lives: in the current directory \".\" lives the file \"--crm\", so you can specify it, and remove it, using \"rm ./--crm\" \u2014 well, specifically this is a directory, and so you have to tell \"rm\" to descend and recurse through the directory, and remove everything it finds there, first. You do this with the \"-r\" flag: hence, \"rm -r ./--crm\". .  A final caveat: now that I've tried to explain all this, I hope you also understand the serious danger in running \"rm -r -f /\". You should never use the \"-f\" flag unless you know what you're doing. .  ",
      "P-tags": "directori",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP that S"
    },
    {
      "id": "so_21802754",
      "task": "Find and replace all the same words in one file in Shell",
      "P-task": "find replac word one file shell",
      "F_verb": "replace",
      "P-body": "It's really unclear what you are asking, but here is a guess: .  ",
      "P-tags": "sed replac shell bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "ul_320332",
      "task": "Force leading zeros in echo of base conversion",
      "P-task": "forc lead zero echo base convers",
      "F_verb": "echo",
      "P-body": "Use \"printf\" to format the numbers: .  Also, no need to put empty string after \"$i\", and no need to quantify \"{1}\" in the regex. .  It might be faster to use brace expansion in zsh, ksh93, bash or \"yash -o braceexpand\": .  ",
      "P-tags": "convers echo sed",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V of NP"
    },
    {
      "id": "su_1513870",
      "task": "runlevel + how to force multi user mode from run-level 3",
      "P-task": "runlevel + forc multi user mode run-level 3",
      "F_verb": "force",
      "P-body": "run level 3 is multiuser, 5 is graphical. RHEL 7 uses systemd instead of system v, and the runlevel is replaced by systemd targets. it can be changed with sytsemctl: .  https://www.thegeekdiary.com/centos-rhel-7-how-to-change-runlevels-in-rhel7-with-systemd/ .  ",
      "P-tags": "redhat-enterprise-linux runlevel linux",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_399127",
      "task": "Use find command to extract lines from text files in subfolder",
      "P-task": "use find command extract line text file subfold",
      "F_verb": "find",
      "P-body": "Just do .  Or you can use \"exit\" handler, which it will exit after print first line and better when you only want to print first line and not required \"awk\" to process whole file till the end of it. .  ",
      "P-tags": "awk find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP S_INF from NP in NP"
    },
    {
      "id": "au_313231",
      "task": "How to figure out if my DVD-reader is also a burner?",
      "P-task": "figur dvd-reader also burner",
      "F_verb": "figure",
      "P-body": "Here's an alternative.  .   Open a new Terminal window with Ctrl+Alt+T and type in the following: \"sudo apt-get install libcdio-utils\" Now there's a tool called \"cd-drive\" in the utility you've just installed. So in your Terminal run \"sudo cd-drive\" and hit enter.  The output should look like this: .  ",
      "P-tags": "disk dvd",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V if S"
    },
    {
      "id": "so_61761514",
      "task": "Use inotifywait to change filename and further loop through sql loader",
      "P-task": "use inotifywait chang filenam loop sql loader",
      "F_verb": "change",
      "P-body": "I have modified your script to this, .   Remove the \"echo\" if you think the output is correct. I just don't know how you can integrate the other parts of your script with that, probably create a separate script or remove the \"-m\" (which you don't want to do most probably). Well you could use a named pipe if \"mkfifo\" is available.   EDIT: as per OP's message add another parameter expansion for another string removal. .  Add the code below the \"if [[ ... ]]; then\" .  Then change \"\"${filename// /_}\"\" to \"\"${newfilename// /_}\"\" .  ",
      "P-tags": "sql-loader inotifywait bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP through NP"
    },
    {
      "id": "so_3597975",
      "task": "How to limit connection in Linux socket programming?",
      "P-task": "limit connect linux socket program",
      "F_verb": "limit",
      "P-body": "Simple. At the point where you call \"accept()\", something like this: .  (and of course decrement \"total_connections\" at the point where you lose a connection). .  ",
      "P-tags": "linux c socket",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_440416",
      "task": "Duplicity - save backup to multiple destinations",
      "P-task": "duplic - save backup multipl destin",
      "F_verb": "save",
      "P-body": "According to the github of duplicity, this feature is still in the to do list. I think the easier way is to make a small shell script that will move the file at the end the process. .  It's a code sample it needs to be tested .  The idea is if duplicity return 0 (no error) on the local backup then it runs rsync to send the file to the remote \"host.com\" and if one of the commands fails a small error message is written. .  ",
      "P-tags": "sftp shell-script backup duplic",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP to NP"
    },
    {
      "id": "so_47085262",
      "task": "Powershell error setting Environment variable for an SSIS package execution",
      "P-task": "powershel error set environ variabl ssi packag execut",
      "F_verb": "set",
      "P-body": "So with some digging I found the answer to my error. Turned out I had multiple versions (11.0.0.0, 12.0.0.0, 13.0.0.0) of the assembly Microsoft.SqlServer.Management.IntegrationServices in my GAC (Windows\\assembly). Examining the schema of the SSISDB catalog, it was version 12.0.5000.0, which meant I needed the 12.0.0.0 version of the assembly. The code I was using: .  was loading the wrong version (probably 13.0.0.0), so I needed to explicitly load the assembly version matching this installation of SSIS, which was 12.0.0.0: .  ",
      "P-tags": "powershel sql-server-2012 sql-server ssi",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_50175688",
      "task": "determining the optimal buffer size for file read in linux",
      "P-task": "determin optim buffer size file read linux",
      "F_verb": "determine",
      "P-body": "You did not disable the line \"#define SIZE 100\" in your source code so the definition via option (\"-DSIZE=1000\") does have influence only above this \"#define\". On my compiler I get a warning for this (\"<command-line>:0:0: note: this is the location of the previous definition\") at compile time. .  If you comment out the \"#define\" you should be able to fix this error. .  Another aspect which comes to mind: .  If you create a file on a machine and read it right away after that, it will be in the OS's disk cache (which is large enough to store all of this file), so the actual disk block size won't have much of an influence here. .  Stevens's book was written in 1992 when RAM was way more expensive than today, so maybe some information in there is outdated. I also doubt that newer editions of the book have taken things like these out because in general they are still true. .  ",
      "P-tags": "system-cal unix linux perform filesystem",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_39903323",
      "task": "Hash MD5 via PHP showing different result than via Unix Terminal",
      "P-task": "hash md5 via php show differ result via unix termin",
      "F_verb": "hash",
      "P-body": "You can generate this same hash using PHP functions, with no shell call. .  Like this: .  Working example: https://3v4l.org/KkR9v .  ",
      "P-tags": "termin php unix linux hash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP via NP via NP"
    },
    {
      "id": "ul_596940",
      "task": "Error: find argument list too long and -maxdepth 0 is not helping, directory contains many files",
      "P-task": "error : find argument list long -maxdepth 0 help directori contain mani file",
      "F_verb": "find",
      "P-body": " will expand to .  If you have too many file, this cause error you've seen. .  If there is no subdir, you can skip \"-maxdepth 0\" and \"-type f\" .  what you want is .  a final word, if you append \"> /dev/null\", just drop \"-ls\" .  ",
      "P-tags": "ls delet find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_44034901",
      "task": "Get-Credential for IIS FTP User with Virtual Host Name Prefix?",
      "P-task": "get-credenti ii ftp user virtual host name prefix",
      "F_verb": "get",
      "P-body": "One workaround which doesn't use Get-Credential: .  Verifying the password: .  ",
      "P-tags": "powershel secur ii ftp",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP with NP"
    },
    {
      "id": "su_1315891",
      "task": "Hiding your password when typed as an argument into a bash shell / command prompt?",
      "P-task": "hide password type argument bash shell command prompt",
      "F_verb": "hide",
      "P-body": "I don't get much to know, by the details you provided, however I assume the question title itself makes all of it and will answer that : .   Hiding your password when typed as an argument into a bash shell / command prompt ? .   Being a linux user, I would answer it for \"bash shell\". You can write a shell script that prompts for password like this. .  Here \"-s\" in read command means \"suppress\" that suppress the output stream to show anything. Thus having your password invisible when you type it. .  \"NOTE\" : It works in a shell script, but to make it work in applications such as weechat, you have to change the underlying code or better write a shell script that does it when you open the app for the first time. .  To read more on this topic follow this and this  .  Feel free to add-in more details. .  ",
      "P-tags": "command-lin linux ssh bash powershel",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V NP when S"
    },
    {
      "id": "so_1063333",
      "task": "Using PowerShell to download XML, and save as CSV file?",
      "P-task": "use powershel download xml save csv file",
      "F_verb": "download",
      "P-body": "you could do something like: .  ",
      "P-tags": "powershel xml csv",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_496531",
      "task": "How to find out which mount argument is invalid?",
      "P-task": "find mount argument invalid",
      "F_verb": "find",
      "P-body": "\"dmesg\" shows the kernel log. .  Sometimes this has more information, sometimes it does not. .  There is a future kernel interface that might help. It might help in that it will allow setting options in a series of individual calls - e.g. so I hope that if you pass a number which was way out of range, the kernel might tell you as soon as you pass that option. Perhaps the most interesting part of the new interface is that it will allow filesystems to directly return a specific error message. At the moment, they can only return one of a few set error numbers, such as your error 22 (EINVAL / \"Invalid argument\"). .  A new API for mounting filesystems -- LWN.net, May 4, 2018. .  This API has seen some continued work in the past few months. .  ",
      "P-tags": "mount linux ubuntu",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V which S"
    },
    {
      "id": "so_1753366",
      "task": "Redirect output to a bash array",
      "P-task": "redirect output bash array",
      "F_verb": "redirect",
      "P-body": "do you really need an array .  bash .  if you want to put into array .  @OP, regarding your method: set your IFS to a space .  Also, there is no need to use so many tools. you can just use awk, or simply the bash shell .  output .  gawk .  ",
      "P-tags": "redirect shell bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1341643",
      "task": "\"Matplotlib is currently using agg, which is non-GUI backend, so cannot show the figure.\" error when trying to plot with Matplotlib on Ubuntu 20.04",
      "P-task": "matplotlib current use agg non-gui backend show figur\nerror tri plot matplotlib ubuntu 20 04",
      "F_verb": "use",
      "P-body": "Yes, you have to. The accepted answer to this similar Stack Overflow question suggests that the problem is that \"tkinter\" is not installed. You can install it using: .  ",
      "P-tags": "python3 matplotlib 20 04",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP which S"
    },
    {
      "id": "so_6617255",
      "task": "Using sed to find a folder directory in a file and replacing with another directory",
      "P-task": "use sed find folder directori file replac anoth directori",
      "F_verb": "replace",
      "P-body": " ",
      "P-tags": "sed shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V with NP"
    },
    {
      "id": "so_55063054",
      "task": "Cannot connect using Connect-MsolService",
      "P-task": "connect use connect-msolservic",
      "F_verb": "connect",
      "P-body": "You should install the latest AzureAD module. https://docs.microsoft.com/en-us/powershell/module/azuread/ .  Logon with \"Connect-AzureAD\" .  Confirm Domain with \"Confirm-AzureADDomain\" .  ",
      "P-tags": "azur powershel",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V using NP"
    },
    {
      "id": "su_650741",
      "task": "Linux system login: How to use /etc/passwd to filter user name again ldap",
      "P-task": "linux system login : use etc passwd filter user name ldap",
      "F_verb": "use",
      "P-body": "For allowing only a subset of LDAP users to login: .   If you have a way to filter them without modifying the LDAP server, then you can add the filter to your \"/etc/nslcd.conf\" file, e.g.: .   Otherwise, you'll have to allow all LDAP users as local users and grant permissions just to the ones that you want, e.g., by changing \"/etc/security/access.conf\" and/or \"/etc/ssh/sshd_config\". .   For having additional local users, on top of those from the LDAP server, you'll need your \"/etc/nsswitch.conf\" file to contain something like: .  I hope I'm not forgetting something... .  ",
      "P-tags": "ldap linux authent",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_23578453",
      "task": "Run command line using setup factory",
      "P-task": "run command line use setup factori",
      "F_verb": "run",
      "P-body": "on-startup(before setup begin) .  runscript(\"NameOfYourPowerShell.ps1\"); .   ",
      "P-tags": "powershel instal",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP using NP"
    },
    {
      "id": "so_36213496",
      "task": "Program still wants to take input even if the all pipes are closed",
      "P-task": "program still want take input even pipe close",
      "F_verb": "take",
      "P-body": "The top level process is not closing the pipe. Since the parent process is really just a coordinator and doesn't actually use the pipe it needs to close both ends once all the last \"fork\" call has been made. One way to do this is to add the close code into the \"else\" case. For example: .  ",
      "P-tags": "system-cal pipe linux fork c",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP if S"
    },
    {
      "id": "au_514105",
      "task": "Compare strings in two files",
      "P-task": "compar string two file",
      "F_verb": "compare",
      "P-body": "You can use the join command .  username file has the format .  contacts has the format .  When the file is not sorted then you can do the following .  and then run the join command on username.sorted and contacts.sorted .  or as another post pointed out you can do it directly using  .  ",
      "P-tags": "script text-process",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_99032",
      "task": "How do I track down the source of a ssh login message?",
      "P-task": "track sourc ssh login messag",
      "F_verb": "track",
      "P-body": "Updated answer based on some researching Remove duplicated welcome messages  Since you login with ssh, the first welcome message should be coming from \"/etc/issue.net\". To remove the message, just remove the contents of that file. To remove the second welcome message, remove the contents of \"/etc/motd\".  Colorize the line about mail To colorize that line, the easiest option I can think of requires quite a bit of low-level work: the option is that you modify and build \"pam_mail.so\" yourself. .  These are the steps for modifying it and installing the modified version  Download Linux-PAM source from linux-pam.org (the official project site). Extract the source (this will create a new directory named \"Linux-PAM-1.1.8\") and cd to it: .   Change the following lines (the lines which begins with \"+\", 4 lines at all) in file \"modules/pam_mail/pam_mail.c\" to be as the following diff shows (produced with \"diff -u\")(the filename \"pam_mail.c.new\" is just my temporary file that I could produce that diff): .  I have simply added \"\\\\033[0;1;31m\" to the beginning of those messages and \"\\\\033[0m\" to the end of those messages. .  Note: Now it displays those messages as red; from ascii-table.com page about Ansi Escape Sequences under title Set Graphics Mode you can find more complete list about colors and other tricks about customising terminal output. .  Compile it (Note: from here to the end I assume that your working directory is \"Linux-PAM-1.1.8\", the very same directory to which we cd'd at the beginning, i.e. the \"root\" directory of the Linux-PAM package): .   Backup your existing \"pam_mail.so\" in case that the new one breaks your system (I doubt it will break, but it's always good to have the original file in safe): .   Copy the file \"modules/pam_mail/.libs/pam_mail.so\" to \"/lib/i386-linux-gnu/security/\": .   Log out and again in (or start a new ssh session, whatever), and you should see red \"No mail.\" message (assuming you have no new mail). .   The old, obsolete answer The mail message can be disabled by changing the following line in file \"/etc/pam.d/system-login\" from .  to .  Reference from archlinux's forums. .  The text before the mail information is in \"/etc/motd\", and you can disable it to be printed when login with ssh by putting the following line to \"~/.ssh/config\": .  ",
      "P-tags": "mail-command script bashrc login profil",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "su_543467",
      "task": "Renaming computers via command prompt",
      "P-task": "renam comput via command prompt",
      "F_verb": "rename",
      "P-body": "I haven't used this myself, but a quick google brings this command back a lot .  If the computer name has dashes or other special characters you need to quote the computer name .  Source .  ",
      "P-tags": "powershel windows-7 windows-8",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP via NP"
    },
    {
      "id": "su_424904",
      "task": "brew doctor giving error on a directory that has been removed",
      "P-task": "brew doctor give error directori remov",
      "F_verb": "give",
      "P-body": "You need to edit your PATH variable. .  You need to start by finding where your PATH is currently being set, it is most likely \"~/.bash_profile\", but it could be set elsewhere. .  Your PATH is the list of directories that Bash (and other shells) looks in when looking for commands. It is what saves you from having to type \"/usr/bin/local/programname\" every time you want to run \"programname\". You merely add \"/usr/bin/local\" to your path and bash indexes everything in that folder. .  ",
      "P-tags": "homebrew maco path bash bash-profil",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP on NP that S"
    },
    {
      "id": "ul_252302",
      "task": "Simulate sed read command with awk",
      "P-task": "simul sed read command awk",
      "F_verb": "simulate",
      "P-body": "An easier way can be: .  or: .  With this approach, you only need to care about the \"awk.scr\", \"awk\" will process \"awk.script\" for you. .  ",
      "P-tags": "awk sed text-process",
      "source": "qa",
      "cate": "simulate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_31890970",
      "task": "Easy way to get result status code of \"systemd-run <command>\"?",
      "P-task": "easi way get result statu code systemd-run command",
      "F_verb": "get",
      "P-body": " It seems the result status code of systemd-run is always 0 unless invoking the run-time systemd unit fails. .   Yes, that's the correct and expected behaviour.. systemd-run does not run the command by itself in this particular case. it creates, validates and en-queues a transient .service file with the parameters you choose, which then started by either the \"--system\" or \"--user\" service manager. To get what you want .. TL;DR .  Note that in this case, the scope unit will inherit the environment of the calling script and execution only returns when the command finishes.. .  ",
      "P-tags": "systemd linux virtual",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_508187",
      "task": "How to get rid of this error",
      "P-task": "get rid error",
      "F_verb": "get",
      "P-body": "Did you do \"sudo apt-get install ubuntu-restricted-extras\"? Although try installing videoplayers VLC and SMplayer, they have bundled plugin version with them.  .  ",
      "P-tags": "video plugin multimedia sound",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_16181447",
      "task": "preventing mongodb from accepting non-local connections",
      "P-task": "prevent mongodb accept non-loc connect",
      "F_verb": "prevent",
      "P-body": "From http://docs.mongodb.org/manual/reference/configuration-options/: .   \"bind_ip\" Default: All interfaces. .  Set this option to configure the mongod or mongos process to bind to and listen for connections from applications on this address. You may attach mongod or mongos instances to any interface; however, if you attach the process to a publicly accessible interface, implement proper authentication or firewall restrictions to protect the integrity of your database. .   Setting that to an address that's only internally accessible (or in extreme, only accessible by processes on that host, ex \"127.0.0.1\") will likely do what you want. .  ",
      "P-tags": "mongodb network unix",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING"
    },
    {
      "id": "so_33478230",
      "task": "Reading in C line by line and storing in an array",
      "P-task": "read c line line store array",
      "F_verb": "read",
      "P-body": "This line .  doesn't do what you want; it copies the address of the \"line\" buffer to \"filenames[counter]\"; all of your \"filenames[i]\" point to \"line\", so when you print \"filenames[2]\", it will print out the last thing read into \"line\". .  If you want to copy the contents of \"line\" to \"filenames[counter]\", you'll need to allocate memory to hold the copy using \"malloc\" or \"calloc\" and then copy the contents using \"strcpy\" (or use \"strdup\" if you have it available): .  or .  You'll need to \"free\" each \"filenames[i]\" when you're done. .  Alternately, you can declare the \"filenames\" array as a 2D array of \"char\": .  and read directly into the array: .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V in NP by NP"
    },
    {
      "id": "so_18122162",
      "task": "Update a SharePoint user field to only accept people - Powershell",
      "P-task": "updat sharepoint user field accept peopl - powershel",
      "F_verb": "update",
      "P-body": "You would set the selection mode for the field prior to updating. The two options are presented below: .  ",
      "P-tags": "powershel sharepoint",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP to NP"
    },
    {
      "id": "so_7840728",
      "task": "How to take a float to a power of another float number?",
      "P-task": "take float power anoth float number",
      "F_verb": "take",
      "P-body": "Here it is in perl: .  ",
      "P-tags": "awk script shell bash sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "au_544358",
      "task": "how to run an application with a command in terminal from all users",
      "P-task": "run applic command termin user",
      "F_verb": "run",
      "P-body": "Copy the file over to a directory that is in everyone's \"$PATH\". You can check the path with \"echo $PATH\". This should be a default path:  .  My suggestion would be the bin directory in local. So that would be .  Avoid general bin directories like /bin, /usr/bin, /sbin and /usr/sbin. Keep those directories clean so you know where your system files and your personal files are. .   I would also advice something else: if possible (ie. those users are similar in permissions) you can also add both users to the same group. That way permisssions for one also apply to the other. .  ",
      "P-tags": "command-lin",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP in NP from NP"
    },
    {
      "id": "au_606188",
      "task": "How can I mount a drive that does not want to mount?",
      "P-task": "mount drive want mount",
      "F_verb": "mount",
      "P-body": "I see a problem with your commands: \"/dev/sdg1\" in the 1st error. \"/dev/sdf\" in the 2nd error. \"g-io-error-quark, 19\" means \"Method name you invoked isn\u2019t known by the object you invoked it on.\" So I would assume your 1st command has an invalid device and it should be \"/dev/sdf1\". .  Regarding the superblock error: start here and read the link in post 2  .   So how the hell you are gonna Surviving a Filesystem Failures? Most of time fsck (front end to ext2/ext3 utility) can fix the problem, first simply run e2fsck - to check a Linux ext2/ext3 file system, first unmount /dev/sdf1 then type following command : .     Is it possible to recover data from an unknown partition? .   Yes as explained above: \"fschk\" can be used to fix your partition .  ",
      "P-tags": "mount data-recoveri hard-driv backup",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP that S"
    },
    {
      "id": "ul_533439",
      "task": "Install Let's Encrypt SSL certificate on Oracle Linux Server",
      "P-task": "instal let encrypt ssl certif oracl linux server",
      "F_verb": "install",
      "P-body": "I believe this should be comparable to CentOS 7.6. The path \"etc/ssl/certs\" is simply a symbolic link to \"/etc/pki/tls/certs/\". The certificate is divided into two parts, the first which you have already mentioned is the *.crt file which contains the public key and shall be placed in \"/etc/pki/tls/certs/\" which is in my case \"certificate.crt\", while the other part is the private key, and shall be placed in \"/etc/pki/tls/private/\", usually has *.key extension, in my case \"private.key\". .  In case you are using Apache web server, here is a working example of my \"redmine.conf\", it should be enough to guide you thru: .  I almost forgot to mention - which might solve your problem - is that you need to make sure that you have firewall rules in place, and permanent ones as follows: .  Also, make sure you have SeLinux disabled in case you have not changed its rules for your web service. .  ",
      "P-tags": "command-lin letsencrypt ssl oracle-vm-serv oracle-linux",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_186291",
      "task": "Assigning middle button to left scroll, Logitech M505",
      "P-task": "assign middl button left scroll logitech m505",
      "F_verb": "assign",
      "P-body": "I figured out how to do this. .  First use xev to find out the \"button numbers\". Type xev in the terminal, and click on the buttons of your mouse in the newly opened white window. Many lines appear in the terminal, such as these: .  The \"button 1\" is the number, in my case, for left-click. .  I wanted to switch left scroll with middle button, which were 6 and 2 respectively. .  The next step is to learn the id of the input device: .  Mine had such an entry for the Logitech mouse: .  Then, I type the following to map button 2 to 6, and vice versa, for the input device with id 10: .  This is only going to be temporary, and be gone when you reboot. To make it permanent, you could edit the xorg.conf file, but doing so caused problems for me, and the system did not boot. Instead, I created an entry in startup applications, writing the last xinput command as the command. .  This has one drawback -- the id has to stay the same. However, I do not know when and why it changes, as mine seem to stay the same. If I was to guess, I'd say that plugging the usb receiver in another usb port could change the id. I am not sure. .  ",
      "P-tags": "12 04 mous",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "au_1277067",
      "task": "Can't connect to a specific WiFi network (Ubuntu 20.04)",
      "P-task": "connect specif wifi network ubuntu 20 04",
      "F_verb": "connect",
      "P-body": "open .  forget all connections and then edit your connection and choose specific band and channel number of your connection .  worked for me check for yours .  ",
      "P-tags": "password wireless router",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "au_405931",
      "task": "How to set up DBus query to get play state of VLC?",
      "P-task": "set dbu queri get play state vlc",
      "F_verb": "set",
      "P-body": "My solution written in C is what I settled on. It is a daemon that uses the low level DBus API to call methods on VLC to get the playback status and ask VLC to quit if it is stopped. The bash and python scripts were not reliable when run as Ubuntu Startup Applications, which is what I wanted. IIRC, the bash and python versions had to be manually run from a terminal to work. .  Bash solution using GDBus (was installed by default on my Ubuntu 12.04): .  Python This is how I set up a DBus query to get the play state of VLC using Python and the \"python-dbus\" module: .  ",
      "P-tags": "vlc dbu",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP S_INF of NP"
    },
    {
      "id": "su_349694",
      "task": "How to disable Guest Access from Terminal in Mac OS X?",
      "P-task": "disabl guest access termin mac os x",
      "F_verb": "disable",
      "P-body": "On OS X Lion, the preference is internally realized as two separate options: .  In \"/Library/Preferences/com.apple.AppleFileServer\", it's the \"guestAccess\" flag, and in \"/Library/Preferences/SystemConfiguration/com.apple.smb.server.plist\", it's the \"AllowGuestAccess\" flag. .  To change these, execute the following with \"root\" permissions: .  Not sure if these are the same in previous versions of OS X. Use \"defaults read <path>\" to find out if these options exist on your system. .  You might need to relaunch the sharing service for the changes to take effect. .  ",
      "P-tags": "cocoa termin maco bash",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_50513963",
      "task": "make: *** No targets specified and no makefile found. Stop. [ubuntu]",
      "P-task": "make : target specifi makefil found\nstop\nubuntu",
      "F_verb": "find",
      "P-body": "It always depends on your CMake \"Generator\". The 'make' is linux/mingw tool/command. For VisualStudio you can use nmake or sln/proj generated stuff. .  More reliable could be utilize CMake for building i.e. for \"NMake Makefiles\" generator: .  or .  for VisualStudio generator .  ",
      "P-tags": "c++ ubuntu cmake",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "au_96892",
      "task": "How do you install less css command line compiler?",
      "P-task": "instal less css command line compil",
      "F_verb": "install",
      "P-body": "I'm not entirely sure if by compiler you want something that will automatically compile your less files on the fly or on the server. Because otherwise you can  .  (On Ubuntu 12.04, the \"node-less\" package is called \"node-less\".) .  and then, .  ",
      "P-tags": "rubi css npm",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_448682",
      "task": "How to modify a find function loop to handle backslashes and whitespaces?",
      "P-task": "modifi find function loop handl backslash whitespac",
      "F_verb": "modify",
      "P-body": "\"find ... | xargs ...\" and \"find ... -exec ...\" are both better options than this: to use a shell loop to iterate over find results correctly, we must use a \"while read\" loop: .  A lot to unpack there: .   we use a Process Substitution to execute the find command and be able to read from the results like it's a file. To read a line of input verbatim, the bash idiom is \"IFS= read -r line\". That allows arbitrary whitespace and backslashes to be read into the variable. \"read -d ''\" uses the null byte (as produced by \"-print0\") as the end-of-line character instead of newline.  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_23758052",
      "task": "Why is Python not using the working directory and how to fix it?",
      "P-task": "python use work directori fix",
      "F_verb": "use",
      "P-body": "The answer is right in the error message you posted: .  Looking at the source on github, the \"__init__\" for the \"Config\" class takes multiple parameters, all with defaults.  .  ...and in the docstring for the class, the \"base_dir\" parameter is explained: .  I suspect that if you pass in \"'/home/fedor/BR1311'\" to this \"__init__\" instead of changing to it, like: .  things will work much better. .  ",
      "P-tags": "linux python import python-import",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_60291384",
      "task": "Custom psobject truncating the results that are added using add-member",
      "P-task": "custom psobject truncat result ad use add-memb",
      "F_verb": "truncate",
      "P-body": "AdminOfThings provided the crucial pointer in a comment on the question: .  Preference variable \"$FormatEnumerationLimit\" controls how many elements of a collection-valued property to display in formatted output. .  E.g, \"$FormatEnumerationLimit = 2; [pscustomobject] @{ prop = 1, 2, 3 }\" prints (at most) 2 elements from \".prop\"'s value and hints at the existence of more with \"...\"; e.g., \"{1, 2...}\"). .   The default value is \"4\", but you can set it to an arbitrary positive value. .  \"-1\" places no limit on how many values are displayed, but note that with tabular output (implicit or explicit \"Format-Table\") the column width may still truncate the value list. .   Pipe to \"Format-List\" to ensure that all values are shown.   Caveat: Due to a bug as of PowerShell [Core] 7.0, setting \"$FormatEnumerationLimit\" is only effective in the global scope - see this GitHub issue. .   As a workaround in scripts, modify the global copy, \"$global:FormatEnumerationLimit\", temporarily (restore it to the original value before exiting the script).  ",
      "P-tags": "failoverclust powershel window windows-clust",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP that S"
    },
    {
      "id": "ul_164668",
      "task": "Updating Java on Linux",
      "P-task": "updat java linux",
      "F_verb": "update",
      "P-body": "It's perfectly fine to have several different java versions installed. By convention in Linux, software packages that aren't available through your package manager are usually installed under \"/opt\" or \"/usr/local/\". .  Just download Java 1.7 from Oracle and extract it to one of those locations. Then set your \"PATH\" or \"JAVA_HOME\" to include that location, depending on your use.  .  On Debian, you have a utility called \"update-java-alternatives\" that will allow you to set the default Java version. It seems you can do that with the \"alternatives\" command in SL as described in this forum post. .  ",
      "P-tags": "scientific-linux rpm java",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "so_51452172",
      "task": "How can I open an URL address from a file using firefox in an Unix/Linux console?",
      "P-task": "open url address file use firefox unix linux consol",
      "F_verb": "open",
      "P-body": " Pass the url in parameter. .  Or you may use .  as a simpler version. .  ",
      "P-tags": "url file shell bash firefox",
      "source": "qa",
      "cate": "open",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "so_20032172",
      "task": "PowerShell get applied windows updates HTML report",
      "P-task": "powershel get appli window updat html report",
      "F_verb": "get",
      "P-body": "I added a foreach-loop that goes through every update-event and removed the \"newobj\" code which seemed redundant. Does this work? .  ",
      "P-tags": "updat html report powershel window",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_39686251",
      "task": "Does all c++ code(exactly the same) will compile and work the same on Windows system as well as Linux Based system? and Why?[in c++] [RBIx]",
      "P-task": "c++ code exactli compil work window system well linux base system\nc++ rbix",
      "F_verb": "compile",
      "P-body": "There are many requirements for C++ code that must be met, if you want it to compile on two different OS: .   Does your code use OS-specific libraries? Such code won't compile on different platforms. Does your compiler provide appropriate extensions on OS \"A\" to support OS \"B\" libraries?  The best way would be to avoid both of these situations. Another question is: .   Does compiler on OS \"A\" use the same C++ standard version as compiler on OS \"B\"?  If you use features from \"C++14\" with \"C++14\"-supporting compiler on OS \"A\", but compiler on OS \"B\" does not support it, it simply won't compile. .   Why are same c++ programs in different versions (Windows version and Linux version)? .   Because C++ standard doesn't provide information about OS without some additional libraries or compiler extensions. There might be also some differences in string parsing that you use in your code, for example when opening files or writing to files. .   Why? and What code work in windows and not in Linux and vice versa? .   Why is that, see above. Only code that uses exacly the same C++ standard without any OS specific aspects will compile of different OS. You can hax this with conditionally compiled code,  .  see this. .   Is there any c++ code to find whether it is running in windows based system or Linux based system? .   Compilers should provide prefedined macros to check the target OS (see link above) .   Does all c++ code(exactly the same) will compile and work the same on MAC system as well as Linux Based system? .   No, definitely not all, reason given above. .  ",
      "P-tags": "c++ linux window",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP on NP as NP"
    },
    {
      "id": "so_66609154",
      "task": "Symlinks cannot be created in Powershell 5.1 but can be created by Powershell 7 and Command Prompt",
      "P-task": "symlink creat powershel 5 1 creat powershel 7 command prompt",
      "F_verb": "prompt",
      "P-body": "When Microsoft enabled non-admin symbolic link creation (with developer mode enabled) they did it in a way that all programs not coded to use it can't use it, and updated \"mklink\" to be able to use it. .  Obvious workaround: invoke \"mklink\" from Powershell via \"cmd /c\", which you have already discovered. .  ",
      "P-tags": "powershel window symlink",
      "source": "qa",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V"
    },
    {
      "id": "so_40218518",
      "task": "Unable to add default root no such device error in linux",
      "P-task": "unabl add default root devic error linux",
      "F_verb": "add",
      "P-body": "I find solution first i add route to another subnet .  \"route add e.f.g.h/32 dev eth0:1\" .  second i add: .  \"route add default gw e.f.g.h\" .  and my problem solved, i hope no one stick in this error . .  ",
      "P-tags": "linux gateway system-administr",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_62397127",
      "task": "Can I push a docker compose application for others to pull and run on their systems?",
      "P-task": "push docker compos applic other pull run system",
      "F_verb": "push",
      "P-body": "Docker Hub only allows you to upload images. As you've seen yourself, you can only publish the Python program. There are two ways you can allow consumers of your app to run both the services: .   In the documentation, such as on your Docker Hub repo's page, show what the Compose file should look like. Using this method, the consumer will have to write their own Compose file, but they'll copy-paste the other services exactly as you want them to. This is the recommended way, and is what other popular Docker Hub repos do. You can create a monolithic \"Dockerfile\". For example, keep \"ubuntu\" as the base image, use \"apt-get\" to download Python, Redis, etc., and \"RUN\" the required commands. This might seem easier, but it will prevent consumers from being able to spin up copies of services (e.g., they might want one Redis instance, but two Python instances).  Note: Also look into Docker App. .  ",
      "P-tags": "docker-compos redi docker python linux-contain",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP S_INF on NP"
    },
    {
      "id": "so_24799307",
      "task": "regarding generating a unique value for a set of numbers and regenerating the set of values when we pass back the same unique value",
      "P-task": "regard gener uniqu valu set number regener set valu pass back uniqu valu",
      "F_verb": "pass",
      "P-body": "Something like this? .  \"$valSet = array(1, 2, 3, 4, 5); $authNum = 5; if($authNum == $someInputByUser) { print $varSet; }\" .  Is this what you mean? .  ",
      "P-tags": "ksh php unix java sql",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V back NP"
    },
    {
      "id": "ul_110894",
      "task": "Find files newer than another file within each subdirectory",
      "P-task": "find file newer anoth file within subdirectori",
      "F_verb": "find",
      "P-body": " With your approach, you need to a shell to expand the \"MarkSheet*\" glob. So: .  ",
      "P-tags": "shell-script find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP within NP"
    },
    {
      "id": "au_792663",
      "task": "Start up script - ubuntu16",
      "P-task": "start script - ubuntu16",
      "F_verb": "start",
      "P-body": "one possible approach would be: .  Create the script with just root acces (for safety sake) .  Then change the sudoers file (according to mutliple tutorials everywhere) .  insert the following line at the end .  This grants your user to use the sudo command on exactly that script without password. This is the reason, why the root access permission is needed on the script - the script could get modified otherwise. .  Now add a custom startup command with the command .  Check with the command  .  if it worked. the result should be .  Hope that helps and meets your requirements. .  ",
      "P-tags": "script gnome 16 04 startup permiss",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V up NP"
    },
    {
      "id": "ul_631358",
      "task": "sed: replace patter by bash function output",
      "P-task": "sed : replac patter bash function output",
      "F_verb": "replace",
      "P-body": "Look closely at your sed invocation, it is missing the closing slash of s/// command. Next, you are using double quotes, so even before sed runs, the rhs of the s/// command has been filled in due to double quote interpolation. Which is not what you want. However, this still won't get you past the goalpost though. .  There is a little-known flag \"/e\" in the \"GNU sed's s///\" command. This is exactly what the doctor ordered in this case. What it does is, dynamically construct the rhs of the s/// command based on running the shell code given in the rhs and replacing it with it's output. Note: It requires the whole of the pattern space be matched. .  This also requires that your user defined function be exported to be available to the children. .   Note the use of single quotes in the sed command. .  ",
      "P-tags": "linux sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP by NP"
    },
    {
      "id": "so_19353037",
      "task": "Scala home directory for creating Scala project in IntelliJ IDEA",
      "P-task": "scala home directori creat scala project intellij idea",
      "F_verb": "create",
      "P-body": "The plugin wants to know where the Scala libraries are installed (as it would want to know where the Java SDK is located for a Java module). Note that for different Scala projects you might use different versions of Scala: 2.9.0 or 2.10.2, etc. The dialog offers to download them or you can go to the Scala site and download them yourself. For example, I downloaded scala-2.10.2.tgz from http://www.scala-lang.org/download/ and expanded it in /home/glenn/Applications/Scala/ to /home/glenn/Applications/Scala/scala-2.10.2/. This latter path is what goes in the \"Set Scala Home\" field in the dialog. .  Note that in my case this is preferable to using the apt-get installation of Scala because the API changes so much that I usually end up with different versions of Scala for different projects that I experiment with. .  Follow the version links at http://www.scala-lang.org/download/all.html to the version page with the download for the docs. .  Note that for me, IDEA wanted the docs to be in the \"doc/scala-devel-docs\" directory, whereas the downloaded docs decompressed to \"scala-docs-2.10.2\". I made a link so that IDEA can find them. My 2.10.2 directory looks like this, now. .  ",
      "P-tags": "scala ubuntu intellij-idea",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_7950794",
      "task": "how to convert multiline linux commands to one line of command",
      "P-task": "convert multilin linux command one line command",
      "F_verb": "convert",
      "P-body": "The GNU \"tar\" program can itself do the compression normally done by \"gzip\". You can use the \"-z\" flag to enable this. So the \"tar\" and \"gzip\" could be combined into: .  Getting \"tar\" to read from standard input for archiving is not a simple task but I would question its necessity in this particular case. .  The intent of \"tar\" is to be able to package up a multitude of files into a single archive file but, since it's only one file you're processing (the output stream from \"mysqldump\"), you don't need to \"tar\" it up, you can just pipe it straight into \"gzip\" itself: .  That's because \"gzip\" will compress standard input to standard output if you don't give it any file names. .  This removes the need for any (possibly very large) temporary files during the compression process. .  ",
      "P-tags": "linux mysql mysqldump shell",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "so_6043680",
      "task": "gdb disassemble: show function offsets in base 16",
      "P-task": "gdb disassembl : show function offset base 16",
      "F_verb": "disassemble",
      "P-body": "GDB currently uses hard-coded '%d' for the offset. .   It's very annoying to have to convert backtrace addresses ... to be able to find the desired instruction .   You do realize that you can simply do .  ",
      "P-tags": "gdb linux-kernel backtrack",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP in NP"
    },
    {
      "id": "su_1362588",
      "task": "Setting up rules in firewalld to allow clients in the same VPN subnet to communicate",
      "P-task": "set rule firewalld allow client vpn subnet commun",
      "F_verb": "set",
      "P-body": "In lack of other comments/answers I will share how I got it to work. I do not know if it is the best way but it works. .  I noticed that the zone vpn had targer = default. default is REJECT.  .  I added  .  Now I can ssh between clients. .  ",
      "P-tags": "firewalld linux vpn fedora wireguard",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP in NP S_INF in NP S_INF"
    },
    {
      "id": "au_313033",
      "task": "How can I see/stop current running crontab tasks?",
      "P-task": "see stop current run crontab task",
      "F_verb": "see",
      "P-body": "Firstly, use only one command per line in crontab. Change this crontab line: .  so it looks like: .  and create \"/path/to/my/crontab/script1.sh\" with this content: .  Of course, don't forget to give it execution permission: .   Secondly, you can see running crontab tasks, in a useful and readable format, in the output of: .  They will appear in the first lines, something like this: .  First column is PID, second is Session ID and third is the command started by cron. You can kill all the processes related to a specific cron task using the Session ID, so in the example above you should kill Session ID 4289: .  ",
      "P-tags": "wget cron",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "au_924889",
      "task": "Is it possible to use onboard in TTY?",
      "P-task": "possibl use onboard tti",
      "F_verb": "use",
      "P-body": "Start with an Ubuntu Server iso file or Ubuntu mini.iso I would select a 32-bit system for an old or weak computer, even if the computer has a 64-bit system because a 32-bit system uses less RAM. But it is also possible to select a 64-bit system or try both and decide afterwards which is the best in your particular case. .  After installing the basic system you can install a simple window manager like Openbox or Fluxbox, or plain LXDE (used in Lubuntu, but without the extra features of Lubuntu), Onboard, and your favourite application programs. It is possible to make the system boot into a text screen, and after that have the option to start the graphical user interface. .  Start with a compressed image of an installed 32-bit system You can also download a compressed image file with an installed 32-bit system built from Ubuntu \"mini.iso\" and tweaked to be easy to manage in order to expand into different final systems. .  This file is found at this link .  dd_X32-dus-lxde-Intl_2017-06-13_4GB.img.xz .  The md5sum is .  and the file expands to 4 GB on the target drive, so you need a drive with at least 4 GB. .  Login and password .  Please change the password. .  Links describing the system .  The descriptions at the following links can help you install and use the system in the new compressed image file, .  help.ubuntu.com/community/OBI/Xenial-32-txt (Xenial, the current version) .  UEFI-and-BIOS mini system with 'text' screen user interface (the 64-bit version) .  Text mode menu as seen after log in: .   .  LXDE graphical desktop environment with Onboard: .   .  ",
      "P-tags": "onboard tti",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_17603990",
      "task": "Why can shared libraries be located as one user, but not as another?",
      "P-task": "share librari locat one user anoth",
      "F_verb": "share",
      "P-body": "The entire directory path leading to the shared libraries must be accessible by \"otherUser\". Check all the folders in the path: .  \"otherUser\" should have access to \"usr\", \"local\", \"Trolltech\", \"Qt-4.8.5\", and \"lib\". .  In my specific case when I had this problem, the \"Trolltech\" directory was not accessible to \"otherUser\". .  ",
      "P-tags": "c++ linux shared-librari qt",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP as NP"
    },
    {
      "id": "so_52960629",
      "task": "How to use sed to replace string that contains slash?",
      "P-task": "use sed replac string contain slash",
      "F_verb": "use",
      "P-body": "You can change the delimiter: .  You can use this, if SigningTable appears once in the file: .  or be more specific: .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF that S"
    },
    {
      "id": "ul_592108",
      "task": "Install matching Linux header files after Linux kernel upgrade",
      "P-task": "instal match linux header file linux kernel upgrad",
      "F_verb": "install",
      "P-body": "Yes, this means the headers have been installed. .  See also the \"build\" and \"source\" symlinks in \"/lib/modules/$(uname -r)\" (those are the important locations). .  ",
      "P-tags": "upgrad linux-kernel header-fil",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP after NP"
    },
    {
      "id": "so_28352141",
      "task": "Convert a secure string to plain text",
      "P-task": "convert secur string plain text",
      "F_verb": "convert",
      "P-body": "You are close, but the parameter you pass to \"SecureStringToBSTR\" must be a \"SecureString\". You appear to be passing the result of \"ConvertFrom-SecureString\", which is an encrypted standard string. So call \"ConvertTo-SecureString\" on this before passing to \"SecureStringToBSTR\". .  ",
      "P-tags": "powershel securestr",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_42495463",
      "task": "How to make Mongodb 27017 port available on Ubuntu",
      "P-task": "make mongodb 27017 port avail ubuntu",
      "F_verb": "make",
      "P-body": "\"nmap\" scan all common port, mongodb use port \"27017\" by default which is not listed in default \"nmap\" default port scan. On the other hand, you can specify the port manually : .  You will get : .  If you see \"STATE\" close, this means mongodb is not running and then you should begin to worry about it .  Or as suggested by @Dimitri using \"netstat\" such as : .  which gives : .  ",
      "P-tags": "mongodb linux ubuntu",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP on NP"
    },
    {
      "id": "au_805445",
      "task": "Need to solve problems with not fully installed packages",
      "P-task": "need solv problem fulli instal packag",
      "F_verb": "solve",
      "P-body": "Run the following: .  ",
      "P-tags": "dpkg apt package-manag server",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP with NP"
    },
    {
      "id": "so_37457615",
      "task": "Why does Sqlite3 gets installed in /usr/local/bin instead of /usr/bin, while compiling and installing from source?",
      "P-task": "sqlite3 get instal usr local bin instead usr bin compil instal sourc",
      "F_verb": "compile",
      "P-body": "This has nothing to do with SQLite itself. .  Everything managed by your distribution is supposed to go into \"/usr\", while stuff that you've added manually is supposed to go into \"/usr/local\". This makes your additions independent from any distribution updates.) .  Therefore, the compilation scripts of most software use \"/usr/local\" as the default prefix, and your distribution would call somthing like \"./configure --prefix=/usr\" to generate its own package. .  ",
      "P-tags": "sqlite ubuntu-14 04",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V from NP"
    },
    {
      "id": "au_557414",
      "task": "How to make ts include year in prepended date?",
      "P-task": "make ts includ year prepend date",
      "F_verb": "make",
      "P-body": "From the manpage: .  For example: .  For the particular format requested: .  Consult \"man strftime\" for the various format specifiers available. .  ",
      "P-tags": "time",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_28224",
      "task": "How to grant a \"no-root-user\" rights to start/stop/restart mysql server on suse machine?",
      "P-task": "grant no-root-us right start stop restart mysql server suse machin",
      "F_verb": "grant",
      "P-body": " Change the setuid bit of the mysqld executable and the ownership of the executable file to the mysql account, besides adding the required user in the group \"mysql\" for making him have access to the files on the filesystem. .  Use \"visudo -f /etc/sudoers\" and grant him permission to execute the \"/etc/rc.d/init.d/mysql start\" and \"/etc/rc.d/init.d/mysql stop\" as two separate commands in the COMMAND list and in the execution part, grant the user to execute both the commands as user (mysql). For more information on sudoers, refer to the sudoers man page. \"man sudoers\". .  Apart from that, from a \"mysqld\" perspective, he may need additional grants on the Database server/databases to guarantee his workflow requirements, like tuning the tables, creating & dropping databases and tables, and performing some monitoring related activities with in a mysql session, etc. .   ",
      "P-tags": "privileg mysql",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF on NP"
    },
    {
      "id": "ul_49053",
      "task": "How do I add X days to date and get new date?",
      "P-task": "add x day date get new date",
      "F_verb": "add",
      "P-body": "You can just use the \"-d\" switch and provide a date to be calculated .    This is quite a powerful tool as you can do things like  .  or .  or .  So if $end_date=20131001 then $prog_end_date=20131011 .  ",
      "P-tags": "linux shell-script date bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_4470673",
      "task": "bash, find, exec and echo",
      "P-task": "bash find exec echo",
      "F_verb": "find",
      "P-body": "You have to escape the '>>', for example like this: .  ",
      "P-tags": "for-loop find command-lin bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_41994185",
      "task": "Getting Error when trying to install browser-sync ubuntu",
      "P-task": "get error tri instal browser-sync ubuntu",
      "F_verb": "get",
      "P-body": "I have Solved the issue:  .  NPM Module was not supported by node v7: .  So I downgraded to node v6.4.0 and it allowed me install browser-sync with no problems! .  ",
      "P-tags": "node js npm ubuntu browser-sync",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "so_40083122",
      "task": "Best way to convert a unix timestamp to javascript date-time",
      "P-task": "best way convert unix timestamp javascript date-tim",
      "F_verb": "convert",
      "P-body": " I think I will leave the am:pm bit to you. Press ctrl-shift j and play with your code in the console right here .  This might be easier to understand. I have kept it closer  .  ",
      "P-tags": "javascript unix",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "su_987929",
      "task": "\"file\" command yields \"ASCII text, with no line terminators\", unless I first edit the file in vim",
      "P-task": "file command yield ascii text line termin unless first edit file vim",
      "F_verb": "edit",
      "P-body": "The standard \"/bin/echo\" can be used to add that newline to the end of the file for you: .  Another option would be to add it in your Python code: .  ",
      "P-tags": "termin linux vim python ascii",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_16087564",
      "task": "how is `while(1)` optimized not to take all resources?",
      "P-task": "1 optim take resourc",
      "F_verb": "optimize",
      "P-body": " Is scanf a special case in that it is I/O and as such the OS schedules it out until a key is effectively pressed .   That's exactly what is happening. In this case \"scanf\" is a blocking operation. That is, if it can't be executed immediately (nothing in the input buffer) the OS simply puts your process to sleep, remembering to wake it up when something turns up. .   Can I somehow force it to be whileing all the time by say, adding a a++ inside the loop .   An \"a++\" won't change anything. You won't be able to peg the CPU as long as you have long-waiting blocking calls. .    until a key is effectively pressed .   In Linux input is usually \"cooked\". That is, pressing a single key isn't typically enough (you also need to hit return before your process gets a chance to look at the data). .   As Basile correctly mentions in the comments \"scanf\" itself may not always block. If there's enough input in the stdio buffer \"scanf\" will just return it. If not it will then call \"read(2)\" which can block. .  ",
      "P-tags": "linux c loop schedul",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V S_INF"
    },
    {
      "id": "so_63464160",
      "task": "Where to find further BlueZ logging and debugging output",
      "P-task": "find bluez log debug output",
      "F_verb": "find",
      "P-body": "Depends how you are starting \"bluetoothd\". .  If you are starting the daemon manually, then you can use the \"-d\" options. http://manpages.org/bluetoothd/8 .  Otherwise, use \"btmon\" in another terminal. http://manpages.org/btmon .  \"bluetoothctl\" communicates with \"bluetoothd\" using D-Bus which can be monitored with \"dbus-monitor --system\". http://manpages.org/dbus-monitor .  ",
      "P-tags": "bluetooth imx6 kernel linux bluez",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_16544739",
      "task": "Create a new file based on matching between two files",
      "P-task": "creat new file base match two file",
      "F_verb": "create",
      "P-body": "Using \"bash\": .  This uses process substitution (\"<(...)\"). You could probably also do it with: .  This tells \"fgrep\" to 'read the strings to be matched from standard input' (\"-f -\"). I've not verified that this works, but I'd expect it to do so. .  You can use \"grep -F\" in lieu of \"fgrep\" (but Mac OS X has \"fgrep\"). .  ",
      "P-tags": "sed unix maco grep",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP between NP"
    },
    {
      "id": "so_61576333",
      "task": "PowerShell to find traveling number",
      "P-task": "powershel find travel number",
      "F_verb": "find",
      "P-body": "If you want to grab the first single-digit number from a string: .  The regular expression pattern consists of: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_27318067",
      "task": "How to lookup a variable and use the outcome to match in PowerShell?",
      "P-task": "lookup variabl use outcom match powershel",
      "F_verb": "use",
      "P-body": "You need to use double quotes around variables. .  Try this: .  Result is: .  So to fix the script, use: .  which gives the result: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF in NP"
    },
    {
      "id": "so_47199317",
      "task": "Powershell - Delete every other line in all the files within a directory",
      "P-task": "powershel - delet everi line file within directori",
      "F_verb": "delete",
      "P-body": "You can use modulus to kill off alternating lines. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP within NP"
    },
    {
      "id": "ul_648847",
      "task": "How to connect with wifi in void linux from scratch",
      "P-task": "connect wifi void linux scratch",
      "F_verb": "connect",
      "P-body": " first one, you should be create a correct service by wpa_passphrase , don't confused between wpa_passphrase and wpa_supplicant, create service as bellow:   now, you must get your device name like \"wlan0\" ,by execute \"ip link\"   now ,run wpa-supplicant ,change wlan0 by your device name   finally , link service to runit by  if you want to test connection run .   if you reboot machin , it's not connect automatic , you should run wpa-supplucant again or add this line to \".profile\" or \".bash_profile\" or \"bashrc\" , for \"zsh\" add to \".zprofile\" \".zshrc\" , for \".xnitrc\" add with & at the end  ",
      "P-tags": "runit linux void-linux system-instal",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V with NP in NP from NP"
    },
    {
      "id": "ul_366048",
      "task": "Xenix / SCO V running in contemporary machines as VMs",
      "P-task": "xenix sco v run contemporari machin vm",
      "F_verb": "run",
      "P-body": "I encountered a very interested of couple of articles about a bug, post1 and post2 in the installation/disk driver that explained why it did not run in many hardware platforms over the years.  .  The link, besides explaining the bug, also points out VirtualBox seems to emulate the behaviour and is able to boot those operating systems. .  So I installed Virtualbox.  .  While it did not recognise an emulated SCSI disk, it recognised an emulated IDE disk < 250MB and got indeed into the installation phase. .   ...so I grabbed QEMU, and popped N1 in and booted it up. Unfortunately, the system would hang almost immediately after. Some testing revealed that the same issue existed on Bochs. PCjs got a bit further, but kernel panicked nearly immediately. Somewhat surprising to me though was VirtualBox not only booted, it got to the first step of the installer. .  The OS is extremely picky about the hardware and BIOS and won\u2019t boot at all in many virtualizers. It also contains an interesting bug in the AT disk driver (called \u2018wd1010\u2019 in this XENIX kernel version) which causes the system to hang if the controller, or more likely an IDE disk, responds \u201ctoo fast\u201d to the Set Drive Parameters command. .   P.S. There seems to be hints people managed to hack/patch the bug out. There is no documentation about that, and the process should be specific to the hacked versions. .  ",
      "P-tags": "virtual-machin sco osx vmware-fus",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP as NP"
    },
    {
      "id": "au_1263516",
      "task": "Unable to uninstall a package showing via apt list",
      "P-task": "unabl uninstal packag show via apt list",
      "F_verb": "uninstall",
      "P-body": "\"apt list | grep virtualbox\" lists the available packages in your software sources that can be installed with apt. You need to run the following command to list the packages that are currently installed with apt: .  Please note that this command will return an error message if you try to run it with apt-get instead of apt. .  This command will return a shorter list of packages because the results of \"sudo apt remove virtualbox-dkms virtualbox-source virtualbox-guest*\" show that many of the packages that are listed in the results are not currently installed. .  The results of \"dpkg --list | grep -i virtualbox\" show that these two packages are manually installed: virtualbox and virtualbox-qt. You can uninstall these two packages with the following command: .  The packages are selected to be purged (i.e. we want to remove everything from system directories, even configuration files). This would be a good command to run if you are planning to install a more recent version of VirtualBox. .  ",
      "P-tags": "apt package-manag dkm uninstal virtualbox",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP via NP"
    },
    {
      "id": "ul_232259",
      "task": "How to not store hdd encryption key on machine, but still mount on boot?",
      "P-task": "store hdd encrypt key machin still mount boot",
      "F_verb": "store",
      "P-body": "The easiest way to set this up would be to have a cleartext system partition (on the SD card, I presume) and an encrypted data partition. Use dmcrypt to encrypt the data partition, with a key stored in a key file that's downloaded from the server. .  First set up the server infrastructure, then download the key file and create the encrypted volume with \"cryptsetup luksFormat /dev/sdb1 /run/data.keyfile\" or add the key to the existing volume with \"cryptsetup luksAddKey /dev/mapper/encrypted /run/data.keyfile\". Note that you can arrange for the volume to be unlocked with either a passphrase or a key file, which may be convenient for administration (you can type the passphrase even if the server is not available). .  The key file doesn't have to be in any particular format. Just generate some random bytes on the server; 16 bytes is plenty (anything more won't give you better security, but anything less won't give you better performance): \"</dev/urandom head -c 16 >pi.keyfile\". .  Serve the key with HTTPS to avoid it being snooped. If you don't have a certificate that's validated by a CA, create your own and add it to \"/etc/ssl/certs\", or pass it to the download command (\"wget --ca-certificate /etc/local/my.cert\" or \"curl --cacert /etc/local/my.cert\"). .  You need to download the key before activating the encrypting volume. You can do that in one step with one of .  or you can download the key to a temporary file, then activate the volume, and finally (not necessary, but may slightly improve security) remove the temporary file. The natural place for this temporary file is in \"/run\", which is in RAM and writable only by root (don't download the key to persistent storage). You should make the file readable only by root (you can set \"umask 700\" before downloading to arrange that), although it only matters if you don't control all the code that runs at boot time. .  If you download the key to a temporary file, you can put the keyfile in \"/etc/crypttab\", and add a systemd unit to download the keyfile that runs before the one that activates encrypted volume (but after the network is available) and another unit to remove the keyfile afterwards. Putting \"wget \u2026 | cryptsetup \u2026\" in \"/etc/rc.local\" looks easier to set up. .  You'll probably want to authenticate the client when it downloads the key. The authentication token will have to be stored in cleartext on the Pi. You can use an SSL client certificate: .  or a password with HTTP basic authentication, stored in \"/root/.netrc\": .  Configuring basic authentication is perhaps easier to set up on the server side. Use a randomly-generated password with no special characters (e.g. \"</dev/urandom | head -c 16 | base64\"). .  Note that whatever you do, someone who steals the Pi will get the password and will be able to download the key if you don't block it first on the sender side. Also, someone who gets physical access to the Pi can quickly pull out the SD card, make a copy, and insert it back; if you don't monitor anything other than uptime, this will look like a power failure. There's no way to completely protect against that. You can put the key in a smartcard, which would prevent the attacker from duplicating it, but not from stealing the smartcard or using it on the spot to download the key file. .  Once again, you cannot protect against someone with physical access quickly downloading the key file, then stealing the disk and decrypting it at their leisure. If you want to protect against that, you need to look into tamper-resistant hardware, which is in a different price range. .  ",
      "P-tags": "arch-linux encrypt crypttab",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP on NP"
    },
    {
      "id": "so_66429344",
      "task": "Powershell to return last existing folder in path",
      "P-task": "powershel return last exist folder path",
      "F_verb": "return",
      "P-body": "An attempt of solving this using the pipeline: .  The \"for\" loop creates a temporay variable \"$p\" so the original path will not be destroyed. At each iteration it outputs variable \"$p\", which is automatically added to the array, due to PowerShell's implicit output behaviour. Then it sets \"$p\" to the parent path of \"$p\" (\"Split-Path\" with a single unnamed argument returns the parent path). The loop exits when there is no parent anymore. .  The \"Where-Object | Select-Object\" line may seem inefficent, but because of \"Select-Object\" argument \"-First 1\" it actually tests only the necessary number of paths. When the first existing path is found, the pipeline will be exited (like a \"break\" statement in a loop). .   The above was the accepted answer. The following solution has been added later. It is more efficient, because it calls \"Split-Path\" only as many times as necessary and doesn't need \"Where-Object\" and \"Select-Object\". .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_18807526",
      "task": "Find the first line having a variable value bigger than a specific number",
      "P-task": "find first line variabl valu bigger specif number",
      "F_verb": "find",
      "P-body": "Find the first occurrence of \"abcd\" greater than 1000 and print the line number and matching line and quit: .  To find any variable greater than 1000 just drop the first condition: .  ",
      "P-tags": "awk linux text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_40040196",
      "task": "PowerShell script to update users' \"Description\" field with username as unique identifier",
      "P-task": "powershel script updat user descript field usernam uniqu identifi",
      "F_verb": "update",
      "P-body": "First you will need to import the \"ActiveDirectory\" module to be able to edit objects in AD via \"PowerShell\". Next you use \"Import-CSV\", note you will need to change the \"-path\" and \"-Delimiter\" parameters to suit your \"CSV\". I have also presumed that your \"CSV\" column headers are (\"username,Description\").  .  You pretty much had the loop in the correct format for \"PowerShell\" you just need to use the cmdlets \"Set-ADUser\" to set the user properties and \"Get-ADUser\" to check if the AD user object exists. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP as NP"
    },
    {
      "id": "ul_401621",
      "task": "Where is cron's PATH set?",
      "P-task": "cron path set",
      "F_verb": "set",
      "P-body": "It\u2019s hard-coded in the source code (that link points to the current Debian \"cron\" \u2014 given the variety of \"cron\" implementations, it\u2019s hard to choose one, but other implementations are likely similar): .  \"cron\" doesn\u2019t read default paths from a configuration file; I imagine the reasoning there is that it supports specifying paths already using \"PATH=\" in any cronjob, so there\u2019s no need to be able to specify a default elsewhere. The hard-coded default is used if nothing else specified a path in a job entry.) .  ",
      "P-tags": "cron path",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V"
    },
    {
      "id": "su_1629334",
      "task": "How do I stop a screen capture with FFmpeg under Windows in a bash script?",
      "P-task": "stop screen captur ffmpeg window bash script",
      "F_verb": "stop",
      "P-body": "To stop ffmpeg, you can send \"signal.CTRL_C_EVENT\" with python's \"os.kill\", but you have to send it to the WINPID, not the PID: .  See a full example here: https://gist.github.com/elsamuko/9c3fe69f00a0f847251ffa3ef1d080a2 .  References: https://trac.ffmpeg.org/ticket/6336 https://bugs.python.org/issue42962 .  ",
      "P-tags": "ffmpeg bash python windows-10",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP with NP under NP in NP"
    },
    {
      "id": "so_39969116",
      "task": "How to get the page directory of a pointer in xv6",
      "P-task": "get page directori pointer xv6",
      "F_verb": "get",
      "P-body": "You need to use \"argint()\" or \"argptr()\" to read the argument. .  ",
      "P-tags": "linux xv6",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_58407406",
      "task": "C Linux Check free space in mount",
      "P-task": "c linux check free space mount",
      "F_verb": "check",
      "P-body": "From here: .  Use the \"statvfs\" API: .  and the prototype of the \"statvfs\" is .  The results will be filled to the buf \"statvfs\" struct: .  The return type is: .   On success, zero is returned. On error, -1 is returned, and errno is set appropriately. .   Also have a look at the man3 manpage of the \"statvfs\" command for more and detailed information. .  ",
      "P-tags": "linux c mount",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "so_34801792",
      "task": "How do I convert an AAC audio mp4 to mp3 using gstreamer",
      "P-task": "convert aac audio mp4 mp3 use gstreamer",
      "F_verb": "convert",
      "P-body": "The bit rate doesn't take effect unless you specify a target. You should add target=bitrate to your pipeline. .  ",
      "P-tags": "lame audio-record linux gstreamer",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP using NP"
    },
    {
      "id": "ul_524961",
      "task": "Debian mailx won't attach files to emails",
      "P-task": "debian mailx attach file email",
      "F_verb": "attach",
      "P-body": "Your original command will work if you have the \"heirloom-mailx\" package installed. .  Then you can: .  ",
      "P-tags": "mailx debian",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP to NP"
    },
    {
      "id": "so_67559914",
      "task": "How to solve the NameError error in a python script ( on linux CentOS)",
      "P-task": "solv nameerror error python script linux cento",
      "F_verb": "solve",
      "P-body": "You have to mention the full path of the file \"sshdlog\" like \"with open(\"full path to sshdlog file\") as f\" or your script and sshdlog is in same directory. .  ",
      "P-tags": "nameerror script linux python cento",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP on NP"
    },
    {
      "id": "so_14770587",
      "task": "How do I get a file path without extension in PowerShell?",
      "P-task": "get file path without extens powershel",
      "F_verb": "get",
      "P-body": "if is a \"[string]\" type: .  if is a \"[system.io.fileinfo]\" type: .  or you can cast it: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP without NP in NP"
    },
    {
      "id": "so_38382352",
      "task": "Run Neo4J locally on ubuntu",
      "P-task": "run neo4j local ubuntu",
      "F_verb": "run",
      "P-body": "You can have a local neo4j, specify the password you used when launching neo4j for the first time or disable auth for playing. .  You best use the \"sdn-4.1\" branch, actually the \"sdn\" branch has some issues and is not maintained since a year. .  Secondly, there is no \"/categories\" endpoint, the right endpoint is \"/api/categories\" which is used by the angular app and return some json, after running the \"cql\" script I have the following response : .  ",
      "P-tags": "neo4j ubuntu",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_33096309",
      "task": "runInstaller permission denied",
      "P-task": "runinstal permiss deni",
      "F_verb": "deny",
      "P-body": "runInstaller calls the appropriate installer from /install folder. You should give permissions to required file. In your case it is .  As I see you have given 775 to runInstaller so you may give same permission to all /instal folder I suppose, but this is not required. .  ",
      "P-tags": "linux permission-deni oracle11g instal oracle-data-integr",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "so_46858807",
      "task": "gcc-4.8 can't compile test program?",
      "P-task": "gcc-4 8 compil test program",
      "F_verb": "compile",
      "P-body": "\"gcc-4.8\" is a C compiler, not a C++ compiler. You should set the \"CXX\" variable to \"g++-4.8\" or \"g++\" or some other C++ compiler executable. .  ",
      "P-tags": "linux c++11 c++ gcc cmake",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP"
    },
    {
      "id": "au_692218",
      "task": "Intellij Idea Community Edition, cannot set `Gradle home`",
      "P-task": "intellij idea commun edit set gradl home",
      "F_verb": "set",
      "P-body": "In \"Gradle home\" option you need provide path to folder where your Gradle distribution was installed.  .  To determine the Gradle home location of your Gradle installation: .   Create build.gradle containing: .   Run .    Reference: Setting up Gradle Plugin For IntelliJ .  ",
      "P-tags": "intellij gradl java",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "au_578967",
      "task": "What does the 'jekyll 2.4.0 | Error: Permission denied - /sys/fs/ext4/sda1/trigger_fs_error' mean",
      "P-task": "jekyl 2 4 0 error : permiss deni - sy fs ext4 sda1 trigger_fs_error mean",
      "F_verb": "deny",
      "P-body": "In your \"_config.yml\" the \"source\" should list the actual location of the project .  Yep, knuckle head mistake. .  ",
      "P-tags": "github permiss ext4 jekyl",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "su_1478787",
      "task": "Run pip from Ubuntu terminal on Windows",
      "P-task": "run pip ubuntu termin window",
      "F_verb": "run",
      "P-body": "According to this official WSL documentation from Microsoft: .   WSL can invoke Windows binaries directly from the WSL command line using\u00a0\"[binary name].exe\". For example,\u00a0\"notepad.exe\". .   Therefore, running \"pip.exe show numpy\" is the correct way to call \"pip\" in this instance (since \"pip\" was installed under Windows). .  ",
      "P-tags": "ubuntu termin window windows-10",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP on NP"
    },
    {
      "id": "so_29329146",
      "task": "Replacing a repeating number in a file with random numbers",
      "P-task": "replac repeat number file random number",
      "F_verb": "replace",
      "P-body": "With GNU sed, you could do something like .  ...but it would be much saner to do it with awk: .  To make sure that the random numbers are unique, amend the awk code as follows: .  Doing that with sed would be too crazy for me. Be aware that this will only work only if there are less than 100 lines with a last field of 892 in the file. .  Explanation The sed code reads .  The awk code is much more straightforward. With \"-F \\;\", we tell awk to split the lines at semicolons, then .  The amended awk code replaces .  with  .  ...in other words, it keeps a table of random numbers it has already used and keeps drawing numbers until it gets one it hasn't seen before. .  ",
      "P-tags": "string sed bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_28005181",
      "task": "Creating a multi layered psd file with \"editable text\" using command line",
      "P-task": "creat multi layer psd file edit text use command line",
      "F_verb": "create",
      "P-body": "You can use Applescript or Extendscript to script Photoshop itself - there is a guide available here. .  You can do something like this using the Applescript version: .  The Extendscript version may be more portable across Linux and Windows. .  ",
      "P-tags": "image-process imagemagick photoshop linux gimp",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "su_1259123",
      "task": "Loop in bash to create symlinks after every git pull",
      "P-task": "loop bash creat symlink everi git pull",
      "F_verb": "create",
      "P-body": "In your repository root, you would have a \".git\" subdir. In there, you should be able to install a post-update hook: .  This assuming the user pulling from git also has permissions to create those links, ... .  ",
      "P-tags": "git linux symbolic-link bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP after NP"
    },
    {
      "id": "so_59100696",
      "task": "Arguments passed to the command line not printed and the program loops indefinitely",
      "P-task": "argument pass command line print program loop indefinit",
      "F_verb": "print",
      "P-body": "Your code is working... I made slight modifications (eg. argc !=4 , i <= argc , etc. ) I compiled it using gcc (g++) on my linux system using: .  Output: .  When I run: .  Output: .  ",
      "P-tags": "c++ linux operating-system unix",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_65795640",
      "task": "Can't close after awk command inside for loop to read and write multiple files",
      "P-task": "close awk command insid loop read write multipl file",
      "F_verb": "close",
      "P-body": "This is probably what you want: .  See https://stackoverflow.com/a/65814521/1745001 for an explanation for why/how I'm using \"close()\". .  By the way, if you're ever considering using \"getline\" in future - it's rarely the right approach and it's hard to use correctly, see http://awk.freeshell.org/AllAboutGetline. .  ",
      "P-tags": "awk csv bash",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V after NP S_INF"
    },
    {
      "id": "au_427125",
      "task": "TeamViewer does not start automatically, how do I make sure it does?",
      "P-task": "teamview start automat make sure",
      "F_verb": "start",
      "P-body": "TeamViewer provides a script called \"teamviewerd.sysv\" available in \"/opt/teamviewer/tv_bin/script\". Here's an excerpt: .  All you need to do is make sure this script runs on startup. Making sure of this is relatively simple, just copy it to \"/etc/init.d\" like so: .  Don't forget to make the script non-writable to anyone but the owner! .  Then run .  The service will now start automatically with each boot. If you don't feel like rebooting, you can start the service manually with: .  2019 EDIT: This answer was written in 2013. Since then, \"systemd\" has arrived in force and is normally used for constructing services that start upon boot. For instructions on how to achieve this in \"systemd\" instead, please see this question: How do I run a single command at startup using systemd? .  ",
      "P-tags": "teamview servic",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_61540982",
      "task": "How to make a video in Linux/Python/Opengl?",
      "P-task": "make video linux python opengl",
      "F_verb": "make",
      "P-body": "For each frame of the video, render the picture, preferrably to a framebuffer object (to avoid image corruption from failed window pixel ownership tests). Read out image using \"glReadPixels\", submit to video encoder. .  Choices for video encoders are broad. On Linux ffmpeg is widely available, so you can just use that. Most straightforward way is to spawn ffmpeg as a process (see the Python module \"\"subprocess\"\") with appropriate command line options to read raw images from stdin and write out to whatever destination you desire, then write the images rendered with OpenGL to the ffmpeg process' stdin. .  ",
      "P-tags": "linux python opengl",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "au_600652",
      "task": "How to accept root password through shell script",
      "P-task": "accept root password shell script",
      "F_verb": "accept",
      "P-body": "yes you can use \"expect\". Install it if you don't have it already with below command .  and then in a script  .  ",
      "P-tags": "script sh",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP through NP"
    },
    {
      "id": "so_10082650",
      "task": "Can't seem to change default editor in OSX Lion terminal",
      "P-task": "seem chang default editor osx lion termin",
      "F_verb": "change",
      "P-body": "I'm not even sure what edit command is. i don't have in on my Mac OS X Lion. Whatever it is, sounds like it ignores the EDITOR env variable and uses your MacOS X application settings. What you want can be accomplished with the alias shell command though: .  ",
      "P-tags": "termin osx-lion bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_98709",
      "task": "Creating directory on an external hard drive via command line (SSH) on Linux",
      "P-task": "creat directori extern hard drive via command line ssh linux",
      "F_verb": "create",
      "P-body": "You need to mount the drive first.  .  then make your directory .  This may help but I haven't watched it. .  Side note: You may need to format the drive or partition it with something Linux can read and write. NTFS support in Linux is pretty mature, but for quite some time you could only mount it read only without possible data loss. If that is still the case then you will need to partition and format it with something more friendly. .  ",
      "P-tags": "raspbian linux external-hdd ssh raspberry-pi",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP via NP on NP"
    },
    {
      "id": "ul_171929",
      "task": "Cannot prompt user using rm builtin prompt option -i with xargs and find",
      "P-task": "prompt user use rm builtin prompt option -i xarg find",
      "F_verb": "find",
      "P-body": "The problem here is that the \"stdin\" (the standard input) for the command ran from \"xargs\" (in this case \"rm\") is redirected from \"/dev/null\", and the \"stdin\" is the file descriptor used by \"rm\" to obtain the user's confirmation. .  You could use the \"-a\" option so that rm obtain the list of files from an intermediate file previously generated by the find command (the \"-a\" option makes \"xargs\" to let the \"stdin\" untouched), in any case, I understand this may not be what you really want since it requires the intermediate file. A more straight approach similar to what you wanted can be obtained with the command below: .  \"for i in $(find . -name file); do rm -i \"$i\"; done\" .  ",
      "P-tags": "prompt xarg rm find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_20536112",
      "task": "How to insert a new line in Linux shell script?",
      "P-task": "insert new line linux shell script",
      "F_verb": "insert",
      "P-body": "The simplest way to insert a new line between \"echo\" statements is to insert an \"echo\" without arguments, for example: .  That is, \"echo\" without any arguments will print a blank line. .  Another alternative to use a single \"echo\" statement with the \"-e\" flag and embedded newline characters \"\\n\": .  However, this is not portable, as the \"-e\" flag doesn't work consistently in all systems. A better way if you really want to do this is using \"printf\": .  This works more reliably in many systems, though it's not POSIX compliant. Notice that you must manually add a \"\\n\" at the end, as \"printf\" doesn't append a newline automatically as \"echo\" does. .  ",
      "P-tags": "linux newlin bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_631587",
      "task": "how to Sort script by columns and remove repeated ones",
      "P-task": "sort script column remov repeat one",
      "F_verb": "remove",
      "P-body": "You can use \"sort\" and \"uniq\" to delete the repeated lines and then use \"awk\" arrays indexed by the first column value, and then append to each value of the array each second column, for example: .  being \"test.txt\" your input file. .  Note that before adding a new column to the correct value of the array you have to check if the array is empty or not, just to add the space between values. .  ",
      "P-tags": "awk sort datamash text-process",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_57890925",
      "task": "Running a git clone and rsync bash script during a docker compose build",
      "P-task": "run git clone rsync bash script docker compos build",
      "F_verb": "compose",
      "P-body": "The Docker image should work as it supposed to work if you run it without docker-compose. try to run .  This issue is with \"volumes:\" it hides everything from Docker image. remove the .  And it should work fine. .  update: .  You can not view the files even if you mount the empty directory of the host, the reason is you cloned repo at build, not at run time. .  To view files in host without exec in Docker you must clone at run time and you should be moved you script from to entry point. you current script \"install-wordpress.sh\" is not entrypoint it's just like other RUN commands of the Dockerfile. .  entrypoint.sh .  so now if you run .  It should work fine and you will able to see files wordpress files also clone files and folder as well. .  ",
      "P-tags": "docker-compos docker dockerfil bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_56833832",
      "task": "How to uninstall / update a module from command line odoo 11",
      "P-task": "uninstal updat modul command line odoo 11",
      "F_verb": "uninstall",
      "P-body": "To update module navigate to odoo folder which contains odoo-bin file then run command .  To update all module you can use .  you can also select which database by including -d database_name before -u in command .  ",
      "P-tags": "odoo-11 ubuntu-16 04 python-3 x odoo python",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_30234209",
      "task": "creating a tarball, encrypt it on the fly and keeps tar messages in a log file",
      "P-task": "creat tarbal encrypt fli keep tar messag log file",
      "F_verb": "keep",
      "P-body": "\"2> file.log\" should achieve it. If you want to \"tee\" the \"stderr\" stream and also keep it going to the original destination, you can achieve that with .  \"2> >(tee file.log >&2)\" .  In your example: .  Your attempts don't succeed because the piping (|) only forwards \"stdout\" of the previous command to the \"stdin\" of the current one. The current command (gpg) doesn't have access to the \"stderr\" of the previous command (\"tar\"). That \"stderr\" has already gone to its destination (your terminal, most likely).  .  \"2> >(command )\" pipes (quite literally \">()\" create an unnamed, OS-level pipe underneath) \"stderr\" to \"stdin\" of \"command\". Since \"command\" is a child process, its \"stderr\" (#2) descriptor will point to the same file as the \"stderr\" of the parent process. .  ",
      "P-tags": "tee shell bash gnupg tar",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "so_60233898",
      "task": "Adding multiple ARM toolchains to path",
      "P-task": "ad multipl arm toolchain path",
      "F_verb": "add",
      "P-body": "your tools will tell you everything you need to know, no need to use SO. .  so somewhere between 5.4.0 and 9.2.0 gcc dropped support for armv2 I suspect it was 6.x.x but the release notes from gcc is where to look. .  google  .  and you find .  test it .  arm-none-eabi-gcc -S -march=armv2 so.c .  now this builds unusable code because it uses bx lr, so maybe gcc 5.x.x is no good either. but to continue .  you can try this for armv4 and newer too gcc 5.x.x appears to default to using the frame pointer .  9.2.0 is also using the frame pointer by default but the -fomit-frame-pointer option also works .  (I intentionally didnt optimize as that would not use the stack, would have had to create a different test function that forced the use of the stack and a desire for a frame). .  same/similar results with optimization and an older version of gcc where it determined it didnt need a frame and didnt use one by default but if you forced it it would. .  ",
      "P-tags": "gcc linux arm path",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_960054",
      "task": "How do I recursively get all directories that contain a txt file with the same name as the containing directory in Bash?",
      "P-task": "recurs get directori contain txt file name contain directori bash",
      "F_verb": "get",
      "P-body": "Given .  then, with the shell's globstar option enabled (\"shopt -s globstar\") .   If you want to store the results in an array for later processing, you can do that using the shell's built-in \"mapfile\" (or its synonym \"readarray\") e.g. .  NOTE: it would be better practice to null-terminate the list using one of the methods discussed in bash: whitespace-safe procedural use of find into select .  You can then iterate over the array like so .  Alternatively, you could avoid storing the results at all and simply process each directory as you find it i.e. .  ",
      "P-tags": "directori file bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP that S"
    },
    {
      "id": "ul_487878",
      "task": "sed/awk/grep/cut: multiply a number in an xml-attribute by factor of ten",
      "P-task": "sed awk grep cut : multipli number xml-attribut factor ten",
      "F_verb": "multiply",
      "P-body": "You can use perl to do math in your regex: .  It could be cleaned up somewhat by making it a full script rather than a single line. At which point I would probably pull out the math in regex and replace it with a loop across the values in viewBox. .  ",
      "P-tags": "awk cut grep sed",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP in NP by NP of NP"
    },
    {
      "id": "ul_533572",
      "task": "Does not write logs into /var/log/security after I modified this file",
      "P-task": "write log var log secur modifi file",
      "F_verb": "write",
      "P-body": "it's normal. Your process doesn't know filename, is only know file-descriptor. So if you delete the file and create a new one with the same name, the process will continues to write into the file descriptor of the former file. it is required to restart the process so that the new file descriptor is loaded and used from the file name.  .  So if you dont want to change the file descriptor and clean the content of the file, without restarting the process, you can try something like \"echo \"\">/var/log/filename\" this command will erase the content of the filename without changing the file descriptor. must be tested first of course)  .  ",
      "P-tags": "freebsd ipfw syslog",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP into NP after NP"
    },
    {
      "id": "so_68047179",
      "task": "Running IPFS Desktop and CLI simultaneously",
      "P-task": "run ipf desktop cli simultan",
      "F_verb": "run",
      "P-body": "Thank you all for your answers. I believe the problem was in installing it using snap store (Ubuntu Software Center) because this changes the default path of the installations. So in effect, the desktop and cli were installed at separate paths. .  I followed the installation on the IPFS site which uses the install script and that put it in the correct path. .  So I re-installed only the CLI and use the webUI in place of the desktop. Along with IPFS Companion, desktop is not really needed. But I still wanted the functionality of having the desktop run the daemon behind the scenes without having a terminal open, so I created the following service unit file to do that: .  Paste the following code in the file \"/etc/systemd/system/ipfs.service\" .  Then I simply ran \"sudo systemctl start ipfs\" in a terminal to get the daemon running as a service. .  Thanks! .  ",
      "P-tags": "ipfs-cli instal ipf ipfs-desktop ubuntu-20 04",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_11633339",
      "task": "Using du to get size of specific sub directories",
      "P-task": "use du get size specif sub directori",
      "F_verb": "get",
      "P-body": "How about .  That should produce a grand total. .  ",
      "P-tags": "linux du bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "su_810416",
      "task": "How to remove file modification tracking on an Emacs buffer?",
      "P-task": "remov file modif track emac buffer",
      "F_verb": "remove",
      "P-body": "Solution is easy: in that shell buffer, type: .  Then with the cursor to the right of the close-paren, do C-x C-e or M-x \"eval-last-sexp\". Then you can erase the expression. .  Man! The attitude of these guys saying \"Well, don't do that.\" This happens to me all the time when I am looking at a file in the other buffer in the frame and want to rename it by saving it, but I forget that the cursor is in my shell buffer. .  ",
      "P-tags": "emac linux shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_152417",
      "task": "Why can't I use public/private key authentication with ssh on Arch Linux?",
      "P-task": "use public privat key authent ssh arch linux",
      "F_verb": "use",
      "P-body": "The permissions on your \"authorized_keys\" file and the directories leading to it must be sufficiently restrictive: they must be only writable by you or root (recent versions of OpenSSH also allow them to be group-writable if you are the single user in that group). See Why am I still getting a password prompt with ssh with public key authentication? for the full story. .  In your case, \"authorized_keys\" is a symbolic link. As of OpenSSH 5.9 (I haven't checked other versions), in that case, the server checks the permissions leading to the ultimate target of the symbolic link, with all intermediate symbolic links expanded (the canonical path). Assuming that all components of \"/home/wayne/dotfiles/authorized_keys2\" are directories except for the last one which is a regular files, OpenSSH checks the permissions of \"/home/wayne\", \"/home/wayne/dotfiles\" and \"/home/wayne/dotfiles/authorized_keys2\". .  If you have root access on the server, check the server logs for a message of the form \"bad ownership or modes for \u2026\". .  ",
      "P-tags": "arch-linux public-key-authent ssh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "so_51168587",
      "task": "how to process filenames correct with shell script",
      "P-task": "process filenam correct shell script",
      "F_verb": "process",
      "P-body": "Your thinking is not far off. I would advise against \"cd\" into the latest dire and simply use the same scheme to get the latest file in that folder by appending \"latest_folder/\" with your command substitution. .  Once you have the \"latest_file\", you can simply use parameter expansion with substring removal to isolate the leading 3-digit number (e.g. \"filenum=\"${latest_file%%.*}\"\"). After than you can make your decision on whether a new directory is required based on \"filenum\". .  If you do need to create a new directory, then use can use \"printf -v\" to take advantage of the field-width modifier and \"'0'\" padding to format your \"new_folder\" names a \"002\" by simply adding \"1\" to the \"latest_folder\" number, e.g. \"printf -v new_folder \"%03d\" $((latest_folder + 1))\" note: that is after removing the leading-zeros from \"latest_folder\" to prevent interpretation as Octal constants when adding \"1\" to get the \"new_folder\" number, e.g. \"$((latest_folder + 1))\". .  Putting it altogether, you should be able to do something similar to: .  note: you should generally use \"find\" and \"sort\" to get the list of directories and filenames (using \"-maxdepth\" and \"-type\" to control the depth and type of file/dir searched for) .  Let me know if you have questions.  .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_314231",
      "task": "How can I prevent data loss (after install)",
      "P-task": "prevent data loss instal",
      "F_verb": "prevent",
      "P-body": "What kinds of danger do you expect? Data loss, of course, but how do you expect that data loss to happen? This immediately rules out several strategies. Regardless, RAID is not a backup. Some of the RAID levels (1,5,6,\u2026) merely provide a way to keep your system running if a disk fails.  .  If there's an error in your system, e.g. an accidental \"rm -rf /media/*\", all your data will be deleted across all your drives in your RAID. Note that it's possible in theory to create a RAID1 with only one drive, copy data to it, and then start mirroring, but again, it's not a backup. .  So instead, just partition and format your second disk with ext4 or another file system of your choice. Now, we come to the next question: do you want incremental backups? Or do you want a mirror of your data? .  A mirror is rather easy: .  But depending on your situation, you want incremental backups. There are several applications available, e.g. \"borg\", and they have different features, like de-duplication, speed, and so on: .  This has the nice side-effect that the mentioned \"rm -rf /media/*\" won't delete your backups (unless you've used \"rsync --delete\"). .  Regardless of the method you use, put that method in a shell script, e.g. \"~/utils/backup.sh\". But don't create a cron job for that file. Instead, add a second file, \"~/utills/backupreminder.sh\", that sends you an email, SMS, notification, or prints a page on your printer to remind you that you should take your drive, go to your Raspberry, connect it, execute \"~/utils/backup.sh\", disconnect it, and put it back. .  The physical distance is important. If your dog pulls your Raspberry from the shelf, any connected drive will likely die. If that's too much of a hassle (and your Raspberry is in an infant safe location), at least dismount the drive after each backup. .   Bonus Question 5: What period should I run (after the initial sync)? Once a day will surely not be enough and every minute may be a bit much. .   That completely depends on you. If you file a very important document in your OwnCloud every day, you should backup every evening. If the contents of your OwnCloud and other folder only change every second day, and you can handle the loss of such a day, backup every fourth evening.  .  And if disk failure is your major concern, add a third drive for that RAID1. But don't forget the backups. .  However if that's all too much (which is understandable), you can always rent some space online for ~60$/year, and backup your files there. .  ",
      "P-tags": "backup raid cron rsync",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP after NP"
    },
    {
      "id": "so_44177713",
      "task": "How to get AWS RDS CPU and memory metric using script other then cloudwatch",
      "P-task": "get aw rd cpu memori metric use script cloudwatch",
      "F_verb": "get",
      "P-body": "Install aws cli if not already installed, then use http://docs.aws.amazon.com/cli/latest/reference/cloudwatch/get-metric-statistics.html .  Example: .  \"aws cloudwatch get-metric-statistics --namespace 'AWS/RDS' --metric-name 'CPUUtilization' --start-time '2017-05-25T12:00:00Z' --end-time '2017-05-25T12:30:00Z' --period 60 --statistics 'Maximum'\" .  ",
      "P-tags": "linux postgresql amazon-web-servic cron rd",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP using NP"
    },
    {
      "id": "so_62943209",
      "task": "Bash get value of matching substring in a long string",
      "P-task": "bash get valu match substr long string",
      "F_verb": "get",
      "P-body": " It would appear that you should be using \"read -r\". .   It also appears that it would be much simpler if you focused on using curl and jq to extract the information, without any grep or tr invocation and without any shell looping. Assuming you can arrange for the output of \"curl\" to be valid JSON(*), a single invocation of jq along the following lines should do the job: .    (*) To check whether the output of \"curl\" is valid, you can pipe the output of your \"curl\" command into \"jq empty\": .  ",
      "P-tags": "awk jq jenkin bash sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_26789231",
      "task": "How shell commands execute",
      "P-task": "shell command execut",
      "F_verb": "execute",
      "P-body": "There are two main types of \"commands\" that the shell can execute. Built-in commands are executed by the shell itself - no new program is started. Simply typing \"echo\" in a shell prompt is an example of such a built-in command. .  On the other hand, other commands execute external programs (also called binaries) - and \"ls\" is an example of this kind of command. .  So, if you run \"echo\" in a shell, it's executed by the shell itself, but if you write a C program that performs the same action, it wil be run as an external program. As a matter of fact, most Linux systems come with such a binary, located at \"/bin/echo\". .  Why does it sometimes make sense to have both a built-in command and a program to accomplish the same task? Built-in commands are faster to execute as there is some cost involved in running an external program. But built-ins have some drawbacks, too: they can't be too complex as this would make the shell big and slow; they can not be upgraded separately from the shell and from each other; finally, there are situations where an external program which is not your shell would like to run an application: it can run external programs but it can't execute shell built-ins directly since it's not the shell. So sometimes it makes sense to have it both ways. Apart from \"echo\", \"time\" is another example of this double approach. .  ",
      "P-tags": "command-lin linux shell bash c",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_41578824",
      "task": "How to return a SecureString object from a function",
      "P-task": "return securestr object function",
      "F_verb": "return",
      "P-body": "The expression \"[SecureString] $SecuredString;\" results in \"$null\" being returned before the \"SecureString\" object. Remove that statement .  Or simpler: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_42460388",
      "task": "How to do search & replace in mingw with quotes in the string?",
      "P-task": "search replac mingw quot string",
      "F_verb": "search",
      "P-body": "You could avoid using double quotes by using the regex \"-replace\" function for your replacements. This should do it: .   You could also use the \"-EncodedCommand\" powershell.exe parameter to pass a base-64-encoded string version of your command. Here an example how you can get your base-64-encoded string using PowerShell: .  Now you can invoke the encoded command using the content of \"$encodedCmd\" like this: .  ",
      "P-tags": "powershel mingw sed bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP with NP in NP"
    },
    {
      "id": "ul_333635",
      "task": "Enabling Synchronous TRIM Only",
      "P-task": "enabl synchron trim",
      "F_verb": "enable",
      "P-body": "I found the solution. .  I tried \"fstrim\" with explicit statements of the partitions as a weekly cronjob shortly after I posted the answer but didn't know whether it was safe. Furthermore, I didn't know whether someone would have a better answer. Therefore, I didn't post it as an answer myself. .  I just looked at the contents of the folder \"/etc/cron.weekly\" where I placed a file containing the command because I wanted to execute it manually after filling my entire disk with data today and having deleted a lot of it a few minutes ago. I didn't remember the command, so I just went where I put it. However, after executing \"ll\" I found 2 files with names leading me to believe that it was my script. .  The other file wasn't put there by me so it's almost certainly delivered with Ubuntu. It's called \"fstrim\" and these are its contents: .  After deleting my own script, I executed the script which came with Ubuntu because its clearly better. It felt like it took about a minute to execute which is what I'd expect from it trimming 36 GB. When I executed it a second time, it returned immediately, indicating that it did actually trim the first time. .  I already sha256summed all the files in my home folder before trimming the first time, sha256summed all of them after the first trim, and found no unexpected changes (well, obviously, the contents of \"~/.cache\" and \"~/.mozilla\" changed as I used Firefox in the meantime) when comparing the files containing the sha256sums via Meld. I therefore concluded that it's probably safe. .  ",
      "P-tags": "trim ssd samsung",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_26415169",
      "task": "removing extra pipes (using sed or tr)",
      "P-task": "remov extra pipe use sed tr",
      "F_verb": "remove",
      "P-body": "You can use this to delete (\"d\") all lines which begin (\"^\") with a pipe. .  ",
      "P-tags": "gnu linux regex tr sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "so_64417020",
      "task": "Powershell Upper case replace",
      "P-task": "powershel upper case replac",
      "F_verb": "replace",
      "P-body": "In PowerShell, all string operators (including regular expression operators) are case-insensitive by default. .  From the \"about_Comparison_Operators\" help topic: .   By default, the \"-replace\" operator is case-insensitive. To make it case sensitive, use \"-creplace\". To make it explicitly case-insensitive, use \"-ireplace\". .   Using the case-sensitive variant (\"-creplace\") produces the expected result: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "replace",
      "pat": "V"
    },
    {
      "id": "ul_394829",
      "task": "Detect media play / pause events",
      "P-task": "detect media play paus event",
      "F_verb": "detect",
      "P-body": "One option is to check the state of the Pulseaudio streams, e.g. with \"pacmd list-sink-inputs\" (look at \"state\"), or interacting directly with the Pulseaudio demon in a programming language of your choice. .  That requires the media player to pause the stream (change \"state\" from \"RUNNING\" to \"CORKED\") if the player itself is paused. Some media players may do that, and some may not. .  ",
      "P-tags": "audio mediaplay event pulseaudio",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_19939010",
      "task": "eclipse execute jar file run on linux machine",
      "P-task": "eclips execut jar file run linux machin",
      "F_verb": "execute",
      "P-body": "Sounds like a classpath difference between the two environments. Check the \"CLASSPATH\" environment variable in both environments, and check the \"Class-Path\" entry in the \"MANIFEST.MF\" file in the jar. I suspect that Eclipse built the jar with a Windows-based \"Class-Path\" entry in the Manifest file inside the jar. .  ",
      "P-tags": "noclassdeffounderror linux jar eclips java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_55687927",
      "task": "Keep different folders under the same repository",
      "P-task": "keep differ folder repositori",
      "F_verb": "keep",
      "P-body": "You can use symbolic links. For instance, if you want to link /path/to/foldera and /path/to/folderb, you can initialize git in /path/to/foldera and link /path/to/folderb to /path/to/foldera using: .  ",
      "P-tags": "git bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP under NP"
    },
    {
      "id": "so_373156",
      "task": "What is the safest way to empty a directory in *nix?",
      "P-task": "safest way empti directori nix",
      "F_verb": "empty",
      "P-body": "The safest way is to sit on your hands before pressing Enter. .  That aside, you could create an alias like this one (for Bash) .  That will show you your directory, wait for an enter press and then remove what you specified with the proper flags. You can cancel by pressing ^C instead of Enter. .  ",
      "P-tags": "linux unix command-lin",
      "source": "qa",
      "cate": "clear/clean/empty/eliminate/unpin/cleanup/unpublish",
      "pat": "V NP in NP"
    },
    {
      "id": "so_64838725",
      "task": "Create Sphinx autodoc for a package loading pywin32 on Linux",
      "P-task": "creat sphinx autodoc packag load pywin32 linux",
      "F_verb": "create",
      "P-body": "The easiest way to solve this is setting \"autodoc_mock_imports = [\"pywin32\"]\". This only requires setting the root package and any subsequent use your code makes of the library (calling or importing submodules, classes, etc) will be mocked by Sphinx. .  Notice the mocked library won't provide any functionality besides allowing its components to be declared and importable. So your code should be structured to not have any module level execution depending on \"pywin32\" callables, because the returns of those callbles will also be mocked. .  I also found this guide that elaborates focused on ReadTheDocs builds and it suggests the same. Parallel to this problem I found the extension sphinxcontrib-mockautodoc that addresses the problem of making builds when you simultaneously have different Python versions in a given project. .  ",
      "P-tags": "python-sphinx linux mock autodoc pywin32",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "au_1057164",
      "task": "How do I show memory usage information in top bar or as notification?",
      "P-task": "show memori usag inform top bar notif",
      "F_verb": "show",
      "P-body": "As pointed out in the other post you want to install the Gnome Shell Extension \"system-monitor\" There's a browser plugin and integrations that can allow you to install it from the browser or from the software center as mentioned by @pomsky. .  However I've found that the easiest way to install it is to just install it from apt using the debian package .  This will also pull in all the required dependencies, and after a reboot or log out the system monitor was in the top task bar.  .   .  (Note that I think I enabled the swap manually before taking the screenshot.) .  ",
      "P-tags": "panel memory-usag 18 04 notif gnome-shel",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP as NP"
    },
    {
      "id": "so_14562423",
      "task": "Is there a way to ignore header lines in a UNIX sort?",
      "P-task": "way ignor header line unix sort",
      "F_verb": "ignore",
      "P-body": " The parentheses create a subshell, wrapping up the stdout so you can pipe it or redirect it as if it had come from a single command. .  ",
      "P-tags": "sort unix command-lin",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP in NP"
    },
    {
      "id": "so_28026838",
      "task": "How can I retrieve wLength of a hid device in linux?",
      "P-task": "retriev wlength hid devic linux",
      "F_verb": "retrieve",
      "P-body": "The answer to this question is using udev. \u200cBy reading special attribute, called bmAttributes, you can find the I/O's actual length. Using below code to read it: .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_425863",
      "task": "How to process files in pairs",
      "P-task": "process file pair",
      "F_verb": "process",
      "P-body": "I'm assuming that the number in the file names are five-digit zero-filled numbers and that the occasional four-digit string in the question and in the comments are typos. .  The loop goes from zero to a large number in increments of two. For each iteration, it constructs the two filenames using the variable \"i\" in two calls to \"printf\" (once for \"i\" and once for \"i+1\"). The format specifier \"%05d\" formats an integer to a zero-filled five-digit string. .  As soon as the constructed filenames no longer corresponds to any existing files (in the current directory), the loop exits. .  If the files are located in another directory than in the current, change the \"printf\" format string from \"'%05d.nii.gz'\" to \"'/path/to/dir/%05d.nii.gz'\". .   To keep with the DRY principle (\"Don't Repeat Yourself\"): .  ",
      "P-tags": "script linux bash",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP in NP"
    },
    {
      "id": "au_232998",
      "task": "How do I install smbmount?",
      "P-task": "instal smbmount",
      "F_verb": "install",
      "P-body": "\"smbmount\" has been deprecated in favor of \"mount.cifs\". I want to say \"since at least 2008\" but I can't find a reference.  .  Here's the accompanying manpage. You would use these parameters instead:  .  You might also need to install the cifs-utils  package. .  ...... .  ",
      "P-tags": "samba",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_248285",
      "task": "How to use lvconvert with two disks for mirroring? - Insufficient suitable allocatable extents",
      "P-task": "use lvconvert two disk mirror\n- insuffici suitabl allocat extent",
      "F_verb": "use",
      "P-body": "1) there was a syntax error, this is the GOOD one:  .  CC1 CC2 CC1 CC2 .  but the man page doesn't really speaks about this.. :) .  2) 1 free PE is needed per PV! So decrease the FS, then LV size to free up 4 MByte.. .  ",
      "P-tags": "lvm",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP for S_ING"
    },
    {
      "id": "au_553003",
      "task": "Step by step instructions on how to remove grub2 or mount the EFI partition and delete files (UEFI)",
      "P-task": "step step instruct remov grub2 mount efi partit delet file uefi",
      "F_verb": "mount",
      "P-body": "go to windows , and open cmd.exe as administrator , execute \"mountvol S: /S\" then \"taskkill explorer.exe\" then \"explorer.exe\" then go to my computer , get in to the volume labeled as \"S:\" look for \"grubx64.efi\" or something like that and delete it .  ",
      "P-tags": "dual-boot grub2 uninstal uefi windows-8",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "ul_473949",
      "task": "How to call several organized input files in a shell script loop",
      "P-task": "call sever organ input file shell script loop",
      "F_verb": "call",
      "P-body": "If you want to use the names of those existing files you can use something like this: .  It will use all files in the current directory starting from \"fort.\" regardless of number of files. Of course, you can use any other command in place of \"echo\", here. .  ",
      "P-tags": "shell-script",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP in NP"
    },
    {
      "id": "so_4628974",
      "task": "How can I get html code from the web with vala(gtk)?",
      "P-task": "get html code web vala gtk",
      "F_verb": "get",
      "P-body": "Forget it, someone just give me an answer on ask ubuntu site. .  The answer is: .   Use the Vala GIO File open shown here http://live.gnome.org/Vala/GIOSamples .   ",
      "P-tags": "linux ubuntu html gtk vala",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP with NP"
    },
    {
      "id": "so_64187160",
      "task": "How can I use a regex variable for a find and replace command in bash?",
      "P-task": "use regex variabl find replac command bash",
      "F_verb": "use",
      "P-body": "If you want to deal with parentheses in squared expressions, try: .  One-line Solution: .  Two-Line Solution: .  https://regex101.com/r/Dp0Duf/1. .  ",
      "P-tags": "replac regex perl bash sed",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "ul_567358",
      "task": "If find 4 digit number print the number and next row value in csv",
      "P-task": "find 4 digit number print number next row valu csv",
      "F_verb": "find",
      "P-body": "Something like can do the work: .  If you want the \"absolute overkill\" version which removes unnecessary \",\" and adds newlines to the output, try .  ",
      "P-tags": "awk grep sed text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_451232",
      "task": "Where is stddef.h defined in Linux?",
      "P-task": "stddef h defin linux",
      "F_verb": "define",
      "P-body": "The C standard does not distinguish compiler features from library features. The distinction is an implementation detail and can vary from platform to platform, but there are common trends. For example the size of basic integer types such as \"size_t\" and associated macros such as \"CHAR_BIT\" and \"SIZE_MAX\" are properties of the compiler and compiler options; on the other hand the contents of \"stdio.h\" are usually independent of the compiler but dependent on how the standard library implements files. .  \"stddef.h\" mostly declares compiler things, so it comes with the compiler. You'd better get different definitions if compiling in 32-bit or 64-bit mode, for instance, and you'll get different definitions with e.g. GCC and Clang. So look for it in compiler directories. Some compilers even don't have a disk file at all, they just treat the name \"<stddef.h>\" specially, but with GCC and Clang you do get a disk file. .  You can find all the copies on your system with the \"locate\" command. .  If you want to know what include path GCC is using when given particular options, pass the option \"-v\" on the command line in additions to the other options you use in your build (especially \"-m\"). .  If you just want this information without compiling anything, invoke GCC in preprocessor-only mode with empty input (\"-xc -E /dev/null\"; you need a \"-xc\" to specify the language is c because GCC can't tell what language you're compiling without a file name). .  The same options work with Clang, by the way. .  If all you want to know is the definition of \"size_t\", then you don't need to know where it comes from. Ask the compiler to print the output of the preprocessor. .  From \"man gcc\", .    \"-E\" Stop after the preprocessing stage; do not run the compiler proper. The output is in the form of preprocessed source code, which is sent to the standard output. Input files that don't require preprocessing are ignored. \"-x language\" Specify explicitly the language for the following input files (rather than letting the compiler choose a default based on the file name suffix). This option applies to all following input files until the next \"-x\" option.    ",
      "P-tags": "gcc glibc linux",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V in NP"
    },
    {
      "id": "so_41854287",
      "task": "ssh - echo $SSH_CLIENT returns empty when executed on initial connect",
      "P-task": "ssh - echo ssh_client return empti execut initi connect",
      "F_verb": "echo",
      "P-body": "The variable is being expanded in the local shell, before the \"ssh\" command runs. As it is unset on the local shell, you are not getting anything, just a newline that \"echo\" produces by default, while being executed on remote shell. .  You need to escape the \"$\" in front of \"SSH_CLIENT\" in any of the usual manners: .  Note that, although it is not strictly necessary in this case, you should quote your variable expansions to prevent word splitting and pathname expansion. .  ",
      "P-tags": "ssh shell bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP when S"
    },
    {
      "id": "so_41913630",
      "task": "Problems assigning variable to output of command",
      "P-task": "problem assign variabl output command",
      "F_verb": "assign",
      "P-body": "Spaces should be avoided. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "ul_180118",
      "task": "Every time I run tmux, new ssh-agent child process is started (zshell)",
      "P-task": "everi time run tmux new ssh-agent child process start zshell",
      "F_verb": "run",
      "P-body": "By default, \"tmux\" spawns a login shell for all new windows. This would then source your \"~/.zprofile\" or wherever your start your \"ssh-agent\".  .  As \"man tmux\" makes clear, you can avoid this behaviour by explicitly setting a default command in your \"~/.tmux.conf\": .  default-command shell-command Set the command used for new windows (if not specified when the window is created) to shell-command, which may be any sh(1) command. The default is an empty string, which instructs tmux to create a login shell using the value of the default-shell option. So, to prevent every new window being spawned as a login shell, add the following line to your config file: .  ",
      "P-tags": "tmux zsh arch-linux linux kde",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_53894219",
      "task": "Error while trying to install Node on Ubuntu",
      "P-task": "error tri instal node ubuntu",
      "F_verb": "install",
      "P-body": "run this : \"node -v\" if it displays a version, then it means you already have the latest version of node installed. Reason is this from your logs: .  ",
      "P-tags": "node js ubuntu instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_574299",
      "task": "instruct apt package installer to access a different python version",
      "P-task": "instruct apt packag instal access differ python version",
      "F_verb": "instruct",
      "P-body": "Since you didn't state which apt-based Linux distribution you're using, I will suppose it's Debian. This should apply for derived distributions, as long as the package \"equivs\" below exists. .  You really should upgrade your system to a recent/supported version, because you'll start having more and more dependency problems. .  Anyway, In order to satisfy your dependency problem, you can try and use the package \"equivs\": .   [...] .  Another use is to circumvent dependency checking: by letting dpkg think a particular package name and version is installed when it isn't, you can work around bugs in other packages' dependencies. Please do still file such bugs, though.) .   You're supposed to create a control file with \"equivs-control\": .  edit the created file \"python3\", for your case you could add or change the relevant lines to: .  (and any other field you deem useful, like \"Description\") .  Then run \"equivs-build python3\" to create an empty (in this case) package called \"python3_3.7.7_all.deb\" which you can then install using \"dpkg -i python3_3.7.7_all.deb\". .  This will satisfy dependencies, but gives no guarantee that you'll have a working result: it depends on what you actually provide with your own python installation. The least you can do is ensure, if it's not already present, that there's also a symlink called \"python3\". It might have to be present in \"/usr/bin/\" rather than only \"/usr/local/bin/\". .  ",
      "P-tags": "apt python debian",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_760743",
      "task": "After 15.10 to 16.04 update some characters became unreadable",
      "P-task": "15 10 16 04 updat charact becam unread",
      "F_verb": "update",
      "P-body": "For some reason Chrome keeps defaulting to Noto Sans CJK Thin. Simplest solution is to replace the NotoSans font bundled with Ubuntu with just the regular weight. .  Idea sparked by noto-sans-cjk-thin-font-issue .  In short:  .   download https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJK-Regular.ttc.zip \"chmod 644\" on the downloaded font replace \"/usr/share/fonts/opentype/noto/NotoSansCJK.ttc\" with the downloaded version  Benefit: no thin browser font rendering. .  Drawback: no font weights other than regular! .  ",
      "P-tags": "chromium font 16 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_59828764",
      "task": "Node-cmd: how to change user from root in Node JS",
      "P-task": "node-cmd : chang user root node js",
      "F_verb": "change",
      "P-body": "As root, you can run: .  With \"-c\", the command \"python3 dataengineering.py\" will run as user leohoy. .  Whereas in your example, \"python3 dataengineering.py\" still runs as root. .  ",
      "P-tags": "node js cmd root bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_13159593",
      "task": "Mount folder with cifs share with nfs on another server",
      "P-task": "mount folder cif share nf anoth server",
      "F_verb": "mount",
      "P-body": "NFS will not \"forward\" mounts. If the real file system is on \"systemW\", you can have a remote mount \"systemW -> (cifs) systemA\", and if \"systemW\" has an NFS implementation (either not Windows, or Windows with add-on software), you can also have a remote mount \"systemW -> (nfs) systemB\". However, as you've noted, trying to mount \"systemA -> (nfs) systemB\" gives you the (probably empty) directory from \"systemA\" upon which \"systemA\" has something else mounted. Your idea to have \"systemW -> (cifs) systemA -> (nfs) systemB\" cannot work, at least with NFS. There are some other options if you really need to chain remote mounts (like \"sshfs\" and some other FUSE-based file system types). .  ",
      "P-tags": "linux mount nf cif samba",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "so_2961635",
      "task": "Using awk to print all columns from the nth to the last",
      "P-task": "use awk print column nth last",
      "F_verb": "print",
      "P-body": "Print all columns: .  Print all but the first column: .  Print all but the first two columns: .  ",
      "P-tags": "awk linux",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "ul_312717",
      "task": "handy script to reduce hardlink count?",
      "P-task": "handi script reduc hardlink count",
      "F_verb": "reduce",
      "P-body": "The situation is tricky. Imagine the maximum links is 5 and you have 12 files \"a01\" to \"a12\" all hard-linked together. You need to split out \"a01..a05\" and \"a06..a10\" and \"a11..a12\", where \"a06\" and \"a07\" etc are still hard-linked together, but not to \"a01\". .  Here's a bash script using \"rsync\" that runs on an example source directory (\"src=/usr/libexec/git-core/\") on my system which has 110 hard-links. It simulates a maximum number of 50 links (\"max\") in the destination directory \"realdest\" by the function \"sim\". In a real case you would just ignore the too many links errors, and not use this function.  .  After the initial normal rsync (with errors), the list of missing files is created by using \"rsync -ni\", extracting the filenames in function \"calctodo\" into \"/tmp/todo\".  .  There is then a loop where we \"rsync\" the missing files, again ignoring too many links errors (which you would have if you had more than \"2*175\" links in the original directory). The successfully created files are hard-linked amongst themselves. The new list of missing files is calculated. This is repeated until there are no more files. .  You may need to revise this if you have filenames with \" => \", newlines and so on. .   Note, you can find the maximum number of links supported by a filesystem by .  ",
      "P-tags": "hard-link aw linux nf filesystem",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_9504938",
      "task": "Shell script to append string to the end of all CSV fields in 2nd column",
      "P-task": "shell script append string end csv field 2nd column",
      "F_verb": "append",
      "P-body": "Below is a command to filter the conversion: .  If you have a file \"source.txt\" which store source data and a file \"result.txt\" to be stored the output, following command will do: .  If you have multiple input files, you can add them in arguments. See manpage of awk for more details. .  ",
      "P-tags": "awk linux pars shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP of NP in NP"
    },
    {
      "id": "so_41284754",
      "task": "How to read array from stdout in bash",
      "P-task": "read array stdout bash",
      "F_verb": "read",
      "P-body": "\"$y\" is the first element of the array. \"${y[@]}\" will give you all of them. .  ",
      "P-tags": "python stdout bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_1142609",
      "task": "root folder is just filling up and filling up",
      "P-task": "root folder fill fill",
      "F_verb": "fill",
      "P-body": "I solved this by getting rid of snapd completely.  .  (Special thanks to OldFred on the Ubuntu Forum for this suggestion)  .  ",
      "P-tags": "partit directori root",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_352752",
      "task": "How to access drives that are mounted by other users?",
      "P-task": "access drive mount user",
      "F_verb": "mount",
      "P-body": "This is happen because when a device is mounted is mounted under your name and so, the system think that is yours and only you should have access to it. To pass by this you can simply unplug and plug again that device when you switch to another account, or... .  From this output: .  I can understand that you have probably more than one device plugged. Let's take for example \"sdb2\" - it was the last one plugged. It's UUID is \"8AD65635D65621AD\" - keep this in mind. .  First, make a group called let say \"my_device\" (you can call it whatever else) and add your accounts to it. You will do these from terminal: .  Second, make a new folder called \"my_device\" in \"/media\" and give everyone in the \"my_device\" group permission to read and write it: .  Finally, open \"fstab\" as root. Something like: .  and add this line at the end: .  Save the file and close it. That's it .  The same method can be applied for other devices. .  Source: http://ubuntuforums.org/showthread.php?t=1684055 .  ",
      "P-tags": "mount permiss user",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V by NP"
    },
    {
      "id": "so_7338032",
      "task": "fgets is reading more data from a closed filedescriptor",
      "P-task": "fget read data close filedescriptor",
      "F_verb": "read",
      "P-body": "Like others have said, \"close(fileno(FD));\" is a bad idea. If you do that, the same file descriptor might be reused for another file and \"fgets\" will suddenly read that fd instead. This is especially likely for multithreaded applications. .  Also, fgets is buffered. It has probably read a large chunk of data or so from the file the first time it's called, and following calls just returns more data from the buffer. .  Instead, do something like this: .  ",
      "P-tags": "fget linux eof c file-io",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "au_1104304",
      "task": "How to make YOLO algorithm run detection on images automatically and saves them in a separate folder?",
      "P-task": "make yolo algorithm run detect imag automat save separ folder",
      "F_verb": "save",
      "P-body": "Not sure if you still need help, but there's already a command for you to capture the image from the network camera. .  ./darknet detect demo cfg/yolov3.cfg yolov3.weights (fill your rtsp address here) .  In the source code \"image.c\" you can copy the following line in a commented section of this function void draw_detections_v3(...): .  and modify \"cropped_im\" to \"im\" to save the whole screen of each frame (you may need a counter to change the saved names) to your local folder. .  ",
      "P-tags": "command-lin playonlinux python detect 14 04",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "so_12409185",
      "task": "XML to Hash Table using Powershell",
      "P-task": "xml hash tabl use powershel",
      "F_verb": "hash",
      "P-body": "This should do the trick: .  ",
      "P-tags": "powershel xml hashtabl",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_425620",
      "task": "Apt not working due to lack of libstdc++ after Debian upgrade : \"`GLIBCXX_3.4.15' not found (required by apt-get)\"",
      "P-task": "apt work due lack libstdc++ debian upgrad : glibcxx_3 4 15 found requir apt-get",
      "F_verb": "find",
      "P-body": "You have a copy of \"libstdc++.so.6\" in \"/usr/local/lib\" which is being used in preference to the system\u2019s copy (in \"/usr/lib\" or one of its sub-directories). To get \"apt\" working again, you need to delete it or at least rename it: .  You should also rename the file \"libstdc++.so.6\" points to; after doing the above, run: .  ",
      "P-tags": "glibc apt debian librari",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V by NP"
    },
    {
      "id": "so_25414916",
      "task": "How to send mail depending on stdout?",
      "P-task": "send mail depend stdout",
      "F_verb": "send",
      "P-body": "I found even a better solution. Use the -E option for the mail command and it won't send e-mails if the body is empty. The manual for mail states the following. .  So just like that. .  ",
      "P-tags": "email bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP on NP"
    },
    {
      "id": "so_53371880",
      "task": "terminal find file with latest patch number",
      "P-task": "termin find file latest patch number",
      "F_verb": "find",
      "P-body": "Reverse order all files by time and print the first line. .  In case you have some other files then you can print files having hotfix text only.  .  ",
      "P-tags": "command-lin shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "au_1239492",
      "task": "How can I start automatically a command on Ubuntu 18.04?",
      "P-task": "start automat command ubuntu 18 04",
      "F_verb": "start",
      "P-body": "Use \"i3\" config file for starting up apps. .  It's located here: \"~/.config/i3/config\" .  More in official documentation : https://i3wm.org/docs/userguide.html#configuring .  Just add these lines: .  ",
      "P-tags": "command-lin i3-wm fish 18 04 startup",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP"
    },
    {
      "id": "so_5696454",
      "task": "Data Does not stores in Structure",
      "P-task": "data store structur",
      "F_verb": "store",
      "P-body": "In your mainfile you call \"ReadFromFile(&args);\" - so the function argument is a pointer to a struct Matrix. But you function itself has this declaration:  .  This means that it needs a struct Matrix - not a pointer to it. You you may want to change this argument into a pointer. This will of course also mean that you need to change the access to this struct from \"args.m1[i][j] = (int)temp;\" to \"args->m1[i][j] = (int)temp;\" .  Edit: Also, if you posted your whole header file, you missed the declaration of ReadFromFile. .  To be honest, I wonder why your code actually compiled in the first place with those errors, you might want to output all warnings while compiling (-Wall flag for gcc) .  ",
      "P-tags": "linux c data-structur",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V in NP"
    },
    {
      "id": "so_17616828",
      "task": "What is the right way to convert into UNIX timestamp from the date and time in C/C++?",
      "P-task": "right way convert unix timestamp date time c c++",
      "F_verb": "convert",
      "P-body": "POSIX has a formula for exactly what you want: .  http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap04.html#tag_04_15 .  This works whenever you have a broken-down time in GMT, even if the underlying system's \"mktime\", etc. functions do not use the same format \"time_t\" as \"Unix timestamps\". .  If your original time is in local time, you can use \"mktime\" and \"gmtime\" to convert it to GMT using the system's notion of timezone rules. If you want to apply your own timezone offset rules, just do that manually before using the above formula. .  ",
      "P-tags": "c unix-timestamp c++ datetim date",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V into NP from NP in NP"
    },
    {
      "id": "so_45162403",
      "task": "Permission denied for Git Clone when I do npm install",
      "P-task": "permiss deni git clone npm instal",
      "F_verb": "deny",
      "P-body": "I had this exact same error with installing chimp (not from a git repo) after I'd upgraded from NodeJS 6.10 to 8.10 (and more importantly, to NPM 5.6.0). The problem is that npm 5 handles permissions / directories very differently than npm 4. .  The solution is to NEVER use sudo when running npm 5. You'll find cases of when you have to use it with npm 4, but you shouldn't need to use sudo with npm 5. If you're installing globally, this link might help you. It didn't help me. .  Since I was in a docker container, I could just modify my docker file to not use sudo and then everything was fine. If you're not, I suggest you run the following as your user (not root): .  ",
      "P-tags": "json ubuntu-14 04 github node js reactj",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V for NP when S"
    },
    {
      "id": "so_14689584",
      "task": "How to catch input from Python in bash script",
      "P-task": "catch input python bash script",
      "F_verb": "catch",
      "P-body": "The errors in bash appear because you put spaces around the \"=\". You should use .  instead of  .  When you put spaces there, Bash thinks the line is a command invocation and tries to run \"history_file\" as a command. .   In your Python script, you can simply use: .  instead of what you have. This is simpler, and will work correctly if the arguments contain spaces, which your current code will fail on. There's no point in building the \"input_string\" string only to split it back in the following line. .  ",
      "P-tags": "python bash",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "ul_138256",
      "task": "Making su ask for password multiple times",
      "P-task": "make su ask password multipl time",
      "F_verb": "make",
      "P-body": "As a workaround, I would suggest the following: .  This returns a zero value even if \"foo\" has a different exit code. WARNING: using this workaround (which is a bit ugly), you won't be able to determine \"foo\"'s exit code. I don't know if it is required for your project. .  ",
      "P-tags": "password su authent",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP for NP"
    },
    {
      "id": "au_852092",
      "task": "How to create a minimalist cartoon avatar using linux?",
      "P-task": "creat minimalist cartoon avatar use linux",
      "F_verb": "create",
      "P-body": " I know there are softwares like gimp available for this platform but I have a very little knowledge about them. .   So do \"apt-get -y install gimp\" and try it out! It's not very hard to make a \"minimalistic cartoon avatar\" in \"gimp\". I don't think there is a FOSS tool that just takes a photo \".jpg\" and spits out a \"minimalistic cartoon avatar\" automatically. .  ",
      "P-tags": "image-process photoshop image-editor software-instal gimp",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "so_56368143",
      "task": "How to convert the result of invoke-request to a multidimensional array?",
      "P-task": "convert result invoke-request multidimension array",
      "F_verb": "convert",
      "P-body": "There are two problem lines in the JSON:  .   This line has a misplaced \"\"\"  \"{\"Name\":\"Opened On\",\"Values\":[\"Mark, John, L=Toronto, S=Ontario, C=CA\",\"www.doman.com\", O=Office, L=Toronto, S=Ontario, C=\"CA\"]},\" .  It should probably be  .  \"{\"Name\":\"Opened On\",\"Values\":[\"Mark, John, L=Toronto, S=Ontario, C=CA\",\"www.doman.com\", \"O=Office, L=Toronto, S=Ontario, C=CA\"]},\" .   And this line   \"{\"Name\":\"Internet System Address\",\"Values\"[\"www.doman.com/Locations\"]},\"  .  should have a \":\" after \"Values\" .  \"{\"Name\":\"Internet System Address\",\"Values\":[\"www.doman.com/Locations\"]},\" .  Once you've fixed those issues, the result is valid JSON and can be piped to ConvertFrom-JSON:  .  ",
      "P-tags": "json powershel invoke-webrequest",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "so_34906278",
      "task": "How to extract first and last name from a string",
      "P-task": "extract first last name string",
      "F_verb": "extract",
      "P-body": "Try this: .  This will output .  It splits on space and selects the first and last name .  Edit based on your Code: .  ",
      "P-tags": "powershel powershell-3 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "au_1211314",
      "task": "How to set a higher resolution for 2 external monitors?",
      "P-task": "set higher resolut 2 extern monitor",
      "F_verb": "set",
      "P-body": "According to the specs of Intel Corporation UHD Graphics 620 [1], it should be able to support up to 3 monitors up to 4096x2304@60Hz. However, the limiting factor seems to be the docking station. According to the compatibility matrix of the Lenovo ThinkPad Thunderbolt 3 Dock Gen 2 [2] it only supports 2 or 3 monitors (built-in monitor + 2 external monitors) at a maximum resolution of 3840x2160 if used at 30Hz. Unfortunately, I was not able to set both my screens to 3440x1440@30Hz but only one and the other on 2560x1080@30Hz which is okay. Still wondering though why it does not work with both on maximum resolution... Nevertheless, I'm fine with both on a reasonable 21:9 resolution for now. I used the following commands, in case someone else experiences the same issue with external monitors at 60 Hz on a higher resolution and wants to also try it out on 30 Hz: .  [1] https://www.intel.com/content/www/us/en/support/products/126789/graphics-drivers/graphics-for-8th-generation-intel-processors/intel-uhd-graphics-620.html .  [2] https://support.lenovo.com/in/en/solutions/pd029622 .  ",
      "P-tags": "multiple-monitor xrandr display",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "su_290577",
      "task": "how go to next page in man page",
      "P-task": "go next page man page",
      "F_verb": "go",
      "P-body": "\"man\" being piped through \"less\" has no way to generate much less follow any such links. You will need to invoke \"man 1 ssh-keygen\" yourself. .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V to NP in NP"
    },
    {
      "id": "so_17715774",
      "task": "C++ linux: dlopen can't find .so library",
      "P-task": "c++ linux : dlopen find librari",
      "F_verb": "find",
      "P-body": "Read the dlopen(3) man page (e.g. by typing \"man dlopen\" in a terminal on your machine): .   If filename contains a slash (\"/\"), then it is interpreted as a (relative or absolute) pathname. Otherwise, the dynamic linker searches for the library as follows (see ld.so(8) for further details): .   So you need to call \"dlopen(\"./libLibraryName.so\", RTLD_NOW)\" -not just \"dlopen(\"libLibraryName.so\", RTLD_NOW)\" which wants your plugin to be in your \"$LD_LIBRARY_PATH\" on in \"/usr/lib/\" etc .... - or add \".\" to your \"LD_LIBRARY_PATH\" (which I don't recommend for security reasons). .  As Jhonnash answered you should use and display the result of \"dlerror\" when \"dlopen\" (or \"dlsym\") fails: .  You might want to read some books like Advanced Linux Programming to get some knowledge about Linux system programming in general. .  ",
      "P-tags": "codeblock c++ linux dynamic-librari",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "au_724792",
      "task": "How to make sure that firewall is off?",
      "P-task": "make sure firewal",
      "F_verb": "make",
      "P-body": " You can turn it off and on with ... .  By default it is disabled. .   You can check if there are iptables rules active with: .  Your output, with no lines between the \"target prot opt source destination\" header and the next \"Chain\", indicates that no rules are active. .  If you have \"iptables\" active this will cancel it .   explanation of all the options   If you want a graphical method:  .   Website Image:   .  ",
      "P-tags": "14 04",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP that S"
    },
    {
      "id": "ul_133887",
      "task": "How do you encrypt a USB drive partition with the Twofish cipher and SHA-512 hash without using TrueCrypt?",
      "P-task": "encrypt usb drive partit twofish cipher sha-512 hash without use truecrypt",
      "F_verb": "encrypt",
      "P-body": "With a little help from reddit, I've figured it out. .  tcplay did the trick. It encrypted my USB flash drive with the following command: .  tcplay is essentially a TrueCrypt clone. It's available in the Ubuntu repositories. -c tells tcplay to create a new volume. -d specifies device. -a specifies hash. -b specifies cipher. .  If tcplay gives you problems, you can use the eCryptfs. .  Here's a helpful tutorial. .  ",
      "P-tags": "secur encrypt truecrypt cryptsetup luk",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP with NP without S_ING"
    },
    {
      "id": "au_35138",
      "task": "editing apache vhosts and ubuntu hosts file?",
      "P-task": "edit apach vhost ubuntu host file",
      "F_verb": "edit",
      "P-body": "File: /etc/hosts .  File: /etc/apache2/apache2.conf .  Files: /etc/apache2/sites-available/site{i}.local.conf (instead of {i} insert number: 1 or 2 or 3) .  In directory /etc/apache2/sites-enabled/ create symbolic links: .  Restart apache and have fun :) .  ",
      "P-tags": "11 04 virtualhost apache2 host",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_729670",
      "task": "sudo cp --preserve=all not preserving ownership",
      "P-task": "sudo cp -- preserv preserv ownership",
      "F_verb": "preserve",
      "P-body": "It was all down to operator error. The file system I was trying to copy to was not ext2 in the end but FAT32. I did a \"mount -l\" and found: .  ",
      "P-tags": "ownership permiss cp",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_44243710",
      "task": "How to take away the 'execute' permission from the root user?",
      "P-task": "take away execut permiss root user",
      "F_verb": "take",
      "P-body": "If you are simply looking for a small safeguard, an obstacle to accidentally running the script as \"root\", write the script to voluntarily exit if run as root. Add the following to the beginning of the script: .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "au_351593",
      "task": "bulk/batch convert mp4 and m4v files to webm via command line?",
      "P-task": "bulk batch convert mp4 m4v file webm via command line",
      "F_verb": "convert",
      "P-body": "Yes, with \"ffmpeg\" and \"bash\" this is not only possible, but very easy. .  Here is the command for variable bit-rate conversion for .mp4 -> .webm:  .  You can then use the command in a bash script to batch covert your files. Here is an example of how you could do that: .  Keep in mind that depending on your computer, this may take a very long time. .  And of course, this can be done for the m4v files as well. I won't guarantee everything will work since I don't have ffmpeg installed on this machine to test it, so you may need to modify the script and/or the conversion settings to suit your needs. .  Documentation for the webm encoder can be found here: http://trac.ffmpeg.org/wiki/vpxEncodingGuide .  ",
      "P-tags": "ffmpeg mp4 webm",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP via NP"
    },
    {
      "id": "su_1652568",
      "task": "Create .zip with PowerShell",
      "P-task": "creat zip powershel",
      "F_verb": "create",
      "P-body": "This could be done as a two-step process: .   Call RoboCopy through PowerShell to copy the directory structure and files of a specific extension [\"/E\" argument copies empty folders, too, if needed]: .   Now call Compress-Archive to compress \"C:\\Destination\". .    ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP"
    },
    {
      "id": "so_22495497",
      "task": "making a linked list in kernel module",
      "P-task": "make link list kernel modul",
      "F_verb": "make",
      "P-body": "1) You have to use memecpy function to copy content from message to your data structure.  .  2) If the message is pointer point to a memory buffer in user space, you have to use the copy_from_user() function instead of memcpy. This function will handle the user space to kernel space memory copy.  .  3) Please do not reinvent the wheel. The kernel already has link list structure herel and your can just use it rather than recreate it. Besides, if the list may be access by different threads, you have to protect them by a lock before access it. .  ",
      "P-tags": "linux struct c linux-kernel",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "so_16204522",
      "task": "Bash: Find a string before another string in a file",
      "P-task": "bash : find string anoth string file",
      "F_verb": "find",
      "P-body": "With awk : .  StringA and StringB can be regular expressions. .  ",
      "P-tags": "grep sed bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP before NP in NP"
    },
    {
      "id": "so_52275411",
      "task": "Powershell - Disable and move users to a new OU",
      "P-task": "powershel - disabl move user new ou",
      "F_verb": "move",
      "P-body": "You could use the \"-PassThru\" switch with \"Disable-ADAccount\" to hand your user object along the pipline to \"Move-ADObject\" .  Alternative this should work as well: .  ",
      "P-tags": "powershel foreach",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP"
    },
    {
      "id": "so_29817186",
      "task": "How to get all lines from one file which contain a string in another file?",
      "P-task": "get line one file contain string anoth file",
      "F_verb": "get",
      "P-body": "This is what works finally. .  ",
      "P-tags": "file linux python bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP which S"
    },
    {
      "id": "so_57664912",
      "task": "How would one add a domain user to a PC from Command Prompt or PowerShell?",
      "P-task": "would one add domain user pc command prompt powershel",
      "F_verb": "add",
      "P-body": "Add-LocalGroupMember does exactly that. .  Example: .  where \"-Name\" sepcifies the name of the local group to which the user should be added. .  ",
      "P-tags": "powershel command-prompt command-line-argu command-lin",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP from NP"
    },
    {
      "id": "so_49163197",
      "task": "Adding extra argument to xargs",
      "P-task": "ad extra argument xarg",
      "F_verb": "add",
      "P-body": "If you want \"EXTRA_ARG\" to be available to the subshell, you need to \"export\" it. You can do that either explicitly, with the \"export\" keyword, or by putting the \"var=value\" assignment in the same simple command as \"xargs\" itself: .  The \"_\" prevents the first argument passed from \"xargs\" to \"bash\" from becoming \"$0\", and thus not included in \"\"$@\"\". .  Note also that I changed \"\"${suite_array[@]}\"\" to be assigned by splitting \"$1\" on commas. This or something like it (you could use \"IFS=$'\\n'\" to split on newlines instead, for example) is necessary, as \"$1\" cannot contain a literal array; every shell command-line argument is only a single string. .  ",
      "P-tags": "xarg shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "au_257617",
      "task": "How can I upgrade the Ubuntu LTS kernel to newer?",
      "P-task": "upgrad ubuntu lt kernel newer",
      "F_verb": "upgrade",
      "P-body": "New deployments of 12.04.2 will be installed with an updated kernel and a new X windows stack. For existing 12.04 deployments, users will need to opt-in to what is being called the LTS Hardware Enablement Stack. If you already have Ubuntu 12.04 installed with an earlier kernel stack, it is recommended that you keep this stack in place rather than switching to a later kernel; the newer kernel and X stacks are provided for enablement of hardware not supported by earlier kernels, and there is generally no reason to upgrade to a newer stack if your hardware is supported by the default kernel. .  In order to upgrade to the 3.5 kernel on 12.04.2, you will need to run the following command(s): .  For the new kernel: .  For the new X stack: .  WARNING: If you are using the xorg-edgers PPA, do not install the xserver-xorg-lts-quantal package as this will most likely result in breakage.  .  Reference: https://launchpad.net/~xorg-edgers/+archive/ppa .  This is only recommended for x86 hardware installations. .  See also: .   The 12.04.2 Release Notes for more details. Quantal backported kernel in 12.04.2? What's going on there? How to remove Kernel/LTS Enablement Stack?  ",
      "P-tags": "kernel hardware-enablement-stack lt",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP to NP"
    },
    {
      "id": "so_2802738",
      "task": "Perl -check for uninitialized value",
      "P-task": "perl -check uniniti valu",
      "F_verb": "check",
      "P-body": "In scalar context (for example, in an \"if\" or \"unless\" condition), an array evaluates to the number of items in the array. If your SQL result set contains no rows, the array will evaluate to 0 -- one flavor of falseness. .  ",
      "P-tags": "perl unix",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V for NP"
    },
    {
      "id": "au_1002209",
      "task": "Can't get fresh Ubuntu server to update/upgrade",
      "P-task": "get fresh ubuntu server updat upgrad",
      "F_verb": "get",
      "P-body": "Ubuntu 17.04, released in 2017-April (hence 17.04) came with nine months of support; 2017-04 + 9 months = 13-Jan-2018 EOL (End-Of-Life). .  Sometime after EOL (no length-of-time is defined) the repos get moved from \"archives.ubuntu.com\" (where Ubuntu versions look for updates) to \"old-releases.ubuntu.com\", so your 17.04 is looking for updates where they were. .  Given it's a clean install - just use 17.10, or an LTS (long term support; five years of support) version if you don't want to upgrade often. .  If you looked (eg. opened-in-a-browser) the address you specified \"http://security.ubuntu.com/ubuntu\" has artful (17.10), xenial (16.04), trusty (14.04) & other supported releases (inc. 'in-test' 18.04), but will discover the 'zesty' (17.04) & other post-EOL release folders are gone. .  ",
      "P-tags": "17 04 server",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_908646",
      "task": "How to setup luks encryption to ask for passphrase after suspend",
      "P-task": "setup luk encrypt ask passphras suspend",
      "F_verb": "ask",
      "P-body": "I don't think that's possible, because when you boot up, everything will be decrypted and while you suspend your system, your files are still available in decrypted form and many of them are available on your memory. .  While you are booting-up the system, a lot of tools will be get involved to decrypt your full encrypted device (Hard disk), things like \"GRUB\" and \"initramfs\". .  However, When your system is running, that means a lot of your resource are busy and you can't just encrypt all of them on the air; At the same time, if even it was possible, then you have no more tools available to decrypt your device again. .  As we can see in \"cryptsetup's\" man page, there are two subcommand: \"luksResume\" and \"luksSuspend\", these two are not related to system suspend, they suspend a device; And if we pay more attention we will find an warning: .   WARNING: never suspend the device on which the cryptsetup binary resides.  .   Which mean it's not capable of encrypting whole system while it's running, because as I already said, it's not capable of decrypting it again. .  \"luks\" will protect you against \"cold boot\" attacks, you can use Ubuntu home encrypting in contrast of \"luks\" to protect your home directory when you are not logged in but your machine is running.  .  For \"luks\", you can use \"hibernate\" feature, because everything will be stored on hard disk and your memory will be freed. it should do the job. .  ",
      "P-tags": "suspend encrypt luk 16 04",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V for NP after NP"
    },
    {
      "id": "au_1324381",
      "task": "How to install and use latest Nitech HTS voices for festival on Ubuntu 20.04",
      "P-task": "instal use latest nitech ht voic festiv ubuntu 20 04",
      "F_verb": "install",
      "P-body": "Notice There seems to be a bit of misunderstanding on your side... The Nitech HTS 2.3.2 which was released in 2017 is a speech synthesis system/engine which uses deep learning and neural networks to train speech modules based on datasets like these... The resulting modules can then be built for use with different speech engines including festivals. It is not a group of voices that you can download and use with festival. .  Pre-built voice modules are available on the Internet. So you can either use the pre-built voices available in the link below as well as the ones provided by the links in your comment above or you can go ahead and build your own and you can start from here.Please notice thee following on that page: .   These distibutions include Festival CLUNITS based voices. bdl, slt, jmk and awb HTS based voices are available from available from http://hts.ics.nitech.ac.jp/ using Nagoya Institute of Technology's HTS HMM-based Speech Synthesis System. .   So the voices are already pre-built and available for festival 2.5.0 since the year 2017 on this link .  Please also keep in mind that setting the right environment, training and building is a lengthy process that might take days and a lot of resources and effort. .   Adding pre-built voices to Festival (Version 2.5.0:release December 2017) Festival voices go under \"/usr/share/festival/voices/\" and the voices you refer to are linked here. To add and use new pre-built voices, please follow the instructions below: .   Cleate a new directory for the new voices like so: .   \"cd\" to your Downloads directory like so: .   Donload desired voice from here like so: .   Extract the downloaded voice file like so: .   Copy the new downloaded voice located under \"festival/lib/voices/us/\" in the extracted file to festivals voices like so: .   Start festival like so: .   List the available voices like so: .   The output will look like this: .   Select the newly added voice by adding \"voice_\" prefix before its name like so: .   Test the new voice like so: .    ",
      "P-tags": "festiv",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "au_424329",
      "task": "Error trying to compile qemu from source",
      "P-task": "error tri compil qemu sourc",
      "F_verb": "compile",
      "P-body": "To fix this issue: .   Cloned dtc from its repository and extract the tarball to \"qemu/dtc/\". .  Compile dtc from source using \"make\" .  Restart configuring qemu using \"./configure\" when in \"qemu\" directory. .   The problem was qemu tries to search for dtc binaries in \"qemu/dtc\". Even if you have installed dtc using \"sudo apt-get install device-tree-compiler\", you will get the above error(mentioned in the question), so you probably need to have the binaries in \"qemu/dtc\". .  ",
      "P-tags": "qemu 12 10",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_139252",
      "task": "Give user permission to rm without password or sudo",
      "P-task": "give user permiss rm without password sudo",
      "F_verb": "give",
      "P-body": "First of all, you should probably consider why this isn't working in the first place. If you don't understand why they are owned as different users there is a good chance that you will be breaking something by attempting to hack around the limitation. It is quite likely that there is a security issue you will be opening yourself up to by doing this. .  Additionally, sudo is the right method for a lot of things, but if you are setting it up without a password that is another indication that you are doing something wrong from a security standpoint. Don't assume that because its \"your\" machine and \"you are the only one using it\" that you don't need to worry about these things. Especially if you are running a service like and HTTP server, there is a reason the files being served are owned by a different user than you normally use on the system! .  All caveats aside, the proper fix for this is to use the normal file system permission levels to give your ubuntu user permission to operate on the files without having to change to another user or escalate to root privilege levels. This is probably easiest done by adding the ubuntu user to the group that owns /www. .  Now assuming your files have group as well as owner permissions (i.e. \"664\" or similar for files and \"775\" for directories) you should be good to go for normal file operations with no special sudo interventions. .  Note: After adding a user to a group you have to actually login again in order to for the system to recognize you as part of the new group. .  ",
      "P-tags": "sudo permiss rm",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP to NP without NP"
    },
    {
      "id": "so_55395101",
      "task": "Import-Csv data parse to array",
      "P-task": "import-csv data pars array",
      "F_verb": "parse",
      "P-body": "The likeliest explanation is that: .   the multi-line value from your CSV (obtained from a single field) contains LF-only (Unix-style) newlines,  whereas the string derived form the registry values has CRLF (Windows-style) newlines, due to applying \"Out-String\" to an array of strings.  The most direct fix is to remove the CR chars. from \"$regval\" (you can use \"\"`r\"\" in PowerShell to generate a CR char): .  That said: .   Since you're comparing just two objects that are strings, you can avoid the overhead of \"Compare-Object\" and simply use \"-eq\": .   Alternatively, you can split the multi-line values into arrays of lines and compare them individually; note that if you use regex \"\"`r?`n\"\" or (\"'\\r?\\n'\") to match newlines to split by - which matches both LF-only and CRLF newlines - you needn't remove CR chars. beforehand or even apply \"Out-String\" to the array output from the \"Get-ItemProperty HKLM:\\...\" call to begin with; however, with the variable values from your question, you'd use: .     As for what you tried: .   \"$Tostring = ($data.Value | out-string).Trim()\" .   If \"$data.Value\" is a single string that doesn't have a trailing newline - whether or not it has embedded newlines - the above is an effective no-op: .   An input object that is already a string is passed through as-is by \"Out-String\". While \"Out-String\" does append a trailing CRLF newline (on Windows), the subsequent \".Trim()\" call removes it again.  ",
      "P-tags": "powershel compareobject",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V S_INF"
    },
    {
      "id": "so_22167481",
      "task": "Install rst2man failed for varnish agent [fix]",
      "P-task": "instal rst2man fail varnish agent fix",
      "F_verb": "install",
      "P-body": "rst2man is a virtual package, then you need install python-docutils package than provide rst2man and utilities for the documentation of Python modules. .  After install this package, try the command: .  ",
      "P-tags": "apt-get varnish sudo packag ubuntu-serv",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP"
    },
    {
      "id": "so_51296141",
      "task": "Running into a race-condition, even with a 'wait'",
      "P-task": "run race-condit even wait",
      "F_verb": "run",
      "P-body": "I noticed that each the following three hacks work, but not quite sure why: .  Hack 1 .  Hack 2 .  Hack 3 .  Could this be a 'flushing problem' with OS' disk-buffer/cache, especially when dealing with background processes, especially in \"bash\"? In other words, the call to \"wait\" seems to returning BEFORE it flushes the diskcache (or, BEFORE the OS, on its own realizes and, is done flushing the diskcache). .  EDIT Thanks to @Jon, his was a very close guess and got me thinking in the right direction, along with the age-old, bit-wise tweaking advice from @chepner.  .  The Real Problem: I was starting \"foo\", not directly/plainly as shown in my inaccurate abstracted version in my original question, but via another \"launchThread\" function that, after doing some bookkeeping, would also say \"foo 1 &\" in its body. And the call to \"launchThread\" was itself suffixed with an \"&\"! So, my \"wait\" was really waiting on \"launchThread\" and not on \"foo\"! The \"sleep\", \"sync\", and \"while\" just were helping buy more time for \"foo\" to complete, which is why introducing them worked. The following is a more accurate demonstration of the problem, even though you may or may not be able to duplicate it on your own system (due to scheduling/timing variance across systems): .  Output of the above buggy program: .  If I remove the \"&\" from EITHER \"Line 2\" OR from \"Line 3\", the program works correctly, with the following as output: .  The program also works correctly if I remove the \"$(now)\" part from \"Line 1\". .  ",
      "P-tags": "race-condit flush wait diskcach bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V into NP with NP"
    },
    {
      "id": "au_1189139",
      "task": "How to install free software with Software without registration?",
      "P-task": "instal free softwar softwar without registr",
      "F_verb": "install",
      "P-body": "You do not have to use the Software Center - neither do I. .  You can either install it via command line \"sudo apt-get install arduino\" or - especially if you prefer a more up-to-date version, you can download it from https://www.arduino.cc/en/Main/Software .  ",
      "P-tags": "software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP without NP"
    },
    {
      "id": "au_412372",
      "task": "How to fix Libreoffice and Python3-uno",
      "P-task": "fix libreoffic python3-uno",
      "F_verb": "fix",
      "P-body": "When I ran the following command, .  it told me something about /var/lib/dpkg/info/python3-uno.prerm and py3clean. I removed python3-uno.prerm and reinstalled libreoffoffice and it works fine! .  ",
      "P-tags": "depend apt python libreoffic",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_18595340",
      "task": "How to open raw UDP socket in promiscuous mode?",
      "P-task": "open raw udp socket promiscu mode",
      "F_verb": "open",
      "P-body": "It's because you use \"SOL_PACKET\" which is only used for \"packet(7)\" sockets. For raw \"INET\" sockets, you don't need that option. .  ",
      "P-tags": "socket linux raw-socket network-program c",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP"
    },
    {
      "id": "so_56415274",
      "task": "how to use sls with get-azlocation in Azure (Powershell)",
      "P-task": "use sl get-azloc azur powershel",
      "F_verb": "use",
      "P-body": "As the comment mentioned, you could use \"Where-Object\". .   .  ",
      "P-tags": "azur powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_461091",
      "task": "How to check every file in directory and ask the user to do action in csh shell",
      "P-task": "check everi file directori ask user action csh shell",
      "F_verb": "check",
      "P-body": "Part of your shell code looks like \"bash\" code even though you use a \"#!\"-line specifying \"csh\". \"csh\" does not have a \"read\" command, and this is why you get a \"signal 13\" error. .  Signal 13 is the PIPE signal, and it gets sent to a process when it's trying to write to a dead pipe (a pipe that nobody is reading from the other end of). The pipe is dead because the \"read\" call failed in the \"while\"-loop. It failed since it's not available in \"csh\".  .  If \"csh\" had had a \"read\" command, your loop would get filenames, but you would not have had any way of knowing where those filenames belonged (in what subdirectory) since you removed the directory path from them. You would therefore not be able to do much with them. .   The easiest way for doing this would be to have \"find\" ask the question to the user: .  This would ask for confirmation for each pathname before executing the \"some-action\" utility with the pathname as its argument. It would ask with the complete command line that would be executed for the given pathname, so it's not quite what you might have in mind. .  Note also that specifying \"-type f\" will find all regular files, while your \"-name '*'\" test will always be true for all types of files, including directories. I'm also using \".\" (the current directory) for the top-level directory for \"find\", which is what you seem to want to do with your \"DIR\" variable. .  To manually ask the user for input on each file, and at the same time handle pathnames correctly, the easiest would be to do something like .  This assumes a \"sh\"-like shell, and will spawn \"sh -c\" for batches of pathnames found by \"find\". The internal shell script would ask the user whether they'd like to process each individual pathname or not. If the user answers with a word starting with \"n\" (case insensitive), the next pathname would be considered. .  The \"\"${pathname##*/}\"\" bit in the code is equivalent to \"\"$( basename \"$pathname\" )\"\" as it removes everything in \"$pathname\" up to and including the last slash. .  The \"find\" command acts as a sort of generator of pathnames for the \"for\"-loop in the internal script, so piping pathnames or filenames to a \"while\"-loop is never necessary. .  Related: .   Understanding the -exec option of `find`  ",
      "P-tags": "user-input csh",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "so_63892211",
      "task": "Do I need apt-get update and upgrade in my Python Dockerfile",
      "P-task": "need apt-get updat upgrad python dockerfil",
      "F_verb": "upgrade",
      "P-body": "The base Docker Hub Linux distribution images like \"ubuntu:18.04\" actually update themselves fairly regularly: if you \"docker pull ubuntu:18.04\", wait a week, and repeat it, you will get a newer image. You're somewhat dependent on intermediate images, like \"python:3.8\", doing the same thing. .  It is unusual, but not unheard-of, to run \"apt-get update\" and similar \"upgrade everything\" commands in a Dockerfile; it is more common to either assume the base image is up-to-date already, or to have specific provenance requirements and build everything from scratch on top of a base distribution image. .  If you're using a major-version or minor-version image tag (\"python:3\", \"python:3.8\", \"python:3.8-buster\") you're probably okay, so long as you make sure to update your base image to something listed on the Docker Hub image page periodically. If you're forcing a specific patch level (\"python:3.8.4\") you're at some risk, since these images stop getting updates once a newer upstream version is released. .  You do need to run \"apt-get update\" if you need to install any OS-level packages, and for Docker layer-caching reasons you should do it in the same \"RUN\" command as the corresponding \"apt-get install\" .  ",
      "P-tags": "linux python apt-get docker",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V in NP"
    },
    {
      "id": "au_199489",
      "task": "What's the easiest way to upgrade Ghostscript?",
      "P-task": "easiest way upgrad ghostscript",
      "F_verb": "upgrade",
      "P-body": "ghostscript is not found under Ubuntu Software Center  .  So, either install it from there or you can just update your current version to latest one: .  If that doesn't work download one of the following: .   64 bit 32bit   Then: .  ",
      "P-tags": "upgrad ghostscript",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_1218130",
      "task": "Ubuntu 18.04 - Lenovo Thinkpad Carbon sound card not recognized since firmware update",
      "P-task": "ubuntu 18 04 - lenovo thinkpad carbon sound card recogn sinc firmwar updat",
      "F_verb": "update",
      "P-body": "Thanks to all of you that answered and commented my question. While waiting for an answer here, I found someone on the web with the same problem that was advised to go and look here : https://bugs.launchpad.net/ubuntu/+source/linux-oem-osp1/+bug/1864061/comments/3. The two steps proposed there solved the issue : .   add \"options snd-hda-intel dmic_detect=0\" in the configuration file \"/etc/modprobe.d/alsa-base.conf\" add \"blacklist snd_soc_skl\" in the config file \"/etc/modprobe.d/blacklist.conf\"  As this fixed my issue, I do not know if other solutions work as well, but I'm sure they do :). Thanks again! .  ",
      "P-tags": "sound thinkpad driver 18 04 lenovo",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_16765389",
      "task": "Is it true, that modern OS may skip copy when realloc is called",
      "P-task": "true modern os may skip copi realloc call",
      "F_verb": "skip",
      "P-body": " 1) Is it true that modern OS (Linux - the most interesting for me; FreeBSD, OSX, Windows) and their realloc implementations really capable to realloc pages of data using reordering of virtual-to-physical mapping and without byte-by-byte copy? .  2) What is the system call used to achieve this memory move? (I think it can be splice with SPLICE_F_MOVE, but it was flawed and no-op now (?)) .   See thejh's answer. .  Who are the actors? You have at least three actors with your Qt example. .   Qt Vector class glibc's \"realloc()\" Linux's \"mremap\"  \"QVector::capacity()\" shows that Qt allocates more elements than required. This means that a typical addition of an element will not \"realloc()\" anything. The glibc allocator is based on Doug Lea's allocator. This is a binning allocator which supports the use of Linux's \"mremap\". A binning allocator groups similar sized allocations in bins, so a typical random sized allocation will still have some room to grow without needing to call the system. Ie, the free pool or slack is located a the end of the allocated memory. .  An answer  3) Is it profitable to use such page shuffling instead of byte-by-byte copy, especially in multicore multithreaded world, where every change of virtual-to-physical mapping need to flush (invalidate) changed page table entries from TLBs in all tens of CPU cores with IPI? (In linux this is smth like flush_tlb_range or flush_tlb_page) .   First off, faster ... than mremap is mis-using \"mremap()\" as R notes there. .  There are several things that make \"mremap()\" valuable as a primitive for \"realloc()\". .   Reduced memory consumption. Preserving page mappings. Avoiding moving data.  Everything in this answer is based upon Linux's implementation, but the semantics can be transferred to other OS's. .  Reduce memory consumption Consider a naive \"realloc()\". .  In order to support this, you may need double the memory of the \"realloc()\" before you go to swap or simply fail to reallocate. .  Preserve page mappings Linux will by default map new allocations to a zero page; a 4k page full of zero data. This is useful for sparsely mapped data structures. If no one writes to the data page, then no physical memory is allocated besides a possible \"PTE\" table. These are copy on write or COW. By using the naive \"realloc()\", these mappings will not be preserved and full physical memory is allocated for all zero pages. .  If the task is involved in a \"fork()\", the initial \"realloc()\" data maybe shared between parent and child. Again, COW will cause physical allocation of pages. The naive implementation will discount this and require separate physical memory per process. .  If the system is under memory pressure, the existing \"realloc()\" pages may not be in physical memory but in swap. The naive \"realloc\" will cause disk reads of the swap page into memory, copy to the updated location, and then likely write the data out to the disk. .  Avoid moving data The issue you consider of updating TLBs is minimal compared to the data. A single TLB is typically 4 bytes and represents a page (4K) of physical data. If you flush the entire TLB for a 4GB system, that is 4MB of data that needs to be restored. Copying large amounts of data will blow the L1 and L2 caches. TLB fetches naturally pipeline better than d-cache and i-cache. It is rare that code will get two TLB misses in a row as most code is sequential. .  CPUs are of two variants, VIVT (non-x86) and VIPT as per x86. The VIVT versions usually have mechanisms to invalidate single TLB entries. For a VIPT system, the caches should not need to be invalidated as they are physically tagged. .  On a multi-core systems, it is atypical to run one process on all cores. Only cores with the process performing \"mremap()\" need to have page table updates. As a process is migrated to a core (typical context switch), it needs to have the page table migrated anyways. .  Conclusion You can construct some pathological cases where a naive copy will work better. As Linux (and most OS's) are for multi-tasking, more than one process will be running. Also, the worst case will be when swapping and the naive implementation will always be worse here (unless you have a disk faster than memory). For minimal \"realloc()\" sizes, the dlmalloc or QVector should have fallow space to avoid system level \"mremap()\". A typical \"mremap()\" may just expand a virtual address range by growing the region with a random page from the free pool. It is only when the virtual address range must move that \"mremap()\" may need a tlb flush, with all the following being true, .   The \"realloc()\" memory should not be shared with a parent or child process. The memory should not be sparse (mostly zero or untouched). The system should not be under memory pressure using swap.  The tlb flush and IPI needs to take place only if the same process is current on other cores. L1-cache loading in not needed for the \"mremap()\", but is for the naive version. The L2 is usually shared between cores and will be current in all cases. The naive version will force the L2 to reload. The \"mremap()\" might leave some unused data out of the L2-cache; this is normally a good thing, but could be a disadvantage under some work loads. There are probably better ways to do this such as pre-fetching data. .  ",
      "P-tags": "realloc linux-kernel memory-manag",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP when S"
    },
    {
      "id": "ul_52215",
      "task": "Determine the size of a block device",
      "P-task": "determin size block devic",
      "F_verb": "determine",
      "P-body": "\"fdisk\" doesn't understand the partition layout used by my Mac running Linux, nor any other non-PC partition format. Yes, there's \"mac-fdisk\" for old Mac partition tables, and \"gdisk\" for newer GPT partition table, but those aren't the only other partition layouts out there.) .  Since the kernel already scanned the partition layouts when the block device came into service, why not ask it directly? .  ",
      "P-tags": "linux size",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "so_16542935",
      "task": "find command in python failing with \"missing argument to -exec\"",
      "P-task": "find command python fail miss argument -exec",
      "F_verb": "find",
      "P-body": "While using \"exec\", you need a semicolon to indicate the end of the command. .  ",
      "P-tags": "linux python command",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP with NP to NP"
    },
    {
      "id": "so_41635650",
      "task": "How to extract lines from a column separated by empty lines?",
      "P-task": "extract line column separ empti line",
      "F_verb": "extract",
      "P-body": "If you choose your record and field separators sensibly it is straightforward with \"awk\": .  Output: .  Explanation  \"RS=\" sets the record separator to \"empty line\". \"FS=\"\\n\"\" sets the field separator to new-line. \"OFS=\" \"\" sets the output separator to space. \"$1=$1\" reevaluates the input and splits it according to \"FS\". This also evaluates to true and thus outputs the input with \"OFS\" as the separator.  ",
      "P-tags": "unix text-process",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP by NP"
    },
    {
      "id": "ul_618877",
      "task": "How can I add a new physical volume to extend an existing LUKS-encrypted lvm (volume group) and maintain encryption?",
      "P-task": "add new physic volum extend exist luks-encrypt lvm volum group maintain encrypt",
      "F_verb": "add",
      "P-body": "You\u2019ll need to set up encryption on the new physical device: .  (replacing \"newdevice\" as appropriate). .  Then open it: .  You\u2019ll need to add a matching line to \"/etc/crypttab\" so that it\u2019s opened at boot. .  Once you have \"newdevice_crypt\", you can create a physical volume on it: .  and add it to your volume group. .  You can share the passphrase for several encrypted devices; see Using a single passphrase to unlock multiple encrypted disks at boot. .  ",
      "P-tags": "luk lvm",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_506918",
      "task": "Using Systemtap probing Getting the virtual address location of bytes for every read write operation in Linux",
      "P-task": "use systemtap probe get virtual address locat byte everi read write oper linux",
      "F_verb": "get",
      "P-body": "The following SystemTap script would allow you to get the read bytes as an string: .  ",
      "P-tags": "memori systemtap virtual-memori io",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP for NP in NP"
    },
    {
      "id": "au_977649",
      "task": "Accidentally deleted the ipsec.conf file - what to do now?",
      "P-task": "accident delet ipsec conf file -",
      "F_verb": "delete",
      "P-body": "It is reasonably straightforward to retrieve the required conf file from the 17.10 Ubuntu package. Use the following steps from the command line: .  This places the configuration file correctly in /etc and from here you will need to use elevated privileges (sudo) to edit the file using your favoured text editor. Once you are happy the testing directory can be safely removed: .  The Ubuntu file is by default completely commented out but it gives 2 simple examples, either of which could be a great start for you: .  Activate these settings by removing the '#' mark at the beginning of each line and then hopefully all will be well.  .  ",
      "P-tags": "vpn 17 10 ipsec",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP what S"
    },
    {
      "id": "au_408382",
      "task": "Enable Wobbly Windows correctly",
      "P-task": "enabl wobbl window correctli",
      "F_verb": "enable",
      "P-body": "I'm not sure why but I guess CCSM thinks that wobbly windows doesn't have a unity dependency and as a result it disables unity after enabling that effect. I have tried it myself and after a restart unity is gone: no launcher, no nothing. I would stay away from CCSM. .  There is a way to get the wobbly windows effect without using CCSM: https://askubuntu.com/a/166772/292615 .  EDIT .  Actually, the solution I pointed to is kind of long and I found an easier way to enable it without messing up unity. .   Open CCSM and go to \"Preferences > Plugin List\" tab. .  Uncheck \"Automatic plugin sorting\". .  On the left panel find \"wobbly\". Select it and press the right arrow. .  \"wobbly\" should have moved from the left to the right panel. .  And the effect should now be working. .   ",
      "P-tags": "compiz 13 04 uniti",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_34240442",
      "task": "How to import and use variables from a config/param file in a shell script",
      "P-task": "import use variabl config param file shell script",
      "F_verb": "import",
      "P-body": "Try this: .   The dot (\".\") tells the shell to execute the file as a script in the current environment (thus the environment changes are effective). See e.g. here. You must ensure the executed file is a valid script. .  Without the dot(\".\") the script is run in a new process, which can't alter it's parent environment. .   The relevant part of the documentation: .   . name [arg ...]  .  If name is a function defined with the function name reserved word syntax, the function is executed in the current environment (as if it had been defined with the name() syntax.) Otherwise if name refers to a file, the file is read in its entirety and the commands are executed in the current shell environment. The search path specified by PATH is used to find the directory containing the file. If any arguments arg are specified, they become the positional parameters while processing the . command and the original positional parameters are restored upon completion. Otherwise the positional parameters are unchanged. The exit status is the exit status of the last command executed. .   ",
      "P-tags": "ksh shell",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "su_1122153",
      "task": "how to make dir only show the file information",
      "P-task": "make dir show file inform",
      "F_verb": "make",
      "P-body": "one way to do it is using \"find\", but offers not the best performance, probably. .  be aware of case sensitivity (use \"find /I \"readme.txt\"\" for insensitivity) .  ",
      "P-tags": "batch-fil shell-script",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_16006747",
      "task": "how to replace last comma in a line with a string in unix",
      "P-task": "replac last comma line string unix",
      "F_verb": "replace",
      "P-body": "\"awk\" can be quite useful for manipulating data files like this one. Here's a one-liner that does more-or-less what you want. It prepends the string \"xxxxx\" to the twelfth field of each input line that has at least twelve fields. .  ",
      "P-tags": "unix shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP in NP"
    },
    {
      "id": "so_20782545",
      "task": "Tailing only updated line of file",
      "P-task": "tail updat line file",
      "F_verb": "update",
      "P-body": "I assume that file is a log file?  .  So maybe, instead of trying to come up with a way to remember what was written the last time, and only display what's new, you probably want to use a logging system [like syslogd, or a newer version of it], and tell it to log both in the file AND send it to flume? .  Otherwise, here is a dirty hack: create a \"shownew.sh\" file containing: .   At the first invocation of, say, \"shownew.sh /some/file\" : it displays it's whole content, if it's the first time you called it on \"/some/file\". .  Each further time you call the script: \"shownew.sh /some/file\" : it will only show lines that are now in \"${1}\" and that were not before in \"${1}.old\" ... I hope that's what you wanted ?  .   ",
      "P-tags": "unix hbase tail flume filesystem",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_326572",
      "task": "ps command not found in CentOS",
      "P-task": "ps command found cento",
      "F_verb": "find",
      "P-body": "If the ps command is missing you can reinstall it using  .  ",
      "P-tags": "subvers ps",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP"
    },
    {
      "id": "au_966236",
      "task": "How can I repair boot failure due to moved boot sector?",
      "P-task": "repair boot failur due move boot sector",
      "F_verb": "move",
      "P-body": "If you move the head end of the boot partition (which is the root partition, if the /boot directory is there), you must repair grub. You can do it according to the description in this link, .  help.ubuntu.com/community/Grub2/Installing#Reinstalling_GRUB_2 .  Manual methods are described as well as the automatic method with Boot Repair. You have better control, when you use the manual methods with the command line tool \"grub-install\". .  ",
      "P-tags": "partit boot",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP"
    },
    {
      "id": "so_3985295",
      "task": "Convert .bat file to .sh file",
      "P-task": "convert bat file sh file",
      "F_verb": "convert",
      "P-body": " ",
      "P-tags": "batch-fil bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_50265292",
      "task": "Php Fatal Error Class not found",
      "P-task": "php fatal error class found",
      "F_verb": "find",
      "P-body": "You need to require_once homepagebanner class first as below .  and as i seen in comments you are using linux make sure \"classes\" and \"HomePageBanner\" in code are in the same case as in the your directory \"/var/www/html\" .  ",
      "P-tags": "linux mysql php",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_43051294",
      "task": "For loop giving error while creating file",
      "P-task": "loop give error creat file",
      "F_verb": "create",
      "P-body": "There are two issues here: .   You're opening \"/tcb/files/auth/x/xyz\" locally, not on the remote system. \"sudo echo foo > bar\" does not provide extra privileges to help in opening \"bar\".  This latter is because \"something > output\" opens \"output\" before it runs \"something\". Thus, \"sudo\" hasn't even been started when \"/tcb/files/auth/x/xyz\" is opened! .  Instead, consider: .  The first problem is solved because the redirection is inside the string passed to \"ssh\" to be run by a remote shell. If you pass \"ssh\" a bunch of separate arguments, it just combines them with spaces to form such a string; it's better to form the string yourself, and thereby have more control). .  The second problem is solved by forcing \"/tcb/files/auth/x/xyz\" to be opened by \"tee\", after \"tee\" has had its privileges escalated by \"sudo\". .  ",
      "P-tags": "ksh shell",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    }
  ],
  "7": [
    {
      "id": "so_30247385",
      "task": "powershell filter to remove .pdf extension in the name of a file",
      "P-task": "powershel filter remov pdf extens name file",
      "F_verb": "remove",
      "P-body": " I'll start by posting something similar to Leptonator's answer, but simplified by using the \"Select-Object\" command (alias \"Select\" used in code because it's habit, and I'm lazy). .  Now that gets you the file names without extension. But, you actually asked for only part of the file names, as the first file name is \"HD 100616 Dec2014.pdf\" and you specified that you actually only want \"Dec2014\" to be returned. We can do that a couple different ways, but my favorite of them would be a RegEx match (because RegEx is awesome, and I think the \"LastIndexOf\"/\"SubString\" combo is overly complicated imho). .  So, a RegEx match of \"\"\\w+$\"\" will get what you want. That is broken down like this: .  \"\\w\" means any letter or number \"+\" means 1 or more of them \"$\" means the end of the string/line .  So that's 1 or more alpha-numeric characters at the end of the string. We pipe our array of file names into a \"ForEach-Object\" loop (alias \"ForEach\" used out of habit), and then we have: .  Now, this outputs a \"[System.Text.RegularExpressions.Match]\" object, which is more than you want, but it does have a property \"Value\" which is exactly what you asked for! So we use \"Select -Expand\" again for that property and the output is precisely what you asked for: .  RegEx matches are really handy, and if you learn about them you can simplify that quite a bit more like this: .  That one line, as well as the two line code above it both should output: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP of NP"
    },
    {
      "id": "ul_264059",
      "task": "Can I remove my password?",
      "P-task": "remov password",
      "F_verb": "remove",
      "P-body": "Yes you can remove your password from popup authentication, as well as remove passwords in general or your keyring. I would not recommend any of this as it is a security risk however if you wish you can follow the following after typing \"sudo visudo\"  .  NOPASSWD .  If you don\u2019t want to be prompted for any password while running sudo then we can use the NOPASSWD parameter on a particular entry: .  this parameter is the opposite of the default PASSWD and will no longer require any password for the user \u201cadmin\u201d while running 'sudo'. This can be of useful while running scripts that will launch 'sudo' (in this case I would recommend to enable NOPASSWD only for the needed commands), or just if you don\u2019t want to keep typing the password. Obviously with this commodity, you will reduce the security of sudo: if someone hacks the \u201cadmin\u201d account then this can be easily used to gain root privileges. .  Authenticate .  Another option that can be used to control the prompt for a password is the global flag: authenticate. This is by default ON and this means that it will ask the user to authenticate with a password. This can be overwritten as seen above with the 'NOPASSWD' on a particular entry. If we want to disable it globally, this can be done with: .  Once set, this will disable authentication for all users that use the defaults like our \u201cadmin\u201d sample from above. It can be overwritten on particular definition by setting the 'PASSWD' parameter: .  Note: this post doesn\u2019t recommend you to disable the passwords usage in sudo (this is not a good idea, by the way), but just to show you what options are available and how you can use them. Knowing the security implications of disabling password usage in sudo, use them wisely based on your particular needs. .  ",
      "P-tags": "linux-mint software-instal",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "au_1031940",
      "task": "How to switch from libinput to synaptics in Ubuntu 18.04",
      "P-task": "switch libinput synapt ubuntu 18 04",
      "F_verb": "switch",
      "P-body": "I had the same problem and basically solved it by following Ryko's advice. .  ... did the trick. I didn't uninstall libinput like Pilot6 said and libinput is still happily handling my keyboard, etc. .  ",
      "P-tags": "touchpad libinput 18 04 lt synapt",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V from NP to NP in NP"
    },
    {
      "id": "so_4622355",
      "task": "read in bash on whitespace-delimited file without empty fields collapsing",
      "P-task": "read bash whitespace-delimit file without empti field collaps",
      "F_verb": "read",
      "P-body": "Here's an approach with some niceties: .   input data from wherever becomes a pseudo-2D array in the main code (avoiding a common problem where the data is only available within one stage of a pipeline). no use of awk, tr, or other external progs a get/put accessor pair to hide the hairier syntax works on tab-delimited lines by using param matching instead of IFS=  The code. \"file_data\" and \"file_input\" are just for generating input as though from a external command called from the script. \"data\" and \"cols\" could be parameterized for the \"get\" and \"put\" calls, etc, but this script doesn't go that far.  .  Output: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V in NP on NP without S_ING"
    },
    {
      "id": "so_68511256",
      "task": "\"\"Your build pipeline references an undefined variable\" : it's just a powershell variable",
      "P-task": "build pipelin refer undefin variabl : powershel variabl",
      "F_verb": "build",
      "P-body": " Your build pipeline references an undefined variable named \u2018$add.key\u2019 .   This is triggered by the line below: .  The \"$($add.key)\" is parsed by Azure DevOps as macro syntax. You could avoid this by using string formatting: .  Btw, in most cases you don't need to use Write-Output - it's slow and superfluous. See this blog post for details: Let\u2019s Kill Write-Output. .  ",
      "P-tags": "powershel azure-devops-server-2020 azure-pipelin",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_29708778",
      "task": "How to create directories according to filename and copy that file to the end of the directory using bash scripting?",
      "P-task": "creat directori accord filenam copi file end directori use bash script",
      "F_verb": "create",
      "P-body": "A version that should works and some note below. Test it. After a \"chmod u+x Go.sh\" you can call with \"./Go.sh\" and it will take the default one, or you can pass it another destination path e.g. \"./Go.sh /media/UndercoverLemon/storage/definitive\" .  Notes: .  The shebang \"#!/bin/bash\" have to be the 1st line of the script.  .   Better here only 1 place Here below you check if the string $f is equal to same the string cut before -playlist*. If it is equal it means there was not the substring \"-playlist\" in $f. With the not \"!\" you negate the result of the test. Here \"uploader=\"some-user\"\" Here \"playlist=\"some-user-uploader-how-to-do-something\"\". Now you need to cut the part with the current user \"$uploader\" and the keyword \"-uploader-\" Here playlist=\"how-to-do-something\" Now you can create the directory if needed. \"mkdir -p full/path/to\" will give no error if existing and will make parent directories as needed. Now you can copy the file if needed. The option \"-n\" will say to \"cp\" \"do not overwrite an existing file\".  ",
      "P-tags": "video linux youtub bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP to NP"
    },
    {
      "id": "so_5831862",
      "task": "PHP: How to get the error message of failed shell command?",
      "P-task": "php : get error messag fail shell command",
      "F_verb": "get",
      "P-body": "You can use proc_open (as also suggested by Emil). below is a somewhat more complete example of how to achieve what you want. .  EDIT: .  changed output to write to file .  ",
      "P-tags": "mysqldump php bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_69941074",
      "task": "Converting Date string to datetime in powershell",
      "P-task": "convert date string datetim powershel",
      "F_verb": "convert",
      "P-body": "Because you can have strings like \"th\", \"st\", \"nd\" or \"rd\" in there, always followed by a comma, the best thing to do is to use a regex \"-replace\" on these first and next use \"[datetime]::PareseExact()\". .  To demonstrate: .  If your culture (locale) is already set to \"en-US\", you can set the third parameter to \"$null\" .  ",
      "P-tags": "powershel date",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_52916080",
      "task": "Python script doesn't work properly when ran through terminal, but works fine in Jupyter and Visual Studio",
      "P-task": "python script work properli ran termin work fine jupyt visual studio",
      "F_verb": "run",
      "P-body": "After finding the issue as described in the edit, I just implemented the following to get rid of the extra space: .  ",
      "P-tags": "ffmpeg python maco bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V through NP"
    },
    {
      "id": "ul_162506",
      "task": "How to concatenate two files in a new one and sort the output in one line",
      "P-task": "concaten two file new one sort output one line",
      "F_verb": "sort",
      "P-body": "You have already redirected the output of \"file1\" and \"file2\" to the new file \"file3\". .  With this command \"cat file1 file2 > file3 | sort\", \"sort\" after pipe.  .  This could be verified as below.  .  Now when I run the command as, \"cat file1 file2 > file3 | sort\" we could see that the contents of \"file1\" and \"file2\" are written to \"file3\" but it is not sorted.  .  I believe what you are trying to achieve could be fairly easily accomplished as, .  However, it doesn't show the output in the console window.  .  If you need the output of two files after sorted to be written to a new file and at the same time the sorted output to be available in the console, you could do something like below.  .  However, it is good to make use of \"tee\" in this case. \"tee\" could be effectively used as, .  The above command basically concatenates 2 files and sorts them and displays the output in the console and at the same time writes the output of the pipe to the new file specified using the \"tee\" command.  .  As user casey points out, if you have \"zsh\" shell available on your system, you could use the below command as well.  .  ",
      "P-tags": "sort cat",
      "source": "qa",
      "cate": "sort",
      "pat": "V NP in NP"
    },
    {
      "id": "so_39647604",
      "task": "In Powershell, I call a SQL query that returns 10 tables...how can I turn each table into its own variable?",
      "P-task": "powershel call sql queri return 10 tabl turn tabl variabl",
      "F_verb": "call",
      "P-body": "Thanks Matt. I ended up using... .  ",
      "P-tags": "sql powershel window excel",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP that S"
    },
    {
      "id": "so_5289557",
      "task": "Remove or replace double quotes from values of XML (specific search and replace)",
      "P-task": "remov replac doubl quot valu xml specif search replac",
      "F_verb": "replace",
      "P-body": "This may work, but you should really use the proper tools. .  ",
      "P-tags": "xml replac bash quot search",
      "source": "qa",
      "cate": "replace",
      "pat": "V"
    },
    {
      "id": "ul_155808",
      "task": "Replace word instances with its count attached to it",
      "P-task": "replac word instanc count attach",
      "F_verb": "replace",
      "P-body": "A job for \"perl\": .  ",
      "P-tags": "sed text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP"
    },
    {
      "id": "so_27273412",
      "task": "Cannot install packages inside docker Ubuntu image",
      "P-task": "instal packag insid docker ubuntu imag",
      "F_verb": "install",
      "P-body": "It is because there is no package cache in the image, you need to run: .  before installing packages, and if your command is in a Dockerfile, you'll then need: .  To suppress the standard output from a command use \"-qq\". E.g. .  ",
      "P-tags": "ubuntu-14 04 docker",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_51886667",
      "task": "A shell script that checks if the nginx service is running, with action",
      "P-task": "shell script check nginx servic run action",
      "F_verb": "check",
      "P-body": "I would maybe check the www services that you are trying to serve instead of if the service is running. Take a look at these various examples : .  Update: super simple example added here : .  ",
      "P-tags": "cron shell bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S with NP"
    },
    {
      "id": "so_41280071",
      "task": "Dynamically take ports from squid.conf files and put them to json file using bash",
      "P-task": "dynam take port squid conf file put json file use bash",
      "F_verb": "take",
      "P-body": "You can move the definition of \"tcp_ports\" inside the loop, and run it only on the current config file: .  ",
      "P-tags": "json bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP to NP using NP"
    },
    {
      "id": "au_232575",
      "task": "When I switch to new user, I am unable to see the name in the prompt - Why?",
      "P-task": "switch new user unabl see name prompt -",
      "F_verb": "see",
      "P-body": "I found the solution here .  but i will explain the exact steps I used. .  first at root i did a .  I saw that I have /bin/bash .  then i switch to www-data .  then i do a  .  I saw that I had .  instead. .  So I did a  .  I was prompted for my www-data password so I gave it. .  after that I switch back to root .  then i log back into www-data .  I checked the $SHELL again .  I saw that now it is  .  and also my prompt is back .  ",
      "P-tags": "prompt 12 10 command-lin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "au_634099",
      "task": "How to ssh using perl scipt,run a command, and return the output...?",
      "P-task": "ssh use perl scipt run command return output",
      "F_verb": "return",
      "P-body": "I agree that the current examples look helpful but don't always work! My previous examples are included in that. I'm not a Perl expert at all but I've cobbled the following together and it works for me: .  Obviously you'll want to change the hostname, username and location of your RSA/DSA/etc key. Additionally, you'll need the compat library to make this work well on Ubuntu: .  And finally \u2014assuming you call it \"script.pl\"\u2014 call it like so: .  ",
      "P-tags": "ssh perl command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_32748529",
      "task": "PowerShell script to remove file from hidden folders",
      "P-task": "powershel script remov file hidden folder",
      "F_verb": "remove",
      "P-body": "You are missing the the \"-Force\" parameter. The code below is using alias so it won't require horizontal scrolling. Know that \"gci\" is \"Get-ChildItem\". .  Note that you will only be able to get access if you have permission. .  At this point, you probably already took care of the non-hidden files. If you want to run the script again, but only for hidden files (and not non-hidden files), you can do that with the \"-Hidden\" flag. .  Again, you will only be able to get access if you have the permission. .  ",
      "P-tags": "powershel window appdata",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "au_25633",
      "task": "How to migrate user settings and data to new machine?",
      "P-task": "migrat user set data new machin",
      "F_verb": "migrate",
      "P-body": "User settings are stored in the Home folder by design. So, if you copy your \"/home/your-username\" to your new computer, you should be fine... .  ...but there are caveats: .   Permissions. It is common that \"programs\" (shellscripts, custom build programs) are put in the home folder. To preserve permissions, use the \"--preserve=mode\" switch (using \"cp\") or \"-p\" (using \"tar\") UserID / GroupID. Even if the usernames are equal on both systems, the user ID do not have to. Usually, this is not a problem, but if you've scripts/programs/settings relaying on the UserID, you should make sure that the user ID and group ID should be the same on the target system. You can find the current userID and groupID by executing \"id\". For example, to change the userID of user \"your-username\", run \"sudo usermod --uid 1234 your-username\". To change the groupID, you have to run \"sudo groupmod --gid 1234 your-username\".  Settings (Firefox profile, appearance, ...) are often stored in hidden folders (or files). Hidden folders/files are prefixed with a dot, like \".mozilla\" for Firefox (and other Mozilla applications). .  As security is not an issue, and you want to have the copying job done as fast as possible, I suggest a combination of the netcat and tar programs. Both applications are installed by default. Make sure that the firewalls on both computers allows ingoing access to destination port 8888 (source computer) and outgoing to destination port 8888 (target computer). Put the nettop next to the computer so you can run the commands quickly. .  On the source computer, you need to have the traditional netcat program installed (a.k.a. Swiss Army Knife, not the BSD one). To do so, install the \"netcat-traditional\" package. You may also want to configure the traditional netcat program as default. Commands to install netcat-traditional and use it as default: .  On the source computer, type the next command in a terminal (do not press Enter yet): .  Explanation: .   tar is an utility for packing files \"cz\" creates such a packed file (\"tarball\") The tarball is compressed using the GZip algorithm to lower the file size. \"-C/home $(whoami)\" changes the working directory to \"/home\" and puts your username folder. Alternative, you can type your \"your-username\" folder in the tarball \"nc\" (netcat) is used for setting up connections between machines easily \"-l\": Listening mode, allows other machines to connect to the current machine \"-p 8888\": Listens on port 8888 (randomly chosen number, it could be any other number higher than 1024 as well) \"-w 10\": quit netcat after 10 seconds silence. You must connect to this source computer within this time.  Now go to the target computer (nettop). To add the files to the target machine, type (do not run it yet): .   \"192.168.1.2\" is the IP address of the source computer. To get its IP address, run: \"ifconfig\" on the source machine \"8888\" is the port number as entered on the source machine \"xzp\": extracts the GZip-compressed tarball while preserving permissions. \"-C/home\": extracts the \"your-username\" folder to \"/home/your-username\" Optionally, add the \"-v\" switch to the tar command for verbose extraction, so you can get an idea of the progress. This could slow down the copy process because every file has to be printed.  Now go to the source computer, press Enter to run the server command. Quickly switch to your nettop and press Enter to run the client command. .  If you have any questions, just use the comment field below. .  ",
      "P-tags": "user-data clone",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_323122",
      "task": "When a vulnerability has been found affecting Linux Kernel, what should I do with Docker?",
      "P-task": "vulner found affect linux kernel docker",
      "F_verb": "find",
      "P-body": "Since docker containers use the host kernel. Once the host kernel is updated you won't have problems with the containers.  .  Issues in libraries are another story. Openssl for example is a library which can be different in containers and the host and should be upgraded.  .  It is a good practice to include a \"apt-get update && apt-get -q -y upgrade\" at the top of your Dockerfile. So you should build your images regularly.  .  If you use official images it is good practice to make a pull regularly to upgrade your containers. If you use docker-compose: .  It will upgrade them. For plain docker you need to make a pull. Delete the container and create a newer one pointing to the same volumes: .  Regards  .  ",
      "P-tags": "linux secur linux-kernel docker",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_47999144",
      "task": "Invoke-RestMethod and foreach loop",
      "P-task": "invoke-restmethod foreach loop",
      "F_verb": "invoke",
      "P-body": "As Ansgar Wiechers suggests in a comment on the question, do not use \"return\" inside a \"foreach\" statement's body in an attempt to return (output) a value while continuing the loop; \"return\" would return from any enclosing function or script.  .  Instead, rely on PowerShell's implicit output behavior, as demonstrated in this simple example: .  Simply referencing \"$el\" without assigning to a variable or piping / redirecting it elsewhere cause its value to be output. .  If needed at all, use \"continue\" to prevent execution of subsequent statements in the loop body while continuing the loop overall; use \"break\" to exit the loop. .   By contrast - and that may be the source of the confusion - inside the body of a \"ForEach-Object\" cmdlet call - as part of a pipeline - rather than the \"foreach\" statement, the rules change, and \"return\" indeed would only exit the iteration at hand and proceed with the next input object: .   Note that even in this case \"return $_\" is just syntactic sugar for \"$_; return\" - i.e., an output generating statement followed by a control-flow statement, and simply using \"$_\" may be enough. .  Do NOT use \"break\" / \"continue\" with the \"ForEach-Object\" cmdlet, as these statements would look for an enclosing loop statement (such as \"foreach\", \"do\", while`) and - in the absence of one - exit the entire script. .   Unfortunately, there is no direct way to exit a pipeline prematurely, - see https://github.com/PowerShell/PowerShell/issues/3821; make your voice heard there if you think this should change.   ",
      "P-tags": "powershel rest",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "ul_23291",
      "task": "How to ssh to remote server using a private key?",
      "P-task": "ssh remot server use privat key",
      "F_verb": "use",
      "P-body": "You need your SSH public key and you will need your ssh private key. Keys can be generated with \"ssh-keygen\". The private key must be kept on Server 1 and the public key must be stored on Server 2. .  This is completly described in the manpage of openssh, so I will quote a lot of it. You should read the section 'Authentication'. Also the openSSH manual should be really helpful: http://www.openssh.org/manual.html .  Please be careful with ssh because this affects the security of your server. .  From \"man ssh\": .  This means you can store your private key in your home directory in .ssh. Another possibility is to tell ssh via the \"-i\" parameter switch to use a special identity file. Also from \"man ssh\": .  This is for the private key. Now you need to introduce your public key on Server 2. Again a quote from \"man ssh\": .  The easiest way to achive that is to copy the file to Server 2 and append it to the authorized_keys file: .  Authorisation via public key must be allowed for the ssh daemon, see \"man ssh_config\". Usually this can be done by adding the following statement to the config file: .  ",
      "P-tags": "openssh ssh",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "su_1480463",
      "task": "Disable password login in console and SSH allowing only key-based login. User should be able to elevate",
      "P-task": "disabl password login consol ssh allow key-bas login\nuser abl elev",
      "F_verb": "disable",
      "P-body": "To disable automatic spawning of virtual terminals, set the following in \"/etc/systemd/logind.conf\": .  \"getty@tty1.service\" probably starts by default, so disable it: .  I think you need to restart \"systemd-logind.service\": .  and manually stop any existing \"getty@ttyN.service\": .  This may not terminate all processes using ttys, so you may want to examine the output of \"ps\" to find processes having \"/dev/tty*\" as their controlling terminals and deal with them. The \"-t\" option of \"ps\" may be helpful. .  Or just reboot. .   The relevant fragment of \"man 5 logind.conf\": .   \"NAutoVTs=\" Takes a positive integer. Configures how many virtual terminals (VTs) to allocate by default that, when switched to and are previously unused, \"autovt\" services are automatically spawned on. These services are instantiated from the template unit \"autovt@.service\" for the respective VT TTY name, for example, \"autovt@tty4.service\". By default, \"autovt@.service\" is linked to \"getty@.service\". In other words, login prompts are started dynamically as the user switches to unused virtual terminals. Hence, this parameter controls how many login \"gettys\" are available on the VTs. If a VT is already used by some other subsystem (for example, a graphical login), this kind of activation will not be attempted. Note that the VT configured in \"ReserveVT=\" is always subject to this kind of activation, even if it is not one of the VTs configured with the \"NAutoVTs=\" directive. Defaults to \"6\". When set to \"0\", automatic spawning of \"autovt\" services is disabled. .  \"ReserveVT=\" Takes a positive integer. Identifies one virtual terminal that shall unconditionally be reserved for \"autovt@.service\" activation (see above). The VT selected with this option will be marked busy unconditionally, so that no other subsystem will allocate it. This functionality is useful to ensure that, regardless of how many VTs are allocated by other subsystems, one login \"getty\" is always available. Defaults to \"6\" (in other words, there will always be a \"getty\" available on Alt-F6.). When set to \"0\", VT reservation is disabled. .   ",
      "P-tags": "linux ssh authent",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP in NP"
    },
    {
      "id": "so_45448481",
      "task": "How to get Azure SQL DB Password for user using powershell",
      "P-task": "get azur sql db password user use powershel",
      "F_verb": "get",
      "P-body": "As far as know, it is not possible. If you could get the password by using PowerShell, I think it is unsafe. Azure does not allow this. .  But, you could reset SQL DB password by using PowerShell. Just use \"Set-AzureRmSqlServer\". .  ",
      "P-tags": "azur azure-powershel azure-sql-databas",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP using NP"
    },
    {
      "id": "so_53963740",
      "task": "How to fix 'The Decimals'",
      "P-task": "fix decim",
      "F_verb": "fix",
      "P-body": "Even though guys in comments already pointed out how to perform such task it still might be a little confusing. So all together: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_1030695",
      "task": "How do I get icons for Thunar in 18.04?",
      "P-task": "get icon thunar 18 04",
      "F_verb": "get",
      "P-body": "The approach from hrzhu's answer still works: .   Install \"lxappearance\". Run it and pick a working icon theme. Note how the default, Adwaita, seems to be broken. Restart Thunar.   .  ",
      "P-tags": "icon 18 04 thunar",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_33772602",
      "task": "Redirecting stdout and stderr to a file in c++",
      "P-task": "redirect stdout stderr file c++",
      "F_verb": "redirect",
      "P-body": "first close stdout and stderr .  open new file to write logs to. .  duplicate the logfile file descriptor to use with stdout and stderr. see \"man dup2\" .  I hope above code help you.. .  ",
      "P-tags": "c++ linux log stdout",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "ul_22863",
      "task": "What's the best way to determine the working directory for UNIX process using 'ps'?",
      "P-task": "best way determin work directori unix process use ps",
      "F_verb": "determine",
      "P-body": "I'm not sure if that answers your question, but the \"pwdx\" could give you the current working directory of any process. .  Like this: .  You could also do what Ulrich Schwarz said and run  .  ",
      "P-tags": "command-lin shell-script process ps rubi",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP for NP using NP"
    },
    {
      "id": "so_62871747",
      "task": "Powershell script to convert .csv to .html and handling multiple files",
      "P-task": "powershel script convert csv html handl multipl file",
      "F_verb": "convert",
      "P-body": "You're close! What you need to do is define the \"$Pre\" string inside the ForEach-Object loop. The \"Select-Object\" you do in between there has no use unless you want to select a subset of the CSV data to output. .  Something like this should do it: .  An alternative could be to create your \"$Pre\" as template including placeholders \"{0}\" and \"{1}\", and fill in the name and id inside the ForEach loop using the \"-f\" Format operator: .  ",
      "P-tags": "jqueri powershel javascript html",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_193802",
      "task": "How do I compile an out-of-tree kernel driver on Fedora to fix super-slow wifi?",
      "P-task": "compil out-of-tre kernel driver fedora fix super-slow wifi",
      "F_verb": "compile",
      "P-body": "So, the core problem there is that it's looking for the kernel header files needed to compile new kernel modules. You can install those with .  sudo yum install kernel-devel .  But the further trick is that the compile process is looking for kernel devel files which match your running kernel. You can run \"uname -r\" to find the currently-running kernel, and \"rpm -q kernel-devel\". By default on an updated system, you will probably have multiple kernel versions installed, because the update system saves the last two for safety. But, unless you've rebooted after the last update, you may not be running the latest one. By contrast, the kernel-devel package is usually kept to the latest (and that's what you'll get with the yum install command above). .  So, if you reboot, you should have the newer kernel both installed and running, and when you run \"make\", you'll see it looking for the newer version instead of 3.17.4. .  That said, there is a note on the github repo you've linked which says that fixes for slow speed were slated to go into the 3.18 kernel, and since we're at 3.19.3 now, it is very likely that simply updating alone will fix your issue. .  (Disclaimer: I work on Fedora for my job, so I'm not unbiased, but I do want to add that our awesome kernel team does a great job of tracking the latest upstream kernel very closely and quickly, and rolls those updates out across all of our currently-supported releases, making Fedora a great choice for hardware-enablement issues like this.) .  ",
      "P-tags": "driver wifi fedora",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP on NP S_INF"
    },
    {
      "id": "au_582109",
      "task": "14.10: VirtualBox \"No suitable module for running kernel found\", Cannot Find Kernel Source",
      "P-task": "14 10 : virtualbox suitabl modul run kernel found find kernel sourc",
      "F_verb": "find",
      "P-body": "It seems like your upgrade from Ubuntu 14.04 to 14.10 broke something. You should have kernel version 3.16.0-30 .  Make sure that your \"/etc/apt/sources.list\" only contains entries with 'utopic' and not 'trusty'. Then make sure that following packages are installed, or install them if necessary:  .   apt-get install linux-generic linux-image-generic linux-headers-generic linux-signed-generic .   After that you should be able to remove and re-install virtualbox and rebuild the kernel module. .  ",
      "P-tags": "14 10 kernel virtualbox",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_37237310",
      "task": "Show a warning during import, when MySQL dump contains `use`",
      "P-task": "show warn import mysql dump contain use",
      "F_verb": "show",
      "P-body": "Reading while importing example: .  The example will import the file \"dump.sql\" into mysql while printing the use-statements as they come by: .  Explanation: If you have a full dump with all databases of the mysql server (\"--all-databases\" long option) and you would like to review all SQL \"USE\"-statements while the file pipes into mysql, you could make use of \"tee\" to duplicate the content on the fly and \"sed\" to only print from those duplicated lines if a line is a \"USE\"-statement. .  Then the filtered output is redirected to STDERR for review while the unfiltered output can be imported as normal by mysql. .  I hope this helps. .  ",
      "P-tags": "mysql bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP when S"
    },
    {
      "id": "au_1112364",
      "task": "Systemd service starts with enable/start command but does nothing on startup",
      "P-task": "systemd servic start enabl start command noth startup",
      "F_verb": "start",
      "P-body": "Did you try running the enable command? Assuming your service is called keyboard-backlight.service, try running the following: \"systemctl enable keyboard-backlight.service\". .  ",
      "P-tags": "systemd",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V with NP"
    },
    {
      "id": "ul_367966",
      "task": "What does the RSA key fingerprint represent for a forwarded port?",
      "P-task": "rsa key fingerprint repres forward port",
      "F_verb": "represent",
      "P-body": "The host's public keys in \"/etc/ssh/ssh_host_*_key.pub\": .  (Note that it doesn't matter if you ask \"ssh-keygen\" for a fingerprint of the private key (without the \".pub\" extension), it automatically reads the corresponding public key instead.) .  In your case, it's the RSA key that is mentioned, so \"/etc/ssh/ssh_host_rsa_key.pub\", and with the port forwarding, it's the host \"ssh\" eventually connects to.  .  With newer versions of \"ssh-keygen\", the default output is the base64-encoded SHA256 hash of the key. Adding the \"-E md5\" option gives the hex-encoded MD5 hash (but note that now there's a prefix indicating the hash type): .  ",
      "P-tags": "ssh ssh-tunnel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V for NP"
    },
    {
      "id": "ul_625496",
      "task": "Recover partition table from running system and encrypted disk",
      "P-task": "recov partit tabl run system encrypt disk",
      "F_verb": "recover",
      "P-body": "Finally I've used \"testdisk\" to solve the issue I've identify my other partition : .  So with that in mind I needed to identify my boot drive properly in \"testdisk\" and it was this one : .  I selected this selection and add two other partition corresponding to the value found in \"/sys/class/block\". \"testdisk\" uses start and end sector not start sector and count. So to find end sector you need to add comute \"start+count-1\". .  As partition type I chooses Luks partition in linux subcategorie. Et voil\u00e0. .  ",
      "P-tags": "data-recoveri fdisk luk gdisk",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP from NP"
    },
    {
      "id": "su_1334857",
      "task": "Run a powershell script exactly like a batch command",
      "P-task": "run powershel script exactli like batch command",
      "F_verb": "run",
      "P-body": "If you run \"stree.ps1\" in PowerShell like this: .  then your \"stree.bat\" should look like: .  See the documentation for more details. .  Edit: I haven't tested it, but I assume you would pass the arguments in the same way as with any other batch script: .  and then run: .  Edit 2: Ok, I tested it and it works like expected. .  ",
      "P-tags": "cmd exe command-lin powershel window batch",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_109698",
      "task": "dpkg: dependency problems prevent configuration of initramfs-tools",
      "P-task": "dpkg : depend problem prevent configur initramfs-tool",
      "F_verb": "prevent",
      "P-body": "Your system is in a state which I think should not happen: you have the new version of the dependency \"initramfs-tools-bin\" in the installed state, but the old version of the dependency \"initramfs-tools\" in a half-installed state. I'm not sure whether the problem is that APT is letting the system get into a state where it can't recover, dpkg is letting the system get into a state where it can't recover, the package maintainer used a combination of dependencies which isn't supported, or my limited understanding doesn't cover this case. .  Try using \"dpkg\" directly: .  If this still complains about dependencies, try .  If this works, you have the dpkg database in a consistent state. You need to get APT in a good state (which requires no broken dependencies): .  After this you can resume normal upgrading. .   If your purge of \"/boot\" was deleting old kernels that were in packages, you won't be able to remove the kernel packages anymore. You'll have to recreate the files. You can create empty files (\"touch `cat /var/lib/dpkg/info/linux-image-1.2.3-foo`\") if you're removing the \"linux-image-1.2.3-foo\" package and you manually removed some of its files. .  ",
      "P-tags": "dpkg depend package-manag software-instal",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP of NP"
    },
    {
      "id": "so_16639742",
      "task": "Scan for wireless stations",
      "P-task": "scan wireless station",
      "F_verb": "scan",
      "P-body": "It looks that this is near impossible, so I decided to grab wireless packets with libpcap (\"pcap/pcap.h\"), and build a list based on its headers (src, dst, bssid). .  This helped me a bit with the developing: http://www.tcpdump.org/pcap.html .  ",
      "P-tags": "linux c c99",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V for NP"
    },
    {
      "id": "au_860172",
      "task": "How to make Decibel play in 16.04?",
      "P-task": "make decibel play 16 04",
      "F_verb": "make",
      "P-body": "Thanks to @Mark Kirby's comment under the question above and to the posts here (especially post 6), I have found the solution: the needed Decibel package is a 1.06 (not 1.08) version made for Xenial and available as a deb, which needs as a dependency \"gstreamer0.10-plugins-ugly 0.10\" also available as a deb, which instead needs \"libx264-146\". .  If version 1.08 version is installed, remove it (\"sudo apt remove decibel-audio-player\"), then, in the following order, download and install, preferably using gdebi-gtk: .   libx264-146 .  gstreamer0.10-plugins-ugly 0.10 .  decibel-audio-player 1.06 .   Also,\"gstreamer0.10-alsa\" is needed if not already installed: .  To be able to add CD play/access to the file manager menu, two optional packages are also needed: .  ",
      "P-tags": "sound 16 04 gstreamer",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "so_33119213",
      "task": "Run program in another process and receive pid in Python",
      "P-task": "run program anoth process receiv pid python",
      "F_verb": "receive",
      "P-body": "You are running into Unix process group management. In particular, when you kill the session leader of a process group when it is attached to a terminal (as is your script), all processes in that group receive a \"SIGHUP\", which by default causes termination. .  One solution is to establish a new session for the child using \"os.setsid()\". In Python 3 \"subprocess.Popen()\" accepts a \"start_new_session=True\" which does this for you. For Python 2, we can get a similar solution using \"preexec_fn\": .  ",
      "P-tags": "subprocess python process unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_45223787",
      "task": "kubernetes service exposing shellinabox timeout after approx. 60 seconds",
      "P-task": "kubernet servic expos shellinabox timeout approx\n60 second",
      "F_verb": "expose",
      "P-body": "Enable the session Affinity to direct the traffic to one pod per client session here is the samepl deployment. .  ",
      "P-tags": "kubernet linux",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP after NP"
    },
    {
      "id": "so_9958834",
      "task": "Ruby/Bash script to backup my table and delete records",
      "P-task": "rubi bash script backup tabl delet record",
      "F_verb": "delete",
      "P-body": "I would suggest the following: .   Redundancy - depending on how critical your data is, you may want redundant storage (e.g. a master-slave database setup, or the database on a RAID device) Backups - have hourly/daily/weekly backups (again, depending on how critical it is to maintain these backups, how much space you can afford for them, how much traffic you're getting, and what the impact is on the database) of the entire database. Truncation - have a cron task (check out the \"whenever\" gem which makes this easy) that deletes all entries older than some threshold (2 weeks?). There's no need to populate a new table just to delete old entries.  I believe these approaches are orthogonal, so you can pick whichever ones suit you, or implement the important one(s) first. .  ",
      "P-tags": "rubi mysql ruby-on-rail bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "su_1322857",
      "task": "Eclipse incompatible java versions - is it safe to install multiple JRE versions?",
      "P-task": "eclips incompat java version - safe instal multipl jre version",
      "F_verb": "install",
      "P-body": "The error message you get suggests that you need to specify what JVM Eclipse should use. You can do this within the eclipse.ini file (see this website for more details). You need to include the path to the java 10 JVM within the eclipse.ini file, like this: .  Change \"C:\\jdk10\\bin\\javaw.exe\" to reflect your path to the java 10 JVM. .  To answer your question: .  It's perfectly safe to have multiple java versions installed. You can change the default java version by running \"sudo update-alternatives --config java\". When you execute the \"java\" og \"javac\" command from the command line, it will use the version defined there. Eclipse can however be configured to use whatever version of java you want (as long as it's installed on your machine). .  It seems like you already have Java 10. You can verify this by either running \"java -version\", or get a list of all installed java environments by running \"sudo update-alternatives --list java\". In Eclipse you can go to \"Window -> Preferences -> Java -> Compiler\" to see what java compilers are available to Eclipse, and add the one you need if it's not listed. If your desired java compiler version is available, you should be able to right click on the project within the project explorer, select Properties and then select the that version of the java compiler. .  Hope this helps. .  ",
      "P-tags": "kubuntu eclips jre",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_44371401",
      "task": "Iterating over an array batch script",
      "P-task": "iter array batch script",
      "F_verb": "iterate",
      "P-body": "in batch spaces matter because it's an argument delimiter .  should be .  Something strange with cmd is that variables can terminate with a space .  ",
      "P-tags": "shell32 batch-fil cmd window",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V over NP"
    },
    {
      "id": "ul_41670",
      "task": "How can I make the Gnome3 calendar use Thunderbird instead of Evolution?",
      "P-task": "make gnome3 calendar use thunderbird instead evolut",
      "F_verb": "make",
      "P-body": "OK, I found how to do this at How to change gnome-shell calendar default application .  Just execute this in a terminal!! .  I have tested it and it works!! (it's not exaclty what I wanted but it's a start) .  ",
      "P-tags": "opensus gnome-shel thunderbird gnome3",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP of NP"
    },
    {
      "id": "au_1059781",
      "task": "UFW Allows 22 for IPv4 and IPv6 but SSH Disconnects When Enabling",
      "P-task": "ufw allow 22 ipv4 ipv6 ssh disconnect enabl",
      "F_verb": "disconnect",
      "P-body": "Background, and bounds for the issue: .   The issue only occurs when UFW, or iptables, with these ssh allow rules, is enabled and an ssh session is started. i.e. Any SSH session that was started with no iptables at all works fine, but may be subject to random drop outs once the rule set are put in place.  recall that ufw is merely a front end for iptables. The issue is present even with kernel 4.18-rc8.  What is going on? .  The \"sudo ufw allow in port 22\" results in the following iptables rules segment: .  Upon \"sudo ufw disable\" followed by \"sudo ufw enable\", and even though the ssh connection itself remains fine, the resulting iptables rule set seems to have forgotten the association with that particular connection and therefore classifies any incoming packets as invalid. Somehow the connection tracking table has become confused and the packet is not even considered NEW, but with incorrect flags, nor is it considered part of the existing connection. .  Consider a very basic iptables equivalent of what \"ufw\" is doing. Two scripts, one for clearing the rule set and one for creating it: .  And: .  Resulting in these packets counts after a clear/load cycle with an ssh session that was started after a load cycle: .  Notice the 35 invalid packets as I typed on the crippled ssh session terminal, and before PuTTY terminated. .  Why did this stop working, it used to work? .  Because this is 100% repeatable, a kernel bisection was relatively easy, just time consuming. The results were: .  Link to the entire commit. .  How to revert to the expected behavior? .  After disabling ufw or clearing the iptables rules set, create a new SSH session. It will survive a subsequent ufw enable, but might be subject to a random drop out at some point. .  This issue will be taken upstream at some point, via the related e-mail list. .  EDIT: upstream e-mail thread (contains a work around). Workaround copied here: .  EDIT 2: upstream proposed patch , which I have tested and reported back. .  EDIT 3: 2018.11.06: This has stalled upstream, and I haven't had time to pester them. I'll try to get back to it soon. .  EDIT 4: 2019.03.17: I can not reliably reproduce this issue with kernel 5.0. .  ",
      "P-tags": "firewal kernel ufw ssh 18 04",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V when S_ING"
    },
    {
      "id": "so_3593764",
      "task": "C++: can an int be assigned a char*?",
      "P-task": "c++ : int assign char",
      "F_verb": "assign",
      "P-body": "Neither C nor C++ have a type that can store \"characters\" as values with some dedicated character-specific properties. In that sense, there's no \"character\" type neither in C nor in C++. .  In both C++ and C languages \"char\" is an integral type. It contains numbers. It is just a smallest (in terms of range) integral type. Conversion between \"char\" and \"int\" exists, just like it exists between \"int\" and \"long\" or \"int\" and \"short\". \"char\" has no special status among other integral types (aside from the fact that \"char\" type it is distinct from \"signed char\" type). .  A literal of the form \"'h'\" in C++ has type \"char\", but as any other integral type it is comparable to \"int\". That's why you can use it in \"case\" label the way it is used in your original example. .  In other words, your original code is as \"strange\" as .  would be. In this case the \"switch\" argument is an \"int\", but the case label is a \"long\". The code is valid. Do you find it surprising? Probably not. Your example with \"'h'\" is in not much different. .  ",
      "P-tags": "cast c++ linux char",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "ul_62147",
      "task": "Why does a desktop launcher not start my app, while command line does?",
      "P-task": "desktop launcher start app command line",
      "F_verb": "start",
      "P-body": "Your software installed in \"/opt/...\" is not a statically linked binary but requires some libraries which are also installed below /opt but your system does not know to search that directory for the required libraries. One way to fix this is setting the \"LD_LIBRARY_PATH\" variable to include your directory in /opt. .  ",
      "P-tags": "desktop-environ",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP while S"
    },
    {
      "id": "so_14129186",
      "task": "powershell - difference between executing locally and remotely",
      "P-task": "powershel - differ execut local remot",
      "F_verb": "execute",
      "P-body": "Assuming the remote endpoint is set up to use your credentials, the remote session may have a different set of modules available (or different versions), there may be a profile script configured to run for the remote session and the environment is likely to be different. Also note that remote endpoints can be configured to limit access to commands (including applications) as well as restrict the language mode. A script could also walk various variables and functions to limit their visibility as well. If you look at session state you can see some of the properties that can be tweaked when configuring a remoting endpoint e.g.: .  See this article for more info on constrained endpoints. All that said, it is likely you're using the default endpoint which is usually not constrained. Another difference could be bitness. For instance, you could be running in an x86 shell but connecting to a 64-bit endpoint or vice-versa. If you need to connect to a 32-bit endpoint try the following: .  ",
      "P-tags": "powershel invoke-command",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_15897005",
      "task": "How to handle this patch issue with git?",
      "P-task": "handl patch issu git",
      "F_verb": "handle",
      "P-body": " It will bring up an editor. Change all the \"pick\" text to \"s\" except the first one. This will \"squish\" all your commits into one commit. .  You could have also have used cherry-pick (to pull out a few commits onto A), or git rebase --interactive (and deleted all the B commits to get C). .  ",
      "P-tags": "linux git c",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_356207",
      "task": "FDisk Not Extending to Full Amount after LVM resize",
      "P-task": "fdisk extend full amount lvm resiz",
      "F_verb": "extend",
      "P-body": "It would be simpler for you to use a tool such as GParted, which should be available in whatever distribution you\u2019re using (Ubuntu presumably, given the tags). .  Here\u2019s what\u2019s happening with \"fdisk\". You currently have a small primary partition, likely \"/boot\", from sector 2048 to sector 499711, followed by an extended partition from sector 501758 to sector 10483711, which contains a logical partition, your LVM PV, from sector 501760 to sector 10483711. This explains the numbering: on MBR disks, the primary and extended partitions are numbered 1 to 4, and logical partitions start from 5 (even if there aren\u2019t four primary or extended partitions). When you ask \"fdisk\" to create a new partition, it can only create a new primary or extended partition because your extended partition is full. Since there\u2019s a little room after \"sda1\", \"fdisk\" probably picks a start sector in there, probably 499712 since that\u2019s aligned on a mibibyte boundary; but then the partiton can only extend to sector 501757 at the most. .  To fix things with \"fdisk\", you should create a new primary partition and specify the start sector (10483712 works, it\u2019s correctly aligned). Then you\u2019ll be able to use the added space. .  (You could also enlarge your extended partition and create a new logical partition, or enlarge your existing logical partiton, but that\u2019s a little more complicated with \"fdisk\" \u2014 just use GParted.) .  ",
      "P-tags": "ubuntu fdisk lvm",
      "source": "qa",
      "cate": "inflate/extend",
      "pat": "V to NP after NP"
    },
    {
      "id": "au_812086",
      "task": "kubuntu 16.04 how to reinstall kde/plasma over the top of lxde",
      "P-task": "kubuntu 16 04 reinstal kde plasma top lxde",
      "F_verb": "reinstall",
      "P-body": "If I understood correctly, what you are asking is how to remove lxde components completely. Assuming you installed it by \"sudo apt install lxde\" (or you chose the lxde metapackage from your ubuntu software center) the packages installed are listed here: http://packages.ubuntu.com/xenial/lxde (including the recommendations). So to remove all the packages execute this command: .  You must choose the recommendations you want to remove yourself from the link above (like clipit, deluge, evince-gtk and others) because some of them would probably be pre-installed. .  ",
      "P-tags": "kubuntu 16 04",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP over NP of NP"
    },
    {
      "id": "ul_82398",
      "task": "Can't access command history in my shell (sh)",
      "P-task": "access command histori shell sh",
      "F_verb": "access",
      "P-body": "You are running \"sh\", which in Debian links to \"dash\". If that is not the shell you want, try typing in \"exec bash\". .  \"dash\" (well, neither \"dash\" nor the original Bourne \"sh\") doesn't use readline, which explains why you see those escape sequences when you attempt to use the arrow keys. .  ",
      "P-tags": "debian shell dash",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP in NP"
    },
    {
      "id": "so_1646312",
      "task": "What caused the mysterious duplicate entry in my stack?",
      "P-task": "caus mysteri duplic entri stack",
      "F_verb": "duplicate",
      "P-body": "The reason you get \"bad\" stack is that \"__lll_mutex_lock_wait\" has incorrect unwind descriptor (it is written in hand-coded assembly). I believe this was fixed somewhat recently (in 2008), but can't find the exact patch. .  Once the \"GDB\" stack unwinder goes \"off balance\", it creates bogus frames (#2 through #8), but eventually stumbles on a frame which uses frame pointer, and produces correct stack trace for the rest of the stack. .  ",
      "P-tags": "debug linux gdb c++ g++",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP in NP"
    },
    {
      "id": "so_54564342",
      "task": "Docker build fails with \"RUN: command not found\"",
      "P-task": "docker build fail run : command found",
      "F_verb": "build",
      "P-body": "Just use one RUN command, and escape newlines. If you have several commands, you have to wrap them in a bash command. .  Besides that, you can extract from a \".tar.gz\" file directly without uncompressing it first. .  ",
      "P-tags": "dockerfil linux docker",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP"
    },
    {
      "id": "so_33715597",
      "task": "Can I read from stdin in a non-canonical way?",
      "P-task": "read stdin non-canon way",
      "F_verb": "read",
      "P-body": "No, not without external crates or unsafe FFI code. You will probably want to use the termios functions. Specifically, see \"ICANON\" and \"tcsetattr\". The crate nix has bindings for these functions. See here for an example of how to use them in Rust. .  ",
      "P-tags": "rust linux",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V from NP in NP"
    },
    {
      "id": "so_46806701",
      "task": "Powershell: appending a percent sign to the end of a variable",
      "P-task": "powershel : append percent sign end variabl",
      "F_verb": "append",
      "P-body": "Explanation: .  Adding \"\" \"\" around your output to treat it as a string and then append the variable onto the end. This means you are able to switch it over from \"%\" to a string such as \"Percent Remaining\". .  Hope this helps, you were close! .  Code: .  Example Result of \"$diskpercentFree\": .   PS C:\\Windows\\system32> $DiskpercentFree .  57% .   ",
      "P-tags": "string-concaten powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "so_62019431",
      "task": "Delete document matching condition in multi colection MongoDB",
      "P-task": "delet document match condit multi colect mongodb",
      "F_verb": "delete",
      "P-body": "As of now, Mongo doesn't support cascade delete operation. Mongo just does what it has been told to do. Cascade delete is not a concept in MongoDB, it's more of a concept in SQL. .  So, for now what you can do is, you can manually delete the matching record in every collection. You can use the below to delete a document: .  There is another way, but, it's a long route. What you can do is change your schema. Instead of making different collection, you can put everything in just one collection. But, I would recommend you to do this only if your collections are connected and it's frequently updating.  .  ",
      "P-tags": "mongodb mongo-shel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "au_201451",
      "task": "Grub error after removing another Linux partition with Ubuntu",
      "P-task": "grub error remov anoth linux partit ubuntu",
      "F_verb": "remove",
      "P-body": " First Login in to Ubuntu and use this command in a terminal .   Then remove the Linux mint's partition using gparted or disk-utility. .  Then use this command to update grub men .    Now you should have a system with no Mint and no grub error! .  ",
      "P-tags": "boot dual-boot grub2",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_483122",
      "task": "Prevent overwriting a file with redirection",
      "P-task": "prevent overwrit file redirect",
      "F_verb": "prevent",
      "P-body": " is there a way to configure the shell to do not overwrite the file if it already exists? Maybe a no-clobber option? .   Yes, there is the \"noclobber\" option: .   Prevent output redirection using \">\", \">&\", and \"<>\" from overwriting existing files. .   ",
      "P-tags": "shell-script shell bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V S_ING with NP"
    },
    {
      "id": "so_13669321",
      "task": "Run bundle install as a background process",
      "P-task": "run bundl instal background process",
      "F_verb": "run",
      "P-body": "If you really aren't concerned with its output (and whether it succeeds or fails), you can also redirect the stderr of the process: .  ",
      "P-tags": "rubi bundler unix shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP"
    },
    {
      "id": "ul_616145",
      "task": "Prepare a USB-stick for bootable linux. Need to?",
      "P-task": "prepar usb-stick bootabl linux\nneed",
      "F_verb": "prepare",
      "P-body": "The ISO file is a block-by-block image of what would be on a bootable optical disk (CD-ROM, DVD, etc.). These disks are in ISO9660 format (that's why the image file is a \".ISO\" file) rather than FAT32, ext4, or any of the other filesystem types you may be familiar with, and they don't have partitions in the way you are thinking of (ISO9660 doesn't even have a partition table). If you just \"dd\" the ISO image on to your USB flash drive, whatever partitioning you formatted the USB flash drive with originally will be gone, because this operation overwrites the partition table. When you boot your system from a USB flash drive, it doesn't care about partition tables or anything like that - it just loads the boot block from the flash drive (just as it would do with any other drive you are booting from) and runs whatever code it finds there. It is up to the boot code to decide what to do next, and how to interpret whatever is on the flash drive. When you boot from a USB flash drive that you've written an ISO image to using \"dd\" or similar, the system literally treats it as if it's booting from an optical drive - just the same as if you had burned the ISO image on to a writable CD-ROM or DVD disk, and booted from that instead. .  If you are using USB 2.0 flash drives, then that is going to be sort of slow, no matter what else you do. The type of filesystem on the flash drive doesn't change this. If you use a USB 3.x flash drive, on a system with USB 3.x interfaces, access will be much faster. If you use a USB 3.x flash drive on a system that only has USB 2.0 interfaces, you're only going to get USB 2.0 speed regardless of what kind of flash drive you use. .  ",
      "P-tags": "usb linux iso",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP for NP"
    },
    {
      "id": "so_14557038",
      "task": "C#: Tamir.SharpSsh unable to change directory in unix",
      "P-task": "c : tamir sharpssh unabl chang directori unix",
      "F_verb": "change",
      "P-body": " Each call to \"RunCommand()\" will create a separate channel which runs independently of the others. In the common case (making an ssh connection to a unix server), each channel will invoke a separate shell instance. A command like \"cd\" run in one channel won't affect subsequent commands launched in different channels. .  To do what you want, you have to arrange to run the sequence of commands in the same \"RunCommand\" invocation. Assuming the remote server is a unix server invoking a shell like \"bash\", you can use shell syntax, for example: .  ",
      "P-tags": "unix c sharpssh cd ssh",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_181114",
      "task": "How can I teach fail2ban to detect and block attacks from a whole network block?",
      "P-task": "teach fail2ban detect block attack whole network block",
      "F_verb": "detect",
      "P-body": "Fail2ban doesn't have neat functionality to automatically block attacks from a whole subnet. It is possible to do, though, using a recent version of fail2ban (I use v0.11), some simple fail2ban scripts and a small, pure python3 script. .  Note: The question refers to 'a whole subnet' (which I'll refer to as CIDR blocks or IP ranges). This is a difficult thing, because we don't know how large a block of addresses the attacker controls. It might even be that the attacker by chance controls a handful of addresses from the same block, with the in-between addresses being legitimate. .  Step 1. Get CIDR of hosts The log files that fail2ban monitors typically show hosts (e.g. 127.0.0.1) instead of CIDR blocks (127.0.0.0/24) or IP ranges (127.0.0.0 - 127.0.0.255). .  A solution could be to first assume a small CIDR block and then grow it as logs report more misbehaving hosts. Obviously it should only grow the CIDR, if those hosts are from adjacent addresses. But this is complex and legitimate addresses might get caught up regardless of the sophistication of the algorithm. .  Instead, we can also simply lookup the CIDR in whois. This incurs some latency for the whois lookup, and generates some traffic. But the script that parses whois, can just write the CIDR to syslog, which can then be caught by fail2ban again. .  Note: don't forget to hook this script into the actionban of your preferred action.d/lorem-ipsum.conf script. Be aware that if its maxretry > 1, then you will not catch CIDR blocks where hosts only fail once! .  Step 2. Figure out when to block a CIDR If we had the dynamic CIDR determination this might get a little elaborate, as we'd have to change what we're banning. But with the whois lookup we can simply ban the CIDR block we found, based on a maxretry and findtime that we deem appropriate. Here's the jail I use: .  And accompanying filter .  Step 3. Actually block the CIDR As you may have noticed, I use action.d/nft-common.conf. nftables allows blocking CIDR blocks instead of single hosts. This requires a small change to the first line of the actionstart part of the action script: .  Should be modified to: .  ",
      "P-tags": "fail2ban",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP from NP"
    },
    {
      "id": "so_2407981",
      "task": "Skip all databases and run only specific one",
      "P-task": "skip databas run specif one",
      "F_verb": "skip",
      "P-body": "You can try doing: .  This will only execute the \"SQL\" commands for the specified database and will skip the commands for all other databases. The \"-o\" (\"one database\") option is critical to this working as expected (it tells \"mysql\" to ignore statements related to other databases). .  \"dump.sql\" is the result of executing \"mysqldump --all-databases\" .  ",
      "P-tags": "linux mysql mysqldump databas",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP"
    },
    {
      "id": "so_1118058",
      "task": "Unix scripting, trying to hosts, getting \"013 not found: 3(NXDOMAIN)\"",
      "P-task": "unix script tri host get 013 found : 3 nxdomain",
      "F_verb": "get",
      "P-body": "\\013 indicates that you have a carriage return at the end of your host name. Strip it (e.g. using something like \"tr -d '\\r'\") before passing the host name to '\"host\"'. .  Try changing: .  to: .  ",
      "P-tags": "shell unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_411006",
      "task": "Unity on 13.10: Ctrl + Alt resizes the window. How to disable this?",
      "P-task": "uniti 13 10 : ctrl + alt resiz window\ndisabl",
      "F_verb": "resize",
      "P-body": "I found a way to do this:  .   install compiz-config: \"sudo apt-get install compizconfig-settings-manager\" Run CompizConfig Settings Manager from the dash Disable the Grid plugin (Window Management section).  That's all. It seems, this plugin was causing this behavior somehow .  ",
      "P-tags": "shortcut-key uniti",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_438629",
      "task": "find user name through full name / gecos field?",
      "P-task": "find user name full name geco field",
      "F_verb": "find",
      "P-body": "I have not found a way to search the database, but looking up entries in OpenLDAP directly works for me. .  ",
      "P-tags": "ldap getent nsswitch search",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP through NP"
    },
    {
      "id": "so_63237496",
      "task": "run linux executable in c# with params",
      "P-task": "run linux execut c param",
      "F_verb": "run",
      "P-body": "This is a typical way to start a terminal application with arguments, wait for it to finish, then output what it sent to stdout. .  ",
      "P-tags": "execut linux c paramet",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_43145328",
      "task": "Read 'n' lines from file and assign each line to distinct variable",
      "P-task": "read n line file assign line distinct variabl",
      "F_verb": "read",
      "P-body": "A bit of dynamic variable assignment using \"declare\" and indirect expansion as .  ",
      "P-tags": "while-loop bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_458672",
      "task": "Can I schedule running a script inside a particular shell process once in a while?",
      "P-task": "schedul run script insid particular shell process",
      "F_verb": "run",
      "P-body": "Not entirely sure what you're after, but you can kick off a background job that does something and then waits X seconds, before repeating. .  Example .  ",
      "P-tags": "cron bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP inside NP"
    },
    {
      "id": "ul_239125",
      "task": "How do I check whether a variable has been passed to a function in Bash?",
      "P-task": "check whether variabl pass function bash",
      "F_verb": "check",
      "P-body": "\"bash\" conditional expression \"-v var\" check if shell variable named \"var\" is set. .  When using \"[[ -v $1 ]]\", you actually checked whether a variable named by content of \"$1\" was set. In your example, it means \"$cd\", which was never set. .  You can simply check if \"$1\" is non-empty string, using \"-n\": .   Note that \"var\" must be a shell variable for \"-v var\" work. \"[[ -v 1 ]]\" will never work because \"1\" is denoted for positional parameter. .  ",
      "P-tags": "shell-script bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V whether S"
    },
    {
      "id": "so_5012280",
      "task": "Redirecting file descriptor 3 with tee",
      "P-task": "redirect file descriptor 3 tee",
      "F_verb": "redirect",
      "P-body": "Your guess is right. It's a rather nifty trick to swap standard output and standard error. To answer your questions: .   these redirections are captured by the shell so they apply to that portion of the pipeline (which is \"sudo\"). The \"sudo\" process itself will detect all the arguments and pass them along to its subcommand (\"rsync\") but the redirections have been captured and acted upon before that point: \"sudo\" never sees them. File handle 3 is not left hanging. It will be closed when the process ends.  ",
      "P-tags": "unix tee redirect shell bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_17633",
      "task": "ACPI wakeup from keyboard/mouse via /proc/acpi/wakeup after suspend. How to find the correct device?",
      "P-task": "acpi wakeup keyboard mous via proc acpi wakeup suspend\nfind correct devic",
      "F_verb": "suspend",
      "P-body": "Ok, I've found a way, though it does not look very clean ;) .  I'll start from the end - running this one-liner will tell you the truth: .  Nice, isn't it? And here is, how it works: .   The beginning should be obvious: \"grep \"USB.*\" /proc/acpi/wakeup\" extracts from the list only USB devices that have a known sysfs node. \"cut -d ':' -f 2-\" leaves just the ending (numbers) after 'pci:' on each line. Then, for each ending (\"aaa=0000:00:1d.2\" and so on), try to find an udev device symlink that contains the string. For each device symlink found, the find command :  prints the name of udev symlink, <-- this is the most useful part executes grep to display the line from \"/proc/acpi/wakeup\" that corresponds to the found device, appends a blank line for output clarity.   So, thanks to the meaningful naming of device symlinks by udev, you can tell which USB device is the keyboard, mouse etc.  .  ",
      "P-tags": "suspend acpi linux",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V"
    },
    {
      "id": "so_45224694",
      "task": "Align/pad some content in these strings with regex in javascript",
      "P-task": "align pad content string regex javascript",
      "F_verb": "align",
      "P-body": "I guess you could use string.slice().  .  The regex \"/^(\\s*\\S+(\\s+)(?:\\S+\\s+){2}\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)/\"  .  Explained  .  JS code  .     \r  .  Output  .  ",
      "P-tags": "awk linux javascript regex",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP with NP in NP"
    },
    {
      "id": "so_50887691",
      "task": "git negation of excluding hidden directory with hidden files",
      "P-task": "git negat exclud hidden directori hidden file",
      "F_verb": "exclude",
      "P-body": "Adding \"!.bashrc_includes/*\" will exclude the files from the ignored files, but the directory itself is still ignored! .  The following \".gitignore\" allows you to exclude the directory and the files inside from the ignored files: .  You can find some more in-depth explanations in this question: .gitignore exclude folder but include specific subfolder. .  ",
      "P-tags": "git linux gitignor",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "au_284557",
      "task": "How to suppress IPv4 checksum errors on virtual terminal?",
      "P-task": "suppress ipv4 checksum error virtual termin",
      "F_verb": "suppress",
      "P-body": "This will happens due to upgrade of drivers to recent versions and you can fix it by disabling the checksum checking in your PC for that particular connection.  .  All you need to do is simply open your terminal and type as follow .  then disable checksum .  that's it. It will stop giving error messages but this setting will be lost after restarting of your PC.  .  you would better make it as start up script. .  hope that helps. .  ",
      "P-tags": "command-lin virtual-termin",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP on NP"
    },
    {
      "id": "so_1715347",
      "task": "if-statement always evaluates to TRUE",
      "P-task": "if-stat alway evalu true",
      "F_verb": "evaluate",
      "P-body": "Try this instead: .  The brackets around the first letter of processName means do don't need the \"grep -v grep\", while the -q means we don't need the pipe to /dev/null .  $? gives you the return code of the previous command executed. Hence, testing if it were 0 would indicate if \"grep\" found what it was looking for. .  Update .  If your process name is really short (say \"cup\"), you might get a false positive as it may match other processes too (say \"cupsd\"). You can overcome this by having grep match whole words - add the \"-w\" flag. .  Not that this technique is not perfect. You may end up matching entries in the username/date fields. If that happens, look up \"man ps\" and be more selective of what you print out before doing a grep. Alternatively, prefilter the output with awk to extract only the column showing process/cmd name . E.g: .  Update 2 .  you can also use pgrep as suggested in answer below.  .  For really short process names, you might want to specify word boundaries (\\b) before and after your process name to prevent overmatching (as described above) .  Update 3 .  From the updated question, I see that you're running it from an init script. There's always a danger of pgrep matching the script itself. Try: .  That excludes the PID of the script from pgrep matches. .  Update 4 .  (final update? fingers crossed) .  If the init script is run via the \"service\" command, then we need to filter out the parent PID as well. How about: .  ",
      "P-tags": "linux process unix bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V to NP"
    },
    {
      "id": "su_457736",
      "task": "How can I get a list of commands used for navigating in the terminal?",
      "P-task": "get list command use navig termin",
      "F_verb": "get",
      "P-body": "If you are looking for a complete list of every command on your Linux system, press the TAB key and enter y to the question. All your commands will be gracefully displayed. .  If you are looking for help on a particular command, use this syntax: \"man command-name\". Example: \"man ls\" will give you the manual for the ls command. .  ",
      "P-tags": "shell termin maco",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP for NP in NP"
    },
    {
      "id": "ul_148387",
      "task": "Can't start mysql service",
      "P-task": "start mysql servic",
      "F_verb": "start",
      "P-body": "The \"/var/lib/mysql/aria_log_control\" file is open by another process and consequently, \"mysqld\" fails to start. .  Check who/what is currently has the file open with: .  It should list the process(es) that has it open. .  If the process definitely shouldn't be running, then shut it down with: .  If that fails: .  Or reboot. .  ",
      "P-tags": "opensus mysql systemd servic",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "ul_232058",
      "task": "How to list filenames that contain spaces and special characters without using find",
      "P-task": "list filenam contain space special charact without use find",
      "F_verb": "find",
      "P-body": "\"grep -E\" should do what you need. Note that some characters need to be escaped with a backslash, so if you add more and the results aren't what you expected, escape it and try again. Note the \"|\" is an \"or\"... .  ",
      "P-tags": "wildcard command-lin bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "ul_255076",
      "task": "Finding out binary's compiling computer name",
      "P-task": "find binari compil comput name",
      "F_verb": "find",
      "P-body": "You should run \"strings\" on your program: .  This will print all strings of (by default) 4 or more printable characters in a row to your terminal. A lot of this will be junk, but if the hostname is actually somewhere in the binary, that should tell you. .  I agree with you that it is highly unlikely that it will contain things like MAC address or hostname of the compiling host; however, if the binary is unstripped (i.e., contains debugging symbols), it likely will still contain path names to the source that it was compiled from. This may give you some clue as to in which environment it was built in the first place. .  ",
      "P-tags": "solari binari gcc vxwork",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V out NP"
    },
    {
      "id": "so_50476361",
      "task": "Removing Strings if Substring of the String is Present in Same Array",
      "P-task": "remov string substr string present array",
      "F_verb": "remove",
      "P-body": "First, a solution based strictly on shared domain names (e.g., \"helpx.adobe.com\" and \"adobe.com\" are considered to belong to the same domain, but \"list-manage.com\" and \"manage.com\" are not). This is not what you asked for, but perhaps more useful to future readers: .  Assuming \"list.manage.com\" rather than \"list-manage.com\" in your sample input, the above command yields: .   \"{ ($_ -split '\\.')[-2,-1] -join '.' }\" sorts the input lines by the last 2 domain components (e.g., \"adobe.com\"): .  \"-Unique\" discards duplicates. .    A shared-suffix solution, as requested: .  ",
      "P-tags": "array powershel contain foreach",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP if S"
    },
    {
      "id": "au_798898",
      "task": "Which OS on GRUB to use?",
      "P-task": "os grub use",
      "F_verb": "use",
      "P-body": "The \"Ubuntu\" entry will boot your Ubuntu system. .  \"Advanced options for Ubuntu\" opens a submenu that allows you to chose which installed kernel version you want to boot and whether to use systemd (available and default since 15.04) or upstart. It also allows you to boot Ubuntu in recovery mode. .  The \"EFI/ubuntu/MokManager.efi\" entry will boot a MOK Manager tool. MOKs are \"Machine Owner Keys\" which are used to sign boot loaders. This is needed if you want to enable your UEFI system's \"Secure Boot\" feature and add new trusted boot loaders. You will probably not need it as average use, it's easier to turn \"Secure Boot\" off. .  \"System Setup\" will get you into your UEFI setup. You should be able to achieve the same by pressing a special key like Del or F2 (depending on your UEFI) before GRUB starts. .  All other entries will pretty sure boot into Windows equally. .   If you want to tidy up your GRUB menu by renaming, deleting or reordering some entries or putting them into submenues, you can do this most easily using a tool called \"grub-customizer\". You can learn how to install and use it here: How do I customize the GRUB 2 menu? .  ",
      "P-tags": "grub-efi dual-boot",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_58388169",
      "task": "date command not found in shell script",
      "P-task": "date command found shell script",
      "F_verb": "find",
      "P-body": "Shells can't find commands if the commands aren't in directories in \"$PATH\". Quick fix: replace \"date\" with \"/bin/date\". However, a similar problem might occur in conf.sh or backup.sh, so a more global solution is to echo \"$PATH\" at the beginning of your script, figure out what's missing, and and fix it, e.g., \"PATH=/bin:$PATH\". .  ",
      "P-tags": "sh",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP"
    },
    {
      "id": "so_61216427",
      "task": "parsing json file with jq",
      "P-task": "pars json file jq",
      "F_verb": "parse",
      "P-body": "The following program, when invoked with the -n command-line option, produces the expected output in both cases: .  Specifically, in the first case, it produces a JSON array, and in the second case, the actual value of \".ReadVersion\". .  ",
      "P-tags": "json jq pars shell",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP with NP"
    },
    {
      "id": "so_29382659",
      "task": "Is there a way for Windows to return the path to a directory as Linux does?",
      "P-task": "way window return path directori linux",
      "F_verb": "return",
      "P-body": "If you are running interactively you can copy the windows path to the clipboard then use: .  This will return a unix style path. .  Example \"C:\\Users\\john\\Dropbox\". Highlight right click and copy in windows. Then run: .  ",
      "P-tags": "path linux window r",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP as NP"
    },
    {
      "id": "so_22222302",
      "task": "how to modify ~/.inputrc for brackets autocompletion in bash vi mode?",
      "P-task": "modifi inputrc bracket autocomplet bash vi mode",
      "F_verb": "modify",
      "P-body": "Adding the following into ~/.inputrc solves the problem: .  or in ~/.bashrc: .  ",
      "P-tags": "readlin autocomplet bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "ul_396427",
      "task": "Does 'find' traverse a directory if '-not -path \"*/FolderName/*\" ' is used?",
      "P-task": "find travers directori -not -path foldernam use",
      "F_verb": "find",
      "P-body": "The \"-depth\" (and \"-delete\" implies \"-depth\"), \"-prune\", \"-maxdepth <n>\", \"-depth [+-]<n>\", \"-follow\" (now replaced with the \"-L\" option), \"-quit\", \"-exit\", \"-xdev\"/\"-mount\" predicates (not all implementations support all of them) are the only ones that affect the directory traversal. .  Here, instead of .  You can do: .  Or if you also want to exclude \"whatever\" itself (which \"! -path '*/whatever/*'\" doesn't): .  Those would have to be inserted before predicates like \"-type f\". .  That also avoids the problems whereby \"*\" doesn't match sequence of bytes that don't translate to characters in some locales and some implementations (like GNU \"find\" in most common locales). .  So for your example: .  Or: .  (note that it excludes all files called \"FolderName\" even those that are not of type directory). .  ",
      "P-tags": "find command-lin",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP if S"
    },
    {
      "id": "au_1029743",
      "task": "Unable to log in to Cinnamon session 18.04",
      "P-task": "unabl log cinnamon session 18 04",
      "F_verb": "log",
      "P-body": "I was facing the same problem. .  Try out the solution here : Cinnamon session crashing login from greeter .  It worked perfectly for me. Seems \"gnome-user-share\" was the problem. .  ",
      "P-tags": "18 04 cinnamon",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in to NP"
    },
    {
      "id": "ul_588392",
      "task": "How to get exclusivity on stdout",
      "P-task": "get exclus stdout",
      "F_verb": "get",
      "P-body": "The \"stty tostop\" setting makes the kernel send \"SIGTTOU\" to background processes which try to write to the terminal. A process can ignore that signal, though. .  An alternative might be to connect the application to an unused virtual console. Create a new user for that, make the terminal accessible only for that user and run the program as that user. .  edit .  It is much easier: You do not need (in practice) a different user. You just need a currently unused terminal. In general no other process of the same user will use that terminal but you can prevent all but root processes from writing there by executing \"chmod 000 /dev/tty\". That is no problem for the running shell and its future child processes as the file descriptor has already been opened and is inherited by the children. .  In theory processes of the same user could restore the permissions but they are not going to do that. .  ",
      "P-tags": "termin stdout",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "su_673983",
      "task": "Use date to update date",
      "P-task": "use date updat date",
      "F_verb": "update",
      "P-body": " -s, --set=STRING set time described by STRING .   A quote from \"date --help\" .  You have to do \"date --set='60 seconds ago'\" .  In bash scripting \"'64 seconds ago'\" is a string and \"--set\" takes STRING .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_29869888",
      "task": "Change Color of Text Being Currently Used (Terminal - OSX)",
      "P-task": "chang color text current use termin - osx",
      "F_verb": "use",
      "P-body": "To do what you are asking, these steps would be needed: .   at the end of the prompt, turn on the text color which you want to show when you press return (to complete editing) turn the text-color off.  bash does not reset attributes while you edit, so the color \"should\" work \u2014 while editing. As you edit, bash is likely to use escape sequences which clear the current line (which may fill it with whatever background color you have selected). .  The real problem is how to reset the colors when you press Enter. That does not appear to have a straightforward solution: I do not see a way to rebind the Enter key to add features\u2014no distinction is made between levels of interpretation, and you may not find it possible to enhance the Enter key. The key binding feature in bash talks mainly to the readline library; leftovers are sent to bash. In a binding you may be able to do these things: .   send the name of a macro to bash, or a full \"echo\" command which resets colors (since readline has no \"echo\" of its own, it seems) the Enter key (i.e., \"^M\"), and to readline directly, the \"accept-line\" function  Alternatively, what you could do is bind another key, say control/L to do the bash \"accept-line\" function as well as resetting color. Here are a couple of links which you would find useful to investigate how to do this: .   how to bind the 'Enter key' Complex keybinding in bash In bash, how do I bind a function key to a command? Smart preparsing with the bash shell  ",
      "P-tags": "termin bash-profil maco",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_24557053",
      "task": "sh + how to run command and set it into parameter ( VAL )",
      "P-task": "sh + run command set paramet val",
      "F_verb": "set",
      "P-body": "Testing with Bash 3.2 (on Mac OS X 10.9.4) run as \"sh\": .  Note that there is a difference between using back-ticks and \"$(\u2026)\". I recommend the use of \"$(\u2026)\" because it is simpler to understand. If you want to stick with back-ticks, double up the back-slashes. I'm not quite sure why it is behaving as it is, but that's what the empirical evidence says you need to do.) .  If you want to use arrays, use arrays: .  ",
      "P-tags": "array linux sh shell",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP into NP"
    },
    {
      "id": "ul_207645",
      "task": "Find Command: display the file numbers",
      "P-task": "find command : display file number",
      "F_verb": "find",
      "P-body": "Have I already mentioned I like zsh's glob qualifiers? .  ",
      "P-tags": "termin linux-mint command-lin",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "su_474474",
      "task": "How to remove text from vim",
      "P-task": "remov text vim",
      "F_verb": "remove",
      "P-body": "If you want to remove the whole word, and if your sample is complete, then you want to use this regexp: .  It removes every bit consisting of 3 digits followed by \"abc\". .  ",
      "P-tags": "linux vim regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "au_926396",
      "task": "Disabling secure boot has no effect - 16.04",
      "P-task": "disabl secur boot effect - 16 04",
      "F_verb": "disable",
      "P-body": "There are at least three possible solutions: .   Don't use the proprietary Nvidia drivers -- The proprietary drivers might or might not provide any real benefit to you. Thus, you might want to at least try not using them. Personally, I avoid proprietary video drivers whenever possible. In my experience, they cause more problems than they solve. OTOH, I'm not into gaming, so their benefits are pretty modest for me.) Disable Secure Boot the \"hard\" way -- You could disable Secure Boot by using your computer's firmware setup utility rather than the tool provided with Ubuntu. The trouble with this approach is that there's no standardization of the menus and methods used to do this. The good news is that, despite the lack of standardization, there are some strong similarities between implementations in practice. See this page of mine for several examples. Sign the modules yourself -- You can sign the kernel modules with a tool called \"sign_file\", which is provided with the kernel source code. I don't have an exact step-by-step procedure handy to sign the Nvidia modules, but it ought to be similar to the procedure needed to sign VirtualBox modules, which is covered in this question and its answer. Note that the question references a couple more question, so you may be picking through several questions and answers to piece together something that might work. You'll also have to know enough about the driver files to apply the VirtualBox process to the Nvidia drivers. You'll need to create your own Secure Boot key pair and enlist the public key as a MOK (or as a regular Secure Boot key, if you go all-out and take full control of Secure Boot on your system).  These options are listed in roughly increasing order of difficulty, although the first two could easily be flipped, depending on your system's current state and how hard it is to remove the Nvidia drivers if they're already installed. .  BTW, I doubt if disk encryption is complicating anything. .  ",
      "P-tags": "driver nvidia-geforc nvidia secure-boot",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "so_68578309",
      "task": "Azure Functions Powershell: module could not be loaded via managed dependencies",
      "P-task": "azur function powershel : modul could load via manag depend",
      "F_verb": "manage",
      "P-body": " Does the module require authentication? It seems it's trying to launch a winforms window which isn't available in PowerShell 7. .  Is there another authentication mechanism you can use with that module like service principal or certificate that prevents the window? .  ",
      "P-tags": "azur powershel azure-funct",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "au_400374",
      "task": "Tried to disable GUI now neither GUI or TEXT loads",
      "P-task": "tri disabl gui neither gui text load",
      "F_verb": "disable",
      "P-body": "You need to have root permissions to edit the grub file so it should alow you to write if you open with either: .  depending on whether you want a to do the editing in command line. You want to change .  to .  then save and go back to the terminal and run: .  Then you can reboot to test: .  ",
      "P-tags": "gui server command-lin",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "so_15287862",
      "task": "Find and replace using regex in sed",
      "P-task": "find replac use regex sed",
      "F_verb": "replace",
      "P-body": "You could use \"+\" to enforce at least one character which is not a \"#\" .  Since the \"sed\" in OSX does not support the enhanced regular expression syntax like \"+\" by default, you need to pass the \"-E\" flag to sed. And the good news is \"-E\" flag works well on \"*nix\" systems too. When using the \"-E\" flag, you can skip escaping the special regex characters like \"+\", \"(\", etc. .  ",
      "P-tags": "unix sed regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V using NP in NP"
    },
    {
      "id": "au_1284685",
      "task": "How do I show default user on WSL?",
      "P-task": "show default user wsl",
      "F_verb": "show",
      "P-body": "If you use \"bash\" or \"bash.exe\" as mentioned by Terrance, you'll be invoking the default WSL distribution in your system which may or may not be Ubuntu or desired version of Ubuntu in case you have multiple distributions or multiple versions of Ubuntu. In those scenarios you can specify the distribution instead of \"bash\" or \"bash.exe\", i.e. .  This would execute the command in default shell in non-interactive mode, i.e., environment variables won't be available at this stage (for example, \"SHELL\" and \"PATH\"). You'll get no result if you run .  As an alternative of \"c\" option, you can use \"run\" as well. From the help page of \"ubuntu\" (which can be obtained using \"ubuntu help\"): .  The resultant command would be: .   Footnotes:  Enclosing command in quotes is optional. Anyway you should escape the special characters (if used anywhere). \".exe\" is part is also optional after \"bash\", \"ubuntu\" and even \"wsl\". \"ubuntu\" command can vary according to the version. For example, if you have installed Ubuntu, command would be \"ubuntu\" but for Ubuntu 18.04 and 20.04, it would be \"ubuntu1804\" and \"ubuntu2004\" respectively.  ",
      "P-tags": "command-lin windows-subsystem-for-linux",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_475093",
      "task": "Can't connect to WiFi with WPA-EAP",
      "P-task": "connect wifi wpa-eap",
      "F_verb": "connect",
      "P-body": "The problem was solved by removing this line: .  from \"/etc/NetworkManager/system-connections/conname\". .  ",
      "P-tags": "wpa wifi network wpa2-eap",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP with NP"
    },
    {
      "id": "so_32488342",
      "task": "How can I remove a single user ACL from a large set of folders?",
      "P-task": "remov singl user acl larg set folder",
      "F_verb": "remove",
      "P-body": "The \"-Path\" parameter of \"Set-Acl\" expects a path string, not a \"DirectoryInfo\" object. When passing the latter only its \"Name\" property is expanded, so \"Set-Acl\" is looking for an object with the given name in the current working directory (in your case apparently \"C:\\Windows\\system32\"). .  Change .  into .  and the problem will disappear. .  With that said, you may want to make some other modifications as well. .    If you don't want the parent folder in the array: don't put it in the array in the first place. And since you apparently have PowerShell v3, you could use the \"-Directory\" parameter instead of a \"where\" filter. .    Each access rule has only a single identity reference, so the inner loop is pointless. .  Your code could be streamlined to something like this: .  or (using pipelines) like this: .  ",
      "P-tags": "powershel powershell-3 0 powershell-2 0 acl",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP of NP"
    },
    {
      "id": "so_16265513",
      "task": "uWSGI server does not respond",
      "P-task": "uwsgi server respond",
      "F_verb": "respond",
      "P-body": "For those who may encounter this problem too here're final results of my investigation: the issue is definitely environment-related, and most probably Linux kernel specific. The strace util showed that uWSGI couldn't receive a single byte - it is a kernel level. .  I think that key line is .  The Linux is running in a virtual environment and 2.6.27 is not a default kernel version for Debian 6.0.7. In 2.6.32-5 everything worked perfectly. .  I don't know if it is a bug of an old kernel, or uWSGI compatibility, or both. But updating the kernel helps. .  ",
      "P-tags": "linux uwsgi debian python django",
      "source": "qa",
      "cate": "respond",
      "pat": "V"
    },
    {
      "id": "so_16047356",
      "task": "Linux Shell Script: Writing file and string together to another file",
      "P-task": "linux shell script : write file string togeth anoth file",
      "F_verb": "write",
      "P-body": " ",
      "P-tags": "linux file string bash echo",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V"
    },
    {
      "id": "so_29542241",
      "task": "How to create a folder when user specify the number to be created in unix?",
      "P-task": "creat folder user specifi number creat unix",
      "F_verb": "create",
      "P-body": "I supose you will do this with a bash script. In that case you can use a loop and the \"mkdir\" command. For example: .  this will create 4 folders with the names \"folder1\", \"folder2\", \"folder3\" and \"folder4\". .  ",
      "P-tags": "unix linux shell bash functional-program",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V in NP"
    },
    {
      "id": "au_645545",
      "task": "7zip: How to exclude file types?",
      "P-task": "7zip : exclud file type",
      "F_verb": "exclude",
      "P-body": "\"7z\" only accepts a single archive within its arguments, but you're passing a wildcard which expands to the full content of the current working directory; anothe issue is that also the wildcards within the arguments will expand as well, either if non-quoted or double-quoted. .  So you should only extract a single archive per command; you should remove the wildcard at the end, specify a single archive and single-quote the arguments: .  To extract multiple archives at once however you can use multiple methods: .   \"bash\":   \"find\":  ",
      "P-tags": "archiv wildcard command-lin 7zip",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_62304808",
      "task": "How to create a shell script which can create a .java file on executing?",
      "P-task": "creat shell script creat java file execut",
      "F_verb": "create",
      "P-body": "Here-docs will expand variables, so .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP which S"
    },
    {
      "id": "so_12499110",
      "task": "how to create a txt file with columns being the descending sub-directories in Linux?",
      "P-task": "creat txt file column descend sub-directori linux",
      "F_verb": "create",
      "P-body": "Hmm, nobody?  .  You should redirect output of \"find\" command, consider switches -type d, and -maxdepth, and probably parse it with sed, replacing \"/\" with \"spaces\". Maybe piping through \"cut\" and \"column -t\" commands, and \"sort\" and \"uniq\" will be useful. Do names, except FF and ID, contain spaces, or special characters e.g. related to names of participants?  .  It should be possible to get a TXT with \"one liner\" and a few pipes.  .  You should try, and post first results of your work on this :) .  EDIT: Alright, I created for me a structure with several thousands of directories and subdirectories numbered by participant, by exam number etc., which look like this ( maybe it's not identical with what you have, but don't worry ). Studies are numbered from 5 to 150, FF from 45 to 75, and dates from 2012_01_00 to 2012_01_30 - which makes really huge quantity of directories in total.  .  Now, I want ( quote ) \"txt file with one line per participants and the following columns: study ID, FF_number, Exam_Number and date.\" .  So I use the following one-liner: .  and here is the output ( a few first lines from out.txt ). Lines are very long, I cutted it on output for first 80-90 characters: .  I hope this will help you a little, and you'll be able to modify it according to your needs and patterns, and that seems to be all I can do :) You should analyze the one liner, especially \"cut\" command, and perl-regex part, which removes newlines and full directory name from \"ls\" output. This is probably fair from optimal, but beautifying is not the point here, I guess :) So, good luck :) PS. \"head\" command limits output for N first lines, you'll probably want to skip out | head .. | part. .  ",
      "P-tags": "file directory-structur linux",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "su_595077",
      "task": "Elementary OS - Stop MySQL from starting automatically at boot",
      "P-task": "elementari os - stop mysql start automat boot",
      "F_verb": "stop",
      "P-body": "Elementary OS is based on Ubuntu so I would have a look through the \"/etc/rc\" directories and see if there is an entry in there which is starting mysql .  The Ubuntu guide for this sort of thing suggests something along these lines: .  where 'myscript' is the service you want to stop starting at boot .  ",
      "P-tags": "linux ubuntu mysql",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING at NP"
    },
    {
      "id": "so_45563956",
      "task": "CSV file generates new name - call powershell",
      "P-task": "csv file gener new name - call powershel",
      "F_verb": "generate",
      "P-body": "You can use \"Get-Childitem\" to get files/directories in a directory. You can combine it with \"-Filter\" to get only CSVs, \"Sort-Object\" to sort by \"LastWriteTime\" (most recent CSV at the top) and \"Select-Object\" so you only get the most recent file. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_39160388",
      "task": "How to remove duplicate function",
      "P-task": "remov duplic function",
      "F_verb": "remove",
      "P-body": "I removed all my modules from the directory and opened ISE again to verify that the \"New-SMOConnection\" command is gone. Created then a new Module (My-HelpfullCommands) with only the \"New-SMOConnection\" in it. In all the other modules, I removed the \"New-SMOConnection\" function and copied them back into the modules directory. .  Now the \"New-SMOConnection\" is declared only once and I can use it for all my modules.  .  Everything seems to work as expected. .  Next I plan to add all my littel helper functions into the \"My-HelpfullCommands\" module. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_47421993",
      "task": "Get specific key value pairs with jq",
      "P-task": "get specif key valu pair jq",
      "F_verb": "get",
      "P-body": "Your question is not exactly accurate: .   The example JSON is invalid, because the last property of the second object has a trailing comma, which should raise a parsing error The output of \"map(select(.charge == null))\" is not an object as in the example, but an array of a single object  In any case, you can extract the \".id\" from the result of \"map\" like this: .  ",
      "P-tags": "json jq bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "au_522647",
      "task": "How to force 'top' to show human readable values for %MEM RES and VIRT",
      "P-task": "forc top show human readabl valu mem re virt",
      "F_verb": "force",
      "P-body": "If you press h, the help screen contains, among other things: .  Pressing e cycles through mega, giga, tera and peta-sized figures (and the default suffixless kilobyte) values. .  After selecting the size, press W to have \"top\" save your preferences to \"~/.toprc\". Now it should start with the preferred size. .  ",
      "P-tags": "top",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP S_INF for NP"
    },
    {
      "id": "so_55928393",
      "task": "Compile Python 3.6 statically with OpenSSL",
      "P-task": "compil python 3 6 static openssl",
      "F_verb": "compile",
      "P-body": " I'm trying to compile Python 3.6 on Linux statically with OpenSSL. ... .   Change \"-lssl\" and \"-lcrypto\" to \"-l:libssl.a\" and \"-l:libcrypto.a\": .  You can also use the full path to the archive: .  Archives (\"*.a\") are just a collection of object files (\"*.o\"), so you can use an archive wherever you use an object file. .  Also see \"-l:filename\" in the \"ld(2)\" man page: .   \"--library=namespec\" .  Add the archive or object file specified by namespec to the list of files to link. This option may be used any number of times. If namespec is of the form :filename, ld will search the library path for a file called filename, otherwise it will search the library path for a file called libnamespec.a. .   If you have other components in \"/usr/local\" you are using, then you might want to add \"-L/usr/local/lib -Wl,-R,/usr/local/lib -Wl,--enable-new-dtags\" to your \"LDFLAGS\". The \"new-dtags\" embeds a \"RUNPATH\" (as opposed to \"RPATH\") in the ELF headers. \"RUNPATH\" can be overridden with \"LD_LIBRARY_PATH\". .    I get a compiled binary, but it isn't statically linked to OpenSSL. .   The way to check is to use \"ldd\" with the paths you use at runtime. For example, here is from a local OpenSSL build on Fedora: .   Here are a couple of related questions, but it does not look like they cover static linking with Python. .   Building Python with SSL support in non-standard location How do I compile Python 3.4 with custom OpenSSL?   And to be clear, \"config.log\" has the error but you did not show the relevant portion from it: .  Static OpenSSL may (or may not) fix the problem. .  ",
      "P-tags": "static-link linux python openssl",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP with NP"
    },
    {
      "id": "so_28885587",
      "task": "Compare 2 csv files and match based on 1 column then export new file that contains fields from both",
      "P-task": "compar 2 csv file match base 1 column export new file contain field",
      "F_verb": "compare",
      "P-body": "Let's try to simplify this. Add the 'Name ID' field to all records in CSV1. Then loop through it, and get the matches, and update the field. Something like: .  ",
      "P-tags": "powershel csv merg",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_87920",
      "task": "How to detect if a disk is seeking?",
      "P-task": "detect disk seek",
      "F_verb": "detect",
      "P-body": "The ratio \"(rkB/s + wkB/s)/%util\" of the \"iostat -x\" output should give you some insight: .  I'm not sure how exactly this ratio corresponds to the disk seek. But the idea is that, if the disk is busy and does not have a high throughput it is probably seeking. However, it's not guaranteed. Broken disks sometimes show a high utilisation and have almost no throughput. But it's at least an indicator. .  You can also provide a number to iostat (e.g. \"iostat -x 5\") to specify the update interval. That way you can monitor continuously. .  ",
      "P-tags": "disk linux measur",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "su_898604",
      "task": "Copying files from an existing directory to a newly mounted disk",
      "P-task": "copi file exist directori newli mount disk",
      "F_verb": "mount",
      "P-body": "On your answer you are suggesting a process with two copies: .   from /var/log to temporary folder from temporary folder to new /var/log  However you can do it in a single copy-process .   Mount the new disk in another place different of \"/\", for example mount it on \"/media\" so its path will be \"/media/var/log\". Do the copy from \"/var/log\" to \"/media/var/log\". .  After it is finished unmount both and mount the new disk on \"/\". .   If you use \"cp\" don't forget the \"-p\" option that will preserve timestamp and ownership. .  ",
      "P-tags": "mount linux",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_20000552",
      "task": "script to replace all dots in a file with a space but dots used in numbers should not be replaced",
      "P-task": "script replac dot file space dot use number replac",
      "F_verb": "replace",
      "P-body": " Try any solution you're considering with that input file as it includes some edge cases (there may be more I haven't included in that file too). .  The solution is basically to temporarily convert periods within numbers to some string that cannot exist anywhere else in the file so we can then convert any other periods to underscores and then undo that first temporary conversion. .  So first we create a string that can't exist in the file by converting all \"a\"s to the string \"aA\" which means that the string \"aB\" cannot exist in the file. Then convert all \".\"s within numbers to \"aB\"s, then all remaining \".\"s to \"_\"s then unwind the temporary conversions so \"aB\"s return to \".\"s and \"aA\"s returns to \"a\"s: .  That approach of creating a temporary string that you KNOW can't exist in the file is a common alternative to picking a control character or trying to come up with some string you THINK is highly unlikely to exist in the file when you temporarily need a string that doesn't exist in the file. .  ",
      "P-tags": "awk unix script replac vi",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_20356323",
      "task": "Linking to modules folder gives undefined reference",
      "P-task": "link modul folder give undefin refer",
      "F_verb": "give",
      "P-body": "You need to include the \".o\" file as well. That is, you should compile this as .  This worked and ran for me. .  ",
      "P-tags": "fortran linux ld maco",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_65694749",
      "task": "Powershell Best way to parse string content",
      "P-task": "powershel best way pars string content",
      "F_verb": "parse",
      "P-body": "The response is CSV, as the URL indicates with the \"output=csv\" parameter. .  Use the \"ConvertFrom-Csv\" cmdlet. .  \"$data\" will be an array. .  PowerShell will assume the CSV has headers by default, which conveniently is the case here. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_37576105",
      "task": "How do I use Bash to get a Ruby variable?",
      "P-task": "use bash get rubi variabl",
      "F_verb": "get",
      "P-body": "You can use it as such. .  If for example you want to export an environment variable. .  More information on command substitution. .  ",
      "P-tags": "rubi bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_72784",
      "task": "Migrate from Gnote to Org-mode",
      "P-task": "migrat gnote org-mod",
      "F_verb": "migrate",
      "P-body": "I used https://github.com/StAlphonsos/scriptologie/blob/develop/scripts/tomboy2org.pl which is mentioned in http://orgmode.org/worg/org-tools/. .  Here is how to proceed. Note, however, that you may want to clean out your notes before so that you do not migrate unwanted notes.) .   Install the dependencies for running the script: .   Download the script from https://github.com/StAlphonsos/scriptologie/blob/develop/scripts/tomboy2org.pl. .  Close Gnote so that any changes is written to its database. .  Run the script. I chose to run the script with the option \"-notebooks\" to make one .org file out of each Gnote notebook: .    ",
      "P-tags": "org-mod gnote emac",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V from NP to NP"
    },
    {
      "id": "so_15435233",
      "task": "Where do I get 32 bit Linux kernel source for x86",
      "P-task": "get 32 bit linux kernel sourc x86",
      "F_verb": "get",
      "P-body": "There is no specific 32 bit linux kernel source. All architectures are contained in the same tarball / git repository. .  The majority of the linux kernel is implemented in portable C which can be used on all architectures. The architecture specific parts are in separate sub directories below the \"arch\" directory. See also https://github.com/torvalds/linux/tree/master/arch. .  When configuring and compiling on a \"x86_64\" machine, you will get an \"x86_64\" kernel by default. If you want to build a 32 bit \"x86\" kernel on the same machine, you need to cross-compile, for example: .  will give you the necessary options to select an x86 based processor type. .  will then build the x86 based kernel image. .  ",
      "P-tags": "linux linux-kernel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP"
    },
    {
      "id": "so_38129577",
      "task": "mPDF never renders on Ubuntu / Apache / PHP7 stack",
      "P-task": "mpdf never render ubuntu apach php7 stack",
      "F_verb": "render",
      "P-body": "So the server had an IP firewall and mPDF uses \"file_get_contents()\" to reference assets for the PDF as external assets, including the domain name: .  This means the request was going out of the server, coming back to it and being refused by the firewall. .  Removing the firewall solved our issue. .  I'd still love to know if mpdf can reference assets locally. The docs for its \"basePath\" property seem to indicate that it always used a full domain URL: .  https://mpdf.github.io/reference/mpdf-functions/setbasepath.html .  ",
      "P-tags": "ubuntu apach mpdf php",
      "source": "qa",
      "cate": "draw/render/paint/redraw/plot",
      "pat": "V on NP"
    },
    {
      "id": "so_36791320",
      "task": "Stopping an unknown process in linux server",
      "P-task": "stop unknown process linux server",
      "F_verb": "stop",
      "P-body": "Your oneliner kill: (I know it's bad, but it should work) .  ps -ef finds the program line:  .  Then we use \"grep\" to remove parts we don't want. .  And lastly pass the pid to kill.  .  ps: replace 'root' for the user you know run the service/pid you are looking for. .  ",
      "P-tags": "linux jar spring java",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_182121",
      "task": "apt-get failed to find any updates for Debian squeeze",
      "P-task": "apt-get fail find updat debian squeez",
      "F_verb": "get",
      "P-body": "I think you might need to put this in your \"/etc/apt/sources.list\" file: .  Source: https://wiki.debian.org/LTS/Using .  ",
      "P-tags": "upgrad apt debian",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF for NP"
    },
    {
      "id": "au_689710",
      "task": "'ssh localhost' gives 'Permission denied (publickey).'",
      "P-task": "ssh localhost give permiss deni publickey",
      "F_verb": "give",
      "P-body": "Please, check \"/var/log/auth.log\" for possible errors during connection. This line .   Oct 25 09:49:47 me-myubuntu sshd[16442]: User me from localhost not allowed because not listed in AllowUsers .   indicates the problem. .  ",
      "P-tags": "12 04 localhost ssh",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "su_1001973",
      "task": "bash - find string index position of substring",
      "P-task": "bash - find string index posit substr",
      "F_verb": "find",
      "P-body": "Use parameter expansion: .  $rest contains the part of $t after $searchstring. The starting position of the substring is therefore the length of the whole string minus the length of the $rest minus the length of the $searchstring itself. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "su_656082",
      "task": "External HDD doesn't show up in /dev on raspberry pi",
      "P-task": "extern hdd show dev raspberri pi",
      "F_verb": "show",
      "P-body": "Possible reasons why a USB hard drive doesn't show up in \"/dev\" when connected: .   Drivers for your USB chipset or hardware not loaded or not working properly (try updating kernel if possible) USB driver had a problem initializing the device - typically wrong driver, defective or unsupported hardware Some hardware may act bad if too much power is consumed by attached USB devices Hard drive is dead, defective or not communicating with the SATA/IDE to USB bridge (hard drive not connected to enclosure properly?) - SATA/IDE to USB bridge may also be dead or defective. Hard drive is not powered on or not getting enough power Physical issue with USB cable or port  Try putting the hard drive in an enclosure that is separately powered and see if you have better luck with that. .  ",
      "P-tags": "linux hard-driv mount usb raspberry-pi",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V up in NP on NP"
    },
    {
      "id": "au_1124278",
      "task": "Program clogging up my RAM- but when I stop it via 'sudo service X stop' it says its not loaded",
      "P-task": "program clog ram- stop via sudo servic x stop say load",
      "F_verb": "stop",
      "P-body": "As per the updated question there are no packages matching \"mongodb-org*\". Uninstalling mongodb will probably be achieved by issuing .  Uninstalling mongo-tools .  ",
      "P-tags": "mongodb",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V"
    },
    {
      "id": "ul_334666",
      "task": "How to set/change LXTerminal font for standard user?",
      "P-task": "set chang lxtermin font standard user",
      "F_verb": "set",
      "P-body": "check \"~/.config/lxterminal/lxterminal.conf\" You can save the right config and overwrite at every boot. But it's better to find out what is overwriting constantly your config files. .  ",
      "P-tags": "lxtermin lxde font",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_26729001",
      "task": "Shell scripting : Giving error invalid command name \"server1\"",
      "P-task": "shell script : give error invalid command name server1",
      "F_verb": "give",
      "P-body": "Problem is here: .  You cannot have 2 shebangs in same Unix script. Only first will be in effect and second will be ignored. Hence your script must be fully \"expect\" compliant script (since that is first one here - should be lowercase \"expect\" though). .  Moment you try to use a \"bash\" syntax in it, you will get errors since that \"bash\" specific script will be interpreted by \"expect\". .  ",
      "P-tags": "expect unix shell",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "so_19145454",
      "task": "Tomcat opening a lot of instance in memory",
      "P-task": "tomcat open lot instanc memori",
      "F_verb": "open",
      "P-body": "By default \"htop\" list threads instead of process, try to use \"top\" of \"ps -ef | grep tomcat\" .  ",
      "P-tags": "ubuntu tomcat6 java",
      "source": "qa",
      "cate": "open",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_40697134",
      "task": "Error when building source files with wxWidgets , Linux, C++",
      "P-task": "error build sourc file wxwidget linux c++",
      "F_verb": "build",
      "P-body": "If you use Ubuntu, you really shouldn't have any problems if you just installed the distribution package. .  It looks like you had tried to install wxWidgets from sources before and your \"wx-config\" comes from \"/usr/local/bin\" and is not the one installed by the package. You can check it using \"which wx-config\" and/or using full path to \"/usr/bin/wx-config\" when compiling. Just get rid of this one, and all the other traces of wxWidgets under \"/usr/local\", if you're using the system packages. .  ",
      "P-tags": "build c++ linux wxwidget",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP"
    },
    {
      "id": "au_1213047",
      "task": "How to (quickly) switch to dark mode in Ubuntu with GNOME and to make it fully dark?",
      "P-task": "quickli switch dark mode ubuntu gnome make fulli dark",
      "F_verb": "make",
      "P-body": "For easy and quick toggling from Dark to Light theme and vice versa install this GNOME extension: .   Night Theme Switcher (GNOME Shell Extension), it has a lot of settings options incl. automated switch based on time. Ubuntu Appearance (GNOME Shell Extension) integrates Light, Dark, Standard option into system tray menu. For pictures and more info including installation, see UbuntuHandbook article.  Invert the color of individual windows only (Default shortcut is Super+I): use the Globe Extension Invert Window Color. Thank you Sam! .  Ubuntu 20.04: You can now easily choose a dark mode within the Settings: \"Appearance > Window colors > Dark\". There is no possibility to set a time to have an automatic switch based on time, though (without a GNOME extension, see above). .  For a Full Dark Mode of the system (incl. System tray menu, top-bar calendar, notification popups, and desktop context menu) you need some more steps: .   Install GNOME Tweaks and other tools if you don't have them, then reboot/restart. In a terminal:  (*) Firefox add-on for GNOME Shell integration in Firefox. 2. Install user themes GNOME Shell extension: https://extensions.gnome.org/extension/19/user-themes/ 3. Turn on user themes GNOME extension in GNOME Tweaks or in the GNOME extensions app. 4. Log out and back in to your session OR manually restart GNOME Shell (Alt + F2, type r, hit enter) for the theming extension to actually be activated. 5. Launch GNOME Tweaks and navigate to Appearance in the left pane, choose Yaru-dark as the Shell theme! More details and source: [How to Enable Dark Gnome Shell Menus, Calendar in Ubuntu 20.04 | UbuntuHandbook] .  In the future this answer may be shorter, read this GNOME blog article on Dark Style Preference. .  But the Dark Theme Toggle does not make some of the apps fully dark and you have to do some further configuration: .  LibreOffice: (adapted from Debugpoint.com) .   Open LibreOffice. Open any component \u2013 Writer, Calc etc. From menu, click Tools -> Options. Go to Application Colours, select document background as Black. You can also choose the Application background as Black. There may be more custom color settings you like to adapt. For example, Remove the gray background from Table Of Contents: Modify the color setting in Text Document, \u2611 Index and table shadings. Or disable it: \u2610 Index and table shadings.) Some special formatting, e.g. links were not shown well on my computer, I chose a lighter colour for the unvisited and visited links. If you would like to change to a dark icon theme, change it from \"View\" options on the left side for better visibility of the toolbar icons, e.g. choose \"Breeze (dark) as icon style.  Update 2021/08: With LO 7.2 you get a new LibreOffice dark mode colour scheme. This is designed to compliment the dark theme enabled by your system. To enable it, head to: Alternative Tools \u25b8 Options \u25b8 LibreOffice \u25b8 Application Colors theme 'LibreOffice Dark' and \"apply\" it. .  There is a also a dark theme to install: RaitaroH/LibreOffice-BreezeDark: Icons, color palette and color scheme for LibreOffice .  Firefox: Enable Dark Mode in Firefox, see HowToGeek for details. .   Click menu > Add-ons > Themes, choose Dark theme.  To view the webpages in dark colours, use an add-on. Two tested options: .   Dark Reader:   Handy keyboard short-cut to toggle: Shift-Alt-D It promises that \"it does not show ads and doesn't send user's data anywhere. It is fully open-source.\" It may cause more CPU use, though.   Dark Background and Light Text Before you install disable similar extensions. Handy keyboard short-cut to toggle: F9  PDF viewer (e.g. Evince document viewer): See Is there any pdf viewer with dark mode? - Ask Ubuntu Go to the options on the top right corner (Sandwich menu). Then select Night Mode or Inverted colours. .  Wire messenger (How to install Wire messenger on Ubuntu): Go to preferences, then Options, choose dark theme. .  Thunderbird With TB 78+ you can choose a dark theme (open add-on page and choose themes on the left side). Apart from that there are some dark theme add-ons with more tweaks. .  Audacity: The theme to use can be selected at Edit > Preferences > Interface You can also change the colour of the waves without selecting a theme. And more sophisticated (source: OMG!Ubuntu): .   Download the Audacity Clean Dark Theme pack Extract the .zip Copy ImageCache.png from the named colour folder you want Paste file into ~.audacity-data/Theme (if the directory doesn\u2019t exist, create it) Open Audacity > Preferences > Interface Select \u2018Custom\u2019 theme option  Calibre: See How do I get a dark theme/night mode in Calibre? - Ask Ubuntu .  ",
      "P-tags": "gtk theme ubuntu-gnom",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V in NP with NP"
    },
    {
      "id": "au_999845",
      "task": "Firefox Developer Edition fails to update itself automatically although the settings show I allowed it to automatically install updates",
      "P-task": "firefox develop edit fail updat automat although set show allow automat instal updat",
      "F_verb": "update",
      "P-body": "If you've copied files to \"/opt\" or \"/usr/local\", both are owned by root, and aren't writable by regular users. To be able to auto update, you need to install it in your home folder, or chown \"/opt\" or \"/usr/local\". .  Alternatively, just download the new version and copy its files again, overwriting old ones. .  ",
      "P-tags": "14 04 firefox",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_24909083",
      "task": "BASH get error code in parent terminal from child terminal?",
      "P-task": "bash get error code parent termin child termin",
      "F_verb": "get",
      "P-body": "It seems GNOME Terminal exits immediately after starting, which is obvious if you run for example \"gnome-terminal -x sleep 10\". Since it doesn't wait for the command to finish, there's no way the return code will be that of the command. I could find no option in \"gnome-terminal --help-all\" to keep the process in the foreground. .  Regarding your second question, you've double-quoted the command, so \"$?\" is expanded before running it. This should work: .  PS: The \"-x\" option is not documented in GNOME Terminal 3.8.4's \"gnome-terminal --help-all\", various references don't help much, and there's no good explanation for why there's a \"-e\" option with identical semantics and different syntax. .  ",
      "P-tags": "gnome-termin process bash error-cod parent-child",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "ul_154716",
      "task": "How to kill all processes for a given user that take longer then X time",
      "P-task": "kill process given user take longer x time",
      "F_verb": "kill",
      "P-body": "to answer 1), start with .  (depending on you context, you may wish to select time (cpu time), etime (elapsed time)) .  to answer 2), try .  You really want to kill Running process ? .  ",
      "P-tags": "linux ubuntu command-lin command",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP for NP that S"
    },
    {
      "id": "ul_673643",
      "task": "reduce lvm space and create new partition",
      "P-task": "reduc lvm space creat new partit",
      "F_verb": "create",
      "P-body": "First, you need to reduce the size of the physical volume, using \"pvresize\": .  This ensures that all the data and metadata end up inside the first 132GiB of \"/dev/vda2\". I\u2019m playing it safe size-wise here. .  Then you need to shrink the \"/dev/vda2\" partition entry, using \"fdisk\" or a similar tool \u2014 delete the partition entry and re-create it with the same starting sector and the appropriate size (slightly more than 132GiB, 276,824,064 512-byte sectors, to stay safe). This will allow you to create a new partition. .  Finally, resize the PV again, this time using .  so that it uses all the available space in the partition. .  ",
      "P-tags": "disk partit fdisk partition-t lvm",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_28274708",
      "task": "Powershell 3: preventing excessive memory usage for webrequest",
      "P-task": "powershel 3 : prevent excess memori usag webrequest",
      "F_verb": "prevent",
      "P-body": "Seems the only way to do this is using WebClient .  ",
      "P-tags": "powershel powershell-3 0",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP for NP"
    },
    {
      "id": "au_180158",
      "task": "How does one connect to a GTK signal with a dash inside it while using Quickly?",
      "P-task": "one connect gtk signal dash insid use quickli",
      "F_verb": "connect",
      "P-body": "You simply do something like the following to connect to any signal. From working code: .  ",
      "P-tags": "pygtk quickli",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP with NP while S_ING"
    },
    {
      "id": "ul_184376",
      "task": "CentOS - commands in rc.local not run",
      "P-task": "cento - command rc local run",
      "F_verb": "run",
      "P-body": "Turned out that the IPNHost program was dependent on intel ipp libraries environment variables for which the location was not specified at that point of time during boot.  .  Did a script autoStart.sh .  The source /opt/intel/bin/compilervars.sh intel64 loads the required intel environment variables which specify where to find the dynamically loaded libraries.  .  In rc.local I then called autoStart.sh, this works.  .  ",
      "P-tags": "cento linux boot",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "au_787641",
      "task": "How does APT work (apt-get, cache, search)",
      "P-task": "apt work apt-get cach search",
      "F_verb": "get",
      "P-body": "You are right that \"apt-get update\" reads from the sources (online) and the other commands \"apt-get search\" and \"apt-get install\" read from the cached information. From \"man apt\": .  The difference between \"apt search <package>\" and \"apt-cache search <package>\" is that the output of \"apt search\" is fancier (has colours, alphabetically organised, has nice line separation for easy reading) because apt is a fancy new interface. This is explained well in this answer on the difference between apt & apt-get .  However, search isn't the only thing you can do with apt-cache: .  This is from the \"info\" page for \"apt-cache\" .  \"apt\" combines commands from \"apt-get\" and \"apt-cache\", so you can get the same or slightly fancier/tidied up output from any of the \"apt-cache [option] <package>\" commands with \"apt [option] <package>\" eg .  displays almost exactly the same as  .  ",
      "P-tags": "apt updat package-manag software-instal repositori",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V"
    },
    {
      "id": "ul_151162",
      "task": "Parse multiple sections of data into separate files",
      "P-task": "pars multipl section data separ file",
      "F_verb": "parse",
      "P-body": "How about something like .  ",
      "P-tags": "awk sed text-process",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V"
    },
    {
      "id": "so_32769695",
      "task": "How to pass a bash variable to sqlplus and then pass that output to another variable",
      "P-task": "pass bash variabl sqlplu pass output anoth variabl",
      "F_verb": "pass",
      "P-body": " The error I keep getting is .  This tells me that it's not passing the output of the select statement to $FINDPDB, but rather the actual select statement itself. .   I don't see why you would expect this to pass the output of the \"SELECT\" query into \"$FINDPDB\". You're putting together a big long string which bash passes to the standard input of sqlplus and then writes to stdout the output from sqlplus. At no point is bash picking out certain lines of the sqlplus output and putting them into shell variables. .  In fact, try adding \"echo $ALTER\" to your bash script before you call sqlplus. You will quite probably find that the output is .  If so, then bash has already done the substitution you didn't want before you've even started \"sqlplus\". .  You seem to want bash and sqlplus to have some kind of back-and-forth dialog. I would give up on this approach. Instead of trying to put the PDB name into a shell variable, I would put it into a sqlplus substitution variable. I would try something like the following (not tested): .  We use \"column pdb_name new_value pdb\" to set the substitution variable \"pdb\" to the next value to be selected from a column named \"pdb_name\". We then run a \"select\" query to fetch the PDB name and hence store it in \"pdb\". Once we've got this value in a substitution variable, we can then issue the \"alter session\" statement to change the PDB and finally the \"delete\" statement to delete data from the PDB. .  I'm tempted to avoid the use of a PL/SQL block for this, as has been suggested in another answer. I would prefer that the \"delete\" statement is parsed after the PDB is changed as I would want to be sure that the data from the 'correct' PDB is being deleted. My concern with using PL/SQL for this is that the PL/SQL compiler would determine which table to delete from when the block is parsed, which would be before it runs the block, and hence before it executes the \"alter session\" statement to change the PDB. However, I don't know PDBs and CDBs in Oracle 12c well enough to say whether this is a genuine problem or unfounded nonsense. .  I don't have access to a pluggable Oracle 12c database to run something like this against, so I can't tell you whether this script works. If not, hopefully it should give you an idea of where to go. .  ",
      "P-tags": "sql linux bash oracl",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_61724986",
      "task": "Is there any way linking GPO with ou using the ou canonical name?",
      "P-task": "way link gpo ou use ou canon name",
      "F_verb": "use",
      "P-body": "Try it this way:  .  No tested the above using forms, but it should work as intended. .  ",
      "P-tags": "powershel window gpo",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_56597408",
      "task": "assign output of memcache command to a variable in shell/bash script",
      "P-task": "assign output memcach command variabl shell bash script",
      "F_verb": "assign",
      "P-body": "You could just do: .  but check the man page for \"nc\" to see if it has any options to control what it outputs. .  ",
      "P-tags": "memcach shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP to NP in NP"
    },
    {
      "id": "ul_78804",
      "task": "How to mount a disk from destroyed raid system?",
      "P-task": "mount disk destroy raid system",
      "F_verb": "mount",
      "P-body": "In my case I brought up CentOS 7 and tried following everyone's instructions on this page. I kept running into a device busy message. The reason in my opinion why you are getting the  .   mdadm: cannot open device /dev/sda1: Device or resource busy .   error message is because the device is already mounted as something else. .  I also did not want to make any changes to the disk at all since my use case was to extract a very large file from my RAID1 array that failed to be extracted every possible way otherwise and the fastest way was to pull one of the drives out, I do want to put the drive back in and still have my configuration in place as well. .  Here is what I did after doing some online research on other sites: NOTE: NAS:0 is the name of my NAS device so substitute appropriately. .  It was automatically mounted although it would say that its not mounted if you were to run the mount command, you can verify that it was mounted by running: .  Notice it was automatically mounted under \"/dev/md127\" for me. .  Ok then: .  That did it for me. .  If in doubt, DD the drive to make a full copy and use CentOS or other Linux Live CD. .  ",
      "P-tags": "data rescu debian raid",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "so_31791798",
      "task": "bash: recursively move all matched files in sub directory of parent to new sub directory",
      "P-task": "bash : recurs move match file sub directori parent new sub directori",
      "F_verb": "move",
      "P-body": "You probably want \"find \"$dir\"\" rather than \"find .\" in your code: .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP in NP of NP to NP"
    },
    {
      "id": "au_958509",
      "task": "Dual boot: Ubuntu cannot detect Windows 10 (Legacy) after install",
      "P-task": "dual boot : ubuntu detect window 10 legaci instal",
      "F_verb": "detect",
      "P-body": "I just looked at my partition table and it seems that your Windows OS partitions' boot flag was removed. It you look at what you posted, the \"*\" on \"/dev/sda1\" is only 1G and is marked as BOOT. Unless you loaded your bootloader on that partition. .  If we take a look at your partition table, we see that you have 2 partitions that are NTFS which is the format windows uses. You have \"/dev/sda2\" and \"/dev/sda5\". Figure out which one of those 2 is the one with the windows installation by mounting them. Once you figure out which one has the windows installation then you can set a boot flag on it: being the partition number that has the windows installation on it, you have 2 and 5 available. .  We can start by mounting both of them, one at a time and checking their contents. .  I know you already mentioned that your files are in \"/dev/sda2\" but im writing these instructions for others who have it different. .   \"mkdir ~/MOUNT\" <- This will create a temporary directory for us to mount our partition in your home folder. So the path of this folder will be \"/home/user/MOUNT\" so you can browse to it via file manager GUI. \"sudo mount -t ntfs -o uid=user,gid=user /dev/sda2 ~/MOUNT\" <- This will mount the second partition as NTFS in the directory we just created. As well as mounting it as your current username that way you can browse to it freely. If the \"uid\" and or \"gid\" are not added for your user, it will mount as \"root\" and only \"root\" can browse to it. If the command completed without error, you should be able to browse in the directory from a file manager and check if it contains your windows installation. \"sudo umount /dev/sda2\" <- This will unmount your partition.  Now repeat the same steps (1-4) for \"/dev/sda5\" if \"/dev/sda2\" was not where Windows was installed. .  Before we make any changes, lets update grub first then reboot and see if that helped (see #5). .  Now that you figured out which partition has the Windows installation, and updating grub prior did not have an effect, you can try to manually set a boot flag on your windows partition. .   \"sudo fdisk /dev/sda\" In the menu, press \"a\" and it will ask which partition to add a boot flag. Which ever you find out has the windows installation, that will be the number you will enter. Once you have made your choice, you can press \"P\" to print out the current partition table and make sure the partition you typed has been marked with an \"*\" in the \"Boot\" column. Once you have verified that everything is correct, you can press \"w\" to write changes to the partition table and exit. Now we need to update grub with \"sudo update-grub\" or \"sudo update-grub2\", depending on the version of grub you are using.  Let us know if you need more help! .  ",
      "P-tags": "boot window dual-boot windows-10",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP after NP"
    },
    {
      "id": "so_61656432",
      "task": "Building from source using:\"pip install .\" doesn't work with sudo",
      "P-task": "build sourc use : pip instal\nwork sudo",
      "F_verb": "build",
      "P-body": "You can install the package into the user directory with \"pip install . --user\" .  ",
      "P-tags": "linux ubuntu pip",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V from NP using NP"
    },
    {
      "id": "so_43419500",
      "task": "How do you start a Docker-ubuntu container into bash?",
      "P-task": "start docker-ubuntu contain bash",
      "F_verb": "start",
      "P-body": "First of all, a container is not a virtual machine. A container is an isolation environment for running a process. The life-cycle of the container is bound to the process running inside it. When the process exits, the container also exits, and the isolation environment is gone. The meaning of \"attach to container\" or \"enter an container\" actually means you go inside the isolation environment of the running process, so if your process has been exited, your container has also been exited, thus there's no container for you to \"attach\" or \"enter\". So the command of \"docker attach\", \"docker exec\" are target at running container. .  Which process will be started when you \"docker run\" is configured in a \"Dockerfile\" and built into a docker image. Take image \"ubuntu\" as an example, if you run \"docker inspect ubuntu\", you'll find the following configs in the output: .  which means the process got started when you run \"docker run ubuntu\" is \"/bin/bash\", but you're not in an interactive mode and does not allocate a tty to it, so the process exited immediately and the container exited. That's why you have no way to enter the container again. .  To start a container and enter \"bash\", just try: .  Then you'll be brought into the container shell. If you open another terminal and \"docker ps\", you'll find the container is running and you can \"docker attach\" to it or \"docker exec -it <container_id> bash\" to enter it again. .  You can also refer to this link for more info. .  ",
      "P-tags": "docker ubuntu bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP into NP"
    },
    {
      "id": "au_1208349",
      "task": "sh: 1: program not found occurs when running a Terminal command via Python, but directly entering the command in the Terminal works fine",
      "P-task": "sh : 1 : program found occur run termin command via python directli enter command termin work fine",
      "F_verb": "find",
      "P-body": "As I thought what may be the case, the problem was due to Gunicorn being installed in a virtual environment. I uninstalled Gunicorn and this time skipped the steps in the guide that set up a virtual environment before re-installing Gunicorn. I also changed the myproject.service file from this: .  to this: .  Now I just need to wait for Google Domains to link the IP of the server to my domain which is freeaudioconverter.net .  ",
      "P-tags": "nginx flask server wine python",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP when S"
    },
    {
      "id": "so_29340612",
      "task": "Open a socket with the name socket:[4023]",
      "P-task": "open socket name socket : 4023",
      "F_verb": "open",
      "P-body": "The part in square brackets is the inode number of the socket. You can obtain the remote endpoint (for connected sockets), local address (for listening sockets) or path (for Unix sockets) using .  or using \"netstat -nae\" if you do not have \"ss\" installed. netstat's output is more non-uniform though. .  Both programs extract this information from \"/proc/net/tcp\", \"/proc/net/unix\", et al. To obtain the information using C, parse these files directly. They come with a readable header, so the columns should be clear; the idea is the same: Search for the line with the matching inode and extract the endpoint. .  ",
      "P-tags": "linux c socket",
      "source": "qa",
      "cate": "open",
      "pat": "V NP with NP"
    },
    {
      "id": "so_66030176",
      "task": "Learning the grep command and came across this. How does it work combined with tail?",
      "P-task": "learn grep command came across\nwork combin tail",
      "F_verb": "learn",
      "P-body": "tail -4 when executed with a file would normally print the last four lines of the file .  With: .  The tail command is being executed on the output of the grep command and so will print the last 4 lines of the output of grep. .  If for example there are 50 occurrences of \"&\" in input.txt, only the last 4 will print. .  ",
      "P-tags": "tail grep bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_26827605",
      "task": "Powershell set focus on new window",
      "P-task": "powershel set focu new window",
      "F_verb": "set",
      "P-body": " ",
      "P-tags": "powershel powershell-2 0 powershell-3 0",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP"
    },
    {
      "id": "so_7368395",
      "task": "Finding a list of files by name given a list of keywords and finding the list of keywords that were not found",
      "P-task": "find list file name given list keyword find list keyword found",
      "F_verb": "find",
      "P-body": "untested .  ",
      "P-tags": "find unix bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP by NP of NP"
    },
    {
      "id": "su_204003",
      "task": "Make OS X Terminal commands I type BOLD",
      "P-task": "make os x termin command type bold",
      "F_verb": "make",
      "P-body": "Edit your \"~/.bash_profile\" or \"~/.bashrc\" (see Gilles' comment below) and add the following lines: .  Move the \"${BOLD}\" around to make part of the prompt also bold. If the prompt itself should not be colored, you need the \"${OFF}\" prefix in \"PS1\", otherwise empty lines (pressing enter without having something written) will make the following prompt bold (credits to @Jay, thanks again!) .  This adds a debug trap to turn bold format off, so it's quite a hack. Credits (works without group tty on OS X though). .   This is a bit of a hack, so use it at your own risk. .   Only setting your \"PS1\"/\"PS2\" prompts to bold would be easier and just as visible: .  ",
      "P-tags": "termin command-lin mac maco bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_18882853",
      "task": "How can I pass default credentials to a PowerShell Web Client Object? Alternative to Invoke-WebRequest for PS v2?",
      "P-task": "pass default credenti powershel web client object\naltern invoke-webrequest ps v2",
      "F_verb": "invoke",
      "P-body": "Just set the \"UseDefaultCredentials\" property of the WebClient to \"$true\" and that will use the credentials of the current user for authentication. .  ",
      "P-tags": "powershel powershell-2 0 webclient-download powershell-3 0",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP for NP"
    },
    {
      "id": "au_1377630",
      "task": "How do i revert adding a permenant boot arg from initramfs?",
      "P-task": "revert ad permen boot arg initramf",
      "F_verb": "revert",
      "P-body": "You can boot into recovery mode from the Grub menu and this will bypass the kernel arguments on \"GRUB_CMDLINE_LINUX_DEFAULT\". From recovery mode, you will be able to edit your \"/etc/default/grub\" file to remove the arguments. Also, don't forget to run \"sudo update-grub\" to apply the changes after you are finished editing the file. .  To explain: arguments listed after \"GRUB_CMDLINE_LINUX_DEFAULT\" are not passed on when using recovery mode. See here for more information. .  ",
      "P-tags": "kernel boot initramf grub2",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V S_ING from NP"
    },
    {
      "id": "so_12315670",
      "task": "What do I need to debug pthreads?",
      "P-task": "need debug pthread",
      "F_verb": "debug",
      "P-body": "This: .  means that the \"libthread_db.so.1\" library was not able to find the symbol \"ps_lgetfpregs\" in gdb.  .  Why? .  Because I built gdb using Crosstoolg-NG with the \"Build a static native gdb\" option and this adds the \"-static\" option to gcc. .  The native gdb is built with the \"-rdynamic\" option and this populates the .dynsym symbol table in the ELF file with all symbols, even unused ones. libread_db uses this symbol table to find \"ps_lgetfpregs\" from gdb. .  But \"-static\" strips the \".dynsym\" table from the ELF file. .  At this point there are two options: .   Don't build a static native gdb if you want to debug threads. Build a static gdb and a static libthread_db (not tested)  Edit: .  By the way, this does not explain why Breakpad in unable to debug multithreaded applications on my target. .  ",
      "P-tags": "cross-compil linux embed cross-platform pthread",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "au_548392",
      "task": "Trying to fix broken dependencies (Libre Office)",
      "P-task": "tri fix broken depend libr offic",
      "F_verb": "fix",
      "P-body": "I have answered this myself after doing some research and learning some new tricks. I am going to provide the answer in case someone runs into an issue related to these broken dependencies. I used synaptic package manager to remove broken packages. Here is how I did that .  First I Downloaded Synaptic Package Manager Synaptic Package Manager .  I then moved the downloaded .deb file to my home folder ( for easy terminal access) then proceeded to open terminal .  I had to install the package via dpkg because apt-get was not working due to broken dependencies .  once this was complete I opened up synaptic running the following in terminal .  Within the Synaptic Package Manager  .  click on the \"Status Tab\"  .  and then click on \"Broken\" and select the packages that are broken. and \"Mark for Complete Removal\" and continue to apply the changes.  .  I also made sure everything was completely removed by using the following in terminal .  and double checking the packages in synaptic package manager .  there was no left over libre office packages so I continued to install Libre Office through Ubuntu Software Center .  ",
      "P-tags": "depend apt libreoffic",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_29778873",
      "task": "Can't push git updates & run Unix commands when connecting via SSH",
      "P-task": "push git updat run unix command connect via ssh",
      "F_verb": "push",
      "P-body": "That page is incorrect. .  Those assignment lines are not valid in \"/etc/environment\". .  Variable expansion does not occur for lines in \"/etc/environment\". .  See this superuser question for some more discussion about this. .  ",
      "P-tags": "linux cento ssh java git",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_21275553",
      "task": "removing duplicates using awk in unix",
      "P-task": "remov duplic use awk unix",
      "F_verb": "remove",
      "P-body": "It looks as though the ID lines start with \">\". Given the order of the output, you want the first sequence associated with a given ID, not the last. This means you need something like: .  The first line decides whether the current ID is unique and sets \"printing\" to 1 if it is, and 0 otherwise. The second line notes whether printing is required, and prints appropriately. Note that if there's more than one line of data in the sequence, it is quite happy to print all those lines. It does not rely on there being just one line in the sequence data. .  ",
      "P-tags": "awk ubuntu unix",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP in NP"
    },
    {
      "id": "so_26062174",
      "task": "How to add a part of a line (for every line in a file) at the end of the line",
      "P-task": "add part line everi line file end line",
      "F_verb": "add",
      "P-body": "how about this awk one-liner: .  change into \"OFS=\", \"\" if you love that whithspace after the last comma. .  ",
      "P-tags": "awk grep linux bash sed",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP for NP in NP at NP of NP"
    },
    {
      "id": "so_34388173",
      "task": "split text file (Genome data) based on column values keeping header line",
      "P-task": "split text file genom data base column valu keep header line",
      "F_verb": "keep",
      "P-body": "Is this data for the human genome (i.e. always 46 chromosomes)? If so, how's this: .  (This is a second edit, based on @Sasha's comment above.) .  Note that the parens around \"(\"chr\"$2\".txt\")\" are apparently not needed on GNU awk, but they are on my OS X version of awk. .  ",
      "P-tags": "bioinformat linux unix",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_674561",
      "task": "How Ubuntu 15.04 amd64 Desktop install media (ISO file) is generated?",
      "P-task": "ubuntu 15 04 amd64 desktop instal media iso file gener",
      "F_verb": "install",
      "P-body": "Thank you for the suggestions guys but I think I've found the answer to my own question, also it was (at least partially) answered here: How do I create an EFI-bootable ISO of a customized version of Ubuntu? in great detail, with the exception of the isohybrid portion. .  In fact that guide produce a bootable ISO9660 (Rock Ridge) EFI/UEFI image but when I try to write the resulting image to a USB drive with the low level dd utility all I get is an unbootable drive (it works however when I burn it to a DVD) .  The trick here is to use the isohybrid utility to modify the image: \"isohybrid --uefi output.iso\", this will add a small FAT partition to the structure of the ISO image, making it capable of booting via USB on EFI/UEFI systems. .  ",
      "P-tags": "uefi boot iso usb",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_66280717",
      "task": "Removing specific words from a text string?",
      "P-task": "remov specif word text string",
      "F_verb": "remove",
      "P-body": "You have to use -replace : .  Or like this : .  But if you need to use Regex because the string's words can vary then you have to rethink the problem. .  You won't be looking to erase a part of the string but to extract something out of it. .  In you case, I think that you're looking for a username using a name.lastname format which is pretty easy to capture : .  Using -match will return True / False. .  If it does return True, an array named $Matches will be created. It will contains on index 0 ($Matches[0]) the whole string that matched the regex. .  Every others index greater than 0 will contains the captured text from the regex parenthesis called \"capture group\". .  I would highly recommend using an if statement because if your regex return false, the array $Matches won't exist : .  ",
      "P-tags": "powershel script regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_29812323",
      "task": "bash - execute curl and export base64 file to variable",
      "P-task": "bash - execut curl export base64 file variabl",
      "F_verb": "execute",
      "P-body": "You can use process substitution: .  Or, as Etan Reisner points out in a comment, a pipeline will work as well: .  While a process substitution results in a filename getting passed to \"base64\" (either the name of a FIFO or a named file descriptor such as \"/dev/fd/63\", depending on platform), the pipeline passes its data to \"base64\" via stdin - the net effect is the same here. .  The advantage of using a pipeline is that is POSIX-compliant, whereas process substitution is a \"bash\"-specific feature. .  ",
      "P-tags": "base64 curl bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP to NP"
    },
    {
      "id": "au_81483",
      "task": "Charm parameters configured at deployment",
      "P-task": "charm paramet configur deploy",
      "F_verb": "configure",
      "P-body": "Bruno, there is actually an open feature request right now for this capability: .  https://bugs.launchpad.net/juju/+bug/893184 .  You can create a yaml file right now that will set those options, this page explains it: .  https://jujucharms.com/docs/stable/charms-config#configuring-an-application-at-deployment .  Basically to do what your example talks about, save this as local.yaml: .  And then do .  \"juju deploy charm-name service-name --config local.yaml\" .  You can also set the options immediately after the deploy (before the unit is even running) with .  \"juju set service-name key=value key2=value2\" .  ",
      "P-tags": "juju",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V at NP"
    },
    {
      "id": "so_37441091",
      "task": "On powershell, i have a code that sends IP details in an email but when the resulting email is received it comes out like @{IPV4Address=10.240.47.197}",
      "P-task": "powershel code send ip detail email result email receiv come like ipv4address 10 240 47 197",
      "F_verb": "send",
      "P-body": "You need to call the \"IPV4Address\" property, so \"$ipaddress.IPV4Address\", or something. Something like: .  ",
      "P-tags": "powershel powershell-3 0",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP in NP when S"
    },
    {
      "id": "su_626189",
      "task": "Is there a way to open all files that match a certain directory structure on windows DOS / Powershell",
      "P-task": "way open file match certain directori structur window do powershel",
      "F_verb": "open",
      "P-body": "Use this powershell script: .  It will open all \"web.config\" files in all the folders of \"C:/Websites\" with notepad++. .  You could also use AppCmd.exe to get the websites. This will only get websites instead of all folders.  .  ",
      "P-tags": "powershel ms-do window",
      "source": "qa",
      "cate": "open",
      "pat": "V NP that S"
    },
    {
      "id": "au_135231",
      "task": "Use a Clementine smart playlist to show duplicate songs",
      "P-task": "use clementin smart playlist show duplic song",
      "F_verb": "use",
      "P-body": "Try installing FSLint! .  To install from terminal Hit Alt+Ctrl+T and run the following command: .  \"sudo apt-get install fslint\" .  To install from Software Center, Search for 'fslint'. .  It can easily find duplicate files and then gives you an option to delete, Move etc. Give it the path to your iTunes folder, and click find. .   .  ",
      "P-tags": "clementin 12 04 duplicate-fil file delet",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_18038",
      "task": "How to list files and folders that are not maintained by any DEB package",
      "P-task": "list file folder maintain deb packag",
      "F_verb": "list",
      "P-body": "\"cruft\" is a useful tool exactly for this purpose: it makes a comparison between a file system and the database of installed Debian packages. In addition to listing unknown files it also lists files which are missing but should be there. .  I use it routinely together with \"debsums\" when I need to start system administration or upgrade work on machine which I did not take care of earlier. This allows me to spot any local modifications and installations and plan for them, instead of the customer telling me after an upgrade that their software does not work any more. .  Install: .  List all \"cruft\" but ignore the named directories: .  More information: .  ",
      "P-tags": "apt aptitud debian backup",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP that S"
    },
    {
      "id": "so_25689864",
      "task": "How do I pass a powershell argument to a non powershell command?",
      "P-task": "pass powershel argument non powershel command",
      "F_verb": "pass",
      "P-body": " In v2: .  Or in v3 .  Or: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_16773186",
      "task": "SwiftMailer: can't open .tar.gz archives on Linux",
      "P-task": "swiftmail : open tar gz archiv linux",
      "F_verb": "open",
      "P-body": "Try: .  then: .  This was taken from: .  http://fosshelp.blogspot.com.au/2012/04/solution-tar-this-does-not-look-like.html .  ",
      "P-tags": "swiftmail linux gzip tar",
      "source": "qa",
      "cate": "open",
      "pat": "V NP on NP"
    },
    {
      "id": "so_50731177",
      "task": "How to get Get-ChildItem to handle path with non-breaking space",
      "P-task": "get get-childitem handl path non-break space",
      "F_verb": "get",
      "P-body": "It's still unclear why Sandra's code didn't work: PowerShell v2+ is capable of retrieving files with paths containing non-ASCII characters; perhaps a non-NTFS filesystem with different character encoding was involved?  .  However, the following workaround turned out to be effective: .   The idea is to replace the non-breaking space char. Unicode \"U+00A0\"; hex. \"0xa\") in the input file path with wildcard character \"?\", which represents any single char. .  For \"Get-ChildItem\" to perform wildcard matching, \"-Path\" rather than \"-LiteralPath\" must be used (note that \"-Path\" is actually the default if you pass a path argument positionally, as the first argument). .  Hypothetically, the wildcard-based paths could match multiple files; if that were the case, the individual matches would have to be examined to identify the specific match that has a non-breaking space in the position of the \"?\". .   ",
      "P-tags": "get-childitem unicod character-encod powershel filesystem",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF with NP"
    },
    {
      "id": "au_357010",
      "task": "How to open external drive from remote location?",
      "P-task": "open extern drive remot locat",
      "F_verb": "open",
      "P-body": "By adding a line in /etc/fstab you can ask the system to automatically mount your drive on boot. Then it will always be available. But if you do not want the drive to always be mounted, then you'd have to do it manually (as suggested by Radu) .  To know what to enter in /etc/fstab, you can play with the manual command. That will tell you all the parameters you need. .  It could also be that a line with /media/mydisk already exists in your fstab file. .  PS. you can find more info about mount and fstab in the manual pages: .  ",
      "P-tags": "server",
      "source": "qa",
      "cate": "open",
      "pat": "V NP from NP"
    },
    {
      "id": "au_1164664",
      "task": "Removing certain file types that do not contain the hostname in the file name",
      "P-task": "remov certain file type contain hostnam file name",
      "F_verb": "remove",
      "P-body": "Your command does not work as expected because of \"rm *PC-*-*.json\"! it would expands by shell and includes all \"PC-x-x.json\" files. .  Actually you're using \"xargs\" in a wrong way. .   Something like this should do the job: .  change \"echo\" with \"rm\" when you where sure that it works. .  A better solution would be using \"find\": .   remove \"-i\" from \"rm\" after you were sure that command is working correctly.  ",
      "P-tags": "xarg hostnam bash uninstal file",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP that S"
    },
    {
      "id": "ul_636471",
      "task": "How to use json variable in shell script file?",
      "P-task": "use json variabl shell script file",
      "F_verb": "use",
      "P-body": "Take a look at the \"jq\" command it is a command line json parser. You can pull any field you would like. .  https://www.systutorials.com/docs/linux/man/1-jq/ .  For example this will return the java_version number. .  If you prefer using core commands so you don't have to install anything you can use this command. .  Shorter version of the above command before someone says you don't have to cat into grep. .  EDIT: Another option would be. .  ",
      "P-tags": "json packer shell-script bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_48993910",
      "task": "using bash script, get the list of dates from filenames in folder, list dates, list suffixes",
      "P-task": "use bash script get list date filenam folder list date list suffix",
      "F_verb": "get",
      "P-body": "If your files names are guaranteed to NOT contains space/newline: .  ",
      "P-tags": "sed linux filenam sort",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP in NP"
    },
    {
      "id": "so_42531043",
      "task": "awk find the common rows to two files and combine the rows to a row in a third file",
      "P-task": "awk find common row two file combin row row third file",
      "F_verb": "combine",
      "P-body": "You can use this awk command to achieve your output: .  ",
      "P-tags": "awk shell bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "su_257255",
      "task": "Why doesn't the shebang cause a program to fork like it should?",
      "P-task": "shebang caus program fork like",
      "F_verb": "cause",
      "P-body": "The shebang never causes a process to fork.\u00a0 It doesn't do anything UNLESS the script is executable and it is invoked in such a away that it causes the system to evaluate the shebang to see what program/shell to execute the script with. .  If, for instance, you were already running in bash, and you executed the script with the \"source\" command, then the script would be executed inside the shell you were currently running, and the \"exit\" would affect that shell process, rather than it being a new shell process which got ended. .  If you have a script file that you want to run, you should make it executable with the following command: .  Then, if you want to run the script, and if we assume that the script file is in the current directory, you use the following command: .  Note that this is very different from \". script\", which is just shorthand notation for \"source script\". .  The \"./script\" is a relative pathname to the script file, which means search in the current directory to find the script file 'script' and then execute it \u2014 which works only if the script file is executable. .  If you have script file that is NOT executable, then you can invoke it with: .  But in this case you are specifying which shell to run and the shebang line is ignored. .  ",
      "P-tags": "shell-script unix bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_44035950",
      "task": "Restart Windows service from Git Bash (MINGW64)",
      "P-task": "restart window servic git bash mingw64",
      "F_verb": "restart",
      "P-body": "A Windows bash script should still be able to call Windows exe programs. .  So try and call \"/C/Windows/System32/sc.exe\" (the \"sc\" command). That will allow you to stop/start services. .  ",
      "P-tags": "mingw git-bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP from NP"
    },
    {
      "id": "so_67397027",
      "task": "Can value of a file descriptor go beyond max opened file descriptor softlimit?",
      "P-task": "valu file descriptor go beyond max open file descriptor softlimit",
      "F_verb": "go",
      "P-body": "Yes, it can. The soft limit is something you can change with a call to \"ulimit(2)\" system call.... so you can put it under the number of actually open files and that mean that \"open(2)\" will fail on the next open, but it doesn't affect the actual number of open files you have open now. anyway... let's imagine this scenario: .   you open 97 files (plus stdin, stdout and stderr, this makes 100 open descriptors from 0 to 99) you close descriptors 0 to 49 (You have still open 50 to 99). beware that this example will not allow you to print anything, as you have closed stdin, stdout & stderr) you reduce the soft limit to 75.  you can still open 25 files more (you have 50 open files now)... and the'll go in the range 0 to 24, but the others continue to be open from 50 to 99. And you cannot open more files, because you run out the limit of open files. .  By the way, the descriptor you get from the system from an open system call is always the minimum value available number to get... so, if you avoid touching the ulimits maximum number of open files, then you can do what you want. .  ",
      "P-tags": "linux c file-descriptor",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V beyond NP"
    },
    {
      "id": "so_49568948",
      "task": "Docker - memory issue - how to set it to higher value?",
      "P-task": "docker - memori issu - set higher valu",
      "F_verb": "set",
      "P-body": "Seeing the \"1.952GiB\" limit in the docker stats output, I can guess that the problem is the default configuration that the docker machine has: it is assigned with 2GB of memory by default. .  As per in my other answer here, you can see how to configure docker to allow more memory for containers. .  ",
      "P-tags": "memori host ubuntu docker",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_615689",
      "task": "mount and fstab: why can they be configured to allow users to mount but not umount?",
      "P-task": "mount fstab : configur allow user mount umount",
      "F_verb": "configure",
      "P-body": "The reason behind this, as with many Unix/Linux peculiarities, is of course historical. Unix, which itself evolved out of Unics (a pun on its predecessor Multics) was designed as a true multi user system. Users can log in either locally or remotely through \"getty\" and \"login\", get a shell and and run their programs. .  These days, the TTYs are virtual and \"login\" has been replaced by GDM/KDM, but utilities such as \"mount\", \"df\", \"ls\", \"ps\" (which belong to the oldest Unix commands) still remain largely unchanged in purpose, although they have acquired many additional features over the year. .  The commands \"mount\" and \"umount\" were originally only meant to be run by the system administrator, or \"root\". As Unix evolved and spread to personal computers both \"mount\" and \"umount\" became SUID programs to enable regular users to mount and unmount filesystems, but only under strict conditions. From \"man mount\": .   Normally, only the superuser can mount filesystems. [...] Note that mount is very strict about non-root users and all paths specified on command line are verified before fstab is parsed or a helper program is executed. [...] It drops suid permissions and continue as regular non-root user. [...] Only the user that mounted a filesystem can unmount it again. If any user should be able to unmount it, then use users instead of user in the fstab line. .   Hence, both \"mount\" and \"umount\" are SUID programs that look for the \"user\" option or \"users\" option in \"/etc/fstab\", then drop their root privileges and finally make the \"mount()\"/\"umount()\" system call. .  ",
      "P-tags": "mount non-root-us fstab",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V S_INF NP S_INF"
    },
    {
      "id": "ul_174699",
      "task": "How to copy a file with scp via another server",
      "P-task": "copi file scp via anoth server",
      "F_verb": "copy",
      "P-body": "L is not able to connect to B, but is B able to connect to L? You didn't say, but I will assume no. .  If A is your only way to communicate between B and L then you will definitely have to log in to A at some point. And also, the data will flow through A one way or another (which might be important if A is on a slow connection). .  You can establish an SSH tunnel through A in a couple of different ways to get from L to B. For example: .  Now add the following configuration in \"~/.ssh/config\" on L as a convenience for connecting to B through the tunnel: .  Then you can connect to B through the tunnel: .  There are other options for setting up this tunnel, including tools to automatically establish the tunnel in the background. .  ",
      "P-tags": "linux scp",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP with NP via NP"
    },
    {
      "id": "so_53865597",
      "task": "Can't connect to Daemon Deluge on CentOS 6.10",
      "P-task": "connect daemon delug cento 6 10",
      "F_verb": "connect",
      "P-body": "The solution was to use an older version of Deluge. The last version supported by CentOS 6.10 is \"deluge-1.3.10-1\". .  Here is the updated install script of Deluge : .  ",
      "P-tags": "cento daemon delug shell",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP on NP"
    },
    {
      "id": "so_65560450",
      "task": "Apache is not starting after I deleted ssl certificate from certbot",
      "P-task": "apach start delet ssl certif certbot",
      "F_verb": "start",
      "P-body": "You'll need to edit the etc/apache2/sites-enabled/000-default-le-ssl.conf file to change the file being referenced, as you have deleted that file. You can create a new certificate to reference using certbot instructions, or delete 000-default-le-ssl.conf altogether if you are no longer using SSL. .  To edit the file, navigate to the directory in SSH using .  and then edit the file as root using .  ctrl+ x will exit and give option to save when done. You may want to restart apache2 after: .  ",
      "P-tags": "ubuntu-18 04 lets-encrypt ssl ssl-certif apach",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V after S"
    },
    {
      "id": "su_1068279",
      "task": "Copy Multiple Files w/ Same Extension but Add Date",
      "P-task": "copi multipl file w extens add date",
      "F_verb": "add",
      "P-body": "Create a function with a loop in your ~/.bashrc file: .  If everything looks fine remove \"echo\". .  Syntax: \"mybackup\" .  ",
      "P-tags": "linux command-lin bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_435743",
      "task": "Can you enumerate all the ways to start an interactive shell?",
      "P-task": "enumer way start interact shell",
      "F_verb": "enumerate",
      "P-body": "\u201cunless \"-s\" is specified\u201d qualifies \u201cwithout non-option arguments\u201d. The synopsis for \"bash\" is .  Non-option arguments are \"command_string\" or \"file\". If you specify either of these, the resulting shell isn\u2019t interactive, unless you specify \"-s\", without specifying \"-c\". \"-s\" causes the arguments to be assigned to the positional parameters instead of being interpreted: .  opens an interactive shell, and .  outputs .  So you can open an interactive Bash shell using either of the following: .   ensure the standard input and output are connected to a terminal and specify no non-option arguments; ensure the standard input and output are connected to a terminal and specify \"-s\" with any arguments apart from \"-c\"; specify \"-i\".  If you specify both \"-c\" and \"-s\", \"-c\" takes precedence (it\u2019s processed earlier). The resulting shell is non-interactive and processes the given command. .  ",
      "P-tags": "interact bash",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_49049787",
      "task": "\"tls: oversized record received with length 20527\" trying to \"docker run\" from Win10 WSL Bash only",
      "P-task": "tl : overs record receiv length 20527 tri docker run win10 wsl bash",
      "F_verb": "receive",
      "P-body": "Solution As this freaked me out a bit, I made another Google session and found the solution down in the comments of this side: * https://nickjanetakis.com/blog/setting-up-docker-for-windows-and-wsl-to-work-flawlessly .  In a nutshell: * The issue I've described comes from an default but outdated \"docker.io\" installation, instead of the latest and maintained \"docker-ce\" installation.  .  Once I've removed the old one with (the trailing \"*\" is intended!): .  and installed the latest \"docker-ce\" one -- according to the procedure described on the page above -- the TLS issue was gone! .  Happy docking. .  ",
      "P-tags": "tls1 2 docker-for-window docker windows-subsystem-for-linux window",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V with NP from NP"
    },
    {
      "id": "so_45722692",
      "task": "Removing Attributes with Ansible",
      "P-task": "remov attribut ansibl",
      "F_verb": "remove",
      "P-body": "You can set \"attr\" to a blank string or whatever the default is on your system. For Ubuntu that is 'e'. .  ",
      "P-tags": "linux ansibl",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "so_65150445",
      "task": "Execute Long Multi Bash Commands in Laravel Scheduler",
      "P-task": "execut long multi bash command laravel schedul",
      "F_verb": "execute",
      "P-body": "You're wrapping your command in backticks, which will both interpolate variables and execute the value as a command. You want neither of these things. .  Use single quotes to build the command, and then pass it to \"exec()\". .  For a somewhat more efficient approach, you might try just editing the history file directly. .  There's no need to erase the last entry in the file, as it's a history of interactive shell commands. .  Obviously the best thing to do would be not putting \"sensitive\" things in the command line. For MySQL, this can be done by adding credentials to the \".my.cnf\" file. .  ",
      "P-tags": "laravel laravel-schedul php bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_50144269",
      "task": "Invoking program compiled using linux subsytem through python on windows",
      "P-task": "invok program compil use linux subsytem python window",
      "F_verb": "invoke",
      "P-body": "\"subprocess\" uses \"CreateProcess\" to run programs on Windows. If you use \"shell=True\" it adds \"cmd.exe\" to the front of your command so that it is run through Windows command interpreter instead of direct execution. You can play the same game with the Windows Subsystem for Linux. It uses \"wsl.exe\" much like \"cmd.exe\". So, with \"shell=False\" (the default) you can .  or .  ",
      "P-tags": "subprocess python windows-subsystem-for-linux",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP using NP through NP on NP"
    },
    {
      "id": "so_64092031",
      "task": "Powershell 5.1: unable to sort extracted XML attribute names with Get-Unique",
      "P-task": "powershel 5 1 : unabl sort extract xml attribut name get-uniqu",
      "F_verb": "sort",
      "P-body": "It's pretty simple, just change .  to .  Output: .  ",
      "P-tags": "xml powershell-5 0",
      "source": "qa",
      "cate": "sort",
      "pat": "V NP with NP"
    },
    {
      "id": "su_1162920",
      "task": "Why do source code uninstaller scripts \u201ccd\u201d into the directory before deleting a file?",
      "P-task": "sourc code uninstal script cd directori delet file",
      "F_verb": "delete",
      "P-body": "I can only think that this because of a mistake that was once made in the past. .  Basically someone accidentally inserted an extra space into a file path, and deleted it; see this commit on GitHub for example. .  By doing \"cd '/usr/local/share/man/man8' && rm -f mtr.8\" - if the first part of the command, the \"cd\" fails, it will never run the \"rm -f\" at all. It\u2019s a fail safe. .  ",
      "P-tags": "uninstal linux command-lin",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_37547772",
      "task": "sql statement in a bash script \"command not found\"",
      "P-task": "sql statement bash script command found",
      "F_verb": "find",
      "P-body": "Answered by a nice person on IRC; have to escape the ` .  ",
      "P-tags": "mysql bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_55070274",
      "task": "Get list of actual Azure Function endpoints from Powershell",
      "P-task": "get list actual azur function endpoint powershel",
      "F_verb": "get",
      "P-body": "I got it. In the data for the function itself, the route is part of the properties.config object.  .  Request should look like this: \"https://management.azure.com/subscriptions/{subscriptionid}/resourceGroups/{resourceGroupName}/providers/Microsoft.Web/sites/{functionAppName}/functions/{functionName}?api-version=2016-08-01\" .  In the return value is a \"properties\" object, and within that is \"config\" object. Underneath that is the \"route\" property which contains the trigger endpoint. .  In Powershell, it's this: .  You can test it here: https://docs.microsoft.com/en-us/rest/api/appservice/webapps/getfunction .  Hope this helps someone else! Thanks to those who contributed. .  ",
      "P-tags": "azur powershel azure-funct azure-management-api",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_65431265",
      "task": "Powershell: How to properly count number of items in array of objects when there is only one object left in array",
      "P-task": "powershel : properli count number item array object one object left array",
      "F_verb": "count",
      "P-body": "The most PowerShell-idiomatic solution is to use \"@()\", the array-subexpression operator, which ensures that a command's output is treated as an array even if only one object is returned: .  To get the count directly: \"@($myArrayOfObjects | ...).Count\" .  You can also use an \"[array]\" type constraint - in essence, a cast placed to the left of the target variable - which doesn't require modification of the RHS: .  ",
      "P-tags": "array powershel psobject",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP of NP in NP of NP when S"
    },
    {
      "id": "so_10910927",
      "task": "How to get whether OS is 32 bit or 64 bit by UNIX command?",
      "P-task": "get whether os 32 bit 64 bit unix command",
      "F_verb": "get",
      "P-body": "In linux, the answer to such a generic question is just using .  or even: .  In C you can use the uname(2) system call. .  In windows you can use: .  or even examine the environment: .  (or with getenv() in C) .  ",
      "P-tags": "bit operating-system unix command",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V whether S"
    },
    {
      "id": "so_50069951",
      "task": "Remove first 3 characters and last 1 character from all mp3 files in all subdirectory",
      "P-task": "remov first 3 charact last 1 charact mp3 file subdirectori",
      "F_verb": "remove",
      "P-body": "You may use this while loop: .  Once you're satisfied with the results, remove \"echo\" before \"mv\" command. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_251116",
      "task": "Why can't I install these packages?",
      "P-task": "instal packag",
      "F_verb": "install",
      "P-body": "The output you provided on \"apt-cache policy\" confirms my suspicion about outdated lists. .  For the example of \"krb5-multidev\" in 12.04 you should see version \"1.10+dfsg~beta1-2ubuntu0.3\" as a candidate provided through \"precise-updates\". .  So, as I already suggested in the comments, run .  And you should be all set (retry the installation and also properly update your system!). .  ",
      "P-tags": "12 04 apt package-manag",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_1130307",
      "task": "How to update 7-Zip on Ubuntu",
      "P-task": "updat 7-zip ubuntu",
      "F_verb": "update",
      "P-body": "If you check on https://sourceforge.net/projects/p7zip/files/p7zip/, you can see the latest version available is \"16.02\", this also true per Disco (19.04) releases. .  The 'newest' version however, only available in Windows machine. .   .  So it appear the developer of 7-Zip hasn't released latest version for Ubuntu yet, and considering it's been 3 years already, I don't think that will the case. .  ",
      "P-tags": "7zip",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "so_36425683",
      "task": "How to read a file in shell script",
      "P-task": "read file shell script",
      "F_verb": "read",
      "P-body": "perhaps you want to write it this way .  \"-q\" option is to suppress the output when the keyword is found. .  ",
      "P-tags": "grep linux readfil shell bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "so_57345234",
      "task": "Bash - How to get the value of a var with name from another var",
      "P-task": "bash - get valu var name anoth var",
      "F_verb": "get",
      "P-body": " Output: .   See: What is indirect expansion? What does ${!var*} mean? .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP with NP from NP"
    },
    {
      "id": "so_11473968",
      "task": "How to execute an action based on registry values?",
      "P-task": "execut action base registri valu",
      "F_verb": "execute",
      "P-body": " ",
      "P-tags": "powershel powershell-2 0 registri",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_19674137",
      "task": "shell: any way to use `uniq -c` taking into account a prior `uniq -c`?",
      "P-task": "shell : way use uniq -c take account prior uniq -c",
      "F_verb": "use",
      "P-body": "I don't know of a way to get \"uniq\" to do the job, but it's pretty trivial with awk: .  ",
      "P-tags": "uniq shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP into NP"
    },
    {
      "id": "su_1458600",
      "task": "How to connect ftp to local ipv6 address",
      "P-task": "connect ftp local ipv6 address",
      "F_verb": "connect",
      "P-body": "Link-local addresses in many operating systems require the interface to be explicitly specified, e.g. \"fe80::1:1:ff:f%eth0\" on Linux. This is because all links share the same fe80::/64 prefix. .  (Windows is an exception because it supports discovering the correct interface through NDP probing.) .  Note that if you use FTP passive mode, it's still possible that you won't be able to establish data connections, because the client might not know that it needs to remember interface used for the control connection and copy it to all addresses used for data connections. .  ",
      "P-tags": "linux metasploit ftp",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP"
    },
    {
      "id": "so_27057967",
      "task": "Parse string using delimiter and pick up elements from 2nd index till the last in Shell / Bash",
      "P-task": "pars string use delimit pick element 2nd index till last shell bash",
      "F_verb": "pick",
      "P-body": "You can do this with pure Bash: .  ",
      "P-tags": "array shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V up NP from NP"
    },
    {
      "id": "so_7318497",
      "task": "Omitting the first line from any Linux command output",
      "P-task": "omit first line linux command output",
      "F_verb": "omit",
      "P-body": "Pipe it to \"awk\": .  or \"sed\" .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_38264283",
      "task": "How to generate a list of directories that has names starting with \"A\" and ending with \"O\"?",
      "P-task": "gener list directori name start end",
      "F_verb": "generate",
      "P-body": "The answer is .  The \"-type d\" option tells \"find\" to only output directory names, and the \"-name \"A*O\"\" option further restricts those names to those matching the pattern \"A*O\" (i.e. starting with \"A\" and ending with \"O\"). It does this in the current directory (\".\") and will recursively enter any directory therein and performs the same task. .  ",
      "P-tags": "find unix",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP that S"
    },
    {
      "id": "ul_524254",
      "task": "Why are backslashes included in this shell script?",
      "P-task": "backslash includ shell script",
      "F_verb": "include",
      "P-body": "Backslash will suppress alias expansion, ie it executes the original command and makes sure that alias version does not run. Scripts can unknowingly run with alias expansion when the system has set \"shopt -s expand_aliases\" (BASH only) or if it is executed using \"source\". .  Some sysadmins like to put backslash in everything as a preventive measure against side-effects of aliases, just in case it was aliased unintentionally somewhere else and the alias gets expanded as explained previously. For example, if the system has set this \"alias dirname='dirname -z'\" somewhere and the condition allows the alias to be expanded, then a script that tries to call dirname will unfortunately call \"dirname -z\" instead, which was not the script intended. .  If there's certainty that such alias do not exist, we can remove all the backslash and it should work fine.  .  Alternatively, one can use \"command\" instead of backslash version to suppress alias. Thus, instead of \"\\dirname\", one can use \"command dirname\", which might look more readable. For built-in commands like \"cd\", one should use \"builtin\" instead). I prefer this instead, as it also bypasses function with same name as well as any aliases. .  ",
      "P-tags": "shell-script bash",
      "source": "qa",
      "cate": "import/include",
      "pat": "V in NP"
    },
    {
      "id": "so_65230768",
      "task": "what does \"echo $line\" mean in bash\uff1f",
      "P-task": "echo line mean bash",
      "F_verb": "echo",
      "P-body": "\"$line\" is a shell variable. You get nothing because in you shell \"$line\" is undefined. But if you will execute echo in environment where \"$line\" is defined, you will see value of \"$line\". For example, you can run those commands: .  In first line you defined variable line. In second line you \"echo\"ed it. You can learn more about it here .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "so_30606655",
      "task": "Set up TightVNC programmatically with BASH",
      "P-task": "set tightvnc programmat bash",
      "F_verb": "set",
      "P-body": " Modify to taste, if your packaging for tightvnc uses a location other than \"~/.vnc/\" for the \"passwd\" file. .   If you have separate view-only and full-control passwords, then: .  If you needed compatibility with \"/bin/sh\" (or otherwise weren't using \"#!/bin/bash\" shebangs), this would instead be: .  ",
      "P-tags": "vnc-server debian bash tightvnc expect",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP with NP"
    },
    {
      "id": "so_30806523",
      "task": "pull the table mapping in a GoldenGate replicat program",
      "P-task": "pull tabl map goldeng replicat program",
      "F_verb": "pull",
      "P-body": "Simply read your input file, ignore lines beginning with \"--\", split and re-join the remaining lines, and write the result back to a file: .  The condition \"$_ -notmatch '^\\s*$'\" is just for skipping over blank lines. If you don't have blank lines in your input file you can remove it. .  Edit: On second thought you could also replace the delimiters instead of splitting and re-joining the lines: .  ",
      "P-tags": "powershel regex",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "su_570443",
      "task": "Update manager is not working on Efika MX (Ubuntu Maverick)",
      "P-task": "updat manag work efika mx ubuntu maverick",
      "F_verb": "update",
      "P-body": "The answer was at powerdeveloper.org (as pointed out by the official Genesi support): .  ",
      "P-tags": "updat ubuntu maverick",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP S_ING on NP"
    },
    {
      "id": "so_22362829",
      "task": "How to grep out the variables in a file?",
      "P-task": "grep variabl file",
      "F_verb": "grep",
      "P-body": "With Vixie cron, a crontab line is: .   a comment if the first non-blank character is # .  an environment setting if the first non-blank character is a letter or _ .  a cron command if the first non-blank character is a digit, * or @ .  a blank line if there is no non-blank character .  otherwise, an error. .   So to grep for case 3 (cron command): .  Alternatively, to remove case 2 (environment setting) but leave everything else, including comments and errors: .  ",
      "P-tags": "grep shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V out NP in NP"
    },
    {
      "id": "ul_651044",
      "task": "tty says \"-bash: flatpak: command not found\" even through I don't have flatpak installed. It was uninstalled properly",
      "P-task": "tti say -bash : flatpak : command found even flatpak instal\nuninstal properli",
      "F_verb": "find",
      "P-body": "\"Flatpack\" install some commands in the shell profile. If you remove: .  You should be ok. .  Also note that to remove a package \"apt-get remove ...\" does not remove the configuration for a package, while \"apt-get purge ...\" removes both the package and the configuration (in this case \"purge\" should have removed that file). .  ",
      "P-tags": "flatpak tti linux debian",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "ul_170829",
      "task": "How to catch mount events on Linux?",
      "P-task": "catch mount event linux",
      "F_verb": "catch",
      "P-body": "If polling is okay you could look at the time on \"mtab\": .  You could also use \"filecmp\" or \"difflib\" to see if there are any changes, and parse what kind of changes occurred if you go with this route. .  ",
      "P-tags": "mount python event",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_581744",
      "task": "Insufficient space to create volume snapshot in CentOs",
      "P-task": "insuffici space creat volum snapshot cento",
      "F_verb": "create",
      "P-body": "You successfully extended the LVM volume group (i.e. the steps in your guide up to and including the \"vgextend\" command), but then you used up the new space by also extending the \"LVM-root\" logical volume, using up the new space. .  You should have stopped after the \"vgextend\" step, then you would have had free PEs in your volume group, usable for LVM-level snapshots. .  Unfortunately you cannot shrink an \"ext4\" filesystem on-line, and it's your root filesystem so you cannot just unmount it, so you would need to boot from some live Linux boot media, activate the volume group (\"vgchange -ay\") and then shrink the filesystem inside the LV with: .  Then (and only then) you can shrink the LV. If you specify the sizes in gigabytes, it will be safer to specify the new size of the LV as a bit bigger than what you shrunk the filesystem into, to avoid chopping off the tail end of the filesystem because of a rounding error. .  (At this point, you can boot back into the CentOS proper, if you wish.) .  To shrink the LV to 30G: .  To match the size of the filesystem exactly to the new size of the LV: .  (If this command extends the filesystem just a little bit, you know you did the shrinking step correctly.) .  After this, you should have about 38G available in the VG for any combination of snapshots, LV extensions and/or new LVs. .  ",
      "P-tags": "cento lvm",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_24629113",
      "task": "How do I recover the address server of user, put it in variable and execute it in command line",
      "P-task": "recov address server user put variabl execut command line",
      "F_verb": "execute",
      "P-body": "With HTML forms you can just ignore the server and go straight to the script. .  For example like  .  ",
      "P-tags": "linux python",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "au_49196",
      "task": "How do I create a self-signed SSL certificate?",
      "P-task": "creat self-sign ssl certif",
      "F_verb": "create",
      "P-body": "Ubuntu, even the 'minimal' flavour, comes with the \"ssl-cert\" package pre-installed, which means you don't need to do anything. .  The files you're looking for are already on your system: .   Advanced: .  If for some reason you need to create a fresh certificate, you can run .  If you want to change the expiration date of you certificate, you can manipulate the make-ssl-cert script at \"/usr/sbin/make-ssl-cert\". Around like 124 there's a line similar to this: .  Where you can change the expiration date by adding the \"-days\" argument: .  More options can be found in the manual page of \"req\". .  ",
      "P-tags": "server ssl",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_63908132",
      "task": "Find and Replace String in a text file using Power Shell",
      "P-task": "find replac string text file use power shell",
      "F_verb": "find",
      "P-body": "There are special characters in regex that need to be escaped, specifically the backslash. To escape them you use a backslash - it would look like this .  However, to avoid manually escaping, you can simply use the regex escape() method. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "au_278912",
      "task": "Mount an ISO image in Wine?",
      "P-task": "mount iso imag wine",
      "F_verb": "mount",
      "P-body": "CDemu We sucessfully mounted CD or DVD images for application installation in Wine or for running an application which needs access to its CD using CDemu. Amongst ISO a wide variety of other formats are supported. Therefore the image does not need to be in ISO format. .  The application can be installed by adding the following ppa to our sources: .   ppa:cdemu/ppa  We can then install the CDemu client and the CDemu daemon with .  After logging out and back in, or a reboot, the daemon will be started. To mount an ISO file as CD we can then issue: .  The \"<number>\" corresponds to the internal number of drives loaded by CDemu (per default 2 drives, change this in \"/etc/default/cdemu-daemon\" to a higher number if needed. .  The following is an example command to load a drive \"0\" from an \"image.iso\": .  This will unload an image: .  Related questions: .   How do I use cdemu with Unity? Apps capable of mounting/unmounting CD/DVD Images with multi-sector or protected format How can I graphically mount ISOs?  ",
      "P-tags": "mount iso wine",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "so_13791626",
      "task": "Replace an output result",
      "P-task": "replac output result",
      "F_verb": "replace",
      "P-body": "Try .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "ul_153102",
      "task": "How to start XTerm with prompt at the bottom?",
      "P-task": "start xterm prompt bottom",
      "F_verb": "start",
      "P-body": "If using \"bash\", the following should do the trick: .  Or (less efficient as it runs one \"tput\" command before each prompt, but works after the terminal window has been resized): .  To prevent \"tput\" from changing the exit code, you can explicitly save and reset it: .  Note that the variable \"retval\" is local; it doesn't affect any \"retval\" variable you might have defined otherwise in the shell. .  Since most terminals \"cup\" capability is the same \"\\e[y;xH\", you could also hardcode it: .  If you want it to be safe against later resetting of PS1, you can also utilize the \"PROMPT_COMMAND\" variable. If set, it is run as command before the prompt is output. So the effect can also be achieved by .  Of course, while resetting \"PS1\" won't affect this, some other software might also change \"PROMPT_COMMAND\". .  ",
      "P-tags": "termin xterm bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP with NP at NP"
    },
    {
      "id": "so_29370831",
      "task": "How to use linux device model and /sys filesystem?",
      "P-task": "use linux devic model sy filesystem",
      "F_verb": "use",
      "P-body": "Without context your statement about \"/dev\" is not clear. Anyway: .   You cannot create char devices on sysfs. The main purpose of sysfs is to export information and allow the user to adjust single values (just navigate under \"/sys/\" for some examples). Char devices usually does much complicated things. .  If you mean how you call your driver's open,read,write,ioctl, ... well, by doing open(2), read(2), write(2), ioctl(2) (look at man pages of these commands) .  when a device appear, the kernel create a directory under /sys. For example take a look at \"ls /sys/bus/usb/devices/\". All that directories are created when an USB device appear. You can try by plug/unplug USB devices. \"udev\" put an eye on sysfs to detect new devices and according to the information from sysfs it create the device under \"/dev\". This happens when the driver, somehow, calls \"device_add()\". Often this functions is invoked by other register functions like: \"device_create\", \"device_register\", or other from other sub-systems. .  the idea of sysfs is to provide information about the devices and drivers loaded. So you can change device, bus and driver options. Or manually attach a device to a module .  Actually, behind the sysfs attributes there is a set of file_operation, where open, read and write are managed by the kernel and not by your driver. In order to create a sysfs attribute you have to provide the pair of function show and store to read/write something from/to the driver. Then the kernel will route the requests to your correct attribute .   ",
      "P-tags": "linux-device-driv linux sysf",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_12388403",
      "task": "LInux Kernel API to find the vma corresponds to a virtual address",
      "P-task": "linux kernel api find vma correspond virtual address",
      "F_verb": "find",
      "P-body": "You're looking for \"find_vma\" in \"linux/mm.h\". .  This should do the trick: .  ",
      "P-tags": "linux linux-kernel memory-manag",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP to NP"
    },
    {
      "id": "su_1073189",
      "task": "Debian Scripting to remove the logging during apt-get install",
      "P-task": "debian script remov log apt-get instal",
      "F_verb": "remove",
      "P-body": "Redirect the \"stdout\" to \"/dev/null\" by appending \"> /dev/null\" to any command: .  To also redirect \"stderr\" to \"/dev/null\" append \"2>&1\": .  To upgrade or install packages without being prompted for \"[Y/n]\" add \"-y\": .  You could also send it to a log file: .  A single \">\" will overwrite the file, to log multiple commands use two \">>\", which will cause the output to be appended to the end of the file: .  ",
      "P-tags": "linux script debian instal",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP during NP"
    },
    {
      "id": "ul_123821",
      "task": "How to record the actual running time of a program with other programs running?",
      "P-task": "record actual run time program program run",
      "F_verb": "record",
      "P-body": "Call \"time myprogram\". .  This reports wall clock time, user time and system time. User time is the time spent by the process in computations. If the program is multithreaded and the machine has multiple processors, the time spent on all processors is summed (so for a sufficiently parallel program, the user time can be more than the wall clock time). The system time is time spent in the kernel, i.e. doing input/output. .  This is as close as you get to \u201ctime not counting interference by other running programs\u201d. The only way to know how much wall clock time the program would take if there were no concurrent programs is to run it without other concurrent programs. .  ",
      "P-tags": "perform time",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP of NP with NP S_ING"
    },
    {
      "id": "au_1288656",
      "task": "I hate the three horizontal bars on top. Any idea on how to reduce or merge them like ubuntu 16?",
      "P-task": "hate three horizont bar top\nidea reduc merg like ubuntu 16",
      "F_verb": "merge",
      "P-body": "There are several options. .  1) Use the Pixel saver extension. .  This extension will remove the legacy titlebar when an application is maximized. This will work nicely for Firefox, Libreoffice and any other application that uses legacy titlebars. .   .   Install the extension with the command \"sudo apt install gnome-shell-extension-pixel\". Enable the extension using Gnome Tweaks or Extensions. Both are not installed by default, but can be installed with the command 1 sudo apt install gnome-tweaks\"or\"sudo apt install gnome-shell-extension-prefs`.  2) Hide the top bar .  Hide the top bar. Then, only the chrome of your applications will be visible. .  Install the extension: \"sudo apt install gnome-shell-extension-autohidetopbar\". Enable the extension as outlined under 1). .  You can combine this with option 1) to further increase vertical screen real estate. .  3) Install Dash to Panel .  You currently have launchers on the bottom. The extension Dash to Panel will combine these launchers with the elements of the top bar (application menu, clock, status menu, ...) into one bottom bar. .  To install the extension, install \"gnome-shell-extension-dash-to-panel\" and enable it as described under 1). .  You can go a step further and combine this extension with the \"Pixel saver\" extension to remove the title bar at the top when the application is full screen. .  4) Only for Firefox: disable the titlebar .  This removes the titlebar in Firefox only. Head to the menu (\u2630) and select \"Customize\". In the left bottom corner, turn \"Title bar\" off. .  ",
      "P-tags": "20 04",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_56000934",
      "task": "How to integrate a bash command into a python code",
      "P-task": "integr bash command python code",
      "F_verb": "integrate",
      "P-body": "Assuming this is the code you are actually asking about: .  Of course, \"inRaster\" inside of singe quotes is just a literal string; to interpolate the variable's value you can say .  or .  or a number of other string interpolation techniques in Python (legacy \"%\" formatting, f-string, etc). But a better solution is to replace \"os.system\" with the more flexible and versatile \"subprocess\", as suggested even in the \"os.system\" documentation. .  \"subprocess.run\" was introduced in Python 3.5; if you need compatibility with older versions, try \"subprocess.check_call\" or even the crude \"subprocess.call\". .  ",
      "P-tags": "indic python bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_18239636",
      "task": "Add '\\n' after a specific number of delimiters",
      "P-task": "add n specif number delimit",
      "F_verb": "add",
      "P-body": "Using (GNU) \"sed\": .  \"[^;]*;\" matches a sequence of characters that are not semicolons followed by a semicolon. .  \"(...){4}\" matches 4 times the expression inside the parentheses. .  \"&\" in the replacement is the whole match that was found. .  \"\\n\" is a newline character. .  The modifier \"g\" make \"sed\" replace all matches in each input line instead of just the first match per line. .  ",
      "P-tags": "awk csv bash cut sed",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP after NP of NP"
    },
    {
      "id": "au_260239",
      "task": "I cannot make a Installation USB",
      "P-task": "make instal usb",
      "F_verb": "make",
      "P-body": "Try \"unetbootin\". .  Hope this will help you if I didn't misunderstand what you mean. .  ",
      "P-tags": "disk instal usb startup make",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "ul_210150",
      "task": "How to read *.journal files?",
      "P-task": "read journal file",
      "F_verb": "read",
      "P-body": "Borrowed from this answer:  .  journalctl --file, e. g. \"journalctl --file /path/to/some/file.journal\" .  As indicated in the other answer, these logs are regularly rotated, and may not stretch back as far as you might hope. .  ",
      "P-tags": "dmesg systemd-journald fedora",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_36747506",
      "task": "identifier \"creal\" is undefined - seen on Mac but not on Linux",
      "P-task": "identifi creal undefin - seen mac linux",
      "F_verb": "see",
      "P-body": "This is just Clang's read of the C++ standard - see that answer - which to me appears to be the correct one. Basically, you are not supposed to use the C99 complex type and the associated functions in C++ and should use \"std::complex<T>\" instead. Both complex types should be layout-compatible and you should be able to pass complex data between C and C++ code. .  \"g++\"'s \"complex.h\" includes both \"<ccomplex>\" (in C++11 mode) and the C \"<complex.h>\" and therefore the code compiles with GCC (from Homebrew in my case). I don't have the Intel compiler for OS X, but you could check what it does with \"icpc -E ttc-creal.cpp | grep complex\" and observe the sequence of include file expansions. .  Clang: .  GCC: .  You can force Clang to include \"<path to SDK>/usr/include/complex.h\" by e.g.: .  and your MCVE will compile, but doing so is probably a very Bad Idea (tm). .  By the way, the same behaviour is observed on FreeBSD 10.2-RELEASE with Clang 3.4.1 (error) and GCC 4.8.5 (success). .  All credit goes to Potatoswatter - the author of the the answer referenced at the top. .  ",
      "P-tags": "c++ linux maco complextyp",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V on NP"
    },
    {
      "id": "au_277288",
      "task": "dlclose does not call library destructors, dlopen called just once",
      "P-task": "dlclose call librari destructor dlopen call",
      "F_verb": "call",
      "P-body": "This works with glibc 2.17, gcc 4.8.0 or icc 13.1 or icc 12.1: .  \"icc -std=c99 -nostdlib -shared test.c -o /tmp/test\" .  against: .  Also tested with glibc 2.10, glibc 2.12. And all \"RTLD_*\" flags. .  Edit: Using an actual Ubuntu system (gcc (Ubuntu/Linaro 4.7.2-2ubuntu1) 4.7.2), GNU C Library (Ubuntu EGLIBC 2.15-0ubuntu20), I must say that above code works there too. So maybe after all it's not about the compiler and/or glibc. .  ",
      "P-tags": "ld 12 10 g++ glibc dynamic-link",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "so_50219595",
      "task": "How do I cancel cloning a Git repository from Git Bash?",
      "P-task": "cancel clone git repositori git bash",
      "F_verb": "cancel",
      "P-body": "Ctrl+C should send a SIGINT or similar (signal for graceful exit) to the git process; if this does not help you can issue a SIGQUIT with Ctrl+\\; last but not least you can always kill the process using the Windows Task Manager.  .  The directory you're cloning into may not be in a consistent state as a result of killing the git executable so you may wish to delete it before attempting to clone again, if git doesn't do so for you. When you try again, you can use the flag \"--depth=N\" to fetch only the last N commits. .  ",
      "P-tags": "git git-bash git-clon",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V S_ING from NP"
    },
    {
      "id": "au_25664",
      "task": "Which MPI package should I install?",
      "P-task": "mpi packag instal",
      "F_verb": "install",
      "P-body": "If it's just for simple usage on your own system, OpenMPI is very nice, as it doesn't require any setup after installation, just running your application with \"mpirun\" is sufficient. .  ",
      "P-tags": "package-manag kubuntu",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_69797054",
      "task": "Linux OpenSSH ignore certificate creation time on host",
      "P-task": "linux openssh ignor certif creation time host",
      "F_verb": "ignore",
      "P-body": "RTFM I guess, I read the sshd_config docs but not the \"ssh-keygen\" manpage, for the next guy check out the -V option. .   -V validity_interval - Specify a validity interval when signing a certificate. A validity interval may consist of a single time, indicating that the certificate is valid beginning now and expiring at that time, or may consist of two times separated by a colon to indicate an explicit time interval. .   Tested, working. .  ",
      "P-tags": "cryptographi linux embed ssh",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP on NP"
    },
    {
      "id": "so_46230485",
      "task": "Showing two or more different animation with SDL2-render in two different threads (no threads in the solution). C++",
      "P-task": "show two differ anim sdl2-render two differ thread thread solut\nc++",
      "F_verb": "render",
      "P-body": " ",
      "P-tags": "c++ linux anim multithread",
      "source": "qa",
      "cate": "draw/render/paint/redraw/plot",
      "pat": "V"
    },
    {
      "id": "su_338240",
      "task": "Recovering Ubuntu after filesystem was overwritten using dd",
      "P-task": "recov ubuntu filesystem overwritten use dd",
      "F_verb": "recover",
      "P-body": "I'm assuming this is dm-crypt/ LUKS. How late did you realize this mistake and terminate the \"dd\"? If you've overwritten the salt in the header, it's impossible to recover your data. Otherwise, there are some tools in the \"cryptsetup-luks\" package to perform surgeries by hand and recover data. For more, see the questions that follow \"What happens if I overwrite the start of a LUKS partition or damage the LUKS header or key-slots?\" in the official LUKS FAQ. .  ",
      "P-tags": "dd linux ubuntu lvm",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP after NP using NP"
    },
    {
      "id": "ul_601087",
      "task": "resolving a subdomain with dnscrypt-proxy returns an IP address but claims that the domain does not exist",
      "P-task": "resolv subdomain dnscrypt-proxi return ip address claim domain exist",
      "F_verb": "resolve",
      "P-body": "Granted, \"Domain exists: probably not, or blocked by the proxy\" is a little bit confusing. .  It actually means that a query for that name returned a response that doesn't include any name servers. .  A query for an actual domain (not host name) such as \"google.com\" would return a set of name servers instead: .  Some resolvers may always return the name servers, some may return minimal responses instead. So, this \"Domain exists:\" line properly returns the number of servers when the name is a domain, but is not reliable when it is a fully-qualified host name. .  ",
      "P-tags": "dnscrypt dn",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP with NP as NP that S"
    },
    {
      "id": "au_243044",
      "task": "Why isn't rc.local executed?",
      "P-task": "rc local execut",
      "F_verb": "execute",
      "P-body": "I finally got it working. Dunno if this is the best solution, but works for now. I moved the \"/etc/init.d/rc.local\" and the \"/etc/rc.local\" to a different location, and the I ran  .  Afterwards I moved the two scripts back into place and ran .  It now appears to be working correct. .  ",
      "P-tags": "boot script upstart",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_16076315",
      "task": "Appending multiple files into one file",
      "P-task": "append multipl file one file",
      "F_verb": "append",
      "P-body": "Original answer to original question Well, the easiest way is probably \"cp\": .  Failing that, you can use: .  Revised answer to revised question The original question had \"echo \"$AnotherFile\"\" as the third line; the revised question has \"sort $AnotherFile | uniq -c\" as the third line. .  Assuming that \"sort $AnotherFile\" is not sorting all the contents of the files mentioned in the list created from concatenating the original files (that is, assuming that \"file1\", \"file2\" and \"file3\" do not contain just lists of file names), then the objective is to sort and count the lines found in the source files. .  The whole job can be done in a single command line: .  Or (more usually): .  which lists the lines in increasing order of frequency. .  If you really do want to sort the contents of the files listed in \"file1\", \"file2\", \"file3\" but only list the contents of each file once, then: .  It looks weird having three sort-related commands in a row, but there is justification for each step. The \"sort -u\" ensures each file name is listed once. The \"xargs sort\" converts a list of file names on standard input into a list of file names on the \"sort\" command line. The output of this is the sorted data from each batch of files that \"xargs\" produces. If there are so few files that \"xargs\" doesn't need to run \"sort\" more than once, then the following plain \"sort\" is redundant. However, if \"xargs\" has to run \"sort\" more than once, then the final sort has to deal with the fact that the first lines from the second batch produced by \"xargs sort\" probably come before the last lines produced by the first batch produced by \"xargs sort\". .  This becomes a judgement call based on knowledge of the data in the original files. If the files are small enough that \"xargs\" won't need to run multiple \"sort\" commands, omit the final \"sort\". A heuristic would be \"if the sum of the sizes of the source files is smaller than the maximum command line argument list, don't include the extra sort\". .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_52400451",
      "task": "How to write API for insertion and erase functionality of multimap?",
      "P-task": "write api insert eras function multimap",
      "F_verb": "erase",
      "P-body": "Looking up the actual documentation for remove: .   Removes the first element t in self such that the expression (t == a) is true and returns true. Returns false if there is no such element. .   So, this would be a start: .  Live On Coliru .  Prints .  ",
      "P-tags": "c++ linux boost",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "au_1032459",
      "task": "How to disable the \"tap dragging\"-feature in Ubuntu 18.04 (libinput) without disabling \"tap to click\"?",
      "P-task": "disabl tap drag -featur ubuntu 18 04 libinput without disabl tap click",
      "F_verb": "disable",
      "P-body": "Since 18.04 is using Xorg instead of Wayland, you should be able to set it this way: .  First find the device: .  I'm on a thinkpad. Your devices are likely different. .  List the properties of the touchpad: .  Then disable it: .  The way I set this permanently is by putting into a script that runs on login. .  I hope that helps. I don't know how to fix it at the system-level, nor on Wayland. .  ",
      "P-tags": "touchpad libinput gnome xorg 18 04",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_12527823",
      "task": "How can i dynamically assign filename with -w option in tcpdump.sh on freebsd?",
      "P-task": "dynam assign filenam -w option tcpdump sh freebsd",
      "F_verb": "assign",
      "P-body": "try the multiple argument form of system: .  you also may want to remove the spaces from the date string: .  ",
      "P-tags": "freebsd perl bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP with NP in NP on NP"
    },
    {
      "id": "ul_655529",
      "task": "run xterm in background and exit",
      "P-task": "run xterm background exit",
      "F_verb": "run",
      "P-body": "The -X option opens an X11 tunnel that runs through the ssh connection. The tunnel can exist only as long as that ssh connection is open. .  To do what you ask, you need to put ssh itself in the background without an interactive session involved. .  There are at least two ways to do this. One is to set up ssh connection sharing, which would allow you to open ssh in the background and then start multiple ssh sessions using the shared connection. The ssh man page has details on this. .  A simpler way would be to open ssh in the background just to open your two xterm sessons: .  The \"-n\" option tells ssh to not use stdin, which allows it to be placed in the background. If ssh requires a password, you can omit the final \"&\", enter the password, and then suspend it and put it in the background. .  ",
      "P-tags": "cento linux bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_52055535",
      "task": "`kill \"$!\"` doesn't work when FOR loop is around",
      "P-task": "kill\nwork loop around",
      "F_verb": "kill",
      "P-body": "I suspect your \"wait\" is also waiting for the backgrounded progress bar. Try capturing the specific pids of the backgrounded \"ssh\" instances, and waiting on them specifically: .  This places the pids of backgrounded \"ssh\"es into an array, then waits on the members of the array rather than \"everything that is backgrounded\", which is \"wait\"'s default behaviour. The bash man page states: .   If n\u0332 is not given, all currently active child processes are waited for .   Note: untested. May contain nuts. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP when S"
    },
    {
      "id": "so_48736249",
      "task": "Typing two letters at the same time causes docker exec -it shell to exit abruptly",
      "P-task": "type two letter time caus docker exec -it shell exit abruptli",
      "F_verb": "cause",
      "P-body": "This issue appears to be a bug with docker and windows. See the github issue here. .  As a work around, prefix your \"docker exec\" command with winpty, which comes with git bash.  .  eg.  .  ",
      "P-tags": "docker-toolbox shell docker",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_656293",
      "task": "How to use password for ftp user and still maintain pem authentication for root?",
      "P-task": "use password ftp user still maintain pem authent root",
      "F_verb": "use",
      "P-body": "You need to specify the following two options in your \"sshd\" config file: .  This allows the use of passwords for your FTP user (and all other users). .  This explicitly allows \"root\" to only login via \"ssh\" using a keyfile, and prevents logging in as \"root\" with password. .  ",
      "P-tags": "ubuntu ssh authent",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP"
    },
    {
      "id": "au_22946",
      "task": "How do I install and use the latest version of GNOME?",
      "P-task": "instal use latest version gnome",
      "F_verb": "use",
      "P-body": "Installing from the Software Center (11.10 and newer) Open the software center search for \"gnome shell\" and install it, or just click this button: .   .   .  After it installs, log out. .   For 11.10 .  at the login screen click the little gear icon and select \"GNOME\" from the menu.  .   .  For 12.04 and 12.10 .  At the login screen click the icon show and select \"GNOME\" from the menu. .   .   .   After that just put in your password and login: .  The login manager will remember the last session you went into so you only need to select GNOME once, after that you can just login normally. .  Customizing it further You can also use the fallback mode if you prefer an old-school experience: .   How to revert to GNOME Classic Desktop?  And if you use auto logins you might need to tell lightdm to always use shell: .   How can I use gnome shell by default instead of unity?  Other Goodies to install with it  gnome-documents  gnome-boxes   Command Line Instructions:   .  Where to report problems:  Discussion about GNOME3 packaging (Mailing list link on the bottom left): https://launchpad.net/~gnome3-team  Most problems and issues with this set of packages can go on this list, it should be the first place you report problems and issues.  Bug reports that are NOT packaging related: https://bugzilla.gnome.org/  If GNOME3 isn't working well it could be packaging related, so please don't just randomly report bugs to GNOME unless you are confident that it's an upstream GNOME problem. If you're not sure if you should report the bug upstream then ask someone either on IRC or on the mailing list above if you need help determining if something should be reported to GNOME.   ",
      "P-tags": "gnome software-instal",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_162414",
      "task": "Yum search , install and list",
      "P-task": "yum search instal list",
      "F_verb": "install",
      "P-body": "  Is my understanding of the above commands correct ?    Yes  .    What does the local repo mean ? Is it a directory that contains all the packages    If you are configuring your own yum repository (or your system admin. in your lab) then it may refer as local yum repository. It may be on local system or on a private network. Ref: How to configure yum repository.  .    How do I find what the default repo directory of yum is on my computer?    This is configured in \"/etc/yum.repos.d/\" directory. There is no such think as \"default\" here. If repository is enabled that means that is active. You can find enabled repos by:  .    How do I list all the packages that are available on my local repo only?    For this, I am running a query with help of this command:  .  where, replace \"myrepo\" with your repository name. .  ",
      "P-tags": "fedora yum",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_46227403",
      "task": "In Automic 12 bash, special characters in mailx body result in body being attached as a binary file",
      "P-task": "autom 12 bash special charact mailx bodi result bodi attach binari file",
      "F_verb": "attach",
      "P-body": "Mailx is a evolved MUA. For just sending a mail, if you use \"sendmail\", you could build your own mail header: .  Or you could use html encoding: .  Care, use only ASCII characters there! .  ",
      "P-tags": "autom linux bash email mailx",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V as NP"
    },
    {
      "id": "su_1217454",
      "task": "How do you control thread affinity across multiple processes on Linux?",
      "P-task": "control thread affin across multipl process linux",
      "F_verb": "control",
      "P-body": "First: get your cpu layout from /proc/cpuinfo, that will look something like (this is on a 2-socket, 6-core, listing truncated): .  physical-id will be your socket, notice in my case, the core-id's toggle between sockets. .  use 'schedtool' to set the affinity of 1 group to all be on 1 physical id. So in my case, since the evens and odds are on separate physical cpus(sockets), I'd use: .  where run_group1 starts all your threads you want on 1 core, and run_group2 starts the other ones. look at 'man schedtool' (in section 8 for more options. I put both of them in background so both groups should run concurrently. .  You might need to be root to set affinity -- not sure. .  Does that solve your Q or did I misunderstand something? .  ",
      "P-tags": "parallel-process multi-cor linux smp cento",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP across NP on NP"
    },
    {
      "id": "so_4207690",
      "task": "Update command line application status",
      "P-task": "updat command line applic statu",
      "F_verb": "update",
      "P-body": "Output a \"\\r\" before printing the update, then flush. This will return the cursor to the first column. .  ",
      "P-tags": "java bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_67976264",
      "task": "List Files That Do Not Contain String in Filename",
      "P-task": "list file contain string filenam",
      "F_verb": "contain",
      "P-body": "You can use the \"-Exclude\" parameter: .  See Example 5 from MS Docs. .  Note: Using \"-Filter\" with \"-Include\" or \"-Exclude\" will not work: .  However if you do it like this, it works fine: .   Using \"Where-Object\" it would look like this: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_177569",
      "task": "Can't concat file paths, permission denied",
      "P-task": "concat file path permiss deni",
      "F_verb": "concat",
      "P-body": "Shell variables are set using the syntax \"name=value\". There must not be any [unquoted] whitespace characters in the declaration. .  The space in your usage was invoking the other usage of \"name=value\", i.e. temporarily setting environment variables for a single program invocation. .  For instance: .  The reason you were getting a permission denied error on \"path1= \"./src/$1\"\" was because it was taken to mean \"Set environment variable path1 to empty and invoke program ./src/$1\" and since \"./src/$1\" doesn't have its executable bit set it failed. .  ",
      "P-tags": "shell-script osx bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "su_376692",
      "task": "Auto enable Mouse Wheel Emulation for ANY mouse devices on Linux",
      "P-task": "auto enabl mous wheel emul mous devic linux",
      "F_verb": "enable",
      "P-body": "Thanks to help on Archlinux's forum , I've found the way to archive this: .  Edit \"/etc/X11/xorg.conf.d/10-evdev.conf\" and change first section to: .  ",
      "P-tags": "linux xorg",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "so_20580897",
      "task": "Get X window id from process in bash",
      "P-task": "get x window id process bash",
      "F_verb": "get",
      "P-body": " gives me the windows and their PIDs. Sample output: .  ",
      "P-tags": "xorg bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_615991",
      "task": "Where do I give feedback about the Lubuntu website?",
      "P-task": "give feedback lubuntu websit",
      "F_verb": "give",
      "P-body": "I'm not sure if you have to be on the mailing list to send them an email but I found this email here:  .  lubuntu-qa@lists.launchpad.net  .  you can also  .  lubuntu-users@lists.ubuntu.com  .  You can sign up for the users list here if you would like to receive followups and future posts https://lists.ubuntu.com/mailman/listinfo/lubuntu-users .   The proper download link should be this instead: .  http://cdimage.ubuntu.com/lubuntu/releases/15.04/release/lubuntu-15.04-desktop-i386.iso.torrent .   Also, you can upgrade to 15.04 by running the following commands: .  source: http://www.cyberciti.biz/faq/howto-upgrade-to-ubuntu-14-04-from-ubuntu-13-10-or-12-04/ .  ",
      "P-tags": "lubuntu",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP about NP"
    },
    {
      "id": "au_817101",
      "task": "Cannot upgrade to 16.04 after failed attempt",
      "P-task": "upgrad 16 04 fail attempt",
      "F_verb": "upgrade",
      "P-body": "It appears that your upgrade was partially successful except for perhaps the latest kernel. Since you have now made room in /boot, you can try installing the metapackage \"linux-generic-lts-xenial\" which will get you the latest xenial kernel. .  If other portions of the upgrade didn't succeed, I do not know how to diagnose that. .  ",
      "P-tags": "14 04 upgrad 16 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V to NP after NP"
    },
    {
      "id": "so_7254517",
      "task": "Resetting the session in PowerShell",
      "P-task": "reset session powershel",
      "F_verb": "reset",
      "P-body": "You can just dotsource your profile. .  If your profile handles errors when things like drives, or vars even exists, everything is ok. .  ",
      "P-tags": "powershel window powershell-2 0",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_56923333",
      "task": "Wordpress can't reach a page after added SSL certificate to my VPS",
      "P-task": "wordpress reach page ad ssl certif vp",
      "F_verb": "add",
      "P-body": "I forgot to unblock the port. .  ",
      "P-tags": "php wordpress linux ubuntu apach",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "au_754098",
      "task": "how to calculate script run time",
      "P-task": "calcul script run time",
      "F_verb": "calculate",
      "P-body": "Most of the shells has a builtin named \"time\", \"bash\" has it too. It will show you the actual human time (\"real\") a process takes with the CPU time the process spends on user space (\"user\") and kernel space (\"sys\"). .  So run the command perpending \"time\": .  At the end \"bash\" will show the time on STDERR like: .  Even if you are on a shell that does not have the \"time\" builtin you have the external \"time\" command \"/usr/bin/time\" from the \"time\" package. The usage is same. .  ",
      "P-tags": "telnet command-lin bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP"
    },
    {
      "id": "so_16139655",
      "task": "How to save the output file in a directory and print the name of the output file?",
      "P-task": "save output file directori print name output file",
      "F_verb": "save",
      "P-body": "There were several serious problems with your existing code. One is your use of \"pwd\" inside of a double-quoted string. That just won't work. You could use \"pwd\" inside of backticks and capture the output, but not inside of a double quote literal. .  Another problem is that the logic of your code doesn't approach the complexity of the description of how you would like to gracefully degrade destinations. .  The following code snippet will first look for a directory named \"special\" within the executable's directory. If it doesn't exist, it will try to create it. If creation fails (probably due to permissions), it will next look for a directory named \"special\" in the user's current working directory. If it doesn't exist, it will try to create it. If that fails, it will die with a descriptive message. .  If it runs past this point, then the \"special\" directory either pre-existed or has been created along one of the permissible paths. Next, the files are opened. If opening the output file fails, we die. Otherwise, continue and presumably write to the file. Then close both the input and output files. Finally, print the path at which the output file may be found. .  I'm using the Perl module FindBin to locate the executable. And File::Path is being used to create the directory. .  ",
      "P-tags": "unix file-handl perl sudo bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "so_47354123",
      "task": "Bash - heredoc with variable expansion, preserving newlines",
      "P-task": "bash - heredoc variabl expans preserv newlin",
      "F_verb": "preserve",
      "P-body": "First, you don't need \"read\" for this: .  Second, you should always quote parameter expansions; you'll know when doing so isn't what you want, and such cases are rare. .  Finally, consider whether you need \"msg\" in the first place: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_872556",
      "task": "Build OpenSSL from source to have TLS extension \"heartbeat\" (id=15) in Apache",
      "P-task": "build openssl sourc tl extens heartbeat id 15 apach",
      "F_verb": "build",
      "P-body": "Below is my script to prepare an environment to demonstrate CVE-2014-0160.  .  Here I cannot post download link because I do not have enough reputation. You need to download openssl-1.0.1e.tar.gz, httpd-2.4.25.tar.gz, apr-1.5.2.tar.gz, apr-util-1.5.4.tar.gz, pcre-8.40.tar.gz into your home directory. .  ",
      "P-tags": "server openssl software-instal 12 04 apache2",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP S_INF"
    },
    {
      "id": "so_5468392",
      "task": "How to break down a bash script into minimal work chunks using Java",
      "P-task": "break bash script minim work chunk use java",
      "F_verb": "break",
      "P-body": "This is what I got so far. I have not tested it exhaustively. .  ",
      "P-tags": "bash java regex",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V down NP into NP using NP"
    },
    {
      "id": "so_39013360",
      "task": "Activate bash and pass it \"single line code\" instead of file",
      "P-task": "activ bash pass singl line code instead file",
      "F_verb": "activate",
      "P-body": "Elaborating on fedorqui's and Yani Maltsev's comments: .  or .  If you use either single quotes outside and only double quotes inside, or else double quotes outside and only single quotes inside, no escaping will be needed. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_63196",
      "task": "In Vim, how can I automatically determine whether to use spaces or tabs for indentation?",
      "P-task": "vim automat determin whether use space tab indent",
      "F_verb": "determine",
      "P-body": "You can use something like this in your \"~/.vimrc\" to adjust to use spaces/tabs as appropriate: .  ",
      "P-tags": "indent whitespac vim",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V whether S"
    },
    {
      "id": "so_67628679",
      "task": "save .csv rows in different files",
      "P-task": "save csv row differ file",
      "F_verb": "save",
      "P-body": "Your code sample handles multiple input files. You seem to understand the file I/O but as the commenters have already noted, you are not making use of the built in CSV and Object processing within PowerShell. .  First we'll read your sample data from a here-string for simplicity and to make the code below easy to test .  Your question referred to two steps. Use \"Where-Object\" for filtering. Use \"Select-Object\" to pick out the columns you want. Use a backtick ` at the end of a line for line continuation .  Now we can pipe the output of the $Step1 variable to CSV. Filter it first using \"Where-Object\" again. Since you gave two specific cases (50 and 51) that is what is demonstrated below. .  Note that the output data will be wrapped in quotes like this. .  If this is problematic, there are several methods to remove the quotes. .  ",
      "P-tags": "powershel export-csv import-csv",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "so_64425105",
      "task": "How to copy both stdout and stderr to a file with timestamp from within a bash script?",
      "P-task": "copi stdout stderr file timestamp within bash script",
      "F_verb": "copy",
      "P-body": "To redirect both stdout and stderr of a command to a sequence of commands, and finally to both the console and a file, you can do it with this syntax .  which is the synonym of this .  or redirecting both streams to a process substitution .  or redirecting the output and then make the stderr a copy of stdout .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "au_56107",
      "task": "How to move my Trash into /tmp or automatically empty trash on reboot?",
      "P-task": "move trash tmp automat empti trash reboot",
      "F_verb": "move",
      "P-body": "Why don't you use another approach: .  Crontab combined with command line client for trash  Install trash-cli  / \"sudo apt-get install trash-cli\", which will allow you to control your trash folder from shell. Open your crontab with \"crontab -e\" in shell (will open your default shell editor chosen by \"select-editor\") Add an entry like .    Now on every reboot your trash will be emptied. You can specify other times to empty trash. Just look at a crontab tutorial to learn how. .   Of course you can use your link approach from above just as well. The problem with your approach was that you copied the link. Most likely that broke the link. Also your newly created folder \"/tmp/my-trash/\" didn't have the proper directory structure of a trash folder specified by the free desktop standard. That can be remedied in the following way: (FIRST empty the trash manually)  .  To make that change persistent, you have to include the following line in your user's crontab with \"crontab -e\" or just the part without \"@reboot\" in your \"~/.bashrc\". .  ",
      "P-tags": "trash tmp",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP into NP on NP"
    },
    {
      "id": "ul_425622",
      "task": "what is the best way to match a version number from file",
      "P-task": "best way match version number file",
      "F_verb": "match",
      "P-body": "At the very least, you'd want to match on \"$version\" provided it's not preceded nor followed by a digit or dot to avoid matching on things like 23.092.123 or 1.23.092.12 (though you may also want to also consider cases like \"23.092.12-rc1\", \"23.092.12b\", \"23.092.12-2\"...). May be easier with \"perl\": .  That matches on: .  But not on .  The \"(?<!...)\" and \"(?!...)\" are respectively negative look behind and look forward regex operators. We use \"\\Q...\\E\" so that the content of the env var is taken as a fixed string instead of a regexp (so \".\" loses its special meaning of matching any character). .  If, as per your edit, your version numbers in the input file are always found at the start of the line and always followed by a spacing character, you can simplify it to: .  Or use \"awk\" to match on lines whose first field is the version: .  The concatenation with \"\"\"\" is to force a string comparison. Without it, with a \"$version\" like \"123.4\", it would match on \"123.40\". .  To match on the \"$version\" being any space delimited field in the input: .  That is \"$version\" provided that it's neither preceded nor followed by a non-spacing character (\"\\S\"). .  ",
      "P-tags": "grep regular-express linux text-process perl",
      "source": "qa",
      "cate": "match",
      "pat": "V NP from NP"
    },
    {
      "id": "so_30526140",
      "task": "Run script daily with cron and create compressed log file",
      "P-task": "run script daili cron creat compress log file",
      "F_verb": "create",
      "P-body": "This is possible. .  Instead of running \"/usr/local/bin/php\" every 15 minutes, why not replace that call with a shell script which does everything you described? .  This shell script would run your php script, pipe the output to a file somewhere on your system which you can then compress. .  ",
      "P-tags": "linux ubuntu cron crontab",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "ul_155928",
      "task": "Failed to fetch 404 errors during apt-get commands",
      "P-task": "fail fetch 404 error apt-get command",
      "F_verb": "fetch",
      "P-body": "Take a look at this answer, looks like support for etch ended a while ago. Try using the archive instead of using the Netherlands mirror. .  ",
      "P-tags": "xenomai",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP during NP"
    },
    {
      "id": "su_1005796",
      "task": "bash - string manipulation get string before or after substring",
      "P-task": "bash - string manipul get string substr",
      "F_verb": "get",
      "P-body": "You have to place the asterisk to the other end of the string. The asterisk stays for \"whatever\", so .  means \"remove from string everyting from the searchstring onwards\". .  This is documented in \"man bash\" under \"Parameter Expansion\". .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP before NP"
    },
    {
      "id": "au_438312",
      "task": "\"ls\" with one-digit pattern gives me strange results",
      "P-task": "ls one-digit pattern give strang result",
      "F_verb": "give",
      "P-body": "As @Sparhawk explained, what is happening is that you are listing the content of the directories. This will not depend on the *nix you are using, as far as I know, this is the default behavior of GNU \"ls\". Non-GNU implementations may be different but I doubt it. .  When you run this command: .  The glob (\"*6*\") is expanded by your shell (bash for example) before calling \"ls\". So, given the following directory structure: .  \"ls d*\" will be expanded to \"ls dir1 dir2\", and give the results you expect: .  This is how \"ls\" deals with multiple target directories by default, it lists each directory found and then the contents of that directory. However, if you run it on a single directory, the name is not printed: .  So, since there is only one match for the glob \"*6*\" in \"/usr/include\" and that match is a directory, you are running \"ls\" with a single directory as input and, therefore, it is listing the contents of the directory without including the directory name. .  ",
      "P-tags": "ls",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP"
    },
    {
      "id": "au_133314",
      "task": "How do I install a Gadmei TV Tuner (UTV380)",
      "P-task": "instal gadmei tv tuner utv380",
      "F_verb": "install",
      "P-body": "If you have more than a video source (which seems to be your case), you must specify which one is going to be used by \"tvtime\" in order to get the images. .  In order to know which are your video sources you can drop this in a terminal: \"ls -l /dev/video*\" and you must have an output like this: .  Then you must try with each different video source, tvtime usually starts from 0, so you try from \"/dev/video1\" with this command in a terminal \"tvtime --device=/dev/video1\" .  If everything is ok then you'll see the TV signal in a window. If it drops an error please edit your question with the output of your terminal in order to edit this answer with an advice/solution. .   Expected issues: Video but no sound. Be warned.   Additionally, if you face sound issues or no-sound while playing the tv station, just try this in a terminal, change the 48000 value for whatever your broadcast can stand for, in certain cases 32000 is good enough but it depends on your tv tuner. .  \"tvtime --device=/dev/video1 | arecord -D hw:1,0 -r 48000 -c 2 -f S16_LE | aplay -\" .   Check this out: https://askubuntu.com/a/45391/9598 and don't forget to use the proper \"--device=/dev/video1\" when needed. .  Good luck! .  ",
      "P-tags": "tvtime",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_12415942",
      "task": "How to append timestamp to matching string using SCons' env.Command",
      "P-task": "append timestamp match string use scon env command",
      "F_verb": "append",
      "P-body": "Protect the \"$\" from the SCons parser by writing it as \"$$\": .  ",
      "P-tags": "scon build python unix",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP using NP"
    },
    {
      "id": "so_26927687",
      "task": "duplicate every row multiple times in linux",
      "P-task": "duplic everi row multipl time linux",
      "F_verb": "duplicate",
      "P-body": "With \"perl\" you can do this .  and with \"awk\" .  and with \"sed\" .  ",
      "P-tags": "row linux",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP in NP"
    },
    {
      "id": "so_27604856",
      "task": "How to handle space in a line in a file using shell script?",
      "P-task": "handl space line file use shell script",
      "F_verb": "handle",
      "P-body": "You can write the entire code in a single while as .  Gives output as .  ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "au_609303",
      "task": "How can I view a progress bar when running rsync?",
      "P-task": "view progress bar run rsync",
      "F_verb": "view",
      "P-body": "How about this? .   \"$rsync_param\" .  Avoids double input of parameters .  \"$(rsync \"$rsync_param\"n a/ b | awk 'NF' | wc -l)\" .  Determines the number of steps to complete. .  \"a/ b\" .   \"a/\" is the source \"b\" is the target   ",
      "P-tags": "rsync",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP when S"
    },
    {
      "id": "so_13928005",
      "task": "Install CPAN Modules without messing up the system Perl installation",
      "P-task": "instal cpan modul without mess system perl instal",
      "F_verb": "install",
      "P-body": "Are you looking for something like \"local::lib\" .   local::lib - create and use a local lib/ for perl modules with PERL5LIB .   ",
      "P-tags": "linux perl",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP without S_ING"
    },
    {
      "id": "ul_469126",
      "task": "Is there a way to create file references that won't be broken when files and directories are renamed or moved?",
      "P-task": "way creat file refer broken file directori renam move",
      "F_verb": "rename",
      "P-body": "Yes, several ways. .   Hard links: \"ln file1 file2\". Now \"file2\" will be another name for \"file1\", and no matter what you rename \"file1\" to, or even if you delete it, \"file2\" will always still work to access it (unless you rename/delete it too, obviously). This only works for files, not directories, and all of the links have to be on the same filesystem. Bind mounts: \"mount --bind file1 file2\". This works like hard links, except it works for directories too, and it doesn't have the same-filesystem restriction. The downside is it's a privileged operation, so you need to be root (or be in your own user and mount namespaces). File descriptors: \"exec {foo}</some/file\". Once you do that, \"/proc/self/fd/$foo\" will be a \"magic\" symlink to the file (it's \"magic\" in the sense that it won't break like regular symlinks would, and is possible because of the special /proc pseudo-filesystem). This works for both files and directories, doesn't need any special privileges, and is automatically inherited and usable by child processes. The downsides are that it only lasts until the process that did it exits, and that you don't have much control over the path to it. name_to_handle_at/open_by_handle_at: This meets your literal requirement, but is more complicated than any of the above and is a privileged operation. The only advantage is that the handle is regular data and doesn't require any state to be held.  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "au_914413",
      "task": "How to install bios updates in Zesty (on a Dell laptop)?",
      "P-task": "instal bio updat zesti dell laptop",
      "F_verb": "install",
      "P-body": " Am I doing the wrong thing? .   Yes, I think so. There is a page dedicated to BIOS updates and it says about Dell this: .   If you are using UEFI and your F12 boot options include \"Flash BIOS upgrade\", one may download the BIOS upgrade .exe from Dell's website, and put it to your \"/boot/EFI/\" folder. Reboot and select \"Flash BIOS upgrade\" option. In the dialog select the .exe file you have just downloaded and continue with the process. .  For more on Dell specific procedures, please see here. .   ",
      "P-tags": "17 04 uefi dell bio",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP on NP"
    },
    {
      "id": "au_1216692",
      "task": "apt-get not found after running some purge commands",
      "P-task": "apt-get found run purg command",
      "F_verb": "get",
      "P-body": "okay, make a backup first from your important data.  .  I hope wget is also present on your system. .  Next we draw the required packages. .  For 64-bit system. .  Next is .  Install both  .  Next we test apt .  For 32-bit .  and  .  The steps for installing is the same as for the 64-bit packages. .  ",
      "P-tags": "18 04 apt purg command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V"
    },
    {
      "id": "ul_401291",
      "task": "How to get the trash and x-gvfs-show partitions on Thunar via AwesomeVM?",
      "P-task": "get trash x-gvfs-show partit thunar via awesomevm",
      "F_verb": "get",
      "P-body": "Finally I found the reason. This bug is related to lightDM starting awesome without \"dbus-launch\". I fixed the whole problem described here by editing by hand the file \"/usr/share/xsessions/awesome.desktop\" as: .  This is not a very pleasant solution and neither a good one, since I editing that file this thing will be mess-up when I got a new update of awesome and \"/usr/share/xsession/awesome.desktop\" be overwritten. .  Looking forward for better solutions, but for now, only for now, this is working pretty fine. Trash appears now on thunar, xfdesktop and x-gvfs-show-partitions it's working as expected. .  ",
      "P-tags": "awesom trash fstab thunar gvf",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP via NP"
    },
    {
      "id": "au_620700",
      "task": "USB Keyboard not working in Xubuntu session - How to debug?",
      "P-task": "usb keyboard work xubuntu session - debug",
      "F_verb": "debug",
      "P-body": "Since \"xinput list\" shows that your keyboard has device ID 12 what you need is \"xinput enable 12\" and now your keyboard should work. This does not help explain why Xubuntu isn't enabling it nor does it help if you unplug it and replug it. In my experience the device ID is always the same. .   You can make a watchdog script to enable the keyboard if it's disabled: .   Run \"sudo mkdir -p /usr/local/bin\" to create the local binaries folder if doesn't exists. Run \"sudo touch /usr/local/bin/keyboard_watchdog\" to create a file on that folder. Run \"sudo chmod 777 /usr/local/bin/keyboard_watchdog\" to give it permissions to edit. Run \"gedit /usr/local/bin/keyboard_watchdog\" to edit the file. Paste in it this: .   Save the file. Open Settings Manager and select Session and Startup. On the Application Autostart tab, click on the Add button. On the dialog that opens write the name of the application (i.e. Keyboard fix) and the command that runs the application (\"/usr/local/bin/keyboard_watchdog\"). Once you click OK the application will be added to the list and will automatically be started on the next session login.  ",
      "P-tags": "xubuntu usb keyboard 14 04 logitech-unifi",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V"
    },
    {
      "id": "au_132059",
      "task": "How to make a package manager wait if another instance of APT is running?",
      "P-task": "make packag manag wait anoth instanc apt run",
      "F_verb": "make",
      "P-body": "You can use the \"aptdcon\" command  to queue up package manager tasks by communicating with aptdaemon instead of using apt-get directly.  .  So basically you can just do \"sudo aptdcon --install chromium-browser\" or whatever and while that command is running you can run it again but install different packages and apt-daemon will just queue them up instead of erroring out.  .  This is especially useful if you're doing a long upgrade or something and want to keep installing packages or if you're scripting something together and want to make sure installing things will be more reliable.  .  ",
      "P-tags": "apt command-lin",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP if S"
    },
    {
      "id": "au_1170027",
      "task": "Error while loading shared libraries: cannot open shared object file: No such file or directory",
      "P-task": "error load share librari : open share object file : file directori",
      "F_verb": "open",
      "P-body": "You need to install the missing library (in a terminal, ctrl-alt-t to start one): .  That should fix your problem. Shared libraries are needed by the executable, and are brought into the running process at load time. You can see what shared libraries are needed by an executable with the ldd command .  ",
      "P-tags": "shared-librari permiss software-instal",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "ul_470917",
      "task": "Rebuild from src.rpm using new version",
      "P-task": "rebuild src rpm use new version",
      "F_verb": "rebuild",
      "P-body": "\"rpmbuild --rebuild QuantLib-1.4-7.el7.src.rpm\" will \"just\" extract the source package to \"~/rpmbuild/{SPEC,SOURCES}/\" and run \"rpmbuild -ba ~/rpmbuild/SPEC/QuantLib\". Nothing else. .  You want to rebase to new version, which can be easy or tricky. Hard to say in advance. .  The easy version is that you .   \"rpm -Uvh QuantLib-1.4-7.el7.src.rpm\" \"cd ~/rpmbuild/SOURCE\" create tar.gz from the upstream git repository and put it to this directory. optionaly you can dele the old version which is in this directory. edit ~/rpmbuild/SPEC/QuantLib.spec and change \"Version\", \"Release\", \"Source0\" and edit \"%changelog\". run \"rpmbuild -ba ~/rpmbuild/SPEC/QuantLib.spec\"  Sometimes this work. Usually for simple projects or for well maintained projects. .  Sometimes the last step fails with ... nearly anything. There is zilion options to fail. To fix that you should really know how packaging RPM works. The good start is to read https://rpm-packaging-guide.github.io/ .  Note that QuantLib maintain spec file in their github repository. This may help you. .  And once you build the package, you can make world better and build it in https://copr.fedorainfracloud.org where others can easily find it and use it. .  ",
      "P-tags": "compil rpmbuild librari rpm amazon-linux",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V from NP using NP"
    },
    {
      "id": "so_29032368",
      "task": "Calabash - how to compare text from label with given id?",
      "P-task": "calabash - compar text label given id",
      "F_verb": "compare",
      "P-body": "These methods exist in the base Ruby stack rather than Calabash. You can find Ruby's assert methods here: http://ruby-doc.org/stdlib-2.0/libdoc/minitest/rdoc/MiniTest/Assertions.html .  More information is here: https://github.com/seattlerb/minitest .  Rather than use assert, I personally like Ruby's 'should' syntax. First install this gem: .  then in features/support/env.rb: .  finally, you can assert like so: .  Should has been deprecated in favor of expect(). I still prefer should ... more info is here: http://rspec.info/blog/2012/06/rspecs-new-expectation-syntax/ .  ",
      "P-tags": "rubi io calabash bdd calabash-io",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP from NP with NP"
    },
    {
      "id": "so_54621238",
      "task": "How to use variable to store error type for catch block?",
      "P-task": "use variabl store error type catch block",
      "F_verb": "use",
      "P-body": "Short answer, I don't believe you can do what you're trying. Lemme walkthrough just to make sure I understand the scenario. .  The parameter for the \"catch\" block is one or more exception types like \"System.Net.WebException\": .  Saying this just to level set. .  Now, we typically see those types hard coded, but you'd like to assign the type in the catch block dynamically as a variable: .  The problem is catch needs to be followed by an exception type not a variable. That variable will be (if it hosts an exception type) of type RuntimeType. You can try to finagle the exception type out of the variable with GetType() or something like that. Net-net, it just won't work. .  Put a generic catch block (with no type) in your script-function-whatever then pass the values to your catch function, and have the branching logic in there do whatever you're trying to do. .  And, if you don't want to pass the whole exception object, you can use... .  ",
      "P-tags": "error-handl powershel try-catch exception-handl",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP to NP for NP"
    },
    {
      "id": "au_830198",
      "task": "What is the default dhcp server package on a standard Ubuntu install?",
      "P-task": "default dhcp server packag standard ubuntu instal",
      "F_verb": "install",
      "P-body": "There is no such thing as default dhcp server. NICs use broadcasts to find DHCP servers. In fact that's the whole point of DHCP, to get an IP at an unknown network. .  The way DHCP works is, first your NIC sends a DHCP DISCOVER packet as a broadcast. Broadcast means packets destination IP 255.255.255.255 and destination MAC FF:FF:FF:FF:FF:FF. Which means that every device on your LAN receives the packet, but everyone will ignore it except your DHCP server, which will reply with a DHCP OFFER packet, then you request offered IP with DHCP REQUEST, and finally the DHCP server confirms it with DHCP ACK. .  You can see it with \"sudo dhclien -v eth0\" #or whichever your interface is  .  ",
      "P-tags": "dhcp network server",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_17700748",
      "task": "how to make switch execute 2 cases",
      "P-task": "make switch execut 2 case",
      "F_verb": "make",
      "P-body": "The \"case\" statement in bash executes the commands in the \"COMMAND-LIST\" for the first match only. .  However, In \"bash version 4\" or later introduced the \";&\" terminator. The \";;&\" operator is like \";;\", except the case statement doesn't terminate after executing the associated list - Bash just continues testing the next pattern as though the previous pattern didn't match. Using these terminators, a case statement can be configured to test against all patterns, or to share code between blocks, for example. .  Reference: Excerpt taken from http://wiki.bash-hackers.org/syntax/ccmd/case .  So if you have \"bash v 4 or later\" this would give your desired result:  .  ",
      "P-tags": "linux switch-stat shell bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_257564",
      "task": "Catalyst control center settings not loading on startup",
      "P-task": "catalyst control center set load startup",
      "F_verb": "load",
      "P-body": "Same problem here, with Ubuntu 12.04TLS amd64, on a AMD A10 with integrated AMD Radeon HD6670 video and a AOC 23\" monitor connected via HDMI. .  I had the same monitor on a 32bit 12.04TLS Ubuntu on a much older AMD CPU and its integrated video card, and the screen used also a part of the panel, but changing the DTV settings in Catalyst Control Center solved it and the settings were permanent. .  The main difference I know of is amd64 / 32bit change, but I have no clue as to this can explain the settings not kept upon logout or reboot. .  SOLUTION FOUND ! see https://help.ubuntu.com/community/BinaryDriverHowto/ATI -> 5.2. HDTV underscan .  Here is what I did successfully : .  enjoy .  ",
      "P-tags": "radeon 12 10 display driver catalyst",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V on NP"
    },
    {
      "id": "au_155360",
      "task": "Where does the Unity Dash get its launchers from?",
      "P-task": "uniti dash get launcher",
      "F_verb": "get",
      "P-body": "The dash also looks in \"~/.local/share/applications\", so you might want to check in there too. .  ",
      "P-tags": "launcher wine unity-dash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from"
    },
    {
      "id": "ul_630881",
      "task": "Readable format of file sizes using the Find command",
      "P-task": "readabl format file size use find command",
      "F_verb": "use",
      "P-body": "Use \"numfmt\" .  Output: .  Use \"--to=si\" if you want factor 1000 instead of 1024 .  ",
      "P-tags": "script shell-script find disk-usag",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_1346576",
      "task": "How to fix \"GLib-GIO-ERROR Settings schema 'org.gtk.Settings.FileChooser' is not installed\"?",
      "P-task": "fix glib-gio-error set schema org gtk set filechoos instal",
      "F_verb": "fix",
      "P-body": "This schema is contained in \"libgtk-3-common\" package. You have to reinstall it with .  ",
      "P-tags": "gtk nautilu gnome",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_373012",
      "task": "Why does phpmyadmin require a kernel update...?",
      "P-task": "phpmyadmin requir kernel updat",
      "F_verb": "require",
      "P-body": " instructs \"apt-get\" to upgrade everything it can without removing any package. To upgrade a specific package, you need to \"install\" it: .  ",
      "P-tags": "upgrad apt phpmyadmin",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_48255834",
      "task": "How to get apache to use python3.6 and its modules?",
      "P-task": "get apach use python3 6 modul",
      "F_verb": "get",
      "P-body": "You can't force mod_wsgi compiled for one Python version to use a different Python installation for a different version. This is because mod_wsgi actually links the Python library for the version it was compiled for, it doesn't just run the \"python\" program of some arbitrary version. .  The only thing you can do is uninstall mod_wsgi from system packages (which uses Python 3.5) and install mod_wsgi from source code yourself and compile it against Python 3.6. .  Also, neither of the paths you gave \"WSGIPythonHome\" and \"WSGIPythonPath\" were correct anyway. When you install mod_wsgi from source code, don't set those directives as they will continue to screw things up. .  ",
      "P-tags": "ubuntu python-3 6 apach mod-wsgi",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_33762773",
      "task": "how to pass parameter to shell script to use as part of variable filename",
      "P-task": "pass paramet shell script use part variabl filenam",
      "F_verb": "pass",
      "P-body": "In the shell script, use \"$1\" to denote the first parameter passed to it. .  Fix your java as below, .  ",
      "P-tags": "shell java bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP S_INF of NP"
    },
    {
      "id": "so_66261952",
      "task": "Stuck in Terminal after echo",
      "P-task": "stuck termin echo",
      "F_verb": "echo",
      "P-body": "You need to leave the terminal with \"Ctrl + C\" or \"Ctrl + D\". This is caused because you did not close the opened quote. You can also type a closing quote to exit the \">\". .   .  The arrow \">\" means, terminal is waiting for you to close the opened quote. .  If you want to use a quote in your echo, you can escape it with backslash .  You can read This for more info. .  ",
      "P-tags": "termin linux command-line-tool",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V"
    },
    {
      "id": "so_23777992",
      "task": "Loops with PHP shell_exec() : Use php for() or bash for-do-done?",
      "P-task": "loop php shell_exec : use php bash for-do-don",
      "F_verb": "use",
      "P-body": "Go for bash loop, because \"shell_exec\" function is called only once. It will be faster than calling \"shell_exec\" multiple times. Enabling functions like exec, shell_exec itself a huge security issue. If someone managed to upload a PHP shell in your server then he can hack your server. .  ",
      "P-tags": "bash for-loop php loop shell-exec",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_282881",
      "task": "How to call php or apache to render a page from the command line?",
      "P-task": "call php apach render page command line",
      "F_verb": "call",
      "P-body": "Can you just add it to Apache as a new virtualhost? The simplest way to get something to behave like a website is to treat it like a website. If you could just host this as a local website (eg only on the 127.0.0.1 interface) and wget it, that would probably be the cheapest and cleanest way to deal with this. .  Run it as a script with the \"php\" command You can run \"php example.php > output.html\" and that should work for most simple scripts. .  Note that this will use the php-cli configuration rather than \"mod_php\", \"php-fpm\", \"php-cgi\", etc configurations. That might be important if you have a funny setup. .  Edit: I saw this question yesterday that might be of use. It's aimed at wordpress but the same logic should apply for most things where you need to fake a real request. You set up a load of PHP's \"$_SERVER\" variables so your script (whatever that might be) can execute correctly\u2026 And then include your script. .  Use the PHP built-in server (requires PHP 5.4+) If you \"cd\" into your directory and run \"php -S localhost:9000\" you start a local server on port 9000 that will host your website. This is only for testing things like this and should never be exposed to the internet. .  This allows you to do a traditional \"wget\" lookup: .  From my previous (now deleted) answer, if you find yourself needing to spoof the domain name, \"wget\" will let you pass the host in. This comes in handy if the PHP is doing lookups on server variables. .  ",
      "P-tags": "php apache2 command-lin",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP S_INF from NP"
    },
    {
      "id": "ul_359224",
      "task": "Detect optional function argument (scalar)",
      "P-task": "detect option function argument scalar",
      "F_verb": "detect",
      "P-body": "Yes, you can do this: .  Result: .  ",
      "P-tags": "awk argument function",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_30873059",
      "task": "How to redirect Access Denied and all other errors in Powershell to a variable (Loop until command doesnt fail)",
      "P-task": "redirect access deni error powershel variabl loop command doesnt fail",
      "F_verb": "redirect",
      "P-body": "you can use -errorvariable .  Or if you want to do something with the error: .  then search the text file for your errors .  EDIT .  So a few things the actual correct use of errorVariable doesnt use the \"$\" so it would be \"-errorvariable myError\" .  If you want to search an error a better way to do it would be this: .  All errors can be found in \"$error\" and if you want to check that last error you use \"$error[0]\" which give you the last error that was received.  .  ",
      "P-tags": "powershel powershell-3 0",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP in NP to NP"
    },
    {
      "id": "so_46484956",
      "task": "Generating html page with css integration through AWK",
      "P-task": "gener html page css integr awk",
      "F_verb": "generate",
      "P-body": "  Solution : You have to escape quotes .  It seems your existing code, will put link, head, table and tr tag for each record read by awk, which does not produce html table correctly : .  Probably I guess you need below one: .  For example with test file .  It will output : .     \r  .  ",
      "P-tags": "shell html awk css",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP through NP"
    },
    {
      "id": "so_22850243",
      "task": "Need help understanding Linux kernel's BIOS interrupt calls",
      "P-task": "need help understand linux kernel bio interrupt call",
      "F_verb": "interrupt",
      "P-body": "Notice that the makefile specifies \"-mregparm=3\" for the compilation of 16 bit C code. This instructs the compiler to put the first 3 arguments into the registers \"eax\", \"edx\" and \"ecx\" if possible. So the value of \"dx\" is going to be the second argument, \"&iregs\". Also notice the comment further down that confirms this: \"/* Original %cx == 3rd argument */\" .  I find it kind of funny that you had no problem right at the start, about how \"al\" gets the value of the interrupt number :) .  ",
      "P-tags": "c linux-kernel assembl",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "au_657160",
      "task": "Automatically Run a Command/script at startup",
      "P-task": "automat run command script startup",
      "F_verb": "run",
      "P-body": "rc.local has solved this for me, and although I have read is outdated But kept around for compatibility, if somebody has the updated, but JUST AS SIMPLE answer, please share as I will update my server. .  You can use either calling a script in \"rc.local\" or directly run desired commands. Eg: .  Cheers! .  ",
      "P-tags": "boot server command-lin autostart",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP at NP"
    },
    {
      "id": "so_34610379",
      "task": "Powershell Recursively getting filtered list of files in directory",
      "P-task": "powershel recurs get filter list file directori",
      "F_verb": "get",
      "P-body": " I run the function passing: .   In argument mode, the PowerShell parser will treat each individual argument to a command like an expandable string unless it's told otherwise (see below), meaning that PowerShell ends up interpreting \"[\"*1*\"]\" as a string literal, and the \"-like\" operation inside the function behaves very differently from what you expect. .  Simply drop the square brackets: .   If you want to explicitly pass an array as an argument, use the array subexpression operator, \"@()\" (this will cause the parser to evaluate the argument as an expression and treat the output as an array, before binding it to a parameter): .  If your array needs to contain multiple values, separate by comma: .  or .   Another approach would be to declare the parameters in an inline \"Param()\" block and use the \"ValueFromRemainingArguments\" parameter attribute, this will let you supply an unbounded number of arguments to the command, much like \"params\" in C#: .  Now you can do: .  all you want .  ",
      "P-tags": "powershel window recurs",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "au_308285",
      "task": "/boot partition out of free space on standard install of 13.04",
      "P-task": "boot partit free space standard instal 13 04",
      "F_verb": "install",
      "P-body": "Try to use \"apt-get autoremove\" and see if that removes some of the older kernel packages. .  If that does not work, I would suggest you do what I've had to do before, find the kernel you're on now, that's working fine, then use \"apt-get purge <name_of_older_kernel_package>\" on the packages for the older kernels. .  This will remove all of those older kernels that you are not booting to any longer and may no longer be needed. .  ",
      "P-tags": "software-updat updat 13 04 boot encrypt",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V of NP"
    },
    {
      "id": "ul_343208",
      "task": "cron not running bash job",
      "P-task": "cron run bash job",
      "F_verb": "run",
      "P-body": "Quite late, but I figured the solution: run the script with the -l option. the cronjob will not run because of the variables I had setup on my login shell, also it will not log any errors. As per the man page: .   -l Make bash act as if it had been invoked as a login shell (see INVOCATION below). .   so my crontab will look like this: .  ",
      "P-tags": "script cron bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_60132876",
      "task": "Couldn't parse this elif clause",
      "P-task": "pars elif claus",
      "F_verb": "parse",
      "P-body": "1 - For assigning output of a command to a variable you can use two methods: .  2 - As you mention, \"var\" do not need any \"$\" and equal sign comes with no spaces. .  3 - The output of \"currentfile\" variable is in different lines, and \"if\" statement can't parse this.It's better to change it like this: .  4 - Also you should change your if statement with OR condition like this : .  5 - The \"then\" near line 32 is missing for \"elif\" section. .  6 - After third \"if\" section which is come with \"elif\" , it needs \"fi\" in order to close \"if\" section. .  7 - final \"if\" also look as array, so for checking in if condition, you should do something like this: .  8 - Your variable \"currentfiles\" contain line numbers . and moving to directory getting error. .  So you do need just a list like this: .  At the end, your code could be change like this: .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "ul_150698",
      "task": "virtualbox keeps showing error \"Kernel driver not installed\"",
      "P-task": "virtualbox keep show error kernel driver instal",
      "F_verb": "keep",
      "P-body": "Remember to use \"sudo\". Run it like this and it will work: .  see if it works now. .  I am trying to use it too. I had the same problem. I did the following in the terminal: .  I don't have a virtual machine yet, but this problem/error is solved for me after doing this. .  ",
      "P-tags": "virtualbox dkm",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V S_ING"
    },
    {
      "id": "su_398448",
      "task": "find files with ACLs set",
      "P-task": "find file acl set",
      "F_verb": "find",
      "P-body": "\"getfacl\" can dump ACLs recursively, and it has a \"--skip-base\" option for ignoring files without ACLs. .  ",
      "P-tags": "acl linux find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "so_61546835",
      "task": "How can I compare two hex strings in Bash?",
      "P-task": "compar two hex string bash",
      "F_verb": "compare",
      "P-body": "Use \"[[\". .  ",
      "P-tags": "type-convers bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP in NP"
    },
    {
      "id": "so_61079627",
      "task": "Compress-Archive handle files with same name in Powershell",
      "P-task": "compress-arch handl file name powershel",
      "F_verb": "handle",
      "P-body": "I would just copy the files along with their parent directories to a destination folder, then zip it up with \"Compress-Archive\". Then you don't have to worry about making filenames unique.  .  Demo: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_62618418",
      "task": "Rename multiple files in a directory by looping through a list of names in a .txt / .csv file for a partial match",
      "P-task": "renam multipl file directori loop list name txt csv file partial match",
      "F_verb": "rename",
      "P-body": " See if this works, it iterates through the csv then iterates through the directory to see if the directory's name is in the csv's line that is being iterated, then sets a variable to be the fullname of the file and renames it to the first name before the period. .  ",
      "P-tags": "batch-renam script loop powershel window",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP by S_ING through NP of NP in NP for NP"
    },
    {
      "id": "ul_188575",
      "task": "Why do du's subdirectory values not sum up to total?",
      "P-task": "du subdirectori valu sum total",
      "F_verb": "sum",
      "P-body": "The calls above miss large hidden files. Here is the result with \"du -a\" .  ",
      "P-tags": "linux command-lin disk-usag",
      "source": "qa",
      "cate": "cumulate/sum",
      "pat": "V up to NP"
    },
    {
      "id": "so_48361916",
      "task": "How to get more information from valgrind?",
      "P-task": "get inform valgrind",
      "F_verb": "get",
      "P-body": "The warning points to the allocation in \"dl-init.c\" line 72: .  I do not think, it is a problem in your code but the dynamic library loader. See this answer, for more details: c++ valgrind shows memory leak in hello world .  According to the bug report, it is fixed in gcc 6. When I tested with gcc 7.2.1 and clang 5.0.1, I also do not get the valgrind warning. .  ",
      "P-tags": "codeblock c++ valgrind linux-mint",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_219189",
      "task": "Is there a way to disable recursive make?",
      "P-task": "way disabl recurs make",
      "F_verb": "disable",
      "P-body": "No. If you invoke \"make\" even once in \"Makefile\", it would be called a recursive make. There's no easy option in GNU Make to prevent it. .  Once you read the paper mentioned in your post, you could understand it's determined by how you write \"Makefile\"s whether the make is recursive or non-recursive. .  Linux kernel build system would be one of the most famous applications of traditional recursive make in large scale. Android build system is a good example of non-recursive make, which is explicitly addressing problems of recursive make. Both build systems are exploiting GNU Make specific features intensively. .  ",
      "P-tags": "gnu-mak",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "ul_160086",
      "task": "How to start teamspeak server on reboot as specific user",
      "P-task": "start teamspeak server reboot specif user",
      "F_verb": "start",
      "P-body": "Found this solution: .  ",
      "P-tags": "daemon cento startup teamspeak",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP as NP"
    },
    {
      "id": "so_49324815",
      "task": "query errors out if ran from shell script",
      "P-task": "queri error ran shell script",
      "F_verb": "run",
      "P-body": "Single quotes cannot be included in a single-quoted string in shell. The single quotes around \"TRUE\" aren't included in the SQL command passed to \"impala-shell\"; the first closes the initial \"'\", and the second starts a new quoted string, so your script is equivalent to .  One solution is to use double quotes as I have above, which allow you to include the single quotes that SQL requires. .  Alternatively, use \"$'...'\" to quote the argument to \"-c\", in which case you can include properly escaped single quotes in the string. .  However it's not clear why you are using \"bash -c\" at all instead of just running \"impala-shell\" directly as: .  ",
      "P-tags": "sql impala shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V from NP"
    },
    {
      "id": "au_297361",
      "task": "Programs look ugly with ClearLooks-Phenix theme, how to fix?",
      "P-task": "program look ugli clearlooks-phenix theme fix",
      "F_verb": "fix",
      "P-body": "\"gtk2-engines\" probably became uninstalled somehow; run \"sudo apt-get install gtk2-engines\" to fix it. .  ",
      "P-tags": "gtk3 13 04 gtk-2 gtk theme",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "au_453096",
      "task": "Why was the virtualbox package removed from the 14.04 repository?",
      "P-task": "virtualbox packag remov 14 04 repositori",
      "F_verb": "remove",
      "P-body": "In Ubuntu 14.04, Virtualbox package version 4.3.10 is available in \"multiverse\" repository. So enable multiverse repository and install virtualbox through \"apt-get\". .  How i know that information? .  ",
      "P-tags": "apt virtualbox release-manag",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V from NP"
    },
    {
      "id": "au_431478",
      "task": "Decompressing multiple files at once",
      "P-task": "decompress multipl file",
      "F_verb": "decompress",
      "P-body": "If you really want to uncompress them in parallel, you could do .  That however, will launch N processes for N .zip files and could be very heavy on your system. For a more controlled approach, launching only 10 parallel processes at a time, try this: .  To control the number of parallel processes launched, change \"-P\" to whatever you want. If you don't want recurse into subdirectories, do this instead: .  Alternatively, you can install GNU parallel as suggested by @OleTange in the comments and run .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP at NP"
    },
    {
      "id": "au_644289",
      "task": "Can't open synaptic package manager after installing get deb",
      "P-task": "open synapt packag manag instal get deb",
      "F_verb": "open",
      "P-body": "You can fix it using this: .  searched for 'trusty' and replaced it with Your Ubuntu codename. .  You can get your ubuntu codename by running command: .  Once you've done then run the command: .  Now synaptic must run again. .  Source: https://answers.launchpad.net/ubuntu/+source/synaptic/+question/213406 .  ",
      "P-tags": "package-manag",
      "source": "qa",
      "cate": "open",
      "pat": "V NP after S"
    },
    {
      "id": "su_416536",
      "task": "Create a tar and splitting it into multiple archives then putting them back together",
      "P-task": "creat tar split multipl archiv put back togeth",
      "F_verb": "create",
      "P-body": "Leave off the \"tar\" part entirely. .  ",
      "P-tags": "bash-script linux gz archiv tar",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "su_788289",
      "task": "Creating remote user to launch one file",
      "P-task": "creat remot user launch one file",
      "F_verb": "create",
      "P-body": "I could not create a passwordless user, but I created one with username and password programname and in the /etc/ssh/sshd_config file I added \"Match User testuser\"and \"ForceCommand python /path/file.py\" That way anyone can log in (the login info is in the web site at that server) see the program and then log out automatically when the program closes.  .  ",
      "P-tags": "linux user-account debian ssh",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_470839",
      "task": "How can I choose the audio output device using the terminal?",
      "P-task": "choos audio output devic use termin",
      "F_verb": "choose",
      "P-body": "Sure, you could use the \"pactl\" and \"pacmd\" command. .  An example for a pair of external USB speaker + internal speakers, with music playing. .  The first one with index 0 is the internal speak, music is running on this sink. Another one with index 1 is the external USB speaker. .  If you're not palying anything during the switch, you could stop here.  .  (Note, to make sure it really works, it would be better to do this with something playing, and move the stream as follows.) .  If you're playing something you will notice that the music still running on the old device, you have to move it to the desired device: .  Voil\u00e0! You could compose a script base on these. .  Reference: How to change pulseaudio sink with \u201cpacmd set-default-sink\u201d during playback? .  ",
      "P-tags": "output sound command-lin",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP using NP"
    },
    {
      "id": "so_29470527",
      "task": "How can I set the initial value of a Switch Button on a Gambas Qt application?",
      "P-task": "set initi valu switch button gamba qt applic",
      "F_verb": "set",
      "P-body": "You need to do the status check inside \"Form_Open()\": .  ",
      "P-tags": "linux functional-program qt variabl gamba",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP on NP"
    },
    {
      "id": "so_27296203",
      "task": "Adding members to local groups by SID in multiple languages",
      "P-task": "ad member local group sid multipl languag",
      "F_verb": "add",
      "P-body": "Question is simple, once asked correctly, and answer is to be found here: Microsoft Supprt: NET /ADD command . If \"NET\" limit is 20 characters, and \"Autentiserade anv\u00e4ndare\" is 24 characters, it's not supposed to work. Workaround is to be found in the same link. .  ",
      "P-tags": "powershel sid",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP by NP in NP"
    },
    {
      "id": "so_8197477",
      "task": "How to make Java app detect that the Linux PC has resumed from suspended state (sleep mode)?",
      "P-task": "make java app detect linux pc resum suspend state sleep mode",
      "F_verb": "make",
      "P-body": "Here's what the Canonical support engineer suggested.  .   20/11/2011 22:53 | Jason My suggestion is to create a script under the /etc/pm/sleep.d/. The script will be execute when resume from suspend. Please reference to the /usr/share/doc/pm-utils/HOWTO.hooks.gz for the details. .   Here's the intro from that file: .  How to write a pm-utils hook: .  PARAMETERS .  A pm-utils hook is simply an executable file that accepts at least one parameter.  .  For hooks in sleep.d, the potential values of the first parameter are: .  suspend -- The hook MUST perform whatever action is appropriate when the system is preparing for memory sleep (or its equivalent). .  resume -- The hook MUST perform whatever action is appropriate when the system is coming out of suspend. .  hibernate -- The hook MUST perform whatever action is appropriate when the system is preparing for suspend-to-disk. .  thaw -- The hook MUST perform whatever action is appropriate when the system is coming out of suspend-to-disk. .  help -- If your hook parses the PM_CMDLINE environment variable for switches, this function SHOULD output text describing the parameters it parses in a format easily understandable by an end-user. .  The actual sleep method being used will be passed as the second parameter -- if your hook needs to handle suspend-hybrid (or any other platform-specific sleep method), it should examine the second parameter. .  For hooks in power.d, the potential values of that parameter are: true -- the hook MUST perform whatever action is appropriate when the system transitions TO battery power. false -- The hook MUST perform whatever action is appropriate when the system transitions FROM battery power. .  And here's an example: .  ",
      "P-tags": "suspend linux java",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP that S"
    },
    {
      "id": "so_23331832",
      "task": "pointer problems when trying to build a directory tree in memory",
      "P-task": "pointer problem tri build directori tree memori",
      "F_verb": "build",
      "P-body": "When you allocate space for \"new_path\" you need to add 2 (one for the slash, one for the null terminator). And you never close the directories you open (use closedir()). .  An even more serious error is this line: .  which only allocates nchild bytes, not enough to hold nchild pointers! Try: .  ",
      "P-tags": "linux tree c unix",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_68453714",
      "task": "Using a loop to execute several yarn scripts",
      "P-task": "use loop execut sever yarn script",
      "F_verb": "use",
      "P-body": "I have just found the answer to my question : .  \"eval \"$script\"\" .  as my array of scripts holds only strings as I understand it. .  ",
      "P-tags": "loop bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_7843974",
      "task": "Does apt-get work to install Clojure on Linux (ubuntu 10)?",
      "P-task": "apt-get work instal clojur linux ubuntu 10",
      "F_verb": "get",
      "P-body": "To summarize the comments:  .  Yes, apt-get works \u2013  .  ... BUT it it is not the preferred way to install Clojure.  .  So ... whats the \"right\" way to install Clojure ? .  Leiningen remains the up-to-date, conventional way to rapidly get a Clojure installation up and running.  .  The steps are as follows :  .   copying this shell script: https://raw.github.com/technomancy/leiningen/stable/bin/lein moving it to \"/usr/local/bin\" calling \"sudo chmod +x /usr/local/bin/lein\".  Make sure you have Java installed first, of course.  .  These steps will install Clojure on any platform with the latest version. .  ",
      "P-tags": "clojur ubuntu instal",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF on NP"
    },
    {
      "id": "ul_157292",
      "task": "How can I get a full list of software installed on a non-functioning system, from its disk mounted on a new one?",
      "P-task": "get full list softwar instal non-funct system disk mount new one",
      "F_verb": "get",
      "P-body": "Mount the old drive, e.g. under \"/mnt/old\" and then do: .  \"dpkg\" has facilities built-in to install/list/de-install on a filesystem not based directly under \"/\". .  ",
      "P-tags": "migrat",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP on NP from NP on NP"
    },
    {
      "id": "so_34824938",
      "task": "awesome wm - how to bind a key to another key",
      "P-task": "awesom wm - bind key anoth key",
      "F_verb": "bind",
      "P-body": "Finally, I found a not perfect solution. First, install \"xdotool\", I'm using \"ArchLinux\", so: .  And edit \"~/.config/awesome/rc.lua\" .  But somehow it will just input \"j\", and I don't know why. .  ",
      "P-tags": "awesome-wm linux keyboard-shortcut",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP to NP"
    },
    {
      "id": "so_24977969",
      "task": "Sed cannot convert uppercase to lowercase",
      "P-task": "sed convert uppercas lowercas",
      "F_verb": "convert",
      "P-body": "I am going to assume that you do not have GNU sed and therefore do not have access to \"\\L\". Instead, try perl: .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_166873",
      "task": "How can I delete all text between curly brackets in a multiline text file?",
      "P-task": "delet text curli bracket multilin text file",
      "F_verb": "delete",
      "P-body": " Explanation: .   \":again;$!N;$!b again;\" .  This reads the whole file into the pattern space. .  \":again\" is a label. \"N\" reads in the next line. \"$!b again\" branches back to the \"again\" label on the condition that this is not the last line. .  \"s/{[^}]*}//g\" .  This removes all expressions in braces. .   On Mac OSX, try: .  Nested Braces Let's take this as a test file with lots of nested braces: .  Here is a modification to handle nested braces: .  Explanation: .   \":again;$!N;$!b again\" .  This is the same as before: it reads in the whole file. .  \":b\" .  This defines a label \"b\". .  \"s/{[^{}]*}//g\" .  This removes text in braces as long as the text contains no inner braces. .  \"t b\" .  If the above substitute command resulted in a change, jump back to label \"b\". In this way, the substitute command is repeated until all brace-groups are removed. .   ",
      "P-tags": "awk grep sed text-process",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP between NP in NP"
    },
    {
      "id": "so_63661729",
      "task": "How to parse a file and return a string following a keyword when diliminater appears more than once",
      "P-task": "pars file return string follow keyword diliminat appear",
      "F_verb": "parse",
      "P-body": " ",
      "P-tags": "sed linux shell bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_26964718",
      "task": "Using a variable in an awk Bourne shell script",
      "P-task": "use variabl awk bourn shell script",
      "F_verb": "use",
      "P-body": "Change: .  to: .  and read http://www.gnu.org/software/gawk/manual/gawk.html#Computed-Regexps .  ",
      "P-tags": "awk sh shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_32890401",
      "task": "Find features/cmdlets not supported in PowerShell V2",
      "P-task": "find featur cmdlet support powershel v2",
      "F_verb": "find",
      "P-body": "I cant really suggest off site resources as that would not make for a good answer. Also haven't found a good dupe for this generalization either.  .  There is a way that I can suggest help you get the newer features out of your code. While you are coding in 3.0, with features that I would miss if I didn't have them, you can test your code by running PowerShell with the \"-Version\" switch .  So my suggestion here is test your code in the lower version. If/When it breaks you can troubleshoot those individual parts. If you still are stuck it could be another good question to ask.  .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_619390",
      "task": "Why i3 doesn't read its config files (they exist) and starts with defaults?",
      "P-task": "i3 read config file exist start default",
      "F_verb": "start",
      "P-body": "How about \"i3 -C\" or \"i3 -c <file>\" reports? .  By default it should be \"$HOME/.config/i3/config\". .  ",
      "P-tags": "i3 x11",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V with NP"
    },
    {
      "id": "su_1118480",
      "task": "Newly created directories inherit group permissions from parent",
      "P-task": "newli creat directori inherit group permiss parent",
      "F_verb": "create",
      "P-body": "Use POSIX ACLs \u2013 set a \"default\" ACL of \"group::rwx\" on the directory: .  ",
      "P-tags": "linux permiss",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "so_47738004",
      "task": "Find files by given pattern and grep for whole word count matching the search string pattern and ignoring some pattern and print along with file name",
      "P-task": "find file given pattern grep whole word count match search string pattern ignor pattern print along file name",
      "F_verb": "find",
      "P-body": "If I understand correctly, you are looking two make two changes: .   Exclude lines that contain \"throws\" Exclude lines that don't start with \"2017-12-09 \"  You could use a \"zgrep\" to match the lines that you want (start with \"2017-12-09 \" and contain \"xception\"), and then an \"awk\" to exclude the lines that you don't want (contains \"throws\"), and exclude parts of the lines that you don't want (text between filename and the exception name): .  This should work with the GNU implementation of \"awk\". .  After your further clarification, you want to turn a line like this: .    To lines like this: .  That's possible, using a different tool of \"awk\", the \"match\" function, which returns the starting position of a match, and 0 when there are no more matches. We can call it repeatedly, with appropriately modified parameters, as long as there are matches, and print the output as we go: .  ",
      "P-tags": "awk grep unix regex bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP by NP"
    },
    {
      "id": "so_27623073",
      "task": "Populate an array using dynamic variables names in Powershell",
      "P-task": "popul array use dynam variabl name powershel",
      "F_verb": "populate",
      "P-body": "Just because of your other question I have built this to output the random numbers in the matrix block. It uses \"$width\" and \"$height\" to define the size of \"$theMatrix\" which is built as an array of string arrays.  .  This will build a matrix of random numbers. I think this is visually important to you so I converted the numbers to string so that I could use \"PadLeft\" when single digits are encountered to make the output look cleaner. In the end use \"$_ -Join \"|\"\" to display the matrix in its readable form. Feel free to change the delimiter to a comma or something else.  .  Sample Output .  ",
      "P-tags": "powershel matrix popul dynamic-vari",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP using NP in NP"
    },
    {
      "id": "so_35823211",
      "task": "What happens in the kernel when the process accesses an address just allocated with brk/sbrk?",
      "P-task": "happen kernel process access address alloc brk sbrk",
      "F_verb": "happen",
      "P-body": "Well, after finally finding an excellent guide (http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/) and some hours digging the Linux kernel, I found the answers... .   Indeed, \"brk\" only pushes the virtual memory area. When the user application hits \"*allocated_integer = 5;\", a page fault occurs. The page fault routine will search for the virtual memory area responsible for the address and then call the page table handler. The page table handler goes through each level (2 levels in x86 and 4 levels in x86_64), allocating entries if they're not present (2nd, 3rd and 4th), and then finally calls the real handler. The real handler actually calls the function responsible for allocating page frames.  ",
      "P-tags": "virtual-memori linux-kernel memory-manag",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V in NP when S"
    },
    {
      "id": "so_62838673",
      "task": "Awk permission denied when run through msmtp",
      "P-task": "awk permiss deni run msmtp",
      "F_verb": "deny",
      "P-body": "Thanks to advice from marlam I found out that this issue is due to an overly restrictive AppArmor profile for msmtp. I am led to assume that my new OS version is more stringent with regards to usage of msmtp (good thing I guess). Unfortunately this often happens on Debian and Ubuntu and it confuses many users. The commands I've used to solve it are .  ",
      "P-tags": "awk bash msmtp email gnupg",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V when S"
    },
    {
      "id": "so_18602234",
      "task": "Sed to remove everything after \".\" in file using * command?",
      "P-task": "sed remov everyth\nfile use command",
      "F_verb": "remove",
      "P-body": "Either escape the \".\" with a backslash to get a literal \".\", or use brackets to define a character class: .  You tried \"'s/\\.*//'\", which is \"zero or more literal dots\", which is different from \"literal dot followed by zero or more of anything\", i.e. \"'s/\\..*//'\". I also added a \"$\" for good measure. .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP after NP in NP using NP"
    },
    {
      "id": "au_1272199",
      "task": "What is the correct way to use specific DNS servers if using DHCP in a no-desktop Ubuntu 20.04 install, and can you use DNS over TLS?",
      "P-task": "correct way use specif dn server use dhcp no-desktop ubuntu 20 04 instal use dn tl",
      "F_verb": "use",
      "P-body": "Ok, you have several questions rolled into one: .  DNS-over-TLS (DoT) .  Ubuntu provides the \"stubby\" package which is one of the de-facto standard DoT daemons. Just run \"apt install stubby\" and you should be good to go. .  DHCP DNS Overrides .  As chili555 pointed to in the comments, you want to use the dhcp4-overrides -> use-dns option to disable the use of DHCP-provided DNS servers. .  Using Stubby .  As you already encountered, systemd-networkd will start its own DNS resolver (systemd-resolved) by default. If you want to run Stubby, they'll both want to bind on port 53 which will cause an error. You have two options: .   Disable systemd-resolved and configure netplan.io to use 127.0.0.1 as your DNS override server. This has the downside of disabling DNS caching (I think). Tell Stubby to bind on a different localhost IP and/or port using the \"listen_addresses\" variable in \"/etc/stubby/stubby.yml\" and then tell \"netplan.io\" to use a dns override to point it at that new IP/port.  ",
      "P-tags": "dn network server tl 20 04",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP if S"
    },
    {
      "id": "so_63723693",
      "task": "Escaping slashes in sed",
      "P-task": "escap slash sed",
      "F_verb": "slash",
      "P-body": "What those snippets show is that you can use basically any character as a delimiter for the command. \"s\" is the command and the character afterwards is the delimiter. It is used to separate the \"options\" for \"s\" from each other. .  \"s\" takes three options, the thing that is to be replaced (a regex), the thing that it is replaced with (a string) and flags like \"g\" for example. You added a \"/\" in the last place which is interpreted as a flag, but the \"/\" is not a valid flag. That is what is causing the error. .  When you use something that is not a slash as the delimiter, the slash does not have any special meaning to \"sed\". .  ",
      "P-tags": "ubuntu sed bash",
      "source": "qa",
      "cate": "cut/slash/separate/clip/crop",
      "pat": "V in NP"
    },
    {
      "id": "so_69497150",
      "task": "Issue Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA",
      "P-task": "issu cpu support instruct tensorflow binari compil use : avx2 fma",
      "F_verb": "issue",
      "P-body": "If when forcing the \"os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\" doesn't work, then this means that your tensorflow gpu installation did not succeed. You must ensure you have the right combination of \"TensorFlow\" + \"CUDA\" + \"CUDNN\". That is why you get the error, because due to improper versions/installation TF falls back on CPU. .  ",
      "P-tags": "linux tensorflow qsub",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP that S"
    },
    {
      "id": "so_55643041",
      "task": "How do I rename files found with the find command",
      "P-task": "renam file found find command",
      "F_verb": "find",
      "P-body": "Try: .  How it works: .   \"-execdir bash -c '...' Mover {} \\;\" .  This starts up bash and tells it to run the command in the single quotes with \"Mover\" assigned to \"$0\" and the file name assigned to \"$1\". .  \"mv -i -- \"$1\" \"${1//_/}\"\" .  This renames file \"$1\". This uses bash's parameter expansion feature, \"${1//_/}\", to create the target name from \"$1\" by removing all underlines. .  The option \"-i\" tells \"mv\" to ask interactively before overwriting a file. .  The option \"--\" tells \"mv\" that there are no more options. This is needed so that files whose names begin with \"-\" will be processed correctly. .   Example Let's start with a directory with these files: .  Next we run our command: .  After the command completes, the files are: .  The purpose of \"$0\" Observe this command where we have added an error: .  Note that \"Mover\" appears at the beginning of the error message. This signals that the error comes from within the \"bash -c\" command. .  If we replace \"Mover\" with \"-\", we would see: .  When running a single command in a terminal, the source of the error may still be obvious anyway. If this \"find\" command were buried inside a long script, however, the use of a more descriptive \"$0\", like \"Mover\" or whatever, could be a big help. .  ",
      "P-tags": "renam find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "su_521307",
      "task": "How can I repair my USB drive?",
      "P-task": "repair usb drive",
      "F_verb": "repair",
      "P-body": "I found a useful thread. They ran \"hdparm -r0 /dev/sdb\" to try to force the r/w on the drive. .  If that fails, I'd try plugging the usb device in while running gparted. You could see if gparted throws any errors about the drive. .  ",
      "P-tags": "usb linux usb-storag",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_60407085",
      "task": "Most efficient way to perform exception handling in bash?",
      "P-task": "effici way perform except handl bash",
      "F_verb": "perform",
      "P-body": "Enclose it inside a \"while loop\" .   the while read loop should be enough. The \"\"${response:-empty}\"\" is form of P.E. parameter expansion.  ",
      "P-tags": "except perform valid input bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_88452",
      "task": "Concatenating two variables with an underscore",
      "P-task": "concaten two variabl underscor",
      "F_verb": "concatenate",
      "P-body": "You can use something like this: .  This works as well: .  ",
      "P-tags": "shell-script bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP"
    },
    {
      "id": "su_242928",
      "task": "Disable linux read and write file cache on partition",
      "P-task": "disabl linux read write file cach partit",
      "F_verb": "write",
      "P-body": "there is a solution which perfectly fits your use case: http://code.google.com/p/pagecache-mangagement/ .  After checking out the source code:  .  issue .  then, you can start whatever application you want with .  and the App won't fill up your caches! .  ",
      "P-tags": "mount linux cach",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP on NP"
    },
    {
      "id": "so_18057428",
      "task": "Suppressing sh script output when using <<END",
      "P-task": "suppress sh script output use end",
      "F_verb": "suppress",
      "P-body": "You can accomplish it redirecting the output of \"bc\" to \"/dev/null\": .  Note that using \"& > /dev/null\" both stdout and stderr will be sent to \"/dev/null\", so not output will appear at all. .  ",
      "P-tags": "sh output suppress shell",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP when S"
    },
    {
      "id": "ul_378359",
      "task": "How to use UART pins on Orange Pi zero?",
      "P-task": "use uart pin orang pi zero",
      "F_verb": "use",
      "P-body": "My config on Orange Pi Zero for UART on mainline kernel: .  Both UARTs work fine. .  ",
      "P-tags": "uart armbian",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_272541",
      "task": "Is it possible to declare a local variable without overriding the original for the child processes?",
      "P-task": "possibl declar local variabl without overrid origin child process",
      "F_verb": "declare",
      "P-body": "A common convention is to use all-uppercase for environment variables and all-lowercase for script local variables. This way a local variable never clashes with an environment variable. .  I don't think zsh has an option to distinguish between the local value and the exported value of a variable. A workaround is to save and restore the value. That does mean listing the variables you want to save. .  If you want to preserve the whole environment, you can run \"typeset -px\" to print it out in a parseable form. Note that this won't work if you have exported read-only variables; to handle that case, you'd need to go through the variable names and select only the ones that aren't read-only. .  Another option is to structure your script differently. Determine the command you want to run in a subshell, and print it out (suitably quoted) for the parent to execute. .  ",
      "P-tags": "shell-script zsh",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP without S_ING"
    },
    {
      "id": "au_750216",
      "task": "set new icon for rxvt-unicode",
      "P-task": "set new icon rxvt-unicod",
      "F_verb": "set",
      "P-body": "I was able to pretty much fix my problem. I made edits to the rxvt-unicode.desktop file changing the icon to one of my choosing. At that point I was able to see the new icon when loading rxvt-unicode from the unity launcher or sidebar. Information on finding the .desktop files can be found here: How can I find *.desktop files? .  One thing I noticed though is if I use another terminal to launch rxvt-unicode it still shows the old icon. Not sure yet why that is happening. This only has become a problem because I created a keyboard shortcut to make \"Super+q\" launch a terminal and it does that through the terminal as far as I can tell. .  ",
      "P-tags": "icon custom command-lin",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_18762621",
      "task": "Can we use C code in Python?",
      "P-task": "use c code python",
      "F_verb": "use",
      "P-body": " I want to invoke those C function or executables in python. Is that possible. .   Yes, you can write C code that can be imported into Python as a module. Python calls these extension modules. You can invoke it from Python directly, an example from the documentation: .  Python Code .  C Code .   If I want the C code to be a library, which means I use it with #include and linkage of the *.o likely in python, how to do it or is that possible. .   You build it as a shared library *.dll or *.so You can also investigate using distutils to distribute your module. .   If I write the C code into executable, which means it becomes a command, can I invoke it in python directly? .   If you write a *.exe then you are doing the opposite (invoking Python from C). The method you choose (exe vs shared library) depends on if you want a \"C program with some Python\" or a \"Python program with some C\". .   Also, I heard that python code can be compiled, does that mean we can execute the code without the source file? Are the output files binary files? Does it improve performance? .   Python reads *.py files and compiles to *.pyc bytecode files when you run it. The bytecode is then run in the Python virtual machine. This means \"executing the same file is faster the second time as recompilation from source to bytecode can be avoided.\" (from the Python glossary) So if you haven't edited your *.py files, it will run the *.pyc. You can distribute *.pyc files without *.py files, however they are not encrypted and can be reverse-engineered. .  ",
      "P-tags": "linux c python compiler-construct",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_53984688",
      "task": "Running a Spring Boot app from Docker is not working",
      "P-task": "run spring boot app docker work",
      "F_verb": "run",
      "P-body": "If the posted Dockerfile the file you are using then there is a wrong quote sign just before java: .  ",
      "P-tags": "linux docker spring-boot",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_28954236",
      "task": "Why the command executed is not that command found by \"which\"",
      "P-task": "command execut command found",
      "F_verb": "execute",
      "P-body": "This typically happens after you've removed a command that used to be there. For efficiency reasons, \"bash\" doesn't scan the \"PATH\" every single time you run any command. Instead, it remembers the last location and avoids the lookup the next time. .  You can make it forget all remembered locations with .  Afterwards, \"svn --version\" should find the new location. .  ",
      "P-tags": "shell svn maco",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_48081562",
      "task": "bash add git command result to local variable",
      "P-task": "bash add git command result local variabl",
      "F_verb": "add",
      "P-body": "To assign the output of a command to a variable, you need to use command-substitution syntax in \"bash\".  .  What you have done is stored the literal string in those local variables defined. When shell was tokenizing them to evaluate it has understood it as a variable assignment gone horribly wrong! What it understood is a \"local\" variable in the name of \"currentBranch\" set to a value \"git\" and tries to run \"rev-list\" as a command which it cannot obviously find in its list of standard paths (under \"$PATH\") .  ",
      "P-tags": "git bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_674234",
      "task": "Is it possible to perform a command on string stored inside a variable?",
      "P-task": "possibl perform command string store insid variabl",
      "F_verb": "perform",
      "P-body": "The \"cut\" utility reads data from its standard input stream, it does not operate on strings given as arguments. .  To use \"cut\", therefore, you need to pass the data on standard input: .  However, that would be very slow in a loop. Instead, use a built-in parameter substitution to delete everything after the first \"/\" in the \"$DATE\" string: .  This removes the longest suffix string from \"$DATE\" that matches the shell pattern \"/*\". If the string is \"2021/10/21\", then this returns \"2021\". .  To get the first four characters of every file in a directory (which is the essence of what I believe your current code is attempting to do), you could use \"sed\" like so: .  This reads in the first line of each file, replaces the contents of the line with the first four characters of the line, and then quits after outputting the result to the terminal. .  ",
      "P-tags": "script shell-script",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP inside NP"
    },
    {
      "id": "au_209702",
      "task": "Why is my RAID /dev/md1 showing up as /dev/md126? Is mdadm.conf being ignored?",
      "P-task": "raid dev md1 show dev md126\nmdadm conf ignor",
      "F_verb": "ignore",
      "P-body": "I found the answer here, RAID starting at md127 instead of md0. In short, I chopped my /etc/mdadm/mdadm.conf definitions from:  .  to: .  and ran: .  I am far from an expert on this, but my understanding is this ...  .  The kernel assembled the arrays prior to the normal time to assemble the arrays occurs. When the kernel assembles the arrays, it does not use mdadm.conf. Since the partitions had already been assembled by the kernel, the normal array assembly which uses mdadm.conf was skipped. .  Calling \"sudo update-initramfs -u\" tells the kernel take a look at the system again to figure out how to start up.  .  I am sure someone with better knowledge will correct me / elaborate on this. .  Use the following line to update the initrd for each respective kernel that exists on your system: .  ",
      "P-tags": "mdadm",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "so_37278705",
      "task": "how to move only files to subdirectory in linux",
      "P-task": "move file subdirectori linux",
      "F_verb": "move",
      "P-body": "You can use \"find(1)\". .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_59050448",
      "task": "Combine multiple files into one including the file name",
      "P-task": "combin multipl file one includ file name",
      "F_verb": "combine",
      "P-body": "Could you please try following. Considering that your Input_file names extensions are \".csv\". .  After seeing OP's comments if file extensions are \".txt\" then try: .  ",
      "P-tags": "awk cat shell bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP into NP"
    },
    {
      "id": "au_173206",
      "task": "How do I install drivers for the Panasonic MB1900CX All-in-One Printer/Scanner?",
      "P-task": "instal driver panason mb1900cx all-in-on printer scanner",
      "F_verb": "install",
      "P-body": "1. Installing the 64-bit printer driver: You can download it from the Panasonic webpage you linked. Here's how to install the 64-bit driver: .   Open a terminal with \"Ctrl+Alt+T\", and type/paste the following line-by-line: .   You should see output like the below, after which the driver will be installed. Once it's working, you can renmove the \"mccgdi...\" folder from Nautilus. .    2. Installing the 32-bit scanner driver on 64-bit Ubuntu  There is no guarantee this will actually work, since I don't have a MB1900CX to test it... You have already installed \"ia32-libs\" so you shouldn't need the following, but if \"dpkg\" complains trying to install the scanner drivers, you should do the following in a terminal: .   Download the 32-bit Panasonic libsane driver with: .   And install it with: .   If all goes well, you will see output like the below, and your scanner functions should also work: .    ",
      "P-tags": "print sane",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP"
    },
    {
      "id": "su_594276",
      "task": "A specific Google Talk account isn't going online with Telepathy client on KDE",
      "P-task": "specif googl talk account go onlin telepathi client kde",
      "F_verb": "go",
      "P-body": "The reason of the problem was so silly (and so obviously solvable) that I'm almost embarassed by having had that issue. .  Quoting from the KDE Community Wiki .   I keep being told \"Authentication Failed\"  .  Make sure you have telepathy-auth-handler installed. Do you have Empathy installed? If so remove it. Also check all the steps in the following section.  .   \"telepathy-auth-handler\" was present in my system, and Empathy is not installed, so I went on: .   Google Talk disconnects with Network Error shortly after connecting .  You need to check if your avatar (user picture) is small enough. Maximum file size allowed is 8192 bytes, maximum allowed dimensions for avatars are 96x96. .   After having changed the avatar picture to a proper one, the account works properly. .  ",
      "P-tags": "linux google-talk instant-messag kde",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "au_1041372",
      "task": "How to change display resolution and scaling using the command line",
      "P-task": "chang display resolut scale use command line",
      "F_verb": "change",
      "P-body": "This is an X Server solution and may not work with Wayland. .  You can use \"randr\" for that, just determine the output name and available modes with \"xrandr\" and use the \"--mode\" and \"--scale\" options to change the settings. Provided this mode already exists, this would change the output DP2 to 3840x2160 with 200% scaling: .  This changes to 1024x768 with 100% scaling: .  Further reading: .   \"man xrandr\" How do I change the screen resolution using Ubuntu command line?   To automate this I\u2019d use \"xdotool\", e.g. to call \"xrandr\" as soon an \"xterm\" window gets focus: .  ",
      "P-tags": "scale script hdpi display-resolut",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_91067",
      "task": "Fedora 19 install hard drives not visible",
      "P-task": "fedora 19 instal hard drive visibl",
      "F_verb": "install",
      "P-body": "I don't have a GPT disk so this is just a guess, but that may be why fdisk has a problem -- it did not support GPT until last year. However, I notice that is dated several months after the last stable util-linux (the source package which includes fdisk), 2.21, which is the fdisk here on my fedora 17 system. You can check this with \"fdisk -v\". .  That post seems to refer to a version 2.3.1 which is not available? The last branch on git looks like 2.23. .  So most likely your fdisk does not support GPT, and the version which does is apparently not ready for public consumption. However, \"gdisk\", \"an fdisk like partitioning tool for GPT disks\" is available in the fedora repos (in fact, it is already on my system, so perhaps it is part of a base install). If you can use that from a live CD, you can set up the partitions yourself and tell the installer to skip that step. .  Googling around, it seems that F19 should support a GPT install, but some people have had problems... .  ",
      "P-tags": "live-usb fedora software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_609398",
      "task": "Is there a Magnifier app for Ubuntu? I want to use a bounding box with the mouse on a part of the screen and magnify it for our eyes to Zoom",
      "P-task": "magnifi app ubuntu\nwant use bound box mous part screen magnifi eye zoom",
      "F_verb": "use",
      "P-body": "Please see the following related answer: .  Default screen magnifier? .  The accessibility settings in 14.04 appear to have been changed to only include \"enhanced zoom desktop\", but you may find this a suitable alternative to a magnifier.  .  After installing \"compizconfig-settings-manager\" per the linked answer, you will want to configure the enhanced desktop zoom such that you have a zoom in and zoom out key, at a minimum. From there, you can zoom as needed. The zoom follows your mouse as well, making it somewhat similar to a magnifier. .  ",
      "P-tags": "14 04 compiz access display",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP on NP of NP"
    },
    {
      "id": "au_696507",
      "task": "How can I get avahi-autoipd to get an address on an alias, regardless of the state of the interface?",
      "P-task": "get avahi-autoipd get address alia regardless state interfac",
      "F_verb": "get",
      "P-body": "I looked at the ifupdown source and definition file and the ipv4ll interface type is just a manual up/down wrapper. You can configure an avahi-autoipd interface in /etc/network/interfaces as a manual type: .  If you have eth0 configured for dhcp then you also need to comment out the line in /etc/dhcp/dhclient-enter-hooks.d/avahi-autoipd that causes the avahi interface to be killed off when dhcp configures itself. Once you do these things then you will be able to use an eth0 and eth0:0 (which gets renamed to eth0:avahi after you ifup eth0:0, oddly). .  ",
      "P-tags": "network avahi",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF on NP"
    }
  ],
  "8": [
    {
      "id": "ul_535278",
      "task": "How can I prevent a TTY (e.g. /dev/tty1) from writing to the framebuffer (/dev/fb0)?",
      "P-task": "prevent tti e g\ndev tty1 write framebuff dev fb0",
      "F_verb": "prevent",
      "P-body": "To stop /dev/tty1 from overwriting the buffer I'm using .  \"systemctl stop getty@tty1.service\" and then make the cursor invisible with.. .  \"/usr/bin/tput civis > /dev/tty1\" .  This allows me access to console after reboot should I lose access via ssh. .  ",
      "P-tags": "tti framebuff",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING to NP"
    },
    {
      "id": "so_56199472",
      "task": "Replace string with own contents within bash",
      "P-task": "replac string content within bash",
      "F_verb": "replace",
      "P-body": " ",
      "P-tags": "awk text-process regex bash sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP within NP"
    },
    {
      "id": "ul_303788",
      "task": "Understanding read built-in",
      "P-task": "understand read built-in",
      "F_verb": "build",
      "P-body": "what is your goal? echo is executable (\"/bin/echo\"), read is builtin. -e means execute an executable. If you wanna use a builtin function of your shell (bash?) use \"urxvt -e /bin/bash -c read -r CMD\" .  ",
      "P-tags": "read shell-script",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V in"
    },
    {
      "id": "au_997920",
      "task": "How to execute ubuntu command in python code?",
      "P-task": "execut ubuntu command python code",
      "F_verb": "execute",
      "P-body": "Editing dconf/gsettings from python You really shouldn't use \"os.system()\" for system calls anymore, it has been deprecated and totally outdated for a long time. .  There are different options to edit the \"dconf\" database. .  Using subprocess Say I have a \"dconf\" path \"/com/gexperts/Tilix/keybindings/app-shortcuts\", I can use: .  Mind the quoting! .   In most cases however, you will also be able to use (better)\"gsettings\". Use \"Gio.Settings\" if the value also can be set from \"gsettings\". .   Using Gio.Settings See also https://lazka.github.io/pgi-docs/#Gio-2.0/classes/Settings.html#Gio.Settings and https://people.gnome.org/~gcampagna/docs/Gio-2.0/Gio.Settings.html .  About gsettings/dconf Preferences on modern Ubuntu versions are mostly stored in the \"dconf\" database in binary format. These settings can be edited directly by \"dconf\" (cli), or \"dconf-editor\" (gui). Dconf is low level, and directly editing settings via \"dconf\" extremely fast and light-weight. .  In general it is however considered better practice to edit settings in the database via \"gsettings\" if possible, which is the cli frontend to \"dconf\". The reason is that \"gsettings\" has a consistency check, safer to use. .  You might find this an interesting read on \"gsettings\": https://developer.gnome.org/gio/stable/GSettings.html .  And this one on \"dconf\": https://developer.gnome.org/dconf/unstable/dconf-tool.html .  Notes  I used another path / key example since I don't run Unity.  ",
      "P-tags": "python command-lin",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_39980359",
      "task": "Write magnetic tape end of record linux",
      "P-task": "write magnet tape end record linux",
      "F_verb": "write",
      "P-body": "Issue was with tcopy, it uses block size on device instead of detecting it. .  after last write allowed tcopy to display data as intended. .  ",
      "P-tags": "fcntl linux mt python ioctl",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP of NP"
    },
    {
      "id": "so_64803778",
      "task": "Replace all non alpha-numeric characters with dots using bash commands",
      "P-task": "replac non alpha-numer charact dot use bash command",
      "F_verb": "replace",
      "P-body": "The following works: .   Replace non word characters (non \"a-zA-Z_\") with dot (\".\") Replace underscores (\"_\") with dot (\".\") Squash sequences of dots into a single dot  Online test: https://rextester.com/GJOW76941 .  A shorter option: .   Replace non word characters (non \"a-zA-Z_\") with underscore (\"_\") Squash and replace underscores (\"_\") with dot (\".\")  ",
      "P-tags": "bash regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "so_42330340",
      "task": "how to pass shell variable into expect within shell script",
      "P-task": "pass shell variabl expect within shell script",
      "F_verb": "pass",
      "P-body": "Be careful what you are talking about. We have shell variables and we have exported shell variables a.k.a. environment variables. In your code, you have an environment variable, because you export it.  .  I answer here therefore for accessing environment variables from within the expect program. If you are really concerned about shell variables, please clarify this in your posting. .  First, I strongly recommend to use ALL UPPERCASE names for environment variables. Having lower case in the name of an environ might or might not work, depending on the concrete case. .  Now assume I have an environment variable FOO, and I want to access it within expect. This can be done in two ways, using the builtin array \"env\": .  BTW, in cases like yours, you do not need the double-colon; for instance \"$env(FOO)\" would do the same. However, if you get used to write the \"::\", you will be on the safe side in case you have to maintain more complex expect programs. .  ",
      "P-tags": "expect shell",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP into NP within NP"
    },
    {
      "id": "so_30870186",
      "task": "How to call external input and output file names to run Python Programs at Linux Command Prompt",
      "P-task": "call extern input output file name run python program linux command prompt",
      "F_verb": "call",
      "P-body": "Use python standard \"argparse\" library .  ....etc .  ",
      "P-tags": "linux python command-prompt file-io",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP S_INF at NP"
    },
    {
      "id": "ul_203535",
      "task": "Create SOX batch script to extract first 15 seconds and rename multiple files in folder",
      "P-task": "creat sox batch script extract first 15 second renam multipl file folder",
      "F_verb": "rename",
      "P-body": "If you want/need to use \"sox\" for this you can use its \"trim\" command: .  The splitting you can also do with the commandline utility that is part of mp3splt. You explicitly set the output file with \"-o\", so the originals are not touched, just remove them after you are done with them. This allows you to incorporate tags defined in the file in the output name than \"sox\" does (what you don't seem to need right now): .  Note that \"-o\" normally works with \"@\" based directives to include tag elements in the output name and appends \".mp3\". Without \"${i%.mp3}\" you would get \".mp3.mp3\" files. .  Times are dot separated, don't try to use \":\" instead, you get a less than useful error message that you don't have enough split points. .  I would not remove the input files until you have tested that the scripts works. Also note that if you stop it halfway, or add files later, that you cannot re-run it without removing any \"sample-\" files first. You might want to specify a directory before \"sample-...\", to keep things apart. .  ",
      "P-tags": "audio shell-script mp3 sox",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_622534",
      "task": "grep -ril, show only top directory once",
      "P-task": "grep -ril show top directori",
      "F_verb": "show",
      "P-body": "Directories don't match patterns for content; files do. What you seem to be asking is how to get the directories of files that match the pattern. .  Strip off the path past the first component, and ensure the result is presented as unique values in sorted order, as you have specified .  Replace the \"sort\" with \"awk '!h[$0]++'\" if you don't want to change the order of results .  ",
      "P-tags": "grep",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "ul_86905",
      "task": "How to determine how many files are within a directory without counting?",
      "P-task": "determin mani file within directori without count",
      "F_verb": "determine",
      "P-body": "The size of the directory (as seen with \"ls -ld /var/lib/php/sessions\") can give an indication. If it's small, there aren't many files. If it's large, there may be many entries in there, or there may have been many in the past. .  Listing the content, as long as you don't \"stat\" individual files, shouldn't take a lot much longer than reading a file the same size. .  What might happen is that you have an alias for \"ls\" that does \"ls -F\" or \"ls --color\". Those options cause an \"lstat\" system call to be performed on every file to see for instance if they are a file or directory. .  You'll also want to make sure that you list dot files and that you leave the file list unsorted. For that, run: .  Provided not too many filenames have newline characters, that should give you a good estimate. .  You can also deduce the number of files there by subtracting the number of unique files elsewhere in the file system from the number of used inodes in the output of \"df -i\". .  For instance, if the file system is mounted on \"/var\", with GNU \"find\": .  To find the number of files not in /var/lib/php/sessions. If you subtract that to the \"IUsed\" field in the output of \"df -i /var\", you'll get an approximation (because some special inodes are not linked to any directory in a typical ext file system) of the number of files linked to \"/var/lib/php/sessions\" that are not otherwise linked anywhere else (note that /var/lib/php/sessions could very well contain one billion entries for the same file (well actually the maximum number of links on a file is going to be much lower than that on most filesystems), so that method is not fool-proof). .  Note that if reading the directory content should be relatively fast, removing files can be painfully slow. .  \"rm -r\", when removing files, first lists the directory content, and then calls \"unlink()\" for every file. And for every file, the system has to lookup the file in that huge directory, which if it's not hashed can be very expensive. .  ",
      "P-tags": "directori linux file ext4",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP within NP without S_ING"
    },
    {
      "id": "so_24904943",
      "task": "how to print concatenate string in a column in mysql in bash",
      "P-task": "print concaten string column mysql bash",
      "F_verb": "print",
      "P-body": "You need to use quotes in your \"update sql\": .  ",
      "P-tags": "mysql bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP in NP in NP"
    },
    {
      "id": "au_100278",
      "task": "How do I install and mount an exFAT partition?",
      "P-task": "instal mount exfat partit",
      "F_verb": "mount",
      "P-body": "You will need the packages \"exfat-fuse\" and \"exfat-utils\" to allow you to read and write on exFAT drives: .  For 14.04 and higher: .  Afterwards you just need to plug in the HDD and you're good to go. .  ",
      "P-tags": "filesystem exfat",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_1316376",
      "task": "Non english file names not shown or incorrectly on Kubuntu 20.04.2 LTS",
      "P-task": "non english file name shown incorrectli kubuntu 20 04 2 lt",
      "F_verb": "show",
      "P-body": "You have set (probably via the KDE GUI) the \"cv_RU.UTF-8\" locale which has not yet been generated. Fix that by running: .  ",
      "P-tags": "local kubuntu file local",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP on NP"
    },
    {
      "id": "so_699576",
      "task": "Validating parameters to a Bash script",
      "P-task": "valid paramet bash script",
      "F_verb": "validate",
      "P-body": " edit: I missed the part about checking if the directories exist at first, so I added that in, completing the script. Also, have addressed issues raised in comments; fixed the regular expression, switched from \"==\" to \"eq\". .  This should be a portable, POSIX compliant script as far as I can tell; it doesn't use any bashisms, which is actually important because \"/bin/sh\" on Ubuntu is actually \"dash\" these days, not \"bash\". .  ",
      "P-tags": "valid shell bash",
      "source": "qa",
      "cate": "validate/authenticate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_64513061",
      "task": "How do you source neovim config file without restarting nvim?",
      "P-task": "sourc neovim config file without restart nvim",
      "F_verb": "restart",
      "P-body": "\"$MYVIMRC\" is always available from inside vim or neovim, so you can just use .  \":source $MYVIMRC\" .  and bind it to a convenient mapping: .  \"nnoremap <Leader>sv :source $MYVIMRC<CR>\" .  2021 update: If you are using neovim with a lua config, you can use \":luafile $MYVIMRC\" .  ",
      "P-tags": "zsh neovim vim bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "ul_68463",
      "task": "how are directories implemented in UNIX filesystem?",
      "P-task": "directori implement unix filesystem",
      "F_verb": "implement",
      "P-body": "Basically: it is your decision .  If by \"UNIX File System\" you mean UFS, then a parent directory inode does not cache the file types, it only contains the files and corresponding inodes. Source: UFS File Systems (PDF, see chap 15.2.2) .  This might not be the case for all file systems, it is a design choice. And for your file system it could be your design choice. .  For the silliness of this choice, I would disagree. Think how many times would the system have to check for the types of files under a directory? You have to balance the frequency of a \"ls -l\" command with the extra space that caching the information in the inode would take. If your file system is a cluster-like (e.g. glusterfs) or network-like (e.g. nfs) one, then this could be a good idea due to the possible latency of accessing all the inodes. On local storage this could be less of a concern. In addition what is your file system trying to achieve? If it is designed to be efficient with directories that contains each thousands of files, then it could be worth considering caching the file types, if it is designed to be lean with the smallest footprint then caching could not be avoided. .  Note about ext2, 3 and 4 and the filetype feature .  It seems that \"ext2-4\" can do exactly what you have in mind. It can cache the file types in the directory entry. This is only active with the feature \"filetype\" as filesystem creation time. When this feature is used, then ext4 uses a different structure for the directory entry which can have a cache of the file types. This applies to ext2 and ext3 as well. .  ",
      "P-tags": "directori file filesystem",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V in NP"
    },
    {
      "id": "au_395861",
      "task": "How to fix: conky disappears after click on desktop or other window?",
      "P-task": "fix : conki disappear click desktop window",
      "F_verb": "fix",
      "P-body": "Edit \"conky\" configuration file, i.e. open in \"gedit\" from the terminal: .  This worked for me: .  This worked too, but made desktop icons not visible at all or blinking .  I have also modified \"conky\" to be movable by removing \"undecorated\" from: .  ",
      "P-tags": "12 04 window conki",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP after NP on NP"
    },
    {
      "id": "so_10690604",
      "task": "How do you shut down a Linux system?",
      "P-task": "shut linux system",
      "F_verb": "shut",
      "P-body": "Try this: .  ",
      "P-tags": "shutdown linux",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V down NP"
    },
    {
      "id": "so_54159449",
      "task": "Not able to access zabbix default port (10050) in a server that contains VPN installed",
      "P-task": "abl access zabbix default port 10050 server contain vpn instal",
      "F_verb": "contain",
      "P-body": "I think its better to use Iptables rule, below command will allow zabbix server ip in tcp mode.  .  ",
      "P-tags": "strongswan ubuntu-18 04 zabbix vpn ipsec",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_21251469",
      "task": "awk Compare 2 files, print match and difference based on Start Range And End Range:",
      "P-task": "awk compar 2 file print match differ base start rang end rang :",
      "F_verb": "compare",
      "P-body": "This might work for you: .  ",
      "P-tags": "awk unix",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "ul_538351",
      "task": "Why does my init.d script work when invoked manually, but not on startup?",
      "P-task": "init script work invok manual startup",
      "F_verb": "invoke",
      "P-body": "So, kudos go to Patrick Mevzek. The hint to look into \".xsession\" brought me to someone with the same need. And from there to Debian's description on xinitrc. The description there states: .   Note : Modern Desktop environment also have (easier|GUI) session management tools. Under Gnome System Menu > Preferences > session). Except for very specific purpose, it shouldn't be necessary to touch xinitrc file.  .   I use Xfce and yes it has a possibility to add programs on session start under: -> Settings -> Session and startup behavior -> Automatically started programs .  ",
      "P-tags": "sysvinit shell",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V"
    },
    {
      "id": "so_27372224",
      "task": "Bash script: ensure process has terminated without waiting unnecessarily",
      "P-task": "bash script : ensur process termin without wait unnecessarili",
      "F_verb": "ensure",
      "P-body": "The same method that you use for detecting the process is still running should be usable to see if it's not. .  Something like this should do it, keeping in mind the possibility that there may be potential problems with that way of detecting if the program is running in the first place (a): .  It's basically a loop which runs for up to 120 seconds (roughly) but stops prematurely if the process disappears, waiting at most a second or so after the process actually exits. .   (a) A better way of detecting the process (without trying to parse the output of \"ps\") would be to use \"kill -0\" which doeesn't actually send a signal to the process, it just returns a result stating whether the process exists. .  Incorporating that \"kill -0\" method would give you code like: .   You'll also notice that I've changed your \"2>&1 >/dev/null\" into \">/dev/null 2>&1\". If you want to throw away all messages, that's important - the order on the command line has subtle effects. .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "confirm/ensure",
      "pat": "V NP without S_ING"
    },
    {
      "id": "so_11785821",
      "task": "PowerShell Remote join to domain",
      "P-task": "powershel remot join domain",
      "F_verb": "join",
      "P-body": "You should be able to call the \"Add-Computer\" cmdlet via PowerShell remoting. .  ",
      "P-tags": "powershel active-directori powershell-remot",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_25112200",
      "task": "Docker - Why is this express.js container with an exposed/published port reject connections? (using boot2docker)",
      "P-task": "docker - express js contain expos publish port reject connect\nuse boot2dock",
      "F_verb": "expose",
      "P-body": "I found out the source of confusion. My machine is running on Mac OSX and thus I installed docker with boot2docker.  .  So again repeating the process: .  Finally, the trick was not to connect to my own machine but to curl from the VM's IP address: .  So I had finally achieved success when I curled the VM: .  This is all explained well in detail on Docker's installation guide but I missed it as it was towards the end of the document. .  ",
      "P-tags": "javascript port docker node js linux-contain",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V"
    },
    {
      "id": "so_61978129",
      "task": "Is there a way to execute a .jar file through a shell script? (Raspbian)",
      "P-task": "way execut jar file shell script\nraspbian",
      "F_verb": "execute",
      "P-body": "First go to the directory and then execute the java -jar... command .  ",
      "P-tags": "shell minecraft linux java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP through NP"
    },
    {
      "id": "so_32538878",
      "task": "How to found if a TFS workspace is a local or server workspace",
      "P-task": "found tf workspac local server workspac",
      "F_verb": "find",
      "P-body": "After a long search (hours and hours in the very bad msdn documentation about the \"tf.exe\" command!), I have found the way to get the information! .  First you have to use the \"tf.exe workfold c:\\your\\path\" command to find out in which workspace the folder is. The command output something like that: .  Then you have to extract the 'workspace' (note: we really don't know why here the \"tf.exe\" command don't output the workspace in the format accepted everywhere by the \"tf.exe\" command i.e. \"WorkspaceName;Owner\" and consequently should be adapted!) and 'collection' data to use it in the \"tf.exe workspaces /format:detailed\" command, like that: .  The command output something like that: .  The important data that I want here is \"Location : Local\" (or \"Server\") .  I have written a little powershell script, if it could be of little use for someone to extract the data in the output to use them: .  This script give the answer only for the current folder but could be easily adapted... .  ",
      "P-tags": "powershel version-control command-lin tf",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V if S"
    },
    {
      "id": "so_40365142",
      "task": "Cannot find the process identifier on remote computer using Powershell",
      "P-task": "find process identifi remot comput use powershel",
      "F_verb": "find",
      "P-body": " by .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "ul_184888",
      "task": "xmodmap shift + keycode to produce keysym",
      "P-task": "xmodmap shift + keycod produc keysym",
      "F_verb": "produce",
      "P-body": "Key chords (like Shift+\\) are specified by combining one key with a set of modifiers, not by combining keys directly. So rather than \u201ckeycode 50 plus keycode 21\u201d, what you need to specify is \u201ckeycode 21 plus the Shift modifier\u201d. Only modifiers can be used in combinations. Furthermore xmodmap is somewhat limited: you need to specify all the key chords for a particular base key at the same time. .  The first keysym (character or function key name) after the equal sign is the one corresponding to the bare key, then comes the one corresponding to the key with Shift, then with AltGr, then with Shift+AltGr. .  If you want dead keys, then change this to .  If you want a standard Norwegian layout, though, you should be able to select it in your desktop environment's configuration interface, or with XKB \u2014\u00a0\"setxkbmap -layout no\" switches to a Norwegian layout. .  ",
      "P-tags": "xmodmap x11 keyboard-layout",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_13017473",
      "task": "How running a program or PowerShell script, after the \"SQL Server Maintenance\" plan ended?",
      "P-task": "run program powershel script sql server mainten plan end",
      "F_verb": "end",
      "P-body": "You can run your \"PowerShell\" script within \"SQL Server 2008/2008r2/2012 Agent\". In SQL Server Management Studio create a SQL job and select a \"PowerShell job step\" specifying the full path to your PowerShell script. Then add the job at the end of your maintenance plan as '\"Execute SQL Server Agent Job Task\"' .  ",
      "P-tags": "sql powershel maintenance-plan sql-server",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V"
    },
    {
      "id": "so_11679931",
      "task": "Why my shell script is in standby in the background till I bring it back on the foreground?",
      "P-task": "shell script standbi background till bring back foreground",
      "F_verb": "bring",
      "P-body": "Background processes are not allowed to write to the terminal, which your script tries to do with the \"echo\" statements. You just need to redirect standard output to a file when you put it to the background. .  (I've redirected standard error as well, just to be safe.) .  ",
      "P-tags": "detach background-process bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP on NP"
    },
    {
      "id": "so_15064783",
      "task": "Makefile - cannot find shared library",
      "P-task": "makefil - find share librari",
      "F_verb": "find",
      "P-body": " The above should be: .  That is, for each non-standard dynamic library location \"-L\" a corresponding \"-Wl,-R\" should be specified. \"$ORIGIN\" is needed to locate dynamic libraries relative to the executable, not sure if you need it here. .  People often advise using \"LD_LIBRARY_PATH\". This is a bad advice, in my opinion, because it makes deployment more complicated.  .  ",
      "P-tags": "c++ linux makefil",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_68127346",
      "task": "Create multiple connections using netcat and send continuous traffic through each netcat connection",
      "P-task": "creat multipl connect use netcat send continu traffic netcat connect",
      "F_verb": "create",
      "P-body": "You could replace the \"echo sahil\" with \"dd if=/dev/urandom | base64\" if you need a bunch of random data, otherwise \"dd if=/dev/zero\" could also work. .  I think that technically answers your question, but if you are looking to perform a loadtest on a server, there are many tools such as Apache Bench, or Locust, which will make that much easier. .  ",
      "P-tags": "shell bash netcat traffic connect",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "so_30478584",
      "task": "How to abort if command fails in Unix shell?",
      "P-task": "abort command fail unix shell",
      "F_verb": "abort",
      "P-body": "This looks like a gulp question, rather than a shell question. As gulp completes successfully (i.e. reaches an exit without raising an error), it doesn't tell the shell that anything is wrong. The best way to address this is to reconfigure gulp to interpret lint failures as errors. .  Could you post your \"gulpfile.js\"? Specifically your \"tslint\" task. .  It probably looks like .  You can instruct your reporter to fail on error by changing this to: .  edit: look at the gulp-tslint README for more details on emitError .  ",
      "P-tags": "unix linux shell bash gulp",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V if S"
    },
    {
      "id": "so_64933329",
      "task": "How to print Django queryset in Tabular form in python3 manage.py shell",
      "P-task": "print django queryset tabular form python3 manag py shell",
      "F_verb": "print",
      "P-body": "Django doesn't have this feature, but it would be easy to create a function using tabulate .  ",
      "P-tags": "django django-shel django-model",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_27578756",
      "task": "Error in bash script - assign value to variable",
      "P-task": "error bash script - assign valu variabl",
      "F_verb": "assign",
      "P-body": "Command substitution assigns the output of a command: .  Arithmetic expansion will get you the argument to \"head\" and \"tail\": .  ",
      "P-tags": "linux ubuntu bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_343788",
      "task": "sed replace just some letters regex",
      "P-task": "sed replac letter regex",
      "F_verb": "replace",
      "P-body": "The pattern \"[^ing]\" doesn't do what you think it does: it matches one character, which has to be none of \"i\", \"n\", or \"g\". .  If your problem can be rephrased as \"replace instances of cheer as a whole word\", then the following may work, using the marker for word boundaries, \"\\b\": .  ",
      "P-tags": "sed regular-express",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "au_34666",
      "task": "What happened to /etc/apt/apt.conf?",
      "P-task": "happen etc apt apt conf",
      "F_verb": "happen",
      "P-body": "The \"/etc/apt/apt.conf\" file is still read if it exists. The apt configuration provided by packages is installed as separate files in \"/etc/apt/apt.conf.d/\" so that it can be added and updated independent of any local changes you make in the main configuration file. .  So if you have local configuration changes, just create the file. .  ",
      "P-tags": "apt 11 04 proxi",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V to NP"
    },
    {
      "id": "ul_432801",
      "task": "rsync - Exclude a certain file extension, unless zipped",
      "P-task": "rsync - exclud certain file extens unless zip",
      "F_verb": "exclude",
      "P-body": "Instead of excluding each and every filetype you don't want, include the ones you do want: .  You may also want to use the \"--one-filesystem\" (\"-x\") option which stops \"rsync\" from traversing other filesystems than the one the source directory is located on. .  Alternatively, specify \"*.fasta.gz\" in an include pattern and then \"*.fasta\" in a exclude pattern afterwards. .   For backups, I'd suggest something like \"borgbackup\" (possibly together with \"borgmatic\") or \"restic\" instead of \"rsync\". These all deduplicate data which makes the backups take much less space. .  ",
      "P-tags": "rsync",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP unless S"
    },
    {
      "id": "au_129436",
      "task": "Restarted computer during update; \"the system network service is not compatible with this version\"",
      "P-task": "restart comput updat system network servic compat version",
      "F_verb": "restart",
      "P-body": "Edit: This answer is over six years old and is no longer fresh due to changes in Ubuntu. This is a workaround. .  Go into settings, startup items. Add an entry with the following command: .  In a terminal, use \"visudo\" to add a \"NOPASSWD\" entry for this command so you do not need to give a password: .  Next time you log on, this will force a start of the network manager (supposing that it is configured such that it can start up). .  ",
      "P-tags": "upgrad network wireless",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP during NP"
    },
    {
      "id": "so_56599219",
      "task": "How to convert list to xml in Powershell?",
      "P-task": "convert list xml powershel",
      "F_verb": "convert",
      "P-body": "It is all about how \"out-file\" deals with XML variables. to understand this you need to test it on a simple variable, lets say we have a variable  .   \"$x=\"This an XML variable\"\" .   . first we will out this variable using \"out-file\" like this  .   \"$x|out-file -path C:\\test.xml\" .   without convert it to XML. Of course when open it as XML file it will be empty but when editing it using notepad it will show the string we entered. after that we will convert to XML then out it as you did in your code.  .   \"$xXML=$x|convertto-XML\" .  \"$xXML|out-file C:\\test2.xml\" .   As before the XML file will be empty but when editing the file test2.xml it will contain something like this: .   xml Objects .  --- ------- .  version=\"1.0\" encoding=\"utf-8\" Objects .   and this the same result you will see if you typed \"$xXML\" in the shell. So out-file just out the results which passes through the pipeline. if you want to see the XML representation you need to type \"$xXML.innerxml\", i prefer to save any XML data to file using one of these methods. .   \"$xXML.save(\"C:\\test3.xml\")\" .   OR .   \"$x |Export.CliXML -path \"C:\\test4.xml\"\" .   So instead of the last line in your code you can just type .   \"$OutComId | Export-CliXML \"$exportPath\\combined.xml\"\" .   ",
      "P-tags": "powershel xml",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_7083085",
      "task": "Shell script that watches for changes to specific files then cats them",
      "P-task": "shell script watch chang specif file cat",
      "F_verb": "watch",
      "P-body": "Disclaimer: This might be overkill, but on the other side maybe faster to implement and more stable. .  There is a ruby library called directory_watcher, which can monitor directories for changes. .  A simple script, such as .  can get you started. Here the modified (or deleted or added) filenames just gets printed to stdout.  .   Here is an example script, that will watch for \"file1.txt\", \"file2.txt\", \"file3.txt\". Whenever one of those is changed, it will concatenate them into \"files-combined.txt\". .  Output would be like: .  ",
      "P-tags": "shell watch maco",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V for NP to NP"
    },
    {
      "id": "so_57712234",
      "task": "Calculate time passed since $STARDATE and current date",
      "P-task": "calcul time pass sinc stardat current date",
      "F_verb": "calculate",
      "P-body": "You can use python: .  Or you have to build something like: .  Years and month would be more difficult .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP since NP"
    },
    {
      "id": "so_49550252",
      "task": "Reading JSON from Powershell",
      "P-task": "read json powershel",
      "F_verb": "read",
      "P-body": "Use \"ConvertFrom-JSON\" to parse the JSON-value in your \"notes\"-property. I'd store the converted notes in a variable just in case you need to access \"Project\" or another part of the json later. Try: .  ",
      "P-tags": "json powershel virtual-machin",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP from NP"
    },
    {
      "id": "so_12245080",
      "task": "where is error number of ::accept from socket.h",
      "P-task": "error number : :accept socket h",
      "F_verb": "accept",
      "P-body": "\"errno\" is a global integer variable that contains error codes after system calls like \"accept\" fails. You might have to include the header file \"<errno.h>\" for the variable to be defined. .  In your case, you shouldn't throw the value returned by \"accept\" but the value of \"errno\": .  The function \"std::strerror\" is declared in the header file \"<cstring>\" and returns a string describing the error.  .  An important note: The value of \"errno\" is only valid if a function returns that it failed. If, in your example, \"accept\" succeeds then the value of \"errno\" is undefined. .  ",
      "P-tags": "socket linux error-handl c++ throw",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V from NP"
    },
    {
      "id": "su_670000",
      "task": "Trying to find out when system running Solaris 9 was last updated",
      "P-task": "tri find system run solari 9 last updat",
      "F_verb": "find",
      "P-body": "Found this for Solaris 8 http://compgroups.net/comp.unix.solaris/how-to-show-the-last-time-solaris-8-machine/65540 .  Appears to show timestamps from when patch packages were applied. Also used: .  to show timestamp of patch log. .  ",
      "P-tags": "solari unix",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V out when S"
    },
    {
      "id": "so_49052346",
      "task": "Cannot use parameter in SET clause of UPDATE query (Powershell, MS Access SQL)",
      "P-task": "use paramet set claus updat queri powershel ms access sql",
      "F_verb": "use",
      "P-body": "As @JacobH posted in a comment, it seems that OleDB is sensitive to the order parameters come in. .  Therefore, here is the corrected version of \u00b4Set-FruitCount` that does work: .  Note that @COUNT and @FRUIT are now appearing in the same order as in the SQL query. .  ",
      "P-tags": "sql powershel ms-access",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP of NP"
    },
    {
      "id": "so_24992169",
      "task": "Complex parsing of a logfile to retrieve information from multiple lines and store in a new file in a given format",
      "P-task": "complex pars logfil retriev inform multipl line store new file given format",
      "F_verb": "retrieve",
      "P-body": "Give this script a try; .  ",
      "P-tags": "awk grep perl bash sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP from NP"
    },
    {
      "id": "so_13785063",
      "task": "Why you would choose \"a.out file\" over \"a.out < file\" or vice versa? c++",
      "P-task": "would choos file file vice versa\nc++",
      "F_verb": "choose",
      "P-body": "Stdin is particularly useful when you want to be able to pipe the output of one program to the input of another program, and so on in a chain, like this: .  (which will print out the number of lines in myfile.txt containing the string MyKeyword) .  If the \"grep\" and \"wc\" utilities were set up to only read from a specified file, rather than from stdin, the above task would be more difficult; you'd have to do it in multiple steps instead: .  ... which would be awkward and also requires writing a temporary file to the disk, which can be problematic (e.g. what if there was already a temp.txt file in the current directory? Oops, you just overwrote it, too bad! Or what if you don't have write-access to the drive? No way to write out a temporary file then) .  On the other hand, sometimes your program needs to read from more than one file. For example, if you wanted to concatenate several files together you can do this: .  cat part1.txt part2.txt part3.txt > wholething.txt .  If \"cat\" only supported reading from stdin it would be difficult to do such a thing, as you'd need some way to pipe multiple files into cat's stdin stream. .  Also, if a program needed to read the file in non-linear order (e.g. fseek() forward or back in the file rather than just reading it straight through) it wouldn't be able to do that using stdin, since you can't seek on a pipe. .  ",
      "P-tags": "c++ command-lin unix",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP over NP"
    },
    {
      "id": "su_1516057",
      "task": "What regular expression can be used with grep, flag -E, to display lines from a text file with ONLY an odd number of characters?",
      "P-task": "regular express use grep flag -e display line text file odd number charact",
      "F_verb": "display",
      "P-body": "Use \"^.(..)*$\". .  Explanation: .  In action: .  ",
      "P-tags": "linux grep regex",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP from NP with NP of NP"
    },
    {
      "id": "ul_27704",
      "task": "How can I generate a DEB from an installed package?",
      "P-task": "gener deb instal packag",
      "F_verb": "generate",
      "P-body": "\"dpkg-repack\" .  ",
      "P-tags": "apt debian",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP"
    },
    {
      "id": "au_553976",
      "task": "How to (using GUI) empty a flash drive's trash without emptying the computer's?",
      "P-task": "use gui empti flash drive trash without empti comput",
      "F_verb": "empty",
      "P-body": "When you open flash drive press CTRL+H or through menu View > Show hidden files, hidden folder should appear \".Trash-1000\" or similar. Delete this folder like normal file, you will be prompted with ask \"Remove it permanently?\", press delete button. Or delete this folder by selecting it and pressing Shift+Del. .  ",
      "P-tags": "trash external-hdd gui",
      "source": "qa",
      "cate": "clear/clean/empty/eliminate/unpin/cleanup/unpublish",
      "pat": "V NP"
    },
    {
      "id": "so_6398469",
      "task": "Make an hour into timestamp",
      "P-task": "make hour timestamp",
      "F_verb": "make",
      "P-body": "Try mktime  .  http://php.net/manual/en/function.mktime.php .  ",
      "P-tags": "unix-timestamp php",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP into NP"
    },
    {
      "id": "so_8496660",
      "task": "linux mysql-server can't find mysql_config",
      "P-task": "linux mysql-serv find mysql_config",
      "F_verb": "find",
      "P-body": "The \"mysql_config\" executable is by default located in the bin directory of the MySQL server installation if you install it from precompiled binaries. But if you install it using \"apt-get\" it may not exist on your server. .  Try:  .  ",
      "P-tags": "ubuntu mysql configur",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_25836222",
      "task": "bash read command splits line into words using space as delimiter even though space is not in IFS",
      "P-task": "bash read command split line word use space delimit even though space if",
      "F_verb": "read",
      "P-body": "This is most likely just an issue with how you \"echo\" \"IFS\" .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP into NP using NP as NP"
    },
    {
      "id": "au_229268",
      "task": "How to change system time or force a sync with hardware clock",
      "P-task": "chang system time forc sync hardwar clock",
      "F_verb": "change",
      "P-body": "You can set the hardware clock with the command (for example) .  You then need to syncronise the system clock to the hardware clock: .  Reference: $ man hwclock .  ",
      "P-tags": "time",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP with NP"
    },
    {
      "id": "au_365030",
      "task": "How to make Nemo start in foreground?",
      "P-task": "make nemo start foreground",
      "F_verb": "make",
      "P-body": "I started to experience the issue with other apps later, and then I began to search for solution not for Nemo, but in general, and found one on the Ubuntu Forums, and two on Ask Ubuntu as well. .  This is caused by Compiz, so you have to use \"compizconfig-settings-manager\" (\"sudo apt-get install compizconfig-settings-manager\", then start \"ccsm\" command with Alt+F2, or from terminal, or search for \"CompizConfig Settings Manager\" from the dash). .   Open \"General Options\" Under \"Focus and Raise Behaviour\" tab set Focus Prevention Level to Off  After following these steps, all my newly opened windows show up in the foreground as expected. .  ",
      "P-tags": "nemo",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "au_74155",
      "task": "Change SciTE background colour when Find highlights the word I'm looking for?",
      "P-task": "chang scite background colour find highlight word look",
      "F_verb": "find",
      "P-body": "That property can be changed by editing \"/usr/share/scite/SciTEGlobal.properties\" and then changing this lines: .  which are BTW used for setting the colors for displaying selected text. .  For example, for yellow background and red text, without translucency, it would look like: .  ",
      "P-tags": "text editor",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_149425",
      "task": "Tiling window manager that keeps the titlebar?",
      "P-task": "tile window manag keep titlebar",
      "F_verb": "keep",
      "P-body": "You are looking for tiling window managers having non-tiling windows capabilities. Maybe the answer is not getting something working out-of-the-box, but using something like \"openbox\" or \"fluxbox\" (which allows to use everything you put in your description, and being mouse-friendly) plus an add-on or program running on top of that - for example, check the following link: .  You might want to try Tile-windows: .   The Tile-windows application is a tool which allows for the tiling of windows within non-tiling window manager. .   Also, acording to the Tiling window manager Wikipedia's article, there are some tiling window managers that allows the placement of windows in the screen using the mouse: .   i3 - a built-from-scratch window manager, based on wmii. It has vi-like keybindings, and treats extra monitors as extra workspaces, meaning that windows can be moved between monitors easily. Allows vertical and horizontal splits, and parent containers. It can be controlled entirely from the keyboard, but a mouse can also be used. .  Musca - features manual tiling, multiple screen support, virtual desktops and mouse or keyboard navigation. .  ShellTile - tiling window manager extension for GNOME Shell, started from the code of shellshape, allows manual arrangement of windows using mouse and keyboard. .  Ctrlwm is a tool for automatic window position in various layouts, also processing mouse screen edge/corner actions. .   You may want to take a look at the Third party tiling applications on Xorg section of the article.  .  So, there's a lot to try - Have fun!  .  ",
      "P-tags": "software-rec window-manag tiling-wm",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "so_43665089",
      "task": "Is there an automated way to create projects and namespaces?",
      "P-task": "autom way creat project namespac",
      "F_verb": "create",
      "P-body": "Yes. C# project (I am assuming C# based on the question being tagged as C#) projects are \".csproj\" files that are really XML files with a special extension. Create a template \".csproj\" file in Visual Studio and then view that file in a text editor (e.g. notepad) to see what the XML should look like. .  The \"System.Xml\" namespace contains support for authoring XML files which can be used to create the \".csproj\" files. .  The \"System.IO\" namespace contains support for creating directories.  .  Between these two namespaces in the framework, you have the tooling needed to automate the creation of directory structure and project files from C#. .  ",
      "P-tags": "c visual-studio-2017 visual-studio-2015 visual-studio powershel",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_11944604",
      "task": "Escape certain characters in shell script",
      "P-task": "escap certain charact shell script",
      "F_verb": "escape",
      "P-body": "Inside backticks and double quotes, you basically need to double your backslashes, yes. If a backslash is not a known escape sequence, it will be preserved, though. .  So if you want \"hive\" to see a double backslash there, you will need to put four backslashes in the Bash script. .  See further e.g. http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_03_03.html .  ",
      "P-tags": "hive unix linux shell bash",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP"
    },
    {
      "id": "so_32709402",
      "task": "Run line of Perl/Python/Ruby from Bash",
      "P-task": "run line perl python rubi bash",
      "F_verb": "run",
      "P-body": "Each of these commands has a switch to execute a string passed as an argument. For python, it's \"-c\": .  For ruby, it's \"-e\": .  By the way, the output of \"python --help\", \"ruby --help\" or looking in the \"man\" page for either program would give you the answer.  .  ",
      "P-tags": "rubi python perl shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "au_520427",
      "task": "How to update manual page in Ubuntu 12.04?",
      "P-task": "updat manual page ubuntu 12 04",
      "F_verb": "update",
      "P-body": "Right, the \"ip\" subcommand \"tuntap\" is described in \"man ip\" under 14.04 Trusty, but not under 12.04 Precise. .  If the command itself in the latest repository version for Precise does indeed support \"ip tuntap\", the missing description is a bug that should be reported for the package \"iproute2\". .  The man page is in the main package, \"iproute2\". The package \"iproute2-doc\" does exist, but is an empty transitional package, with dependency on \"iproute2\". .  I do not know how to best get a package installed with an updated man page - it may not be easy, because the software is in the same package. .  But you can get the man page versions of the Ubuntu releases online at http://manpages.ubuntu.com - for example man ip for Precise and man ip for Trusty. .  ",
      "P-tags": "updat update-manag",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_280067",
      "task": "Have rm not report when a file is missing?",
      "P-task": "rm report file miss",
      "F_verb": "report",
      "P-body": "Use the \"-f\" option. It will silently ignore nonexistent files. .  From \"man rm\": .  [The \"never prompt\" part means that (a) \"-f\" overrides any previously specified \"-i\" or \"-I\" option, and (b) write-protected files will be deleted without asking.] .  Example Without \"-f\", \"rm\" will complain about missing files: .  With \"-f\", it will be silent: .  ",
      "P-tags": "rm",
      "source": "qa",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V when S"
    },
    {
      "id": "au_1165877",
      "task": "Is it possible to use docker without sudo?",
      "P-task": "possibl use docker without sudo",
      "F_verb": "use",
      "P-body": " If you don\u2019t want to preface the docker command with sudo, create a Unix group called docker and add users to it. When the Docker daemon starts, it creates a Unix socket accessible by members of the docker group. .   Warning: .  The docker group grants privileges equivalent to the root user. For details on how this impacts security in your system, see Docker Daemon Attack Surface.  .   If you still want to run docker without \"sudo\":  .   Add the docker group if it doesn't already exist: .   Add the connected user \"$USER\" to the docker group. Change the user name to match your preferred user if you do not want to use your current user: .   Either do a \"newgrp docker\" or log out/in to activate the changes to groups (If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect). .  You can use  .  to check if you can run docker without sudo. .   PS: If you initially ran Docker CLI commands using \"sudo\" before adding your user to the \"docker\" group, you may see the following error, which indicates that your \"~/.docker/\" directory was created with incorrect permissions due to the \"sudo\" commands. .  To fix this problem, either remove the \"~/.docker/\" directory (it is recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands: .  Source: Docker documentation .  ",
      "P-tags": "sudo group permiss docker",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without NP"
    },
    {
      "id": "ul_65613",
      "task": "How do I test that two connected serial ports really transmit data?",
      "P-task": "test two connect serial port realli transmit data",
      "F_verb": "transmit",
      "P-body": "You could open an additional session with ssh and issue the following command in it: .  it will print out everything that arrives at ttyS0. Of course, this solution is useful if you transmit printable characters only as otherwise your screen may be flooded with garbage.  .  ",
      "P-tags": "serial-consol serial-port",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "au_681663",
      "task": "How do I see Samba groups?",
      "P-task": "see samba group",
      "F_verb": "see",
      "P-body": "Groups within samba are mapped over from the normal Unix groups used on your system. You can view these with the command. .  ",
      "P-tags": "server samba",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "ul_676199",
      "task": "How should I set up a systemd service to auto-start a server and let me pass commands to it?",
      "P-task": "set systemd servic auto-start server let pass command",
      "F_verb": "pass",
      "P-body": "I don't have a full answer for you because I can't reproduce the problem. But I've tried to put togeather a minimum verifiable example and had some ideas for troubleshooting: .  Then running this works: .  There are some tricks that you might be running into here: .   If you \"systemctl stop minecraft@1_17_1.service\", then this will not stop the parallel socket. That means \"/run/minecraft1_17_1.stdin\" will continue to run. In fact, if you \"echo \"hello\" > /run/minecraft1_17_1.stdin\", it will launch your service. I can imagine if you're troubleshooting your service, an old socket could be affecting your tests. I suggest one of two options: .   Use \"systemctl stop minecrat@1_17_1.{service,socket}\" to stop it, Add \"PartOf=minecraft@%i.service\" to the \"[Unit]\" section of the socket. This will cause it to automatically stop when the service is stopped.   You are using \"Restart=on-failure\". This is great for your end result, but it could be hiding your initial failure. While you are troubleshooting, consider removing this temporarily. Then when it fails, you'll see the initial reason it failed. My guess is that you are having a legitimate problem with the server startup, but then your socket is bound to that first instance. Then each restart fails to bind to the old socket before even trying the ExecStart= and so you never discover why it originally failed in the first place. Be sure to stop the service and socket, then start it and check the output immediately. I wouldn't be surprised if your error message was different. .   You described the minecraft server as having a gui. This is optional and suddenly depends on things like your \"DISPLAY\" and \"XAUTHORITY\" being set. That introduces a lot of stuff that can break. Consider calling your service with the \"nogui\" option in \"start.sh\" to eliminate this possible cause of the initial failure. If you REALLY REALLY want that gui, then you'll need to set the \"DISPLAY\" and \"XAUTHORITY\" environment variables in your script (but that's not necessarily the easiest thing to do). I recommend at least trying it without the GUI to see if that gets your service running. .   It's possible that you've forgotten to run \"sudo systemctl daemon-reload\" while editing your files. As a reminder, be sure to run this so that systemd reads the latest version of each unit. .    ",
      "P-tags": "systemd minecraft fedora fifo",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_67206970",
      "task": "openapi-generator: command not found for bash script",
      "P-task": "openapi-gener : command found bash script",
      "F_verb": "find",
      "P-body": "In generate.sh, replace \"openapi-generator\" with \"openapi-generator-cli\" instead. .  (\"openapi-generator\" is usually installed via brew on Mac) .  ",
      "P-tags": "git-bash bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V for NP"
    },
    {
      "id": "su_1455042",
      "task": "cannot find owncloud docker files for backup",
      "P-task": "find owncloud docker file backup",
      "F_verb": "find",
      "P-body": "If you're having trouble finding where on your host system docker is saving your volumes use the following steps: .   \"docker volume ls\" to find the volume name \"docker volume inspect VOLUME NAME\" to show the details for the volume specified by \"VOLUME NAME\"  In the details it will show a mountpoint in your local file system. .  ",
      "P-tags": "linux owncloud backup docker",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_298904",
      "task": "AppArmor is causing Firefox segfaults",
      "P-task": "apparmor caus firefox segfault",
      "F_verb": "cause",
      "P-body": "I have managed to solve the issue. The way I did this was by editing /etc/default/grub and changing GRUB_CMDLINE_LINUX from .  to .  Then after running \"sudo update grub\" and \"sudo reboot\" the issue was fixed. However this stopped apparmor from working as it gave the error: .  \"apparmor.common.AppArmorException: 'Warning: unable to find a suitable fs in /proc/mounts, is it mounted?\\nUse --subdomainfs to override.\\n'\" .  However I managed to solve this by using the commands from the debian guide again. .  After the reboot I tried to launch firefox and I didn't get any errors and it is all working fine now. However after trying it on my pc I started having the segfault issue again and this fix didn't work. but after comparing the apparmor profiles in \"/etc/apparmor.d\" I found that the profile rules were different. .  Rules on segfaulting pc: .  Rules on working pc: .  I added \"#include <abstractions/bash>\" and \"/bin/dash ix,\" to the config file, then changed the path to \"/usr/bin/firefox\" and now the issue is fixed after rebooting. .  ",
      "P-tags": "debug apparmor linux debian",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_1375080",
      "task": "How to get the right text with bash",
      "P-task": "get right text bash",
      "F_verb": "get",
      "P-body": "There are several options, but you haven't defined your clear criteria - so I'm mostly guessing here. .  If the output you need is consistently in the bottom of your file, you can use \"tail\" to get the last X lines, e.g.: .  ... will give you the last 6 lines (the table). .  Another option is to use \"grep\" to search for a pattern, e.g.: .  ... will match those lines that include either the word \"STATIC\" or \"DYNAMIC\". .  ",
      "P-tags": "script command-lin bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_66559022",
      "task": "how to mount a local volume for my docker?",
      "P-task": "mount local volum docker",
      "F_verb": "mount",
      "P-body": "The \"container_dir\" is the path inside the container, where you'd like to see your mounted files. The directory inside container does not even have to exist, yon can pick almost any place to mount your files. If you work with \"jupyter\", it makes sense to add your files to the working directory: .  Once inside the container you will find \"/home/pyman/PEYMAN\" in \"/workspace/myfiles\". .  ",
      "P-tags": "linux python jupyter-notebook docker",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_671303",
      "task": "nvida drivers disapeared during night (poweroff/poweron) DKMS cannot be rebuild",
      "P-task": "nvida driver disapear night poweroff poweron dkm rebuild",
      "F_verb": "rebuild",
      "P-body": "When you run into issues such as this, deleting old kernels and associated initramfs is the last thing you should do; instead, you can reboot into the previously-known working kernel. You\u2019ve been bitten by bug #994860: the NVIDIA graphics drivers currently in testing don\u2019t build with kernel 5.14, and the latter just migrated to testing. .  Why did this happen seemingly overnight? Until you powered off, your system was running a 5.10 kernel, which is the version that was in testing until two days ago. When you upgraded, the newly-migrated 5.14 kernel was installed; and when you booted up again, that\u2019s the kernel that was loaded. \"dkms\" noticed that the NVIDIA modules were missing, tried to build them, and failed because of the aforementioned bug. It would have tried to build them during installation too.) .  To fix the situation, assuming you no longer have the 5.10 kernel, you can install that to return to your previously-working configuration: .  The NVIDIA modules should build fine for this kernel again, and you can then reboot and choose the 5.10 kernel from the boot menu. This won\u2019t break anything else in your system, the 5.10 kernel is safe to use with Debian testing \u2014 in fact that\u2019s what was in testing until September 28. The above instructions won\u2019t install exactly the same kernel, they\u2019ll install an updated 5.10 kernel from Debian 11 \u2014 Debian testing doesn\u2019t get security support.) .  Alternatively, upgrade to the NVIDIA drivers currently in unstable, but be aware that you might then run into issues with OpenCL (if that\u2019s important to you). .  ",
      "P-tags": "dpkg nvidia debian dkm",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V"
    },
    {
      "id": "so_18695105",
      "task": "How to concatenate huge number of files",
      "P-task": "concaten huge number file",
      "F_verb": "concatenate",
      "P-body": "If your directory structure is shallow (there are no subdirectories) then you can simply do: .  If you have subdirectories, you can limit the find to the top level, or you might consider putting some of the files in the sub-directories so you don't have this problem! .  This is not particularly efficient, and some versions of find allow you to do: .  for greater efficiency. Note the backslash before the \"+\" is not necessary, but I find it nice for symmetry with the previous example.) .  ",
      "P-tags": "concaten cat unix",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP of NP"
    },
    {
      "id": "au_76948",
      "task": "Problems Connecting MSN with empathy",
      "P-task": "problem connect msn empathi",
      "F_verb": "connect",
      "P-body": "Without uninstalling anything, you can fix this by changing a line in the file \"/usr/share/pyshared/papyon/service/description/AB/__init__.py\". .  Edit it as root by running: .  Change line 23 from this: .  To this: .  Or to this:  .  Reboot and test it, it's working for me! .  ",
      "P-tags": "11 10 empathi connect msn",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP"
    },
    {
      "id": "au_536762",
      "task": "Run rkhunter regularly on a desktop system",
      "P-task": "run rkhunter regularli desktop system",
      "F_verb": "run",
      "P-body": "Run at startup, display with \"zenity\" Create a file \"/usr/local/sbin/rkhunter-check\" and make it executable: .  Edit the file \"gksu gedit /usr/local/sbin/rkhunter-check\" .  If the rkhunter run generates any output (only warnings), this script will show up as a scrollable window with the rkhunter output. .   create a systemd startup script Create the script \"/etc/systemd/system/rkhunter.service\": .  Update systemd with: .   start by \"/etc/rc.local\" On systems without \"systemd\" call the script at runtime in \"/etc/rc.local\" and put a sleep before the whole command: .  Add this command before the last line in \"/etc/rc.local\" that contains \"exit 0\": .    Both solutions will wait 30 minutes before executing the rkhunter check as root. .   You can also combine this solution with the notify-send solution, because in case there are no warnings, a zenity dialog is not perfect. a notification would suffice in that case .   source: How to run a script during boot as root .  ",
      "P-tags": "secur dbu cron rkhunter libnotifi",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_616824",
      "task": "Btrfs: Why create a snapshot of a subvolume inside of that subvolume?",
      "P-task": "btrf : creat snapshot subvolum insid subvolum",
      "F_verb": "create",
      "P-body": "It's really a matter of preference. Personally, I don't create a snapshot of a subvolume inside of the subvolume I'm snapshotting. BTRFS is fine with it, but I find it confusing. .  I use the method you suggested: \"btrfs subvolume snapshot /btrfs/SV1 /btrfs/SV1-snap1\" .  ",
      "P-tags": "btrf snapshot",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP inside NP"
    },
    {
      "id": "so_4481005",
      "task": "Get wireless SSID through shell script on Mac OS X",
      "P-task": "get wireless ssid shell script mac os x",
      "F_verb": "get",
      "P-body": "The command .  will give you details about your current wireless network connection. .  To get specifically the SSID, use this command: .  To retrieve SSID names that might have colons as well as spaces: .  ",
      "P-tags": "shell maco",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP through NP on NP"
    },
    {
      "id": "ul_174896",
      "task": "How to change dir to the last directory?",
      "P-task": "chang dir last directori",
      "F_verb": "change",
      "P-body": "if \"lastdir\" is the only directory of that name in your directory hierarchy, you might get away with this in \"bash\" (although it may take a while to run) .  ",
      "P-tags": "directori cd-command shell",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_18297909",
      "task": "Can't find AD user using the command get-aduser when the user is an object",
      "P-task": "find ad user use command get-adus user object",
      "F_verb": "find",
      "P-body": "You can assign the username to a variable and use it in the query: .  or use an expanded string instead of a script block: .  ",
      "P-tags": "powershell-2 0 window powershel powershell-1 0 powershell-3 0",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP using NP when S"
    },
    {
      "id": "su_505857",
      "task": "Set the terminal prompt in Ubuntu to show only the working directory name instead of its full path",
      "P-task": "set termin prompt ubuntu show work directori name instead full path",
      "F_verb": "set",
      "P-body": "Best guess for default Ubuntu install Find where your \"PS1\" variable is set and change \"\\w\" to \"\\W\". .  You can do an initial check of this method thus: .  It is probably being set in your \".bashrc\". If not, check \"/etc/bashrc\" and override the variable there in your \".bashrc\". You will of course have to do an \"exec bash\" or source your \".bashrc\" for changes made there to take effect. .  Other setups There are different variations on how to do this depending on what shell you are using and how it is set up. For example, you might conceivably have your prompt set up like this: .  In which case you will want to do: .  ",
      "P-tags": "linux ubuntu",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP S_INF of NP"
    },
    {
      "id": "so_58097928",
      "task": "merge multiple columns into rows based on different column values",
      "P-task": "merg multipl column row base differ column valu",
      "F_verb": "merge",
      "P-body": "Not awk, but the always handy GNU datamash makes it easy: .  This does assume that your input is already partitioned by gene and those further sorted by SNP value, as they are in your sample data. .   Strips the header line with \"tail -n +2\" Uses \"datamash\" to turn groups into lines that look like \"NonGene 22:1_A/T,22:2_A/G,22:3_A/C\" Uses \"tr\" to convert the commas into tabs for final output.  ",
      "P-tags": "awk linux",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP into NP on NP"
    },
    {
      "id": "su_478922",
      "task": "Fast way to check disk usage in linux?",
      "P-task": "fast way check disk usag linux",
      "F_verb": "check",
      "P-body": "If you have /home on a separate partition you can use \"df -h\" to show the disk usage. This should be pretty fast since the command doesn't summarize the disk usage of each file (as \"du\" does). .  ",
      "P-tags": "cento linux hard-driv ssh",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "so_9193659",
      "task": "Write to a cacheable physical address in linux kernel without using ioremap or mmap",
      "P-task": "write cacheabl physic address linux kernel without use ioremap mmap",
      "F_verb": "write",
      "P-body": "The simplest way to do this would be to do \"kmalloc()\" to get some memory in the kernel. Then you can get the physical address of the pointer that returns by passing it to \"virt_to_phys()\". This is a total hack but for your case of debugging / tracing under qemu, it should work fine. .  EDIT: I misunderstood the question. If you want to use a specific physical address, there are a couple of things you could do. Maybe the cleanest thing to do would be to modify the e820 map that qemu passes in to mark the RAM page as reserved, and then the kernel won't use it. ie the same way that ACPI tables are passed in). .  If you don't want to modify qemu, you could also modify the early kernel startup (around \"arch/x86/kernel/setup.c\" probably) to do \"reserve_bootmem()\" on the specific physical page you want to protect from being used. .  To actually use the specified physical address, you can just use \"ioremap_cache()\" the same way the ACPI drivers access their tables. .  ",
      "P-tags": "linux linux-kernel memory-manag",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP in NP without using NP"
    },
    {
      "id": "au_41569",
      "task": "Can I make a *.desktop item always be maximized?",
      "P-task": "make desktop item alway maxim",
      "F_verb": "make",
      "P-body": "\"gnome-terminal\" has an undocumented \"--maximize\" option (and also \"--full-screen\"). You can add that to the launcher's EXEC line to have it start maximized. .  ",
      "P-tags": "gnome-termin launcher window-manag",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_35497503",
      "task": "How to get system image list icon index of an IShellItem?",
      "P-task": "get system imag list icon index ishellitem",
      "F_verb": "get",
      "P-body": "Basically it doesn't seem that there's any easy method for this. It simply hasn't been provided in the API. .  In your question you say \"But the shell supports things besides files and folders in the filesystem.\", which makes me think you have overlooked that \"SHGetFileInfo\" does actually support using PIDLs directly (with the \"SHGFI_PIDL\" flag) - so it can be used on non-filesystem objects. If you still have the full PIDL this is the easiest way to get an icon index, otherwise something like this should hopefully work: .   Or using Raymond Chen's suggestion: .   .  Turns out that \"IShellFolder\" doesn't support the \"IShellIcon\" sometimes. For example attempting to browse inside a zip file. When that happens, the \"QueryInterface\" of \"IShellFolder\" for \"IShellIcon\" fails. .  Yet \"SHGetFileInfo\" knows how to handle it.  .  So best to not try to get an \"IShellIcon\" interface yourself. Leave the heavy lifting to \"SHGetFileInfo\" (at least until someone from Microsoft documents how to use \"IShellIcon\"). .  ",
      "P-tags": "window com shell winapi",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_15799047",
      "task": "Trying to remove yum which is protected in Centos",
      "P-task": "tri remov yum protect cento",
      "F_verb": "remove",
      "P-body": "The right way to do what I was looking for is by doing: .  in the command line. .  ",
      "P-tags": "rvm rubi linux cento",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP which S"
    },
    {
      "id": "so_29334851",
      "task": "Sed command not found",
      "P-task": "sed command found",
      "F_verb": "find",
      "P-body": "The nature of your program* snippet implies that you have just overwritten \"PATH\". \"PATH\" is an important environment variable that lets the shell know where to find commands\u2026 commands like \"sed\". If you overwrite it, \"sed\" will not be found. .  Use another name; even lowercase \"path\" will work fine. .  *I'm fairly confident that you overwrote PATH because PATH should not be a directory \u2013\u00a0it should be a colon-separated list of directories. If \"[ -d $PATH ]\" is true it either implies you have a very restrictive context for PATH, or, more likely, you have overwritten it. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_21860203",
      "task": "Can't execute more than one shell command at a time",
      "P-task": "execut one shell command time",
      "F_verb": "execute",
      "P-body": "You need to add a new line after each command: .  ",
      "P-tags": "android root shell runtim exec",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP at NP"
    },
    {
      "id": "so_66975478",
      "task": "How can I read a file into a variable in bash",
      "P-task": "read file variabl bash",
      "F_verb": "read",
      "P-body": "\"Q\" contains the asterisk. It is the unquoted expansion of \"$Q\" that replaces the \"*\" with a list of files. .  The right-hand side of an assignment is not subject to path name expansion, so \"Q=*\" would work as well, and the command substitution used to read from the file is also not affected. \"Q=$(cat hello)\" works fine: you just need to quote the expansion of \"Q\". .  ",
      "P-tags": "double-quot bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP into NP in NP"
    },
    {
      "id": "so_44913528",
      "task": "Move folder but keep preceding structure using shell in CENTOS6.8",
      "P-task": "move folder keep preced structur use shell centos6 8",
      "F_verb": "keep",
      "P-body": "I don't really understand what are you trying to do, but something as ...? .  I think I'm missing something tho .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V S_ING using NP in NP"
    },
    {
      "id": "ul_538970",
      "task": "How to use variable in sed command",
      "P-task": "use variabl sed command",
      "F_verb": "use",
      "P-body": "Variables are not expanded in single quotes. Use this: .  ",
      "P-tags": "variabl command-lin shell-script sed",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_23066322",
      "task": "how does one install python modules",
      "P-task": "one instal python modul",
      "F_verb": "install",
      "P-body": "If you have root you can hand move these files to the System wide python \"../lib/site-packages/\" or you can follow the instructions in this post. Adding module to sys.path .  You are probably better off(unless you need to absolute bleeding edge) installing the package from pypi. Packages from here are typically installed using either \"ez_install\" or \"pip\".  .  Its worth nothing that Python typically has two notions of where packages are installed \"System\" and \"virtualenv\". The \"system\" package are globally available to all scripts executed when running the untainted \"python\" executable. The \"virtualenv\" libraries are available from a command line where you have sourced a \"virtualenv\". The \"virtualevn\" may or may not have access to the \"System\" packages depending on how you have set it up. As @wooble noted your are best served by creating a \"virtualenv\" especially if you are experimenting.  .  As an aside...aside you can explore the \"pyenv\" and \"pyenv-virtualenv\" project. These allow you to easily manage what versions of python are installed as well as providing your with all the package management stuff setup for you. Using this method installing PyVCF is as simple as calling \"pip install PyVCF\" .  ",
      "P-tags": "linux python",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_33121965",
      "task": "How do I capture a specific word on a bash screen using Python?",
      "P-task": "captur specif word bash screen use python",
      "F_verb": "capture",
      "P-body": "This little code snippet will execute your command in a subprocess, and will give you the possibility to capture the standard output.  .  If you only want the first column of the second line, you can do that: .  ",
      "P-tags": "python-2 7 python shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "so_24087504",
      "task": "in anyone can explain why i can't run some command with user permission granted..?",
      "P-task": "anyon explain run command user permiss grant",
      "F_verb": "run",
      "P-body": "Even \"ifconfig\" will not perform any action as non-root. If you are executing it without any arguments it will just print the current state, which can be considered secure. If you are using it to change some network settings, it will require root permissions as \"shutdown\" does. This is because it will then attempt to write to files, which are writable by root only or perform other actions which are restricted to the root user.  .  ",
      "P-tags": "operating-system filesystem maco bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_35031382",
      "task": "How to check the output only contains a specific string",
      "P-task": "check output contain specif string",
      "F_verb": "check",
      "P-body": "Have it this way: .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_40153240",
      "task": "How to change AuthenticationLevel attribute from Win32_DCOMApplicationSetting class using powershell?",
      "P-task": "chang authenticationlevel attribut win32_dcomapplicationset class use powershel",
      "F_verb": "change",
      "P-body": "I solved it! .  Just call the put method from $wmi instance. .  ",
      "P-tags": "powershel dcom wmi",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "so_69745913",
      "task": "PowerShell - How to Concatenate variable with text? on same line on text file",
      "P-task": "powershel - concaten variabl text\nline text file",
      "F_verb": "concatenate",
      "P-body": "try this .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "au_751175",
      "task": "\"git config --list\" command not showing complete list, is the configuration incomplete?",
      "P-task": "git config -- list command show complet list configur incomplet",
      "F_verb": "show",
      "P-body": "No, a default installation and only specifying \"user.name\" and \"user.email\", you will only have those two options list. Take a look at the documentation on where these values are pulled: .   If not set explicitly with --file, there are four files where git config will search for configuration options: .  $(prefix)/etc/gitconfig .  System-wide configuration file. .  $XDG_CONFIG_HOME/git/config .  Second user-specific configuration file. If $XDG_CONFIG_HOME is not set or empty, $HOME/.config/git/config will be used. Any single-valued variable set in this file will be overwritten by whatever is in ~/.gitconfig. It is a good idea not to create this file if you sometimes use older versions of Git, as support for this file was added fairly recently. .  ~/.gitconfig .  User-specific configuration file. Also called \"global\" configuration file. .  $GIT_DIR/config .  Repository specific configuration file. .   Take a look at the options. Most have defaults or default behavior that git will take if not specified. .  To answer your question, you should have a usable configuration even with those couple specified. .  ",
      "P-tags": "git text-editor command-lin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "so_11324062",
      "task": "Trying to get meaningful data from an output text file using powershell",
      "P-task": "tri get meaning data output text file use powershel",
      "F_verb": "get",
      "P-body": "Try this it should work.Tested using your example. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "au_45746",
      "task": "Where do I find the default Ambiance theme?",
      "P-task": "find default ambianc theme",
      "F_verb": "find",
      "P-body": "You can get it from the source package of the light-themes using: .  \"sudo apt-get source light-themes\" .  ",
      "P-tags": "theme ambianc",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "au_629718",
      "task": "Why does software differ from desktop to desktop environment?",
      "P-task": "softwar differ desktop desktop environ",
      "F_verb": "differ",
      "P-body": "A more efficient question would be: Why there is so many distributions that look the same except for the logo! .  Even though this may have some disadvantages as you said of reinventing the wheel, but this has many advantages. This is freedom which Linux and open source stands for. .  This is power of Linux. The diversity, you can find many alternatives for the same application. .  This is not weakness instead this is powerful, a person who uses Linux can have many choices to work on. .  Plus, each software comes from a different background with different programming language, also developers have their personal attitude. .  An important point to list here, that most of applications in Linux are community based, with non-profit developers which means those developers don't have a single company to work in, though collaboration needs union and founding a company to sponsor and direct. .  Another note: Also you should note that in really most of these applications are not really reinventing the wheel, most of them depend on the same core packages, differences mostly on appearance. For example, \"k3b\" and \"brasero\" are both depend on same core package \"cdrecord\" and \"wodim\". .  ",
      "P-tags": "desktop-environ",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V from NP to NP"
    },
    {
      "id": "au_155562",
      "task": "Ready-to-use time and/or datetime selection widgets for GTK3?",
      "P-task": "ready-to-us time datetim select widget gtk3",
      "F_verb": "use",
      "P-body": "For the calendar you can use \"Gtk.Calendar\" which is part of GTK itself (and available to embed in your app in Glade. I am not aware of a slider for selecting the time, but you could add this easily with some \"Gtk.SpinButton\" widgets. .  ",
      "P-tags": "application-develop gtk3 python",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP"
    },
    {
      "id": "so_46779644",
      "task": "Why does powershell executes my property getters",
      "P-task": "powershel execut properti getter",
      "F_verb": "execute",
      "P-body": "It's difficult to tell without seeing your code, but there's tons of ways this could be happening. If the object is being displayed at all, the properties are probably all being read. .  You should change those to methods, and then they won't get read without specifically being invoked. .  Or, change your getters to detect an uninitialized object (you should be doing this already if it's possible for consumers to end up with such an object). .  Edit: With your code posted, it's clear: .   \"SetMedia\" returns a \"VlcMedia\", which contains a \"Statistics\" property, which is automatically invoked by PowerShell. .   Everything returned in PowerShell goes somewhere. If you don't assign it or redirect it, it gets sent to the pipeline. .  It seems that you don't want or need the output from this method, so you should either assign it to a variable or dispose of the return in one of a few ways: .  (note: piping to \"Out-Null\" is the least performant, which is magnified since you're doing this in a loop) .  If you want to use the value later (not shown in your code), assign it and use it later. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_999038",
      "task": "How can I get the manufacturer of GPU via command line in Ubuntu?",
      "P-task": "get manufactur gpu via command line ubuntu",
      "F_verb": "get",
      "P-body": "To show the manufacturer of the GPU and other verbose information about the GPU, open the terminal and type: .  The \"-vnn\" options are: .  \"-v\" \u2013 \u00a0 \u00a0verbose output \"-nn\" \u2013 display both the description and the number. display the PCI vendor code and the device code only as numbers  .  The first line of the output has the name of the vendor, the model name/series and the pci id. Note the numbers enclosed by a pair of brackets having the form 1234:5678. Such a number is present for almost all graphics cards. The first 4-digit number (1234) indicates the vendor id and the second number (5678) indicates the pci id, which indicates the model of the graphics processing unit. .  ",
      "P-tags": "graphic nvidia gpu command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP via NP in NP"
    },
    {
      "id": "so_9471101",
      "task": "Sort CSV file by column priority using the \"sort\" command",
      "P-task": "sort csv file column prioriti use sort command",
      "F_verb": "use",
      "P-body": " ",
      "P-tags": "sql-order-bi sort csv unix",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_45714104",
      "task": "How to execute two NPM commands sequentially copying a file as the last step?",
      "P-task": "execut two npm command sequenti copi file last step",
      "F_verb": "execute",
      "P-body": "\"copy\" is not a valid bash command. Try using \"cp\" instead. .  You can write a nodejs script that just copies that file. .  copy.js .  I got it running using M$-DOS \"COPY\". It also works using PowerShell using \"Copy-Item\". .  Don't forget you have to use backslashes on M$, which you also need to escape.  .  \"\"deploy\": \"COPY .\\\\a\\\\test .\\\\b\\\\test\"\" or \"\"deploy\": \"Copy-Item .\\\\a\\\\test .\\\\b\\\\test\"\" .  ",
      "P-tags": "npm-script post-build-ev angular npm powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_ING"
    },
    {
      "id": "au_537749",
      "task": "What's the best way to copy `previously run command` to another terminal?",
      "P-task": "best way copi previous run command anoth termin",
      "F_verb": "copy",
      "P-body": "Write out your history in the source terminal: .  Then load it in your target terminal: .  If you executed nothing in between, the long long command should be the third last command: .  Or you can do \"history\", note the number of the long long command (say 2365), and do: .   From \"help history\": .  You can also use \"history -n\" instead of \"-r\": .  Also see this SO question. .  ",
      "P-tags": "command-lin",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP to NP"
    },
    {
      "id": "su_992192",
      "task": "How to fetch address and modify the value in key/value format file?",
      "P-task": "fetch address modifi valu key valu format file",
      "F_verb": "modify",
      "P-body": " Current record no. \"NR\") equals current file record no. just for the first file, then \":\"'s substitution is done, subsequently the line is placed on the \"macadd\" variable, and \"next\" skips line output. .  The other instructions are applied to the \"hostapd.conf\" file; final \"1\" stands for \"true\", thus lines are printed. .  If everyting works fine, you may redirect command output to a new file, and replace \"hostapd.conf\". .  Notes: .   files order does matter, as you can tell \"gawk\" features in-place replacement starting from 4.1.0  ",
      "P-tags": "awk raspberry-pi shell-script",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_57591958",
      "task": "Replace value of an environment variable declared in a file",
      "P-task": "replac valu environ variabl declar file",
      "F_verb": "replace",
      "P-body": "Just use a scriptable editor like \"ed\": .  ",
      "P-tags": "envsubst bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_319963",
      "task": "Unable to configure wifi on Packard Bell Dot S",
      "P-task": "unabl configur wifi packard bell dot",
      "F_verb": "configure",
      "P-body": "From your desktop clic connect .   .  Next step clic Load module .   .  Choose \"b43\" or \"b43-legacy\" then press Load .  If the tow modules doesn't work , you can choose Ndiswrapper then select the \".inf\" file (of the windows driver) .  ",
      "P-tags": "broadcom wifi puppy-linux",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP"
    },
    {
      "id": "so_67393159",
      "task": "Modify local users property description in Powershell 4.0",
      "P-task": "modifi local user properti descript powershel 4 0",
      "F_verb": "modify",
      "P-body": "Working with ADSI can be very tricky but, its super helpful since it usually doesnt rely on 3rd party modules. .  Without going super in depth on \"ADSI\", heres the easiest way you can change, or add a value to a property, the description property in this case: .  Using \"$User.SetInfo\" method, we can write the changes to the database. It's not a method you would get either when piping to a \"Get-Member\". Unfortunately, it's one that you would need to know already. Using Dot Notation we can reference the property you'd like to change, then assigning it a value just like we would when assigning a value to a variable: \"$var = value\". .  ",
      "P-tags": "ansibl user-interfac adsi powershel winapi",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "so_35106543",
      "task": "unix search/replace with wildcard",
      "P-task": "unix search replac wildcard",
      "F_verb": "replace",
      "P-body": " But be careful with \"sed -i\", it replaces files in place... Also this works for the specified search/replace strings, it might be more compicated if you need to escape things .  ",
      "P-tags": "unix php eclips regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V with NP"
    },
    {
      "id": "so_16970593",
      "task": "Translate names or not",
      "P-task": "translat name",
      "F_verb": "translate",
      "P-body": "Although some people have suggested hashing your usernames, this is both opaque to inspection (so you can't tell by examining the filesystem what the usernames that correspond to the directories are) and non-reversible (so neither human system administrators nor software can ever enumerate the usernames by consulting the filesystem). Therefore it may or may not work for you. .  I suggest encoding the usernames. By inspiring myself from the 2 main content encodings used in MIME, may I suggest either quoted-printable or base64? .   With quoted-printable, you can encode all the \"unusual\" bytes in the username while leaving most of the printable characters as-is. This way, it is still fairly obvious what the usernames are when examining the directory with \"ls\". You should encode at least all control characters (bytes with values between 0 and 31 as well as 127), =, /, and all chararters that are special to the shell (like space, quotes, $, #, etc...). The disadvantage of quoted-printable is that if the usernames are expected to contain a lot of these unusual characters, the filenames can become very long: each encoded sequence takes 3 bytes. .  Base64 is an encoding that will be more compact than quoted-printable in case the usernames might contain a lot of characters that need encoding, but it is not immediately readable to humans, so an \"ls\" of your directory doesn't look very clear. Note that you have to modify the last character of standard base64, for example by changing the last character of the alphabet from / to - like this because otherwise the encoded strings can contain /. .   ",
      "P-tags": "structur unix oop",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_35743960",
      "task": "How to save the name of the file if it is being treated in the script",
      "P-task": "save name file treat script",
      "F_verb": "save",
      "P-body": "You don't need a loop (and see https://unix.stackexchange.com/questions/169716/why-is-using-a-shell-loop-to-process-text-considered-bad-practice for why that's a Good Thing): .  ",
      "P-tags": "awk script bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP of NP if S"
    },
    {
      "id": "so_27704917",
      "task": "Apply css only for linux chrome but not for windows chrome",
      "P-task": "appli css linux chrome window chrome",
      "F_verb": "apply",
      "P-body": "The only way I can think of (and I don't like it) is to use JavaScript (as you tagged \"javascript\" on the question) to detect \"Linux\" in the user agent string and then add a class to \"body\" or similar to activate the Linux-only style; or the converse, add the class only when not using Linux. But I'd lean toward the former.) .  or .  Then use the \".linux\" or \".not-linux\" ancestors when defining the relevant styles. .  ",
      "P-tags": "javascript linux html debian css",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_200409",
      "task": "how to exit activities screen?",
      "P-task": "exit activ screen",
      "F_verb": "exit",
      "P-body": "Press: CTRL+ALT+F1 Then login and restart your \"gdm\", \"kdm\" , or so on. It's related to your Desktop Environment. .  ",
      "P-tags": "gnome",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_55887626",
      "task": "Read only and write only using open()",
      "P-task": "read write use open",
      "F_verb": "write",
      "P-body": "Your \"argc\" check is wrong. The value of \"argc\" is the number of valid elements in the \"argv\" array, including the \"command\" in \"argv[0]\". If there's two arguments, then the value of \"argc\" will be \"3\". .  This should have been quite easy to see, primarily since if you provided two arguments to the program then the error message about it should have been written. And if you used a debugger then that should have made it obvious as well. .  ",
      "P-tags": "c unix shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V using NP"
    },
    {
      "id": "au_90907",
      "task": "Determine what buttons are in CCSM?",
      "P-task": "determin button ccsm",
      "F_verb": "determine",
      "P-body": "It shows 20 buttons by default, which doesn't mean you actually can trigger 20 buttons. .  To check which ones work, you can use the \"xev\" command. Type the command into a terminal, ensure the xev window has focus and then try your buttons: .   .  Button numbers are shown as highlighted. .  ",
      "P-tags": "ccsm compiz",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "so_284608",
      "task": "How do I make Subversion use a third-party diff tool?",
      "P-task": "make subvers use third-parti diff tool",
      "F_verb": "make",
      "P-body": "From a Beyond Compare forum post: .  /usr/bin/bcompare_svn: .  The invocation of bcompare is obvious but I had to add \"exit 0\" so that svn would open more than one file at a time. .  To make svn invoke my script, I added the following line in the [helpers] section in ~/.subversion/config .  ",
      "P-tags": "svn linux diff beyondcompar",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "su_656895",
      "task": "Grid Engine / multithreading / multi-core / multi-cpu: How to decide optimum number of threads?",
      "P-task": "grid engin multithread multi-cor multi-cpu : decid optimum number thread",
      "F_verb": "decide",
      "P-body": "Well there's a few parts to this question - in general a good rule of thumb is to run no more threads than you have logical processors - though this is usually for the whole system, and may depend on load. To find out how many physical processor cores you have, you can use \"cat /proc/sysinfo\". It'll print a set of lines for each logical core so scroll down and look at the last one (I have 8 almost identical ones on my quad core, HT system) .  I'll pick out the important lines here physical id: 0 (this is the first socket - if you use more than one socket then check the processor and cpu cores for each physical jd - if this is a number greater than 0 you have multiple sockets)  .  Processor : 7 (This number starts from 0, to n-1,this is the 8th logical core in its socket - looking at the largest number you have for a set of values sharing a physical id )  .  cpu cores : 4 (I have 4 physical cores - this will be the same for every core, and and since SMP generally uses identical cores, should be the same on a dual socket system)  .  My processor should allow me to run 8 threads simultaneously, assuming a core per thread. That said, depending on the run time, and other factors you may be able to get away with more .  SO has quite a few questions on this and picking two of those, the answers to this question suggest that one thread per logical core is a good idea though this one suggests you may be able to go higher. As such, unfortunately the answer is to start with one thread per process, and tune it higher - which may be an insanely high number of threads, if they arn't long running, memory hungry threads. .  ",
      "P-tags": "cpu linux gridengin",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_386979",
      "task": "Info on cp --preserve=links",
      "P-task": "info cp -- preserv link",
      "F_verb": "preserve",
      "P-body": "The \"--preserve=links\" option does not refer to symbolic links, but to hard links. It asks \"cp\" to preserve any existing hard link between two or more files that are being copied. .  You can see that the two original files are hard-linked and their inode number is 6034008. .  You can see now that without \"--preserve=links\" their copies have two different inode numbers: there is no longer a hard link between the two. .  You can see now that with \"--preserve=links\", the two copies are still hard-linked, but their inode number is 6089617, which is not the same as the inode number of the original files (contrary to what \"cp --link\" would have done). .  ",
      "P-tags": "hard-link symlink cp",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "au_527571",
      "task": "cannot install openoffice",
      "P-task": "instal openoffic",
      "F_verb": "install",
      "P-body": "I am running OpenOffice fine on my xubuntu 14.04. Three things to keep in mind: .   Make sure you really removed any LibreOffice package prior installing OpenOffice (for example using: .   Install the OpenOffice \".deb\" files; like you did .  don't forget about the DESKTOP integration, so under en-US/DEBS .    From what you are writing, you might have missed \"3.\" .  ",
      "P-tags": "xubuntu openoffic org",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_49130176",
      "task": "How to execute \"sudo nvm\"?",
      "P-task": "execut sudo nvm",
      "F_verb": "execute",
      "P-body": "Consider defining a shell function wrapper: .  ...thereafter: .  ...or... .   To explain the above logic: .   Using the \"-l\" and \"-i\" arguments to bash ensure that dotfiles for the target user (in this case \"root\") are run, which appears to be necessary for \"nvm\"'s correct operation. \"bash -c\"'s immediate next argument must be a script. The arguments following that become \"$0\", \"$1\", etc. in the context where the script is executed. \"\"$@\"\" in the function context refers to the full set of arguments to the function. \"\"$@\"\" in the \"bash -c\" script's context refers to the full set of arguments (starting at \"$1\", so skipping the \"_\") passed to the shell after the \"-c\".  ",
      "P-tags": "termin unix nvm shell node js",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_52493610",
      "task": "Bash: echo showing blank value",
      "P-task": "bash : echo show blank valu",
      "F_verb": "echo",
      "P-body": "When using \"grep -q\" you don't get any output from \"grep\". Only return status is available that you can get using: .  As per \"man grep\": .   \"-q, --quiet, --silent\" Quiet mode: suppress normal output. grep will only search a file until a match has been found, making searches potentially less expensive. .   Note that if you are not using \"SampleOutput\" anywhere else then you can directly use: .  ",
      "P-tags": "awk grep linux bash sed",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V S_ING"
    },
    {
      "id": "ul_19875",
      "task": "Setting vim filetype with modeline not working as expected",
      "P-task": "set vim filetyp modelin work expect",
      "F_verb": "set",
      "P-body": "So, after some digging, it transpires that the system \"vimrc\" shipped with OSX sets the \"modelines\" (note the trailing 's') variable to 0. This variable controls the number of lines in a file which are checked for set commands. Setting modelines to a non-zero value in my \".vimrc\" solved the problem. .  Full output, for the curious: the output of \"vim --version\" prompted me to check the system vimrc: .  Looking at the system vimrc: .  Led me to the \"modelines\" variable. It appears that MacVim does not source this system file (perhaps looking for a system GVIMRC instead? \":help startup\" isn't clear). .  ",
      "P-tags": "osx vim",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP with NP as NP"
    },
    {
      "id": "so_13181982",
      "task": "Set an environment variable from a process that will be visible by all processes",
      "P-task": "set environ variabl process visibl process",
      "F_verb": "set",
      "P-body": "This is simply not possible. .  Setting an environment variable (or changing your current environment) is only visible from the children (and descendants) processes of your current process. .  Other processes, in particular the parent process (usually the shell running in the terminal where you start your program) are not affected. .  You might play dirty tricks like e.g. adding lines into \"$HOME/.bashrc\" etc. But you should not. .  You just need to document what environment variables are relevant. It is the user's responsibility to set environment variables (perhaps by manually editing his \"$HOME/.bashrc\" etc etc). Leave that freedom to your user. Explain to him how to do that and why. .  You edited your question to explain that  .   I have 10 processes that use the same library. The problem is that in that library a checking procedure ( which is CPU hungry ) is performed. I want to avoid that library checking procedure to be executed for every process. .   But you definitely should not need to change environment variable for that. .  You could .   decide and document that the checking is not performed, unless some particular environment variable (or some program argument) is given .  decide that the checking is given a particular file name, and use file locked write to write that file, and use file locked reads to read it again .  Have the checking write its result in some known in advance file, and read that file before deciding it you want to make the costly checks .  Have one process starting all the others, and inform them about the check (perhaps indeed setting some environment variable or some program argument) or use some Inter Process Communication trick to communicate with the others (you could use sockets, locked files, shared memory, etc etc...) .  Do many other tricks. .   ",
      "P-tags": "c environment-vari glib unix",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP from NP that S"
    },
    {
      "id": "so_11808356",
      "task": "Handling KILL signal in Service?",
      "P-task": "handl kill signal servic",
      "F_verb": "handle",
      "P-body": "From \"man 7 signal\": .   The signals SIGKILL and SIGSTOP cannot be caught, blocked, or ignored. .   This is fundamentally by kernel design. Think about it: if a process could ignore all signals whatsoever, then how would you stop it if it ran away uncontrolled? No, what you'll have to do is see to it that the KILL signal is not sent. Running your program under its own userid should achieve this, as long as no one with administrative privileges generates the signal -- but even this requirement may be practically impossible to meet. By design, the system provides the basic ability to kill a process, on the theory that the user or sysadmin might (for whatever reason) want the process killed. .  ",
      "P-tags": "android linux process",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP in NP"
    },
    {
      "id": "au_612342",
      "task": "How to install the Vala environemt?",
      "P-task": "instal vala environemt",
      "F_verb": "install",
      "P-body": "The recommended method is to add a repository to your system: .  If you are unsure on how to add this read the link on the launchpad page. Verification of the repository: .  After this you can use Ubuntu Software Center or \"sudo apt-get install valac-0.26\" from command line to install the latest stable version of vala (read the description on the launchpad page for more details). .  From our community page on vala: .   The Vala team PPA also contains: .   libgee - Libgee is a collection library providing GObject-based interfaces and classes for commonly used data structures. vtg - Vala Toys for gEdit is an experimental collection of plugins that extends the gEdit editor to make it a better programmer editor for the Vala language. valide - Val(a)IDE is an Integrated Development Environment (IDE) for the Vala programming language. gtksourcecompletion - used by the editor packages. Source completion is not working in the PPA builds; there is no library file created.   ",
      "P-tags": "compil vala software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "ul_342430",
      "task": "Unable to log in to tty1",
      "P-task": "unabl log tty1",
      "F_verb": "log",
      "P-body": "The error was with the \"plymouth\" hook being executed \"mkinitcpio\" at startup which itself did not exist and somehow caused issues with the \"tty\". I removed \"plymouth\" from \"HOOKS\" section in \"/etc/mkinitpcio.conf\" and ran \"mkinitpcio -p linux\" as \"root\". The issue was resolved upon \"reboot\". .  ",
      "P-tags": "arch-linux tti",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V in to NP"
    },
    {
      "id": "so_42890035",
      "task": "How to extend string to certain length",
      "P-task": "extend string certain length",
      "F_verb": "extend",
      "P-body": "Bash provides a simple way to get the length of a string stored in a variable: \"${#STRING}\" .  The expected output you posted doesn't match the requirements in the question. I tried to follow the requirements and ignored the sample expected output and the code you posted. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "inflate/extend",
      "pat": "V NP to NP"
    },
    {
      "id": "so_11905830",
      "task": "nmap shows less ports open when it runs against ip other than localhost",
      "P-task": "nmap show less port open run ip localhost",
      "F_verb": "run",
      "P-body": " why nmap shows more ports open when it's running against localhost while less ports are shown when it's running against the ip .   Some applications decided to explicitly listen (\"bind\" actually) only on localhost, i.e. \"127.0.0.1\". You can do a \"netstat\" to check things out. .  ",
      "P-tags": "port linux nmap",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V against NP"
    },
    {
      "id": "au_911940",
      "task": "Error: .ini file does not include supervisorctl section",
      "P-task": "error : ini file includ supervisorctl section",
      "F_verb": "include",
      "P-body": "Adding a blank \"[supervisorctl]\" section seems to resolve the issue for me: .  ",
      "P-tags": "supervisor 16 04",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP"
    },
    {
      "id": "so_35274687",
      "task": "Launch an unparented process from PowerShell",
      "P-task": "launch unpar process powershel",
      "F_verb": "launch",
      "P-body": "A \"classic\" trick, due to the simple nature of a Process Tree in Windows (just a backwards linked list to each process' ancestor), is to open a separate process that then in turn launches your new \"independent\" process. .  In \"powershell.exe\" this is super easy: .  The \"inner\" \"powershell.exe\" instance launches \"notepad.exe\", and exits immediately, leaving \"notepad.exe\" orphaned .  ",
      "P-tags": "powershel process",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP from NP"
    },
    {
      "id": "so_8500180",
      "task": "How to find the port number of any PC?",
      "P-task": "find port number pc",
      "F_verb": "find",
      "P-body": "I don't know the standard, but I say it's not. At least, I don't like to do it like that. .  You can check occupied ports by parsing the outputs of programs like \"netstat\" and avoid using those. You can also use the method that attempts connecting on one port, and upon failure, tries another port. Unless you're really really unlucky, you should get a valid port on second try. .  You should use ports within the ranges of 49152\u201365535. Ports below 49152 are reserved/registered. .  ",
      "P-tags": "socket unix port tcp c",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "so_1828236",
      "task": "How to make this sed script faster?",
      "P-task": "make sed script faster",
      "F_verb": "make",
      "P-body": "The best I was able to do with sed, was this script: .  In my tests, this ran about 30% faster than your sed script. The increase in performance comes from combining the first two regexen and omitting the \"g\" flag where it's not needed. .  However, 30% faster is only a mild improvement (it should still take about an hour and a half to run the above script on your 1GB data file). I wanted to see if I could do any better. .  In the end, no other method I tried (awk, perl, and other approaches with sed) fared any better, except -- of course -- a plain ol' C implementation. As would be expected with C, the code is a bit verbose for posting here, but if you want a program that's likely going to be faster than any other method out there, you may want to take a look at it. .  In my tests, the C implementation finishes in about 20% of the time it takes for your sed script. So it might take about 25 minutes or so to run on your Unix server. .  I didn't spend much time optimizing the C implementation. No doubt there are a number of places where the algorithm could be improved, but frankly, I don't know if it's possible to shave a significant amount of time beyond what it already achieves. If anything, I think it certainly places an upper limit on what kind of performance you can expect from other methods (sed, awk, perl, python, etc). .  Edit: The original version had a minor bug that caused it to possibly print the wrong thing at the end of the output (e.g. could print a \"null\" that shouldn't be there). I had some time today to take a look at it and fixed that. I also optimized away a call to \"strlen()\" that gave it another slight performance boost. .  ",
      "P-tags": "sed linux perform unix",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_59064152",
      "task": "Start antivirus scan from a script on Azure Linux VM",
      "P-task": "start antiviru scan script azur linux vm",
      "F_verb": "start",
      "P-body": "Seems there is something wrong with your \"ScriptPath\" param . If you are using Azure Automation, we can't place static script files in it , but we can download our script first and place it in \"c:/temp\" folder of Azure automation.  .  I did some tests on my side , I placed my scripts in Azure storage account , before I need to run this script, I will download it to Azure automation temp folder so that I can specify a path to run it .  .  Try the PS below in Automation:  .  Modules I imported :  .  I place my script in my storage account, in this case , it is used for download something :  .  My test script content :  .  Test on Azure automation and its result :   As you can see the file has been download successfully .  .  Btw, there is no need to use remote powershell here , you can use run command feature of Azure VMs to run your scripts on Azure VMs directly .  .  ",
      "P-tags": "azur azure-data-factory-2 linux azure-funct virtual-machin",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP from NP on NP"
    },
    {
      "id": "ul_353867",
      "task": "How do I permanently change environment variables via terminal? (Ubuntu 16.04)",
      "P-task": "perman chang environ variabl via termin\nubuntu 16 04",
      "F_verb": "change",
      "P-body": "\"export\" will set them during that session. .  What you wrote is the content of one of the variables. The \"PATH\" variable. .  To check what it's currently set to, you can use, .  From a terminal. .  This can be overrides for your user on multiple places. Most common would be a few hidden files on your home directory. .  Check the following files, .  See if you find a line that references the \"PATH\" .  You can post here the content. .  ",
      "P-tags": "ubuntu login environment-vari",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP via NP"
    },
    {
      "id": "so_57620852",
      "task": "Exact same OpenCover script completes successfully when run locally, but fails when run via Azure DevOps",
      "P-task": "exact opencov script complet success run local fail run via azur devop",
      "F_verb": "run",
      "P-body": "The solution is to use: .  rather than: .  Reference: https://github.com/OpenCover/opencover/issues/915#issuecomment-526284026 .  ",
      "P-tags": "net c azure-devop opencov powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V via NP"
    },
    {
      "id": "au_300617",
      "task": "Is it possible to close vlc to system tray?",
      "P-task": "possibl close vlc system tray",
      "F_verb": "close",
      "P-body": " Go to Tools>Preferences Under interface you will find two options to mark, I have marked them for you in this image:   Check \"Systray popup when minimized\" Check \"Show systray icon\" .  3. Close VLC. .  4. Now open it using: .  Hope this works for you. .  ",
      "P-tags": "vlc set",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP to NP"
    },
    {
      "id": "au_324072",
      "task": "How to exclude/delete files only?",
      "P-task": "exclud delet file",
      "F_verb": "exclude",
      "P-body": "I presume you want to delete them... .  \"find -type f -delete\" .  This will delete all files in the current folder and all subfolders but leave the directories intact. .  ",
      "P-tags": "file command-lin",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_20479649",
      "task": "How to delete a table in postgresql",
      "P-task": "delet tabl postgresql",
      "F_verb": "delete",
      "P-body": "Most probably explanation: some other open transaction is holding an exclusive lock on the table. .  You are using pgAdmin, so you can check with \"Tools -> Server Status\". The activity pane lists all current connections. For instance, there is one (or more) listings for every open SQL window. Look for long running connections. .  You can also try to issue a \"DROP TABLE\" and check this list. With any luck you'll see what blocks it. Once you have identified the troublemaker and made sure, it's not needed, you might be able to kill the process. Might be vacuuming gone haywire because of bad settings .. .  That, or something is seriously broken. .  ",
      "P-tags": "sql postgresql linux ubuntu",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "so_57092909",
      "task": "find members of groups excluding disabled users",
      "P-task": "find member group exclud disabl user",
      "F_verb": "find",
      "P-body": "The following should produce the output you want in the \"$Table\" variable. You can then pipe \"$Table\" to one of the \"format-*\" commands. .  Explanation: .  The \"Get-ADGroupMember\" command will not provide the \"Enabled\" property of its returned objects. You will need to feed its output into another command like \"Get-ADUser\" for that data. Since you already stored all of the enabled users in \"$US\", we can simply compare \"$US\" collection to the results of each \"Get-ADGroupMember\" output. .  I removed most of the \"Where-Object\" commands in favor of using the \"-Filter\" parameter on the AD commands. Almost always, the \"-Filter\" parameter will be faster especially when you are comparing AD indexed attributes like \"Name\" and \"Enabled\". .  You do not need to store each output object in a variable unless you are going to further manipulate it. This is why \"$Record\" was removed. Instead, all returned objects are stored in the array \"$Table\". I removed the \"+=\" operator mainly because of its inefficiency when repeatedly building arrays. Also, you can simply set a variable to the output of a \"foreach\" loop, which will result in the array you require. Since we created a custom object on each loop iteration and provided the properties at the time of declaration, \"[ordered]\" is not required. However, if you create the hash table first and then create a corresponding object, you will potentially need to use \"[ordered]\". As an aside when you are creating custom objects that are involved in a loop, it is usually best practice to create a new object each time. Otherwise, you could unintentionally update values on the wrong objects. Just because you add an object to an array, you can still update its properties after the fact.  .  The \"Compare-Object\" command ties everything together. The \"-ExcludeDifferent -IncludeEqual\" parameter combination will only output objects with matching property values. Since we are comparing \"$Arrayofmembers\" and \"$US\", that is ideal. The \"-PassThru\" switch allows the objects to be returned with all of the properties that were passed into the command. Then you can use the \"Select-Object\" command to pick which properties matter to you. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_589904",
      "task": "Convert time format using sed",
      "P-task": "convert time format use sed",
      "F_verb": "convert",
      "P-body": "This should work: .  Explanation .  When you write .  in the second part of the \"sed\" command, you're not saying \"replace with the digits you had as input\" but \"replace with some digits\", so \"sed\" can't understand what you want to use as a replacement. .  Using regex group (check this simple explanation) will say to \"sed\" \"use the exact digits you had as input\". .  ",
      "P-tags": "sed regular-express",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP using NP"
    },
    {
      "id": "so_62938031",
      "task": "Regex to match string at certain position",
      "P-task": "regex match string certain posit",
      "F_verb": "match",
      "P-body": "You may use this \"awk\": .  Note that using \"1\" in the end will print each record including header. .  ",
      "P-tags": "sed unix regex",
      "source": "qa",
      "cate": "match",
      "pat": "V NP at NP"
    },
    {
      "id": "su_806487",
      "task": "How to find files by type and show it's respective path",
      "P-task": "find file type show respect path",
      "F_verb": "find",
      "P-body": " ",
      "P-tags": "zsh command-lin maco bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP by NP"
    },
    {
      "id": "so_66127662",
      "task": "Sum various columns to get subtotal depending on a criteria from a row using Powershell",
      "P-task": "sum variou column get subtot depend criteria row use powershel",
      "F_verb": "get",
      "P-body": "Working code .  Explanation: .  Use \"Group-Object\" to make collection of groups. Groups have 4 properties: .   \"Name\" - Name of group, equals to stingified values of property(-ies) you're grouping by \"Values\" - Collection of values of properties you're grouping by (not stringified) \"Count\" - Count of elements grouped into this group \"Group\" - Values of elements grouped into this group  For grouping by single string properties (in this case it is ok), you can easily use \"Name\" of group, otherwise, always use \"Values\". .  So after \"Group-Object\", you iterate not on collection-of-rows of CSV, but on collection-of-collections-of-rows grouped by some condition. .  \"Measure-Object\" can process more than one propertiy for single pass (not mixing between values from different properties), we use this actively. This results in array of objects with attribute \"Property\" equal to passed to \"Measure-Object\" and value (\"Sum\" in our case). We move those \"Property=Sum\" pairs to hashtable. .  \"[PSCustomObject]\" converts hashtable to object. Objects are always better for output. .  ",
      "P-tags": "powershel csv sum",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP from NP"
    },
    {
      "id": "so_32224923",
      "task": "Symlink \"Permission denied\"",
      "P-task": "symlink permiss deni",
      "F_verb": "deny",
      "P-body": "User \"www\" simply does not have access to \"/home/user/foo/bar/baz\". .  Check this and add proper access rights to this directory. .  ",
      "P-tags": "linux symlink",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "ul_230544",
      "task": "How to see the actual nameservers of a domain instead of the \"nsrecords\"",
      "P-task": "see actual nameserv domain instead nsrecord",
      "F_verb": "see",
      "P-body": "If you want to see the nameservers listed by the registrar, those are available in the DNS system via the root servers.  .  For example: .  If you modify the name servers listed in your registrar account, those servers will be reflected in the root / gtld servers. When you modify your DNS zones that your nameservers serve, they have no effect on the results returned by the root servers. Additionally, the only records the root servers will return are NS and A/AAAA defined by the registrar for the listed NS records. These are just pointers to find the authoritative (per the registrar) name servers for a domain to send your queries to. .  ",
      "P-tags": "domain dn nslookup",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP of NP"
    },
    {
      "id": "so_25347638",
      "task": "svn import error: unable to connect to a repository at URL",
      "P-task": "svn import error : unabl connect repositori url",
      "F_verb": "connect",
      "P-body": "The \"file://\" URL you enter is incorrect because it's incomplete. You have to specify the full path to the repository on your local filesystem since you access the repository directly. So in your case the URL will be as in this command-line: .  \"svn import ./likeU file:///home/seoyoung/repository\" .  Read SVNBook! .  ",
      "P-tags": "svn ubuntu",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP at NP"
    },
    {
      "id": "so_59042496",
      "task": "How to select a table cell within a powerpoint using powershell",
      "P-task": "select tabl cell within powerpoint use powershel",
      "F_verb": "select",
      "P-body": "\"Table.Cell\" is a PowerPoint Method, within which the Property: .  Holds the value of the Text in the given cell. To get the text from cell(1,1) in your code, use: .  ",
      "P-tags": "powershel powerpoint",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP within NP using NP"
    },
    {
      "id": "so_56827791",
      "task": "Checking actual version of Python running my code",
      "P-task": "check actual version python run code",
      "F_verb": "check",
      "P-body": "There are several ways to detect the version of python your program is using. .  From your question I get the feeling you're not understanding why \"$ python -V\" and \"$ /usr/bin/python3 -V\" are returning different versions. This is simply due to the python command being soft linked to a specific binary version (in your case, 2.7). .  If you want to understand to which binary the python command on your shell is linked to: .  Programmatically you can get your Python version with: .  Which will result in the following output: .  You you're just wondering which version python is using when called via a shell, you can easily find out by: .  You can also inspect the header of your python file and check which interpreter is being used for that particular python script when you don't specify it when you're calling the script. i.e: \"$ ./python_file.py\") .  ",
      "P-tags": "python shell",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "so_57371255",
      "task": "Forked Service getting restarted as soon as it starts?",
      "P-task": "fork servic get restart soon start",
      "F_verb": "restart",
      "P-body": "The problem is with the Work directory I believe. .  If you defined variables in \"bash_profiles\" or \"bashrc\" that not get used by the systemd unit. You could use \"EnvironmentFile=\" section for that. .  Most likely the \"$root_dir\" variable is empty so \"cd $root_dir\" change the working director from what systemd unit defined ( \"WorkingDirectory=/opt/taskparticipant\" ) to javauser home directory. I think this is not the intended behavior. .  This can be verified if you change line \"cd $root_dir\" to \"cd ${root_dir:?}\" this way script exit with error if \"$root_dir\" variable is empty. .  ",
      "P-tags": "linux systemd shell bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V as S"
    },
    {
      "id": "au_1041649",
      "task": "Replacing a string with quotes selectively using sed",
      "P-task": "replac string quot select use sed",
      "F_verb": "replace",
      "P-body": "Use an address. The quotes are not a problem if you single quote your \"sed\" expression .  If you really need to match the whole pattern, fine: .  \"*\" matches any number of the preceding character (space). .  You can use \"\\s\" to also match tabs (any horizontal whitespace): .  Add the \"-i\" option after testing to modify the original file. .  ",
      "P-tags": "sed command-lin text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "ul_203690",
      "task": "How to replace multiple occurrences of a pattern with sed",
      "P-task": "replac multipl occurr pattern sed",
      "F_verb": "replace",
      "P-body": "Your problem comes from the \".*\". If you only match every character that is not a ' or a \" it will work: \"sed -ri \"s/\\[ ([0-9]+|(\\x27|\\x22)[^\\x27\\x22]*(\\x27|\\x22)) \\]/[\\1]/g\" file.php\" .  Even better (to take possible \" or ' into account): .  ",
      "P-tags": "replac sed regular-express",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP of NP with NP"
    },
    {
      "id": "su_567648",
      "task": "ps comm format always cuts the process name",
      "P-task": "ps comm format alway cut process name",
      "F_verb": "cut",
      "P-body": "The \"comm\" field (also \"/proc/$pid/comm\") is limited by the kernel to 16 bytes total (15 characters + terminating NUL byte). .  If the system is Linux and you own the process (or are root), you can obtain the executable path by following \"/proc/$pid/exe\" using the \"readlink\" command. .  Otherwise, you will have to use the \"cmd\" field (aliases \"args\", \"command\"). On Linux it's taken from \"/proc/$pid/cmdline\" (which is NUL-separated), so you can also use \"cut -d \"\" -f 1 /proc/$pid/cmdline\". .  Beware that both \"cmdline\" and \"comm\" can be changed by the process itself. .  ",
      "P-tags": "ps bash",
      "source": "qa",
      "cate": "cut/slash/separate/clip/crop",
      "pat": "V NP"
    },
    {
      "id": "su_676708",
      "task": "Gvim fails to open: E25: GUI cannot be used: Not enabled at compile time",
      "P-task": "gvim fail open : e25 : gui use : enabl compil time",
      "F_verb": "open",
      "P-body": "You need to install another package for GVIM; that'll also get you the \"gvim\" command: .  ",
      "P-tags": "linux gvim vim",
      "source": "qa",
      "cate": "open",
      "pat": "V at NP"
    },
    {
      "id": "so_57560190",
      "task": "How to install pyside2-uic in Ubuntu 16.04?",
      "P-task": "instal pyside2-u ubuntu 16 04",
      "F_verb": "install",
      "P-body": "I tried these commands and it worked. .  ",
      "P-tags": "uic ubuntu-16 04 python pyside2",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_53470631",
      "task": "errors while unserialize data received from shell exec in php",
      "P-task": "error unseri data receiv shell exec php",
      "F_verb": "receive",
      "P-body": "Unserialize is complaining about the leading single quote. But your serialized string also misses all double quotes. Since it was working online, I think your shell on localhost treats quotes differently. You can avoid problems like that, if you encode your arguments with e.g. base64. In your first script: .  and in your second script: .  ",
      "P-tags": "php shell-exec",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V from NP in NP"
    },
    {
      "id": "so_27964044",
      "task": "code to get address of last 2 called functions",
      "P-task": "code get address last 2 call function",
      "F_verb": "get",
      "P-body": "In general, you can't do that because you don't know the stack layout of your callers. Assuming they use standard stack frames you can use the \"backtrace\" function which is more portable, or \"backtrace_symbols\" if you want symbols. That said if you insist on manually walking the stack, here is an example: .  Sample run: .  ",
      "P-tags": "linux stack assembl",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "au_481208",
      "task": "Error libx264 not found",
      "P-task": "error libx264 found",
      "F_verb": "find",
      "P-body": "It happens because you are compiling libav with \"--enable-libx264\" which would need the libx264 headers to complete. It fails at the configure phase with: .  This can be fixed easily installing the needed headers package \"libx264-dev\" which should be done with \"sudo apt-get install yasm libvpx. libx264.\" but for some reason it doesn't for you: .  ",
      "P-tags": "software-instal",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_14850538",
      "task": "Making sure php script is only run locally",
      "P-task": "make sure php script run local",
      "F_verb": "make",
      "P-body": "You'll need to check if it is run from the command-line too to handle the cron case .  ",
      "P-tags": "linux php",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_17499272",
      "task": "Debugging shell scripts with line numbers",
      "P-task": "debug shell script line number",
      "F_verb": "debug",
      "P-body": "Put this at the top of the script you want to debug: .  and perhaps redirect the output to a file for easy analysis. .  ",
      "P-tags": "linux unix shell",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP with NP"
    },
    {
      "id": "so_68929376",
      "task": "How to get replace by id (Id value get from XML) and put into CSV, powershell",
      "P-task": "get replac id id valu get xml put csv powershel",
      "F_verb": "put",
      "P-body": " You need to modify the \"foreach\" loop to update the (in-memory) CSV rows (objects), and then save them back to a CSV file: .  ",
      "P-tags": "powershel xml csv",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V into NP"
    },
    {
      "id": "au_139662",
      "task": "How to start/stop downloads in Azureus (Vuze) via terminal?",
      "P-task": "start stop download azureu vuze via termin",
      "F_verb": "start",
      "P-body": "So far I found Flush which has command-line options which does my job but it has very less functionality compared to others. .  I use \"Flush\" to start or stop torrent downloads of running instance through terminal. .  I can use these options with flush. .  note: I didn't find anyway to do this in Vuze. .  ",
      "P-tags": "bittorr 11 04 command-lin",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP via NP"
    },
    {
      "id": "au_992571",
      "task": "GUI/Unity crashing in 16.04 LTS after updates 2018-01-04, compiz segfaults",
      "P-task": "gui uniti crash 16 04 lt updat 2018-01-04 compiz segfault",
      "F_verb": "update",
      "P-body": "UPDATE APRIL I was hit again by this bug/symptoms on 26 April 2018. I could solve it by applying the March fix AND additionally cleaning the crash dir. .  UPDATE March 2018. It seems a bug with more or less the same symptoms hit a couple of users beginning of March 2018. This new bug is in compiz-config, not compiz. And it is less severe: guest session and low graphics mode is working fine. New bug report. .  Fix (for most users): .  Explanation: Remove any lowgfx.conf file and change \"profile = unity-lowgfx\" to \"profile = unity\" in \".config/compiz-1/compizconfig/config\". Clean the .cache directory in your home directory.Reboot.Thx to everyone contributing in the bugreport. .  If you're hit in March and above solution is not working, leave a message on the bug report. Try workaround 3 (see below). Otherwise try to tweak compiz settings in CCSM. Or delete/clean your ~/.cache directory. .   Bug Fixed (January) This bug is fixed now. Updates are in Xenial-updates, so an update will solve the issue. .  You can disable proposed: .  Or revert any of your workarounds. .  Background This bug is acknowledged and caused by the mesa updates of 2018-01-04 to 17.2.4. The bug is now marked as a duplicate of an earlier bug filed 2017-12-01, unfortunately that bug was misfiled.  .  Only older Intel, ~2006-2011, with integrated graphics (gen4/5) are affected, so that's why it slipped through testing. And it only seems to affect Unity, not Gnome or LXDE. .  Following info is obsolete The patch for this bug will be available in xenial-proposed shortly. Please help Ubuntu by testing this new package. See https://wiki.ubuntu.com/Testing/EnableProposed for documentation on how to enable and use -proposed. Please give feedback at the bug report page to help getting this update out to other Ubuntu users. See comment 48 for info. .  To enable proposed (please read info in above links first): .  Install patches .  Then add a file \"/etc/apt/preferences.d/proposed-updates\" .  This will protect you from updating all packages in the proposed repository next time you do a \"sudo apt upgrade\". You don't want that. .  If you add this file before you install the patches, you will get a dependency error message. .  If you have used a PPA as a workaround, you have to purge that first. .  Until this bug is fixed, what are the workarounds? .  1. Install lubuntu-desktop (LXDE) aside unity .  This will take around 400MB and install things like Abiword, you can remove them later to save disk-space. Simply choose Lubuntu at login. Remove lubuntu-desktop again when the bug is resolved. .  2. Downgrade the mesa-packages .  This is described in the bug report. It can have unwanted side-effects and break dependencies, so decide for yourself.  .  As it seems these 4 packages need to be downgraded: .  One way is to download them from the link in this comment and follow the instructions. \"dpkg -i *.deb\" .  I you use Wine you will need the i386 packages too.  .  Prevent automatic upgrading from these 4 packages. Don't forget to remove that file once the bug is resolved. .  3. Use low graphics mode  .  This will mitigate the bugs and give you a somewhat working GUI. But: .   Dash not working Alt tab not working logout, reboot and halt needs to be done with terminal, same for programs not in the launcher super key (windows) not working  That said: launcher, workspace switching and keyboard shortcuts are working, so just spread your programs over workspaces :) .  Create a file \"~/.config/upstart/lowgfx.conf\" .  Logout and login. .  4. PPA .  Update mesa to a newer version through a PPA. Don't forget to purge the PPA when the bug is solved. This is probably the best choice. Please read the info on the PPA-page before you apply following code. .  Reboot and it should be fine. If not please leave a message in the bug report. .  Don't forget to purge the PPA when the bug is resolved. .  5. Downgrade from HWE to stock kernel (and mesa/x-server) .  Bug is caused by mesa (17.2.4) updates, and mesa is updated along kernels in the HWE stack. Returning to stock kernel (4.4) will solve the issue, it will downgrade mesa to 11.2. .  That will removes all HWE packages. Probably the most secure solution. .  Hopefully this bug bug will be solved soon. Consider helping Ubuntu in testing . .  ",
      "P-tags": "uniti crash gui 16 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "ul_679534",
      "task": "debian buster exim4 hostname --fqdn did not return a fully qualified name",
      "P-task": "debian buster exim4 hostnam -- fqdn return fulli qualifi name",
      "F_verb": "return",
      "P-body": "You have to replace the line .  in \"/etc/hosts\" with .  from manpage .   The recommended method of setting the FQDN is to make the hostname be an alias for the fully qualified name using /etc/hosts, DNS, or NIS. For example, if the hostname was \"ursula\", one might have a line in /etc/hosts which reads .   ",
      "P-tags": "exim debian",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_460022",
      "task": "AWK doesn't add new column",
      "P-task": "awk add new column",
      "F_verb": "add",
      "P-body": "Your file is ending in (Windows) \"CR LF\" instead of (Unix) \"LF\". The \"CR\" character moves the line to the start and then the value of the new calculated column is being printed over the first column. .  Either use \"dos2unix\", or filter the file with \"tr -d '\\r'\" or simply use this: .  remove the last \"NR>12{exit}\" to process the whole file. .  ",
      "P-tags": "awk",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_143422",
      "task": "Specify parameters for launcher program",
      "P-task": "specifi paramet launcher program",
      "F_verb": "specify",
      "P-body": "The easiest thing to do is: .   Remove your existing Chrome icon from the Unity launcher Open the Unity Dash and make it non-maximized   .   Type \"chrome\" Drag the Chrome icon to your desktop Right-click on the Chrome icon on your desktop and choose \"Properties\" Modify \"Command\" to insert \"--scroll-pixels=50\" before \"%U\" and close the window Move the icon from your desktop to some folder (where it will stay) Drag the icon from the folder to your Unity launcher  ",
      "P-tags": "google-chrom mouse-scrol",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_19853551",
      "task": "Find the process id of the process name",
      "P-task": "find process id process name",
      "F_verb": "find",
      "P-body": "Probably you are looking for \"pgrep\" .   Another option .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_494501",
      "task": "Find all lines containing only the same character and replace with the same amount of another character",
      "P-task": "find line contain charact replac amount anoth charact",
      "F_verb": "find",
      "P-body": "You can pattern match for lines that contain only tilde characters, and then perform a character-by-character replacement .  ",
      "P-tags": "awk sed text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_11544955",
      "task": "Spawn process from shell script which runs as a background job",
      "P-task": "spawn process shell script run background job",
      "F_verb": "spawn",
      "P-body": "First, I would suggest considering the first rule of optimization: do not optimize. .  Then if you really think you need to optimize it, I would pick the 1st approach and do as much as possible in Java. .  One approach could be the following: 1) run all the processes with ProcessBuilder and create a \"List<Process>\" 2) Wrap each Process into a ShellScriptProcess and acquire a \"List<ShellScriptProcess>\" .  3) wait for processes to finish .  This is only a very rough solution, just to demonstrate the idea of how this could be acomplished. And I didn't test the code, it might contain of syntax errors :) Hope this helps. .  ",
      "P-tags": "shell multithread java",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP from NP which S"
    },
    {
      "id": "au_1069810",
      "task": "Why does `svn` hang in `ssh` terminal but work from desktop `lxterminal` using `http` protocol?",
      "P-task": "svn hang ssh termin work desktop lxtermin use http protocol",
      "F_verb": "use",
      "P-body": "I did some further experiments with my laptop sitting next to the Ubuntu machine that was causing me problems. With them next to each other, I noticed that after I entered my \"svn\" password in the \"ssh\" session started from the laptop, I was getting a keyring dialog box in the desktop session. That's terrible behavior since I'm generally using \"ssh\" because I don't have access to the machine, but it was entirely the culprit. If I clicked \"Cancel\" in that dialog box in the desktop session, the \"svn\" transaction in the \"ssh\" terminal would complete. .  Armed with that information, I was able to track an apparently permanent fix. In the file \"~/.subversion/servers\" toward the bottom, there is an option commented out for \"store-passwords = no\". I uncommented that, and now it seems to work. It doesn't store the password, but that's what I wanted anyway. .  ",
      "P-tags": "network server svn ssh proxi",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_33490950",
      "task": "SSH login between servers still asking for password, why?",
      "P-task": "ssh login server still ask password",
      "F_verb": "ask",
      "P-body": "In addition to running the client in verbose mode, start a new server instance in debug mode on another port: .  server-2 as root: .  Then connect in verbose mode to that server on the same port: .  server-1 as deploy .  9/10 it has to do with permissions. .  ",
      "P-tags": "cento linux ssh ssh-key",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V for NP"
    },
    {
      "id": "so_8903930",
      "task": "localtime alternative that won't overwrite the supplied struct",
      "P-task": "localtim altern overwrit suppli struct",
      "F_verb": "overwrite",
      "P-body": "It has nothing to do with your \"strftime\" call but with the fact that (from here): .   The pointer returned by readdir() points to data which may be overwritten by another call to readdir() on the same directory stream. .   Since you're simply pushing a character pointer that points to data that may be overwritten by subsequent calls to \"readdir\", you may well end up with garbage. .  You can probably fix it by using a copy of the C string with something like: .  And, if your implementation doesn't have a \"strdup\" (it's not part of the standard), you can use mine (found here). .  ",
      "P-tags": "c++ linux localtim",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "su_786949",
      "task": "Why does 'export foo=1' not get read when I use ssh?",
      "P-task": "export foo 1 get read use ssh",
      "F_verb": "get",
      "P-body": "\"$OPENBLAS_NUM_THREADS\" is being evaluated locally by \"bash\" before it is sent to your remote machine. .  You need to either escape the \"$\": .  or use single quotes, which inhibit the bash variable evaluation: .  ",
      "P-tags": "linux environment-vari ssh",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "so_55758700",
      "task": "Obtaining real device of VLAN-interface through the netlink",
      "P-task": "obtain real devic vlan-interfac netlink",
      "F_verb": "obtain",
      "P-body": "It's all about \"IFLA_LINK\": .  Thus through the native netlink API it could be done such a way: .  Full example on github. .  ",
      "P-tags": "netlink linux linux-kernel vlan c",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP through NP"
    },
    {
      "id": "ul_265874",
      "task": "Using MPV to play DVD movies",
      "P-task": "use mpv play dvd movi",
      "F_verb": "play",
      "P-body": "To start the main stream of a video DVD with \"mpv\" (instead of just simply drag & dropping the \"VIDEO_TS\" folder onto the mpv window) use the command : .  (as specified by jasonwryan in a comment below), or even (replacing \"username\" with \"yours\") .  So, just use that with a keyboard shortcut or in a launcher; or a specific \".desktop\" file can be created on the desktop or in \"~/.local/share/applications\" like so (text editor like \"gedit\" is your choice): .  with .  Edit the icon path too: possibly use this, .   .  or this one.) .   .  The launcher button/icon can be put on the desktop, on the panel, or can be searched and executed from an \"applications launcher\" (Dash, Synapse, Kickoff, Wisker Menu, Slingshot etc) .  To access more than the main stream (secondary videos, menu content, images), one can go into the DVD's \"VIDEO_TS\" folder and look there for more, or you may try a different command (to be used as above in a shortkey or launcher):  .  which will play and seek through all included streams including menus as if in a single file. But the results of that may vary from good to very bad (for some reason the image is awful sometimes with this command). .  The \"mpv\" gui is very minimalistic, but it includes two buttons to cycle audio streams and subtitles, and they work for DVDs too. The next/previous buttons will change the chapters inside the video stream (not the different streams/titles) .   .  It has many possible shortkeys. The defaults ones are described as follows: .  The ones that I find especially helpful are: .  Those can be customized in .  By default, it is: .  All needed explanations are inside this file. .  The default keybindings are hardcoded into the mpv binary. You can disable them completely with: \"--no-input-default-bindings\", but it is more useful to use new more intuitive keys and mouse actions that can be added at the end of that file, like: .  As already mentioned, \"mpv\" is the best way to add external subtitles to DVDs. .  ",
      "P-tags": "mpv mediaplay dvd",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "au_398457",
      "task": "The error: \"mount: only root can do that\" while mounting a partition",
      "P-task": "error : mount : root mount partit",
      "F_verb": "mount",
      "P-body": "Use (note \"sudo\" in front) .  If in future, a program informs you that \"only root can do that\", \"root access required\", \"super user required\", \"Permission denied\", or similar permissions based problems, you should try sticking \"sudo\" in front of the command you're executing. .   Mounting a device like Nautilus If you just want to mount a device from the command line, like it would be mounted if you clicked its icon in the Nautilus sidebar, you can use this command: .  replacing \"<device>\" with your device. This doesn't requrire root access, however will only allow you to do a safe mount, i.e. without any custom mount options and mounting to \"/media/$USER/<device>\" only. .  ",
      "P-tags": "mount permiss",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_347554",
      "task": "should i install bumblebee?",
      "P-task": "instal bumblebe",
      "F_verb": "install",
      "P-body": "\"+\" means that the Intel graphics card is being used. Your Nvidia graphics card is still powered on (see \"Pwr\", if it was off, then it reads \"Off\"). .  By installing Bumblebee, it will power off the Nvidia graphics card and thereby extending your battery life. You can optionally run programs on the nvidia graphics card using the \"optirun\" program. .  By not installing Bumblebee, you will have an ineffective heater which may be useful in the winter. .  ",
      "P-tags": "graphic nvidia bumblebe",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_344712",
      "task": "How to install 'precise' linux-image package from livecd after I accidentally deleted all kernels?",
      "P-task": "instal precis linux-imag packag livecd accident delet kernel",
      "F_verb": "install",
      "P-body": "Of course like any a little hard to solve the question in stack overflow sites I had to manage on my own. .   start a live CD, I used ubuntu 12.10 installation.  \"sudo -i\"  mount your system under /mnt. use \"mount -o bind\" to bind /proc, /sys and /dev to the mounted system. \"cp $(readlink /etc/resolv.conf) /mnt\" --> this will make sure u can use the networking... \"chroot /mnt bash\" \"service networking restart\" \"dpkg --purge $(dpkg -l|grep \"^iU *linux-image\")\"  After that I could install a specific kernel version using \"apt-get install linux-image-3.0.xx-yy\" and restart the system with a new normal image, my main problem was that for some reason the -19 version of the kernel with the 'extra' package failed to install together. Installing just the kernel alone solved the problem. .  ",
      "P-tags": "dpkg 12 04 apt live-cd",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP from NP after S"
    },
    {
      "id": "au_621353",
      "task": "Reduce Grub Menu Items",
      "P-task": "reduc grub menu item",
      "F_verb": "reduce",
      "P-body": "After following Ron's answer and looking at 40_custom a little closer, I eliminated duplicate sections of: .  (Of course there was content between the BEGIN and END comments.) This eliminated some of the duplicate entries in grub. Those ones are actually not shown in the grub screen shot above.)  .  However, I should have read this article more closely to begin with. https://linuxnorth.wordpress.com/2011/03/09/grub2-revisited I did the following: .  These steps eliminated the first five entries seen in the screen shot above of grub. .  You may also want to do the same for \"20_memtest86+\" and \"25_custom\".  .  I suppose installing grub-customizer would work also. I only like to do things manually/hands-on if possible. I feel I learn my system better that way. Customization and freedom, one of the reasons I love Linux.  .  ",
      "P-tags": "boot grub2 dual-boot",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_581375",
      "task": "How to extract all lines in file1 that match a pattern in another file2 by awk?",
      "P-task": "extract line file1 match pattern anoth file2 awk",
      "F_verb": "extract",
      "P-body": "As mentioned in the comment, this is the perfect one : .  If you still prefer to use awk : .  Using simple for loop ( same as what first grep would do ) : .  ",
      "P-tags": "awk bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP that S"
    },
    {
      "id": "ul_523967",
      "task": "How to tune this `scratch` alias for Bash by using the `PS2` variable?",
      "P-task": "tune scratch alia bash use ps2 variabl",
      "F_verb": "tune",
      "P-body": "I'm not entirely sure what this is useful for (compared to \"nano\", \"vim\" or any editor you fancy), but... does it need an alias? .  Just \"\"\" would be even shorter but there'll be an error message... .  Note that these things are not really gone... .  If that bothers you, disable history first or clear it afterwards. .  For a custom PS2 prompt, it's difficult since (at least for Bash) it has to be set to the parent shell. If you set it in a subshell, it'll be ignored. You can kind of work around it by starting an explicit shell instance like this... .  But at this point it would make more sense to write a dedicated scratch and discard program. .  Different approach, not using the PS2 prompt at all: .  Only you can't use '.' to get out here. Well, you could easily add that as a condition... .  However, you can also just get out by sending EOF with Ctrl+D. .  ",
      "P-tags": "prompt bash",
      "source": "qa",
      "cate": "tune",
      "pat": "V NP for NP by using NP"
    },
    {
      "id": "so_6565034",
      "task": "Segmentation Fault when shutting down Linux with assembly application",
      "P-task": "segment fault shut linux assembl applic",
      "F_verb": "shut",
      "P-body": "WARNING: remember to \"sync(2)\" before calling \"reboot(2)\". .  The \"reboot(2)\" system call takes 4 parameters.You are confusing it with the libc wrapper. .  WARNING: remember to \"sync(2)\" before calling \"reboot(2)\". .  (It actually takes the magic* parameters so that people have to reread the documentation and don't forget calling \"sync(2)\".) .  WARNING: Did I say that you have to \"sync(2)\" before calling \"reboot(2)\"? .  ",
      "P-tags": "shutdown gnu linux segmentation-fault assembl",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V down NP with NP"
    },
    {
      "id": "ul_201848",
      "task": "Can't connect to the sshd in my unprivileged LXC guest. What to do?",
      "P-task": "connect sshd unprivileg lxc guest",
      "F_verb": "connect",
      "P-body": "General troubleshooting advice for OpenSSH First of all I refer you to this short troubleshooting guide for \"sshd\" which I am using as a recipe time and time again. .  The plot thickens Only difference in this case, I used \"lxc-console\" to attach to the guest, logged in and stopped the running \"sshd\" and then started my instance on the default port 22. And then I connected from the host to the guest with heightened verbosity: .  Hmm, there's nothing enlightening in that output. Let's check the server side output of our connection attempt: .  Pay special attention to the following the following lines from the above output: .  indicating some issue with the privilege separation feature of OpenSSH (configuration directive \"UsePrivilegeSeparation yes\"), and: .  indicating that an attempt was made to change the effective GID of the process to 65534. .  Reviewing the container configuration Now have a look again at the stanzas from the container configuration file: .  which tells LXC to create a user namespace (userns) with 10000 IDs for both, group and user IDs respectively, starting at 1000000000. Inside that namespace, the UID 1000000000 becomes 0, i.e. superuser. .  The solution There are effectively two solutions to the problem: .   fix the container configuration and allow at least for 65535 subordinate IDs in the mapped range, or set the configuration option \"UsePrivilegeSeparation no\" in \"sshd_config\"  Background The script \"container-userns-convert\" which is hosted on launchpad (checkout with \"bzr branch lp:~serge-hallyn/+junk/nsexec\") and written by Serge Hallyn, one of the important contributors to LXC, and uses \"uidmapshift\" from the same repository, will assign only 10k subordinate IDs for the mapping by default. .  This tripped me up. Normally I assign a block of 100000 IDs (as it's easier to read) or 65535 myself. .  ",
      "P-tags": "lxc usern sshd",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP in NP"
    },
    {
      "id": "so_40755787",
      "task": "transpose a column in unix",
      "P-task": "transpos column unix",
      "F_verb": "transpose",
      "P-body": "With GNU awk for multi-char RS: .  ",
      "P-tags": "awk unix transpos",
      "source": "qa",
      "cate": "flip/rotate/permute/swap/transpose/reverse/shuffle",
      "pat": "V NP in NP"
    },
    {
      "id": "so_13112475",
      "task": "get count of the word in all files",
      "P-task": "get count word file",
      "F_verb": "get",
      "P-body": "Try something like this: .  \"find . -type f | xargs -n1 grep \"Hello\" -c\" .  Adding \"-type f\" to \"find\" ensures that it only returns files, not directories. Adding \"-n1\" to \"xargs\" makes it so that every file returned by \"find\" gets its own invocation of \"grep\", so that you can get a per-file count. The \"-c\" argument to \"grep\" returns the count of matches instead of every match. .  The above expression will count the number of lines that have 'Hello' in them. If you need the total number of Hellos, instead of just the number of lines that have Hello in them, you'll need to do something more sophisticated. You can use the \"-o\" option on grep to just print the matching section of a line, and then combine that with \"wc -l\" to get the number of total occurrences. .  ",
      "P-tags": "wc linux grep bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "au_498377",
      "task": "How to write shell script for creating zip ?",
      "P-task": "write shell script creat zip",
      "F_verb": "write",
      "P-body": "Hi & Welcome to AskUbuntu, .  Well, I'm not sure why \"/var/www\" directory is been owned by root while technically it should be \"www-data\" who'll be the owner & the group as default. Nevertheless, the simplest way to achieve this is using below script which I use to compress some of my directories. I'm using \"tar\" command instead. .  Creating a shell script  open a terminal (with CTRL+ALT+T) & create a new bash file. .   type the command \"nano filenam.sh\" & paste below (alter the script according to your need). .     save the script (with CTRL+O & enter). Then exit (with CTRL+X).  Executing the command  Simply run \"sudo sh filename.sh\" to perform (sudo will run with root previledge)  You may also add this to a cronjob which will automate the process according to your needs. This bash script append a time stamp and backup on an incrimental basis. Its just a simple script that I took and altered to your ease. .  Refer official Ubuntu Documentation on Shell Scripts & bash script which I took from BroExperts. .  Hope it helps! .  ",
      "P-tags": "script zip",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP for S_ING"
    },
    {
      "id": "so_65790476",
      "task": "WSL+samba+git: \"error: insufficient permission for adding an object to repository database .git/objects\" / git-clone / git-add permission errors",
      "P-task": "wsl+samba+git : error : insuffici permiss ad object repositori databas git object git-clon git-add permiss error",
      "F_verb": "add",
      "P-body": "Solution: Upgrade to WSL2 As I found out, the solution was to Upgrade from WSL1 to WSL2, there mounting works correctly. I'm able to git-add or git-clone without permission errors now. .  Open a PowerShell to see your current version: .  In case its 1 you can upgrade it, but check the WSL2 requirements first (just to be safe). .  Upgrade Guide Excerpt from Guide/Steps I had to do: .   Check WSL2 Requirements Windows above certain build resp. meets the requirements Download and execute: WSL2 Linux kernel update package for x64 machines Enable Windows Virtual Machine Platform Feature: \"dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\" Reboot Upgrade your distro to WSL2: open Powershell and enter \"wsl --set-version <distribution name> <versionNumber>\", in my case it was \"wsl --set-version Ubuntu 2\". To see your distribution name type \"wsl -l -v\" Verify the upgrade with \"wsl -l -v\"  Just to provide complete information, here also the mount options \"/etc/fstab\" .  Compared to .  ",
      "P-tags": "git-add samba permiss windows-subsystem-for-linux",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "au_713628",
      "task": "Bind mouse to a concrete monitor in a dual screen setup with two independent pointers",
      "P-task": "bind mous concret monitor dual screen setup two independ pointer",
      "F_verb": "bind",
      "P-body": "About the answer The answer below might need some additional editing. To create two separate mice, I followed the steps, mentioned in your question. It did work, but my \"normal\" mouse had some issues afterwards. Left-click did not work in some situations. .  Since you do not mention the side- effect in your question, I assume it has to do with hardware- specific conflicting functionality of both mice I connected. .  The good news is that \"xdotool\" apparently only \"sees\" the coordinates of the \"main\" mouse, which makes it possible to lock up the cursor in one of the screens. .  Two scripts Below two scripts: .   A script to lock up the pointer in either which one of the two screens. A script to automate step 2, as described in your question: Configure two independent pointers   .  1. Script to lock the cursor into one screen, in a dual monitor setup to use  The script uses \"xdotool\": .   Copy the script into an empty file, save it as \"lock_cursor.py\" .  Run it with the screen (\"left\" or \"right\") as argument, by either: .  or  .     .  2. Script to automate the setup of two independent mice This might be a tricky one, since I don't own a Wacom Bamboo, and I could not do a \"final test\" in a live situation. With my ordinary second mouse, it worked fine however (be it with different id- strings). .  If it also works fine in your situation, both script could be merged to run in one call; the script below only takes action if the double- mice setup was not yet performed. .  To use Simply copy the script into an empty file, save it as \"setup_bamboo.py\", run it by the command: .  Notes  I could not find another way to lock the mouse to one screen but to use \"xdotool\". The (first) script therefore locks up the mouse with the help of \"xdotool\". Since it runs in a periodic loop, the mouse position is corrected if it trespasses the screen's limit. The consequence is that, although effectively it works fine, you will still notice a cosmetic difference with a \"hard\" fence. .  I spent some time trying to reduce the effect, \"smartly\" increasing the loop speed whenever the mouse is near the screen's limit, or even making it dependent on the direction the mouse moves into. In the end however I came to the conclusion that the gained improvement is minimal, and simplicity of coding should be preferred. .   ",
      "P-tags": "monitor mous graphics-tablet",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP to NP in NP with NP"
    },
    {
      "id": "au_490289",
      "task": "How do I run KDE widgets in XFCE?",
      "P-task": "run kde widget xfce",
      "F_verb": "run",
      "P-body": "KDE's widgets are part of the KDE Plasma Desktop... which is a huge chunk of KDE. It can be done (you just install \"plasma-desktop\" and \"plasma-scriptengines\" and run \"plasma-desktop\" at start-up) but that is going to override your existing desktop. .  I honestly can't say if the end result is something you'll like, but it's the only way I know how to do what you want. .  ",
      "P-tags": "xfce kde4",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_33490825",
      "task": "How to use chmod in ~/.bashrc",
      "P-task": "use chmod bashrc",
      "F_verb": "use",
      "P-body": "\"~/.bashrc\" is run as the user when the user logs in. It is not run on boot. .  If you want to change the permissions on a file, you need to have permission to do so. The message is telling you that you don't have permission -- only root can do so. .  The simplest way to do something custom on boot-up is to stick it in the file \"/etc/rc.local\". This script is run by root after booting up (so on every reboot), so you can just stick your chmod command in there. .  ",
      "P-tags": "ubuntu-14 04 linux sy bash chmod",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_386362",
      "task": "debconf is broken, can't install anything anymore",
      "P-task": "debconf broken instal anyth anymor",
      "F_verb": "install",
      "P-body": "You're missing your main Raspbian archive, which should be in your sources.list: .  Without that, there is nowhere to download debconf 1.5.56+deb8u1 from. .  It's likely that adding the source back, then \"apt-get update\", then \"apt-get install -f\" will be sufficient to fix it. If not, you'll need to manually download http://mirrordirector.raspbian.org/raspbian/pool/main/d/debconf/debconf_1.5.56+deb8u1_all.deb and install it with \"dpkg -i debconf_1.5.56+deb8u1_all.deb\". Ways of manually downloading that include wget/curl or \"apt-get download debconf=1.5.56+deb8u1\". The latter is easiest if it works. .  ",
      "P-tags": "dpkg apt raspbian raspberry-pi debconf",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_591204",
      "task": "Is it possible to specify default images for scopes?",
      "P-task": "possibl specifi default imag scope",
      "F_verb": "specify",
      "P-body": "No, there is no way to provide a fallback image URL to the dash for display, through the scopes API currently. .  You can however, have your scope download the images, and pass local \"file:///\" URIs to the dash for the image location, replacing any which were not usable with a URI pointing to the fallback image you wish to use instead. .  ",
      "P-tags": "application-develop ubuntu-touch",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "au_391474",
      "task": "Stop cpu from overheating",
      "P-task": "stop cpu overh",
      "F_verb": "stop",
      "P-body": "Intel Ubuntu 16.04+ solution for Sandy Bridge and newer processors From (wiki.debian.org -thermald) there is Debian's (Ubuntu's) write up about thermald A Linux daemon for cooling tablets and laptops. This only works for Sandy Bridge (2nd generation) and newer Intel Cores. Once the system temperature reaches a certain threshold, the Linux daemon activates various cooling methods to try to cool the system. .  Linux thermal daemon (thermald) monitors and controls temperature in laptops, tablets PC with the latest Intel sandy bridge and latest Intel CPU releases. Once the system temperature reaches a certain threshold, the Linux daemon activates various cooling methods to try to cool the system. .  It operates in two modes: .  Zero Configuration Mode  For most users, this should be enough to bring the CPU temperature of the system under control. This uses DTS temperature sensor and uses Intel P state driver, Power clamp driver, Running Average Power Limit control and cpufreq as cooling methods.  User defined configuration mode  This allows ACPI style configuration in a thermal XML configuration file. This can be used to fix the buggy ACPI configuration or fine tune by adding more sensors and cooling devices. This is a first step in implementing a close loop thermal control in user mode and can be enhanced based on community feedback and suggestions.  How to install  TLP From Arch Linux: .   TLP brings you the benefits of advanced power management for Linux without the need to understand every technical detail. TLP comes with a default configuration already optimized for battery life, so you may just install and forget it. Nevertheless TLP is highly customizable to fulfill your specific requirements. .   Please read the full Arch Linux TLP link above. There are issues with Nvidia that require configuration changes. .  After many trials and errors with other packages, I've had great success using TLP. It gives superior fan control and works seamlessly with thermald and p-states. .  As these installation instructions for Ubuntu 15.04+ mention TLP not only reduces overheating but it extends battery life too. .  Since installing TLP, Powerclamp (described below) has never been invoked again. .   Intel Powerclamp Intel's Powerclamp driver is defined here (kernel.org - Intel Power Clamp.txt) and is part of thermald described above. A direct quote for Powerclamp from the link: .   Consider the situation where a system\u2019s power consumption must be reduced at runtime, due to power budget, thermal constraint, or noise level, and where active cooling is not preferred. Software managed passive power reduction must be performed to prevent the hardware actions that are designed for catastrophic scenarios. .  Currently, P-states, T-states (clock modulation), and CPU offlining are used for CPU throttling. .  On Intel CPUs, C-states provide effective power reduction, but so far they\u2019re only used opportunistically, based on workload. With the development of intel_powerclamp driver, the method of synchronizing idle injection across all online CPU threads was introduced. The goal is to achieve forced and controllable C-state residency. .  Test/Analysis has been made in the areas of power, performance, scalability, and user experience. In many cases, clear advantage is shown over taking the CPU offline or modulating the CPU clock. .    How do you know Powerclamp is running? Powerclamp might only show itself once a year when your fan vents get too much dust & lint. So how do you know it's actually running in the background? Use: .  And you should see a list similar to this: .  If you see \"intel_rapl\" and \"intel_powerclamp\" you know it's working and simply waiting temps to exceed 85C. .   Powerclamp in action displayed by Conky Here is a screen shot when Powerclamp injects sleep cycles: .   .  Normally on this system CPU clock speed is 2400 Mhz to 3400 Mhz when watching HTML5 video and 10 Chrome tabs open. Normally CPU utilization is about 9% to 12% across 8 CPUs. When things get too hot (86C) Powerclamp kicks in and this happens: .   CPU speed is reduced to 1200 Mhz.  CPU utilization spikes up to 80%. This is misleading because the extra 70% is sleeping time. The top 9 CPU processes are usually 5 or 6 Chrome processes plus Xorg, Conky, Pulse Audio and an occasional kworker. However now 8 of the top 10 are the kidle_inject/x process where \"x\" is from 0 to 7. For the first 8 CPUs.  The Powerclamp driver runs until temps drop below 85C again. While the driver is running you might have split second pausing in your videos and possibly split second keyboard and mouse lag. .   Disable Intel Turbo Boost Back in the \"cool old days\" of Ubuntu 14.04 Intel Turbo Boost was broken so my processor speed fluctuated between 1200 Mhz and 2400 Mhz. After upgrade to Ubuntu 16.04 it would go up to 3400 Mhz (3.4 Ghz) because Turbo Boost was finally working. But it also raised the heat. .  To disable Intel Turbo Boost use: .   Short term fix in this scenario To \"band-aid\" fix this problem I pulled the old laptop cooler pad with dual fans out of the closet and popped under the laptop. This dropped temps to 63C under the same workload. .  The next step will be compress air in vents. After that the final step will be new Cooling Heatsink with pipes for CPU and GPU. Good thermal paste such as Arctic Silver 5 is also needed in that operation. A new fan was already installed last year and that seems to be running ok. .  Update Jan 25 2017 Blew out fan vents with compressed air and temps dropped from 63C to 56C. This is still using the laptop cooling pad mind you. .  Update Aug 06 2017 Have been using \"TLP\" (described above) for many months now and temperatures are steady around 50C and fan performance is optimal. .   Watch out for too many fan control drivers Because this is a Dell I had installed I8K Fan Monitor / Control in hopes it would speed up the fan sooner and faster. When I type \"sensors\" I get: .  Ignore the virtual temps, they are out to lunch. Under Ubuntu 14.04 the were accurate and I used \"temp 1\" in Conky display. After Ubuntu 16.04 upgrade I had to refer to a third temperature not displayed on this screen. To see the REAL temps you can use this command: .  When I type: .  I see the \"dell_smm_hwmon\" kernel module / driver. When I google that driver and \"I8K\" people report the two drivers cause system freezes for a split-second every 10 seconds or so. I was having this problem myself so had to remove I8K fan control. .  There are lots of other utilities and cooling methodologies but this is getting TL;DR. .  ",
      "P-tags": "cpu temperatur",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING"
    },
    {
      "id": "so_24683577",
      "task": "powershell v2 : WebClient/UploadString never connect",
      "P-task": "powershel v2 : webclient uploadstr never connect",
      "F_verb": "connect",
      "P-body": "The global variable \"$url\" is not available inside your event handler script block. Change your Register-ObjectEvent like so: .  ",
      "P-tags": "powershel powershell-2 0 uploadstr webclient",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V"
    },
    {
      "id": "su_1496843",
      "task": "SSH suddenly stopped working in git-bash on Windows 10",
      "P-task": "ssh suddenli stop work git-bash window 10",
      "F_verb": "stop",
      "P-body": "I've got the same issue with mysysgit 2.28.0 in Windows 10 2004 and I've opened a ticket at https://github.com/git-for-windows/git/issues/2822 for further analyzation of this issue. I did some investigation with WinDbg and in my case it looks like this is related to ACL- or Hostname-Resolution. .  As a workaround I've installed OpenSSH for Win32 (https://github.com/PowerShell/Win32-OpenSSH) using the Chocolatey package manager (see https://chocolatey.org/packages/openssh/8.0.0.1 for more information). Then I set the environment variable \"GIT_SSH_COMMAND\" to \"\"C:\\Program Files\\OpenSSH-Win64\\ssh.exe\"\". After that git push/pull/etc. worked for me again. .  Addendum 2020-10-20 I found out that the problem was caused by the \"epclient64.dll\" which belongs to Citrix Workspace VPN client software (this can be done using \"strace\" command). After uninstalling Citrix Workspace from my computer \"ssh.exe\" from mysysgit doesn't hang anymore. Furthermore I found out that the problem doesn't occur when I install the Citrix Worspace App from the Windows Store instead of using the Installer from the Citrix Download Site (https://www.citrix.com/de-de/downloads/workspace-app/windows/). .  ",
      "P-tags": "git-bash ssh",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V S_ING in NP on NP"
    },
    {
      "id": "so_69519126",
      "task": "powershell string replace inline or new loop",
      "P-task": "powershel string replac inlin new loop",
      "F_verb": "replace",
      "P-body": " it needs to be done after the MD5 is already calculated .   I don't think you can depend on another calculated property when creating a calculated property, at least not within the same pipeline step. Each calculated property will only be available when the current pipeline step has finished as a whole. .  What you could do is chain two \"Select-Object\" statements like this: .  ",
      "P-tags": "powershel cmdlet",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "so_30062739",
      "task": "How do I replace a line with sed with /",
      "P-task": "replac line sed",
      "F_verb": "replace",
      "P-body": "When there's a \"/\" in the original string, or replacement string, we muse use \"\\\" to escape \"/\". Alternatively you can use any character as substitution delimiter, such as \"@\" .  ",
      "P-tags": "linux sed regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP"
    },
    {
      "id": "au_395516",
      "task": "fatal: could not create work tree dir 'metasploit-framework'.: Permission denied",
      "P-task": "fatal : could creat work tree dir metasploit-framework\n: permiss deni",
      "F_verb": "create",
      "P-body": "Run the following in the terminal to open a new terminal session as root, so that you get permission to run the commands: .  ",
      "P-tags": "git permiss software-instal",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_28689828",
      "task": "How to read in each line/ string in a file A, and find the line containing the string in file B and deltes it in ubuntu",
      "P-task": "read line string file find line contain string file b delt ubuntu",
      "F_verb": "find",
      "P-body": "Either you can use command substitution in combination with \"sed\"'s \"-f\": .  but this is not very robust unless you know that your patterns won't contain characters which \"sed\" interprets. .  Better: Just use \"grep\" with a temp file: .  ",
      "P-tags": "ubuntu sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_33511772",
      "task": "Read file line by line in PowerShell",
      "P-task": "read file line line powershel",
      "F_verb": "read",
      "P-body": " Not much documentation on PowerShell loops. .   Documentation on loops in PowerShell is plentiful, and you might want to check out the following help topics: \"about_For\", \"about_ForEach\", \"about_Do\", \"about_While\". .  Another idiomatic PowerShell solution to your problem is to pipe the lines of the text file to the \"ForEach-Object\" cmdlet: .   Instead of regex matching inside the loop, you could pipe the lines through \"Where-Object\" to filter just those you're interested in: .  ",
      "P-tags": "powershel powershell-is",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP by NP in NP"
    },
    {
      "id": "so_49664220",
      "task": "Replace multiple newlines with just 2 newlines using unix utilities",
      "P-task": "replac multipl newlin 2 newlin use unix util",
      "F_verb": "replace",
      "P-body": "You can use awk like this: .  \"RS\" is the input record separator, \"ORS\" is the output record separator. .  From the awk manual: .   If RS is null, then records are separated by sequences consisting of a newline plus one or more blank lines .   That means that the above command splits the input text by two or more blank lines and concatenates them again with exactly two newlines.  .  ",
      "P-tags": "bash unix newlin util util",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "so_60472549",
      "task": "How to increment loop variable to get next value while iterating bash arguments",
      "P-task": "increment loop variabl get next valu iter bash argument",
      "F_verb": "get",
      "P-body": "Don't use a \"for\" loop. Just process \"$1\" every time through the loop, and use \"shift\" to adjust the argument list. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP while S"
    },
    {
      "id": "so_26218486",
      "task": "How to download latest version of software from same url using wget",
      "P-task": "download latest version softwar url use wget",
      "F_verb": "download",
      "P-body": "Usually, for processing the html-pages i recommendig some perl tools, but because this is an Directory Index output, (probably) can be done by bash tools like \"grep\" \"sed\" and such... .  The following code is divided to several smaller bash functions, for easy changes .  prints .  ",
      "P-tags": "grep regex shell bash wget",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP using NP"
    },
    {
      "id": "so_11857108",
      "task": "What should be the permissions on /var/tmp/mysite if my PHP script writes there?",
      "P-task": "permiss var tmp mysit php script write",
      "F_verb": "write",
      "P-body": "You need to fix your permissions before changing the group will be effective. As mentioned in Explosion Pill's answer, you should change the group to be \"www-data\" for Apache. You can do this recursively on your \"/var/www\" directory: .  where \"owner\" is the user that currently owns the files. .  Here you can see the read/write/execute permissions on the file for the owner, group, and others respectively: .   drwxr-xr-x .   Ignore the \"d\", the other letters mean: .   owner - read write execute group - read ------ execute others - read ------ execute  This site gives you the meaning of the \"chmod\" numbers: .  http://www.goldenplanet.com/support/kb/articles/changing-of-file-rights-chmod-on-the-webserver.html .  You can do \"chmod 775\" on the directory that is giving the permission error which will give the owner of the file and the group full permissions, while only giving \"others,\" read and execute access. .  ",
      "P-tags": "php linux apach permiss apache2",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_58512430",
      "task": "How to write to protected pages in the Linux kernel?",
      "P-task": "write protect page linux kernel",
      "F_verb": "write",
      "P-body": "There is a way that does not need to recompile the kernel. Since the kernel will detect whether the wp bit has been modified in \"write_cr0\", you can provide a custom function to bypass it. .  Here is the function that enables/disables write protection. We use \"mywrite_cr0\" instead of \"write_cr0\" .  In your \"mod_init\" function, you can use \"kallsyms_lookup_name(\"sys_call_table\")\" to figure out the address of \"sys_call_table\" at runtime, instead of compile time. Fortunately, we can now directly write to \"sys_call_table\" without dealing with pageattr. .  The code below is tested on Linux Kernel 5.1.4 .  ",
      "P-tags": "page system-cal linux-kernel",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP in NP"
    },
    {
      "id": "ul_65751",
      "task": "How to get functions propagated to subshell?",
      "P-task": "get function propag subshel",
      "F_verb": "get",
      "P-body": "Functions are naturally propagated to subshells: .  But they are not and cannot be propagated to independent shell processes that you start by invoking the shell under its name. .  Bash has an extension to pass functions through the environment, but there's no such thing in other shells. While you can emulate the feature, it requires running code in the nested shell anyway. You might as well source your function definitions in the nested shell. .  ",
      "P-tags": "env function shell subshel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_21335309",
      "task": "two questions, second only appearing if you answer 'y'",
      "P-task": "two question second appear answer",
      "F_verb": "answer",
      "P-body": "The beginning of your \"case\" statement appeared to be malformed. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_8776300",
      "task": "How to exit program with close button in XCB",
      "P-task": "exit program close button xcb",
      "F_verb": "exit",
      "P-body": "I struggled on this topic some time ago as well. .  Look at http://marc.info/?l=freedesktop-xcb&m=129381953404497 . .  The key is to store the cookie for the WM_DELETE_WINDOW in a separate cookie... .  and in the event loop compare the client_message with the cookie2 .  ",
      "P-tags": "linux xcb",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_19088135",
      "task": "Obtain substring using awk",
      "P-task": "obtain substr use awk",
      "F_verb": "obtain",
      "P-body": "Something like this? It divides the string at the first -number. .  Or you can be more specific and devide after first -x.x, where x is a number .  ",
      "P-tags": "awk linux regex shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP using NP"
    },
    {
      "id": "so_35893366",
      "task": "Apply bash variables for directories (recursive)",
      "P-task": "appli bash variabl directori recurs",
      "F_verb": "apply",
      "P-body": "A common idiom is to have a config file in one (or more) of several directories and have your script check each one of them in order. For instance you could search: .  You might also search the environment as a last resort. This search strategy is very easy to implement in bash. All you have to do is: .  It sources the two config files if they exist. If the user copy exists it overrides the global settings. If neither exists, the script will naturally use any environment variables. This way the user could override the config settings like so: .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_19633",
      "task": "Which header defines the macro that specifies the machine architecture?",
      "P-task": "header defin macro specifi machin architectur",
      "F_verb": "define",
      "P-body": "No header file defines it - those macros are predefined by the compiler. To find out the full list of predefined macros do this: .  Then look through the results for likely macros. .  ",
      "P-tags": "linux header-fil",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP that S"
    },
    {
      "id": "so_25723783",
      "task": "how to use libminiupnpc to setup port forwarding",
      "P-task": "use libminiupnpc setup port forward",
      "F_verb": "use",
      "P-body": "Miniupnp is not very well (or at all?) documented. Here is what I eventually figured out is required to add and list port mappings. I'll leave out error handling. .  Two useful files were \"upnpc.c\" and \"upnpcommands.c\" from the github project at https://github.com/miniupnp/miniupnp/tree/master/miniupnpc. .  ",
      "P-tags": "linux upnp miniupnpc",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "au_39788",
      "task": "configure tor to use only US proxies",
      "P-task": "configur tor use us proxi",
      "F_verb": "configure",
      "P-body": "Vidalia, open Settings\u2192Advanced and add this to your \"torrc\" file: .  ",
      "P-tags": "tor uniti",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_805418",
      "task": "How can I find encoding of a file via a script on Linux?",
      "P-task": "find encod file via script linux",
      "F_verb": "find",
      "P-body": "It sounds like you're looking for \"enca\". It can guess and even convert between encodings. Just look at the man page. .  Or, failing that, use \"file -i\" (Linux) or \"file -I\" (OS\u00a0X). That will output MIME-type information for the file, which will also include the character-set encoding. I found a man-page for it, too :) .  ",
      "P-tags": "file unix shell encod",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP via NP on NP"
    },
    {
      "id": "so_65903782",
      "task": "Docker compose can't access ports of other containers",
      "P-task": "docker compos access port contain",
      "F_verb": "compose",
      "P-body": "You have to understand more detail about network in docker compose. .  To solve your issue, you need : .   Add network in your docker compose file for each container (there is a default network but to understand the mechanism, you can define it explicitly). This must looks like this (under ports for example) for the first container (named keycloak):  On the second container (named keycloak_installer) (you must expose the port that you want to request in the first container): .   On your script call explictly the second container which will be now available by the network. You must change your code by this :  ",
      "P-tags": "docker-compos network shell docker",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP"
    },
    {
      "id": "au_159112",
      "task": "disk space wrongly displayed after installing LVM disk",
      "P-task": "disk space wrongli display instal lvm disk",
      "F_verb": "display",
      "P-body": "You apparently only allocated 10gb to your root fs. You can use \"pvs\" to see how much space lvm has allocated to volumes, and how much it has left, and \"lvextend\" to increase the size of a logical volume ( does not need to be unmounted ). After increasing the size of the logical volume, you will need to tell the fs to use the new space. Assuming you are using ext[234], you can do this with \"resize2fs\", which also can expand without unmounting. .  Note that expanding the volume to use ALL of the unallocated space may not be such a great idea, since you won't have any left to add new volumes later, should you choose to do so, or make use of lvm snapshots. You can reduce the size of the volume later to free up some space, but that requires the fs to be unmounted, thus you will need to boot the server from some other medium. .  ",
      "P-tags": "df fdisk lvm disk-usag",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V after S"
    },
    {
      "id": "au_1275090",
      "task": "How can i move multiple files to folder with same name",
      "P-task": "move multipl file folder name",
      "F_verb": "move",
      "P-body": "In this particular case, probably the most simple way is to use the builtin \"for\" loop in a way as this: .   remove the \"echo\" command in order to do the actual file-system changes.  ",
      "P-tags": "mv command-lin bash",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "so_62545993",
      "task": "Empty files being included in a grep: More efficient to just ignore them or use arguments/piping to filter them out?",
      "P-task": "empti file includ grep : effici ignor use argument pipe filter",
      "F_verb": "use",
      "P-body": "Try using \"find\" with \"-empty\" option for files finding: .  ",
      "P-tags": "awk grep pipe tcsh shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_55299213",
      "task": "How to add new string/line below certain line in file which contains multiple same lines throughout a file in BASH?",
      "P-task": "add new string line certain line file contain multipl line throughout file bash",
      "F_verb": "add",
      "P-body": "This does what you want with the provided sample data: .  ",
      "P-tags": "script pars shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP below NP in NP which S"
    },
    {
      "id": "ul_365623",
      "task": "How to delete the content of all subdirectories named \"output\"?",
      "P-task": "delet content subdirectori name output",
      "F_verb": "delete",
      "P-body": "If your \"find\" has \"-mindepth\" and \"-delete\" (at least GNU or BSD): .  ",
      "P-tags": "file find",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "au_1109162",
      "task": "gnome-clocks 3.30 : prompting for permission to access geolocation -updated to 3.31.2",
      "P-task": "gnome-clock 3 30 : prompt permiss access geoloc -updat 3 31 2",
      "F_verb": "update",
      "P-body": "To /etc/geoclue/geoclue.conf add : .  ",
      "P-tags": "gnome-clock",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V to NP"
    },
    {
      "id": "su_183294",
      "task": "How to block access to a website on Lucid Lynx?",
      "P-task": "block access websit lucid lynx",
      "F_verb": "block",
      "P-body": "You can block the website's IP using an iptables rule. Something along the flavor provided below. .  Just replace the zeros with the IP of the website you wish to deny access to. This syntax also supports a wildcard. By typing an IP with a zero in it, you are effectively blocking the entire span of that field. For example, 192.168.13.0 references the IP range of 192.168.13.1 to 192.168.13.254. .  In addition to blocking by IP, you can also block by hostname using this same syntax. Just change the IP address to the domain name and it'll do the rest of the work for you. .  So you can do all of what you wanted in iptables (freeing up your hosts file from needless records). .  ",
      "P-tags": "linux iptabl firewal host",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP to NP on NP"
    },
    {
      "id": "au_988044",
      "task": "while installing pecl extension in mongodb on ubuntu 16.04 i am getting this error",
      "P-task": "instal pecl extens mongodb ubuntu 16 04 get error",
      "F_verb": "get",
      "P-body": "The pecl mongo extension is no longer maintained and new projects are advised to use the mongodb extension and PHP library.  .  Open the terminal and type: .  The latest version of mongodb requires alcaeus/mongo-php-adapter in order to install mongodb packages with composer. .  ",
      "P-tags": "mongodb php7",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_1033129",
      "task": "how to scan all clients if they contain files with a specific line of text",
      "P-task": "scan client contain file specif line text",
      "F_verb": "scan",
      "P-body": "This .  will return any file inside /home that contains \"help\" on remote server {host} on {port} using {user} and add it to \"/tmp/search.txt\". This assumes {host} will accept {user} as a valid user and might prompt for passwords. .  For this to work over multiple machines you could read a config file with users and hosts and iterate over them. It would probably be easier to do this in \"python\" or \"perl\" as you can easily manipulate and format the results on each pass and then write to stdout the results. .  ",
      "P-tags": "client server command-lin grep",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP if S"
    },
    {
      "id": "so_27591628",
      "task": "Update properties file using powershell",
      "P-task": "updat properti file use powershel",
      "F_verb": "update",
      "P-body": "So you have a file with those properties in it yes? Who's to say how it was created or if that is the only contents? Lets just assume you have a file with lots of properties other than that just in case. You want to navigate the file replacing all occurrences* of \"${BuildPath}\" with \"D:\\Data\\Sample\\lib\" .  This would give the following output in \"c:\\temp\\file.ini\" .  * regex will only replace the first occurrence on each line. Doubt there would be more than one anyway.  .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_106198",
      "task": "How to start ipsec on Gentoo after migrated to systemd?",
      "P-task": "start ipsec gentoo migrat systemd",
      "F_verb": "start",
      "P-body": "Assuming that the service file actually exists, you should be able to launch it with \"systemctl start ipsec\". You'll need the appropriate USE flags for systemd as well, probably -- I'd suggest a systemd subprofile if you're not already using one. .  ",
      "P-tags": "systemd gentoo ipsec",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP after S"
    },
    {
      "id": "ul_147862",
      "task": "Where should xt.vim be put on osX?",
      "P-task": "xt vim put osx",
      "F_verb": "put",
      "P-body": "Put the file to \"~/.vim/syntax/xt.vim\", and ensure that you have \":syntax on\" in your \"~/.vimrc\". .  To edit a file with that syntax highlighting, use .  or define a filetype detection rule, cp. \":help new-filetype\". .  ",
      "P-tags": "osx vim",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V on NP"
    },
    {
      "id": "so_29829923",
      "task": "How to set up execve call on nasm right?",
      "P-task": "set execv call nasm right",
      "F_verb": "set",
      "P-body": "As @Jester suggested, you need to declare \"argv\" properly: .  \"db\" refers to defining a list of 8-bit bytes. \"dw\" would let you define 16-bit shorts. \"dd\" is for 32-bit numbers - on 32-bit Linux, this is the proper pointer size. You would use \"dq\" on 64-bit, because that's a 64-bit number, which is the right pointer size in that case.) .  \"execve\" expects a NULL-terminated list of pointers, so we use \"dd\" for each of our pointers, and then NULL (0) to terminate the parameter list. .  Also - while \"execve\" normally does not return, robust code will take into account the possibility that \"execve\" fails, and handle this properly. .  ",
      "P-tags": "nasm system-cal linux exec assembl",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP on NP"
    },
    {
      "id": "au_247629",
      "task": "How do I display the whole desktop in Virtual Box fullscreen mode?",
      "P-task": "display whole desktop virtual box fullscreen mode",
      "F_verb": "display",
      "P-body": "To be able to scale the screen geometry, and to enable fullscreen mode of a Virtual Box guest Ubuntu we need to install the guest additions: .   How do I install Guest Additions in a VirtualBox VM? In case we have no functioning GUI we may install the guest additions from command line.  In case this fails we may try to reinstall guest additions, and watch out for errors we may get when doing so. Older versions of Virtual Box may be incompatible with either the graphics drivers from the host, or with the guest Ubuntu version. We then have the following options we may try the follwing: .   Make sure we have 3D-acceleration enabled in the virtual machine settings, and allow enough of video memory: .   .   How do I install the VirtualBox version from Oracle to install an Extension Pack? .   Update the guest operation system from command line (hold left Shift key on booting to enter a root shell) and then run: .   In rare cases we may have a better performance with an older Ubuntu release, or a more lightweight derivate such as Lubuntu, or Xubuntu. .    After having installed the guest additions the guest OS needs a reboot for the virtual driver to be loaded. We then should be able to resize or scale the guest screen, or enter full screen mode with Host + F. .  Also see Adjusting display geometry in a virtual machine? for additional options to adjust screen geometry. .  Note: Pre-release alpha versions of Ubuntu are likely to not yet perform as expected. .  ",
      "P-tags": "fullscreen guest-addit guest-sess virtualbox",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_14610687",
      "task": "How to get rid of warning when copy_to_user(struct *file, const char __user *buf, size_t len, loff_t *off_t )",
      "P-task": "get rid warn copy_to_us struct file const char __user buf size_t len loff_t off_t",
      "F_verb": "get",
      "P-body": "Your problem is that the \"len\" passed in to your \"myread\" and \"mywrite\" functions may be greater than \"SIZE\"; if this is the case, the \"copy_from_user\"/\"copy_to_user\" will overflow your array and read from / write to other nearby memory. Your code needs to restrict the length of the copy to no more than the length of the kernel memory that it's accessing. .  ",
      "P-tags": "linux-device-driv c linux-kernel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP when S"
    },
    {
      "id": "au_573936",
      "task": "VMWare Workstation 6.5.5 on Ubuntu 14.04: Kernel Headers not found",
      "P-task": "vmware workstat 6 5 5 ubuntu 14 04 : kernel header found",
      "F_verb": "find",
      "P-body": "Try Oracle VirtualBox . It should open VMDK images too. If not try to convert your disks using qemu-img : .  ",
      "P-tags": "14 04 vmware-workst",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "su_1644633",
      "task": "How to safely kill bash/zsh/other shells with its history stored?",
      "P-task": "safe kill bash zsh shell histori store",
      "F_verb": "kill",
      "P-body": "Send it a SIGHUP \u2013 this is the signal used to indicate that the terminal has been \"hung up\" (including when a GUI terminal window is closed, or when an SSH connection is lost). Most interactive programs will interpret this as a signal to cleanly exit. .  A real hangup will send the signal to all processes having the terminal as their controlling tty, so you should do the same (e.g. using \"pkill -HUP -t pts/1\"). This will work whether the terminal is sitting idle at a shell prompt, or whether it has a text editor open, or something else. .  (The term 'hang up' comes from dial-in terminals which were accessed through modems over actual phone calls.) .  Note: If this is a graphical terminal, you do not need to send the SIGHUP to the terminal emulator itself \u2013 it'll exit as soon as the shell exits anyway. .   On Linux, if you have root privileges, it is possible to send fake input to another terminal line using the TIOCSTI ioctl. You can find a small program \"writevt.c\" which can be used to, for example, send a \"exit\\n\" or any other input as if it were typed on that terminal. .  ",
      "P-tags": "bash zsh linux kill shell",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_635405",
      "task": "~/.ssh/config Host entry not honored when connecting via IP address",
      "P-task": "ssh config host entri honor connect via ip address",
      "F_verb": "connect",
      "P-body": "Add the IP address to the list of the host name patterns that should match the configuration section. Here, \"GW2\" and \"203.0.113.1\" will match: .  You can find this documented (briefly) with \"man ssh_config\", .   \"Host\" Restricts the following declarations (up to the next \"Host\" or \"Match\" keyword) to be only for those hosts that match one of the patterns given after the keyword. If more than one pattern is provided, they should be separated by whitespace. A single \"*\" as a pattern can be used to provide global defaults for all hosts. The host is usually the hostname argument given on the command line (see the \"CanonicalizeHostname\" keyword for exceptions). .   ",
      "P-tags": "linux configur ssh",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V via NP"
    },
    {
      "id": "au_785169",
      "task": "Eliminate 404 error",
      "P-task": "elimin 404 error",
      "F_verb": "eliminate",
      "P-body": "Yes there is a way to stop seeing this, you have to edit your \"/etc/apt/sources.list\" file or removing the proper file from \"/etc/apt/sources.list.d/\" directory, for that open a terminal (ctrl+alt+t) and check if it is in the \"sources.list\" file by typing: .  If it is a line in here which got added you can edit the \"sources.list\" by: .  If its not there you might want to check the files in the \"/etc/apt/sources.list.d\" directory by listing the contents of that directory with: .  If your line with the \"ppa\" shows there find the corresponding list file and remove it: .  Of course if you not want to remove this file but instead correct it you can edit it with: .  ",
      "P-tags": "ppa",
      "source": "qa",
      "cate": "clear/clean/empty/eliminate/unpin/cleanup/unpublish",
      "pat": "V NP"
    },
    {
      "id": "au_226587",
      "task": "Cannot reset my password",
      "P-task": "reset password",
      "F_verb": "reset",
      "P-body": "In a terminal try: .  \"passwd\" .  Then enter a new password. .  ",
      "P-tags": "gnome-control-cent password-recoveri",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP"
    },
    {
      "id": "so_43193748",
      "task": "Passing different parameters in .xml document through PowerShell script",
      "P-task": "pass differ paramet xml document powershel script",
      "F_verb": "pass",
      "P-body": "If this were me I would do this a little differently. I would make a hashtable with keys that describe the environment, and values that contain the parameter set for those environments. Something like: .  Then if you want that as an XML file you can use \"Export-CliXml\" to save that as an XML file. .  Now that you have those defined your Deploy.ps1 script can have its parameters changed just a little bit to accept an object, and change properties to parameters as such: .  Then you can just pass whatever environment you want to the script: .  Edit: Since you are having trouble, here's what I did to test. I started by creating the hashtable, and exporting it to a file, exactly as I describe above. Then I imported that file, and saved it as a new variable. .  Then I made a simple script for testing: .  I saved that to the current folder (C:\\Temp, but that shouldn't matter) as test.ps1. I then passed the 'Failover' set to the script as such: .  The result was: .  ",
      "P-tags": "powershel xml paramet",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP in NP through NP"
    },
    {
      "id": "ul_538679",
      "task": "Setting shell variable before command gives 'command not found'",
      "P-task": "set shell variabl command give command found",
      "F_verb": "set",
      "P-body": "\"$SLS_DEBUG_TEXT\" is expanded too late, after the stage where the shell would otherwise treat its value as an assignment. The variable's value is therefore instead treated as a command. .  What you could do instead is to use \"env\": .  Note the quoting around every single variable expansion. .  If \"SLS_DEBUG_TEXT\" may be empty or unset, the above would generate an error since \"env\" would try to execute a command with no name. .  To work around that, you may instead use .  The \"${SLS_DEBUG_TEXT:+\"$SLS_DEBUG_TEXT\"}\" would expand to \"\"$SLS_DEBUG_TEXT\"\" if that variable is set and non-empty. Otherwise it would expand to nothing (not even an empty string, which would be the case with \"\"$SLS_DEBUG_TEXT\"\"). .  Note too that if you have \"SLS_DEBUG_TEXT='SLS_DEBUG=* '\" (as in your code), the space after the \"*\" would become part of the value of \"SLS_DEBUG\" in the \"sls\" process' environment. I don't know if this is intended or not. .   I'm also noticing that the error message that you quote says .  To me, this indicates that you are using the variable's name without \"$\" in front of it at some point in the script. This may be totally unrelated to the main issue that you had. The code that you show would instead cause the error .  ",
      "P-tags": "variabl shell-script shell",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP before S"
    },
    {
      "id": "so_34166689",
      "task": "Sending Outlook E-mail using Powershell",
      "P-task": "send outlook e-mail use powershel",
      "F_verb": "send",
      "P-body": " ",
      "P-tags": "powershel email outlook",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP using NP"
    },
    {
      "id": "au_887713",
      "task": "Extract line beginning with a specific pattern in sed",
      "P-task": "extract line begin specif pattern sed",
      "F_verb": "begin",
      "P-body": "\"egrep\" can get multiple lines from a file. Using a pipe \"|\" as a separator you can pull as many different criteria as you want. \"egrep\" is the equivalent of \"grep -E\". \"egrep\" is a script found in the \"/bin\" folder with the contents pointing to \"exec grep -E \"$@\"\". .  Example: .  or .  Should output: .  Hope this helps! .  ",
      "P-tags": "command-lin text regex text-process sed",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V with NP in NP"
    },
    {
      "id": "so_59708014",
      "task": "write to a specific line in a file from a command line in MAC OS",
      "P-task": "write specif line file command line mac os",
      "F_verb": "write",
      "P-body": "For BSD/Mac sed provide an argument for in-place replacement (\"-i\" option): .  Or to replace original file without creating a backup pass an empty string to \"-i\" (you should first test this without \"-i\" and verify it works as expected): .  ",
      "P-tags": "command-lin maco shell bash sed",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP in NP from NP in NP"
    },
    {
      "id": "su_859557",
      "task": "How to fix apt-get missing key error after adding deb source for package?",
      "P-task": "fix apt-get miss key error ad deb sourc packag",
      "F_verb": "fix",
      "P-body": " Look at your keys and figure out which one or ones are bad and remove them, then try your apt-get update again. .  ",
      "P-tags": "aptitud linux-mint linux ubuntu debian",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP after S"
    },
    {
      "id": "ul_57686",
      "task": "cannot find libarchive when compiling YAP prolog in OSX",
      "P-task": "find libarch compil yap prolog osx",
      "F_verb": "find",
      "P-body": "The -devel packages usually contain header files, pkgconfig data and similar - anything one would need to link an application against the library in question. I'm not sure how ports work, but check \"/opt/local\" (or \"/opt/local/include\") for \"archive.h\" and \"archive_entry.h\". Without these files you won't be able to compile the application. Since the path sounds rather non-standard (\"/opt/local/...\"), you will likely need to tell the buildsystem, that is should look for the libraries and headers in that particular directory. .  The basic generic layout of files on unix-like systems these days is governed by the Filesystem Hierarchy Standard. The most important parts are as follows: .   \"bin\" and \"sbin\" hold binaries (the programs you run) - this is why these directories are usually mentioned in the \"$PATH\" shell variable. The \"s\" in \"sbin\" used to stand for static as in statically linked binary, which doesn't need any dynamic linking and can be basically run \"as-is\". .  \"lib\" (and/or \"lib64\" or even \"lib32\") hold the shared (and possibly also static) libraries .  \"include\" contains header files enabling linking your code against libraries (basically APIs definitions). .  \"etc\" and \"share\" are for configuration and additional data files. .  \"PREFIX\" is usually \"/usr\", \"/usr/local\", \"/opt\" or \"/opt/<something>\" but you can as well create such structure in your home directory for example. .   How to tell the buildsystem where to look for binaries depends on what bs the code uses. Usually this very kind of information is placed in either the \"README\" or \"INSTALL\" file that accompany the source. For example for GNU autotools, it is usually in the form of \"--with-name=PREFIX\" or \"--with-name-lib=PREFIX/lib --with-name-include=PREFIX/include\" arguments passed to the \"configure\" script. If this isn't available, you might want to explicitly export variables used by compiler and linker: .  In your case this would be \"-I/opt/local/include\" and \"-L/opt/local/lib\" respectively. .  ",
      "P-tags": "compil",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP when S"
    },
    {
      "id": "au_1286218",
      "task": "Unable to resume upgrade from Ubuntu 20.04 to 20.10 after not enough free disk space error",
      "P-task": "unabl resum upgrad ubuntu 20 04 20 10 enough free disk space error",
      "F_verb": "resume",
      "P-body": "Solution .  \"sudo apt upgrade\" did not show anything, but \"sudo apt update\" did show a package that was kept back. .  It was qtcam because the repo was stuck on xenial, I updated the repo to use bionic and I updated packages normally. .  After that the upgrade UI was still not working but using \"sudo do-release-upgrade\" did work and I could upgrade to Ubuntu 20.10 normally. .  ",
      "P-tags": "upgrad apt 20 10",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP from NP to NP after S"
    },
    {
      "id": "so_13636389",
      "task": "How to use a .ps1 t4scaffolding template to Add Projects to the current solution?",
      "P-task": "use ps1 t4scaffold templat add project current solut",
      "F_verb": "use",
      "P-body": "I did figure this out, but i don't believe this was the route I wanted to take. I'm opting for a custom multi-project Template to handle my project creations, and then using mvcscaffolding for the class generation later. .  This code does work though to generate a created class library project into the current solution and was really hard for me to dig up so i'm posting it here .  ",
      "P-tags": "asp net-mvc asp net-mvc-scaffold scaffold powershel t4",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF to NP"
    },
    {
      "id": "so_20945159",
      "task": "Cannot use Cabal in Ubuntu",
      "P-task": "use cabal ubuntu",
      "F_verb": "use",
      "P-body": "It seems that your package isn't properly installed. So remove it cleanly using this command: .  \"sudo apt-get purge cabal-install\" .  And once this is over, re-install it again using the familiar command: .  \"sudo apt-get install cabal-install\" .  ",
      "P-tags": "linux ubuntu haskel cabal",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_55141819",
      "task": "Nested while loop in bash script - inner being skipped",
      "P-task": "nest loop bash script - inner skip",
      "F_verb": "skip",
      "P-body": "Your indentation is misleading: .  Check your code with proper indentation .  See? Your second \"while\" is inside the \"else\" branch of your first \"if\" statement .  I think, what you meant would be .  ",
      "P-tags": "nested-loop shell bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V"
    },
    {
      "id": "su_152416",
      "task": "How to change the X-Windows default border width for all window frames in Ubuntu using Gnome 2.28",
      "P-task": "chang x-window default border width window frame ubuntu use gnome 2 28",
      "F_verb": "change",
      "P-body": "Using a google site search: .  Google: \"theme create site:library.gnome.org/users/\" .  I found the info I was looking for on the official Gnome site in the Administrator documentation section: .  The Intro Gnome docs URL that talks about creating your own or modifying existing theme settings: http://library.gnome.org/admin/syste...mes-15.html.en .  And the detailed settings file docs can be found in here some where. http://library.gnome.org/devel/gtk/unstable/index.html .  The default installed Gnome themes are found here on a Gnome install: /usr/share/themes/theme-name .  and inside each theme folder there is the following structure: .  All the details theme settings such as border and edge widths are in the \"gtkrc\" file: .  Every Gnome theme object can reference pre-defined style blocks with attributes. .  Most styles have an xthickness and ythickness value defaulting to = 1 .  Changing the x/ythickness values can change the pixel thickeness of all objects. .  This blog post also provides an example of creating a new theme and changing it. .   http://martin.ankerl.com/2008/10/10/how-to-make-a-compact-gnome-theme/ .   ",
      "P-tags": "linux ubuntu appear gnome x-window",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP for NP in NP using NP"
    },
    {
      "id": "so_47185850",
      "task": "Linux: How to finish/interrupt the `less` command in \"&<pattern>\" mode",
      "P-task": "linux : finish interrupt less command pattern mode",
      "F_verb": "finish",
      "P-body": "Just use \"&\" again with no pattern, i.e. enter \"&\" and hit return. .  ",
      "P-tags": "linux pattern-match less-unix text-process",
      "source": "qa",
      "cate": "finish/complete/finalize/complement",
      "pat": "V"
    },
    {
      "id": "so_25712906",
      "task": "How does bash get commands into the operating system?",
      "P-task": "bash get command oper system",
      "F_verb": "get",
      "P-body": "Well, unless the command you enter into the command prompt is a bash builtin (such as \"cd\", \"alias\" or \"echo\"[1]) the shell will create a new process (using \"fork(2)\" syscall) and execute the program via the exec system call. .  [1] you can run \"type something\" to find out if \"something\" is a shell builtin .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_3050512",
      "task": "On Ubuntu, how do you install a newer version of python and keep the older python version?",
      "P-task": "ubuntu instal newer version python keep older python version",
      "F_verb": "install",
      "P-body": "When you install from source, by default, the installation goes in \"/usr/local\" -- the executable in particular becomes \"/usr/local/bin/pythonX.Y\" with a symlink to it that's named \"/usr/local/python\". Ubuntu's own installation is in \"/usr/\" (e.g., \"/usr/bin/python\"), so the new installation won't overwrite it. Take care that the \"PATH\" environment variable doesn't have \"/usr/local/bin\" before \"/usr/bin\", or else simple mentions of \"python\" would execute the new one, not the old one. .  ",
      "P-tags": "gnu ubuntu instal python configur",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_49511460",
      "task": "Running self or other program as sudo once my Python script knows the password?",
      "P-task": "run self program sudo python script know password",
      "F_verb": "run",
      "P-body": "If you go down the \"subprocess\" route, then you can use the \"-S\" flag on \"sudo\" so that you can pass the password through \"stdin\": .  As far as I am aware it is not possible to elevate the UID of a currently running process to root, however. It would probably be much easier to just launch a new Python or other process as root, as in the example. .  ",
      "P-tags": "privilege-elev linux python",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP as NP"
    },
    {
      "id": "ul_565782",
      "task": "At what size is *.xsession-errors* turned into *.xsession-errors.old*?",
      "P-task": "size xsession-error turn xsession-error old",
      "F_verb": "turn",
      "P-body": "GG, look in \"/etc/logrotate.d\" there may be a logrotate file doing the work and then you can manipulate the number of days and file size to rotate and many other things. .  File name probably called xsession or similar. Let us know what you find in /etc/logrotate.d  .   Added after Edit  If you find nothing you could create a new logrotate  .  You can add a file to create a new logrotate in /etc/logrotate.d Here is something I have used variations of many times. copy this to /etc/logrotate.d/xsessionerrors (new file)  .  Logrotate has many variables but this will get you going with some obvious settings you can tweek. .  ",
      "P-tags": "log logrot",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V into NP"
    },
    {
      "id": "ul_84140",
      "task": "How to set a variable equal to the output from a command in GRUB2?",
      "P-task": "set variabl equal output command grub2",
      "F_verb": "set",
      "P-body": "I found the answer myself. Instead to use \"date\" command, I can use \"insmod datehook\" module and like this the following environment variables will be accessible: \"$YEAR\", \"$MONTH\", \"$DAY\", \"$HOUR\", \"$MINUTE\", \"$SECOND\", \"$WEEKDAY\". .  Example: https://askubuntu.com/a/323516/147044 .  ",
      "P-tags": "script grub2",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP from NP in NP"
    },
    {
      "id": "au_284178",
      "task": "Certain Xubuntu graphics persist on Ubuntu",
      "P-task": "certain xubuntu graphic persist ubuntu",
      "F_verb": "persist",
      "P-body": "Install these packages and their dependencies: .  Also purge this package: .  Finally, you should reconfigure \"plymouth\", e.g. by installing and using \"galternatives\" and update the \"initramfs\" with the \"update-initramfs\" command. .  After a reboot, you should be back to normal. .  ",
      "P-tags": "xubuntu notif lightdm",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V on NP"
    },
    {
      "id": "so_4306768",
      "task": "How to run C++ binaries on NTFS in Ubuntu 10.10?",
      "P-task": "run c++ binari ntf ubuntu 10 10",
      "F_verb": "run",
      "P-body": "The default mount options for ntfs filesystems probably changed between Ubuntu versions. .  Locate the line in /etc/fstab that controls the mount point in question. .  First thing to try: Make sure that the option string does not contain \"noexec\". If it does, remove it, \"umount\", remount and see if that fixes it for you.  .  If noexec wasn't there or you still cannot execute, then check to see if \"user\" or \"users\" is one of the options. Since \"user\" implies noexec (normally) you may need to add (after \"user\") the option \"exec\", so the result would read: .  If \"user\" was present try making this change, then \"umount\" and remount. .  If at this point you still cannot execute, then and add or set the following mount option in the option string for the mount point in question: .  This is probably excessively permissive but should be okay for a single user system. This tells mount that all files in the filesystem should be treated as (among other things) executable by default. Now \"umount\" and remount again and see if it's working. .  ",
      "P-tags": "eclipse-cdt linux file-permiss ubuntu-10 10",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP in NP"
    },
    {
      "id": "au_253889",
      "task": "How can I configure preseed to use a drive ONLY if it exists?",
      "P-task": "configur prese use drive exist",
      "F_verb": "use",
      "P-body": "Short answer: you can't. .  Long answer: as far as I am aware, you will need to run some kind of \"early_command\" to read the current disks and echo the results of that to a file that \"partman\" will read later, presumably on /hd-media somewhere. .  I have once found a program/script that would do this, I think, but my Google-fu does not seem to work right now =/ .  ",
      "P-tags": "partit prese",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP if S"
    },
    {
      "id": "so_34090054",
      "task": "How to remove the file '--help'",
      "P-task": "remov file -- help",
      "F_verb": "remove",
      "P-body": "Use this: .  ",
      "P-tags": "delete-fil bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_67295788",
      "task": "How to pass space to Cobra CLI string slice flag?",
      "P-task": "pass space cobra cli string slice flag",
      "F_verb": "pass",
      "P-body": "Here is how to do it from a Windows command prompt: .  yields \"[a\"b c d e]\" and .  does \"[a\\\"b c d e]\" (I\u2019m not sure which one you actually want). .  The reason for this is, as has been pointed out, that the Pflag library makes use of the Go standard library encoding/csv supporting the format described in RFC 4180. If we refer to section 2 from paragraphs 5, 6 and 7: .   If fields are not enclosed with double quotes, then double quotes may not appear inside the fields. .    Fields containing line breaks (CRLF), double quotes, and commas should be enclosed in double-quotes. .    If double-quotes are used to enclose fields, then a double-quote appearing inside a field must be escaped by preceding it with another double quote. .   ",
      "P-tags": "powershel go go-cobra",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_261043",
      "task": "Give the command to remove duplicate lines in a .txt file and save the new file as new.txt file",
      "P-task": "give command remov duplic line txt file save new file new txt file",
      "F_verb": "save",
      "P-body": "You are missing one pipe \"|\" character. .  Try: \"sort myfile |uniq -u|tee newfile.txt\" .  If this is not working, please provide the error message you are getting. By the way, this command \"uniq -u\" eliminates all lines which have duplicates. If this is your intention, that is fine. But if you want to see one of the duplicate lines, you need to drop \"-u\" for the \"uniq\" part of this command line, i.e., \"sort myfile | uniq | tee newfile.txt\" .  ",
      "P-tags": "linux shell-script command-lin",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP as NP"
    },
    {
      "id": "au_946424",
      "task": "How to install Eclipse CDT Oxygen on Ubuntu 16.04",
      "P-task": "instal eclips cdt oxygen ubuntu 16 04",
      "F_verb": "install",
      "P-body": "You don't have to install anything, as you mentioned just move the extracted folder \"eclipse\" to \"/opt\", then you could make a symbolic link to the executable with \"sudo ln -sv /opt/eclipse/eclipse /usr/local/bin/eclipse\". When you have done these steps you can run Eclipse with the simple command \"eclipse\".  It's not managed by \"apt\" because you didn't install it via \"apt\" (\"sudo apt install eclipse\"), that Eclipse that you find in the \"apt\" repository it's an old version of the Java IDE. .  ",
      "P-tags": "eclipse-cdt eclips",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_35608801",
      "task": "How to divide my script output by the output of another command?",
      "P-task": "divid script output output anoth command",
      "F_verb": "divide",
      "P-body": "Just set up another array \"L\" to track the count of items: .  ",
      "P-tags": "awk grep bash",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP by NP of NP"
    },
    {
      "id": "so_50245807",
      "task": "How to call bash function from script with the same name in the PATH",
      "P-task": "call bash function script name path",
      "F_verb": "call",
      "P-body": "This is what already happens if there's a bash function defined. .  The problem in your script is that \"foo_type\" contains something like \"foo is /.../bin/foo\" which is not empty, so the script is never sourced and a function is never defined. .  You can use \"set -x\" to debug this and other problems. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP from NP with NP in NP"
    },
    {
      "id": "au_1103761",
      "task": "Can't run sudo wifi-radar under wayland",
      "P-task": "run sudo wifi-radar wayland",
      "F_verb": "run",
      "P-body": "You should try to use \"xhost\" .   The xhost program is used to add and delete host names or user names to the list allowed to make connections to the X server. In the case of hosts, this provides a rudimentary form of privacy control and security. It is only sufficient for a workstation (single user) environment, although it does limit the worst abuses. Environments which require more sophisticated measures should implement the user-based mechanism or use the hooks in the protocol for passing other authentication data to the server .   \"xhost\" will print list of allowed names .  \"xhost +si:localuser:root\" should help in your case. .  And after that you will see .  And \"sudo wifi-radar\" will work as expected. .  This is roughly one of the reasons you could see this error message. .  ",
      "P-tags": "pygtk wayland",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP under NP"
    },
    {
      "id": "so_62644471",
      "task": "How to make awk produce columns",
      "P-task": "make awk produc column",
      "F_verb": "make",
      "P-body": "With Unix / Linux you can use \"column\" to produce column output: .  To do it in \"awk\" you can read the file twice to get the max field length for each column. Once you do that, you can fix the field width with \"sprintf\" with the field width + pad value: .  Prints: .  ",
      "P-tags": "awk linux unix",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_50630607",
      "task": "Using Interval expressions with bash extended globbing",
      "P-task": "use interv express bash extend glob",
      "F_verb": "extend",
      "P-body": "Somehow I managed to find a way to do this within the confinements of \"bash\". .  Are interval glob-expressions implemented in bash? No! In contrast to other shells such as ksh and zsh, bash did not implement interval expressions for globbing. .  Can we mimic interval expressions in bash? Yes! However, it is not really practical and could sometimes benefit by using \"printf\". The idea is to build the globular expression that mimics the \"{m,n}\" interval using the KSH-globs \"@(pattern)\" and \"?(pattern)\". .  In the explanation below, we assume that the pattern is stored in variable \"p\" .   Match \"n\" occurrences of the given pattern (\"{n}\"): .  The idea is to repeat the pattern \"n\" times. For large n you can use \"printf\" .  or .   Match at least \"m\" occurrences of the given pattern (\"{m,}\"): .  It is the same as before, but with an additional \"*(pattern)\" .  or .   Match from \"n\" to \"m\" occurrences of the given pattern (\"{m,n}\"): .  The interval expression \"{n,m}\" implies we have for sure n appearances and m-n possible appearances. These can be constructed using the ksh-globs \"@(pat)\" n times and \"?(pat)\" m-n times. For n=2 and m=3, this leads to: .  or .  Another way to construct the interval expression \"{n,m}\" is using the ksh-glob anything but pattern written as \"!(pat)\" which allows us to say: give me all, except... .   \"man bash\": \"!(pattern-list)\": Matches anything except one of the given patterns .   This way we can write .  or .  note: you need to do a double exclusion here due to the or (\"|\") in the pattern list. .   What about other shells? KSH93 The interval expression \"{n,m}\" has been implemented in \"ksh93\": .   \"man ksh\": .   \"{n}(pattern-list)\" Matches \"n\" occurrences of the given patterns. \"{m,n}(pattern-list)\" Matches from \"m\" to \"n\" occurrences of the given patterns. If \"m\" is omitted, \"0\" will be used. If \"n\" is omitted at least \"m\" occurrences will be matched.   ZSH Also \"zsh\" has a form of interval expression. It is a globbing flag which is part of the \"EXTENDED_GLOB\" option: .   \"man zshall\": .  \"(#cN,M)\" The flag \"(#cN,M)\" can be used anywhere that the \"#\" or \"##\" operators can be used except in the expressions \"(*/)#\" and \"(*/)##\" in filename generation, where \"/\" has special meaning; it cannot be combined with other globbing flags and a bad pattern error occurs if it is misplaced. It is equivalent to the form \"{N,M}\" in regular expressions. The previous character or group is required to match between \"N\" and \"M\" times, inclusive. The form \"(#cN)\" requires exactly \"N\" matches; \"(#c,M)\" is equivalent to specifying \"N\" as \"0\"; \"(#cN,)\" specifies that there is no maximum limit on the number of matches. .   ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "inflate/extend",
      "pat": "V NP"
    },
    {
      "id": "so_56888683",
      "task": "Can't install QT4 on Ubuntu due to ssl issue",
      "P-task": "instal qt4 ubuntu due ssl issu",
      "F_verb": "install",
      "P-body": "I found the solution ! The problem didn't come from \"libsll\", but it was related to \"openssl\" version. .  The version 1.1.1 was installed (as we can see on the first screen). So I renamed the executable \"/usr/bin/openssl\" as \"/usr/bin/openssl.1.1.1\" and I installed an older version of openssl (1.0.2) : .  And that's it ! I checked the version by typing \"openssl version\" and it returned \"1.0.2\" ! .  Then QT4 compiled just fine ! .  ",
      "P-tags": "qt4 ubuntu embed ssl qt",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP to NP"
    },
    {
      "id": "ul_503382",
      "task": "Is there a Linux system call to create a \u201cview\u201d of a range of a file?",
      "P-task": "linux system call creat view rang file",
      "F_verb": "create",
      "P-body": "One way of doing this is to use a loop device. This approach does have two requirements which may make it less useful: you need to be root to set it up, and the non-cooperating subprocess must be able to write to a block device. Oh, and it doesn\u2019t deal with conflicting changes. .  To set the loop device up, run .  replacing \"1024\", \"2048\" and \"yourfile\" with appropriate values \u2014 \"-o\" specifies the start offset, \"--sizelimit\" the size (counting from the offset). Note that \"sizelimit\" has to be a multiple of 512. .  This will output the name of the loop device which has been set up; adjust the permissions as necessary, and give it to your non-cooperating sub-process. When you no longer need the device, delete it with .  replacing \"N\" as appropriate. .  ",
      "P-tags": "linux file filesystem",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP of NP"
    },
    {
      "id": "so_57423117",
      "task": "Bash loop only read the last line",
      "P-task": "bash loop read last line",
      "F_verb": "read",
      "P-body": "First of all, \"awk\" has the ability to loop through lines and the field separator can be a regex. .  So, your script can be reduced to this optimized format: .  This is the optimized format that you can use. .  Having said that, you might want to know what was wrong in the your script. .  The \">\" marked above is the redirection operator. It writes the stdout of the command (\"awk\" in this case) to the file specified. It does not append, but overwrite. So, in every iteration of the loop, the file is cleared and the output of the command is written to it. Hence it leaves only the last entry. .  To fix that, you can use the append redirection: \">>\". .  Now, there is a caveat. What if the file is not originally empty? This loop will append to the file, without clearing the file first. To fix that, you can first clear the file with: .  However, if we are sure that all the stdout produced by the loop needs to go into the file, you can simply move the redirection out of the loop. That way, shell does not have to keep opening and closing the file descriptors. .  Note that these options are unoptimized, but would still work. The optimized option would be to let \"awk\" itself do the line-by-line processing as mentioned in the first snippet in the answer. .  ",
      "P-tags": "awk for-loop linux shell bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_13308922",
      "task": "Find which program caused a core dump file",
      "P-task": "find program caus core dump file",
      "F_verb": "find",
      "P-body": "You can simply use the \"file\" program to identify them: .  E.g .  ",
      "P-tags": "debug linux ubuntu coredump",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V which S"
    },
    {
      "id": "so_46827258",
      "task": "\"telnet\" command fails with \"bad port\" when executed in shell script, but works on command prompt",
      "P-task": "telnet command fail bad port execut shell script work command prompt",
      "F_verb": "execute",
      "P-body": "Your script file has Windows CR/LF line endings, while *nix systems use LF only. .  The additional CR is taken as a part of the \"telnet\" command, particularly as a part of the last \"port\" argument. Hence the \"bad port\" error. .  Make sure you either: .   save the script using *nix line endings before uploading or upload the script using a text mode transfer or convert the file on the server.  ",
      "P-tags": "linux putti shell telnet",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V in NP"
    },
    {
      "id": "so_49487295",
      "task": "How to specify MaxCharactersFromEntities in Select-XML",
      "P-task": "specifi maxcharactersfroment select-xml",
      "F_verb": "specify",
      "P-body": "One solution is not to use Select-Xml and to disable the XmlResolver: .  ",
      "P-tags": "powershel xml net",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_24272185",
      "task": ".htaccess not running mod-rewrite or not being executed",
      "P-task": "htaccess run mod-rewrit execut",
      "F_verb": "execute",
      "P-body": "Make sure that you have the rewrite module turned on. .  Since you have the if check for the module that means that there wont be any errors if it is not enabled. .  ",
      "P-tags": "php htaccess ubuntu mod-rewrit apach",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "su_1618924",
      "task": "How do I delay a script to allow FreeIPA to start first?",
      "P-task": "delay script allow freeipa start first",
      "F_verb": "delay",
      "P-body": "Adding the following to the \"[Unit]\" section of the systemd service file seems to have resolved the issue for me: .  This sets a dependency and ordering constraint between the service and the \"sssd\" service that provides FreeIPA identity/authentication. .  ",
      "P-tags": "linux systemd freeipa",
      "source": "qa",
      "cate": "delay/defer/postpone",
      "pat": "V NP S_INF S_INF"
    },
    {
      "id": "su_797463",
      "task": "Running find...exec tar czvf only archives one file...need all files",
      "P-task": "run find exec tar czvf archiv one file need file",
      "F_verb": "run",
      "P-body": "Your command is running \"tar\" once for each file, and each call to \"tar\" creates an output of the same name, thus overwriting the previous output. So you end up with only the last file. You need something like .  This should work fine as long as your list of files isn't huge. If it is, then you'll probably want to switch to using \"tar rvf\" and doing a separate \"gzip\" step at the end. .  ",
      "P-tags": "redhat-enterprise-linux gzip logfil tar",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_370667",
      "task": "Empty Disk when trying to install dual-boot system",
      "P-task": "empti disk tri instal dual-boot system",
      "F_verb": "install",
      "P-body": "This symptom is usually caused by one of two problems: .   Leftover software RAID data -- If the disk had been (or is being) used with software RAID, leftover RAID data can confuse the Ubuntu installer. You can usually fix this problem by typing \"sudo dmraid -E -r /dev/sda\"; however, you should be very sure that you're not currently using software RAID. If you erase RAID data when the system is actually using RAID, the result can be problems accessing your disk at all. A damaged partition table -- The libparted library (upon which the Ubuntu installer relies) is extremely sensitive to partition table problems. If any exist, it usually reports the disk as being empty. My FixParts program (part of the \"gdisk\" package in Ubuntu) will correct many of these problems in an automatic or semi-automatic mannger; see its Web page for details. Other problems may require more specialized and manual repairs. If you think this is the source of the problem and if FixParts can't fix it or if you're wary of using FixParts, post the output of \"sudo fdisk -l /dev/sda\". Add four spaces to the beginning of each line of that output to preserve columnar output.) If the disk uses GPT rather than MBR partitions, type \"sudo sgdisk -v /dev/sda\" and post the output here. Both FixParts and \"sgdisk\" are part of the \"gdisk\" package in Ubuntu.)  ",
      "P-tags": "partit windows-8 ssd dual-boot",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_894893",
      "task": "how to reset mouse and touchpad settings on ubuntu 16.04?",
      "P-task": "reset mous touchpad set ubuntu 16 04",
      "F_verb": "reset",
      "P-body": "The peripherals settings for Unity (and Gnome) are stored using \"dconf\". You can install dconf-editor to inspect and reset settings manually. The mouse and touchpad can be found in \"/org/gnome/desktop/peripherals/mouse/\" and \"/org/gnome/desktop/peripherals/touchpad/\" respectively. .   .  Alternatively enter the following commands into Terminal to reset all settings for mouse and touchpad: .  ",
      "P-tags": "16 04",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP on NP"
    },
    {
      "id": "so_33339727",
      "task": "Setting Android Home on Ubuntu. Is this redundant?",
      "P-task": "set android home ubuntu\nredund",
      "F_verb": "set",
      "P-body": "these two lines are sufficient. .  ",
      "P-tags": "android linux ubuntu shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP"
    },
    {
      "id": "au_104126",
      "task": "Can I purge configuration files after I've removed the package?",
      "P-task": "purg configur file remov packag",
      "F_verb": "remove",
      "P-body": "Yes you can. .  From the command line: .  This will remove all of the remaining files that the package installed. .   You can also do this from a GUI: .   Install Synaptic  from the Software Center Run Synaptic Find packages listed under \"Not Installed (residual config)\"  Right click the package and click, mark for complete removal  Click the check button on the tool bar and click apply when the dialogue pops up.   ",
      "P-tags": "package-manag",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_447952",
      "task": "How do recommends and suggests interact with apt-get dist-upgrade and apt-get autoremove?",
      "P-task": "recommend suggest interact apt-get dist-upgrad apt-get autoremov",
      "F_verb": "get",
      "P-body": "\u201cRecommends\u201c and \u201cSuggests\u201d relationships mostly have an effect on package installations, and sometimes removals, not on upgrades. .  At installation time, depending on its configuration (\"APT::Install-Recommends\" and \"APT::Install-Suggests\"), \"apt\" will automatically install any packages which are recommended and/or suggested along with the package carrying the recommendation or suggestion. The default settings enable this for recommendations, not suggestions. Packages installed in this way are marked as automatically installed. .  At removal time, removing a package will cause \"apt\" to remove packages depending on the removed package, but it won\u2019t process recommendations or suggestions. \"apt autoremove\" will then look for any package which is marked as automatically installed, and which no longer has any depending package (including recommendations and/or suggestions, depending on the \"Apt::AutoRemove::RecommendsImportant\" and \"Apt::AutoRemove::SuggestsImportant\" settings); any such package will be removed. The default settings keep recommended and suggested packages (which is asymmetric compared to the installation defaults, but avoids surprises). .  At upgrade time, only installed packages are considered. \"apt upgrade\" tries to upgrade all installed packages to their candidate versions, without removing any package. \"apt full-upgrade\" (or \"dist-upgrade\") considers removing packages if it allows other packages to be upgraded, but it won\u2019t remove a package just because it stops being recommended as a result of the upgrade. Packages which are newly recommended or suggested by an upgraded package aren\u2019t installed automatically. Packages which are no longer recommended or suggested become candidates for the next \"autoremove\". .  \"aptitude\" behaves slightly differently; it will perform the equivalent of \"apt autoremove\" when removing packages, and it will tell you about newly-recommended packages (but it won\u2019t select them for installation automatically). .  The following questions provide complementary information: .   Debian 9.1: apt-get autoremove will not remove dependencies Why did 'apt-get autoremove' not work properly? Find which Debian packages are only installed because they are recommended or suggested  ",
      "P-tags": "apt",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_67060435",
      "task": "How to convert string datetime to UTC UNIX?",
      "P-task": "convert string datetim utc unix",
      "F_verb": "convert",
      "P-body": "You're setting time zone to UTC when converting to datetime. But since your input represents time in Germany you want a time zone that is active there. EX: .  Note that if the input represents the same time zone your OS is configured to use, this works correctly without setting a time zone. But I think it's better to be explicit here, to avoid confusion if you e.g. run this script on a machine configured to use another time zone. .  ",
      "P-tags": "unix-timestamp datetim python python-3 x",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "au_942307",
      "task": "command line: start program by alacarte as sudo in folder/tree",
      "P-task": "command line : start program alacart sudo folder tree",
      "F_verb": "start",
      "P-body": "You can take inspiration from the similar question here. .  You can call the application in the \".desktop\" file as: .  ",
      "P-tags": "command-lin shortcut alacart nautilu sudo",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP by NP as NP in NP"
    },
    {
      "id": "ul_183602",
      "task": "Removing jre7 installs jre6",
      "P-task": "remov jre7 instal jre6",
      "F_verb": "remove",
      "P-body": "You should look at which packages depend on \"openjdk-7-jre\" being instaleld and use .  to remove these together with the openjdk-7-jre.  .  You might however find this impractical, I once thought I could get rid of of Java and Perl on a Linux server machine and couldn't without expecting to break the system. .  ",
      "P-tags": "linux-mint java",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_510562",
      "task": "How to match string in file",
      "P-task": "match string file",
      "F_verb": "match",
      "P-body": " You wouldn't do it in a shell loop as these are generally not ideal for parsing text (see \"Why is using a shell loop to process text considered bad practice?\"). .  Instead, the above single command uses \"sed\" to match the regular expression (here rewritten as a basic regular expression rather as a PCRE, a Perl compatible regular expression). The editing command used with \"sed\" replaces the matching line with the captured text and outputs it. .  Another way: .  This treats each line of the file as a record with fields delimited by \":\" followed by any number of spaces or tabs. When the \"STRING\" pattern is found on a line, the second such field is printed. .  Would you nonetheless want to do it with a \"bash\" loop: .  The \"BASH_REMATCH\" array will contain the various captured bits from the match. The regular expression itself (which should be an extended regular expression) should not be quoted, apart form the bits that needs to be interpreted literally. Note: This is where you went wrong; you quoted the regular expression and did not look in \"BASH_REMATCH\" for the captured data. You also tried to use the regular expression exactly the way you would write the expression in Python. \"bash\" is not Python. .  Or,  .  Given the input that you have in the question, the various variations above will all output .  See also: .   Why is printf better than echo? Understanding \"IFS= read -r line\" Why does my regular expression work in X but not in Y? Why is using a shell loop to process text considered bad practice?  ",
      "P-tags": "regular-express bash",
      "source": "qa",
      "cate": "match",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_311307",
      "task": "apt-get is broken, udev, update-initramfs and insserv seem to be the problem",
      "P-task": "apt-get broken udev update-initramf insserv seem problem",
      "F_verb": "get",
      "P-body": "\"insserv\" thinks \"mountkernfs\" is disabled, which basically means that there are no links to \"/etc/init.d/mountkernfs.sh\" in the \"/etc/rc?.d\" directories. As a result it refuses to enable \"udev\" (which depends on \"mountkernfs\")... .  To fix that, run .  which will restore the default links, in \"/etc/rcS.d\". The \"-v\" option gives more details if necessary.) Then \"insserv\" will consider that \"mountkernfs\" is enabled, so \"udev\" can also be activated. .  As to why things ended up that way, I don't know... .  ",
      "P-tags": "apt udev debian",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_529354",
      "task": "Cannot add an application to the launcher",
      "P-task": "add applic launcher",
      "F_verb": "add",
      "P-body": "Issues with the desktop file Taking the alacarte-made desktop file as a starting point (the other one has more issues), there are two lines which are almost certainly critical, and causing your desktop file to be refused by Dash and the Launcher: .   \"The Exec=\" line: .  What you are actually trying to do here is to open a file \"Java/eclipse/eclipse\" with an executable called \"Eclipse\", located in \"/home/jantek/Instalki\": .  That is probably not what you intended. Instead of the application (\"eclipse\"), you are referring to what seems to be a directory (\"Exec=/home/jantek/Instalki/Eclipse\").  .  Assuming the executable \"eclipse\" (lowercase) is in the folder \".../Eclipse\" (looking at your \"Icon=\" line, but check it), your \"Exec=\" line simply should be like: .   The \"Icon=\" line: .  Like I mentioned in my comment, Alacarte removes the file extension of any icon you define. Apart from that, just like in the \"Exec=\" line, the path you are defining is incorrect (why the space?). Your \"Icon=\" line should look like: .  But again, check if the paths to both the eclipse executable and the icon are correct. .   If you fix these two lines, your \".desktop\" file should work fine. .  Note: If the path to your executable or your icon includes foldernames with spaces: .   If it is in the \"Exec=\" line, put either the whole part after \"Exec=\" in quotes: .  or just the folder with spaces: .   In the \"Icon=\" line, a folder with a space should be fine: .    ",
      "P-tags": "desktop alacart launcher unity-dash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_614530",
      "task": "verify sha1sum and print directory & filename of corrupt files",
      "P-task": "verifi sha1sum print directori filenam corrupt file",
      "F_verb": "verify",
      "P-body": " Its output should match the sample shown in your question and it should work with arbitrary paths. .  Alternatively, using \"awk\" instead of shell features for prepending \"SHA1SUMS\"'s relative path to each file name: .  Note that, depending on its implementation, \"sha1sum\" may print altered file names. Specifically, GNU \"*sum\" utilities escape some characters1 and, when in check mode, prepend a \"\\\" to file names that need escaping, making the path obtained concatenating the relative path of your \"SHA1SUMS\" file and a file name printed by \"sha1sum\" unsuitable for reuse. .  1 The manual (\"sha1sum\"'s manual refers to that of \"md5sum\") says, generically, \"each problematic character\". .  ",
      "P-tags": "hashsum sha1sum find",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "so_26344463",
      "task": "How can I install a linux service from the service itself?",
      "P-task": "instal linux servic servic",
      "F_verb": "install",
      "P-body": "Here is how the problem was solved: .  The child process is detached from the caller and therefore even when the parent process gets killed the dpkg process still runs. .  ",
      "P-tags": "node js linux javascript deb",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP from NP"
    },
    {
      "id": "su_575615",
      "task": "static routing table behaviour with gateway set to * (linux)",
      "P-task": "static rout tabl behaviour gateway set linux",
      "F_verb": "set",
      "P-body": " \"Gateway *\" means that the destination network is directly connected, it doesn't have to go through a router. .  It won't go through a gateway to get to 10.0.2.0/24, it will send directly to the destination through interface p1p2. .  I think it should use the directly connected routing entry for 10.0.1.0/24. Otherwise it has an infinite recursion, since the gateway to 10.0.1.0/24 is on 10.0.1.0/24. .   Answering the question in your comment, 0.0.0.0/0 is the default route, used for anything without a more specific route. .  ",
      "P-tags": "rout linux network",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V to NP"
    },
    {
      "id": "so_11673287",
      "task": "How to remove a word prefix using grep?",
      "P-task": "remov word prefix use grep",
      "F_verb": "remove",
      "P-body": "You don't edit strings with \"grep\" in Unix shell, \"grep\" is usually used to find or remove some lines from the text. You'd rather use \"sed\" instead: .  You'll need to learn regular expressions to use it effectively. .  Sed can also edit file in-place (modify the file), if you pass \"-i\" argument, but be careful, you can easily lose data if you write the wrong \"sed\" command and use \"-i\" flag. .  An example From your comments guess you have a TeX document, and your want to remove the first part of all .com domain names. If it is your document \"test.tex\": .  then you can transform it with this \"sed\" command (redirect output to file or edit in-place with \"-i\"): .  Please note that: .   A common sequence of allowed symbols followed by a dot is matched by \"[a-z0-9-]\\+\\.\" I used groups in the regular expression (parts of it within \"\\(\" and \"\\)\") to indicate the first and the second part of the URL, and I replace the entire match with its second group (\"\\2\" in the substitution pattern) The domain should be at least 3rd level .com domain (every \"\\+\" repition means at least one match) The search is case insensitive (\"i\" flag in the end) It can do more than match per line (\"g\" flag in the end)  ",
      "P-tags": "sed linux shell regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP using NP"
    },
    {
      "id": "so_26376934",
      "task": "Catch a specific array column and write it to file",
      "P-task": "catch specif array column write file",
      "F_verb": "catch",
      "P-body": "You can iterate over the array and use \"read\" to capture 2nd column in each array entry: .  ",
      "P-tags": "array awk if-stat perl bash",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP"
    },
    {
      "id": "so_2902119",
      "task": "How do I compile irb from source on Ubuntu?",
      "P-task": "compil irb sourc ubuntu",
      "F_verb": "compile",
      "P-body": "Can you clarify what you mean exactly by \"compiling IRb without optimizations\"? .  You don't say which implementation of Ruby you are using. I am going to assume you are using YARV. .  With, YARV, there is no separate compile step, it compiles IRb automatically for you, everytime you run it. Even though YARV is a compiler, you can think of it as an interpreter, since you never have to worry about the compilation step.) Also, YARV doesn't do any optimizations when compiling AFAIK, and if it does, there is no way to influence the compilation, thus also no way to turn optimizations off. .  IRb is quite easy to find in the YARV sourcecode. The executable lives in the \"bin\" directory: .   \"bin/irb\"  But it's not doing any interesting work. The real meat is in the standard library: .   \"lib/irb.rb\" and the whole \"lib/irb/\" directory  ",
      "P-tags": "irb rubi ubuntu compil",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP from NP on NP"
    },
    {
      "id": "so_41625406",
      "task": "Is it possible to compile NASA Parallel Benchmarks (NPB) files in Linux using gfortran and openmpi?",
      "P-task": "possibl compil nasa parallel benchmark npb file linux use gfortran openmpi",
      "F_verb": "compile",
      "P-body": "After hacking at it I resolved the issue with the following fixes, not sure what did it. .  OpenMPI may have not been installed properly (was unable to call mpicc or other wrappers/comps), to fix it I ran the following commands .  The more likely fix was simply changing gfortran in the make.def file to mpif77 .  ",
      "P-tags": "linux compiler-error benchmark gfortran mpi",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "so_58602198",
      "task": "Method invocation failed because [System.String] does not contain a method named 'saveasfile'",
      "P-task": "method invoc fail system string contain method name saveasfil",
      "F_verb": "contain",
      "P-body": "Outlook's \"Attachments\" property's enumerator returns a \"String\" key, not an actual attachment object (this is why using an untyped or weakly-typed language like PowerShell for working with COM is a very bad idea). .  While PowerShell wants to be used as a functional, pipelining language (which is a PITA to debug) - sometimes it's easier to use old-fashioned imperative code: .  BTW, you don't need the \"if ($email.attachments.count -ge 1)\" statement because the \"For( $i = 0; $i...\" loop also checks the \".Attachments.Count\" property too. .  ",
      "P-tags": "powershel outlook",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_1308661",
      "task": "Does installing mysql-server include mysql-client as well?",
      "P-task": "instal mysql-serv includ mysql-client well",
      "F_verb": "include",
      "P-body": "They are separate pieces of software, but installing \"mysql-server\" installs \"mysql-client\" as well, because you can use \"mysql-client\" to connect to the server, even over localhost. If you look at the package listing for mysql-server, you will see it depends on mysql-server-8.0, which depends on mysql-client-8.0, causing \"apt\" to install the client as well. .  ",
      "P-tags": "apt mysql server",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP as NP"
    },
    {
      "id": "so_1831955",
      "task": "PowerShell: an elegant way to create closures",
      "P-task": "powershel : eleg way creat closur",
      "F_verb": "create",
      "P-body": "You could create a function that takes a scriptblock, calls GetNewClosure and returns the closure. It is essential that you call this function using the dot operator e.g.: .  Not sure this is much better than just calling GetNewClosure() on the scriptblock though. Note you can pick some other name for the function. I was going for something more like C# lambdas. .  ",
      "P-tags": "powershel closur net",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "au_193403",
      "task": "Problems in LibreOffice Writer when saving as .docx",
      "P-task": "problem libreoffic writer save docx",
      "F_verb": "save",
      "P-body": "LibreOffice Writer is compatible with MS Word, but don't expect that every format you applied in Word will be the same if you open the file in Writer and vice versa. No such thing as 100% compatibility. .  I have been creating documents with MS Word at work and modifies it at home with LibreOffice Writer, and although they are compatible, there are visible changes in the document's formatting such as spacing, font, header and footer, and yes alignment of images as well. .  I'd suggest that if you don't need to open it with Word, stick to the default \".odt\" file format.  .  If you do need to access the file with MS Word, then I'd recommended to save it as \".doc\" and not as \".docx\". Saving it in older doc version will guarantee (most of the time) to open it in the original document formatting. .  For more assistance, please see How to maintain document compatibility between LibreOffice and other office suites? .  ",
      "P-tags": "12 04 libreoffic",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V as NP"
    },
    {
      "id": "so_43469320",
      "task": "read first line of the file and compare it with a string in shell file",
      "P-task": "read first line file compar string shell file",
      "F_verb": "read",
      "P-body": "You could use .  This would ignore any leading/trailing white space. This has the benefit of not forking expensive \"sed\" commands to just remove a few characters. That's like delivering a few sugar cubes with a flat bed truck... .  ",
      "P-tags": "unix shell",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP of NP with NP in NP"
    },
    {
      "id": "au_614246",
      "task": "How can I get a Byobu split to reload users permissions?",
      "P-task": "get byobu split reload user permiss",
      "F_verb": "get",
      "P-body": "A process can change its uid and gid, but few processes do this and fewer let the user do this. Neither multiplexer, unfortunately, does either. With \"screen\", apparently one can run a command on all windows using \"at\" (see this SU post). There seems to be no direct analogue of \"at\" in \"tmux\", solutions usually include parsing the output of other \"tmux\" commands (a gist implementing this). Another solution is to synchronize all the windows, and run the command (from this SO post): .    ",
      "P-tags": "byobu tmux user",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_15235165",
      "task": "Howto use a blank space as a variable with SED",
      "P-task": "howto use blank space variabl sed",
      "F_verb": "use",
      "P-body": " is exactly the same as: .  so you are passing two distinct arguments to sed. You could do: .  but if you insist on using \"sed\" it's probably better to do: .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP with NP"
    },
    {
      "id": "so_57779917",
      "task": "how to use wget spider to identify broken urls from a list of urls and save broken ones",
      "P-task": "use wget spider identifi broken url list url save broken one",
      "F_verb": "use",
      "P-body": "I think I would go with: .  You can use \"-P <count>\" option to \"xargs\" to run \"count\" processes in parallel. .  \"xargs\" runs the command \"sh -c '....' --\" for each line of the input file appending the input file line as the argument to the script. .  Then \"sh\" inside runs \"wget ... \"$1\"\". The \"||\" checks if the return status is nonzero, which means failure. On \"wget\" failure, \"echo \"$1\"\" is executed. .  Live code link at repl. .  You could filter the output of \"wget -nd -nv\" and then regex the output, well like .  but this looks not expendable, is not parallel so probably is slower and probably not worth the hassle. .  ",
      "P-tags": "linux wget shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF from NP"
    },
    {
      "id": "so_35734197",
      "task": "How to use awk to test if a column value is in another file?",
      "P-task": "use awk test column valu anoth file",
      "F_verb": "use",
      "P-body": "You could use something like this: .  This saves each line from \"A.txt\" as a key in the array \"a\" and then prints any lines from \"B.txt\" whose second field is in the array.  .  \"NR == FNR\" is the standard way to target the first file passed to awk, as \"NR\" (the total record number) is only equal to \"FNR\" (the record number for the current file) for the first file. \"next\" skips to the next record so the \"$2 in a\" part is never reached until the second file. .  ",
      "P-tags": "awk linux",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF if S"
    },
    {
      "id": "au_458879",
      "task": "Deleting files by way of the terminal where files have a certain keyword",
      "P-task": "delet file way termin file certain keyword",
      "F_verb": "delete",
      "P-body": "The error you are getting is because you have too many files which means that \"*\" in your \"rm\" command is expanded to a list that is longer than the limit (ARG_MAX). So, to get around this you have various options: .   Give \"rm\" only some of the files: .   Delete the directory containing the files, this avoids listing the files altogether: .   Use \"find\": .  or, for non-GNU \"find\": .   Use a shell loop .    ",
      "P-tags": "git trash command-lin",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP by NP of NP where S"
    },
    {
      "id": "ul_382769",
      "task": "Add sources for apt-get for Debian Linux 2.4.27-3-286",
      "P-task": "add sourc apt-get debian linux 2 4 27-3-286",
      "F_verb": "add",
      "P-body": "in sources.list .  ",
      "P-tags": "debian",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP for NP for NP"
    },
    {
      "id": "so_25070649",
      "task": "Linux: Bind UDP listening socket to specific interface (or find out the interface a datagram came in from)?",
      "P-task": "linux : bind udp listen socket specif interfac find interfac datagram came",
      "F_verb": "bind",
      "P-body": "The solution that I found to work is as follows. First of all, we have to change ARP and RP settings. To /etc/sysctl.conf, add the following and reboot (there's also a command to set this dynamically): .  The arp filter was necessary to allow responses from eth0 to route over a WAN. The rp filter option was necessary to strictly associate in-coming packets with the NIC they came in on (as opposed to the weak model that associates them with any NIC that matches the subnet). A comment from EJP led me to this critical step. .  After that, SO_BINDTODEVICE started working. Each of two sockets was bound to its own NIC, and I could therefore tell which NIC a message came from based on the socket it came from. .  Next, I wanted to respond to in-coming datagrams with datagrams whose source address is that of the NIC the original request came from. The answer there is to just look up that NIC's address and bind the out-going socket to that address (using \"bind\").  .  (Maybe looking up the NIC's address every time seems like a waste, but it's way more code to get informed when an address changes, and these transactions occur only once every few seconds on a system that doesn't run on battery.) .  ",
      "P-tags": "socket linux bind udp c",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP to NP"
    },
    {
      "id": "au_465661",
      "task": "how to see what was updated in last update",
      "P-task": "see updat last updat",
      "F_verb": "see",
      "P-body": "You can look in \"/var/log/apt/history.log\" to see what has been upgraded or installed, through an automated process or by your own decision. .  ",
      "P-tags": "14 04 updat histori",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V what S"
    },
    {
      "id": "au_354645",
      "task": "Get list of installed packages - from damaged partition",
      "P-task": "get list instal packag - damag partit",
      "F_verb": "get",
      "P-body": "If you can mount the virtual disk enough to see the /var/lib/dpkg/ directory, you can tell dpkg to look there with the \"--admindir\" option. .  The only file that is really needed is /var/lib/dpkg/status (or one of its backups). So you could copy that single file to an empty directory and point dpkg at that directory. .  ",
      "P-tags": "dpkg apt vmware instal",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_10571393",
      "task": "How to tell curl to check file existence before download?",
      "P-task": "tell curl check file exist download",
      "F_verb": "tell",
      "P-body": "If the target resource is static, \"curl\" has an option \"-z\" to only download a newer target copy. .  Usage example: .  An example for your case: .  \"for i in $(seq 0 100); do curl -z image$i.jpg -O --max-time 10 --retry 3 --retry-delay 1 http://site.com/image$i.jpg; done\" .  ",
      "P-tags": "curl bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP S_INF before NP"
    },
    {
      "id": "so_2364412",
      "task": "Executing a command from C++, What is expected in argv[0]?",
      "P-task": "execut command c++ expect argv 0",
      "F_verb": "execute",
      "P-body": "\"argv[0]\" is supposed to be the program name. It's passed to the program's \"main\" function. Some programs differentiate their behavior depending on what string \"argv[0]\" is. For example the GNU \"bash\" shell will disable some of its features if called using \"sh\" instead of \"bash\". Best give it the same value that you pass to \"path\".  .  In linux, \"argv[0]\" is the process name displayed by the \"top\" utility (which it probably gets from reading entries in \"/proc/\") .  ",
      "P-tags": "c++ linux execv argument-pass",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_66146149",
      "task": "Foreach loop to add element to XML",
      "P-task": "foreach loop add element xml",
      "F_verb": "add",
      "P-body": "You have to create a new element for each element to be added. Finally, the \"Save()\" call should be only at the end, when you are done with the document. .   On a side note \"[xml]$XmlDocument = Get-Content \".\\test.xml\"\", while being convenient, is bad practice. It works just by chance, as most XML documents these days are UTF-8 encoded, which happens to be the default encoding used by \"Get-Content\". But \"Get-Content\" knows nothing about the actual value of the XML \"encoding\" attribute. .  Proper way to load the XML document, while respecting its \"encoding\" attribute: .  ",
      "P-tags": "powershel xml foreach",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_54383667",
      "task": "How to Make Constants in an Expect Script?",
      "P-task": "make constant expect script",
      "F_verb": "make",
      "P-body": "Like Python, TCL (the scripting language used for Expect) doesn't have constants. .  I would suggest going the python route. Define them in all caps, don't change them and hope everyone else gets the hint. .  If you really think you need them, there are some hacks in the link glenn jackman posted in the comments https://wiki.tcl-lang.org/page/constants. .  ",
      "P-tags": "expect constant bash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "so_39760444",
      "task": "Can't run a file that exist",
      "P-task": "run file exist",
      "F_verb": "run",
      "P-body": "Maybe you should run this command like this: .  or like this: .  The second one cannot collide with another programs that could be in \"/usr/bin\" for example.  .  ",
      "P-tags": "termin linux ubuntu apache-pig hadoop",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP that S"
    },
    {
      "id": "so_37743601",
      "task": "How to upgrade PHP 5.1 to higher version in CentOS 5.x",
      "P-task": "upgrad php 5 1 higher version cento 5 x",
      "F_verb": "upgrade",
      "P-body": "I feel embarrassed. My host told me that I have CentOS 7.x but I wanted to confirm and when I checked it, it was \"centos-release-5-11.el5.centos\" .  I followed this tutorial: https://www.joeferguson.me/installing-php-5-6-x-on-centos-5-11/  .  ALSO do not forget to restart httpd service \"service httpd restart\" after installing packages. .  Problem is fixed. Thanks a lot for your help guys. I couldn't have done it without you. :) .  ",
      "P-tags": "cento linux php",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_50308396",
      "task": "Bash date case not correct",
      "P-task": "bash date case correct",
      "F_verb": "correct",
      "P-body": "As man date does not show help about lowercase month, I would just pipe it .  ",
      "P-tags": "date bsd bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "au_937904",
      "task": "Resize and merge images vertically",
      "P-task": "resiz merg imag vertic",
      "F_verb": "resize",
      "P-body": "This is the \"imergv.py\" script, in Python, that does just that. Imagemagick is required. Note that before running the script, you need to \"cd\" into the directory with the images. Some image viewers suited to view large images are Viewnior, Nomacs and Gwenview. The script will generate some \"tmpfXXXX.png\" images and a file called \"output.png\" with the end result. .  ",
      "P-tags": "imagemagick",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_13477714",
      "task": "How to send signal SIGUSR1 and SIGUSR2 from parent to children?",
      "P-task": "send signal sigusr1 sigusr2 parent children",
      "F_verb": "send",
      "P-body": "You are sending signals so quickly that the signal handler processing \"SIGUSR1\" gets interrupted by the next signal and processes that first before it returns. .   signal 2 arrives, prints signal 2 arrives, prints signal 1 arrives, gets interrupted before it can print because another signal 2 arrives signal 2 arrives, prints after last signal handler returned signal handler for \"SIGUSR1\" continues execution and prints.  Either send your parent some sort or acknowledgement, make your parent sleep a while or make your signal handler return faster (store signal arrival in a buffer. Invoking \"printf\" is quite a long call. .  When signals for a process arrive a random thread of that process gets interrupted and begins executing the signal handler. If the signal handler returns the thread will continue execution as usual. Signal handlers can also be interrupted! .  ",
      "P-tags": "freebsd signal c unix",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "au_187511",
      "task": "How can I use a .ovpn file with Network Manager?",
      "P-task": "use ovpn file network manag",
      "F_verb": "use",
      "P-body": "First, install the OpenVPN Network Manager plugin: .  Open Network Manager, click \"Add\" and from the opened window select \"Import a saved VPN configuration...\" under \"Choose a Connection Type\". Navigate to your .ovpn file (~jrg/Documents/vpn-config.ovpn). If it doesn't automatically find your certificates/keys (the paths of which are found in the .ovpn file), you can select them here, or make any other small changes. .   .  One other thing that may save you some headache down the road is to click IPv4 Settings, then change the method to \"Automatic (VPN) Addresses Only\". When kept at the default, this will cause ALL internet traffic to go over the VPN, regardless of your .ovpn settings. Here you can also set the DNS server and search domains to use while connected. .   .  ",
      "P-tags": "openvpn network-manag",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "so_3839454",
      "task": "how to use pylint in vim",
      "P-task": "use pylint vim",
      "F_verb": "use",
      "P-body": "why so complicated with sed which just works properly on Linux? Try the following: .  ",
      "P-tags": "sed linux pylint vim",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_404551",
      "task": "Overwriting a running executable or .so",
      "P-task": "overwrit run execut",
      "F_verb": "overwrite",
      "P-body": "It depends on the kernel, and on some kernels it might depend on the type of executable, but I think all modern systems return ETXTBSY (\u201dtext file busy\u201c) if you try to open a running executable for writing or to execute a file that's open for writing. Documentation suggests that it's always been the case on BSD, but it wasn't the case on early Solaris (later versions did implement this protection), which matches my memory. It's been the case on Linux since forever, or at least 1.0. .  What goes for executables may or may not go as well for dynamic libraries. Overwriting a dynamic library causes exactly the same problem that overwriting an executable does: instructions will suddenly be loaded from the same old address in the new file, which probably has something completely different. But this is in fact not the case everywhere. In particular, on Linux, programs call the \"open\" system call to open a dynamic library under the hood, with the same flags as any data file, and Linux happily allows you to rewrite the library file even though a running process might load code from it at any time. .  Most kernels allow removing and renaming files while they're being executed, just like they allow removing and renaming files while they're open for reading or writing. Just like an open file, a file that's removed while it's being executed will not be actually removed from the storage medium as long as it is in use, i.e. until the last instance of the executable exits. Linux and *BSD allow it, but Solaris and HP-UX don't. .  Removing a file and writing a new file by the same name is perfectly safe: the association between the code to load and the open (or being-executed) file that contains the code goes by the file descriptor, not the file name. It has the additional benefit that it can be done atomically, by writing to a temporary file then moving that file into place (the \"rename\" system call atomically replaces an existing destination file by the source file). It's much better than remove-then-open-write since it doesn't temporarily put an invalid, partially-written executable in place .  Whether \"cc\" and \"ld\" overwrite their output file, or remove it and create a new one, depends on the implementation. GCC (at least modern versions) and Clang do this, in both cases by calling \"unlink\" on the target if it exists then \"open\" to create a new file. I wonder why they don't do write-to-temp-then-rename.) .  I don't recommend depending on this behavior except as a safeguard since it doesn't work on every system (it may work on every modern systems for executables, but not for shared libraries), and common toolchains don't do things in the best way. In your build scripts, always generate files under a temporary file, then move them into place, unless you know the underlying tool does this. .  ",
      "P-tags": "execut ld write",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "au_775175",
      "task": "How to Install vim-full in 16.04?",
      "P-task": "instal vim-ful 16 04",
      "F_verb": "install",
      "P-body": "vimdiff tool is under package vim. You should install vim using following command: .  Then you can use the vimdiff as: .  ",
      "P-tags": "vim 16 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1249870",
      "task": "N: Skipping acquire of configured file 'universe/binary-i386/Packages' as ... doesn't support architecture 'i386'",
      "P-task": "n : skip acquir configur file univers binary-i386 packag support architectur i386",
      "F_verb": "skip",
      "P-body": "For the first problem, refer to the answer Skippping acquire configured file - doesn't support architecture 'i386' You must find the file located in /etc/apt where the string 'repos.codelite.org' is present and add the string '[arch=amd64]'. In this way only the packages for the correct architecture are installed. .  For the second problem (the one related to the OS updated), according to the output you showed in your question, I suggested you to update the package python-datamatrix running: \"pip3 install python-datamatrix\" .  However, according to your feedback (you were not able to solve), it's best to remove it (as suggested in karel's answer): \"pip3 uninstall python-datamatrix\" .  For this answer, I referred also to Error while trying to upgrade from Ubuntu 18.04 to 18.10: \"Please install all available updates for your release before upgrading.\" and Can't upgrade Ubuntu 18.04 to 20.04 because of \"Please install all available updates for your release before upgrading\" error .  ",
      "P-tags": "18 04 20 04",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP as NP"
    },
    {
      "id": "su_915435",
      "task": "Get-ChildItem recursive that matches regex patterm and rename the item",
      "P-task": "get-childitem recurs match regex patterm renam item",
      "F_verb": "get",
      "P-body": "This works for me: .  It captures the (1) with and without leading whitespace and removes it. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP that S"
    },
    {
      "id": "so_37001694",
      "task": "How to handle backslash character in PowerShell -replace string operations?",
      "P-task": "handl backslash charact powershel -replac string oper",
      "F_verb": "handle",
      "P-body": "Try the following: .  You were only matching 1 backslash when replacing, which gave you the three \"\\\\\\\" at the start of your path.  .  The backslash is a \"regex\" escape character so \"\\\\\" will be seen as, match only one \"\\\" and not two \"\\\\\". As the first backslash is the escape character and not used to match.  .  Another way you can handle the backslashes is use the \"regex\" escape function.  .  ",
      "P-tags": "powershel replac backslash",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP in NP"
    },
    {
      "id": "so_36054390",
      "task": "linux connect to remote sybase and backup/dump",
      "P-task": "linux connect remot sybas backup dump",
      "F_verb": "connect",
      "P-body": "Sybase backup and restore does not support remote operation. It will only dump/load from local partitions. .  If you need to get the database to your local system you can either dump the database then sftp the file to your local system, or use the \"bcp\" utility (which supports remote operations) to extract data from the remote system and import it into your local system. .  More on using bcp .  ",
      "P-tags": "sybas linux remote-access",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "au_1086795",
      "task": "Upgraded from 18.04 to 18.10, now suspend doesn't work anymore",
      "P-task": "upgrad 18 04 18 10 suspend work anymor",
      "F_verb": "suspend",
      "P-body": "I seem to have fixed this by following the instructions in this answer, even though they are from 7 years ago... .  Edit the following line in the \"/etc/default/grub\" file: .  Change it to: .  Save the file, then run: .  and reboot. .  I wonder why I didn't need to do this with 18.04 and it became necessary only since 18.10. .  ",
      "P-tags": "suspend 18 10",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V from NP to NP"
    },
    {
      "id": "so_22569195",
      "task": "Is it possible to print a spinning cursor in a terminal using bash scripting?",
      "P-task": "possibl print spin cursor termin use bash script",
      "F_verb": "print",
      "P-body": "Spinners are nice, but if you really want a controllable progress meter that is aware of the IO you're dealing with, take a look at pv. .  Here's a quick-and-dirty spinner. Many nonstandard implementations of \"sleep\" will let you sleep for fractions of a second.) .  Bash POSIX Sh ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "ul_454796",
      "task": "Remove \"\\n\" string from end of certain lines",
      "P-task": "remov n string end certain line",
      "F_verb": "remove",
      "P-body": "Add a regex address specifier at the front - since your pattern has forward slashes, it's clearer if you use a different expression separator: .  Testing:  .  If you prefer \"leaning toothpicks\" .  ",
      "P-tags": "sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP of NP"
    },
    {
      "id": "so_63566230",
      "task": "Unable to lock file linux",
      "P-task": "unabl lock file linux",
      "F_verb": "lock",
      "P-body": "The \"flock\" command uses \"flock(2)\" to lock the file. As the documentation says .   \"flock()\" places advisory locks only; given suitable permissions on a file, a process is free to ignore the use of \"flock()\" and perform I/O on the file. .   In general, applications don't check advisory locks. They're intended for use within a specific application to coordinate between multiple processes. .  The \"flock\" command is most often used by a single application just to prevent itself from running multiple times concurrently. .  ",
      "P-tags": "file linux flock",
      "source": "qa",
      "cate": "lock/seal/relock",
      "pat": "V NP"
    },
    {
      "id": "au_235777",
      "task": "Ubuntu 12.10 skype 4.1 cannot properly run wrapper",
      "P-task": "ubuntu 12 10 skype 4 1 properli run wrapper",
      "F_verb": "run",
      "P-body": "Link to the thread that fixed this problem .  Ubuntu Forums: .   I dragged and dropped this version .  from this location \"/usr/share/application/\" .   onto the Launcher. .  ",
      "P-tags": "skype",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_62762631",
      "task": "Simple way to get the epoch of 12 AM for today in UTC in Python (3.x)?",
      "P-task": "simpl way get epoch 12 today utc python 3 x",
      "F_verb": "get",
      "P-body": "You need to figure how what date it is currently in UTC, and then replace the time bits: .  In order to get the epoch, use \"midnight.timestamp()\". This will ensure that the timezone information is applied when calculating the timestamp. .  ",
      "P-tags": "unix-timestamp python-3 x",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP in NP in NP"
    },
    {
      "id": "so_25667398",
      "task": "providing root authentication for a qt program",
      "P-task": "provid root authent qt program",
      "F_verb": "provide",
      "P-body": "If I understand correctly you could simply use \"popen\" for a \"su root\" command (which if I am not mistaken should not do anything by itself as it is executed in a seperate shell) and check the return message (\"stdout\") as stated in the example from the link: .  The return is probably system specific but it should be able to give you an idea whether the password is correct or not. .  If you want a prompt to ask for root to even start the program, maybe something like this is what you seek. .  ",
      "P-tags": "linux qt authent",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP for NP"
    },
    {
      "id": "so_36988531",
      "task": "Bash, how to extract grep occurences and store them in an array",
      "P-task": "bash extract grep occur store array",
      "F_verb": "extract",
      "P-body": "Solution using GNU grep Let's take this as the test file: .  If you have GNU \"grep\", which is what you have if you are running Linux, then you can extract the names of elements like this: .  You can put those names into a bash array as follows: .  The \"-P\" option tells GNU grep to use Perl-style regular expressions. \"(?<==)\" requires a \"=\" before the match and \"(?= *:)\" requires a colon after match. .  We can verify that the array is correct via the \"declare\" command: .  Solution not requiring GNU grep One can obtain the same effect using \"sed\": .  The results can be stored in a bash array just like before:  .  ",
      "P-tags": "bash grep regex",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_27628757",
      "task": "Unable to cast object to System.Net.Sockets.Socket",
      "P-task": "unabl cast object system net socket socket",
      "F_verb": "cast",
      "P-body": "Your issue is the lines that have \"Write-Output\". Be default function return all output. That would mean you text as well. This can be verified from running this command .  That is why it is returning \"System.Object[]\" and the cast is failing. Change those lines to \"Write-Host\" .  And PowerShell will handle the rest like it always does. .  Top it off with some supplementary reading: Function return value in PowerShell .  ",
      "P-tags": "type powershel socket net",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_28141653",
      "task": "Does user.name in Git need to match my GitHub username?",
      "P-task": "user name git need match github usernam",
      "F_verb": "match",
      "P-body": "No, your \"user.name\" does not matter. .  However your \"user.email\" should match one of the addresses in your GitHub settings. .  \"git config --global user.email \"YOUR EMAIL\"\" .  You can also keep your email private .  ",
      "P-tags": "git linux github",
      "source": "qa",
      "cate": "match",
      "pat": "V NP"
    },
    {
      "id": "ul_512508",
      "task": "Building sstp-client on Kali Linux from Source: dpkg errors",
      "P-task": "build sstp-client kali linux sourc : dpkg error",
      "F_verb": "build",
      "P-body": "On debian testing, you can install \"sstp-client\" from this git repository. .   Attention Debian Users: .  Debian/Ubuntu users can now use my personal PPA to download and install the \"network-manager-sstp\" and \"sstp-client\" project via launchpad. .   Using \"apt\" (\"bionic\" suite for debian testing): .  ",
      "P-tags": "dpkg sourc kali-linux debian vpn",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP from NP"
    },
    {
      "id": "so_17117230",
      "task": "powershell failing to import module",
      "P-task": "powershel fail import modul",
      "F_verb": "import",
      "P-body": "The most likely case is that you've got your module installed to a personal location, and not a system location. If you're running it inside of a scheduled task, or have it installed for a particular user (and are running as someone else), then you'll need to make sure that the module is in the \"right\" location. .  Will show the current module paths. There should be at least 2. One will be in your user directory, and the other will be in $pshome\\Modules.  .  If you want to be lazy, you can put a module there. If you want to be thorough, you can create a new directory, change PSModulePath (outside of PowerShell, so it sticks from one PowerShell instance to the next) to include this directory. This is the \"official\" way. .  On a personal note, since you're probably using the very old TaskScheduler module I wrote in the PowerShellPack, I'm sorry that my installer drops them into user directories, and not global directories. While user directories are the common case, global directories should have been an option. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP"
    },
    {
      "id": "au_886620",
      "task": "How can I execute command on startup (rc.local alternative) on Ubuntu 16.10",
      "P-task": "execut command startup rc local altern ubuntu 16 10",
      "F_verb": "execute",
      "P-body": "Intro I think you should not create a new service as suggested in the link by George. The \"rc-local.service\" already exists in systemd and the service file suggests that the \"rc.local\", if it exists and is executable, gets pulled automatically into \"multi-user.target\". So no need to recreate or force something that is just done in another way by the \"systemd-rc-local-generator\".  .  One solution A quick solution (I don't know if that's the canonical way): .  In a terminal do: .  After that the \"rc.local\" will be called upon system startup. Insert what you like. .  Background If you do in a terminal: .  You can see that the head comment contains lines such as: .  This indicates, that in this system, if there is a file called \"/etc/rc.local\" which is executable, then it will be pulled into multi-user.target automatically. So you just create the according file (\"sudo touch...\") and make it executable (\"sudo chmod +x ...\"). .  ",
      "P-tags": "16 10 systemd",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP on NP"
    },
    {
      "id": "so_14248214",
      "task": "Adding comments inside single quotes in a shell script?",
      "P-task": "ad comment insid singl quot shell script",
      "F_verb": "add",
      "P-body": "The problem is not single quotes but using \"JSON\". AFAIK, you can't add comments in \"JSON\", see Can comments be used in JSON? .  Note : .  you should add \"-H \"Content-Type: text/json\"\" in your \"cURL\" .  ",
      "P-tags": "comment hash escap shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP inside NP in NP"
    },
    {
      "id": "ul_392667",
      "task": "Checking the execution of the previous command",
      "P-task": "check execut previou command",
      "F_verb": "check",
      "P-body": "The \"expdp\" utility exits with a zero exit status if  .   The export or import job completed successfully. No errors are displayed to the output device or recorded in the log file, if there is one. [Ref: Data Pump Exit Codes]. .   Otherwise it will have a non-zero exit status. This is standard for utilities on Unix. Zero means \"Success\" and it's also a \"true\" value in boolean tests. .  In your script, you should therefore be able to say .  This means that you got the tests backwards in your code. .  If you want to actually display the exit code: .  Since \"echo\" will change \"$?\", you will need to save its value to a new variable straight after using \"expdp\". .  ",
      "P-tags": "linux echo shell-script oracle-databas",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "so_26515950",
      "task": "Add custom object powershell",
      "P-task": "add custom object powershel",
      "F_verb": "add",
      "P-body": "The problem lies in this line: .  $ADSites is an array. It contains all sitenames so what you will create looks like this: .  The solution is to create an array that holds multiple objects and add one object per site: .  Write-Output is used to output to the pipeline not for producing screen output .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_31339932",
      "task": "BASH: How to correctly return true and false from a function",
      "P-task": "bash : correctli return true fals function",
      "F_verb": "return",
      "P-body": "\"[\" is not syntax; it is a command. It is commonly used with \"if\", which works based on its return code. .  To directly check the return code of a different command, e.g. \"kill\", you should remove the \"[\" and \"]\" (the last argument to \"[\"): .  Note that \"&>\" is a Bash extension, equivalent to \">/dev/null 2>&1\". .  ",
      "P-tags": "function kill bash boolean return",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "au_1034622",
      "task": "curl cannot connect to HTTPS sites in 18.04",
      "P-task": "curl connect http site 18 04",
      "F_verb": "connect",
      "P-body": "It turns out I had installed my own version of \"openssl\" a long time ago (2 years) that was being considered as newer than the one provided by the default repositories. Simply reinstalling the correct version fixed my issue. .  ",
      "P-tags": "18 04 curl ssl",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP in NP"
    },
    {
      "id": "so_46288364",
      "task": "How can I make port routing for containers in proxmos?",
      "P-task": "make port rout contain proxmo",
      "F_verb": "make",
      "P-body": "The qm command in proxmox is used for qemu virtual machines (kvm) and not for the LXC containers. It's normal not to work for LXC since when executed, it tries to find a kvm virtual machine configuration for that ID. That id being an LXC container and not a KVM machine, has no configuration file. .  In order to map ports to an LXC container you'll have to use iptables (afaik there is no similar qm tool for lxc). Login to your proxmox server via SSH, become root and the syntax for port forwarding is like this: .  For example if you want to map let's say port 9999 to port 9999 of your LXC container (let's assume the lxc container has ip 1.1.1.1 for the sake of the example), your iptables rule is: .  Please keep in mind that, your default ethernet device might not be eth0 but vmbr0 or whatever that is. So replace eth0 with the corresponding device. .  ",
      "P-tags": "contain rout port linux proxmox",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_1100190",
      "task": "How to pass a parameter from Batch file to a function inside a Powershell script",
      "P-task": "pass paramet batch file function insid powershel script",
      "F_verb": "pass",
      "P-body": "modify your script to look like the following .  and from the batch file, it would look like .  ",
      "P-tags": "powershel batch-fil parameter-pass",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP from NP to NP inside NP"
    },
    {
      "id": "so_28909658",
      "task": "Write a shell script that replaces multiple strings in multiple files",
      "P-task": "write shell script replac multipl string multipl file",
      "F_verb": "write",
      "P-body": " ",
      "P-tags": "shell sed termin maco",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP that S"
    },
    {
      "id": "ul_368018",
      "task": "Taking register value and using it later as variable",
      "P-task": "take regist valu use later variabl",
      "F_verb": "use",
      "P-body": "You are accessing the register variable eth0 by trying to use the name \"register\" which doesn't exist. .  When you register a variable in ansible, you also tell ansible the name of the variable you want to register it as - in your case, eth0: .  So to access it later, you would have to use the name eth0 like so: .   Now, if you permit me to solve what I believe is an XY problem of yours - instead of using grep to parse out the ip address of your interface, why not try using ansible facts? If you know the interface name on the host, then you can simply do something like this: .  If, on the other hand, you do not know the interface name (or they are different on all your hosts) - but you do know that each host has only one viable interface, then you could use something like the following: .  To see all the facts that ansible collects on a system, use the following command: .  ",
      "P-tags": "ansibl",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP"
    },
    {
      "id": "so_67940617",
      "task": "How to add item per line in linux terminal bash `apt install` command?",
      "P-task": "add item per line linux termin bash apt instal command",
      "F_verb": "add",
      "P-body": "What you have should work, with 2 caveats. The backslash must immediately precede the \"\\n\", and you probably want to omit the backslash on the last line. eg: .  Note that by retaining the backslash on the last line in the above example, an additional (unescaped) newline is required to terminate the command. Also note that the leading whitespace on subsequent lines is necessary, as the shell will literally ignore the escaped newline and merge the two arguments if there is no leading whitespace. eg: .  ",
      "P-tags": "termin apt debian shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_58677450",
      "task": "Undeclared variable in a cross compiled root filesystem",
      "P-task": "undeclar variabl cross compil root filesystem",
      "F_verb": "compile",
      "P-body": "\"<limits.h>\" is part of the C standard library, so you really have to have that in somewhere, somehow, if not builtin in the compiler. The \"PATH_MAX\" is a POSIX extension. If by some reason your cross compiler is not enabling necessary flags, you could try with  .  If it still fails then you do not have the target system headers installed.  .  ",
      "P-tags": "chroot linux gcc glibc c",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP"
    },
    {
      "id": "so_31869385",
      "task": "Find a specific folder in all remote and local GIT branches",
      "P-task": "find specif folder remot local git branch",
      "F_verb": "find",
      "P-body": "The following command will output all refs (local and remotes) that point to a commit which contains the path specified in the variable \"SEARCH_PATH\" .  ",
      "P-tags": "git linux smartgit",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_14161415",
      "task": "mysql process cannot be stopped",
      "P-task": "mysql process stop",
      "F_verb": "stop",
      "P-body": "I was having this exact same problem. Running the \"kill\" command would kill the process, but in my case it would keep popping up again under a different process ID. .  The only way I could figure out how to stop it for good was this: .  Hope that helps. .  Source: http://www.itfromscratch.com/how-to-stop-the-percona-mysql-server/ .  ",
      "P-tags": "ubuntu mysql percona",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V"
    },
    {
      "id": "so_37979980",
      "task": "Finding zeros and replacing them with another number in a matrix file by awk",
      "P-task": "find zero replac anoth number matrix file awk",
      "F_verb": "replace",
      "P-body": "\"awk\" to the rescue! .  defined eps, as long as you have a sensible value it should work fine, but doesn't check for going below zero. .  ",
      "P-tags": "awk math matrix shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP in NP by NP"
    },
    {
      "id": "su_1250228",
      "task": "PuTTY error: /bin/bash Operation not permitted when connecting to Cygwin sshd",
      "P-task": "putti error : bin bash oper permit connect cygwin sshd",
      "F_verb": "connect",
      "P-body": "Here is a more direct way doing what the previous posts by \u041a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u0438\u043d \u0411\u0440\u044b\u0437\u0433\u0430\u043b\u043e\u0432 and Mun-dee say. Run a cygwin terminal as Administrator, then: .  ",
      "P-tags": "cygwin putti ssh bash window",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_19985492",
      "task": "Can I use the same pipe between 2 children processes in C?",
      "P-task": "use pipe 2 children process c",
      "F_verb": "use",
      "P-body": "You cannot copy a pipe, it is a file descriptor, it is a pipe with two ends. Use \"tee\" if you need more and named pipes.  .  You cannot copy a pipe means you can't access one end of it from two processes, the pipe cannot copy it's content. .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP between NP in NP"
    },
    {
      "id": "so_36597369",
      "task": "Edit a Text Form Field in MS Word with Powershell",
      "P-task": "edit text form field ms word powershel",
      "F_verb": "edit",
      "P-body": "When you have a legacy text form field, the bookmark is really there to identify the field. If you try to write replace the text of the bookmark in VBA (say) you'll probably get Error 6028 - \"The range cannot be deleted\". .  I don't know Powershell well enough to do this without checking, but the equivalent VBA would be .  so I would guess the powershell is something like .  ",
      "P-tags": "form-field powershel bookmark ms-word",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "au_115864",
      "task": "how to make Samsung CLX-3185 scanner-part work?",
      "P-task": "make samsung clx-3185 scanner-part work",
      "F_verb": "make",
      "P-body": "Instructions how to set-up samsung CLX-3185FW. .  Source: baltas125@ubuntuforums. Originally taken from: bchemnet. .  From the 1st link:  .  After executing instructions I have successfully installed CLX-3185FW over the network. It prints and scans over the network. I have made it on Ubuntu 11.10, 32bit. .  Before installing you MUST REMOVE any other previously installed drivers for Samsung. .  Step 1 (edit sources): .  Add lines: .  Step 2 (install authentication key) : .  Step 3 (update sources): .  Step 4 (install packages): .  Open ubuntu software center and install one by one all packaged that start with \"samsungmfp-\", excepting: .   first install packages which do not have the word \"legacy\"; do not install packages which offer you to remove any other packages; Do not install \"samsungmfp-parallel\" it should only be installed if your printer is actually connected via a parallel port;  Step 5a (check if you are in lp group). Run in Terminal: .  If your account name is next to lp, everything is ok, else add yourself to lp group, e.g. execute Step 5b. .  Step 5b (add yourself into lp group if needed): .  (more information about groups here) .  That's it! Now you can search for your printer in network and add it as clx-3180 series and it will work. .  P.S. Previously I have made some changes to some files. But I do not know if it has any impact. If you have executed the five step above and still no luck, try making those changes: .  lines added .  In ... .  lines added:  .  In ... .  lines added: .  ",
      "P-tags": "scanner samsung",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_18410785",
      "task": "Bash script containing binary executable",
      "P-task": "bash script contain binari execut",
      "F_verb": "contain",
      "P-body": "i never done something like this before ;) this will compile some c source, create a \"b.bash\" script containing the binary (and the original script for simple development) .  (a.bash) .  invoke with (a.bash generates b.bash): .  i don't know how to evade writing out the binary into a temporary file before execution... .  ",
      "P-tags": "binari dump unix bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_46279052",
      "task": "Read parameters and stdin to same variable, keeping space",
      "P-task": "read paramet stdin variabl keep space",
      "F_verb": "keep",
      "P-body": "Your \"tmp\" is reading null-delimited records from standard input, but your test is sending whitespace-separate strings. Test with .  (This assumes a version of \"find\" that can output null-terminated file names.) .  Inside \"tmp\", you need to loop over the input to get each file, then quote \"$pipe\" as well when adding it to the array .  If you are using \"bash\" 4.4 or later, you can use \"readarray\" instead of a loop. .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP"
    },
    {
      "id": "ul_303701",
      "task": "How to create sha1 checksums of files inside a tar archive on busybox without using much disk space",
      "P-task": "creat sha1 checksum file insid tar archiv busybox without use much disk space",
      "F_verb": "create",
      "P-body": "Here are some major problems with this solution : .  1-The tar of busybox cannot show differently filenames with newlines. .  2-The \"read\" from shells does not handle backslash properly. \"\\\" characters are eaten or \"\\n\" is replaced by a new line character) .  3-Shell variables without double quotes eat repeated space characters. .  I cannot fix the problem 1. .  Any way, I can fix 2 and 3. .  Create this shell script : \"tarsha1.sh\" (don't forget \"chmod 755 tarsha1.sh\") .  Then use this command : .  With that you should be able to handle filenames with any characters but new lines (\"\\n\"). .  Note : \"-0\" option for xargs must be activated in busybox compilation options. .  ",
      "P-tags": "command-lin pipe checksum busybox tar",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP inside NP on NP without using NP"
    },
    {
      "id": "au_822213",
      "task": "Why doesn't my startup script to open a terminal work?",
      "P-task": "startup script open termin work",
      "F_verb": "open",
      "P-body": "The Main error in your script is that in your third statement you have actually commented out the command to open the terminal. Kindly remove the \"#\" from the third statement. Meanwhile you can simply use gnome-terminal to activate it but it should be run as user itself. So that means adding it to update-rc won't work either. If you are more lean to terminal ways, well you can add your script in crontab and add it to user's crontab file with reboot constrain. This will run your script at start up. So I sum up as follows : Your file named as script.sh : .  Make script excutable by user using following command. .  Now open up terminal and edit your user's crontab as follows : .  Add the following statement to the bottom of the file after making required changes accordingly. .  Now reboot. That's it. .  ",
      "P-tags": "script",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "ul_295777",
      "task": "apt-get remove removes unexpected packages",
      "P-task": "apt-get remov remov unexpect packag",
      "F_verb": "get",
      "P-body": "These are most likely outdated versions or programs you didn't explicitly install.  .  Since it blocks you from removing \"vlc\" as you requested, nothing would stop you from installing those you need after. It is usually very safe to say \"yes\" there. .  ",
      "P-tags": "apt",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "su_426451",
      "task": "How to find / list all unique files across two directories?",
      "P-task": "find list uniqu file across two directori",
      "F_verb": "find",
      "P-body": " ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP across NP"
    },
    {
      "id": "su_514628",
      "task": "How do I get the current date according to an NTP server without setting it locally?",
      "P-task": "get current date accord ntp server without set local",
      "F_verb": "get",
      "P-body": "This Perl script should do what you need (assuming you don't need precision to the 10-6 of a second): .  Save the script as check_ntp.pl and run it with the server as an argument: .  ",
      "P-tags": "ntp linux cento time-zon date",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP without S_ING"
    },
    {
      "id": "so_29862985",
      "task": "Python Mechanize Form submit",
      "P-task": "python mechan form submit",
      "F_verb": "submit",
      "P-body": "The form has a name, \"LoginForm\". So you should select it like so: .  Also the name of the first form field is \"login\" not \"loggInn\" so you use .  ",
      "P-tags": "mechan linux python form",
      "source": "qa",
      "cate": "commit/submit/upload",
      "pat": "V"
    },
    {
      "id": "au_1185813",
      "task": "How to fix: ubuntu 19.04 cannot upgrade to 19.10 error \"Your python3 install is corrupted. Please fix the '/usr/bin/python3'\"",
      "P-task": "fix : ubuntu 19 04 upgrad 19 10 error python3 instal corrupt\npleas fix usr bin python3",
      "F_verb": "fix",
      "P-body": "The issue is not with the \"/usr/bin/python3\" symlink, but with \"/usr/bin/python\" .  To correct, for 19.04, I ran  .  I found the solution here: \"Your python3 install is corrupted\" looking at the answer from J. B. Rainsberger .  ",
      "P-tags": "upgrad python 19 04 python3",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_1095262",
      "task": "Own made .desktop doesn't show at sidebar Ubuntu 16.04 LTS Unity",
      "P-task": "made desktop show sidebar ubuntu 16 04 lt uniti",
      "F_verb": "show",
      "P-body": "Try \"[Desktop Entry]\" rather than \"[Desktop entry]\". Also make sure the path is correct. .  ",
      "P-tags": "intellij desktop uniti unity-dash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V at NP"
    },
    {
      "id": "so_57710593",
      "task": "Function to test Windows activation",
      "P-task": "function test window activ",
      "F_verb": "test",
      "P-body": "Since you aren't inputting anything, you don't require any parameters. So you could just create a function to do what you already have an then return the string. Something like this: .  Then to get the output and put it into a variable to update your form, you could do: .  I hope this helps a little, I would warn against putting hard-coded values/paths in your scripts. You could have these as variables at the top of your script which get \"injection\" into the function using a parameter. Just a thought :)  .  ",
      "P-tags": "powershel script",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "so_67481308",
      "task": "I'm trying to come up with a shell script to rename a file and run a command each time the filename changes",
      "P-task": "tri come shell script renam file run command time filenam chang",
      "F_verb": "rename",
      "P-body": "You mean something like this? .  Perhaps it would make sense to copy \"a.txt\" in each iteration instead of successively renaming it, then remove the last file when you are done instead; that makes the script more robust against interruptions. .  ",
      "P-tags": "sh shell bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_42427009",
      "task": "How do I check if a Resource Group already exists in Azure?",
      "P-task": "check resourc group alreadi exist azur",
      "F_verb": "check",
      "P-body": "Well, I would suggest you implement something like a loop to check for the existence of resource group and change the name: .  the only downside is that the name would get concatenated, so you would have group354, and then group 354678, but this can be worked around with something like \"$name = $name -replace \".{3}$\"\", well you get the idea. .  ",
      "P-tags": "azur azure-powershel",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "ul_190925",
      "task": "Cannot start Tomcat 7 as Apache Commons Daemon",
      "P-task": "start tomcat 7 apach common daemon",
      "F_verb": "start",
      "P-body": "There's a typo in the jsvc command. I wrote: .  and not: .  I removed the unnecessary underscore and now it works. .  ",
      "P-tags": "tomcat debian java jdk",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP as NP"
    },
    {
      "id": "ul_577075",
      "task": "Can I find under which user is a service running via systemctl command?",
      "P-task": "find user servic run via systemctl command",
      "F_verb": "find",
      "P-body": "You can use \"systemctl show\" for this: .  If \"User\" shows nothing, and \"UID\" is \"[not set]\", the service is running as root, or the owning user in the case of a user service. .  ",
      "P-tags": "systemd",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP which S"
    },
    {
      "id": "so_69733319",
      "task": "Bash Script to Read File, Sort and Print Duplicate Records, and their Identity Number",
      "P-task": "bash script read file sort print duplic record ident number",
      "F_verb": "read",
      "P-body": "I have no idea why you want the duplicate lines twice and I do not understand what the line \"END OF ONE ID-NUMBER IN FILE\" is doing in the middle of the output. .  The following displays just the duplicates. .  If you really want to hard code the name of the input file, you can add the following line in the beginning: .  ",
      "P-tags": "file duplic script bash sort",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "so_35841973",
      "task": "Add Button to NotifyIcon",
      "P-task": "add button notifyicon",
      "F_verb": "add",
      "P-body": "This is just a wild guess, but try running the script in Single Thread Apartment mode: .  ",
      "P-tags": "powershel notifyicon contextmenu",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_45725414",
      "task": "\"Cannot open /var/log/sysstat/sa16 Please check if data collecting is enabled in /etc/default/sysstat\"",
      "P-task": "open var log sysstat sa16 pleas check data collect enabl etc default sysstat",
      "F_verb": "open",
      "P-body": "Try restarting the service and see the data collects or not .  ",
      "P-tags": "linux io unix sar",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "so_64559380",
      "task": "Why Yum package can be listed but not removed?",
      "P-task": "yum packag list remov",
      "F_verb": "remove",
      "P-body": "\"yum list\" lists all available packages, while \"yum list installed\" only lists installed packages. .  So you should try the command \"yum list installed | grep nvidia\". .  ",
      "P-tags": "cento linux yum",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V"
    },
    {
      "id": "so_33311104",
      "task": "Unix/Linux cat x y > y : is my understanding of the processing correct?",
      "P-task": "unix linux cat x : understand process correct",
      "F_verb": "correct",
      "P-body": "Yes, your existing understanding is correct. .  To look at the actual syscalls (from \"strace busybox cat x y >y\", to avoid the GNU version's attempts at detecting and terminating such loops): .  ...and the final two lines repeat ad infinitum. .  Not shown is the outer shell's \"open(\"y\", O_WRONLY|O_CREAT|O_TRUNC, 0666)\", done after the \"fork()\" to spawn the subprocess which then exec's cat but before \"cat\"'s actual execution -- and thus, before all of the above. .  Thus, we see exactly what you posited: Only a single line of \"xxx\"s is available for read until cat performs a write, at which point additional content is immediately available for read, so the loop proceeds. .  ",
      "P-tags": "linux cat io-redirect unix",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "au_127284",
      "task": "Command to launch an application or to show its window if already launched",
      "P-task": "command launch applic show window alreadi launch",
      "F_verb": "show",
      "P-body": "To launch an application or to show its window if already launched or to minimize if it is focused  .  1) Install wmctrl: \"sudo apt-get install wmctrl\"  .  2) Install xdotool: \"sudo apt-get install xdotool\"  .  3) Make a script:  .   Make a file \"gedit ~/.focusshortcut\"  And paste this:    Make it executable: \"chmod +x ~/.focusshortcut\"   3) Make your shortcut point to /home/\"<user>\"/.focusshortcut app_to_show  .  4) Enjoy ;-)  .  ",
      "P-tags": "shortcut-key",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP if S"
    },
    {
      "id": "so_26740105",
      "task": "How to change directory under git bash",
      "P-task": "chang directori git bash",
      "F_verb": "change",
      "P-body": "\"cd\" gets just one argument, so if you say \"cd Program Files\" it does \"cd Program\". So you need to quote \"Program Files\" if you want \"cd\" to it as just one argument: .  otherwise it is trying to find the directory \"Program\". .  ",
      "P-tags": "git window command-lin bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP under NP"
    },
    {
      "id": "so_21726862",
      "task": "How to find files containing newlines in their names",
      "P-task": "find file contain newlin name",
      "F_verb": "find",
      "P-body": "To find all file and directories that have new line in them, you can use this POSIX-compatible call to \"find\": .  where a literal newline is embedded in the single quotes. \"bash\" supports additional syntax to specify a newline: .  OR little less clumsy: .  Or using \"-regex\": .  ",
      "P-tags": "linux regex find bash gnu-findutil",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_31139737",
      "task": "How to grep for exact hexadecimal value of characters",
      "P-task": "grep exact hexadecim valu charact",
      "F_verb": "grep",
      "P-body": "Since you're using \"-P\", you're probably using GNU grep, because that is a GNU grep extension. Your command works using GNU grep 2.21 with pcre 8.37 and a UTF-8 locale, however there have been bugs in the past with multi-byte characters and character ranges. You're probably using an older version, or it is possible that your locale is set to one that uses single-byte characters. .  If you don't want to upgrade, it is possible to match this character range by matching individual bytes, which should work in older versions. You would need to convert the characters to bytes and search for the byte values. Assuming UTF-8, U+00B9 is C2 B9 and U+00BF is C2 BF. Setting \"LC_CTYPE\" to something that uses single-byte characters (like \"C\") will ensure that it will match individual bytes even in versions that correctly support multi-byte characters. .  ",
      "P-tags": "script grep unix bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V for NP of NP"
    },
    {
      "id": "so_61806571",
      "task": "Code review requested: PowerShell executing multiple times against local PC instead of the desired remote PCs in $inventory",
      "P-task": "code review request : powershel execut multipl time local pc instead desir remot pc inventori",
      "F_verb": "execute",
      "P-body": "That is because you are simply running the same code based on the number of items in $inventory. You aren't actually inputting the computer names anywhere. .  Add the \"-ComputerName\" parameter with the current item and it should work as expected: .  ",
      "P-tags": "powershel foreach loop variabl",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP against NP of NP in NP"
    },
    {
      "id": "au_946016",
      "task": "Keyboard shortcut to change font color in Libreoffice to a specific color",
      "P-task": "keyboard shortcut chang font color libreoffic specif color",
      "F_verb": "change",
      "P-body": "Muru's suggestion is close, but use Character styles, not Paragraph styles. .   Press F11 and click the icon for \"Character styles\". Right-click \"Default Style\" and select \"New...\" Change the font color to red. In the Organizer, name the font color \"Red\", then press OK. Tools -> Customize, select the \"Keyboard\" tab. Find Alt+R and select it. Under \"Categories\", choose Styles / Character. Under \"Function\", select \"Red\". Then click the \"Modify\" button. .   .  The \"Default Style\" Character Style is already black, so assign it to Alt+B. Then press OK. .  Finally, select words and press Alt+R. .   .   ",
      "P-tags": "shortcut-key libreoffic",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP to NP"
    }
  ],
  "9": [
    {
      "id": "so_36069556",
      "task": "Compare-Object Output Format",
      "P-task": "compare-object output format",
      "F_verb": "compare",
      "P-body": "If you include a \"format-table -wrap\" in your last line, like so? .  ",
      "P-tags": "powershel compareobject compar",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "au_741672",
      "task": "How do I merge my /boot partition to be a part of the / partition?",
      "P-task": "merg boot partit part partit",
      "F_verb": "merge",
      "P-body": "Short answer: If it ain't broke, don't fix it. .  Long answer: If you insist on fixing what ain't broke: .   Open a Terminal window. Type \"sudo mkdir /boot2\" Type \"sudo cp -a /boot/* /boot2/\" Type \"sudo umount /boot\" Type \"sudo rmdir /boot\" Type \"sudo mv /boot2 /boot\" Edit \"/etc/fstab\" and comment out the line that defines the mount point for \"/boot\". Type \"sudo grub-install\" Type \"sudo update-grub\" (if you're using a BIOS-based install, you'll also need to specify a device filename -- probably \"/dev/sda\") Optionally delete the \"/boot\" partition and resize the root (\"/\") partition. See here for details on how to do this.  I have not tested this procedure! If I've forgotten something or if there's an unexpected error, your system will be rendered unbootable! Hence: .   Please reconsider my \"short answer,\" above.  ",
      "P-tags": "partit",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP of NP"
    },
    {
      "id": "so_42921274",
      "task": "Docker linux: How to start multiple console/terminals for one running container?",
      "P-task": "docker linux : start multipl consol termin one run contain",
      "F_verb": "start",
      "P-body": "Once the container is running, you should be able to use \"docker exec\" to run an additional Bash session in the same container. .  When your first container is running, use \"docker ps\" to find its Container ID (the first column in the \"docker ps\" output), e.g. \"4a7afcdeb729\", then run the following: .  This should open a new terminal session in the container. .  ",
      "P-tags": "termin linux consol docker",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_423687",
      "task": "Remove rows which contain duplicate strings between the first 4 characters of two columns",
      "P-task": "remov row contain duplic string first 4 charact two column",
      "F_verb": "remove",
      "P-body": "To print lines where the first 4 characters of column 2 are not equal to the first 4 characters of column 4: .  This uses the main code as a \"test\" to see whether a line should be printed; there's no explicit action section, since the default-print action is what we want. The main code simply extracts the first four characters from each column and compares them. .  ",
      "P-tags": "bioinformat text-process",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP which S"
    },
    {
      "id": "ul_656117",
      "task": "Redirect rtsp video stream from Ethernet to WiFi network within same device",
      "P-task": "redirect rtsp video stream ethernet wifi network within devic",
      "F_verb": "redirect",
      "P-body": "Here are a few suggestions on how to configure your Yocto system. You'll have to research more thoroughly on each topic. All of them have advantages and drawbacks, but I'd suggest the last one (NAT). .   Set as bridge .  As the Linux system is an AP, it's perfectly possible to bridge the Ethernet interface and the Wifi interface together. Specific method requires configuring hostapd properly to use a bridge. Some pointers here and there. .  You'd probably have to configure (manually at build time or using DHCP) the camera to use 192.168.42.1 this time, but the Yocto system should still have an (other) IP address in 192.168.42.0/24 because it still requires a DHCP server. .  So it would still expose the dual nature of the board. There are probably methods to keep the Yocto system completely transparent and still provide DHCP (appearing from 192.168.42.1) but that's something that would be complex to do. .   Set as router .  You must enable IP forwarding. .   With the camera system visible .  It means you must publish the route to the camera with DHCP, but not as default route. End users would not appreciate losing Internet to use the Camera because of a new default route. To publish specific routes with DHCP you need both of these features at the same time: .   DHCP Classless Route Option 121 .  that's the RFC Standards Track option .   the non-standard Microsoft DHCP Option 249 .  or older Windows systems won't get it .    The configuration depends on the DHCP server used in the system. It's probably Kea, which doesn't have built-in support for these options but can handle any arbitrary option as described there (this requires good understanding of the option from RFC). .  And you must not forget to have the Camera configured with a default route through 192.168.30.34 (manually or DHCP, not requiring options above). .  But it might not be interesting to do so because: .   relies on complex DHCP options and a 2nd network that has a new chance to clash with user's own network setup. still exposes the existence of a dual system in the board   Or Camera hidden behind NAT .  By using as ALG the external (ie: not mainstream) Linux kernel module \"nf_nat_rtsp\" provided by the project rtsp-linux (and for example packaged in Debian as nat-rtsp-dkms) along adequate NAT rules similar to: .  and adequate helper module configuration as described in this blog: Secure use of iptables and connection tracking helpers, or simply re-enabling back the \"unsecure\" method after pondering about any security consideration: .  Summary: .   avoids a complex DHCP configuration and avoid exposing the (fact that there is a) second system in the board .   Camera doesn't even need a default route if double NAT is done: .   requires a kernel module, thus kernel module support if it wasn't enabled before in the embedded system. .   RTSP compatibility of the module should be verified .        ",
      "P-tags": "bridg port-forward network stream",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP from NP to NP within NP"
    },
    {
      "id": "su_1325715",
      "task": "Kernel Compilation: Force all modules to be baked in",
      "P-task": "kernel compil : forc modul bake",
      "F_verb": "force",
      "P-body": "If you do this all 3000+ modules will be built and embeded into your kernel. Your kernel will be massively oversized. .  This is a terrible idea, but: .  You need to have the kernel source on the device in question temporarily. Once you do a make localmodconfig you can copy the .config file to another machine, if you want, and compile it there. .  What you should do is: .   make localmodconfig .   Then edit the config file .  .config .  and do a search and replace for m replacing it with y .  Now you will only have about 110 modules, and it will boot faster, and not be massively oversized. .  ",
      "P-tags": "linux compil linux-kernel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_6651120",
      "task": "How do you hide a Powershell progress message?",
      "P-task": "hide powershel progress messag",
      "F_verb": "hide",
      "P-body": "You could stop the progress bar appearing in the first place by doing the following beforehand: .  You could then restore the preference to \"Continue\" afterwards. Not much help if you actually want the bar of course... .  ",
      "P-tags": "powershel sharepoint-2010",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V NP"
    },
    {
      "id": "ul_175214",
      "task": "How to change date format and position in find output",
      "P-task": "chang date format posit find output",
      "F_verb": "change",
      "P-body": "You could do this: .  Putting \".8\" between \"%\" and \"TT\" modifies that field to limit it to 8 characters (\"hh:mm:ss\"). The \"sed\" regex moves the first part of the line (to sets of non-space characters with one space between) to the end of the line. It's necessary for the time to be at the beginning of the line for the \"sort\" command. .  Warning: Putting the date after the file name could potentially cause confusion if filenames are displayed that contain spaces and numbers. However, for viewing as a human rather that for feeding into another script or program, this output should be fine. .  Otherwise, to leave the times in front of the filenames: .  EDIT: \"sed\" is unnecessary for trimming fractional second per @steeldriver's comment. This may be a GNU extension, but \"-printf\" doesn't appear to be POSIX anyway. Also, corrected sorting bug. .  ",
      "P-tags": "script find",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "su_803872",
      "task": "Getting External IP via PowerShell",
      "P-task": "get extern ip via powershel",
      "F_verb": "get",
      "P-body": "You already have your answer. You just want to get rid of the additional line\u2014nothing is forcing you to use .  as is. Instead, you could use this: .  The String.Trim method \u201cremoves all leading and trailing white-space characters from the current String object.\u201d .  ",
      "P-tags": "ip-address powershel network",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP via NP"
    },
    {
      "id": "su_409018",
      "task": "Parse and remove parts of strings between delimiters",
      "P-task": "pars remov part string delimit",
      "F_verb": "parse",
      "P-body": "Simplest way to do it is using \"awk\". .  \"awk\" reads the file line by line, sets some special variables and runs the command for each line. \"$1\" and \"$5\" here contain first and fifth string when a line is tokenized by using space as delimeter. .  ",
      "P-tags": "sed cygwin shell regex",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP of NP between NP"
    },
    {
      "id": "so_32110118",
      "task": "Replace files in a folder with files in other folder, using powershell",
      "P-task": "replac file folder file folder use powershel",
      "F_verb": "replace",
      "P-body": "Sorry, I am posting the answer late. but here it is !! .  so, 1. Folder1 is named $original 2. Folder2 is named $hotfix .  This replces all the common files of $original and $hotfix with the files in $hotfix !  .  ",
      "P-tags": "powershel powershell-is powershell-2 0",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP in NP"
    },
    {
      "id": "ul_411837",
      "task": "Why does this cron job run?",
      "P-task": "cron job run",
      "F_verb": "run",
      "P-body": "The reason can be found in \"crontab(5)\": .   Commands are executed by cron(8) when the minute, hour, and month of year fields match the current time, and when at least one of the two day fields (day of month, or day of week) match the current time. .   (Emphasis added) .  I believe you want your script to run at the specified time from 1-18 December, but only from Monday to Thursday. As you can see from the manual page, \"cron\" doesn't do this when you specify both day of the month and day of the week. Your command will execute on every day from 1-18 December and on any day from Monday to Thursday in December. December 19, 2017 is a Tuesday, hence the script running. .  Note: the above applies to ISC cron, the default on Debian systems. .  ",
      "P-tags": "cron",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_27259413",
      "task": "Comparing contents of two csv in Unix",
      "P-task": "compar content two csv unix",
      "F_verb": "compare",
      "P-body": "First you need to order your files. .  In the second file, I removed the date, because is not necessary in the output. .  Join the files, keeping unpairable lines from file 1 \"-a1\". The results concatenate fields from both files, so we only want fields 2 and 4 (\"cut\") and then sort the output. .  Add the string \", FAIL\" to the lines that does not contain \"SUCCESS\". .  Join again and you have it. .  ",
      "P-tags": "command-lin unix bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_44762880",
      "task": "How to generated a timestamp based on another formatted timestamp",
      "P-task": "gener timestamp base anoth format timestamp",
      "F_verb": "generate",
      "P-body": "Instead of using the \"-Format\" parameter of \"Get-Date\", use the \".ToString\" method on the date objects you create instead: .  Explanation: .   Get-Date is executed and returns a DateTime object representing the current date and time with the seconds set to 0. This is then cast to a string using the .ToString method to format per your custom style. The next command is the same, but before casting it as a formatted string (whereby it loses the date object methods), the \".AddMinutes\" method is used to remove 30 minutes.  ",
      "P-tags": "powershel datetim",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP"
    },
    {
      "id": "so_60336790",
      "task": "Cannot run ElasticSearch-7.5.0 on Linux(SUSE)",
      "P-task": "run elasticsearch-7 5 0 linux suse",
      "F_verb": "run",
      "P-body": "The latest version of elasticsearch is not compatible with older version of Java and more details on the generic error \"Unsupported major.minor version 51.0\" can be found here.  .  Also as mentioned in this official ES doc, ES will not start if compatible version of JVM isn't found. .   Elasticsearch will refuse to start if a known-bad version of Java is used. The bundled JVM directory may be removed when using your own JVM. .   And the entire supported version of JVM with a different version of elasticsearch can be found in this officially supported matrix link. .  Going through your error message, it is clear that you are using 1.7 JDK version which uses \"51\" as a major version as mention in this SO answer. and if you check the above-supported matrix, on or after ES 5.X there isn't any support for less than JDK 1.8 version. .  Hence you need to point your JDK to 1.8 version as its already installed in your system but not being used and there are a plethora of documents available on how to do it and after that, you should be able to start ES.  .  ",
      "P-tags": "linux elasticsearch suse",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "au_490991",
      "task": "The trash launcher opens an Internet browser",
      "P-task": "trash launcher open internet browser",
      "F_verb": "open",
      "P-body": "Trying creating trash.desktop in \"/usr/share/applications/\" .  The following is your standard .desktop file. .   .  Once the trash.desktop file has been created. Restart Ubuntu and search your previously given \"Name=\" value from the Unity Launcher. .   .  If you would like the Icon in the Launcher, simply click & drag from your search results icon to your Launcher. .  ",
      "P-tags": "12 04 launcher trash",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "ul_305667",
      "task": "Trying to use awk to make ls show non-directories",
      "P-task": "tri use awk make ls show non-directori",
      "F_verb": "use",
      "P-body": "\"!=\" is just a string comparison (or number comparison depending on what is being compared) operator. For string comparison (\"A != B\"), depending on the \"awk\" implementation, it's either a byte to byte comparison, or for some (as required by POSIX), it's short for \"A < B || A > B\", that is \"A != B\" tests whether \"A\" and \"B\" sort differently. .  In any case, it is not a pattern matching operator. For that you have the \"~\" operator (negated with \"!~\"), though that's for regular expression matching, not wildcard pattern matching. You'd need: .  Though here, you might as well use: .  With \"$1 != \"d*\"\", that would return true for anything except a first field that is (or sorts the same as with some \"awk\" implementaions) \"d*\". \"d*\" as a regexp matches any number (including 0) of \"d\", so \"$1 !~ \"d*\"\" would always return \"false\" as any string would contain at the very least 0 \"d\"s. .  ",
      "P-tags": "awk wildcard",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "ul_437543",
      "task": "regex question - to match a string when not equal to",
      "P-task": "regex question - match string equal",
      "F_verb": "match",
      "P-body": "Based on your pattern and answer from https://stackoverflow.com/questions/1971738/regex-for-all-strings-not-containing-a-string: the following pattern work in my editor: \"^[0-9]{9}_(010020).*(?<!004)-[0-9,a-z,A-Z]+_[0-9]{8}_[0-9]{4}\" .  I think there is an extra underscore in your pattern after the '+' sign. And we have to match the last 3 character before checking they are not \"004\"). .  Depending on the exact formatting you might want to ensure we are only matching 3 digits: \"^[0-9]{9}_(010020)([0-9]*(?<!004)){3}-[0-9,a-z,A-Z]+_[0-9]{8}_[0-9]{4}\" .  ",
      "P-tags": "regular-express",
      "source": "qa",
      "cate": "match",
      "pat": "V NP when S"
    },
    {
      "id": "au_124943",
      "task": "How retrieve files in a minimal ubuntu installation? aka how apt-get retrieves files?",
      "P-task": "retriev file minim ubuntu instal\naka apt-get retriev file",
      "F_verb": "retrieve",
      "P-body": "\"apt-get\" uses a library, which you probably cannot use yourself since a minimal system likely does not include a compiler that you could use to build a program using that library. Perhaps you should use \"apt-get\" to install \"wget\" or \"curl\". .  ",
      "P-tags": "apt wget network",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "au_1105976",
      "task": "Keyboard shortcut to bring up System Monitor",
      "P-task": "keyboard shortcut bring system monitor",
      "F_verb": "bring",
      "P-body": "The command you need If you already found out how to set a custom shortcut: the command you need to set is: .  How to find out the command To find a command like that is often easy: .   Open the application Open a terminal, type \"xprop\", click on the application's window. In the terminal output that appears, look for a line like: .  ...and there we are, often the lower case version is the command to run the application. There are a few other ways though. One is to look into the corresponding \".desktop\" file in \"/usr/share/applications\" and see what (the first) \"Exec=\" -line sais.  .   ",
      "P-tags": "shortcut keyboard",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V up NP"
    },
    {
      "id": "ul_183608",
      "task": "Why did sshd delete my /dev/zero?",
      "P-task": "sshd delet dev zero",
      "F_verb": "delete",
      "P-body": "\"DEL\" doesn't indicate that that process deleted \"/dev/zero\", but that that process is using \"/dev/zero\" and the instance of \"/dev/zero\" that was being used has since been deleted. For example, if I have a command (say \"some-command\") that uses \"/some/file\" and I do: .  Then \"lsof\" for \"/some/file\" would look like: .  The contents of the deleted file continue to remain on disk until the process lets go or is killed, but won't be directly accessible. .  The version of \"/some/file\" that I created using \"touch\" is not the one that \"some-command\" is using. .  ",
      "P-tags": "sshd arch-linux linux file-descriptor devic",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_31690700",
      "task": "Find file case insensitively on unix",
      "P-task": "find file case insensit unix",
      "F_verb": "find",
      "P-body": "You started with a ls (looking in the current dir only). The simple form without checking the numbers would be .  You can also use regular expressions with .  When you use regex, the * is not a normal wildcard: Looking for files starting with an \"a\" and ending with [0-9], do not use .  but use .  ",
      "P-tags": "awk ksh shell bash sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_308708",
      "task": "Move a window to another computer",
      "P-task": "move window anoth comput",
      "F_verb": "move",
      "P-body": "As Dave says, \"xpra\" is ideal for this. You need to start an \"xpra\" session on the system where your application will be run (not displayed): .  (\"20\" must be a free X display number \u2014 I usually start at 20, that leaves room for multiple local X servers and incoming forwarded X sessions using SSH.) .  Then you start your application on display 20: .  To display your application, you attach to it with \"xpra\": .  You can do this over SSH too: .  You can run multiple applications in one \"xpra\" session. \"xpra\" offers tons of possibilities, including forwarding PulseAudio, sharing the clipboard, forwarding files... .  By default, attaching from one machine detaches the session from any others, so you don't need to remember to detach. .  ",
      "P-tags": "window network window-manag x11",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_388627",
      "task": "How to loop through files whose names contain vertical lines and spaces in bash",
      "P-task": "loop file whose name contain vertic line space bash",
      "F_verb": "contain",
      "P-body": " There is nothing on that line that would have any sort of problems with filenames containing combinations of spaces and/or pipes in their names: .  Notice too that depending on what you'd like to do with the found names, it almost always better to do that with an \"-exec\" from within \"find\" itself: .  Related answer to another question: Why does my shell script choke on whitespace or other special characters? (see especially \"How do I process files found by find?\" in that answer). .  ",
      "P-tags": "file bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1316313",
      "task": "How to get munin to monitor and show CPU temperatures",
      "P-task": "get munin monitor show cpu temperatur",
      "F_verb": "get",
      "P-body": "Found the solution. Answer for the benefit of future users. .  Make sure plugin output matches supported regexes Looking at the plugin implementation: \"/usr/share/munin/plugins/sensors_\" I noticed that the plugin has detailed regexes in a global hash called \"%config\". There are 4 supported sensor categories: .   fan (Fan speeds in RPM) temp (Temperature in Celsius) volt (Voltage in Volts) power (Power in Watts)  Since the regexes are very specific, it is important to make sure that the output of the \"sensors\" command-line utility, matches these regexes exactly. You cannot call \"sensors -u\" when the \"munin\" plugin expects output in the format generated by \"sensors\" (without the \"-u\" option). .  Make sure symlink name matches a \"sensors\" category The name of the symlink from \"/etc/munin/plugins\" to \"/usr/share/munin/plugins/sensors_\" must match a supported category. The category name is used as the \"%config\" key which defines each regex. Extensions like \"fan\" or \"temp\", which match a supported category are good: .  But using \"tmp\" or \"cpu_temp\" instead of \"temp\" will not work. .  Restart the \"munin-node\" service Another detail that I missed, was the need to restart the \"munin-node\" service after every change in configuration or adding a plugin symlink: .  Remove empty charts of unsupported/missing devices If you see empty graphs for non-existent devices. It is also recommended to remove reports on non-exiting devices: .  Result Now \"munin\" shows my CPU temperatures: .   .  ",
      "P-tags": "cpu monitor temperatur munin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_22538859",
      "task": "Preserving leading whitespace when reading a file in bash",
      "P-task": "preserv lead whitespac read file bash",
      "F_verb": "preserve",
      "P-body": "You need to specify the empty string for \"IFS\" so that \"read\" doesn't discard leading or trailing whitespace: .  ",
      "P-tags": "pars bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP when S"
    },
    {
      "id": "so_58402949",
      "task": "How to capture an output text value in variable in bash",
      "P-task": "captur output text valu variabl bash",
      "F_verb": "capture",
      "P-body": "It is better to add \"\"Name=instance-state-name,Values=running\"\" clause in \"filters\" to make sure you get a running instance only so your \"aws\" command would be: .  Now to store output IP in a variable, you can use command substitution: .  Then to use it: .  ",
      "P-tags": "amazon-ec2 amazon-web-servic ansibl bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP in NP"
    },
    {
      "id": "so_60662240",
      "task": "Is it possible to get the latest GitHub release built from a specific branch?",
      "P-task": "possibl get latest github releas built specif branch",
      "F_verb": "get",
      "P-body": "The releases API call returned 404 because I forgot to specify the access token: .  It doesn't seem possible to do what I am asking through the API, but I was able to do it using PowerShell: .  Since my release names were prefixed with the branch they were created from. .  ",
      "P-tags": "powershel github-api",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_26184982",
      "task": "trigger a .sh script when a specific subject email is received",
      "P-task": "trigger sh script specif subject email receiv",
      "F_verb": "trigger",
      "P-body": "You can't instruct gmail to trigger an external script for you. I think you've got a few basic choices. In order of increasing difficulty and complexity: .  1) Configure a gmail filter to deliver your desired messages to a special folder. Write a script to poll that folder, download (or delete or mark as read) messages it finds there, and then launch your local script. Set up a cron on your local machine to run the script every few minutes. You can poll the folder with IMAP or the GMAIL API. IMAP is probably easier. This will be tricky with shell, you're better of with Python, PHP, or similar. .  2) Configure a gmail filter to forward your desired messages to an address on a mail server that you control. Use \"procmail\" or similar to intercept the incoming messages and launch your script. .  3) Set up an account at \"Mailgun\" and configure the emails so they get delivered there directly. Or forward from gmail as in #2.) Configure Mailgun to launch an API request when it receives messages. Build an API handler to receive the request. Launch your process from your API handler. .  ",
      "P-tags": "linux shell email",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "so_45287924",
      "task": "Error applying chroot to group (groupmod: group 'www' does not exist)",
      "P-task": "error appli chroot group groupmod : group www exist",
      "F_verb": "apply",
      "P-body": "That is not what \"groupmod -R\" does. What it means is that the \"groupmod\" program will \"chroot\" into the directory, and then do everything. It\u2019s intended for when you have one system mounted inside another, such as if you booted from a live USB drive to make changes to a broken system. .  Once \"groupmod\" has run \"chroot\", it looks in the \"/var/www/etc/group\" file to figure out what group ID \"www\" corresponds to, which of course fails because if your system is at all sanely set up you don\u2019t have a \"var/www/etc/group\" file. .  I do not know how to make sure all processes by a specific user run in a \"chroot\", and I don\u2019t think that\u2019s the right way to achieve your goal. If a program is \"chroot\"ed into \"/var/www\", it doesn\u2019t have access to any of the utilities it might expect, like the web server executable. Instead, I would look at the documentation of your web server and see if it supports this directly, or see if you can get a custom mount namespace using systemd. .  ",
      "P-tags": "linux fedora bash",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP to NP"
    },
    {
      "id": "so_30905925",
      "task": "Remove tracked file from Git when file has $$ in name",
      "P-task": "remov track file git file name",
      "F_verb": "remove",
      "P-body": "This is a shell specific problem rather than a git problem. Assuming that your shell is Bash, use single quotes instead, since no variable substitution takes place inside them: .  ",
      "P-tags": "git bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP when S"
    },
    {
      "id": "ul_24931",
      "task": "How to make firefox read stdin?",
      "P-task": "make firefox read stdin",
      "F_verb": "make",
      "P-body": "The short answer is, you're better off writing a temporary file and opening that. Getting pipes to work properly is more complicated and probably won't give you any extra advantages. That said, here's what I've found. .  If your \"firefox\" command is actually starting Firefox instead of talking with an already-running Firefox instance, you can do this: .  Which tells Firefox explicitly to read its standard input, which is where the pipe is putting its data. But if Firefox is already running, the \"firefox\" command is just going to pass that name to the main Firefox process, which will read its own standard input, which probably won't give it anything and certainly isn't connected to your pipe. .  Furthermore, when reading from a pipe, Firefox buffers things pretty heavily, so it's not going to update the page each time you give it a new line of HTML, if that's what you're going for. Try closing Firefox and running: .  (N.B. you do actually need the \"cat\" here.) Paste some long lines into your shell window repeatedly until Firefox decides to update the page, and you can see how much data it takes. Now send an End-Of-File signal by hitting Ctrl+D on a new line, and watch Firefox update instantly. But then you can't add any more data. .  So best is probably: .  ",
      "P-tags": "firefox",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "ul_31443",
      "task": "Finding the best working driver for a video card",
      "P-task": "find best work driver video card",
      "F_verb": "find",
      "P-body": "You probably want the nVidia driver with GLX. Depending on your distribution, it is probably packaged either as \"nvidia-glx-new\", \"nvidia-glx\" (note: on Ubuntu, out of the two you probably want \"nvidia-glx-new\") or \"nvidia\". Bear in mind that this driver is proprietary software. .  ",
      "P-tags": "driver graphic",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP for NP"
    },
    {
      "id": "so_30962676",
      "task": "How to retrieve the missing file sources.list in Ubuntu 14.04?",
      "P-task": "retriev miss file sourc list ubuntu 14 04",
      "F_verb": "retrieve",
      "P-body": "Just rename \"sources.list.save\" to \"sources.list\" . \"sources.list.save\" is a backup file for \"sources.list\". If the \"sources.list\" file got deleted accidentally, you may use the contents inside the \"sources.list.save\" file but the file name must be \"sources.list\" so that Ubuntu would take this file. .  ",
      "P-tags": "apt linux ubuntu file list",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_59827671",
      "task": "serverless powershell script on azure to return html to show in browser",
      "P-task": "serverless powershel script azur return html show browser",
      "F_verb": "return",
      "P-body": "The problem seemed to be the header .  I changed headers from  .  to  .  and now it displays correctly, thank to @John Hanley for mentioning 'validation' as validator.w3.org was complaining about the header refusing to parse the document  .  ",
      "P-tags": "azur powershel serverless html",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF in NP"
    },
    {
      "id": "so_24316857",
      "task": "Reading Multiple files in a while loop in bash, where one file is multicolumn",
      "P-task": "read multipl file loop bash one file multicolumn",
      "F_verb": "read",
      "P-body": "You could do something like this if you want to name all the fields individually: .  or you can read all the fields into an array .  or you can read fields from corresponding lines into separate arrays .  or, I'm sure there are many other possibilities. .  ",
      "P-tags": "while-loop file-io bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP where S"
    },
    {
      "id": "so_69856234",
      "task": "Write script for GitLab for automatic merge of Merge Request",
      "P-task": "write script gitlab automat merg merg request",
      "F_verb": "write",
      "P-body": "With the \"python-gitlab\" library, a python script makes this task a lot simpler to script, especially when it comes to pagination. .  Additionally, you can use the Group merge requests API as a shortcut instead of listing all projects in the group then listing all merge requests in each project. .  With a Python script, it might look something like this: .  So, if you input the correct constants and complete the implementation of the \"mr_meets_merge_criteria\" function, that should be all that is needed :-) .  ",
      "P-tags": "python shell gitlab-ci rest gitlab",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP for NP for NP"
    },
    {
      "id": "so_21258942",
      "task": "How to split a string into several lines while keeping a prefix?",
      "P-task": "split string sever line keep prefix",
      "F_verb": "split",
      "P-body": "This can be a way: .  Explanation  \"BEGIN{FS=OFS=\" \"}\" is optional. \"a=$1 OFS $2 OFS $3\" store the three first values in the \"a\" variable. The \"OFS\" is used so that you can specifiy another Output Field Separator in the \"BEGIN{}\" block and will apply to everything your print. \"for (i=4; i<NF; i+=2) print a,$i,$(i+1)\" print in blocks of two: the three initial values + a pair of key-value values. \"a=\"\"\" empty the variable.  Checking ",
      "P-tags": "awk string split shell",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP into NP while S"
    },
    {
      "id": "so_52056593",
      "task": "Find directories containing only zero-sized files",
      "P-task": "find directori contain zero-s file",
      "F_verb": "find",
      "P-body": "Probably not the most efficient (one invocation of \"find\" per sub-directory, plus one more to find all sub-directories) but this should work: .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_156042",
      "task": "resetting keys changed by xmodmap",
      "P-task": "reset key chang xmodmap",
      "F_verb": "reset",
      "P-body": "You can try: .  to get a clean start if things are wrong now. You can also save the state of a (still correct) mapping with \"xmodmap -pke > filename\" and use \"filename\" as input for everything to reset. .  BTW:  .  should give you the \u20ac sign on Right-Alt+5 .  ",
      "P-tags": "xmodmap linux",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP by NP"
    },
    {
      "id": "au_789829",
      "task": "Find details of click and keyboard events",
      "P-task": "find detail click keyboard event",
      "F_verb": "find",
      "P-body": "You could use the \"xinput --test-xi2 --root\" command (man xinput), where \"test-xi2\" means logging input devices, and \"--root\" is to log from so called root window (a x11 specific concept). It would show you when and which key pressed in the system, mouse clicks, and even mouse motion coordinates. It solves your \"1\" and \"3\" points, you just need to parse these events. .  The \"2\" point is trickier. You can use \"xev -root\" command which would monitor all X events in the system, including things like (dis) appearing windows, entering/exiting focus of a particular window, etc. You have to parse its output, and show a human-readable description of what is happening. Btw, the command logs pressed keys also. .  A caveat: it is, obviously, a great security hole, which dates back to times when Xorg was created, and nobody needed to care. For this reason nowadays X11 is being replaced with the Wayland protocol (it is in the essence a X12, but as not backward compatible, the protocol land called another way), which WMs are implementing ATM. It isn't quick process as the protocol demands much more from WM, but Fedora 25 seem to finally have Wayland session enabled by default. KWin is also catching up. And your script not going to work on Wayland. This doesn't mean you can't do it \u2014 I think, you can. But you'd need to work closely with a particular WM of a particular DE, and the script would be not a stand alone bash script, but rather an addon to a WM. .  ",
      "P-tags": "mous keyboard xorg",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "su_1070931",
      "task": "Execute SSH port forwarding along with the browser",
      "P-task": "execut ssh port forward along browser",
      "F_verb": "execute",
      "P-body": "openSSH supports \"LocalCommand\", which can be used for this, just other way round than you describe. You run \"ssh-forward\" and as soon as it will be connected, the browser will start. It can work like this: .  of course addjust the ports and host. .  This can be also put into the \"~/.ssh/config\" to shorten the command itself: .  and then run just .  which will bring up the proxy and the browser. You can simply store this command in your \"shortcut\". .  ",
      "P-tags": "linux port-forward ssh bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "au_1157219",
      "task": "Removing jdk 11 to jdk 8",
      "P-task": "remov jdk 11 jdk 8",
      "F_verb": "remove",
      "P-body": "I know how :)  .  Uninstall Java first (choose one of these three) : you can type the following into your terminal : .  if this is not a removable package (although it should be since that's what you installed) then run this instead : .  if this is still not it then this must be it :  .  Then reinstall the Java version you want : there java 8 jdk is now installed. .  it now no longer possible (at all, to my knowledge, please correct me if not) to install oracle's version of java 8 (and especially not 9) jdk on ubuntu. .  ",
      "P-tags": "openjdk java jdk",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP to NP"
    },
    {
      "id": "so_66887378",
      "task": "Git hooks - how to handle only files that belong to specific folder inside repo?",
      "P-task": "git hook - handl file belong specif folder insid repo",
      "F_verb": "handle",
      "P-body": "The \"post-receive\" hook will be fed old reference, new reference and a branch reference on stdin. Since multiple branches can be pushed, we'll look for the one we are interested in. Then we can use \"git diff-tree\" to list the files that are being pushed on that branch. The glob expression, \"$deploy_dir/*\", will only list files going to the deploy directory. .  ",
      "P-tags": "git hook bash",
      "source": "qa",
      "cate": "handle/process/preprocess",
      "pat": "V NP that S"
    },
    {
      "id": "au_1281658",
      "task": "Cannot grep apt-cache show output",
      "P-task": "grep apt-cach show output",
      "F_verb": "grep",
      "P-body": "As per \"apt-cache\" man-page .   \"-q, --quiet\" Quiet; produces output suitable for logging, omitting progress indicators. More \"q\"'s will produce more quietness up to a maximum of 2. You can also use \"-q=#\" to set the quietness level, overriding the configuration file. Configuration Item: \"quiet\". .   you have to pass \"--quiet=0\" to use \"apt-cache\" in scripts. .  Use code below: .  or .  ",
      "P-tags": "18 04 16 04 apt-cach",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_57865670",
      "task": "Overlayfs: restore removed or changed file from \"lower\"",
      "P-task": "overlayf : restor remov chang file lower",
      "F_verb": "change",
      "P-body": "Remove file from \"/overlay/upper\", and then remount rootfs. .  ",
      "P-tags": "overlayf linux openwrt filesystem",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP from NP"
    },
    {
      "id": "so_32835796",
      "task": "php file automatically renamed to php.suspected",
      "P-task": "php file automat renam php suspect",
      "F_verb": "rename",
      "P-body": "Posting this answer, it may help others. .   Create a file with '.sh' extension at your convenient location. Add following code in it.  \"#Rename your_file_name.php.suspected to your_file_name.php mv /<path_to_your_file>/your_file_name.php.suspected /<path_to_your_file>/your_file_name.php\" .   Save this file. Set cron for every 10 minute (or whatever interval you need), using following line in crontab  \"*/10 * * * * path_to_cron_file.sh\" .   Restart crontab service.  You will get lot of documentation on creating cron on Google. .  ",
      "P-tags": "amazon-ec2 php linux sugarcrm apach",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V to NP"
    },
    {
      "id": "so_54503610",
      "task": "use sed to in-place replace a line in a file with multiple lines from stdin or HEREDOCs",
      "P-task": "use sed in-plac replac line file multipl line stdin heredoc",
      "F_verb": "replace",
      "P-body": "Is this what you're trying to do? .  Note that the above is using literal string operations so it'll work for any characters in the old or new strings unlike your sed script which would fail given \"/\"s or any ERE regexp character or capture groups or backreferences or... in the input (see Is it possible to escape regex metacharacters reliably with sed for details). .  ",
      "P-tags": "replac newlin bash heredoc sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP with NP from NP"
    },
    {
      "id": "so_53759470",
      "task": "Linux bash script: using ls with glob and getting output in variable not working",
      "P-task": "linux bash script : use ls glob get output variabl work",
      "F_verb": "get",
      "P-body": "You could use find : .  To unzip the target file in your current directory : .  ",
      "P-tags": "ls glob bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_368635",
      "task": "Why is wlan0 gone?",
      "P-task": "wlan0 gone",
      "F_verb": "go",
      "P-body": "I ended up resolving the problem by installing the \"jessie-backports\" version of \"firmware-iwlwifi\": .  ",
      "P-tags": "bunsenlab networkmanag wifi debian",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V"
    },
    {
      "id": "so_54050523",
      "task": "How to send hex string to Serial Port?",
      "P-task": "send hex string serial port",
      "F_verb": "send",
      "P-body": "After the fruitfull dicussion with Hessam and Arkku, a new version of the code : .  ",
      "P-tags": "linux c serial-port",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_27047276",
      "task": "Building glibc from source not compiling ldconfig",
      "P-task": "build glibc sourc compil ldconfig",
      "F_verb": "build",
      "P-body": "I solved it, there is a variable in the configure script \"use_ldconfig\" it was set to \"no\", setting it to \"yes\" did solve the problem. .  ",
      "P-tags": "linux-from-scratch build linux compil glibc",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP S_ING"
    },
    {
      "id": "so_20195542",
      "task": "Python - how to get the import pjsua? giving no module named pjsua",
      "P-task": "python - get import pjsua\ngive modul name pjsua",
      "F_verb": "get",
      "P-body": "\"setup.py\" is trying to create shared library \"build/lib.linux-x86_64-2.7/_pjsua.so\" by dynamically linking pjsip's libraries, but, those doesn't provide a global offsets table(GOT) (check the link to see why this is needed). .  The problem is that \"./configure\" does not provide gcc's \"-fPIC\" option, I would suggest creating a \"configure-linux\" script like: .  ",
      "P-tags": "pjsip linux python",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_1030099",
      "task": "How to print text in the terminal as if it's being typed?",
      "P-task": "print text termin type",
      "F_verb": "print",
      "P-body": "This does not work with Wayland; if you're using Ubuntu 17.10 and didn't change to using Xorg at login, this solution isn't for you. .  You can use \"xdotool\"  for that. If the delay between the keystrokes should be consistent, it's as simple as that: .  This types \"something\" with a delay of \"100\" milliseconds between each keystroke. .   If the delay between the keystrokes should be random, let's say from 100 to 300 milliseconds, things get a bit more complicated: .  This \"for\" loop goes through every single letter of the string saved in variable \"text\", printing either \"key <letter>\" or \"key space\" in the case of a space followed by \"sleep 0.\" and a random number between 1 and 3 (\"xdotool\"'s \"sleep\" interprets the number as seconds). The whole output of the loop is then piped to \"xdotool\", which prints the letters with the random delay in between. If you want to change the delay just change the \"(RANDOM%x)+y\" part, \"y\" being the lower and \"x-1+y\" the upper limit \u2013 for 0.2 to 0.5 seconds it would be \"(RANDOM%4)+2\". .  Note that this approach does not print the text, but rather type it exactly like the user would do, synthesizing single keypresses. In consequence the text gets typed into the currently focused window; if you change the focus part of the text will get typed in the newly focused window, which may or may not be what you want. In either case have a look at the other answers here, all of which are brilliant! .  ",
      "P-tags": "echo command-lin bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP if S"
    },
    {
      "id": "so_8984772",
      "task": "How to suppress PowerShell Get-Content output",
      "P-task": "suppress powershel get-cont output",
      "F_verb": "suppress",
      "P-body": "Probably the output isn't caused by the assignment statement (a voidable statement), but by this line: .  \"[System.Xml.XmlDocument] $Config;\" .  In PowerShell, typically, all statements return a value (except for voidable statements). I think that the first time you run the script no output will be written to the console. However on subsequent runs \"$Config\" will still contain the value of the previous run, and its value will be written to the screen. .   piping to the Out-Null cmdlet: \"[System.Xml.XmlDocument] $Config | Out-Null\" casting to void: \"[void][System.Xml.XmlDocument]$Config\" assigning to $null: \"$null = $Config\" or simply not 'declaring' the \"$Config\" variable  are ways to suppress this behaviour. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "ul_315553",
      "task": "Should I create a /home partition while installing Mint alongside Windows XP?",
      "P-task": "creat home partit instal mint alongsid window xp",
      "F_verb": "create",
      "P-body": "What I usually do in my dual-boot installations is to keep separate paritions for Windows and Linux, keeping also the \"/home\" folder inside the Linux partition as well. Then, I just symlink the folders in my personal folder to the ones located in the data (E:) partition. For Windows, I do the same: I keep my User folder inside the Windows partition and then I symlink the folders to point the data partition. This layout lets me quickly isolate data from the SOs in case any of them gets corrupted, infected, broken, unbootable, etc. If that happens, I only lose the application files and none of my personal ones. .  ",
      "P-tags": "home partit linux-mint",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP while S"
    },
    {
      "id": "su_614597",
      "task": "I somehow made our linux box's \"CP\" command act differently than the default, how can I revert it back to default?",
      "P-task": "somehow made linux box cp command act differ default revert back default",
      "F_verb": "make",
      "P-body": "Linux \"cp\" does not, by default, prompt you when overwriting. If it used to, then as @mirkobrankovic said, it was most likely defined as an alias.  .  User specific aliases are usually in \"~/.bashrc\" and global aliases are in \"/etc/bash.bashrc\". You probably had an alias in one of those files that turned \"cp\" into \"cp -i\" if you were asked before overwriting.  .  To set up that alias again, add this line to either of the two files I mentioned above: .  The alias will take effect next time you open a terminal window.  .  ",
      "P-tags": "linux cp default-set",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_843465",
      "task": "Resetting Ubuntu",
      "P-task": "reset ubuntu",
      "F_verb": "reset",
      "P-body": "It's not simple to backup system settings* but there's an answer for that here. To factory data reset you might as well reinstall Ubuntu. Follow the instructions here to make a bootable Ubuntu USB stick if you haven't already and then install Ubuntu from it. You'll want to use the option 'Erase disk and install Ubuntu' when you get to it, presuming you're not dualbooting. .  *I suppose if you want an easy option in Ubuntu to do this you could try reporting a bug on Launchpad with the command \"ubuntu-bug\" asking for it but you will be submitting a feature request so it will probably be ignored. .  ",
      "P-tags": "16 10 reset",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP"
    },
    {
      "id": "so_17915200",
      "task": "Bash: loop through file line by line, find specific string and append to each subsequent line until same string is found",
      "P-task": "bash : loop file line line find specif string append subsequ line string found",
      "F_verb": "find",
      "P-body": "If I have your requirements right, this little awk program will work: .  That will do nothing with any line which doesn't start with AB1 or AB2 and it fails to check for equality of the 12-character string following the AB1/AB2. I couldn't tell if you require that check. .  ",
      "P-tags": "awk grep regex bash sed",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "su_1364748",
      "task": "I changed my \"HOME\" variable and now cannot find \"~/.bash_profile\" to change it back",
      "P-task": "chang home variabl find bash_profil chang back",
      "F_verb": "change",
      "P-body": "It's in the same place. .  Before the change \"~\" expands to something like \"/Users/YourUserName\", the shell finds your \".bash_profile\" there. After the file gets sourced \"~\" expands to another path so \"~/.bash_profile\" no longer points to the relevant file. This is because in this context \"~\" means \"$HOME\". .  If you know the full path to your actual home directory, you can use it instead of \"~\". In Mac it would probably look like this: .  Or let your Bash look up your home directory in the user database rather than just looking at \"$HOME\". This doesn't require you to remember anything: .  Modifying your \"HOME\" variable without changing your actual home directory is not the best idea. Changing any user's home directory is an administrative task, usually regular users cannot do this. .  ",
      "P-tags": "mac environment-vari bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_68671840",
      "task": "While until echo \"success \" linux",
      "P-task": "echo success linux",
      "F_verb": "echo",
      "P-body": "The loop continues as long as the command produces any output. You need to compare with \"success\". .  ",
      "P-tags": "do-whil linux while-loop",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_7888551",
      "task": "From inside Vim how to replace 2nd occurance of a pattern in all lines?",
      "P-task": "insid vim replac 2nd occur pattern line",
      "F_verb": "replace",
      "P-body": "You can try this .  \"\\zs\" means to start the replacement (to \"EXPORT \\S\\+\" is used to match but is not replaced). .  ",
      "P-tags": "linux vim unix",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_23742928",
      "task": "How to detect if a server is using SPDY",
      "P-task": "detect server use spdi",
      "F_verb": "detect",
      "P-body": " ",
      "P-tags": "linux spdi",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "ul_653786",
      "task": "Can I directly convert a file that lists multiple variables to JSON using the command line?",
      "P-task": "directli convert file list multipl variabl json use command line",
      "F_verb": "convert",
      "P-body": "Using a combination of \"jo\" (from here) and \"jq\" (from here), without creating shell variables or letting the shell interpret the file at all: .  This first uses \"jo\" to create the JSON document .  (but on a single line). It does this by interpreting the variable assignments in your file as key-value pairs. .  The \"jq\" tool is then used to delete the single quotes from the start and end of each value. .  The final result is .  This will not cope with newlines being embedded in the values. Other special characters will however be automatically JSON-encoded by \"jo\". .  ",
      "P-tags": "json command-lin",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP that S"
    },
    {
      "id": "so_46095840",
      "task": "adding i2c client devices on x86_64",
      "P-task": "ad i2c client devic x86_64",
      "F_verb": "add",
      "P-body": "Since you have an ACPI-enabled platform the best approach is to provide the ASL excerpts for given devices. .  Because of Intel Galileo platform for IoT the Atmel 24 series EEPROM has got its own ACPI ID and an excerpt will be simple: .  Note, the size property is being added in a pending patch series (patches add eeprom \"size\" property and add support to fetch eeprom device property \"size\"). .  Note, the address width is 8-bit as hard coded for now. In case you need to have 16-bit you need to create a similar patches as mentioned above. .  For LTC2990 power monitor you need the following excerpt: .  Note, unfortunately there is no compatible string in the driver, so, one needs to add it like it's done here. .  In the examples above \"\\\\_SB.PCI0.I2C2\" is an absolute path to the I2C host controller. .  How to get those files applied: .   first of all, create a folder   save files under names mentioned in the \"DefinitionBlock()\" macro in that folder create the uncompressed cpio archive and concatenate the original initrd on top:  More details are available in SSDT Overlays. .  The other examples and description of the idea behind can be found on meta-acpi GitHub page, some materials from which are copied here. .  ",
      "P-tags": "embedded-linux acpi linux-kernel x86 linux-device-driv",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_29858215",
      "task": "how to print the last login time in shell script?",
      "P-task": "print last login time shell script",
      "F_verb": "print",
      "P-body": "try this: .  \"last | grep pts/ | awk '{ if (users[$1] != 1) { users[$1]=1; print $1 \" \"$4 \" \"$5 \" \"$6 \" \"$7} }'\" .  more simpler: \"last | awk '/pts/ && !users[$1] {print $1, $4, $5, $6, $7; users[$1]=1; }'\" .  ",
      "P-tags": "linux shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "so_46288340",
      "task": "Bash SubMenu Does not Exit back to Parent",
      "P-task": "bash submenu exit back parent",
      "F_verb": "exit",
      "P-body": "Got it. It was the \"while true; do\" in the secondary menu. .  FINAL CODE .  ",
      "P-tags": "sh ubuntu-16 04 bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP to NP"
    },
    {
      "id": "au_19590",
      "task": "How do I share NFS mounts over zeroconf?",
      "P-task": "share nf mount zeroconf",
      "F_verb": "mount",
      "P-body": "My answer to question 18933 actually included an answer for NFS shares (although the question did not explicitly mention NFS): Create a service description file (e.g. \"nfs.service\") in \"/etc/avahi/services\" with the following content: .  The port 2049 requires you to use the \"insecure\" option in the \"/etc/exports\" file, though. .  Then it should be possible to use your file manager, navigate to \"Networks\" and access your share. Unfortunately, The GNOME file manager does not provide support for NFS at the moment (Launchpad Bug #29263, thanks to Jo\u00e3o Pinto for pointing this out) and the NFS support in the KDE file manager is broken (KDE bug #184997 Now fixed) as well\u2026 .  ",
      "P-tags": "nf zeroconf avahi",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V over NP"
    },
    {
      "id": "so_23276183",
      "task": "How to remove words with digits without removing a digit at the beginning of a string?",
      "P-task": "remov word digit without remov digit begin string",
      "F_verb": "remove",
      "P-body": "You may want to try this: .  DEMO http://regex101.com/r/zW2nJ3 .  ",
      "P-tags": "perl unix",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP at NP of NP"
    },
    {
      "id": "so_63104643",
      "task": "Git Permission denied (publickey) when accessing server through Github Actions CI/CD",
      "P-task": "git permiss deni publickey access server github action ci cd",
      "F_verb": "deny",
      "P-body": "Since the passphrase seems to be the issue, you might need to add your key to the ssh agent in your GitHub Action workflow. See as an example \"Using a SSH deploy key in GitHub Actions to access private repositories\" from Matthias Pigulla, which proposes: .  But he has also defined since then actions/webfactory-ssh-agent .   This action .   starts the ssh-agent, exports the SSH_AUTH_SOCK environment variable, loads a private SSH key into the agent and configures known_hosts for GitHub.com.   ",
      "P-tags": "github-act git ubuntu github",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V when S"
    },
    {
      "id": "so_39385795",
      "task": "Suppress Openssl output during grep",
      "P-task": "suppress openssl output grep",
      "F_verb": "suppress",
      "P-body": "As indicated in comments, the problem is that the command \"openssl\" displays part of its output through \"stderr\". Then, this will show no matter what you pipe. .  So if you want to just show what \"grep\" has filtered to you, you have to previously redirect \"stderr\" to \"/dev/null\" so that it does not \"jump the pipe\": .   See another example of this: .  Let's grep, where everything appears: .  Let's grep but redirect stderr beforehand: .  ",
      "P-tags": "grep bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP during NP"
    },
    {
      "id": "ul_106765",
      "task": "Mounting an old floppy image file (.ima format) - how hard can it be?",
      "P-task": "mount old floppi imag file ima format - hard",
      "F_verb": "mount",
      "P-body": "If you can't mount the image you might still be able in some cases to \"stream out\" some of its data with \"cpio\". .  Once you've ascertained whether the image is: .   An image using a supported filesystem and a partition --> \"mount\" An image using a supported filesystem and more than one partition --> \"mount with offset\", or use \"dd\" to extract a partition with offset then mount that partition only or use something like \"kpartx\" An image not using a supported filesystem or with no filesystem at all --> kernel support and further investigation...  You can use the \"hexdump\" and \"strings\" utilities to try to analyze the header and to extract text strings from the image and gain more information about the image file and its structure.  .   Something captured my interest in doing so: .  There's a line like this for every single binary in the image so you somewhat know what's in there. Also, in this case, when you take a closer look at how the installation process occurs on the original platform with \"installpkg\", you find out that: .   The basic mechanism to transfer software from a floppy disk to the UNIX System V /386 hard disk is cpio. .   Basically, the data is extracted with \"cpio\" to /usr/tmp/install and a series of files are included with this (an install, ascii, file, name and size file). It so happens here that this command: .  outputs malformed number errors to begin with, but then creates a /usr/bin folder with the contents of the image! The \"tr\" I was looking for is there: .  Trying \"cpio\" in the first place can't hurt! .  ",
      "P-tags": "mount loop-devic floppi",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_22616552",
      "task": "Linux command to find a specific line in file and add new lines below it",
      "P-task": "linux command find specif line file add new line",
      "F_verb": "find",
      "P-body": "Would .  solve your issue? .  ",
      "P-tags": "linux command",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_497607",
      "task": "Is there a way to figure out what physical port a drive is being inserted into through linux?",
      "P-task": "way figur physic port drive insert linux",
      "F_verb": "figure",
      "P-body": "Yes you can. \"lsusb\" will give you details at the \"Bus\" and \"Device\" level and with \"fdisk -l\" it is possible to view which 'USB drives' are mapped into what devices. You can also look at the \"dmesg\" outputs to see the port in which your 'USB' has been plugged in. You may have to constantly checking the output. .  For example: .  My external drive has been plugged in to my \"USB3.0\" port. .  In the above, my external drive is \"/dev/sdb1\". .  ",
      "P-tags": "partit port linux linux-kernel usb-driv",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V what S"
    },
    {
      "id": "so_61121964",
      "task": "Powershell script to change Existing date & add 1 hour to it",
      "P-task": "powershel script chang exist date add 1 hour",
      "F_verb": "change",
      "P-body": "You can do the following: .  First, cast the retrieved date string as a \"[datetime]\" object. Then add an hour using \"AddHours(1)\". Then format your date string. .  EDIT: .  Your later comments show a different format than in the original question. You can parse that format and apply the same methods: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_62230201",
      "task": "Change multiple folder name from %-% to % (delete everything after the hyphen)",
      "P-task": "chang multipl folder name - delet everyth hyphen",
      "F_verb": "delete",
      "P-body": "With powershell, use \"Get-ChildItem\" to discover all the subfolders, then use \"Rename-Item\" to rename: .  The \"-replace\" operator with remove \"-\" and anything thereafter in the existing name (or, if \"- something\" isn't found, ignore it) .  ",
      "P-tags": "batch-renam powershel window bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP after NP"
    },
    {
      "id": "so_2609985",
      "task": "How to run a PowerShell script within a Windows batch file",
      "P-task": "run powershel script within window batch file",
      "F_verb": "run",
      "P-body": "This one only passes the right lines to PowerShell: .  \"dosps2.cmd\": .  The regular expression excludes the lines starting with \"@f\" and including an \"&\" and passes everything else to PowerShell. .  ",
      "P-tags": "cmd batch-fil script powershel window",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP within NP"
    },
    {
      "id": "ul_315451",
      "task": "How to serve different subnet with one NIC card, according to \u201cdhcp-server-identifier\u201d, in centos7",
      "P-task": "serv differ subnet one nic card accord dhcp-server-identifi centos7",
      "F_verb": "serve",
      "P-body": "I found the solution by myself. .  Adding the virtual interface as permanent interface in /etc/sysconfig/network-script/ will let the server offer multi subnet with one real interface. .  If the interface is added as temporary one .(ex. \"ifconfig eth0:1 172.16.52.0/24\" ), the server will not be able to serve with multi subnet. .  ",
      "P-tags": "cento linux dhcp",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_649666",
      "task": "any program with can show maths steps for simplifying algebra",
      "P-task": "program show math step simplifi algebra",
      "F_verb": "show",
      "P-body": "Well, Mathomatic does a bit what you want: .  ",
      "P-tags": "software-rec math ubuntu",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP for S_ING"
    },
    {
      "id": "so_29287092",
      "task": "Shell Script not reading input",
      "P-task": "shell script read input",
      "F_verb": "read",
      "P-body": "Except where you missed the ending quote where you set \"ROOT_EXCLUDE\" (line #4), it looks okay to me. I take it the missing quote is a transcription error or your program wouldn't really work at all. .  I've tried out the program and it seems to work. .  A debugging trick is to put \"set -xv\" to turn on debugging in your script and \"set +xv\" to turn it off. The \"-x\" means to print out the line before executing, and the \"-v\" means to print out the line once the shell interpolates the line. .  I'm sure that you'll immediately see the issue once you have \"set -xv\" in your program. .  As part of this, you can set \"PS4\" to the line prompt to print when the debugging information is printed. I like setting PS4 like this: .  This way, the line prompt prints out the line it's executing which is nice.  .  In your case, I would put \"set -xv\" right before you set \"OPTIONS\" and then at the very end of the program. This way, you can see the \"if\" comparisons and maybe spot your issue. .   By the way, it's better to use double square brackets like \"[[ ... ]]\" for testing rather than the single square brackets like \"[ ... ]\". This has to do with the way the shell interpolates the values in the test. .  The \"[ ... ]\" is an alias to the built in \"test\" command. The shell interpolates the line as is and the entire line is executed. .  The \"[[ ... ]]\" are a compound statement where the shell will interpolate variables, but not the entire line. The line is kept as whole: .  This will work: .  This won't: .  The shell interpolates the line as is: .  And this is the same as: .  The \"test\" command looks at the first item to see if it's a standard test, or assumes three items and the second item is a comparison. In this case, neither is true. .  However, this will work: .  With the \"[[ ... ]]\" being a compound command, the \"$foo\" and \"$bar\" are replaced with their values, but their positions are kept. Thus, the \"=\" is recognized as a comparison operator. .  Using \"[[ ... ]]\" instead of \"[ ... ]\" has solved a lot of hard to find shell scripting bugs I have. .  ",
      "P-tags": "input shell bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_19709932",
      "task": "Segfault from ld-linux in my build of glibc",
      "P-task": "segfault ld-linux build glibc",
      "F_verb": "build",
      "P-body": " This fails: .   That is entirely expected outcome. .  GLIBC consists of ~200 separate files, which all must match exactly (must have come from the same build), because they use un-versioned binary interfaces between them. .  When you run \"./elf/ld-linux.so.2 /bin/true\", you are using your own build of \"ld-linux\", but the system version of \"libc.so.6\", which did not come from your build. .  You can confirm that that's in fact what is happening by using: .  (this will prove that \"/lib/libc.so.6\" is being used). .  You can fix this by using e.g. .  which will then use \"./libc.so.6\" .  ",
      "P-tags": "linux c ubuntu linker",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V of NP"
    },
    {
      "id": "so_28849827",
      "task": "How to enter Japanese hiragana characters to python 2.6 shell on linux?",
      "P-task": "enter japanes hiragana charact python 2 6 shell linux",
      "F_verb": "enter",
      "P-body": "Provided your locale settings are correct, it should just work. .  ",
      "P-tags": "unicod linux python shell fedora",
      "source": "qa",
      "cate": "enter",
      "pat": "V NP to NP on NP"
    },
    {
      "id": "so_61816829",
      "task": "Use Bash to merge column by column between two files",
      "P-task": "use bash merg column column two file",
      "F_verb": "merge",
      "P-body": "More generic solution and with N number of fields in Input_files following may work. .    You could try following, for fun + written and tested with shown samples only, in case your real files are different then it may not work. .  ",
      "P-tags": "awk sed bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP by NP between NP"
    },
    {
      "id": "au_1154533",
      "task": "Where to find Ubuntu change logs (esp the kernel)",
      "P-task": "find ubuntu chang log esp kernel",
      "F_verb": "find",
      "P-body": "Try \"apt changelog\" .  ",
      "P-tags": "kernel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_55457349",
      "task": "Service Principal az cli login failing - NO subscriptions found",
      "P-task": "servic princip az cli login fail - subscript found",
      "F_verb": "find",
      "P-body": "Actually, I don't recommend you to mix the Azure Powershell and CLI together. If you insist on doing it, I have tried your script, I could not reproduce your issue, it works fine. According to the error, you could try to pass a \"--subscription\", it also works. .   .  Note: Due to the \"AzureRM\" powershell module has been deprecated, I use the new \"Az\" powershell module, if you want to upgrade to Az, see this link. It may not be the reason of the issue, but I recommend you to upgrade it.) .  Update: .   We have to use AZ CLI simply for the property we are trying to grab...there is no PowerShell equivalent. .   Actually you can login with a service principal via powershell, the \"strong password\" is the secret, more details see this post. .  ",
      "P-tags": "azur powershel azure-cli2 azure-cli",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_17248568",
      "task": "A Shell script to find and cd into a folder taking a folder name as argument in one step",
      "P-task": "shell script find cd folder take folder name argument one step",
      "F_verb": "find",
      "P-body": "You must run \"cd\" in your current shell. Running it in another shell won't work, as you've seen. Create a function. Example: .  ",
      "P-tags": "termin linux shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V into NP as NP in NP"
    },
    {
      "id": "so_47199479",
      "task": "Why is my sed substitution with a & failing to execute?",
      "P-task": "sed substitut fail execut",
      "F_verb": "execute",
      "P-body": "Just quote the command so \"&\" does not have an special meaning for Bash! .  What is exactly happening here? As read in \"man bash\": .   If a command is terminated by the control operator &, the shell executes the command in the background in a subshell. .   Thus, when you say: .  Bash is actually seeing two commands: .  The first is sent to the background by \"&\", so you get the message: .    Then it evaluates it and determines it is incomplete, so it triggers the error: .    Finally it shows how the background job has finished: .    In the meanwhile, it tries to execute the command: .  But fails miserably and hence it returns the error: .    ",
      "P-tags": "linux docker sed bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "ul_602732",
      "task": "How do I figure out what just broke my zsh shell beginning-of-line and end-of-line bindings?",
      "P-task": "figur broke zsh shell beginning-of-lin end-of-lin bind",
      "F_verb": "break",
      "P-body": "\"bindkey -A \u2026 main\" defines what the \"main\" keymap is. The \"main\" keymap is the one that the editor uses each time you start editing a line. So what's changed is that the main keymap is now \"viins\" rather than \"emacs\". Basically, zsh now uses Vi editing mode by default rather than Emacs editing mode. .  Unless overridden in your \".zshrc\", zsh defaults to Vi editing mode if it thinks your favorite editor is Vi, and to Emacs editing mode otherwise. More precisely, \u201cit thinks your favorite editor is Vi\u201d is defined as .   If one of the \"VISUAL\" or \"EDITOR\" environment variables contain the string \u2018\"vi\"\u2019 .   It seems that something is now setting one or both of these variables. To fix the problem: .   If you do want that editor with \"vi\" in its name to be your default editor, add \"bindkey -e\" (or \"bindkey -A emacs main\") to your \".zshrc\" to tell zsh that whatever it may think, you prefer Emacs editing mode in zsh. If you don't want that default editor, figure out where the environment variable is set and remove this setting.  ",
      "P-tags": "termin keyboard-shortcut zsh maco line-editor",
      "source": "qa",
      "cate": "split/break/divide/unbundle/demangle/crack/strip",
      "pat": "V NP"
    },
    {
      "id": "ul_83370",
      "task": "How to install ia32-libs in Debian Wheezy?",
      "P-task": "instal ia32-lib debian wheezi",
      "F_verb": "install",
      "P-body": "Luckily Wheezy don't need \"ia32-libs\" any more. Instead one might enable \"i386\" architecture using  .  and then (after \"sudo apt-get update\") install 32-bit libraries using \"apt-get\" like in the following example: .  ",
      "P-tags": "debian 32bit",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_37054314",
      "task": "How to parse this text in Powershell?",
      "P-task": "pars text powershel",
      "F_verb": "parse",
      "P-body": "Using a multi-line regex. It looks like your target strings actually starts at position 52) .  ",
      "P-tags": "powershel pars powershell-3 0",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP in NP"
    },
    {
      "id": "so_24487488",
      "task": "How to change argv[0] value in shell / bash script?",
      "P-task": "chang argv 0 valu shell bash script",
      "F_verb": "change",
      "P-body": " ",
      "P-tags": "dash-shel sh shell bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP"
    },
    {
      "id": "au_151753",
      "task": "Make windows smaller",
      "P-task": "make window smaller",
      "F_verb": "make",
      "P-body": "You cannot set a general scaling factor. You can however, make the font smaller for window titles, and it should make the title bar smaller. You can also make or use a different window manager theme with smaller or no title bars. .  To change the font of the title bars, you can do this, in a terminal: .  \"gsettings set org.gnome.desktop.wm.preferences titlebar-font \"Font Name 10\"\" .  Just replace the \"Font Name 10\" with the font name and size you wish to use. To keep the Ubuntu font and make it smaller, you might want to try \"Ubuntu 8\" for example. Also, it's generally a good idea to step font sizes in multiples of 2 (6, 8, 10, 12), as they scale more evenly. .  ",
      "P-tags": "window-manag resolut uniti xorg",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_43692005",
      "task": "Unix & Linux Files Concurrent Read/Write Handling",
      "P-task": "unix linux file concurr read write handl",
      "F_verb": "write",
      "P-body": "No. File writes are not atomic. .  The basic idea here is to create a temporary file and rename it. Renaming a file is atomic, so there would be either a \"not exist\" error or correct hit. .  Additionally, when overwriting an existing file, the \"rename()\" call on Linux or equavilent calls for other OS will atomically overwrite the file. In this way, you can ensure that either the old one or new one is served, both in complete form. .  ",
      "P-tags": "linux apach content-management-system unix",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "ul_296478",
      "task": "Is it possible to undo LVM pvmove?",
      "P-task": "possibl undo lvm pvmove",
      "F_verb": "undo",
      "P-body": " \"mdadm --detail --scan >> /etc/mdadm/mdadm.conf\" .   It's a good starting point for a mdadm.conf but tends to be too verbose. UUID alone is sufficient. .   It is my understanding that pvmove really just copies everything then updates some metadata so the new physical location is used. .   It's like a small RAID-1 mirror. For each segment to be moved, it starts syncing in the new location and once fully in sync, removes the old location. That way any writes that happen on segments currently in the middle of relocation are handled properly as well. .   I'm just wondering if I could undo the pvmove at this point and go back to the data on /dev/sdb1 and /dev/sdc1, if something were to go wrong with my degraded RAID. .   That depends on what you mean by \"go wrong with\" ... the pvmove mirror is strictly temporary, you have no redundancy to go back. If the new PV fails entirely you will suffer some data loss. .  If you run pvmove in read only mode you might be able to just \"vgcfgrestore\" an old \"vgcfgbackup\" (create a backup before you start moving things around), however that also only works if the pvmove itself never did anything that overlapped with anything else, overwriting old data in the process. .  Running a long smart self-test on all your disks (and looking at other relevant smart data) before starting this movement should tell you beforehand whether to expect big trouble or no. .  Alternative methods: (not necessarily any better) .  If you can do it offline / from a rescue system, you could just dd(rescue) both disks over to the RAID. However in this case you have to deal with size issues (RAID device must not be smaller than the PV size) and duplicate UUID issues. .  You could put the RAID layer onto the original PV without copying anything and then just add the new disks to the RAID. This could be done with \"0.90\" or \"1.0\" metadata which lives at the end of the partition (might have to shrink the PV somewhat first), or by editing LV metadata to free the first few physical extents to make room for mdadm metadata at the start of the partition. However this requires you to fully understand both LVM and MD metadata layouts. .  ",
      "P-tags": "mdadm lvm",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "so_53080772",
      "task": "indent-issues in a tiny python script :: fixed the code - now it runs like perfect",
      "P-task": "indent-issu tini python script : : fix code - run like perfect",
      "F_verb": "fix",
      "P-body": "The error The \"print\" functions halfway through your class are closing the class declaration, making the rest of the indented things after them not count as part of the class. You need to move your accessor methods to before the \"print\" functions as you are making an instance of the class in the middle of its definition. .  Code fixes It's also very bad practice to put statements at a base level in your file (not in a function) and then being followed up by a \"main()\" function and \"if __name__ == \"__main__\":\" .  You should move these print statements into your \"main()\" function to get them out of global space, which will also fix your indentation errors in the process. .  Your accessors can be simplified using some of python's syntax as well. Python doesn't have private variables (similar to Java) where the complier will prohibit you from actually referencing these values. Therefore, you really don't need to use accessors. It prevents unnecessary code that would be used normally just for setting a value and it gives you cleaner syntax, as you're just setting a value to the property instead of in a function. If you really want to have private variables, the standard is to just prepend the variable name with an underscore. .  ",
      "P-tags": "linux python",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_38008374",
      "task": "how to select rows with max value based on one column and group by second column using awk?",
      "P-task": "select row max valu base one column group second column use awk",
      "F_verb": "select",
      "P-body": "Credits to \"sofan's\" idea over in the comments, with some extra manipulations the below logic will do the trick as the OP wants. .   Idea is to sort the file in ascending order first (\"sort -n -k2\") and reverse it (\"-r\") on column 2 (which now will be descending order) \"awk '!x[$1 FS $3]++\" does the grouping of that content unique by column 1 and 3 and \"sort -k1\" sorts/groups it by column 1 contents  ",
      "P-tags": "awk gawk bash",
      "source": "qa",
      "cate": "choose/select",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "au_43306",
      "task": "Duplicate Application Icons appear in Dash",
      "P-task": "duplic applic icon appear dash",
      "F_verb": "duplicate",
      "P-body": "Well it came down to a simple capital letter to confuse Dash.  .  \"/usr/share/applications/docky.desktop\" .  \"~/.local/share/applications/Docky.desktop\" .  Removing the latter desktop entry solved the issue. .  ",
      "P-tags": "icon launcher uniti unity-dash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_581409",
      "task": "Error sh: 1: read: arg count",
      "P-task": "error sh : 1 : read : arg count",
      "F_verb": "read",
      "P-body": "The standard \"read\" utility takes at least one variable's name. .  Some shell's \"read\" implementation uses a default variable, like \"REPLY\", to store the read data if no name is supplied, but \"dash\", aiming to be a POSIX compliant shell, does not (as it's not required to do so by the standard). The equivalent in the \"dash\" shell would be .   The \"bash\" shell, even in its POSIX mode, does keep some non-POSIX features enabled. This is one of them, which means that \"read\" with no variable's name will work even if you run a \"bash --posix\" shell. .  For a full list of things that happens when you enable POSIX mode in \"bash\" (which this question really isn't about), see https://www.gnu.org/software/bash/manual/html_node/Bash-POSIX-Mode.html .  ",
      "P-tags": "read dash shell bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_881556",
      "task": "Install ubuntu on external HDD",
      "P-task": "instal ubuntu extern hdd",
      "F_verb": "install",
      "P-body": "I understand that you want to create a VMware virtual machine which boots Ubuntu from an external USB drive, as opposed to creating a normal VM which lives in a folder on the external drive. .  Note: Generally I would say that you should simply create a regular VM in a folder on the external drive. But, if you absolutely want to boot the VM from a USB drive instead of a virtual hard disk, you can. .  Proceed as follows: .   Prerequisites: .   Get the Ubuntu ISO from releases.ubuuntu.com. .  Get the PLOP Boot Manager to enable the virtual machine to boot from a USB drive. .   Create a VM without a virtual hard disk. Make sure that the virtual machine has a (virtual) USB 2.0 controller, and that the virtual DVD uses the Ubuntu ISO. You probably want to edit the \".vmx\" file and add \"bios.bootDelay=\"3000\"\" in order to give you some time to go into the BIOS setup menu. .  Plug the USB drive in an USB 2.0 port. .  Boot the virtual machine, making sure that it boots from the Ubuntu ISO. .  Choose \"Try Ubuntu\". .  Connect the USB drive to the virtual machine. Check that it is \"/dev/sda\". .  Run the Ubuntu installer and install Ubuntu. .  When the virtual machine reboots: .   Connect the virtual DVD to the PLOP ISO. .  Go into the BIOS setup and make sure that the machine boots in preference from the virtual DVD. .   The USB drive should be still connected to the virtual machine. Use the PLOP menu to boot from it. Note that without PLOP VMware VMs cannot boot from USB, and PLOP only boots from USB 2.0 drives.) .   ",
      "P-tags": "vmware-workst",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_19164543",
      "task": "Bash script: paste and execute an external bash script",
      "P-task": "bash script : past execut extern bash script",
      "F_verb": "execute",
      "P-body": " or, shorter .  See http://www.tldp.org/HOWTO/Bash-Prompt-HOWTO/x237.html .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_31220202",
      "task": "Not able to install both GraphicsMagick and ImageMagick",
      "P-task": "abl instal graphicsmagick imagemagick",
      "F_verb": "install",
      "P-body": "ImageMagick installs in \"/usr/bin/convert\". GraphicsMagick is installed in \"/usr/bin/gm\".  .  In order to use \"convert\" with Graphic Magick use \"/usr/bin/gm convert\" or simply: \"gm convert\".  .  For ImageMagick use, as usual, \"convert\". .  ",
      "P-tags": "imagemagick ubuntu graphicsmagick imagemagick-convert",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_64147310",
      "task": "Comparing all columns in file to reference column in same file when it is not equal to zero",
      "P-task": "compar column file refer column file equal zero",
      "F_verb": "compare",
      "P-body": "Store the headers to use them for filenames and use a for loop, from the first sample to the last one. .  Output: .   In case you get any error about too many files open, here is a memory consuming alternative: .  ",
      "P-tags": "awk linux",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP in NP S_INF when S"
    },
    {
      "id": "so_14492971",
      "task": "How to free memory created by malloc after using execvp?",
      "P-task": "free memori creat malloc use execvp",
      "F_verb": "create",
      "P-body": "You don't need to. Specifically, if you allocate memory in a process before an \"exec()\"-type routine (e.g., \"execvp()\" in your case) is called, all of the memory associated with the original executable is released. It's a similar situation to a process exiting (and having all its resources released), and a new process being started with a clean slate. .  ",
      "P-tags": "linux c exec",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP by NP after S"
    },
    {
      "id": "so_15208095",
      "task": "How to get Primary MX IP from domain in Bash",
      "P-task": "get primari mx ip domain bash",
      "F_verb": "get",
      "P-body": "To get exactly 0 or 1 answers: .  You'll need a non-ancient \"dig\" that supports \"+short\". .  As noted there may be more than one \"primary\" MX as the preferences need not be unique. If you want all the IP addresses of all of the lowest preference records then: .  This does not handle the case where there is no MX record and the A record accepts email, an uncommon but perfectly valid configuration. .  Sadly all the \"dig\" versions I've tested return 0 whether the domain exists or not (NXDOMAIN), and whether any MX records exist or not. You can catch a DNS time-out (rc=9) though. The related \"host\" command does return a non-zero rc with NXDOMAIN, but its behaviour is a little inconsistent, it's messy to script and the output harder to parse. .  A poor man's error-checking version (inspired by tripleee's comment) that might be slightly more robust depending on your \"host\" command is: .  (Perversely, you may require an older version of \"host\" (\"bind-8.x\") for the \"-t mx\" test to work, newer versions just return 0 instead.) .  This is just about the point people start backing away nervously asking why you're not using \"perl\"/\"python\"/\"$MFTL\". .  If you really need to write a robust version in bash, check out the djbdns CLI tools and debugging tools which are rather easier to parse (though sadly don't set user exit codes either). .  ",
      "P-tags": "awk host mx-record bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "au_261900",
      "task": "How do I open a text file in my terminal?",
      "P-task": "open text file termin",
      "F_verb": "open",
      "P-body": "For short files: .  directly shows a text file in the terminal. .  For longer files: .  lets you scroll and search (/ \"text to search\" Enter) in the file; press q to exit. .  e.g. .  ",
      "P-tags": "text-editor file command-lin",
      "source": "qa",
      "cate": "open",
      "pat": "V NP in NP"
    },
    {
      "id": "au_18372",
      "task": "How can I find out what RAM a computer system has?",
      "P-task": "find ram comput system",
      "F_verb": "find",
      "P-body": "Yes there is: .  It will output something like this: .  You may also want to take a look at the full output of \"sudo lshw -short\" or even \"sudo lshw\" to get much more information about your hardware. .  My thanks to jet and CYREX for pointing out a much better method:  .  Which outputs something like this: .  This method is based on the Desktop Management Interface: .   From 1999, Microsoft required OEMs and BIOS vendors to support the DMI interface/data-set in order to have Microsoft certification.(1) .   It should therefore work pretty reliably.  .  ",
      "P-tags": "hardwar ram command-lin",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V what S"
    },
    {
      "id": "ul_35241",
      "task": "How to combine two grep statements and display their results together?",
      "P-task": "combin two grep statement display result togeth",
      "F_verb": "combine",
      "P-body": "What you really want is \"OR\", not \"AND\". If \"AND\" is used, then logically, you'll get no lines (unless the line is something like \"MyVariable = False...MyVariable = True\". .  Use \"extended grep\" and the OR operator (\"|\"). .  ",
      "P-tags": "grep",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_25009070",
      "task": "Linux replace newline",
      "P-task": "linux replac newlin",
      "F_verb": "replace",
      "P-body": "In regular expressions you can use \"$\" to match end of line: .  ",
      "P-tags": "awk linux sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "su_342279",
      "task": "Where to put the GPG keys in $HOME/.gnupg?",
      "P-task": "put gpg key home gnupg",
      "F_verb": "put",
      "P-body": "If I understood correctly, you are trying to import existing keys in your keyring. Enter the following command in the terminal: .  ",
      "P-tags": "opensuse-11 4 linux gnupg gnu",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_60872278",
      "task": "Bash script to swap file locations, files with same names",
      "P-task": "bash script swap file locat file name",
      "F_verb": "swap",
      "P-body": "If you have one file, then find the other .  With the following directory/file recreation: .  outputs: .   does not exist after. Would anybody know why? .   Because the right side of \"|\" is run in a subshell. Parent shell doesn't know anything about child shell environment. .  ",
      "P-tags": "dictionari bash",
      "source": "qa",
      "cate": "flip/rotate/permute/swap/transpose/reverse/shuffle",
      "pat": "V NP with NP"
    },
    {
      "id": "so_53706639",
      "task": "How to merge multiple columns in a file to a single column using bash commands?",
      "P-task": "merg multipl column file singl column use bash command",
      "F_verb": "merge",
      "P-body": "If you are interested in doing it awk this is the way : .  Additionally, if you are seeking to preserve the order of the columns you can use this :  .  Hope it helps! .  ",
      "P-tags": "linux sh bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP in NP to NP using NP"
    },
    {
      "id": "so_6387432",
      "task": "How to make Gedit look like Textmate?",
      "P-task": "make gedit look like textmat",
      "F_verb": "make",
      "P-body": " that should work .  ",
      "P-tags": "ubuntu textmat gedit",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_66098987",
      "task": "How to redirect output of python script to bash variable?",
      "P-task": "redirect output python script bash variabl",
      "F_verb": "redirect",
      "P-body": "After .  the VERSION shell variable will contain a trailing newline, so interpolating it into Python code with \"python3 -c \"print('$VERSION')\"\" will result in .  which is not valid Python. .  You can either add \", end=\"\")\" to the original print or figure out some other way to strip the trailing newline, or use e.g. triple quotes. .  ",
      "P-tags": "python bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "so_42927540",
      "task": "Update a line at specific line and section",
      "P-task": "updat line specif line section",
      "F_verb": "update",
      "P-body": "Following will select the range of records between \"Start OF VM1\" and \"End OF VM1\" and then apply \"gsub\" function over that chunk of records. where \"[]\" is replaced with \"[test1,test2,test,*]\".  .  ",
      "P-tags": "unix shell",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP at NP"
    },
    {
      "id": "so_32641045",
      "task": "Why does this script resource not install Chocolatey packages?",
      "P-task": "script resourc instal chocolatey packag",
      "F_verb": "install",
      "P-body": "It's caused by this issue in OneGet, where you have to enable scrips via Set-ExecutionPolicy or OneGet fails while reporting success. This happens even if you set the execution policy before starting DSC. It has to be set within your DSC configuration. Apparently, it's running in a new session that doesn't inherit the execution policy. .  Here's a simple fix where I set the execution policy before the package installation: .  Instead of using a Script resource to set the execution policy, you might try the xPowerShellExecutionPolicy resource. Install instructions here and here's a sample DSC configuration. .  ",
      "P-tags": "chocolatey powershel package-manag",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_42638728",
      "task": "Produce a file that contains names of all empty subfolders",
      "P-task": "produc file contain name empti subfold",
      "F_verb": "produce",
      "P-body": "I would suggest you accept the answer which suggests to use \"find\" instead. But just to be complete, here is some feedback on your code. .   You read the input directory into \"FOLDER\" but then never use this variable. As an aside, don't use uppercase for your private variables; this is reserved for system variables. You have unpaired quotes in the prompt string. If the opening quote is double, you need to close with a double quote, or vice versa for single quotes. You loop over directory entries, but do nothing to isolate just the ones which are directories, let alone empty directories. Finally, nothing in your script uses Bash-only facilities, so it would be safe and somewhat more portable to use \"#!/bin/sh\"  Now, looping over directories can be done by using \"search_dir/*/\" instead of just \"search_dir/*\"; and finding out which ones are empty can be done by checking whether a wildcard within the directory returns just the directory itself. This assumes default globbing behavior -- with \"nullglob\" you would make a wildcard with no matches expand to an empty list, but this is problematic in some scenarios so it's not the default.) .  Using the wildcard expansion with \"[\" is problematic because it is not prepared to deal with a wildcard expansion -- you get \"too many arguments\" if the wildcard expands into more than one filename -- so I'm using the somewhat more mild-tempered Bash replacement \"[[\" which copes just fine with this. Alternatively, you could use \"case\", which I would actually prefer here; but I've stuck to \"if\" in order to make only minimal changes to your script. .  ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP that S"
    },
    {
      "id": "so_56448114",
      "task": "Finding all files that have whitespace in last few lines",
      "P-task": "find file whitespac last line",
      "F_verb": "find",
      "P-body": "You have to escape the \"+\" inside grep expression, ex. see gnu grpe manual. .  Using \"< <(...)\" shell redirection with process substitution is unneeded here, just pipe it \"|\". .  The following works. Notice how I needed to double escape \"\\\\+\", because \"\\\\\" is expanded to \"\\\" inside \"\"\" braces.: .  However when using \"xargs\" you can do it in parallel \"-P0\", also I like the debugging with \"-t\" better. For strange filenames add \"-print0\" and \"-0\" options to \"find\" and \"xargs\". .  ",
      "P-tags": "linux whitespac",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP that S"
    },
    {
      "id": "ul_582556",
      "task": "awk: print to file, which name is from variable defined in the command",
      "P-task": "awk : print file name variabl defin command",
      "F_verb": "define",
      "P-body": "You can print records to a file whose name is stored in awk variable \"d\" simply by replacing the implicit print action (triggered by the \"1\" pattern) with an explicit \"{print > d}\" .  The tricky thing is that you don't know the value of \"d\" until the second record has been processed; so you need to save the header record until then. .  So for example: .  ",
      "P-tags": "awk text-process",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V in NP"
    },
    {
      "id": "ul_168769",
      "task": "Bash extended globbing",
      "P-task": "bash extend glob",
      "F_verb": "extend",
      "P-body": "Bash has no feature to expand just one match out of many. .  The pattern \"@(foo)\" matches just one occurrence of the pattern \"foo\". That is, it matches \"foo\", but not \"foofoo\". This syntactic form is useful to build or patterns like \"@(foo|bar)\", which matches either \"foo\" or \"bar\". It can be used as part of longer patterns like \"@(foo|bar)-*.txt\", which matches \"foo-hello.txt\", \"foo-42.txt\", \"bar-42.txt\", etc. .  If you want to use one match among many, you can put the matches in an array, and then use an element of the array. .  Matches are always sorted in lexicographic order, so this will print the first match in lexicographic order. .  Note that if the pattern doesn't match any file, you'll get an array containing a single element which is the unchanged pattern: .  Set the \"nullglob\" option to get an empty array instead. .  Zsh has convenient features here. The glob qualifier \"[NUM]\" causes the pattern to expand to only the NUMth match; the variant \"[NUM1,NUM2]\" expands to the NUM1th through NUM2th matches (starting at 1). .  The glob qualifier \"N\" causes the pattern to expand to an empty list if no file is matched. .  The glob qualifier \"om\" sorts matches by increasing age instead of by name (\"m\" is for modification time); \"Om\" sorts by decreasing age . So \"vmlinuz*(om[1])\" expands to the most recent kernel file. .  ",
      "P-tags": "wildcard bash",
      "source": "qa",
      "cate": "inflate/extend",
      "pat": "V NP"
    },
    {
      "id": "so_20598121",
      "task": "Exclude duplicate lines from two different files and generate new?",
      "P-task": "exclud duplic line two differ file gener new",
      "F_verb": "exclude",
      "P-body": "If your file is not big you can basically cat first file twice: .  but this is expensive for big files. .  or using grep you can achieve this (thanks to @tripleee): .  ",
      "P-tags": "uniq linux shell bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "su_996417",
      "task": "What is Install-Module command in Powershell?",
      "P-task": "install-modul command powershel",
      "F_verb": "install",
      "P-body": "I had previously installed PSGet which had overwritten my version of \"Install-Module\". You can check this by running \"help install-module\" and see which version it refers to.  .  I couldn't find uninstall documentation for PSGet so I removed it by deleting the folder \"C:\\Users\\Rory\\Documents\\WindowsPowerShell\\Modules\\PSGet\". Now \"help install-module\" refers to the microsoft version.  .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "su_193277",
      "task": "What happens to the environment when you run \"su -c\"?",
      "P-task": "happen environ run su -c",
      "F_verb": "happen",
      "P-body": "What you are seeing is the fact that \"$PATH\" is expanded in the first users shell during argument processing, before the \"su(1)\" command runs, so it looks like it always does. If you use hard quotes (\"'echo $PATH'\") you should see something different, or just do \"\\$\". .  This will preserve the \"$PATH\" syntax until after the \"su(1)\" command runs. While it normally doesn't fiddle with the environment, it does start a new shell, and so you should check for \"PATH=\" lines in the various shell startup scripts. .  Your \"su(1)\" has a \"-c\" option, so you would seem to be on Linux. On a Mac or a BSD you would get a simplified \"PATH\" instead of the login \"PATH\" but you would still have the same \"when did I expand PATH?\" issue. .  ",
      "P-tags": "sh su unix bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V to NP when S"
    },
    {
      "id": "so_34353763",
      "task": "Compare md5 after tftp transfer",
      "P-task": "compar md5 tftp transfer",
      "F_verb": "compare",
      "P-body": "You risk printing out and comparing garbage since you don't ensure the strings are nul terminated. .  You need to do  .  And similar for \"input_md5\". Or to do it properly, use the return value of \"fread()\" to add the nul terminator in the proper place, check if fread() fails, Check how much it returned. .  If you also place your debug output inside quotes, it'll also be easier to spot unwanted whitespace or unprintable characters: .  ",
      "P-tags": "linux file md5sum strncmp c",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP after NP"
    },
    {
      "id": "so_27077101",
      "task": "Base 64 encoded output is different in java/shell",
      "P-task": "base 64 encod output differ java shell",
      "F_verb": "encode",
      "P-body": "Your encoded strings differ in that the java former includes 2 newline characters \"'\\n'\" at the end while the latter only has one. .  You can tell by typing e.g. \"echo dGVzdAo= | base64 --decode | od -c\" .  ",
      "P-tags": "shell encod java encod",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP"
    },
    {
      "id": "so_29044442",
      "task": "How do you get the 'top' command to work in Java runtime to return a list of processes and the amount of resources each are consuming?",
      "P-task": "get top command work java runtim return list process amount resourc consum",
      "F_verb": "get",
      "P-body": "I tired something like... .  And it output something like... .  Now, obviously, you'll need to parse the individual lines to get meaningful information, but no more then you would have to by reading the output file... .  ",
      "P-tags": "java bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF in NP S_INF"
    },
    {
      "id": "su_1096622",
      "task": "Is it worth to block inbound packets from a security standpoint?",
      "P-task": "worth block inbound packet secur standpoint",
      "F_verb": "block",
      "P-body": " Another guess would be that everytime you send a SYN packet to a server, this server is automatically added to the whitelist so when you try to connect on a website it automatically allow him to reply. Is there a way to do such a thing conveniently ? .   That's how most stateful firewalls work already (e.g. home routers because it's required for doing NAT, but common on servers too). .  In iptables, this is done via the \"conntrack\" module or its simplified \"state\" version. Both examples are equivalent with modern kernels (although I think \"-m state\" was required in 2.6.x days). .  Though, IMHO, you should also unconditionally accept at least \"-p icmp\" and \"-p ipv6-icmp\". .  In pf, keeping state is the default for \"pass\" rules (unless \"no state\" was specified). .  ",
      "P-tags": "firewal secur linux network iptabl",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from NP"
    },
    {
      "id": "so_24982480",
      "task": "How to use Bash (sed or any other) command to insert at EOF-nth line",
      "P-task": "use bash sed command insert eof-nth line",
      "F_verb": "insert",
      "P-body": "If you want to insert a line after 5th line use this \"sed\": .  Here data to insert comes from \"data-file\" .  ",
      "P-tags": "awk unix linux bash sed",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V at NP"
    },
    {
      "id": "so_55741171",
      "task": "Regex which matches all contents between and including outer quotes if present, else entire text blob separated by un-escaped spaces",
      "P-task": "regex match content includ outer quot present els entir text blob separ un-escap space",
      "F_verb": "match",
      "P-body": "\"Bash\" doesn't support \"perl\" regex capabilities that you are trying to use. If you need to stick to bash, check if following helps. .  Output: .  ",
      "P-tags": "parameter-pass bash grep regex",
      "source": "qa",
      "cate": "match",
      "pat": "V NP between NP if S"
    },
    {
      "id": "ul_94507",
      "task": "stopping atd job at specified time",
      "P-task": "stop atd job specifi time",
      "F_verb": "stop",
      "P-body": "I don't see a mechanism within \"at\" to allow you to specify a stop time. I would just schedule another \"at\" job at 7am that would check if any of these at jobs are still running and kill them. .  ",
      "P-tags": "schedul",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP at NP"
    },
    {
      "id": "ul_588518",
      "task": "how to keep stty sane after piping strace to vim?",
      "P-task": "keep stti sane pipe strace vim",
      "F_verb": "keep",
      "P-body": "tl;dr  About \"-o\" \"-o\" exists to provide additional output channel different than stdout or stderr. Without \"-o\" \"strace\" prints to its stderr which is also the stderr of the command (\"file.out\" in your case). It's good to be able to separate the two streams, \"-o\" makes this possible. .   Problems Your approach is flawed in a different way than you think, \"stty sane\" cannot help. Let me repeat the command: .  There are two general problems with it: .   With job control enabled, there's a concept of foreground process group. At any time the terminal recognizes one group that is in the foreground. Processes not in the foreground process group are formally in the background. .  A process in the background cannot read from its controlling terminal; it will receive \"SIGTTIN\" if it tries. The signal will stop it, unless the process ignores it or handles differently. .  A process in the background can write to its controlling terminal, although if it tries and \"stty tostop\" is enabled then the process will receive \"SIGTTOU\". The signal will stop it, unless the process ignores it or handles differently. If not stopped, the process is able to write to the terminal despite \"tostop\" and the signal. .  The above mechanism prevents background processes from stealing input from the terminal, but still keeps them connected to it, so they can be brought to the foreground and then read from the terminal. This is useful for the terminal from which a process was started. Possible interaction with other terminals has nothing to do with being in the foreground or in the background, the other terminal is \"foreign\" anyway; therefore a process can read from or write to a terminal that is not its controlling terminal, if only it has sufficient permissions. .  In your case initially the foreground process group is the one associated with the shell; then with \"strace\"; then with \"stty\" (the one outside \">()\"); and finally with the shell again. .  In Bash processes inside \">()\" are assigned to the process group of the shell handling the \">()\". This means your \"vim\" is able to read from the terminal only after \"strace\" and \"stty\" (the one outside \">()\") finish and the shell's process group is put in the foreground. This brings the second problem. .  When \"vim\" is finally able to read from the terminal, the shell also tries to read. Compare these two: .    Move the cursor around. Some input will go to \"vim\", some input will go to the shell. They are both in the foreground. .   Try to move the cursor around. Now it's different because \"sleep\" is in the foreground. Terminate \"sleep\" with Ctrl+C and the behavior will change. .    .  .  In any case you can recover by killing \"vim\" from another console (\"killall vim\", unless there is another \"vim\" and you want to keep it). .   This is the madness you observed. The culprit is beyond the scope of \"stty sane\", \"reset\" or \"tput reset\". .   Trivia  The following commands generate non-identical madness: .  In the first case \">()\" is handled by the main shell and \"vim\" is placed in the process group of the shell. It will be able to read from the terminal as soon as \"tee\" exits (although the shell interferes); we've seen this before with \"strace\". .  In the second case \">()\" is handled by the shell that handles \">\". It's a subshell that is going to become (exec to) \"tee\". In effect \"vim\" is placed in a process group with \"tee\". It is able to read from the terminal as long as \"tee\" stays in the foreground. .  Because \"tee\" exits almost immediately, the first \"vim\" is almost immediately able to read from the terminal and the second \"vim\" is almost immediately unable to read. .  My tests indicate that \">(vim -)\" in Zsh places \"vim\" in yet another process group, not the one of the shell handling the \">()\". Then \"vim\" can never be in the foreground. It seems there are other differences but I won't elaborate. .    General solutions (not depending on \"strace\")  If you disable job control (with \"set +m\" or by running code in a subshell) then all new processes will belong to the group the terminal considers the foreground. If you delay your return to the shell, the shell won't interfere by reading from the terminal. Try this: .  Use Ctrl+C to terminate \"sleep\" after you exit \"vim\". If you hit this combination in \"vim\" then \"sleep\" won't be affected because \"vim\" configures the terminal like \"stty -isig\". .  This solution is not really elegant. I'm including it here because it shows how things are affected by disabling job control and not allowing the shell to read input. .  Alternatively you need to start and keep \"vim\" in the foreground. Do not use \">(vim -)\". Use \"vim \u2026\" or \"\u2026 | vim -\". .  The most straightforward way is to create a regular file (in your case \"strace -o somefile file.out\") and to open it later (\"vim somefile\"). .    Solution specific to \"strace\" Solutions that avoid creating a file and use \"vim <(strace \u2026)\" or \"strace \u2026 | vim -\" are possible. I guess if you are clever enough (and have \"/proc\"?) then you can manipulate file descriptors and pipe \"-o\" to stdout without merging with the original stdout. .  The right thing however is to use what \"strace\" provides with \"-o\": .   Write the trace output to the file \"filename\" rather than to stderr. [\u2026] If the argument begins with \"|\" or \"!\", the rest of the argument is treated as a command and all output is piped to it. This is convenient for piping the debugging output to a program without affecting the redirections of executed programs. [\u2026] .   (source, emphasis mine) .  Your command becomes: .   .  Note \"|\" must be quoted or escaped, otherwise the shell will try to build a pipeline. The alternative is \"!\", in some shells it needs to be protected as well. .  \"strace\" runs \"sh\", \"sh\" runs \"vim\". The problems stated above are solved. Respectively: .   The three processes belongs to the same process group. If \"strace\" is in the foreground, so is \"vim\". .  The interactive (outer) shell tries to read from the terminal only after \"strace\" exits after \"sh\" exits after \"vim\" exits. .   ",
      "P-tags": "process-substitut strace vim pipe",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP after S"
    },
    {
      "id": "ul_648816",
      "task": "What is the epoch of LUKS that is shown when running luksDump?",
      "P-task": "epoch luk shown run luksdump",
      "F_verb": "run",
      "P-body": "The Epoch increases every time you change anything in your LUKS header (like when adding or removing keys, etc.). .  The LUKS2 header specification states: .     \"seqid\" is a counter (sequential number) that is always increased when a new update of the header is written. The header with a higher seqid is more recent and is used for recovery (if there are primary and secondary headers with different seqid, the more recent one is automatically used). .   Why this is called a \"sequence ID\" in code and technical documentation, but uses the term \"Epoch\" when shown to the end user, remains a mystery. .  That it is in fact the same thing, can be seen if you read the fine source, which prints seqid as Epoch: .    tl;dr You can safely ignore the Epoch, it is a harmless counter with no specific meaning. .  ",
      "P-tags": "disk-encrypt encrypt luk",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_22622224",
      "task": "How to create a file shortcut on Ubuntu using Python?",
      "P-task": "creat file shortcut ubuntu use python",
      "F_verb": "create",
      "P-body": "If by \"shortcut\" you mean symlink, it's just .  ",
      "P-tags": "ubuntu linux python shortcut",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "so_51769887",
      "task": "Unit test with sinon fake does not resolve promise",
      "P-task": "unit test sinon fake resolv promis",
      "F_verb": "resolve",
      "P-body": "You function is a little complex but nothing sinon can't handle with stubs. See https://sinonjs.org/releases/v1.17.7/stubs/ for more info but what you should use is \"callsArgOnWith\" before the function. .  Instead of setting \"exec\" to return a promise you need to set it as a stub. This way you can call the callback using the \"callsArgOnWith\" function when it is encountered.  .  I've changed your test so it now passes by changing the fake \"exec\" function to return a stub \"const fakeShell = { exec: sinon.stub() };\" and adding the line \"fakeShell.exec.callsArgOnWith(2, null, null, 'pass', null)\" before running your function .  ",
      "P-tags": "node js promis shellj mocha js",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "au_644253",
      "task": "Can't Use Audio in One Application Because Another Has Taken Full Use of Sound Card",
      "P-task": "use audio one applic anoth taken full use sound card",
      "F_verb": "use",
      "P-body": "From the command line,  .  will list all the open files in \"/dev/snd\", and which program has them open. See also \"man fuser\". .  ",
      "P-tags": "soundcard music alsa pulseaudio",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_557441",
      "task": "When its necessary to add backslash before dot when using sed",
      "P-task": "necessari add backslash dot use sed",
      "F_verb": "add",
      "P-body": "You only ever have to escape the dot if it is part of a regular expression and should match a literal dot. To match a literal dot with a regular expression, you may use either \"\\.\" or \"[.]\". .  The replacement part of an \"s\" expression in \"sed\" is however not a regular expression. .  The only characters that need to be escaped there (with backslash) are \"\\\", \"&\", newline, and the \"s\" command delimiter (\"/\" if using \"s/pattern/replacement/\"). .  This means that your command .  would work, as long as the values of the variables involved adhere to the above-mentioned rules. I would personally additionally anchor the expression to the start of the line and drop the \"g\" flag from the \"s\" command. .  ",
      "P-tags": "sed regular-express",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP before NP when S"
    },
    {
      "id": "so_61042354",
      "task": "fatal: Could not read from remote repository. Github error: failed to push some refs to",
      "P-task": "fatal : could read remot repositori\ngithub error : fail push ref",
      "F_verb": "read",
      "P-body": "Following steps worked for me: .  This worked for me  .  ",
      "P-tags": "git github git-bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V from NP"
    },
    {
      "id": "so_46002993",
      "task": "How do I put regex match groups into separate output columns, correctly handling missing/empty values?",
      "P-task": "put regex match group separ output column correctli handl miss empti valu",
      "F_verb": "put",
      "P-body": "I'm assuming that \"file\" and \"lines\" will actually be regular expressions with their own match groups. The following allows any ERE to be used in place: .  See BashFAQ #1 (\"How can I read a file (data stream, variable) line-by-line (and/or field-by-field)?\") for a description of the technique used here. .   With your given input, the output is: .  ",
      "P-tags": "text-process grep bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP"
    },
    {
      "id": "au_969361",
      "task": "Is it possible to disable (freeze) a package?",
      "P-task": "possibl disabl freez packag",
      "F_verb": "disable",
      "P-body": "Linux doesn't start applications you don't need and keep them in RAM like Android does so they can receive push messages and the like. So freezing packages is not necessary. .  For many applications, if you don't start the application, it won't run. It will still get updates in case you want to use it. .  If you are really inclined to get rid of a package, uninstalling it (and installing it as needed) is possible for non-essential applications, but as with other Linux distributions, packages on Ubuntu depend on other packages, and have other packages that depend on them, so when you install or remove a package, other packages may be automatically installed as dependencies (or replacements) or removed because they depend on the package you remove. Removing a package with many dependencies or that is essential for the system to run properly may break the system very severely. All this is handled by the package management system. To see what is going to happen when you run a particular install or remove command, use the \"-s\" or \"--simulate\" option in APT, for example .  this will show what will be done without actually doing anything. .  Some programs do run in the background as services though. In those cases, you can use the \"systemctl\" command (part of the interface of \"systemd\" to stop and disable them (disabling prevents the service from starting on boot). Once again, you need to be careful here, because services may also depend on each other and stopping or disabling an important service can have a negative impact on your system's functionality and stability. However, \"systemd\" will start services you have disabled if other services depend on them, so this is less breakable than package management. .  Here are examples on how to stop, enable, disable and start services. .   enabling a service: .  Enabling a service does not start it automatically; you need to use \"start\" for that, or add the \"--now\" flag, or reboot your machine. to make it take effect. .   disabling a service: .  Disabling a service does not make it stop immediately, you need to use \"stop\" for that, or add the \"--now\" flag, or reboot your machine. .   starting a service: .  starting a service does not make it enabled by default (this is what the \"enable\" command is for) but it starts the service immediately if it can be started. .   stopping a service: .  stopping a service does not disable a service which was enabled but stops it for the time being until next reboot. .   restarting a service: .  Restarts a service but like the \"start\" and \"stop\" commands does not affect whether the service will be loaded and started on boot (the behaviour controlled by the \"enable\" \"disable\" commands. .    ",
      "P-tags": "package-manag",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "so_16773407",
      "task": "Calling multiple URLs at a time using multithreading in powershell",
      "P-task": "call multipl url time use multithread powershel",
      "F_verb": "call",
      "P-body": "You will run into a couple of issues with the code above. The scriptblock gets transferred to a different PowerShell.exe process to execute so it won't have acess to $queries. You will to pass that it like so: .  The other issue is that you never remove a completed job from $job so once this \"$jobs.Count -lt 5\" expression evals to false because the count has reached 5, you'll never add anymore jobs. Try something like this: .  Then you'll wind up with only the running jobs in $jobs which will allow you to start more jobs as previous jobs complete (or fail). .  ",
      "P-tags": "powershel multithread",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP at NP using NP in NP"
    },
    {
      "id": "so_26724559",
      "task": "Create postgresl database dump and download it using scp with sshpass in one command",
      "P-task": "creat postgresl databas dump download use scp sshpass one command",
      "F_verb": "download",
      "P-body": "As pg_dump defaults to stdout as it's output file, and ssh displays the command's stdout on it's own stdout, you could do something like: .  which would save the output from the command on your local disk as andi_some_db.sql .  Depending on the size of your dump and the speed of your connection, you could perhaps benefit from pre-compressing your output: .  And so on. .  ",
      "P-tags": "scp postgresql ssh bash sshpass",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP using NP with NP in NP"
    },
    {
      "id": "ul_649636",
      "task": "How to verify fingerprint of Dropbear RSA host key?",
      "P-task": "verifi fingerprint dropbear rsa host key",
      "F_verb": "verify",
      "P-body": "Locate the host key file on the server: .  Use \"dropbearkey\" to get the public key portion and fingerprint of that host key: .  The hash algorithm will be different, depending on your version. Pipe the public key portion into \"ssh-keygen\" to use a specific hash algorithm: .  ",
      "P-tags": "ssh-keygen dropbear ssh fingerprint",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP"
    },
    {
      "id": "au_679233",
      "task": "Failed to fetch ... Hash Sum mismatch. tried rm apt/list but didn't work",
      "P-task": "fail fetch hash sum mismatch\ntri rm apt list work",
      "F_verb": "fetch",
      "P-body": "If deleting \"/var/lib/apt/lists/*\" does not work... esp. if you're behind a proxy), fix \"Hash Sum Mismatch\" like this: .  Create file /etc/apt/apt.conf.d/99fixbadproxy with this content .  See also here .  ",
      "P-tags": "apt updat update-manag",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_534205",
      "task": "I see gnome-screensaver lock screen instead of unity one. What happened and how to fix it?",
      "P-task": "see gnome-screensav lock screen instead uniti one\nhappen fix",
      "F_verb": "fix",
      "P-body": "It turned out that screen reader (like in my case) and on-screen keyboard can cause this. Had to disable all tools in \"System settings/Universal access\". .  ",
      "P-tags": "14 04 gnome-screensav lt unity-greet",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "ul_460030",
      "task": "Is it safe to use echo to pass sensitive data into chpasswd?",
      "P-task": "safe use echo pass sensit data chpasswd",
      "F_verb": "use",
      "P-body": "Your code should be safe as \"echo\" won't show up in the process table since it's a shell built-in. .  Here's an alternative solution: .  This creates your student names and passwords, \"n\" of them, without passing any passwords on any command line of any command. .  The \"paste\" utility glues together several files as columns and inserts a delimiter in-between them. Here, we use \":\" as the delimiter and give it two \"files\" (process substitutions). The first one contains the output of a \"seq\" command that creates 20 student usernames, and the second contains the output of a pipeline that creates 20 random strings of length 13. .  If you have a file with usernames already generated: .  These will save the passwords and usernames to the file \"secret.txt\" instead of showing the generated passwords in the terminal. .  ",
      "P-tags": "password secur bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF into NP"
    },
    {
      "id": "so_16128638",
      "task": "How to launch a .vbs or Window powershell every time my application like notepad, esclipe starts",
      "P-task": "launch vb window powershel everi time applic like notepad esclip start",
      "F_verb": "launch",
      "P-body": "You can create an event listener and launch your vbs file when notepad starts: .  ",
      "P-tags": "registri window vbscript powershel alternate-data-stream",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "au_864574",
      "task": "Is Ubuntu Server required for LAMP server or will anything break if I install LAMP on Ubuntu Desktop?",
      "P-task": "ubuntu server requir lamp server anyth break instal lamp ubuntu desktop",
      "F_verb": "require",
      "P-body": "No, Ubuntu Server is not needed. .  You can very easily install all of the required packages for a LAMP server from Ubuntu Desktop. In fact, most web developers use this exact setup to test things! .  As mentioned in the question you linked, you can install a LAMP stack with two commands: .  You may need to check some other things to make sure that there's nothing else bound on any ports, but (typically) there are no additional steps that are needed. If you want to access your server from the world, you need to set up port-forwarding and probably unblock port 80/443 in your firewall. .  However, if you're running a LAMP server on your own system, it is highly recommended to run a firewall on your upstream router or your machine itself, as well as working through (at least, partially) the Ubuntu Wiki's Security guide. LAMP is not the most secure thing in the world. It's important to set up some best-practice topics to make sure your system stays safe, as well. .   As mentioned in your question, you can also install the LAMP stack using: .  If you want to determine what packages will be installed/altered (just to be safe), you can run the above command with the \"-s\" flag to simulate what will happen to your system. .  ",
      "P-tags": "14 04 lamp webserv server",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP if S"
    },
    {
      "id": "su_311027",
      "task": "How to use RSYNC to get unchanged files hard-linked and appended files copied locally + appended?",
      "P-task": "use rsync get unchang file hard-link append file copi local + append",
      "F_verb": "use",
      "P-body": "Well, I didn't think I was going to be able to accomplish this until I recently discovered a nifty trick you can do with rsync, and since nobody has answered in a while I'll present my solution. .  The trick is when you use the following arguments: .  This causes rsync to backup files before modifying them, but the backups turn out to be in-place, so you're actually making copies of the files before modifying them. This allows you to change files that were hard-linked with out changing the originals. .  Then, the sequence to accomplish the desired behavior could be the following: .  This probably could be solved with the first two steps without using filters but in my particular use case to guarantee coherence in the final destination I need the mutable files transfered before the immutable ones, and the default alphabetic ordering done by rsync does not guarantee this in my case. The reason why I need that is that the mutable files may get deleted and replaced by an immutable file. If I didn't transfer the immutable file because it didn't exist at the moment, but the mutable disappears before I get to it, I'm left with neither and I loose data. .  ",
      "P-tags": "command-lin file-transf linux sync rsync",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_57618731",
      "task": "How to move files to Folder and Sub folder based on file name using Powershell?",
      "P-task": "move file folder sub folder base file name use powershel",
      "F_verb": "move",
      "P-body": "\"$files\" is named appropriately plural as a variable that could contain many files. But when you go to retrieve the date parts, you use call it once, on the whole collection of files, instead of on each individual \"$file\" (which is the variable you have inside the loop which iterates over the collection of files). .  So you want to set the date variables inside the loop, on every iteration, so that it's related to the current file. .  Also the pattern you laid out in your question doesn't seem to be what you're setting, so I'm a little confused how your output looks like it does. .  What you have here: .  Should produce: \"C:\\Archive\\201908\\22\" even though you want \"C:\\Archive\\2019\\201908\\22\". .  To produce what you wanted the line should be like this: .  By the way you can use variables directly in double-quoted strings: .  ",
      "P-tags": "directori powershel subdirectori",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP on NP using NP"
    },
    {
      "id": "au_25623",
      "task": "How can I make a live CD/DVD from my harddisk installation?",
      "P-task": "make live cd dvd harddisk instal",
      "F_verb": "make",
      "P-body": "I just made one for myself a few hours ago! I used RemasterSys. The steps to install are given on the page. After installing it, you can type the following commands on a terminal: .  \"sudo remastersys dist my-hd.iso\" .  to create a distributable image named my-hd.iso. You can burn this on a DVD and share it around. Just make sure you have removed crud like cached packages, unused config files. On a terminal type  .  \"sudo apt-get autoremove && sudo apt get autoclean\"  .  Again, if you are not a commandline guy, install Ubuntu Tweak to clean old packages, kernels and other crud from your system. .  If comamnd line isnt for you, then you can goto Gnome Menu > Admninistration > Remastersys Backup. .  There is also a guide given on Ubuntu.com, if you are willing to DIY. .  ",
      "P-tags": "boot updat package-manag cd",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP from NP"
    },
    {
      "id": "so_7340261",
      "task": "Converting a shell file to a windows batch file",
      "P-task": "convert shell file window batch file",
      "F_verb": "convert",
      "P-body": "You mean a Windows batch file, right? If so, you should specify that in your question. .  I don't have a complete answer, but I can give a few syntax tips. .  \"p=.\" should be changed to \"set p=.\". .  \"$p\" should be changed to \"%p%\". .  To execute multiple commands on a line, separate them with \"&\" rather than \";\" (or, better yet, just write one command per line). .  Windows uses \"\\\" rather than \"/\" as a directory separator. .  The files are probably going to be in different locations, if they exist at all. This assumes you're taking a \".sh\" file from a Unix-like system and creating a \".bat\" file for a Windows system. If they're both the same system (probably because you're using Cygwin), you should mention that as well. .  There is no straightforward way to translate a shell script to a batch file. They're going to be running on different systems. If you have no idea how to do it, your best bet is to find someone who does. .  ",
      "P-tags": "batch-fil shell",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "au_492357",
      "task": "Is there a command to pause the native Ubuntu sound player?",
      "P-task": "command paus nativ ubuntu sound player",
      "F_verb": "pause",
      "P-body": " If you need command-line access, you can talk to it directly over DBUS. Here's an example I stole from Fran Di\u00e9guez: .  To pause: .  Or to toggle: .  For more commands, see the MPRIS2 Player specifications. .   Taken from Oli's answer to this question. .  ",
      "P-tags": "vlc sound rhythmbox pulseaudio",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "ul_247999",
      "task": "How to prevent random console output from breaking the terminal?",
      "P-task": "prevent random consol output break termin",
      "F_verb": "prevent",
      "P-body": "No: .   there is no standard way to \"disable it\", and the details of breakage are actually terminal-specific, but there are some commonly-implemented features for which you can get misbehavior.  For commonly-implemented features, look to the VT100-style alternate character set, which is activated by \"^N\" and \"^O\" (enable/disable). That may be suppressed in some terminals when using UTF-8 mode, but the same terminals have ample opportunity for trashing your screen (talking about GNU screen, Linux console, PuTTY here) with the escape sequences they do recognize. .  Some of the other escape sequences for instance rely upon responses from the terminal to a query (escape sequence) by the host. If the host does not expect it, the result is trash on the screen. .  In other cases (seen for instance in network devices with hardcoded escape sequences for the Linux console), other terminals will see that as miscoded, and seem to freeze. .  So... you could focus on just one terminal, prune out whatever looks like a nuisance (as for instance, some suggest removing the ability to use the mouse for positioning in editors), and you might get something which has no apparent holes. But that's only one terminal. .  ",
      "P-tags": "termin output escape-charact",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from NP"
    },
    {
      "id": "au_367657",
      "task": "Lenovo Ideapad p500 having Windows 8 booting issues. Boot repair pastebin included!",
      "P-task": "lenovo ideapad p500 window 8 boot issu\nboot repair pastebin includ",
      "F_verb": "include",
      "P-body": "Turn off \"UEFI\" which prevents Windows Os from booting. .  ",
      "P-tags": "windows-8 lenovo ideapad 13 10",
      "source": "qa",
      "cate": "import/include",
      "pat": "V"
    },
    {
      "id": "ul_46286",
      "task": "Read and confirm shell script before piping from curl to sh (curl -s [url] | sh)",
      "P-task": "read confirm shell script pipe curl sh curl -s url sh",
      "F_verb": "confirm",
      "P-body": "There is a utility in \"moreutils\" called \"vipe\" that shows stdin in an editor, where you can revew and modify the file before it gets passed on to stdout. .  If you don't want to install \"moreutils\", you can accomplish something similar like so: .  \"mktemp\" is in \"coreutils\" and is very likely already installed on your system. .  ",
      "P-tags": "secur curl command-lin bash",
      "source": "qa",
      "cate": "confirm/ensure",
      "pat": "V NP before S"
    },
    {
      "id": "ul_76919",
      "task": "Identify Tasks/Process which are 7 days old in linux",
      "P-task": "identifi task process 7 day old linux",
      "F_verb": "identify",
      "P-body": "Here's a start: .  You can select whatever information you want to display, see \"man ps\" for the long, long list. The above command lists all processes sorted in descending order by elapsed time. If you want to only display the processes which have been running at least seven days, you'll need to do something with \"grep\" or \"awk\"; in that case, you might just want to print out the \"etime\" and the \"pid\" since you can later on print out whatever data you want on the specific processes. .  Unfortunately, the \"etime\" format is more designed for people than for scripts, but the following should work (although I haven't tested it): .  Brief explanation of command line options: .  ",
      "P-tags": "linux process bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP which S"
    },
    {
      "id": "au_350353",
      "task": "Can't mount external usb driver on Ubuntu 12.04",
      "P-task": "mount extern usb driver ubuntu 12 04",
      "F_verb": "mount",
      "P-body": "When Linux tries to mount your USB drive it tries to guess the correct file system (NTFS in this instance) in the same way that blkid does, unless there you tell it to use a specific file system as in your \"/etc/fstab\": .  Pay attention to the 1st and 3rd column! .  You can work around this manually with the mount command: .  A cleaner way would be to replace all instances of \"/dev/sd*\" by device UUIDs\u00b9, labels, or IDs, because the latter are stable for each device or file system. The former are assigned in the order Linux sees them, which can change especially for removable media. .  In most cases you don't want to assign fixed fstab entries for removable media though, only disks inside your computer. .  \u00b9 \"blkid\" or \"palimpsest\" can tell you device UUIDs .  Take a look at the \"swap\" line in your or an excerpt from my \"/etc/fstab\" for an example: .  and .  ",
      "P-tags": "mount 12 04 usb",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP on NP"
    },
    {
      "id": "au_975111",
      "task": "find: paths must precede expression: )xargs",
      "P-task": "find : path must preced express : xarg",
      "F_verb": "find",
      "P-body": "\"xargs\" attempts to construct an argument list from its stdin (standard input). Often, the stdin of \"xargs\" is the output of some command that has been piped to \"xargs\". To create a useless example, we can waste a lot of characters listing the files in our home directory, instead of just typing \"ls -A ~\" like this: .  The pipe operator \"|\" takes the stdout (standard output) of the command to the left of it, and passes it as the stdin of the command to the right of it. It's important to remember that stdout is just a stream of text, which may cause problems when passed to the second command by \"xargs\" if it contains spaces or special characters. When we use \"find\", whose output is filenames, with \"xargs\", to avoid errors caused by special characters, we conventionally use .  This causes \"find\" to append the null character to each filename and \"xargs\" to interpret the list as null-delimited instead of space-delimited. The null character cannot appear in filenames, so there is no chance that a filename will be interpreted as two filenames if we delimit with the null character. .  Since you missed out the pipe character \"|\" that separates and connects the two commands \"find\" and \"xargs\", \"find\" thought that \")xargs\" was one of its arguments, and since it did not begin with \"-\" or follow a valid test beginning with \"-\", it decided that \")xargs\" must be a path you want to search, but \"paths must precede expression\", the syntax of \"find\" requires the path to search to be given before other arguments. .  Many people prefer to use \"-exec\" with \"find\" instead of piping to \"xargs\" (see What is the difference between find with -exec and xargs?), for example: .  This may be more suitable in your case, particularly since the \"mv\" command expects its last argument to be the destination. You could use \"xargs -I {} mv {} /path/to/destination\" but it would be more readable and perhaps more efficient to specify the destination with \"-t\" .  ",
      "P-tags": "xarg command-lin directori find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_24041752",
      "task": "Get GCC to use AVX in 32-bit code (-m32)?",
      "P-task": "get gcc use avx 32-bit code -m32",
      "F_verb": "get",
      "P-body": "From the GCC 4.8.3 manual: .   -m32 -m64 -mx32 .  Generate code for a 32-bit or 64-bit environment. The -m32 option sets int, long, and pointer types to 32 bits, and generates code that runs on any i386 system. The -m64 option sets int to 32 bits and long and pointer types to 64 bits, and generates code for the x86-64 architecture. For Darwin only the -m64 option also turns off the -fno-pic and -mdynamic-no-pic options. .  The -mx32 option sets int, long, and pointer types to 32 bits, and generates code for the x86-64 architecture. .   The closest you're going to get to \"-m32\" with AVX instructions is using \"-mx32\" in it's place , but it might not be what you want. .  ",
      "P-tags": "linux gcc compiler-optim c avx",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_INF in NP"
    },
    {
      "id": "ul_543531",
      "task": "How to make sure the Bomgar remote client is uninstalled",
      "P-task": "make sure bomgar remot client uninstal",
      "F_verb": "make",
      "P-body": "The software is installed to a custom directory (\"--install-dir\"); the way to remove it, based on their documentation, is to run their \"uninstall\" script: .  (or) .  The uninstall script checks whether stdout is a tty (\"[ -t 1 ]\"); if it is, then it sends a confirmation prompt. The first command above will send a \"y\" to that prompt. If the script determines that stdout is not a tty, it skips the prompt; the second command above redirects stdout to a log file to achieve that. .  ",
      "P-tags": "remote-desktop",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S"
    },
    {
      "id": "so_9434831",
      "task": "how to store the result of sed in variable with the new line characters",
      "P-task": "store result sed variabl new line charact",
      "F_verb": "store",
      "P-body": "The newline is there, you just need to quote the variable properly to see it. \"echo\" is not a very good command for inspecting your variables,but this should work like you want: .  ",
      "P-tags": "sed script shell bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP of NP in NP with NP"
    },
    {
      "id": "ul_607354",
      "task": "Search a string after a match",
      "P-task": "search string match",
      "F_verb": "search",
      "P-body": " We just count that BIOS went past, and trigger on the Version line. .  As the BIOS is the first block (on my system), and grep has a max-count option, this should also work .  ",
      "P-tags": "command-lin search",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP after NP"
    },
    {
      "id": "su_257652",
      "task": "Less hotkeys not working, printing keycodes instead performing action",
      "P-task": "less hotkey work print keycod instead perform action",
      "F_verb": "perform",
      "P-body": "\"php -i\" is doing something weird with stdin. Try this: .  ",
      "P-tags": "termin linux less hotkey fedora",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_1288800",
      "task": "add path permenantly on ubuntu for postgresql user",
      "P-task": "add path permenantli ubuntu postgresql user",
      "F_verb": "add",
      "P-body": "Add your path change to .bashrc perhaps .  Notice there is no export or other fancy stuff in the line .  ",
      "P-tags": "postgresql python server bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP for NP"
    },
    {
      "id": "so_67122659",
      "task": "Reading zip file in Powershell (openread)",
      "P-task": "read zip file powershel openread",
      "F_verb": "read",
      "P-body": "Change \"$Myzipfile\" to \"$Myzipfile.FullName\": .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP in NP"
    },
    {
      "id": "su_702403",
      "task": "How to configure maven to use -source 5 or higher to enable annotations?",
      "P-task": "configur maven use -sourc 5 higher enabl annot",
      "F_verb": "configure",
      "P-body": "You need to modify your \"pom.xml\" and configure the maven compiler plugin. .  Example: .  ",
      "P-tags": "maven linux java",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF S_INF"
    },
    {
      "id": "so_70226713",
      "task": "How do I get next week number in Bash?",
      "P-task": "get next week number bash",
      "F_verb": "get",
      "P-body": "To get the next week number use: .  Adding \"1\" to current week number will give wrong result of \"53\" for the last week of the year. .  On the other hand, above command will give \"1\" for the same case because we are adding \"1 week\" in the current date and then getting week number. .  ",
      "P-tags": "week-numb date bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1368579",
      "task": "How to kill firefox from command line",
      "P-task": "kill firefox command line",
      "F_verb": "kill",
      "P-body": "tl;dr: \"pkill -f firefox\" does the trick. .  I found this in the \"pkill/pgrep\" manpages: .   The process name used for matching is limited to the 15 characters present in the output of /proc/pid/stat. Use the -f option to match against the complete command line, /proc/pid/cmdline. .   With \"/usr/lib/firefox/firefox\" having PID \"691953\" when testing locally on my machine, I found the following in \"/proc/691953/stat\": .  Doing a \"pkill GeckoMain\" killed firefox as promised. \"killall GeckoMain\" works too. .  The simplest workaround is probably to supply the \"-f\" flag to \"pkill\" to match against \"/proc/<pid>/cmdline\", which in my case contained \"/usr/lib/firefox/firefox\". .  ",
      "P-tags": "firefox kill",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from NP"
    },
    {
      "id": "so_24804026",
      "task": "ImageMagick using convert and rename output",
      "P-task": "imagemagick use convert renam output",
      "F_verb": "rename",
      "P-body": "you probably want to run convert in a loop, like .  consider also this little \"trick\" for renaming: .  ",
      "P-tags": "imagemagick linux bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_18039573",
      "task": "Prompt user for input then add and subtract in the corresponding field",
      "P-task": "prompt user input add subtract correspond field",
      "F_verb": "subtract",
      "P-body": "I don't like the mix of shell and Perl in the code, but that's apparently for pedagogical reasons so we have to ignore it. .  Apart from renaming \"pattern\" to \"title\" and \"pattern1\" to \"author\", this code passes the shell variable \"$cpySold\" to the Perl. It also uses a simpler method of retrieving the first three arguments (simply capture the value from \"shift\"). The \"split\" is the same as before. It isn't entirely clear what the format in the data file is since the printed formats use commas rather than colons to separate the fields. .    I simply want the values from new book info to replace current book info in the \"BookDB.txt\" file. .   I'm not convinced this is doing you any favours (you won't learn much unless you try doing it yourself), but ... .  This doesn't pester me with typing the title, author or number of copies sold. You can reinstate those lines if you wish, but the function is probably more useful if it takes the arguments. It is often good to separate user interaction from code that operates on files.) I've used the correct author name (unless you want to use Dodgson as the real name of the author who used the pseudonym Lewis Carroll). The Perl script uses the \"-i\" option to overwrite the input files. It uses the \"English\" module so it can set \"$OFS\" and \"$ORS\". It writes debug information to STDERR (otherwise, it would be part of the information written to the file). .  When the file was called \"pbs2.sh\", a sample run of the script looked like: .  Clearly, this wasn't the first time I'd run the script, and at times I used values other than 3 for the number of copies sold. .  With explicit file management, you can write: .  Sample run: .  ",
      "P-tags": "perl bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V in NP"
    },
    {
      "id": "so_4658128",
      "task": "Run shell command from child shell",
      "P-task": "run shell command child shell",
      "F_verb": "run",
      "P-body": "You can setup in a group, like. .  ( and ) creates a subshell in which you run a group of commands, otherwise a simple function will do. I don't know if ( and ) is POSIX compatible. .  Update: If I understand your comment correctly, you want to be using \"-c\" option with \"bash\", like. .  ",
      "P-tags": "script unix shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "au_72982",
      "task": "Disable ATI Radeon HD 6950 In ubuntu, not in BIOS?",
      "P-task": "disabl ati radeon hd 6950 ubuntu bio",
      "F_verb": "disable",
      "P-body": "You have to \"blacklist\" the device such that it is not activated when you boot into linux. This is done by adding the device to this file /etc/modprobe.d/blacklist.conf. To find out which module you have to put there search with \"lsmod | grep -e radeon -e ati\". .  ",
      "P-tags": "graphic multiple-monitor ati",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP in NP"
    },
    {
      "id": "so_43407748",
      "task": "Read a file or read a standard user input",
      "P-task": "read file read standard user input",
      "F_verb": "read",
      "P-body": "The problem comes from the fact that you always give $FILE as input to your read. You could try redirecting the file to channel 0 when you have an argument and leave it to stdin otherwise. .  \"exec 0< \"$FILE\"\" tells the shell to use $FILE as input for channel 0. Reminder: by default \"read\" listens to channel 0. .  \"0<\" is the key here, where \"0\" indicates channel 0 and \"<\" indicates this is an input. When there is no argument, \"exec 0< \"$FILE\"\" will not be called, in this case channel 0 will use stdin. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_51304350",
      "task": "Retrieve each IP address of Azure web apps",
      "P-task": "retriev ip address azur web app",
      "F_verb": "retrieve",
      "P-body": "This seems to work for your case. not exactly a beatiful solution, but it gets the job done. .  ",
      "P-tags": "azur powershel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP of NP"
    },
    {
      "id": "au_1369636",
      "task": "SSD NVME M.2 not detected on Ubuntu 21.10 during installation",
      "P-task": "ssd nvme 2 detect ubuntu 21 10 instal",
      "F_verb": "detect",
      "P-body": "After some trial and error, the NVME drive was properly detected on Ubuntu 20.04 and 21.04. It is only not working on the latest 21.10 with default kernel version (5.13), while if I use an older one (5.11) it is working fine even on 21.10. I would say that the original issue is solved then, but unfortunately the wifi card (intel AX1675X) was still not working on any version... It turns out that installing \"backport-iwlwifi-dkms\" fixed this last issue. So now it is all good ! .  ",
      "P-tags": "msi nvme",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V on NP during NP"
    },
    {
      "id": "so_39608631",
      "task": "Call a python process inside bash, then capture output into a variable",
      "P-task": "call python process insid bash captur output variabl",
      "F_verb": "call",
      "P-body": "To get the result of a command in a variable, you need to use backticks (`) instead of simple quotes ('), or the \"$()\" idiom: .  or .  without spaces around the equal sign .  ",
      "P-tags": "linux python output shell bash",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_22003260",
      "task": "Finding all PHP files within a certain directory containing a string",
      "P-task": "find php file within certain directori contain string",
      "F_verb": "find",
      "P-body": " The \"-exec\" option to \"find\" executes a command on the files found. \"{}\" is replaced by the filename, and the \"+\" means that it should keep repeating this for all the filenames. \"grep\" looks for a string in the file, and the \"-l\" option tells it to print just the filename when there's a match, not all the matching lines. .  If you're getting an error from \"find\", you may have an old version that doesn't support the \"+\" feature of \"-exec\". Use this command instead: .  \"xargs\" reads its standard input and turns them into arguments for the command line in its arguments. .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP within NP"
    },
    {
      "id": "ul_155303",
      "task": "GNOME 3 - bottom panel is hiding - how to unhide it or change behaviour",
      "P-task": "gnome 3 - bottom panel hide - unhid chang behaviour",
      "F_verb": "hide",
      "P-body": "Moving mouse to bottom of the screen is usually enough to show bottom panel. Just move the mouse to bottom and a little bit more down ;) I know, sometimes it doesn't work for the first time. Second way is to use keyboard shortcut \u2013 \"windows key (left to the left alt) + m\". Panel is not supposed to hide automatically, so clicking away from it's area or another wk+m will hide it. .  ",
      "P-tags": "debug gnome-panel gnome3",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V S_INF"
    },
    {
      "id": "so_8512231",
      "task": "Receive Unix Timestamp and convert time to milliseconds WP7",
      "P-task": "receiv unix timestamp convert time millisecond wp7",
      "F_verb": "receive",
      "P-body": "Unix generally stores time as either seconds, or a \"struct timespec\" that contains both seconds and microseconds for further precision. When referring to dates, it is the number of seconds (or seconds and microseconds) elapsed since January 1, 1970. .  However, these are never referred to as \"ticks\". \"Ticks\" generally refer to the Windows/.NET style time units - a \"tick\" is equal to 100 nanoseconds. When referring to dates, it is the number of hundred nanosecond units that have elapsed since January 1, 0001. .  If you have an object with \"ticks\", then yes, simply dividing by 10000 will convert the units to milliseconds. Alternately, you can use a \"TimeSpan\": .  ",
      "P-tags": "timestamp unix windows-phone-7",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_240476",
      "task": "How do I write the output of Portage to a txt file?",
      "P-task": "write output portag txt file",
      "F_verb": "write",
      "P-body": "You're on the right track. In Unix/Linux there's also an error stream. Every command gets standard input, standard output, and standard error. .  You've been working with standard output. To also capture the standard error stream from the command use \"2>\". For example: .  Now if you want the standard output and error to go into the same file, use \"2>&1\" to tell the shell to send the standard error output to the same place as the standard output: .  Also, if you need to reference and learn more, you can always look this up in the shell man page \"man sh\". .  Thanks for the informative and well-thought question! .  ",
      "P-tags": "output shell-script tti cat",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "au_1109736",
      "task": "Update Ubuntu 16.04.3 LTS to Ubuntu 16.04.5 LTS",
      "P-task": "updat ubuntu 16 04 3 lt ubuntu 16 04 5 lt",
      "F_verb": "update",
      "P-body": "Point release upgrades (16.04.x to 16.04.y) are generally applied automatically whenever you update and upgrade the system from either \"Software Updater\" app or terminal/command line. To update from terminal/command line, run: .  To check which version you are currently using, either go to Settings \u2192 Details or open terminal and run: .  ",
      "P-tags": "upgrad 16 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP to NP"
    },
    {
      "id": "au_945438",
      "task": "Using the find command with the -cnewer test",
      "P-task": "use find command -cnewer test",
      "F_verb": "use",
      "P-body": "From the manual (bold mine): .   \u2014 Test: \"-anewer\" file \u2014 Test: \"-cnewer\" file \u2014 Test: \"-newer\" file True if the file was last accessed (or its status changed, or it was modified) more recently than file was modified. [...] .   So the tests compare the atime, ctime and mtime respectively with the mtime of the specified file. .  If you want to compare ctime with ctime, then use the \"-newerXY\" tests: .  So, the \"-*newer\" tests are shorthand for \"-newer*m\". .  ",
      "P-tags": "find",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_511393",
      "task": "Return the next 50 characters after a string is found in a file",
      "P-task": "return next 50 charact string found file",
      "F_verb": "return",
      "P-body": "I dont know if it's the best idea to parse html like you are trying to, but anyways, this works, if you have linebreaks, if you dont, you can remove the tr part :  .  So, tr will get rid of the linebreaks, to treat everything as one line string. .  awk -F sets the delimiter to the tag, print $2 , prints the part after the delimiter .  and cut -c -50 prints only the first 50 chars .  ",
      "P-tags": "html shell-script text-process",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP after S"
    },
    {
      "id": "ul_144518",
      "task": "Pass argument to script, then redirect script as input to bsub",
      "P-task": "pass argument script redirect script input bsub",
      "F_verb": "redirect",
      "P-body": "It seems applying a command line argument to a bsub file is a very complicated process. I tried the HEREDOC method stated by mikeserv, but bsub acted as if the script filename was a command. So the easiest way to get around this problem is just to not use input redirection at all. .  Since my question specifically involved bsub for Platform LSF, the following is probably the best way to solve this sort of argument problem: To pass an argument to a script to be run in bsub, first specify all bsub arguments in the command line rather than in the script file. Then to run the script file, use .  after all of the bsub arguments. Thus the entire line will look something like: .  In this case, it is better to not use .bsub files for the script and use a normal .sh script instead and use the Unix sh command to run it with arguments. .  ",
      "P-tags": "script argument io-redirect platform-lsf",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP as NP to NP"
    },
    {
      "id": "ul_636204",
      "task": "Find all executable files excluding certain directories",
      "P-task": "find execut file exclud certain directori",
      "F_verb": "find",
      "P-body": "Assuming GNU \"find\" and the \"bash\" shell (as is used in the question), this is a short script that would accomplish what you're trying to do: .  This first creates the array \"args\", consisting of dynamically constructed arguments to \"find\". It does this by splitting the value of \"$PATH\" on colons, the value that we've given to the \"IFS\" variable. The splitting is happening when we use \"$PATH\" unquoted in the loop header. .  Ordinarily, the shell would invoke filename globbing on each of the words generated from the splitting of \"$PATH\", but I'm using \"set -f\" to turn off filename globbing, just in case any of the directory paths in \"$PATH\" contains globbing characters (these would still be problematic as the \"-path\" operand of \"find\" would interpret them as patterns). .  If my \"PATH\" variable contains the string .  then \"args\" will be the following list (each line here is a separate element in the array, this is not really a set of strings with newline characters in-between them): .  This list is slotted into the \"find\" command invocation, in parentheses. There is no need to repeat \"-prune\" for each and every directory, as you could just use it once as I have above. .  I've opted for pruning any non-executable or non-readable directory. This ought to get rid of a lot of permission errors for directories that you can't access or list the contents of. Would you want to simplify the \"find\" command by removing this bit, use .  Also, I'm running \"file\" on the found pathnames in batches, rather than once per pathname. .  ",
      "P-tags": "execut find bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_13386105",
      "task": "Powershell Get-childitem returns \"Cannot find path\" for UNC value from XML",
      "P-task": "powershel get-childitem return find path unc valu xml",
      "F_verb": "get",
      "P-body": "The reason you are getting an error is because the type of $rootBuildPath when you get it from the xml file is string. This results in the equivalent of calling  .  which will throw the exception you are seeing. The reason it doesn't throw an error when you run  .  from the command line is powershell is parsing the path as a path first before handing it to the Get-ChildItem commandlet. .  In order to make your code work, you must remove the errant '`' from the path before calling Get-ChildItem. .  ",
      "P-tags": "unc powershel xml",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP from NP"
    },
    {
      "id": "au_1296801",
      "task": "How to install parquet-tools on Ubuntu 18.04 LTS without building from source",
      "P-task": "instal parquet-tool ubuntu 18 04 lt without build sourc",
      "F_verb": "install",
      "P-body": "So I finally managed to compile from source. .  TL;DR  Compile \"trift\" with \"--host=x86_64\". Use \"apache-parquet-1.11.11\" tag on parquet-mr repo instead of \"master\". Update trift dependency version from 12 to 13 in \"parquet-mr/pom.xml\" and add maven central repo (\"codehaus\" is dead):   ",
      "P-tags": "apache2 software-instal compil",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP without S_ING"
    },
    {
      "id": "so_46311141",
      "task": "How to insert text in a line that may have a special character with sed?",
      "P-task": "insert text line may special charact sed",
      "F_verb": "insert",
      "P-body": "Since you are adding the text at the end of the line, you don't need to put the content of the existing line in your \"sed\" expression. So, you could write your command as: .  which would work irrespective of whether the line being appended to has any special characters. .  The whole code can be written more efficiently as: .   See also: Bash tool to get nth line from a file .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP that S"
    },
    {
      "id": "so_37438922",
      "task": "Can I have a string containing a delegate that is evaluated at runtime?",
      "P-task": "string contain deleg evalu runtim",
      "F_verb": "contain",
      "P-body": "you can do .  and then later use .  (Assuming you want $script:marker to be the characters that get set later, your original example has $({script:$marker}), but that won't work if it is supposed to do what I think it should ;)) .  In general: Define the term as Scriptblock using {} and later .invoke() to evaluate it. .  Just make sure there is no confusion about the types within the curly brackets, otherwise you might get some strange results... .  ",
      "P-tags": "powershel powershell-4 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP that S"
    },
    {
      "id": "so_11745507",
      "task": "Preparing a Perl file to run with Ubuntu and tabix",
      "P-task": "prepar perl file run ubuntu tabix",
      "F_verb": "prepare",
      "P-body": " If that gives one--and only one line--you can do this: .  ",
      "P-tags": "vcftool vcf-variant-call-format ubuntu bioinformat perl",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V NP S_INF with NP"
    },
    {
      "id": "su_1450004",
      "task": "My atom editor is not responding when i open new project file. But it works fine in safe mode",
      "P-task": "atom editor respond open new project file\nwork fine safe mode",
      "F_verb": "respond",
      "P-body": "I solved this..  I just uninstall \"atom-beta\" and remove the folder \".atom\" and I install it again.  My problem is gone.. ",
      "P-tags": "kali-linux freez crash atom-editor",
      "source": "qa",
      "cate": "respond",
      "pat": "V when S"
    },
    {
      "id": "su_438750",
      "task": "CentOS 6, add user to folder",
      "P-task": "cento 6 add user folder",
      "F_verb": "add",
      "P-body": "Create a FTP user group. eg: ftpaccounts  .  Add a new user to this group, and set the default path of that user to /home/user/.  .  Set a password for the newly created user.  .  Set ownership of /home/user to the testuser and ftpaccounts.  .  Give Read/Write access to testuser and all members in ftpaccounts  .  ",
      "P-tags": "cento linux",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_1123634",
      "task": "How do I dynamically create functions that are accessible in a parent scope?",
      "P-task": "dynam creat function access parent scope",
      "F_verb": "create",
      "P-body": "The other solutions are better answers to the specific question. That said, it's good to learn the most general way to create global variables: .  Read 'help about_Scopes' for tons more info. .  ",
      "P-tags": "powershel dynam function scope",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP that S"
    },
    {
      "id": "so_64931488",
      "task": "Show two things side by side using catimg (like in neofetch)",
      "P-task": "show two thing side side use catimg like neofetch",
      "F_verb": "show",
      "P-body": "Produce txt file by merging ouput of \"catimg\" and \"figlet\" Instead of real merge, I will simply put both output at correct place by using ANSI escape code .   .  This could be written as a function: .  And reversed: .  (Nota: This work while catimg length stay bigger than figlet length) .   .  From there, regarding your comment: try using \"42%\" of 80 columns width for image: .  or .  Will render: .   .  Then you could try using \"-f smblock\" option, or modify functions to use \"toilet\" instead of \"figlet\"... .  ",
      "P-tags": "script cat bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP using NP"
    },
    {
      "id": "so_33468740",
      "task": "Get a list of all members from Sharepoint 365",
      "P-task": "get list member sharepoint 365",
      "F_verb": "get",
      "P-body": "You are getting this error since the command: .  throws exception if the connection has not been established. Having said that, you could consider the following solutions: .  Solution 1 .  Use \"-InputObject\" parameter: .   Specifies the object whose members are retrieved. Using the InputObject parameter is not the same as piping an object to Get-Member. The differences are as follows: .  -- When you pipe a collection of objects to Get-Member, Get-Member gets the members of the individual objects in the collection, such as the properties of each string in an array of strings. .  -- When you use InputObject to submit a collection of objects, Get-Member gets the members of the collection, such as the properties of the array in an array of strings. .   Solution 2 .  Since \"Get-MsolUser\" cmdlet requires the connection to be established, execute the command \"Connect-MsolService\" first and then: .  ",
      "P-tags": "sharepoint-2013 powershell-3 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_64401564",
      "task": "Kivy app can't find/read my txt file in root directory Android",
      "P-task": "kivi app find read txt file root directori android",
      "F_verb": "find",
      "P-body": "In your \"buildozer.spec\" file modify the line: .  to: .  And verify that you have not excluded \"txt\" files elsewhere in the \"spec\" file. .  ",
      "P-tags": "android linux kivi buildoz python",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_12590750",
      "task": "Editing files in ubuntu with php or other language",
      "P-task": "edit file ubuntu php languag",
      "F_verb": "edit",
      "P-body": "You mean through some kind of web interface that you are creating? Look into the \"shell_exec\" function. You can use it to create folders like \"shell_exec('mkdir foldername')\" and \"shell_exec('/etc/init.d/apache2 restart')\" .  ",
      "P-tags": "ubuntu python php",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "au_106505",
      "task": "How to cancel holding of a package",
      "P-task": "cancel hold packag",
      "F_verb": "cancel",
      "P-body": "Some packages (like the kernel) can only be upgraded with \"sudo apt-get dist-upgrade\". .  For pinned packages, have a look at the \"/etc/apt/preferences\" file and the files in the \"/etc/apt/preferences.d\" directory. Usually the file and directory is empty unless you've manually set values. Removing a file will then remove the pin. .  ",
      "P-tags": "apt package-manag",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP of NP"
    },
    {
      "id": "su_1658728",
      "task": "Some Services Not Showing With Get-Service cmdlet in Powershell",
      "P-task": "servic show get-servic cmdlet powershel",
      "F_verb": "show",
      "P-body": "Stupid mistake. I was filtering for a common word using the \"-Name\" parameter, when what I wanted was \"-Displayname\". .  ",
      "P-tags": "powershel window servic",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V with NP in NP"
    },
    {
      "id": "so_699785",
      "task": "Edit very large sql dump/text file (on linux)",
      "P-task": "edit larg sql dump text file linux",
      "F_verb": "edit",
      "P-body": "Rather than removing the first few lines, try editing them to be whitespace. .  The \"hexedit\" program can do this-- it reads files in chunks, so opening a 10GB file is no different from opening a 100KB file to it. .  ",
      "P-tags": "linux large-fil mysqldump",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_82242",
      "task": "How to enable WebGL in Chrome or Firefox?",
      "P-task": "enabl webgl chrome firefox",
      "F_verb": "enable",
      "P-body": "Well, according to the WebGL public wiki, both firefox and chrome support WebGL with Nvidia GPUs in X11/Linux. .  In my case the wrong graphic driver was selected. .  Setting it back to nvidia fixed my issues with WebGL. .  ",
      "P-tags": "driver plugin opengl browser",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_513225",
      "task": "How can you move hardlinks to another disk",
      "P-task": "move hardlink anoth disk",
      "F_verb": "move",
      "P-body": "\"rsync\" is able to copy hard links for you. Check \"-H\" option: .  ",
      "P-tags": "linux hard-link",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP"
    },
    {
      "id": "au_252163",
      "task": "How to monitor USB webcam bandwidth usage?",
      "P-task": "monitor usb webcam bandwidth usag",
      "F_verb": "monitor",
      "P-body": "Use usbtop, it gives a nice overview of what devices are using how much bandwidth: .  Install and run it like so: .  ",
      "P-tags": "12 04 bandwidth usb",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "so_65363909",
      "task": "Find a line with a single word and merge it with the next line",
      "P-task": "find line singl word merg next line",
      "F_verb": "merge",
      "P-body": "If \"awk\" is acceptable: .  Where: .   \"NF==1\" - if only one name/field in the current record ... \"printf / getline / print / next\" - print field #1, read next line and print it, then skip to next line \"1\" - print all other lines as is  As a one-liner: .  This generates: .  ",
      "P-tags": "awk grep tr shell sed",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP"
    },
    {
      "id": "so_48534742",
      "task": "How can I replace 'bc' tool in my bash script?",
      "P-task": "replac bc tool bash script",
      "F_verb": "replace",
      "P-body": "In case you need a solution which works for floating-point arithmetic you can always fall back to Awk. .  Putting the code in a \"BEGIN\" block and redirecting input from \"/dev/null\" is a common workaround for when you want to use Awk but don't have a file of lines to loop over, which is what it's really designed to do. .  ",
      "P-tags": "awk linux shell bash sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_65499",
      "task": "lsof doesn't return files open by the same user",
      "P-task": "lsof return file open user",
      "F_verb": "return",
      "P-body": "When you use \"vi\"/\"vim\" to edit a file you aren't actually holding \"~/<filename>\"open you are reading the file into \"~/.<filename>.swp\" and then holding that temp file open. .  If you run \"lsof ~/.<filename>.swp\" it will show you the information you are looking for. .  NOTE: If you have multiple people editing the same file you will need to \"lsof ~/.<filename>.s*\" as each \"vi\"/\"vim\" session will create its own swap file but will name it differently .  ",
      "P-tags": "lsof vim open-fil",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP by NP"
    },
    {
      "id": "ul_130684",
      "task": "lost directory cannot find it with testdisk",
      "P-task": "lost directori find testdisk",
      "F_verb": "find",
      "P-body": "From your description it sounds like you likely dragged your files into another directory. To locate them you can wait a day and there's typically a cron job that runs on most distros that does a index of the files on your system using \"slocate\". Once this completes you can locate your files using the \"locate\" command: .  Where \"<string>\" is either the name of the directory or a file within the directory that you accidentally dragged somewhere. .  ",
      "P-tags": "directori data-recoveri move",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP"
    },
    {
      "id": "au_1106867",
      "task": "Best practice when mounting a new disk within an existing mount?",
      "P-task": "best practic mount new disk within exist mount",
      "F_verb": "mount",
      "P-body": "By definition, every mountpoint except \"/\" is within another mountpoint. Your \"/home\", for example, is a mountpoint in another mountpoint. There's nothing special about that whatsoever. This is safe, common and standard. So just create your mountpoint and add the new filesystem there. .  First, move the current contents of \"/home/mythtv\" somewhere else, then mount the new drive to the now empty \"/home/mythtv\" directory and then move the data over.  .  ",
      "P-tags": "mount filesystem disk",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP within NP"
    },
    {
      "id": "so_58915043",
      "task": "rename recursively adding parenthere if folder name ending with 4 digits in bash",
      "P-task": "renam recurs ad parenther folder name end 4 digit bash",
      "F_verb": "rename",
      "P-body": "following command: .  should work. .   double quote arround variable expansion \"${dir%[0-9][0-9][0-9][0-9]}\" to remove last 4 digits suffix \"${dir#${dir%[0-9][0-9][0-9][0-9]}}\" to remove previous prefix \"-exec bash -c '..' - {} +\" the \"-\" to skip the first argument after \"-c command\" which is taken for \"$0\", see \"man bash\" \"/-c\" \"-prune\" at the end to prevent to search in sub tree when matched, (suppose \"2004/2004\" then \"mv 2004/2004 \"2004/(2004)\"\" or mv 2004/2004 (2004)/2004' would fail)  ",
      "P-tags": "parenthes mv bash recursive-queri renam",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP if S"
    },
    {
      "id": "so_35531134",
      "task": "Get-AzureAutomationAccount returns empty collection",
      "P-task": "get-azureautomationaccount return empti collect",
      "F_verb": "get",
      "P-body": "Did you create the Automation accounts through ARM / the new (formerly preview) Azure portal (portal.azure.com) or through RDFE / ASM / the old Azure portal (manage.windowsazure.com)? If the former, the Automation accounts will not be accessible through RDFE / ASM / the old Azure portal, including via the \"Get-AzureAutomationAccount\" cmdlet. From https://azure.microsoft.com/en-us/documentation/articles/automation-configuring/#automation-accounts: .   Automation accounts, and the resources they contain, that are created with the Azure preview portal cannot be accessed in the Azure portal. If you want to manage these accounts or their resources with Windows PowerShell, you must use the Azure Resource Manager modules. .  Automation accounts created with the Azure portal can be managed by either portal and either set of cmdlets. Once the account is created, it makes no difference how you create and manage resources within the account. If you are planning to continue to use the Azure portal, then you should use it instead of the Azure preview portal to create any Automation accounts. .   If this is indeed the cause of the issue, the solution is to use the ARM cmdlets, rather than the RDFE/ASM cmdlets, to access your Automation accounts and anything within them. Ex: .  \"Add-AzureRmAccount -Credential $Cred Get-AzureRmAutomationAccount Get-AzureRmAutomationRunbook\" .  ",
      "P-tags": "azur azure-autom azure-powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_56302943",
      "task": "How to run gdb in gnome-terminal from mpirun?",
      "P-task": "run gdb gnome-termin mpirun",
      "F_verb": "run",
      "P-body": "The problem is that gnome-terminal hands over the requested program to a terminal server, and then exits immediately. mpirun then sees that the started program has exited, and destroys the MPI runtime environment. When the MPI program actually starts, mpirun has already exited. As far as I am aware, there is no way to make gnome-terminal wait until the given command has ended. .  There is a workaround: Instead of directly starting gnome-terminal with mpirun, instead have two wrapper scripts. The first is started by mpirun. It creates a temporary file, tells gnome-terminal to start the second wrapper scripts, and then waits until the temporary file has disappeared. The second wrapper script runs the command you actually want to run, e.g. \"gdb myprog\", waits until it ends, then removes the temporary file. At that point the first wrapper notices that the temporary file disappeared and exits. Then mpirun can safely destroy the MPI environment. .  This is probably easier to understand from the scripts themselves. .  debug.sh: .  helper.sh .  Run it as \"mpirun debug.sh gdb myproc\". .  ",
      "P-tags": "gnome-termin gdb openmpi bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "au_1106677",
      "task": "Where do I find the usb serial driver for cosmic?",
      "P-task": "find usb serial driver cosmic",
      "F_verb": "find",
      "P-body": "It's located in \"/lib/modules/$(uname -r)/kernel/drivers/usb/serial/usbserial.ko\" .  You have to use the \"uname -r\" command to get the release of the kernel you are running, as this may depend on when you last updated your OS, and frequently changes. .  You can insert it into the running kernel with \"sudo modprobe usbserial\". .  ",
      "P-tags": "usb",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP for NP"
    },
    {
      "id": "au_1116367",
      "task": "File system is reported full with half of it use by ecrypt and other half by the /home/user",
      "P-task": "file system report full half use ecrypt half home user",
      "F_verb": "use",
      "P-body": "After following the advice from Xen2050 I found the root of my problems. When the error occur the \"doubled\" sized did exceed the disk space, the disc is thus not full due to eCrypt virtual mounting (as expected). After investigation it appear that the disk is effectively used by the /home partition on one hand (~120G) but also by the /var/lib which contain 62G of docker libs ... .  The initial misconsception came from the output of df for the user using eCrypt which show : .  leading me to beleive that all the space was eaten by the /home/username partition .  ",
      "P-tags": "ecryptf hard-driv disk-usag",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V by NP"
    },
    {
      "id": "ul_294358",
      "task": "How to execute TMUX commands on a remote server when I have TMUX running locally too?",
      "P-task": "execut tmux command remot server tmux run local",
      "F_verb": "execute",
      "P-body": "When you have nested \"tmux\" sessions, it is the first (\"outermost\", oldest) that gets the Ctrlb+d key sequence to detach. .  You can set up \"tmux\" to send its prefix key to the \"inner\" session like this (in your \"~/.tmux.conf\"): .  This will send the prefix Ctrlb (or whatever you use as prefix) when you press Ctrlb+b, so Ctrlb+b is basically \"the prefix for the inner (of two) \"tmux\" sessions\". .  Sending Ctrlb+b+d will then detach the inner \"tmux\" session. .  Splitting the pane of the innermost session: Ctrlb+b+\" .  The above assumes two nested sessions. Detaching the innermost of three sessions: Ctrlb+b+b+d .  To simplify this, set up a separate \"prefix\" for nested sessions as explained in the answer to a similar question. .  ",
      "P-tags": "tmux",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP when S"
    },
    {
      "id": "so_28472875",
      "task": "Powershell script for going into texts files within a directory and replacing characters",
      "P-task": "powershel script go text file within directori replac charact",
      "F_verb": "go",
      "P-body": "YThis should do the trick: .  The reason yours wasn't acting as you expected it to, is because you where literally taking all the contents out of all files using get-content. This acts like a string concatenation of all text in all files. .  You first have to get a list of files, then pipe that into a foreach to get the contents per file, to then replace what you want replacing. .  ",
      "P-tags": "powershell-2 0 replac text find powershel",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V into NP within NP"
    },
    {
      "id": "so_17162521",
      "task": "How to store the value of apply-template in a variable?",
      "P-task": "store valu apply-templ variabl",
      "F_verb": "store",
      "P-body": "All you need to do is this... .  Do bear in mind though, if your template is outputting elements (as opposed to just a string value, for example), then in XSLT 1.0 you may need to use the \"node-set\" extension function to access the elements. .  ",
      "P-tags": "xslt linux",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "au_197978",
      "task": "How can I uninstall a graphics package in recover mode?",
      "P-task": "uninstal graphic packag recov mode",
      "F_verb": "recover",
      "P-body": "Start by loading the network drivers before dropping to the root shell, then reverse the installation of the Intel module: .  Do you in fact have an Intel video card? Which one. You can get some information on it from .  if you are not root when you try to do this you will need to prefix it with sudo .  ",
      "P-tags": "12 04 intel-graph",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP"
    },
    {
      "id": "so_48531541",
      "task": "Using Bash to delete a bracket delimited substring from string variable",
      "P-task": "use bash delet bracket delimit substr string variabl",
      "F_verb": "delete",
      "P-body": "Bash only: .  ",
      "P-tags": "awk centos7 shell bash sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "su_647528",
      "task": "SNMPGET/WALK Timeout on Printer",
      "P-task": "snmpget walk timeout printer",
      "F_verb": "walk",
      "P-body": "Two possible problems I see are: .   The IP address shown is \"0.0.0.0\". Is that what you're really using? I always use the actual IP address of the target. I didn't see in the man pages where \"0.0.0.0\" was valid. No version option. Try \"-v2c\" or \"-v1\".  ",
      "P-tags": "snmp printer bash",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V"
    },
    {
      "id": "so_59445351",
      "task": "Why the \"wc\" command called in the following program doesn't output any message in terminal?",
      "P-task": "wc command call follow program output messag termin",
      "F_verb": "follow",
      "P-body": "the following proposed code: .   cleanly compiles performs the desired functionality passes the name of a local file, rather than some random string AND the file name is terminated with a NUL byte you will need to modify the passed file name to a file that is in your current directory notice the length passed to \"write()\" includes the trailing NUl byte  and now the proposed code: .  Note: the \"untitled2.c\" is this source file. .  a run of the program results in: .  ",
      "P-tags": "linux c operating-system",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP in NP"
    },
    {
      "id": "so_11043560",
      "task": "how to extract certain columns of a file and save them in new file",
      "P-task": "extract certain column file save new file",
      "F_verb": "save",
      "P-body": "The script (I call it \"matmath\"): .  The data files: .  matrix: .  factors: .  Example run: .  ",
      "P-tags": "awk csh sed bash",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP"
    },
    {
      "id": "so_10512964",
      "task": "cannot find adminpack.sql in postgresql 9.1",
      "P-task": "find adminpack sql postgresql 9 1",
      "F_verb": "find",
      "P-body": "Try \"locate adminpack\". But first, run \"updatedb\" to make sure the \"locate\" database is up to date. .  The output is: .  ",
      "P-tags": "postgresql ubuntu postgresql-9 1",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_47795637",
      "task": "DscTemplate isn't executing my SetScript",
      "P-task": "dsctemplat execut setscript",
      "F_verb": "execute",
      "P-body": "Incorrect syntax (!Test-Path .  or  .  Also add \"-ErrorAction SilentlyContinue\" to your \"Test-Path\" command to suppress error. .  ",
      "P-tags": "powershel dsc",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_33656669",
      "task": "Setting path variables and running Ruby script",
      "P-task": "set path variabl run rubi script",
      "F_verb": "set",
      "P-body": " isn't how we set a PATH entry. .  The PATH is a list of directories to be searched, not a list of files. .  Typically, the PATH should contain something like: .  somewhere in it. .  If it doesn't, then you want to modify it using a text editor, such as \"nano\", \"pico\" or \"vim\" using one of these commands: .  You probably want one of the first two over \"vim\" as vim, while being extremely powerful and one of the most-used editors in the world, is also not overly intuitive if you're not used to it. You can use \"man nano\" or \"man pico\" to learn about the other too. .  Once your in your file editor, scroll to the bottom and remove the line you added. Then find the \"/usr/bin\" section in your PATH and add \"/usr/local/bin:\" before it. \":\" is the delimiter between directories. That change will tell the shell to look in \"/usr/local/bin\" before \"/usr/bin\", so that any things you added to the \"/usr/local/bin\" directory will be found before the system-installed code, which is in \"/usr/bin\". .  It's possible that there isn't a PATH statement in the file. If you don't see one, simply add: .  After modifying your ~/.bash_profile, save the file and exit the editor, and then restart your shell. You can do that by exiting and re-opening a terminal window, or by running: .  at the command-line. .  At that point, running: .  should reflect the change to your path. .  To confirm that the change is in effect, you can run: .  and you should get back: .  At that point you should be able to run: .  and get back a response showing the built-in help. This is because the shell will search the path, starting with the first defined directory, and continue until it exhausts the list, and will execute the first file matching that name. .  Because of the difficulties you're having, I'd strongly recommend reading some tutorials about managing a *nix system. It's not overly hard to learn the basics, and having an understanding of how the shell finds files and executes them is essential for anyone programming a scripting language like Ruby, Python, Perl, etc. We're using the OS constantly, installing files for system and user's use, and doing so correctly and safely is very important for the security and stability of the machine. .  ",
      "P-tags": "linux ubuntu",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_7279547",
      "task": "find and grep command this but not that",
      "P-task": "find grep command",
      "F_verb": "grep",
      "P-body": "You don't need \"grep\". .  In grep, the searching pattern should be a regular expression. Therefore, \".\", \"$\" and \"*\" are having special meaning. .  \"grep -v '\\.o$'\" would match files with \".o\" extension. You need to escape \".\" for its literal meaning). .  ",
      "P-tags": "find shell grep",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_800216",
      "task": "Installing Ubuntu 16.04 LTS: How to install ODBC?",
      "P-task": "instal ubuntu 16 04 lt : instal odbc",
      "F_verb": "install",
      "P-body": "Download directly from dev.mysql.com: https://dev.mysql.com/downloads/connector/odbc/ .  Select Ubuntu 16.04 64 bit or 32 bit (probably 64 bit), download the TAR ball, then copy the file \"libmyodbc5a.so\" to \"/usr/lib/x86_64-linux-gnu/odbc/\" .  then, create \"/etc/odbcinst.ini\" .  and \"/etc/odbc.ini\" .  Note that the username tag is User (and not username as seen in some examples) and the socket is under \"/var/run\" and not under \"/var/lib\" .  then worked for me .  ",
      "P-tags": "odbc mysql 16 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_7936",
      "task": "Can mount using mount but not using /etc/fstab",
      "P-task": "mount use mount use etc fstab",
      "F_verb": "mount",
      "P-body": "Entries in \"/etc/fstab\" normally have four to six fields; I'm not sure if omitting the third field (filesystem type) and fourth field (options) will work. Try .  In fact one problem I can foresee is that since the filesystem type is not present, the boot scripts try to mount the filesystem too early. If you explicitly specify a network filesystem, that filesystem is mounted only when the network is up. .  ",
      "P-tags": "10 10 mount",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_410067",
      "task": "How to find how many paragraphs in a file?",
      "P-task": "find mani paragraph file",
      "F_verb": "find",
      "P-body": "You could use \"awk\" in paragraph mode (i.e. setting an empty record separator) e.g. .  ",
      "P-tags": "linux grep wc",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_65685919",
      "task": "What is the best way to run a web app using gunicorn at certain hours of the day?",
      "P-task": "best way run web app use gunicorn certain hour day",
      "F_verb": "run",
      "P-body": "One possible approach would be to add the logic directly in you Dash app, i.e. something like .  which would thus eliminate the need for external tools to start/stop the app. .  ",
      "P-tags": "linux python plotly-dash gunicorn",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP using NP at NP of NP"
    },
    {
      "id": "so_16820798",
      "task": "Add number of line and a specific character",
      "P-task": "add number line specif charact",
      "F_verb": "add",
      "P-body": " ",
      "P-tags": "awk linux shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_191219",
      "task": "sed command to replace a string from one file with entire contents of another file",
      "P-task": "sed command replac string one file entir content anoth file",
      "F_verb": "replace",
      "P-body": "try .  where .   \"-i\" edit in place \"/PLACEHOLDER/\" search for pattern \"r TestOutput.txt\" read file  note that \"/PLACEHOLDER/\" is not deleted. .  to have it deleted  .  where .   \"-e /PLACEHOLDER/d\" will delete entire line with PLACEHOLDER \"-e s/PLACEHOLDER//\" will delete PLACEHOLDER string  ",
      "P-tags": "awk sed text-process",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP from NP with NP of NP"
    },
    {
      "id": "so_47160007",
      "task": "How do I delete multiline comment with @author",
      "P-task": "delet multilin comment author",
      "F_verb": "delete",
      "P-body": "Using \"gnu sed\" you can use \"-z\" option to treat input delimited by NUL character and use: .  Regex pattern \"\\*\\*[*[:space:]]+\\* @author [^\\n]*[*[:space:]]+*/\\n*\" will match a commented block that has \"* @author\" in the commented text. .  ",
      "P-tags": "awk sed bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "so_20480788",
      "task": "Need to merge multiple pairs of audio files with sox in BASH",
      "P-task": "need merg multipl pair audio file sox bash",
      "F_verb": "merge",
      "P-body": "You could do something like this: .  Save that in a file called \"go\", then type: .  It will show you what it is planning to do without doing anything. If you like what it is planning to do, remove the word \"echo\" in the second last line and do it again. Maybe back up your files first! .  ",
      "P-tags": "sox bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP of NP with NP in NP"
    },
    {
      "id": "au_841406",
      "task": "How to play only specific files in MPlayer?",
      "P-task": "play specif file mplayer",
      "F_verb": "play",
      "P-body": "As far as I am aware this is not possible from within MPlayer itself but a little command line magic can produce some great results. .  The following is perhaps a little clumsy but works well enough here with the naming convention that you have specified: .  Brief explanation: .   \"find . -maxdepth 1\": Search in the current directory with no recursion. \"-name \"[1-7].mp3\"\": Find mp3s that have only the numerals 1-7 as their filename. The \"[1-7]\" section demonstrates Bash range expression where numbers 1 and 7 are matched as well as all numbers between. \"ls -v\" : Sort the search so the playback will be numerically based.  Doubtless there are other ways but this works well enough and if your actual filenames are different it would be simply a matter of changing the regular expression in the \"find\" syntax to match... .  ",
      "P-tags": "mplayer command-lin",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "so_58647331",
      "task": "How to pass array to ansible extra-vars from bash script",
      "P-task": "pass array ansibl extra-var bash script",
      "F_verb": "pass",
      "P-body": "This is what you need to know about bash variables and quoting: .  For the following examples, the variable \"${text}\" is set to \"Hello\": .   Variables are expanded inside double quotes. e.g. \"\"${text}\"\" => \"Hello\" Variables are not expanded inside single quotes. e.g. \"'${text}'\" => \"${text}\"  Single quotes have no special meaning inside double quotes and vice-versa. e.g. \"\"'${text}'\"\" => \"'Hello'\" and \"'\"${text}\"'\" => \"\"${text}\"\" If you need to place a double-quote inside a double-quoted string, or a single quote inside a single-quoted string, then it must be escaped. e.g. \"\"\\\"${text}\\\"\"\" => \"\"Hello\"\" and \"'\\'${text}\\''\" => \"'${text}'\"  With all that said, in your case, you want the variables to be expanded, so you should enclose the entire --extra-vars value in double quotes. According to the Ansible website, the value of each of these extra variables does not need to be quoted, unless it contains spaces. To be safe, you can quote the variables as you might not be able to control their values. .  Try this. I have added extra line breaks to make the code easier to understand: .  ",
      "P-tags": "linux ansibl bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP from NP"
    },
    {
      "id": "au_508692",
      "task": "Intel Corporation 7 Series/C210 Series isn't being detected by any module",
      "P-task": "intel corpor 7 seri c210 seri detect modul",
      "F_verb": "detect",
      "P-body": "First, we need to know what type of audio hardware (if any) the system detects: .  And .  Please run this command and post the output. Should be something like the following: .  And .  Additional information for troubleshooting What is the output of the following? .  Several users on other posts were able to get this audio chipset working by editing /etc/modprobe.d/alsa-base.conf .  And add the following line: .  Posts referenced/researched: .   Fresh Ubuntu 12.10 - no audio (Thinkpad T400) Driver for Intel Corporation 7 Series/C210 Series Chipset Family  ",
      "P-tags": "kernel",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V by NP"
    },
    {
      "id": "so_17847549",
      "task": "Running mono-service with sgen garbage collector",
      "P-task": "run mono-servic sgen garbag collector",
      "F_verb": "run",
      "P-body": "You can try to use the \"MONO_OPTIONS\" environment variable: .  ",
      "P-tags": "linux c mono mono-servic",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "au_248817",
      "task": "How to I connect a raw serial terminal to a bluetooth connection?",
      "P-task": "connect raw serial termin bluetooth connect",
      "F_verb": "connect",
      "P-body": "As an addition to Brian's answer. Screen didnt work for me, immediately displaying \"[screen is terminating]\" .  So I found this miniterm python script. Usage is similar: .  ",
      "P-tags": "bluetooth",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP to NP"
    },
    {
      "id": "au_335881",
      "task": "Quickly application create config folder and config file under user's home folder",
      "P-task": "quickli applic creat config folder config file user home folder",
      "F_verb": "create",
      "P-body": "Quickly doesn't offer any helpers to set up a text config file, you'll have to do that yourself. GLib give you an easy way to get the user config directory, \"GLib.get_user_config_dir()\" and you can use ConfigParser to handle the file itself. .  Something like so: .  ",
      "P-tags": "application-develop python quickli",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP under NP"
    },
    {
      "id": "so_16697361",
      "task": "Linux: handling a segmentation fault and getting a core dump",
      "P-task": "linux : handl segment fault get core dump",
      "F_verb": "get",
      "P-body": "The answer: set the sigaction with flag \"SA_RESETHAND\" and just return from the handler. The same instruction occurs again, causing a segmentation fault again and invoking the default handler. .  ",
      "P-tags": "signal linux segmentation-fault coredump",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_15081423",
      "task": "user created by shell script is not executing proceeding commands",
      "P-task": "user creat shell script execut proceed command",
      "F_verb": "create",
      "P-body": "One problem is that you can't run passwd. It asks to write password twice which you can't do in the script. So you enter password once then for the second time you enter \"mkdir ~test\", hence the message \"Sorry, passwords do not match\" .  Instead of passwd suhail try: .  ",
      "P-tags": "shell",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V by NP S_ING"
    },
    {
      "id": "ul_583266",
      "task": "The key(s) in the keyring /etc/apt/trusted.gpg are ignored as the file has an unsupported filetype",
      "P-task": "key keyr etc apt trust gpg ignor file unsupport filetyp",
      "F_verb": "ignore",
      "P-body": "You have reported also this command output: .  And that the file had an incorrect type: .  Instead of a \"key public ring (v4)\" as it should. .  The conclusion is that the file has got damaged for some reason. Most probably because some command failed when you were manually installing either Docker or OpenFOAM (the keys reported above). .   The solution is simple: .   erase the file (well, move it somewhere else for backup) re-add the trusted keys  The docker key you reported: 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 .  Could be re-added to the trusted keys data base with: .  As explained in this web page .  Please be sure to re-check the key signature. .  But the other key fingerprint: \"6781 84F1 20A8 7A47 5F65 6972 6C0D AC72 8B29 D817\" .  Doesn't appear anywhere on the internet, I would not trust such key. Don't try to reinstall it. .  If needed find a correct guide to install OpenFOAM in Debian. .  Good luck. .  Note: Blindly installing keys, any key, is a very bad idea, this is the way in which what gets installed in our systems gets verified. If the key to verify comes from an un-trusted source, all installed packages (and the system in general) could no longer be trusted. You have been warned !!. .  Added: OpenFOAM has a package in Debian, there is no need to manually install any external key. That raises the level of warning. .  Do you remember installing that key? If not, please reinstall your Debian. .  ",
      "P-tags": "gnome-keyr debian",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V as NP"
    },
    {
      "id": "au_40279",
      "task": "Is it possible to install Python 2.5 in 11.04?",
      "P-task": "possibl instal python 2 5 11 04",
      "F_verb": "install",
      "P-body": "Launchpad has a topic about this.  .  Here is a tutorial on installing python 2.5 on Ubuntu 10.10. 11.04 should be identical for this. .  From that websites the commands would be: .  Executing \"python2.5 file\" at commandline would execute 'file' with v2.5. \"python file\" would use the newest version. .  I only used this once roughly a year ago so be wary of pitfalls. .  ",
      "P-tags": "software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_37178732",
      "task": "Need Regex to match multiple lines until Match is found between common delimiters",
      "P-task": "need regex match multipl line match found common delimit",
      "F_verb": "match",
      "P-body": "Use a negative lookahead assertion to make sure your regex never matches across an \"End of transaction\" boundary: .  Test it live on regex101.com. .  ",
      "P-tags": "powershel pattern-match php regex",
      "source": "qa",
      "cate": "match",
      "pat": "V NP until S"
    },
    {
      "id": "ul_103891",
      "task": "What do I need to add a virtual IPsec adapter?",
      "P-task": "need add virtual ipsec adapt",
      "F_verb": "add",
      "P-body": "Normally what you use is a tunnel, created using \"ip tunnel add\". The tunnel device gives you a virtual device that encapsulates IP packets inside other IP packets. Then the encapsulated packet can be encrypted using IPsec. .  For example, you can create a GRE tunnel using: .  Then you can configure IPSec to encrypt GRE packets (either in general, or just to that destination). .  ",
      "P-tags": "rout command-lin iprout network ipsec",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "so_68020572",
      "task": "Command to remove all but select columns for each file in unix directory",
      "P-task": "command remov select column file unix directori",
      "F_verb": "remove",
      "P-body": "Given: .  You can do in place editing with sed: .  If you want freedom to work with multiple columns and have in place editing, use GNU awk that also supports in place editing: .  If you only have POSIX awk or wanted to use \"cut\" you generally do this: .   Modify the file with awk, cut, sed, etc Redirect the output to a temp file Rename the temp file back to the original file name.  Like so: .  Or with \"cut\": .  To do a loop on files in a directory, you would do: .  ",
      "P-tags": "unix bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_52590125",
      "task": "How to save a recognised regular expression in a column in the same txt file that the pattern was found?",
      "P-task": "save recognis regular express column txt file pattern found",
      "F_verb": "save",
      "P-body": "Check if Field 9 actually ends with the pattern you need, and then \"sub\" the match out with \"sub(/.*:/, \"\", r)\" and add at the end of the valid line only: .  Here, .   \"-F\"\\t\"\" splits into fields using tab char \"if ($9 ~ /KO:K[0-9]{5}$/)\" is a condition, only if Field 9 (\"$9\") ends with \"KO:K\" + 5 digits,  \"r=$9;\" assign the value of Field 9 to \"r\" \"sub(/.*:/, \"\", r);\" then, remove all up to and including the last \":\" \"print $0 \"\\t\" r;\" then, print the whole record with a tab and the \"r\" value  \"else\"  \"print $0;\" print the record as is.   ",
      "P-tags": "output grep unix regex",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP in NP that S"
    },
    {
      "id": "au_938489",
      "task": "How to rename multiple files that have different names to file1, file2, file3, etc?",
      "P-task": "renam multipl file differ name file1 file2 file3 etc",
      "F_verb": "rename",
      "P-body": "Use \"rename\" utility to do this: .  Notes  \"-n\" makes the command show you what will happen if you run it. If the output was what you want, run it without \"-n\" to actually rename the files. replace the \"*\" with what you want to rename, for example: \"dog*.txt\" to only rename \"dog1.txt\", \"dog2.txt\" ... to \"file1.txt\", \"file2.txt\", etc. \"$_\" is a default input (file names) which we should modify. using \"=\" we are modifying it with \"sprintf\" we are defining a schema started by \"file\" followed by \"%d\" means a number and ended to the \".txt\". the number (%d) will be assigned using \"++$::count\", which is a simple counter iterated after each rename.   The idea comes from here. .  ",
      "P-tags": "batch-renam renam command-lin bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP that S"
    },
    {
      "id": "so_64871235",
      "task": "Iterating through Invoke-WebRequest JSON result",
      "P-task": "iter invoke-webrequest json result",
      "F_verb": "iterate",
      "P-body": "The code below will output a table of names: .  If you want to capture them into a variable as an array you can use a feature called Member Enumeration: .  ",
      "P-tags": "powershel invoke-webrequest",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP"
    },
    {
      "id": "su_1145946",
      "task": "how to retain original file name when using imagemagick conversion",
      "P-task": "retain origin file name use imagemagick convers",
      "F_verb": "retain",
      "P-body": "it was amost offensively simple: .  Inspired by this answer .  ",
      "P-tags": "convers linux imagemagick command-lin",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP when S"
    },
    {
      "id": "su_1018166",
      "task": "ctrl+x/c/p (cut/copy/paste) subsitutes in Unix bash?",
      "P-task": "ctrl+x c p cut copi past subsitut unix bash",
      "F_verb": "paste",
      "P-body": "GNOME Terminal is a terminal emulation application which is able to access a UNIX shell in the GNOME environment used in many Linux distributions. .  gnome-terminal keyboard shortcuts (partial list) .  To extend a selected region that was selected with the mouse, hold the Shift key while clicking.  .  A list of gnome-terminal keyboard shortcuts including additional keyboard shortcuts can be accessed in the gnome-terminal by selecting Edit -> Keyboard Shortcuts. .  ",
      "P-tags": "unix bash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP in NP"
    },
    {
      "id": "so_20265732",
      "task": "script to detect db2 deadlocks",
      "P-task": "script detect db2 deadlock",
      "F_verb": "detect",
      "P-body": " need your help to do below math in script .  if a$-b$ = 0 print 0 if a$-b$ > 0 print number .   You can say: .  This would print \"0\" if \"a = b\" else print \"a - b\". .   Actually, even the following should suffice: .  ",
      "P-tags": "script db2 bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP"
    },
    {
      "id": "su_643355",
      "task": "Piping svn diff produces ESC characters (OS X 10.7.5)",
      "P-task": "pipe svn diff produc esc charact os x 10 7 5",
      "F_verb": "produce",
      "P-body": "These escape characters mark parts of the output that are colored if they are not piped. .  Based on this very similar question and its answer I suggest you try to use \"less -R\" instead of plain \"less\". .  If you want to use other tools than just \"less\", you could strip the sequences with \"sed 's/\\x1b\\[[0-9]*m//g'\" as discussed in this answer. .  Your complete command would then be .  In OS X escape codes are different so the pattern must be changed. It also seems to be the case that (using OS X) the escape sequence \"\\x1b\" will work with \"perl\" but not with \"sed\". A resulting expression that works for both linux and OS X is then: .  ",
      "P-tags": "svn maco bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_58488160",
      "task": "How can I define a variable name in bash that includes a variabe?",
      "P-task": "defin variabl name bash includ variab",
      "F_verb": "define",
      "P-body": "Use an associative array. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP that S"
    },
    {
      "id": "so_36120143",
      "task": "Passing two awk columns into a while read command",
      "P-task": "pass two awk column read command",
      "F_verb": "pass",
      "P-body": "You don't have to use awk for this. Bash has a built-in variable to determine where words are split: .  \"IFS\" is set to \",\", so word splitting takes place at commas. .  Instead of piping to the \"while\" loop, I use redirection, which has the advantage of not spawning a subshell. .   A remark: you don't need \"cat\" in this context. Awk can take a file name as an argument, so .  becomes .  Also, when using \"print\", you don't need to explicitly introduce spaces: if you comma-separate your fields, awk will replace the comma by the value of the \"OFS\" (output field separator) variable, which defaults to a space. .  ",
      "P-tags": "awk gawk unix bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP into NP"
    },
    {
      "id": "ul_24796",
      "task": "How to write any Unicode Key without Pre-programmed key for it in kbd?",
      "P-task": "write unicod key without pre-program key kbd",
      "F_verb": "write",
      "P-body": "In GTK+ applications you can simply press Ctrl+Shift+u, type in the hex and press Enter. Example: .  Ctrl+Shift+u 7 E Enter \u2192 \"~\" .  This works in my Vim. For the native Vim combination: .  Ctrl+v u 7 E Escape \u2192 \"~\"; cursor on top of the key .  ",
      "P-tags": "unicod x11 vim",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP without NP for NP in NP"
    },
    {
      "id": "ul_304763",
      "task": "Sed to copy part of file name into another contents of file with same substring",
      "P-task": "sed copi part file name anoth content file substr",
      "F_verb": "copy",
      "P-body": "  \"basename\" command gives only the name of file, stripping away path. And \"-s.sample\" will strip the extension So, if \"i\" is \"/path/to/filename.sample\" , \"str\" will contain \"; label=filename;\" \"/^>/ s/$/$str/\" will find a line starting with \">\" and add the contents of \"str\" variable to end of that line   I do not get how you want the output file to be named. If \"i\" is \"/path/to/filename.sample\", \"\"$i\"_bar\" will give \"/path/to/filename.sample_bar\" .  ",
      "P-tags": "shell-script file sed",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP of NP into NP of NP with NP"
    },
    {
      "id": "so_9809140",
      "task": "How correctly wake up process inside interrupt handlers",
      "P-task": "correctli wake process insid interrupt handler",
      "F_verb": "wake",
      "P-body": "The \"wait_event_interruptible\" macro is already pretty careful about avoiding the race you describe. In fact, you don't need the initial check of your \"bytes\" member -- you could just write in your \"read\" method: .  because \"wait_event_interruptible()\" will not actually go to sleep if the condition is true (or becomes true while it's in the middle of going to sleep). .  ",
      "P-tags": "linux-device-driv atom linux-kernel",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP inside NP"
    },
    {
      "id": "su_1446588",
      "task": "Why isn't Bash trap working if output is redirected to stdout?",
      "P-task": "bash trap work output redirect stdout",
      "F_verb": "redirect",
      "P-body": "The other answer advises \"exec &> /dev/tty\", so traps write to \"/dev/tty\" regardless of previous redirections: .   The traps are run, but the standard output redirect to \"/dev/null\" is still in place, so the output is not printed. [\u2026] add \"exec &> /dev/tty\" to work around it by re-establishing the connection from standard output/error to the terminal. .   Sometimes this may not be the best solution. Consider a general case when you want your script (\"fixed\" with \"exec &> /dev/tty\") to be silent. You invoke .  but then the trap is triggered and it writes to \"/dev/tty\" anyway. .  For me a better way is to store the original stdout and stderr in a form of \"backup\" file descriptors: .  Then, inside the trap function, you either redirect any single command: .  or restore the original destinations and proceed as usual: .  This way the redirections applied to the interrupted command won't affect the trap; still the redirections applied to the entire script will. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP if S"
    },
    {
      "id": "so_59132350",
      "task": "How to update or refresh comboBox item with button.add_click function in PowerShell?",
      "P-task": "updat refresh combobox item button add_click function powershel",
      "F_verb": "update",
      "P-body": "You are populating the \"ComboBox\" with this... .  It sounds like you want clicking the \"Button\" to simply do that again so the \"ComboBox\" will contain an up-to-date list of directories. In that case your \"Click\" event handler should be created like this... .  \"Clear()\" is called first so you don't end up with duplicate directory items. .  By the way, you can simplify this... .  ...to this... .  ...or even this... .  ",
      "P-tags": "winform refresh button combobox powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "au_1008738",
      "task": "Why am I getting the error \"missing terminating ] for character class\"?",
      "P-task": "get error miss termin charact class",
      "F_verb": "get",
      "P-body": "As the error missing terminating ] for character class already says, the problem here has to do with \"[\", which you need to escape. Otherwise, it is understood as a character class by grep. .  Also, you are saying \"//\", while you want to use \"/\" instead of \"\\\" according to your input. .  All together, this prints a set of words after \"[Om/\": .  ",
      "P-tags": "regex grep command-lin text-process",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP for NP"
    },
    {
      "id": "so_68710527",
      "task": "Add a powershell command inside a powershell command",
      "P-task": "add powershel command insid powershel command",
      "F_verb": "add",
      "P-body": "PowerShell's string expansion routine respects the subexpression operator \"$(...)\": .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_47023019",
      "task": "Running a powershell script involving AzureRM as an Azure webjob",
      "P-task": "run powershel script involv azurerm azur webjob",
      "F_verb": "run",
      "P-body": "Just to convert a comment to answer + give you a better idea how Azure works. .  Everything is a REST API call in Azure. If you can do something in Azure (or portal can, or you saw it in some demo) - there is a REST call for that. It might or might not be documented, that's another thing (think demo\\preview features that are not yet documented, or deprecated things already not documented but existing). .  But in your case everything is really simple, you can do this from you local machine: .  With the \"-debug\" switch it will show you the REST call its performing and the answer it got (along with a lot of other information). That is a good way of learning how different Azure REST calls work. This works for any Azure Powershell cmdlets ;). Obviously (or not so obviously), you can do the same with Azure Portal using fiddler. .  ",
      "P-tags": "azur powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP"
    },
    {
      "id": "so_51911982",
      "task": "How Do I Exclude Package Files (Directories) from Bash Mac find?",
      "P-task": "exclud packag file directori bash mac find",
      "F_verb": "exclude",
      "P-body": "Insert a regex criterion that returns false for all content within a package directory. Unfortunately, it does mean having to list the file extensions of the package directories whose contents you wish to exclude. I've listed quite a few of them in my regex string: .  ",
      "P-tags": "find maco bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_10060500",
      "task": "bash: How to evaluate PS1, PS2, ...?",
      "P-task": "bash : evalu ps1 ps2",
      "F_verb": "evaluate",
      "P-body": "One great advantage of open source software is that the source is, well, open :-) .  If you download the code for \"bash\" (I'm looking at version 4.2), there's a \"y.tab.c\" file which contains the \"decode_prompt_string()\" function: .  You can try to extract that (along with any needed support routines and build an executable which did the job for you. Although, from a cursory try, those support routines seem to be a lot, so this may be a hard task. .   Other than that, you can probably \"trick\" \"bash\" into expanding it for you with something like: .  Now I've put that across multiple lines for readability but it was done on one line. .  What this does is run an interactive instance of \"bash\", passing (what hopefully is) an invalid command. .  Because it's interactive, it prints the prompt so I grab the first line with the command string on it and remove that command string. What's left over should be the prompt. .  On my system, this is what I get: .  However, this has problems with multi-line prompts and will actually give you your regular prompt rather than the current shell one. .   If you want to do it properly, it may involve adding a little bit to \"bash\" itself. Here are the steps to add an internal command \"evalps1\". .  First, change \"support/mkversion.sh\" so that you won't confuse it with a \"real\" \"bash\", and so that the FSF can deny all knowledge for warranty purposes :-) Simply change one line (I added the \"-pax\" bit): .  Second, change `builtins/Makefile.in to add a new source file. This entails a number of steps. .  (a) Add \"$(srcdir)/evalps1.def\" to the end of \"DEFSRC\". .  (b) Add \"evalps1.o\" to the end of \"OFILES\". .  (c) Add the required dependencies: .  Third, add the \"builtins/evalps1.def\" file itself, this is the code that gets executed when you run the \"evalps1\" command: .  The bulk of that is the GPL licence (since I modified it from \"exit.def\") with a very simple function at the end to get and decode \"PS1\". .  Lastly, just build the thing in the top level directory: .  The \"bash\" that appears can be renamed to \"paxsh\", though I doubt it will ever become as prevalent as its ancestor :-) .  And running it, you can see it in action: .  Now, granted, making code changes to \"bash\" to add an internal command may be considered overkill by some but, if you want an accurate evaluation of \"PS1\", it's certainly an option. .  ",
      "P-tags": "evalu ps1 bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP"
    },
    {
      "id": "au_661216",
      "task": "unable to install samba on ubuntu 14.04",
      "P-task": "unabl instal samba ubuntu 14 04",
      "F_verb": "install",
      "P-body": "First run these commands in terminal (press Ctrl+Alt+T): .   \"sudo apt-get --fix-broken install\" \"sudo apt-get clean\"  \"sudo apt-get autoclean\" \"sudo apt-get autoremove\" \"sudo dpkg --configure -a\"  \"sudo apt-get update\" then following   1.Changed software and updates to main server  .  2.unmarked all \"other software\" sources  .   .  3.reload it and run for software update. .  4.Install samba : \"sudo apt-get install samba\" .  ",
      "P-tags": "14 04 software-instal samba",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_42628",
      "task": "error while loading shared libraries: libGL.so.1: cannot open shared object file: No such file or directory",
      "P-task": "error load share librari : libgl 1 : open share object file : file directori",
      "F_verb": "open",
      "P-body": "Like Renan said, this is the result of a 32/64 bit mismatch. On OpenSUSE, try \"zypper in Mesa-32bit\" to install the 32 bit version of the library. In general, if you have the 64 bit version, you can use \"rpm -qf\" to find the package containing the library: .  On OpenSUSE, the naming convention for 32bit-libraries is to append \"-32bit\" to the package name, so strip version and architecture information and add the suffix to obtain \"Mesa-32bit\". .  ",
      "P-tags": "librari opensus 64bit dynamic-link linker",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "ul_435786",
      "task": "Run a bash script as root user which has a sudo command in the script",
      "P-task": "run bash script root user sudo command script",
      "F_verb": "run",
      "P-body": "If you can edit the script and remove the \"sudo\" commands, running the script as the root user should work as expected. .  Installing the \"sudo\" command would also be a way to get the command to execute successfully. .  ",
      "P-tags": "script shell-script root sudo bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP which S"
    },
    {
      "id": "so_31194889",
      "task": "Find and show unique value from bash array",
      "P-task": "find show uniqu valu bash array",
      "F_verb": "show",
      "P-body": "Try this: .  Output: .  ",
      "P-tags": "array linux shell bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP from NP"
    },
    {
      "id": "au_898603",
      "task": "Where is the code used to build the official Live CD images?",
      "P-task": "code use build offici live cd imag",
      "F_verb": "build",
      "P-body": "Apparently it's a project called ubuntu-cdimage. It does not appear to be available as a package from the official APT repository. .   The Ubuntu CD image software is used to produce daily builds and releases of Ubuntu and its derivatives. At present it consists of a significantly-modified version of \"debian-cd\" and some fairly extensive wrapper scripts. .   The blog post I linked on your other question linked to a ReleaseTeam page on the wiki (CDImageSetup) that mentioned the ubuntu-cdimage suite. The suite looks geared toward large-scale production (daily ISO builds, testing, etc) rather than individual builds like the \"live-build\" and \"ubuntu-defaults-builder\" packages. .  ",
      "P-tags": "live-cd",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_25598377",
      "task": "Error: EACCES, permission denied Ionic Cordova IOS",
      "P-task": "error : eacc permiss deni ionic cordova io",
      "F_verb": "deny",
      "P-body": "The error you have received is from NPM (since the Cordova CLI is installed via NPM). This is a tricky issue where using NPM with \"sudo\", and then not using \"sudo\" will result in weird permission issues.  .  If you followed the instructions on the Cordova documentation, it has you install Cordova using \"sudo\". It then has you do this: .  Did you do that step? If not try it. If that doesn't work, make sure the \"'/Users/Anuraag/.cordova/lib/tmp'\" directory can be accessed. Given that it is a local temporary directory, there is most likely no harm in giving it full read/write access with something like: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "so_14826981",
      "task": "For two columns, how to sum the values in 1st column grouped by 2nd column?",
      "P-task": "two column sum valu 1st column group 2nd column",
      "F_verb": "sum",
      "P-body": " ",
      "P-tags": "awk sed bash",
      "source": "qa",
      "cate": "cumulate/sum",
      "pat": "V NP in NP by NP"
    },
    {
      "id": "ul_377452",
      "task": "Write hexadecimal values to binary file with bash",
      "P-task": "write hexadecim valu binari file bash",
      "F_verb": "write",
      "P-body": "\"printf\" should be portable and supports octal character escapes: .  (\"printf\" isn't required to support hex escapes like \"\\x00\", but a number of shells support that.) .  See Why is printf better than echo? for the troubles with \"echo\". .  ",
      "P-tags": "binari bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "so_24772751",
      "task": "Linux: make output into one line",
      "P-task": "linux : make output one line",
      "F_verb": "make",
      "P-body": " Expected output: .  Edit: \"sub\" is enough. No need to go \"gsub\". .  ",
      "P-tags": "awk linux sed",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP into NP"
    },
    {
      "id": "ul_673960",
      "task": "Convert to csv file with same name using AWK command",
      "P-task": "convert csv file name use awk command",
      "F_verb": "convert",
      "P-body": "You could do .  ",
      "P-tags": "awk linux csv",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V to NP with NP using NP"
    },
    {
      "id": "so_59287632",
      "task": "How to remove item from an array in PowerShell (v5.1)",
      "P-task": "remov item array powershel v5 1",
      "F_verb": "remove",
      "P-body": "if your array is really a collection of one-item hashtables, then the following otta work ... [grin] it pipes the collection thru the \"Where-Object\" cmdlet & filters out anything item that has the value-to-exclude in the \"EmpId\" key value.  .  output ...  .  note that the items are not required to be in order ... that is how hashtables work if you don't specify \"[ordered]\".  .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "ul_15625",
      "task": "How can I call other shell script like a subroutine?",
      "P-task": "call shell script like subroutin",
      "F_verb": "call",
      "P-body": "You don't say which shell you're using, so assuming bash, you just do .  The variable rc now contains the return code from your other script. Depending on what you're trying to achieve, you might try and do more stuff, but your question is so vague, that's the best starting point. .  ",
      "P-tags": "shell-script",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP"
    },
    {
      "id": "so_34266606",
      "task": "How to restart a python script after x amount of time?",
      "P-task": "restart python script x amount time",
      "F_verb": "restart",
      "P-body": "Use the following: .  ",
      "P-tags": "python shell",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP after NP of NP"
    },
    {
      "id": "so_36891795",
      "task": "disable the automatic change from \\r\\n to \\n in python",
      "P-task": "disabl automat chang r n n python",
      "F_verb": "disable",
      "P-body": "Set the \"newline\" keyword argument to \"open()\" to \"'\\r\\n'\", or perhaps to the empty string: .  This tells Python to only split lines on the \"\\r\\n\" line terminator; \"\\n\" is left untouched in the output. If you set it to \"''\" instead, \"\\n\" is also seen as a line terminator but \"\\r\\n\" is not translated to \"\\n\". .  From the \"open()\" function documentation: .   newline controls how universal newlines mode works (it only applies to text mode). It can be \"None\", \"''\", \"'\\n'\", \"'\\r'\", and \"'\\r\\n'\". [...] If it is \"''\", universal newlines mode is enabled, but line endings are returned to the caller untranslated. If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.  .   Bold emphasis mine. .  ",
      "P-tags": "unix python-3 x line-end python window",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_59246533",
      "task": "Run script in Dockerfile to add aliases",
      "P-task": "run script dockerfil add alias",
      "F_verb": "run",
      "P-body": "Edit: .  I stripped the \"docker-compose.yml\" file to below as I do not have the dependencies: .  Starting the container with \"docker-compose up\" and \"cat\"ting the \"/root/.bashrc\" file shows that the alias is present there. .  Few things to look for: .   You're checking the \"root\" user's \".bashrc\" because the \"RUN\" in Dockerfile will execute commands as root unless specified otherwise. Execute permissions available to \"docker-bootstrap.sh\" file. Rebuilding the image just to be sure.   Original Answer It works for me. Am I missing something here? Please check the following: .  ",
      "P-tags": "docker alia bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP S_INF"
    },
    {
      "id": "so_25187428",
      "task": "Read from disk after write instead of cache",
      "P-task": "read disk write instead cach",
      "F_verb": "read",
      "P-body": "You need to do the equivalent of the following shell commands: .  and then try reading the file again. .  One way to do it from C would be something approximating: .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V from NP after NP of NP"
    },
    {
      "id": "ul_50044",
      "task": "Use a shell variable in awk",
      "P-task": "use shell variabl awk",
      "F_verb": "use",
      "P-body": "You seem to be confusing awk variables and shell variables. \"awk -v vawk=\"$1\"\" creates an awk variable called \"vawk\", yet you are trying to use shell syntax (\"$vawk\"). This doesn't work because the shell doesn't have a variable called \"vawk\". I think what you want is .  ",
      "P-tags": "awk variabl bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_43764653",
      "task": "How to make Tomcat 8.5 RewriteValve work with AJP1.3 JKMount?",
      "P-task": "make tomcat 8 5 rewritevalv work ajp1 3 jkmount",
      "F_verb": "make",
      "P-body": "I've solved it by using \"mod_proxy_ajp\" instead of \"mod_jk\". .  Apache's my.site.com-le-ssl.conf .  Tomcat's rewrite.config .  Now it works as desired. .  ",
      "P-tags": "tomcat ubuntu url-rewrit tomcat8 apach",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_78061",
      "task": "Get environment variable of other user",
      "P-task": "get environ variabl user",
      "F_verb": "get",
      "P-body": "Another option is to use \"env\". Run this as \"root\" : .  For example .  ",
      "P-tags": "root environment-vari shell user",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "su_160501",
      "task": "Unix: Directory listing including last modified time",
      "P-task": "unix : directori list includ last modifi time",
      "F_verb": "include",
      "P-body": "This might be what you're looking for: .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP"
    },
    {
      "id": "so_12875541",
      "task": "Creating a Regex in Perl to extract a value",
      "P-task": "creat regex perl extract valu",
      "F_verb": "create",
      "P-body": "First, you don't print $sdSerial. .  Second, you could save some external calls and simplify your regexp with: .   The above can be simplified to: .  ",
      "P-tags": "linux ubuntu perl regex",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP S_INF"
    },
    {
      "id": "so_23119372",
      "task": "The term 'Rename-Computer' is not recognized as the name of a cmdlet",
      "P-task": "term rename-comput recogn name cmdlet",
      "F_verb": "rename",
      "P-body": "That's because \"Rename-Computer\" was introduced in Powershell 3.0 .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP as NP of NP"
    },
    {
      "id": "ul_638537",
      "task": "Bash: How to create a script which handles folders with a specific substring and continues recursively inside?",
      "P-task": "bash : creat script handl folder specif substr continu recurs insid",
      "F_verb": "continue",
      "P-body": " ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "su_450838",
      "task": "exiftool: delete exif data but preserve some specific tags",
      "P-task": "exiftool : delet exif data preserv specif tag",
      "F_verb": "delete",
      "P-body": "You should always check the man pages if you are in trouble. .  Which should read something like this: .  Something like: .  should work. Ensure that the tags really are named this way using \"exif /path/to/file.jpg\". .  What the command does? \"-all=\" deletes all the tags, \"-tagsFromFile @\" takes the listed flags from the source file, in this case \"@\" represents the current file, (you could of course substitute with a fixed file here like \"-tagsFromFile pic.jpg\") and writes them to the destination. .  ",
      "P-tags": "command-lin unix maco exif exiftool",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_11724",
      "task": "how to detect a laptop hibernate/resume(close lid,open) in osx from a bash script",
      "P-task": "detect laptop hibern resum close lid open osx bash script",
      "F_verb": "detect",
      "P-body": "This StackOverflow question asks a very similar thing, just not bash-specific. The accepted answer states to try a program called Sleepwatcher for which the source is available. .  From reading the source it seems like this program uses the apple-specific \"IORegisterForSystemPower\" function which allows the small C-daemon to be notified by the system before the syetm goes to sleep and after it wakes back up. .  There is no generic ACPI daemon on Mac OS X that I know of. .  ",
      "P-tags": "suspend osx bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "so_61743028",
      "task": "How do i get properties from cmdlet commands and save them as a integers to a variable",
      "P-task": "get properti cmdlet command save integ variabl",
      "F_verb": "save",
      "P-body": "The \"Get-WmiObject -Class Win32_logicaldisk -Filter \"DriveType = '2'\"\" statement is likely to return more than just one object. To compare the Size properties to some value, you need to iterate over the result(s): .  ",
      "P-tags": "powershel cmdlet",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP as NP to NP"
    },
    {
      "id": "so_19984620",
      "task": "Probably grep, but still do not get how to read row in file1 and paste it as a column in file2",
      "P-task": "probabl grep still get read row file1 past column file2",
      "F_verb": "paste",
      "P-body": "If the file looks like what you mentioned, then you can just do.. .  An example of what it will do..  .  ",
      "P-tags": "awk command grep unix linux",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "so_68988696",
      "task": "Set UTF-8 Input and Get UTF-8 Output through pipe to/from Powershell with C/C++",
      "P-task": "set utf-8 input get utf-8 output pipe powershel c c++",
      "F_verb": "set",
      "P-body": "You need to set the console in- and output code pages to \"65001\" (UTF-8) before creating your PowerShell process, via the \"SetConsoleCP\" and \"SetConsoleOutputCP\" WinAPI functions, because the PowerShell CLI uses them to decode its stdin input and to encode its stdout output. .  (By contrast, \"$OutputEncoding = [System.Console]::OutputEncoding = [System.Console]::InputEncoding = [System.Text.Encoding]::UTF8\" only applies intra-PowerShell-session when making external-program calls from PowerShell.) .  Note: If the calling process isn't itself a console application, you may have to allocate a console before calling \"SetConsoleCP\" and \"SetConsoleOutputCP\", using the \"AllocConsole\" WinAPI function, but I'm frankly unclear on (a) whether that makes this console instantly visible (which may be undesired) and (b) whether the \"CreateProcess\" call then automatically uses this console. .  It that doesn't work, you can call via \"cmd.exe\" and call \"chcp\" before calling \"powershell.exe\", along the lines of \"cmd /c \"chcp 65001 >NUL & powershell -c ...\"\"; \"chcp 65001\" sets the console code pages to \"65001\", i.e. UTF-8. .  (This introduces extra overhead, but a \"cmd.exe\" process is relatively light-weight compared to a \"powershell.exe\" process, and so is \"chcp.com\"). .  Here's a sample command you can run from PowerShell to demonstrate: .  This outputs the following, indicating that the \"powershell\" call both correctly read the UTF-8-encoded input and also output it as UTF-8: .   Note: .  You can bypass character encoding problems by using the in-process PowerShell SDK as an alternative to creating a \"powershell.exe\" child process, though I don't know how painful that is from C++. For a C# example, see this answer. .  ",
      "P-tags": "pipe c++ powershel utf-8 window",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "au_868854",
      "task": "I made /usr/local/ world writable, is it secure?",
      "P-task": "made usr local world writabl secur",
      "F_verb": "make",
      "P-body": "Here is a list of my systems /usr/local/ .   To fix /usr/local/ issue these commands: .  That should be it. .   g+s sets the SGID bit (group sticky) 775 = rwx rwx r-x 755 = rwx r-x r-s  ",
      "P-tags": "npm golang permiss chmod",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_61522886",
      "task": "when running powershell --version it gives error",
      "P-task": "run powershel -- version give error",
      "F_verb": "run",
      "P-body": "There is no powershell --version option, in Powershell 5. Output of powershell -? is below. It looks like \"-version\" with one dash can run older versions of powershell. .  In powershell 7 there is a -version option with one dash, but the binary is called \"pwsh\". .  ",
      "P-tags": "azure-powershel powershel powershell-7 0",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_591331",
      "task": "\"^M: Command not found\" from script",
      "P-task": ": command found script",
      "F_verb": "find",
      "P-body": "\"cat -v script\" shows you that at least some of the lines have a CR (carriage return) character, probably at the end. .  Your script is a text file in DOS/Windows format. You need to convert it to Unix format (i.e. remove the CRs). This can be done by editors or e.g. the tool \"dos2unix\". .  ",
      "P-tags": "script csh",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V from NP"
    },
    {
      "id": "so_30577808",
      "task": "What's clean way to join two files together side by side?",
      "P-task": "clean way join two file togeth side side",
      "F_verb": "join",
      "P-body": "Use \"paste\": .  That will separate the lines from A and the lines from B with a tab character. If you want them separated with a space instead, use .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP by NP"
    },
    {
      "id": "au_82426",
      "task": "Evolution randomly stopped supporting my Gmail account",
      "P-task": "evolut randomli stop support gmail account",
      "F_verb": "stop",
      "P-body": "Discover What Causes the Bug .  Starting Evolution from your terminal with some special environment variables causes Evolution to display more information on what it is currently doing. .  The following is a list of variables and what each one tells Evolution to do: .  It's easy to start Evolution with custom variables. One would simply run something like the following: .  ",
      "P-tags": "evolut gmail 11 04",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V S_ING"
    },
    {
      "id": "so_66540548",
      "task": "PowerShell Script to add EIP to instance via User Data",
      "P-task": "powershel script add eip instanc via user data",
      "F_verb": "add",
      "P-body": "I finally solved it! .  The reason why it was not being called was: .   .  Initially \"Enable UserData execution for next service start\" was unchecked. This is something to do with the EC2Config service installed inside the instance itself. .  To summarize the solution: .   Script above (https://gist.github.com/cleydson/ff70493ef37cff03669e21ed37d90a8b) was used and saved into the instance. UserData execution was enabled inside the instance (C:\\Program Files\\Amazon\\Ec2ConfigService\\Ec2ConfigServiceSettings.exe) UserData script to call the script inside, using -Command instead of the more popular -File     \r  .  ",
      "P-tags": "elastic-ip amazon-web-servic eip ip powershel",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP via NP"
    },
    {
      "id": "au_262487",
      "task": "Install postgreSQL on Ubuntu dependency errors",
      "P-task": "instal postgresql ubuntu depend error",
      "F_verb": "install",
      "P-body": "If you are running the server version of Ubuntu, you could try running .  to update the available packages, and then retrying the install with  .  If you are running the Desktop version of Ubuntu however, I would suggest installing postgresql via the Ubuntu Software Center, since this has always worked best for me. .  ",
      "P-tags": "rail postgresql",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_25063677",
      "task": "How much does using htaccess files slow down website performance (especially with solid state disks)?",
      "P-task": "much use htaccess file slow websit perform especi solid state disk",
      "F_verb": "use",
      "P-body": "From an answer on Quora by Jonathan Klein, 12ms for a 1500 line \".htaccess\" file: .   Having a large .htaccess does have a cost. Ours is currently ~1500 lines and we benchmarked the time spent parsing it at around 10-12ms on a production webserver. Hardware makes a difference obviously, but you can fairly safely assume that the cost of that 3000 line .htaccess is around 25-35ms per request. .   ",
      "P-tags": "linux apach perform htaccess",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "au_888152",
      "task": "Creating a new EFI partition on another disk in order to maintain original Windows Boot",
      "P-task": "creat new efi partit anoth disk order maintain origin window boot",
      "F_verb": "create",
      "P-body": "The last I heard, there was a bug in the Ubuntu installer that caused it to always place GRUB on the EFI System Partition (ESP) on the first disk (usually \"/dev/sda\"), even if you tried to force it onto another ESP (say, one on \"/dev/sdb\"). This fact can make separating your Windows and Ubuntu installations a little trickier than you might like. Also, the way Ubuntu configures GRUB, it's reliant on both files on the ESP and a \"grub.cfg\" configuration file in the Ubuntu \"/boot/grub\" directory, which is not on the ESP. Thus, if you install Ubuntu and then delete it by deleting the Ubuntu partition(s), GRUB will remain behind, but with its \"grub.cfg\" file gone, the computer will hang at a \"grub>\" prompt when you boot. This problem can be overcome by manually deleting the GRUB files from the ESP or by tweaking the boot order using \"efibootmgr\" in Ubuntu or EasyUEFI in Windows before deleting the Ubuntu partitions. .  Alternatively, you could follow this procedure to install Ubuntu: .   Download the USB flash drive or CD-R version of my rEFInd boot manager. Write the rEFInd image to a USB flash drive or CD-R, as appropriate. Boot the Ubuntu installer in its \"try before installing\" mode. This results in a normal Ubuntu desktop. Open a Terminal window. Type \"ubiquity -b\". This launches the installer, but the \"-b\" option tells it to not install GRUB. In the installer (or before you run the installer, if you prefer), set up your partitions, and be sure to include an ESP on the second disk (the one to which you're installing Ubuntu). When you're done with the installation, reboot using the rEFInd disk. You should see the rEFInd menu appear. A caveat: The rEFInd disk images I distribute do not support Secure Boot. Thus, if Secure Boot is active, you'll need to either disable it or modify the rEFInd image to include Shim. You can re-enable Secure Boot later, but you may need to jump through some extra hoops at that time. Windows 7 does not support Secure Boot, so you shouldn't run into this problem. I mention it in case somebody wants to do something similar with a Windows 8 or later installation.) Using the rEFInd menu, boot Ubuntu. A caveat: If you use a separate \"/boot\" partition, you'll need to hit F2 or Insert twice and add a \"ro root={rootfs}\" option, where \"{rootfs}\" is a pointer to the root (\"/\") filesystem, such as \"/dev/mapper/lvm-root\". This is normally only necessary if you use LVM or software RAID.) In Ubuntu, check and, if necessary, alter \"/etc/fstab\" so that it mounts the ESP in Ubuntu's directory tree at \"/boot/efi\". If you need to change this detail, be sure to unmount anything that's already mounted there and mount the Ubuntu disk's ESP at \"/boot/efi\" before proceeding. Install your preferred boot loader.  If you want to use GRUB 2, install the \"grub-efi\" package. You may also need to run \"sudo grub-install\" and/or \"sudo update-grub\". If you want to use rEFInd, install the rEFInd Debian package or PPA. If you're asked if you want to copy rEFInd to the ESP, be sure to respond affirmatively.   At this point, when you reboot you should see GRUB or rEFInd appear and you should be able to boot either Windows or Ubuntu. If you want to go back to a stock factory installation, you can wipe all the partitions from the Ubuntu disk, including the ESP, and the computer should skip over the now-invalid entry for GRUB or rEFInd and go straight to booting Windows. If you use rEFInd, it should continue booting Windows even if you delete all the Ubuntu partitions but leave the ESP on which rEFInd resides intact.) .  ",
      "P-tags": "dual-boot partit boot uefi windows-7",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP on NP S_INF"
    },
    {
      "id": "ul_599585",
      "task": "How to add 2 column values and find out percentage value?",
      "P-task": "add 2 column valu find percentag valu",
      "F_verb": "find",
      "P-body": "You can actually use \"awk\" for the entire task: .  will add the \"1k blocks\" and \"used\" column for all lines that start with \"/dev/sda1\" and \"Shared\" in variables \"total\" and \"used\", respectively, and print the ratio of the sums at the end. .  The output is then redirected into the file \"EmmcSpace.txt\". .  ",
      "P-tags": "c shell text-process",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V out NP"
    },
    {
      "id": "ul_621749",
      "task": "How to create full-backup bootable ISO file using Relax-and-Recover app?",
      "P-task": "creat full-backup bootabl iso file use relax-and-recov app",
      "F_verb": "create",
      "P-body": "After struggling with this need and the problem, I Asked it on the rear github, and the answer as in the below: it will generate 1 bootable iso in \"/var/lib/rear/output/rear-YOURSYSTEMNAME.iso\" .  And you can install it where ever you want. Please read the issue carefully. In my experience, if the automatic restore failed, you should manually restore it as the \"rear\" video says: .  https://relax-and-recover.org/ .  rear recovery steps: rear username: \"root\" .  command to restore: \"rear recover\" .  update if you want to generate .iso straight into your usb stick, you can do as below steps: .  ",
      "P-tags": "linux iso bootabl usb backup",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_512357",
      "task": "How to get single character after space?",
      "P-task": "get singl charact space",
      "F_verb": "get",
      "P-body": "Using \"awk\" to output the first whitespace-delimited word concatenated with the first character of the last whitespace-delimited word: .  The \"substr()\" function returns a number of characters from a given position of a string, and \"$1\" and \"$NF\" is the first and last whitespace-delimited word on the current line, respectively. .  Testing: .  ",
      "P-tags": "awk grep linux cut sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP after NP"
    },
    {
      "id": "so_51948239",
      "task": "How to convert GMT date time into GMT Unix TimeStamp using JS?",
      "P-task": "convert gmt date time gmt unix timestamp use js",
      "F_verb": "convert",
      "P-body": "Without a timezone, new Date assumes localtime .  so, lets say you retrieve the string .  what you can do is .     \r  .  ",
      "P-tags": "unix-timestamp datetim javascript gmt",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP into NP using NP"
    },
    {
      "id": "so_38177431",
      "task": "Want to convert a double to timestamp to hours, minutes and seconds",
      "P-task": "want convert doubl timestamp hour minut second",
      "F_verb": "convert",
      "P-body": "You can cast the time to a \"timespan\": .  Output: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_47524432",
      "task": "Docker Install MySQL v3.23 on Ubuntu 16.04",
      "P-task": "docker instal mysql v3 23 ubuntu 16 04",
      "F_verb": "install",
      "P-body": "Wow! The last release of MySQL 3.23 was 2003-09-11, which is 14 years ago as we type this. Oracle has done its best to remove all unsupported versions from official download sites. .  You might find old copies of MySQL 3.23 binaries and source floating around on obscure sites in lesser-known corners of the internet. .  I don't expect the binaries can run on modern OS versions. The runtime shared libraries are just the wrong versions. You'd have to compile MySQL 3.23 from source. .  Even finding the source is hard. I found a copy of 3.23.49 here: http://live.dadanini.at/mysql/downloads_html/mysql-3.23.html  .  (3.23.49 was released 2002-02-14, 19 months before the last version 3.23.58, dated 2003-09-11). .  I spun up a Vagrant box with Ubuntu 16.04 and installed: .  I got the MySQL source to configure... sort of. It wouldn't recognize the pthreads option, so I tried to use mit-threads instead: .  But it ran into errors trying to configure mit-threads: .  That's right, the mit-threads code is so old, it doesn't support 64-bit architecture on Linux!!  .  I'm not going to download a Vagrant box for 32-bit Ubuntu, if such a thing can even be found. .  I'm giving up at this point. You are welcome to continue trying! :-) .  I have to comment that software that is so old has had hundreds of severe security bugs fixed over the years. I wouldn't recommend using the software except temporarily to help serve as a source for ETL of the data into a more current RDBMS. .  If I were you, I would invest the time instead into figuring out the character set issue so you could import directly into MySQL 5.7. .  ",
      "P-tags": "ubuntu mysql docker",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_4180626",
      "task": "how to use extern keyword on struct",
      "P-task": "use extern keyword struct",
      "F_verb": "use",
      "P-body": "\"Test\" is a data-type, so you don't need to use \"extern\". As the error message says, \"extern\" is only for functions and objects. If Visual Studio is allowing your code to compile, then that's a \"bug\" in the compiler. .  The point of \"extern\" is to tell the compiler not to worry about functions and objects that it cannot see, because they've been defined elsewhere (these will be resolved by the linker). This doesn't make sense for data-types; the compiler needs to know the data-type in order to generate correct object code. .  ",
      "P-tags": "c++ linux extern",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_866737",
      "task": "Creating a new terminal/shell window to simply display text",
      "P-task": "creat new termin shell window simpli display text",
      "F_verb": "create",
      "P-body": "A good solution in Unix would be named pipes. I know you asked about Windows, but there might be a similar approach in Windows, or this might be helpful for someone else. .  on terminal 1: .  on terminal 2 (bash): .  Edit: changed terminal 2 command to use \"tail -f\" instead of infinite loop. .  ",
      "P-tags": "python shell",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP S_INF"
    },
    {
      "id": "su_464298",
      "task": "how do I write find expression (atime = ctime) (access time = change time)",
      "P-task": "write find express atim ctime access time chang time",
      "F_verb": "write",
      "P-body": "This gives you all files that differ between atime and ctime: .  See this example: .  Now look at the file stats: .  I separate each field by newline and each record by blank line to ease following processing with awk: \"awk 'BEGIN {FS=\"\\n\"; RS=\"\"}; $2!=$3 {print $1}'\" Here the field separator and the record separator are set at the beginning (RS interprets empty string as blank line). That means $2 and $3 hold the atime and ctime. If they differ the according filename (in $1) is printed.  .  The result here is: .  ",
      "P-tags": "linux timestamp find bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "ul_128512",
      "task": "Error when creating BTRFS Filesystem",
      "P-task": "error creat btrf filesystem",
      "F_verb": "create",
      "P-body": "Using dd we can wipe the partition table. I remember having success with dd while failing with gdisk's zero feature. Make sure that you have your data backed up). .  ",
      "P-tags": "btrf partit mkf",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "su_905255",
      "task": "How to get Fish shell and NVM both installed with Homebrew to work together?",
      "P-task": "get fish shell nvm instal homebrew work togeth",
      "F_verb": "get",
      "P-body": "You can use Bass. Clone the git repository  .  Then cd in the cloned directory and type .  Now you should be able to use node inside fish shell. .  ",
      "P-tags": "homebrew maco fish bash node js",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP S_INF"
    },
    {
      "id": "so_21823001",
      "task": "Get server memory usages on Amazon EC2 Instance",
      "P-task": "get server memori usag amazon ec2 instanc",
      "F_verb": "get",
      "P-body": "As the output of \"free\" command shows above, 5 GB of data is cached. This is a part of Hard Disk which is cached in RAM. Linux will free the memory as the applications need them. More information is available in this answer. Trust linux, he knows the memory management and will free the cached space, as an application needs RAM. .  ",
      "P-tags": "amazon-ec2 tomcat linux java cento",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_57226467",
      "task": "How to add proper spacing in my PSV file?",
      "P-task": "add proper space psv file",
      "F_verb": "add",
      "P-body": "This is quite crude but this q function will take an existing psv file and pad it out: .  It works by taking the max string length of each column and padding the rest of the values to the same width using \"$\". The columns are then stitched back together and saved. .  Taking this example file contents: .  Passing through pad in an open q session: .  Gives the result: .  ",
      "P-tags": "python-3 x kdb unix r",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_48511400",
      "task": "Powershell: Out-File - Access to the path is denied",
      "P-task": "powershel : out-fil - access path deni",
      "F_verb": "deny",
      "P-body": "Well, the error is a bit misleading. You're trying to create the output file as \"C:\\Users\\my-name\\Documents\\Tests\", but that already exists as a directory, hence the access violation. Create the file with the full path: .  ",
      "P-tags": "powershel rest script",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "au_1162960",
      "task": "Can't get out of grub terminal",
      "P-task": "get grub termin",
      "F_verb": "get",
      "P-body": "If your grub menu does not appear but the grub prompt with black screen shows, as long as your Linux system is still intact you can bypass the grub stage and boot directly into Ubuntu. Once you've done that you can easily fix grub from there. The steps to boot up are as follows: .  a) First remove all external drives. Determine where your root partition is. In this case we already know it's sda5. If you don't know and you have one disk you can find out by typing \"ls (hd0,x)/\" trying different values for 'x' which is the number of the root partition on that disk. If you have more than one disk you may have to use hd1 or a higher number if you don't know which disk Ubuntu is installed on. Once you hit the right disk/partition numbers you'll see listed the basic system folders and the 2 files vmlinuz and initrd. Note these 2 files are symlinks to the kernel and initrd image respectively but they must be present. .  b) Now set the root with \"set root=(hd0,5)\" or whatever is the correct combination for disk/partition you found in (a). Press Enter. .  c) Now we need to map the linux kernel to root. Type \"linux /boot/vm\". At this point press the Tab button. The command will partially complete by offering a choice of (usually) 2 kernel versions. Take the higher number by typing it and press Tab button again. The whole kernel version number should autocomplete. You should be seeing something like \"linux /boot/vmlinuz-4.15.0-55-generic\" depending on kernel version. You still need to add root=/dev/sda5 to this line. So the whole command is \"linux /boot/vmlinuz-4.15.0-55-generic root=/dev/sda5\". Press Enter. .  d) Now we do similar for initrd. Type \"initrd /boot/in\" then press Tab button. Again it will offer 2 versions so choose the same version as in c) using Tab button again to autocomplete. You should see something like \"initrd /boot/initrd.img-4.15.0-55-generic\" as the complete command, depending on kernel version. Press Enter. .  e) Then type \"boot\". Press Enter. .  After a a couple of minutes of splash screen activity you will eventually reach the user login screen, then proceed as normal. If during boot-up you reach the \"intrafms\" prompt and booting stops, you've probably mistyped something in the earlier stages and need to start again. Remember, this process boots you into Linux. Grub still needs a couple more commands to fix it once you're in. .  ",
      "P-tags": "boot grubrescu 18 04",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V out of NP"
    },
    {
      "id": "so_24284460",
      "task": "Calculating rounded percentage in Shell Script without using \"bc\"",
      "P-task": "calcul round percentag shell script without use bc",
      "F_verb": "calculate",
      "P-body": "Use AWK (no bash-isms): .  ",
      "P-tags": "percentag linux shell",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V to NP in NP without using NP"
    },
    {
      "id": "so_49731682",
      "task": "Systemd + Sys V init.d script: start works, but stop does not",
      "P-task": "systemd + sy v init script : start work stop",
      "F_verb": "start",
      "P-body": "You'll notice the top of your script loads \"/lib/lsb/init-functions\". You can read the code in there and the related code in \"/lib/lsb/init-functions.d\" to understand the related code you are pulling in. .  A summary is that your script likely being converted to a \"systemd\" \".service\" in the background and is subject to a whole host of documented incompatibilities with systemd .  There is inherit extra complexity and potential problems when you ask systemd to emulate and support the file formats used by the legacy \"Upstart\" and \"sysVinit\" init systems. .  Since you are writing new init script from scratch, consider writing a \"systemd\" \".service\" file directly, removing all the additional complexity of involving additional init systems. .  A minimal \".service\" file to go in \"/etc/systemd/system/\" could look like: .  More details in \"man systemd.service\". Some additional learning now will save you some debugging later! .  ",
      "P-tags": "ubuntu-16 04 upstart systemd init",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_32368777",
      "task": "Run gnuplot scripts in background within a shell script",
      "P-task": "run gnuplot script background within shell script",
      "F_verb": "run",
      "P-body": "What about something simple as .  That assumes, that you have different scripts \"script1.gp\", \"script2.gp\" and \"script3.gp\". .  If you have only a single script and want to pass the iteration number to it, you could do it with .  A simple gnuplot script \"script.gp\" for testing this is .  The \"pause 10\" makes gnuplot pause for 10 seconds. .  ",
      "P-tags": "gnuplot shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP within NP"
    },
    {
      "id": "ul_177157",
      "task": "Need to insert single quotes in text file for use as SQL query using sed",
      "P-task": "need insert singl quot text file use sql queri use sed",
      "F_verb": "insert",
      "P-body": "There are four ways to include the single quote that you need. .  One cannot escape a single-quotes string within a single-quoted string. However, one can end the quoted string, insert an escaped single-quote, and then start a new single-quoted string. Thus, to put a single quote in the middle of \"'ab'\", use: \"'a'\\''b'\". Or, using the sed command that you need: .  The second way is to use a double-quoted string, in which case the single-quote can be inserted easily: .  This issue with double-quoted strings is that the shell does processing on them. Here, though, there are no shell-active characters, so it is easy. .  The third method is to use a hex escape as PM2Ring demonstrates. .  The fourth way, suggested in the comments by Jonathan Leffler, is to place the \"sed\" commands in a separate file: .  This way has the strong advantage that \"sed\" reads the commands directly without any interference from the shell. Consequently, this completely avoids the need to escape shell-active characters and allows the commands to be entered in pure \"sed\" syntax. .  How the \"sed\" solution works The trick is to put single quotes around the comma-separated strings that you want but not around the others. Based on the single example that you gave, here is one approach: .   \"s/,([^ ),]+)/,'\\1'/g\" .  This looks for one or more non-space, non-comma, and non-close-parens characters which follow a comma. These characters are placed inside single quotes. .  \"s/,,/,'',/g\" .  This looks for consecutive commas and places a two single-quotes between them. .   OSX and other BSD platforms To avoid extra backslashes, the above \"sed\" expressions use extended regular expressions. With GNU, these are invoked as \"-r\" but, with BSD, they are invoked with \"-E\". Also, some non-GNU \"sed\" do not accept multiple commands separated with semicolons. Thus, on OSX, try: .  Addendum: Matching a MAC address From the comments, we have the following input; .  And, we want to put single-quotes around the MAC address that follows the open-parens. To do that: .  In any locale, \"[:xdigit:]\" will match any hexadecimal digit. Thus, \"([[:xdigit:]:]+)\" will match a MAC address (hex digit or colon). .  ",
      "P-tags": "text-process sed bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP for NP using NP"
    },
    {
      "id": "so_57563313",
      "task": "How to configure supervisor in docker correctly",
      "P-task": "configur supervisor docker correctli",
      "F_verb": "configure",
      "P-body": "The idea here is to eliminate the supervisor and instead run whatever the supervisor used to run in several different containers. You can easily orchestrate this with \"docker-compose\", for example, all running the same container with different \"CMD\" overrides, or the same container with a different \"CMD\" layer at the end to split it out. The trouble here is the supervisor won't be able to communicate the status of the processes it manages to Docker. It will always be \"alive\" even if all of its processes are completely trashed. Exposing those directly means you get to see they crashed. .  What's best is to break out each of these services into separate containers. Since there's official pre-built ones for MySQL and so on there's really no reason to build one yourself. What you want to do is translate that \"supervisord\" config to \"docker-compose\" format. .  With separate containers you can do things like \"docker ps\" to see if your services are running correctly, they'll all be listed individually. If you need to upgrade one then you can do that easily, you just work with that one container, instead of having to pull down the whole thing. .  The way you're attacking it here is treating Docker like a fancy VM, which it really isn't. What it is instead is a process manager, where these processes just so happen to have pre-built disk images and a security layer around them. .  Compose your environment out of single-process containers and your life will be way easier both from a maintenance perspective, and a monitoring one. .  If you can express this configuration as something \"docker-compose\" can deal with then you're one step closer to moving to a more sophisticated management layer like Kubernetes which might be the logical conclusion of this particular migration. .  ",
      "P-tags": "docker-compos supervisord php linux docker",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_55332406",
      "task": "Saving DNS response in assembly using syscalls",
      "P-task": "save dn respons assembl use syscal",
      "F_verb": "save",
      "P-body": "Here is how it's done .  .  ",
      "P-tags": "socket dn linux assembl x86",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP in NP using NP"
    },
    {
      "id": "ul_513260",
      "task": "Commands Not Found when Passed through SSH",
      "P-task": "command found pass ssh",
      "F_verb": "find",
      "P-body": "GracefulRestart is almost certainly correct. .  No verify, compare the output of $PATH between on-server exec and ssh to server exec: .  \"[server2.com]# echo $PATH [jumpbox]# ssh server2.com 'echo $PATH'\" .  If the path to 'adcli' & 'realm' are missing on the ssh $PATH env variable, then the simplest way to fix is to simply use the full path. .  ",
      "P-tags": "command-lin shell-script ssh",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V when S"
    },
    {
      "id": "au_157640",
      "task": "How can I change the port of Remote Desktop?",
      "P-task": "chang port remot desktop",
      "F_verb": "change",
      "P-body": "For Ubuntu 12.04 you can do that via the \"gsettings\" command. This changes the port to \"1234\": .  To see all the options for Vino: .  ",
      "P-tags": "vnc remote-desktop network",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP"
    },
    {
      "id": "so_49453372",
      "task": "Bash; How to combine multiple files into one file",
      "P-task": "bash combin multipl file one file",
      "F_verb": "combine",
      "P-body": " ",
      "P-tags": "script bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP into NP"
    },
    {
      "id": "so_27519315",
      "task": "std::to_string is not declared compile error in aix",
      "P-task": "std : :to_str declar compil error aix",
      "F_verb": "declare",
      "P-body": "I'm not sure how much support the latest \"xlC 14.1\" (or whatever version you're using) has for \"std::to_string()\". .  If the support is incomplete, C has a hideous double macro method (a) of turning \"__LINE__\" into a C-string so that you can just use \"std::string\", the same as you have for the \"__FILE__\" and \"message\" items, and it appears the C++ pre-processor has stayed faithful to its hideous roots :-) .  The code: .  outputs: .  showing that the \"__LINE__\" has been successfully morphed into a C-string value. .  You should be able to use a similar method in your macro: .  Pre-processing that with \"g++ -E qq.cpp\" gives you: .  (showing relevant line only) which seems to match what you want. .  As a side note however, since you seem to be okay adding C-strings like \"\"[\"\" without needing to construct strings explicitly, I'm not sure that you need the \"std::string()\" calls at all for those. You still need the C macro hack to turn the integer into a C-string but, once that's been done, you should just be able to use that as-is. .  Changing the final macro to: .  will give you: .  Whether that's a good idea, I'll leave to the wider community but it at least gets around your immediate problem. I'd probably place the whole lot inside an \"#if/#else/#endif\" so that C++11 compilers that know about \"std::to_string()\" can use the more accepted approach. .   (a) If you're interested in why this works, I'll explain below. .  The \"#\" and \"##\" macro operators actually take precedence over the recursive nature of macro replacement, as per \"C11 6.10.3.4 /1\": .   After all parameters in the replacement list have been substituted and # and ## processing has taken place, all placemarker preprocessing tokens are removed. The resulting preprocessing token sequence is then rescanned, along with all subsequent preprocessing tokens of the source file, for more macro names to replace. .   That means that the code: .  will actually result in \"\"__LINE__\"\" because the \"#\" happens first and, once that's happened, the \"__LINE__\" within the string literal is not subject to further replacement. By doing the two-step process: .  the first level of replacement turns \"STR2(__LINE__)\" into \"STR1(3)\" because \"__LINE__\" on its own is subject to expansion. .  Then the second level turns \"STR1(3)\", via \"# 3\", into \"\"3\"\". .  Perhaps the following may help: .  The output of that, annotated, is: .  ",
      "P-tags": "c++11 c++ linux aix",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_617466",
      "task": "How to show a line number in bash TUI?",
      "P-task": "show line number bash tui",
      "F_verb": "show",
      "P-body": "Instead of doing this in the \"status_line\" function, I would use the \"draw_line\" function: it knows what the current line is, so it can be changed to output the line number at the start of each line. .  The \"printf\" arguments in the shell are close to those in C, including \"%d\" to display numbers and the size specifiers you\u2019d probably want to use here. You\u2019d also need to reduce \"COLUMNS\" as appropriate, or account for the line number in the width calculations. .  ",
      "P-tags": "text-user-interfac number bash",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_630415",
      "task": "Automatic pushing created / deleted VLANs form a Linux Router to switches",
      "P-task": "automat push creat delet vlan form linux router switch",
      "F_verb": "create",
      "P-body": "On the Linux router| .  Enable the \"GVRP\" setting in VLAN interface ifconfig config file: .  Bring you're interface up and down. .  On you're switch: .  Enable incoming GVRP data on the port that is connected with you're Linux router. .  ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "ul_209813",
      "task": "libdnet is installed but can't be found by snort",
      "P-task": "libdnet instal found snort",
      "F_verb": "find",
      "P-body": "I also upgraded recently to Fedora 22 and experienced the same issue. I resolved it by creating a symlink called libd.1 which points to (in my case) libdnet.so.1.0.1: .  After that Snort worked .  ",
      "P-tags": "snort package-manag fedora librari",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V by NP"
    },
    {
      "id": "ul_461840",
      "task": "Can chmod on a directory without --recursive change who can read a file within that directory?",
      "P-task": "chmod directori without -- recurs chang read file within directori",
      "F_verb": "read",
      "P-body": "If \"/path/to/dir\" has the permission bits \"0660\", then no-one can access \"/path/to/dir/file.txt\", since no-one has the \"x\" permission on the directory \"dir\". In general, they can't even see the type, size or permission bits of \"file.txt\", but some filesystems may reveal some of that data.) The owning user and members of the owning group can list the directory contents (the files within), since they have the \"r\" permission. The \"w\" permission isn't really useful without the permission.  .  See Execute vs Read bit. How do directory permissions in Linux work? .  ",
      "P-tags": "gnu filesystem chmod",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP within NP"
    },
    {
      "id": "au_700441",
      "task": "Any ubuntu plugin for terminal that creates a file with a basic html markup?",
      "P-task": "ubuntu plugin termin creat file basic html markup",
      "F_verb": "create",
      "P-body": "There is an easier method: create a \"template\" in \"~./Templates\" and \"cp\" that to make a copy where you need it. .  ",
      "P-tags": "html file command-lin",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP"
    },
    {
      "id": "so_47164584",
      "task": "Replace characters on specific location every line",
      "P-task": "replac charact specif locat everi line",
      "F_verb": "replace",
      "P-body": "The sed s command accepts flags that specify which field to replace. You can use that with something like: .  to do what you want (I make no claims about the robustness of this expression, and fully expect there are edge cases for which it fails). .  On the other hand, awk is ideally suited to this, and you can do things like: .  Again, these are intended as demonstrative examples only, and I make no claims regarding robustness.  .  ",
      "P-tags": "linux ed gnu",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_99510",
      "task": "How do I print the process name next to the process ID number in a file?",
      "P-task": "print process name next process id number file",
      "F_verb": "print",
      "P-body": "I opened a shell and typed \"man ps\" and then foudn the SEE ALSO section. Here's what it is on my Mint 14 system: .  Your instructions say to pick one of those and use it to list all the processes named \"sshd.\" In this case, pgrep is your friend. Read the man page for pgrep (man pgrep) to learn how to make pgrep spit out the process name along with the PID for the sshd processes. .  On my system, I see that the \"-l\" option will do it: .  ",
      "P-tags": "process ps",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "su_1334277",
      "task": "need <unrar/dll.hpp> to pip install unrardll on Ubuntu",
      "P-task": "need unrar dll hpp pip instal unrardl ubuntu",
      "F_verb": "install",
      "P-body": "The \"unrar\" sources, development files and library aren't packaged for Ubuntu, so you'll need to get them and install them yourself... .  There is an \"UnRAR source\" download on the \"extras\" page of rarlab.com - use this link with \"wget\" below. .  You'll need to build and install the library, and then use the \"--global-option\" with \"pip\" to point it at the headers. .  Follow along below: .  Please note that after doing this, the UnRAR library will be under your control, and thus you will be responsible for updating it. The \"unrar\" utility will still be provided by the package manager, so will update as normal. .   There is a PPA that provides the packages required for this, but the most recent version of Ubuntu supported is \"Saucy Salamander\" (13.10), last updated ~5 years ago with unrar v5.0.14. .  https://launchpad.net/~trinitronx/+archive/ubuntu/unrar-nonfree .  ",
      "P-tags": "linux ubuntu pip python rar",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "su_1034113",
      "task": "Can I install anything on this limited system?",
      "P-task": "instal anyth limit system",
      "F_verb": "install",
      "P-body": "From the output of the commands it appears that all filesystems that are mounted read-write are temporary ones, not backed by non-volatile memory. \"/dev/root\" is probably a symbolic link to one of the \"mtdblockX\" devices, the other partitions are likely to be for the bootloader and configuration. While there may be some free space there if you would remount it read-write, \"nmap\" is several megabytes large already, not to mention its dependencies, and is unlikely to fit on your device even if there was free space. .  It looks like your device has USB support. Depending on your definition of \"install\", a solution would be to mount a USB flash drive you prepopulated with the binaries you'd like to run, or even use the available \"ftpd\" to modify its contents remotely. .  The hard part is acquiring the software that will run on your device. You need a build that is compiled for the MIPS processor in your device, so that may require cross-compilation or finding a binary already compiled for your device (or a device with a compatible processor, kernel, libc and such). .  ",
      "P-tags": "linux shell telnet",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_28718168",
      "task": "Can the following test conditon be simplified",
      "P-task": "follow test conditon simplifi",
      "F_verb": "follow",
      "P-body": "While I agree with the commenters on your question that there may be a better way overall to do what you want to do, to solve this with a single command that is more simplified, you could move your IF statement into awk: .  ",
      "P-tags": "linux test unix",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_25394772",
      "task": "Parsing iwlist scan using bash",
      "P-task": "pars iwlist scan use bash",
      "F_verb": "parse",
      "P-body": "For parsing with such differences in the wanted value formats, you will either need an \"awk script\" or a \"bash script\" to give you the flexibility you need to get all the values. you can do it in one line, but it gets very messy). Here is a bash script that will parse \"iwlist\" and output \"mac essid frq chn qual lvl enc\". I have no \"Noise\", but you can simply follow the format to add it if you desire. .  The usage is from the command line as you want. E.g. \"iwlist 'iface' scan | bash parseiwl.sh\" (where '\"iface'\" is \"ath0\" for you and \"parseiwl.sh\" is just the name I saved the script under). Note: this script is non-portable due to the use of \"[[]]\" and \"=~\" so use in bash only: .  example: .  ",
      "P-tags": "awk linux shell bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP using NP"
    },
    {
      "id": "ul_457432",
      "task": "change the executable JAR file permissions accordingly:",
      "P-task": "chang execut jar file permiss accordingli :",
      "F_verb": "change",
      "P-body": "You need to edit the \"/etc/sudoers\" and add the user peris into it. Either open the file with your favorite edit, for example \"vim\": .  and add the user there under \"root ALL=(ALL:ALL) ALL\" with the same syntax: .  Or just edit it via the command \"visudo\". NOTE: You must do this with root privileges, i.e. \"sudo\". .  ",
      "P-tags": "linux sudo",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_9336258",
      "task": "powershell Get-Counter -ComputerName parameter on Windows 7",
      "P-task": "powershel get-count -computernam paramet window 7",
      "F_verb": "get",
      "P-body": "You can omit the -computername parameter and path the counters directly: .  and that seems to work. .  ",
      "P-tags": "powershel powershell-2 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_47759036",
      "task": "Enabling php ext-xml?",
      "P-task": "enabl php ext-xml",
      "F_verb": "enable",
      "P-body": "It looks like you're using ubuntu 16.04 with the ondrej/php ppa to get the latest version of php. In this case, the package names need to match the version of php you're using: .  You can see the different versions available with something like this: .  Depending on your configuration, you may need to prefix the installation command with \"sudo\". .  ",
      "P-tags": "symfoni ubuntu php",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_61008701",
      "task": "Batch script: Convert path to linux format using wslpath",
      "P-task": "batch script : convert path linux format use wslpath",
      "F_verb": "convert",
      "P-body": "Try this: .  \"%cd%\" returns the path without ending backslash. So you can add a second variable that clears it. .  UPDATE (with string substitution only - use the toLinuxPath subroutine)  .  ",
      "P-tags": "batch-fil windows-subsystem-for-linux",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP using NP"
    },
    {
      "id": "ul_571334",
      "task": "How do I insert my bash variable into my ruby command?",
      "P-task": "insert bash variabl rubi command",
      "F_verb": "insert",
      "P-body": "You use singe quotes. In bash, variables within single quotes do not get expanded. .  ",
      "P-tags": "rubi environment-vari bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_52953924",
      "task": "Sudo make Error: make:*** [prepare-compiler-check] Error 1",
      "P-task": "sudo make error : make : prepare-compiler-check error 1",
      "F_verb": "make",
      "P-body": "It seems that you have an old version of compiler. Do \"make mrproper\", configure, then try: .  \"scripts/config --disable CC_STACKPROTECTOR_STRONG\" .  thereafter \"sudo make -jN\" can be done (where N - is the number of jobs). .  Useful links: 1, 2, 3 .  ",
      "P-tags": "configur linux ubuntu linux-kernel virtualbox",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "au_1110551",
      "task": "xcb-xrm not found when installing polybar",
      "P-task": "xcb-xrm found instal polybar",
      "F_verb": "find",
      "P-body": "There are several ways to solve this problem. I see you are using the \"build.sh\" script. Here the easiest way is to pass the \"-f\" flag to the script when running it, like so: \"build.sh -f\" .  This will force polybar to completely reconfigure itself and thus also detect the xrm dependency. .  If you are not using the \"build.sh\" script, the remaining two ways are to either .   Delete the \"build\" dir (this is what \"build.sh -f\" also does) and run \"cmake\" and \"make\" again When running \"cmake\", additionally pass the \"-DWITH_XRM=ON\" flag, this will force enable xrm support. If you are familiar with it, you can also use \"cmake\" to change the \"WITH_XRM\" variable to \"ON\"  ",
      "P-tags": "18 04 compil librari make",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V when S"
    },
    {
      "id": "so_34397320",
      "task": "Can I collapse this into a single line of code using the pipeline?",
      "P-task": "collaps singl line code use pipelin",
      "F_verb": "use",
      "P-body": "Sure. Simply add .  after the \"Select-Object\". .  ",
      "P-tags": "pipelin powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_11268765",
      "task": "how to get correct orig_eax value when stopped in syscall?",
      "P-task": "get correct orig_eax valu stop syscal",
      "F_verb": "get",
      "P-body": " This is on Ubuntu 12.04, with kernel 3.2.0 .   This doesn't uniquely identify your system. What processor? .  My crystal ball tells me that \"sleep\" you are invoking is a 64-bit program, while your tracer program is not. Or vice versa. .  ",
      "P-tags": "debug linux system-cal ptrace",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "su_368899",
      "task": "Using convert to covert multiple jpg files to pdf - pdf quality",
      "P-task": "use convert covert multipl jpg file pdf - pdf qualiti",
      "F_verb": "convert",
      "P-body": " Do you have ImageMagick installed? .  ",
      "P-tags": "jpeg linux pdf convers",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_54386598",
      "task": "Least Priviledge Role to start/stop vm in Azure",
      "P-task": "least priviledg role start stop vm azur",
      "F_verb": "start",
      "P-body": "yes, the only solution is to create custom role, sample powershell: .  you can remove restart action if you dont need to restart vms .  ",
      "P-tags": "azur azure-powershel azure-role-environ",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_589146",
      "task": "How do I write sequentially several tar's to a tape?",
      "P-task": "write sequenti sever tar tape",
      "F_verb": "write",
      "P-body": "The behavior is related to the EOF handling of the tape driver. .  This handling differs between operating systems and it may help to read the related Solaris man page: .  http://schillix.sourceforge.net/man/man7i/mtio.7i.html .  that explains a difference between the Solaris handling and the old BSD behavior. .  From this explanation, I would expect the old BSD behavior to cause a read after an EOF situation to skip the file mark and to return the first record from the next file on tape. This seems to be what you expect. .  It seems that the observed behavior on BSD is between the documented SVr4 behavior and the old BSD behavior, but I guess that there is a way to make things work on both Solaris and current BSD: .   call tar to read the first tape file .  after that, the tape is positioned at the end of the first tape file, which is just before the file mark... .  call \"mt fsf\" to skip the file mark .  call tar to read the next file on tape. .   From the rest of the discussion, it seems that FreeBSD writes an additional filemark, when \"mt rewind\" is called after a write operation has been applied. .  The command \"mt eom\" will position the tape after the final double filemark and when another write operation takes place, this happens after the double filemark resultng in an empty tape file before that final write. .  A tape with three files looks this way: .  If you like to append a fourth tape file, you need to call: .  to position the tape after the thirf filemark. If you then start writing, this overwrites the fourth filemark and if you then rewind again, you have this tape layout: .  ",
      "P-tags": "freebsd tar backup tape",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP to NP"
    },
    {
      "id": "so_25170085",
      "task": "I need to Parse a tab separated text file, convert from hex to decimal, plot specific values, then calculate RMS value",
      "P-task": "need pars tab separ text file convert hex decim plot specif valu calcul rm valu",
      "F_verb": "parse",
      "P-body": "To be honest I do not know about the plotting and RMS bit, but the rest is really easy in PowerShell. .  You'll need the Get-Content cmdlet, a Regular Expression match, use of a ForEach loop, creating PSCustomObjects, and the [Convert]::ToInt32() method. .  That will output an array of custom objects with 2 properties (TimeStamp and Data) that are an actual DateTime object parsed from the date and time string listed, and the decimal values of the 5th, 6th, 7th, and 8th hex bytes (all mashed together, though I don't know if you want that or want them added, or what) within the parenthesis of any line in the file specified that has the \"44 CT_CCS\" string in it followed by something in parenthesis. Making up some random fake data (the third listed was your exact sample line) in a file output the following for me: .  You could pipe that to a CSV file by adding \"| Export-CSV C:\\Path\\To\\NewFile.csv -NoTypeInformation\" after the last \"}\" in that code. .  As I said, I really don't know anything about the plotting or RMS bit but this at least gets you pairs of numbers that you could plot and convert. Perhaps somebody else could assist with the rest of that. .  As for the Ones, Tens, Hundreds, and Thousands... \"$Matches[2].Split(\" \")\" takes everything in the () from that line, and creates an array from it. I pipe that to a \"ForEach\" loop (alias \"%\" used) that performs \"[Convert]::ToInt32($_,16)\" on each hex number pair specified. I'm specifying records \"[4..7]\" which are the 5th through 8th number pairs. In your example that would be 08, 64, 00, and 00. If you want more just change the \"[4..7]\" to whatever you want to include. If you want to break it down into different columns you can add more lines. Such as: .  could become: .  That would output (using my same fake data): .  Edit: Ok, use the code with \"TimeStamp=\" and \"Data=\" up above. It now grabs the 0864 and converts that to dec like you want it to. .  Edit w/ your code: I copied and pasted your code into my PowerShell and modified it a little (missing some \"\\\" characters). I ran it and it ran ok, but I realized that having date and time separate would probably be a good thing so I split those out. I ran it against a text file named SomeFile.txt with these 3 lines: .  It output a CSV containing this: .  This is the code I ran to do that: .  ",
      "P-tags": "powershel pars perl",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "su_139684",
      "task": "Windows 7: run powershell v2 from start menu's run command",
      "P-task": "window 7 : run powershel v2 start menu run command",
      "F_verb": "run",
      "P-body": "Windows 7 ships with Powershell 2.0. Are you certain that you are running version 1? To confirm run this $PSVersionTable inside the power shell. .  Here is the output from my machine: .  ",
      "P-tags": "powershel windows-7",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_559787",
      "task": "Updating a Linux app (rsync) - what am I meant to do with .yo files?",
      "P-task": "updat linux app rsync - meant yo file",
      "F_verb": "update",
      "P-body": "Follow the installation instructions in the \"INSTALL\" file: as root, run .  This will copy \"rsync\" to whatever prefix \"./configure\" used (\"/usr/local\" by default, so \"rsync\" will end up in \"/usr/local/bin\"), and the manpages to the appropriate directory. .  Don\u2019t replace your existing binaries. Instead, remove the \"rsync\" package (if you can). .  ",
      "P-tags": "upgrad man",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "au_483363",
      "task": "Good shell script to move a file to another location?",
      "P-task": "good shell script move file anoth locat",
      "F_verb": "move",
      "P-body": "You need to change the line  .  \"mv -f $File /home/jon/temporary\" (Ln 9) .  to  .  \"mv -f $FILE /home/jon/temporary\" .  You declared it in capitals. .  ",
      "P-tags": "script sh mv",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP to NP"
    },
    {
      "id": "so_16171865",
      "task": "to grep a pattern from file compare contents with another file and replace",
      "P-task": "grep pattern file compar content anoth file replac",
      "F_verb": "grep",
      "P-body": "This awk script can do the job (this is an enhancement of above answer from @EDMorton): .  Splitting the command in 2 as per OP's request .  ",
      "P-tags": "sed awk unix grep",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP with NP"
    },
    {
      "id": "au_1261270",
      "task": "Dell xps 13 ubuntu 20 touchpad not moving after login",
      "P-task": "dell xp 13 ubuntu 20 touchpad move login",
      "F_verb": "move",
      "P-body": "After a long trial and error: .  where \"12\" is the device id I got from \"xinput list\", and \"316\" is a stupid attribute which is called \"Synaptics Off (316):\". For me it was set to \"1\" for some reason, so I set it to \"0\" using the above command. .  ",
      "P-tags": "touchpad",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V after NP"
    },
    {
      "id": "so_11573974",
      "task": "Write to .txt file?",
      "P-task": "write txt file",
      "F_verb": "write",
      "P-body": " ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP"
    },
    {
      "id": "so_56948849",
      "task": "DevOps Powershell step calls bat file successfully but returns 1",
      "P-task": "devop powershel step call bat file success return 1",
      "F_verb": "return",
      "P-body": "Have you considered changing the batch file exit code? .   Exit codes for batch files .  Use the command EXIT /B %ERRORLEVEL% at the end of the batch file to return the error codes from the batch file .   EXIT /B at the end of the batch file will stop execution of a batch file. use EXIT /B < exitcodes > at the end of the batch file to return custom return codes. Environment variable %ERRORLEVEL% contains the latest errorlevel in the batch file,which is the latest error codes from the last command executed. To know about Environment variable see the below note.  Note: Environment variables are a set of dynamic named values that can affect the way, running processes will behave on a computer. For example, an environment variable with a standard name can store the location that a particular computer system uses to store user profile this may vary from one computer system to another. .  In the batch file , it is always a good practice to use environment variables instead of constant values. Since the same variable get expanded to different values on different computers. .  Example: .  Batch file for Copying File to a Folder .   https://www.manageengine.com/products/desktop-central/returning-error-code-on-scripts-how-to.html .  EDIT: Some more thoughts about the problem- The batch file probably returned 1 as an exit code because one of the commands or programs used within it returned some kind of error code (or at least didn't return 0 exit code). for summing up, your question was not very clear mainly because you didn't separate all the factors and variable withing your problem, thus not knowing where the problem is. Force changing the exit code isn't the right way to fix your problem.  .  ",
      "P-tags": "devop powershel batch-fil yaml",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_454544",
      "task": "Remove multiple strings from file on command line, high performance",
      "P-task": "remov multipl string file command line high perform",
      "F_verb": "remove",
      "P-body": "How big is your \"hitfile\" exactly? Could you show some actual examples of what you're trying to do? Since you haven't provided more details on your input data, this is just one idea to try out and benchmark against your real data. .  Perl regexes are capable of becoming pretty big, and a single regex would allow you to modify the input file in a single pass. Here, I'm using \"/usr/share/dict/words\" as an example for building a huge regex, mine has ~99k lines and is ~1MB big. .   I don't need regex, I only need to compare pure/exact strings against a hash (for speed). i.e. \"pine\" should not match \"pineapple\", but it should match \"(pine)\". .   If \"pine\" should not match \"pineapple\", you need to check the characters before and after the occurrence of \"pine\" in the input as well. While certainly possible with fixed string methods, it sounds like the regex concept of word boundaries (\"\\b\") is what you're after. .   Is there an elegant, high-performance one-liner way ... for my workflow I'd prefer a simple command to my script. .   I'm not sure I agree with this sentiment. What's wrong with \"perl script.pl\"? You can use it with shell redirections/pipes just like a one-liner. Putting code into a script will unclutter your command line, and allow you to do complex things without trying to jam it all into a one-liner. Plus, short does not necessarily mean fast. .  Another reason you might want to use a script is if you have multiple input files. With the code I showed above, building the regex is fairly expensive, so calling the script multiple times will be expensive - processing multiple files in a single script will eliminate that overhead. I love the UNIX principle, but for big data, calling multiple processes (sometimes many times over) and piping data between them is not always the most efficient method, and streamlining it all in a single program can help. .   Update: As per the comments, enough rope to shoot yourself in the foot Code that does the same as above in a one-liner: .  ",
      "P-tags": "awk command-lin rubi tr perl",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP on NP"
    },
    {
      "id": "au_1329742",
      "task": "Zoom won't close and more common issues",
      "P-task": "zoom close common issu",
      "F_verb": "close",
      "P-body": "Zoom is difficult to close The close button \u274c on the top right corner of the Zoom window does not actually close the app. It minimizes the app and removed the app icon from the Dash/Dock (the left panel in Ubuntu). Normally Zoom icon in the system-trey/app-inidiator (top panel) would alert you that Zoom is not closed and close Zoom from there. However, a bug is preventing Zoom icon from appearing in the system-trey. .  Check Zoom Settings First, let us change the default setting so that you are visually reminded that Zoom is not closed when you click the \u274c button. .  Click on the Zoom settings cog icon on the top right of the Zoom window. .   .  On the General tab, uncheck When closed minimize windows to the notification area instead of the task bar. .   .  Note, this will not close zoom when you click on the close icon \u274c. But now you will see that Zoom was not really closed. You can close Zoom by using the context menu of the Zoom icon on the Dock. .   .  There is a bug in \"gnome-shell-extension-appindicator\" This bug prevents the Zoom icon showing up in the system trey if Zoom is set to start automatically on login. .  See No system tray detected after latest update for some applications for various workarounds for this bug. .  Hope this helps .  ",
      "P-tags": "zoom-meet crash 20 04",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "so_56850171",
      "task": "Run a remote .sh script from a local .bat script",
      "P-task": "run remot sh script local bat script",
      "F_verb": "run",
      "P-body": "You can user WinSCP for example \"put_file.bat\" .  \"\"C:\\Program Files\\WinSCP\\winscp.com\" /ini=nul /script=\"C:\\Program Files\\WinSCP\\ticket_upload.sftp\"\" .  for example ticket_upload.sftp .  ",
      "P-tags": "batch-fil bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "su_208681",
      "task": "Problems excluding directories in a Linux find",
      "P-task": "problem exclud directori linux find",
      "F_verb": "exclude",
      "P-body": "This should work: .  ",
      "P-tags": "linux find",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "so_26929556",
      "task": "Can $() always replace backticks for command substitution?",
      "P-task": "alway replac backtick command substitut",
      "F_verb": "replace",
      "P-body": "You are running into one of the reasons that \"$()\" is preferred to the backtick notation. The shell parsing of \"$()\" is more consistent (as it introduces a new parsing context as I understand it). .  So your escaping, while correct for the backtick code, is excessive for the \"$()\" code. .  Try this: .  A little more clearly compare this .  to this .  ",
      "P-tags": "syntax bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP for NP"
    },
    {
      "id": "so_3776718",
      "task": "What command do you use to preview any image",
      "P-task": "command use preview imag",
      "F_verb": "use",
      "P-body": "\"display -size 200x200 filename\"  .  See http://www.imagemagick.org/www/display.html .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V S_INF"
    },
    {
      "id": "so_10964593",
      "task": "HDI: Check the \"in-stock\" status of an item on a web site in bash?",
      "P-task": "hdi : check in-stock statu item web site bash",
      "F_verb": "check",
      "P-body": "You could use curl to grab the web page then grep to search for the alt text of the button...  .  ",
      "P-tags": "scrape webstor bash",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP of NP on NP in NP"
    },
    {
      "id": "so_19820755",
      "task": "Find files by size and copy them to other directory",
      "P-task": "find file size copi directori",
      "F_verb": "find",
      "P-body": " The key part is --parents, to mirror the directory structure. I used -p to preserve mode, timestamp, and ownership. I find \"-exec {} +\" more intuitive than \"-exec {} ;\", but it doesn't matter here, beyond the need to reorder arguments to cp with the former. .  ",
      "P-tags": "copi find unix",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP by NP"
    },
    {
      "id": "so_67492584",
      "task": "How to include one line above of the keyword line during SPLITING a big txt file using Regex and PowerShell",
      "P-task": "includ one line keyword line splite big txt file use regex powershel",
      "F_verb": "include",
      "P-body": "Continuing from my comment, I think it would be far easier to make the split on the line that says \"End\". .  Try .  Using your example this results in three files: .  1.txt .  2.txt .  3.txt .  ",
      "P-tags": "powershell-2 0 powershell-4 0 regex powershel powershell-3 0",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP of NP during NP using NP"
    },
    {
      "id": "so_9786879",
      "task": "Use Powershell to change password on login",
      "P-task": "use powershel chang password login",
      "F_verb": "change",
      "P-body": "This link might help you. .  Also, according to the link above, you need to be on the domain controller to use \"net\" to change password (or supply the \"/domain\" option). .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP on NP"
    },
    {
      "id": "au_587543",
      "task": "shutdown from gnome menu doesn't ask password",
      "P-task": "shutdown gnome menu ask password",
      "F_verb": "ask",
      "P-body": "You can do this in dconf editor. You can install this with \"sudo apt-get install dconf-editor\" See below for the adjustments to make. You can also choose to suppress the restart menu item (among others) .   .  Suppressing the menu item will remove the option from the menu in the upper right corner of the screen. After a reboot). Of course the option won't exist for you either but you can always shutdown by opening a terminal with CTRL+ALT+T and issuing the command \"sudo shutdown -h now\" or restart with \"sudo shutdown -r now\" .  ",
      "P-tags": "password shutdown",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP"
    },
    {
      "id": "so_21095785",
      "task": "PowerShell: get all processes and save them to an xml file?",
      "P-task": "powershel : get process save xml file",
      "F_verb": "get",
      "P-body": "In order to find commands involving XML you can do .  In your case you can use Export-Clixml like this: .  Get-Process | Export-Clixml filename.xml .  ",
      "P-tags": "powershell-3 0",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_43638388",
      "task": "Why is while read data; do echo \"$data\" | cut -d: -f1; done so slow?",
      "P-task": "read data echo data cut -d : -f1 done slow",
      "F_verb": "read",
      "P-body": "Your loop reads each line of input, and creates a new \"cut\" process for each line. The original one-liner used a single \"cut\" process for all the input. Thankfully, you can inherit the script's standard input, and simply write .  There's no need for your script to do anything at all, except replace itself with an appropriate \"cut\" invocation. I included \"\"$@\"\" in case you want to provide additional arguments to \"cut\", but you can safely leave that out if you're sure you don't need it. .  ",
      "P-tags": "pipe perform bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_1261639",
      "task": "Could not connect to cran.stat.ucla.edu:80",
      "P-task": "could connect cran stat ucla edu:80",
      "F_verb": "connect",
      "P-body": "The repository server at http://cran.stat.ucla.edu seems to be down, You can try the repositories given at .  https://cran.ma.imperial.ac.uk/bin/linux/ubuntu/README.html .  Edit: You can use them by appending .  in .  After appending and saving, issue this command .  If you get some key error in above commands, issue .  and repeat update and install commands. .  ",
      "P-tags": "apt updat",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "su_667729",
      "task": "How to remove string from JPEG files using find?",
      "P-task": "remov string jpeg file use find",
      "F_verb": "remove",
      "P-body": "Explanation What you described is a part of a known PHP backdoor. The main PHP code is obscured by base64 encoding so that it is not so easily detectable. The code you showed is normally hidden in the Exif header \"Model\" and another important part (PCRE \"/.*/e\") is normally in the header \"Make\". .  The code from Exif gets executed by another part of the backdoor - calling \"preg_replace($exif['Make'],$exif['Model'],'');\" on the Exif data from the image. For details see for example Malware Hidden Inside JPG EXIF Headers or Hiding Webshell Backdoor Code in Image Files. .  Solution You can remedy the infected images by removing the relevant Exif headers. First check if the problematic strings are in the headers \"Make\" and \"Model\": .  Then you can remove the headers: .  This code will remove the two headers from all the \".jpg\" files regardless of the content of the headers. If you want to remove just the infected headers the code would be considerably more complicated. The script to do this is below at the end of this answer. .  After checking that the results are OK you can remove the backups created by \"exiftool\": .  Keep in mind that the other part of the backdoor whould be removed too. It is in the PHP code on the server and normally looks like: .  Script for more accurate removal The following script detects in which Exif headers there is the code of malware. Store the code into a file e.g. \"rm-jpg-backdoor\" then enable execution: \"chmod a+x rm-jpg-backdoor\". When calling the script you can pass directories of files to clean as arguments. Example: \"./rm-jpg-backdoor /directory/with/images\" .  ",
      "P-tags": "jpeg linux malware-remov find malwar",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "so_44243138",
      "task": "Taking arguments from windows run in powershell",
      "P-task": "take argument window run powershel",
      "F_verb": "take",
      "P-body": "PowerShell essentially provides two ways for handling script arguments: .   The automatic variable \"$args\" holds a list of all arguments, which can then be accessed by index: .  Script: .  Invocation: .  Output: .   A \"Param()\" section at the beginning of the script gets the parameter values assigned to individual variables: .  Script: .  Invocation: .  Output: .    If you want to be able to invoke a PowerShell script without explicitly running the \"powershell.exe\" command you need to change the default action for the \"Microsoft.PowerShellScript.1\" type in the registry, though. You probably also need to adjust the execution policy on your system(s) (\"Set-ExecutionPolicy RemoteSigned -Force\"). .  Typically you'd use \"$args\" only for very simple scenarios (a handful arguments in well-defined order). A full parameter definition gives you far better control about the parameter handling (you can make parameters optional or mandatory, define parameter types, define default values, do validation, etc.). .  ",
      "P-tags": "powershel window",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "ul_437745",
      "task": "OpenSUSE Tumbleweed: The GUI fails to Start. Tumbleweed boots to CLI",
      "P-task": "opensus tumblewe : gui fail start\ntumblewe boot cli",
      "F_verb": "start",
      "P-body": "In the log file line number 69 and 70 are the problems: .  You can run \"sudo zypper in xf86-video-intel\" command to fix this. Since you cannot see the desktop, so you can connect to the WiFi using \"nmcli\" from the same screen that you have posted. .  Steps to do that: .  Step 1: Log in CLI with root or your credentials. After that run \"nmcli con up <mySSID> --ask\" command. .  Step 2: Enter the password and then you can see the connection status. .  Step 3: Now, run the command \"sudo zypper in xf86-video-intel\". .  Ste 4: Reboot the PC by runnng \"reboot now\" or \"sudo reboot now\". .  Things should be fixed now and you will see the log in screen and GUI. .  ",
      "P-tags": "linux opensus",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP to NP"
    },
    {
      "id": "so_47423990",
      "task": "Linux randomly deleted my file while compiling what do I do?",
      "P-task": "linux randomli delet file compil",
      "F_verb": "delete",
      "P-body": "Your problem is here: \"-o prog3.c\". \"gcc\"\u2019s \"-o\" option is used to tell \"gcc\" which name it should give to the executable it generates. So here, you\u2019re basically asking your compiler to replace your \"prog3.c\" source file by an executable. Sadly your code is gone... .  ",
      "P-tags": "linux compil recov gnu",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP while S"
    },
    {
      "id": "su_12268",
      "task": "How to take Screen Shot in Ubuntu",
      "P-task": "take screen shot ubuntu",
      "F_verb": "take",
      "P-body": "There is a program 'shutter' which is a fully featured screen shot application. If you don't have it installed then you should be able to get it by: .  More simply you will likely have \"Take Screeshot\" under you Applications\u2014>Accessories menu. .  ",
      "P-tags": "screenshot ubuntu",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_52069436",
      "task": "Find and execute files whit ()",
      "P-task": "find execut file whit",
      "F_verb": "execute",
      "P-body": "You have to quote the arguments which will contain parentheses after substitution -- as you did for the \"Content-Type:\" argument -- so that the shell doesn't try to parse the special characters (note: there are two places where I inserted quotes): .  ",
      "P-tags": "json unix shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_43336255",
      "task": "I want to pass a selected value in a combobox to a parameter in powershell",
      "P-task": "want pass select valu combobox paramet powershel",
      "F_verb": "pass",
      "P-body": "Not sure I really understand your question. Here is a runnable example showing how to \"trap\" a selection change in a combo box.  .  Maybe it can give you a track to follow: .  ",
      "P-tags": "powershel wpf",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP in NP to NP in NP"
    },
    {
      "id": "so_22793713",
      "task": "How to set a shell exit trap from within a function in zsh and bash",
      "P-task": "set shell exit trap within function zsh bash",
      "F_verb": "set",
      "P-body": "Obligatory boring and uninteresting answer: .  ",
      "P-tags": "zsh shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_35400455",
      "task": "GOPATH not set correctly",
      "P-task": "gopath set correctli",
      "F_verb": "set",
      "P-body": " Package os .  func Getwd .  Getwd returns a rooted path name corresponding to the current directory. If the current directory can be reached via multiple paths (due to symbolic links), Getwd may return any one of them. .   You got what you asked for, your current directory: \"/home/rangga\". .  Change your current directory, .  ",
      "P-tags": "go ubuntu",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_27951624",
      "task": "Powershell Regex find emails and replace email with (<email>)",
      "P-task": "powershel regex find email replac email email",
      "F_verb": "replace",
      "P-body": "I am not convinced that your email Regex is fully robust, but you are only reading the file and not writing back to it. .  I recommend using Get-Content and Set-Content and using piping to link everything together. Although this could get slow and memory intensive for very large files. .  Something like: .  Running the above Powershell turns the textfile C\\test\\test.txt from: .  into .  ",
      "P-tags": "powershel regex",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP with NP"
    },
    {
      "id": "su_466812",
      "task": "Time not set properly when dual booting CentOS and Ubuntu",
      "P-task": "time set properli dual boot cento ubuntu",
      "F_verb": "set",
      "P-body": "Use \"ntpq -p\" to check that NTP is operating. Remember, NTP is designed for continuous operation and may take considerable time to settle at an accurate value. .  Note that NTP software doesn't like making huge adjustments in time so it is worth checking that both operating systems have the same ideas about how the motherboard RTC is interpreted. Typically this is used at startup to set the Linux system clock. .  e.g. in /etc/default/rcS .  If the two OSs disagree, you could get the symptoms you observe. But note different distros have different config files so I'd read relevant man pages carefully. .  ",
      "P-tags": "cento ubuntu time multi-boot",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP when S"
    },
    {
      "id": "so_3656077",
      "task": "Command Line to see the contents Shared Object Module(lib*.so)",
      "P-task": "command line see content share object modul lib",
      "F_verb": "see",
      "P-body": "use \"nm -D --defined-only libname.so\" to get the symbol names from your dynamic library. The \"--defined-only\" switch shows you only the symbol that are defined in these files, and not references to external functions. .  An alternative is to use objdump, and catch only the symbols in the text section : .  ",
      "P-tags": "linux shared-object c dll",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP"
    },
    {
      "id": "so_10656324",
      "task": "\"update-rc.d: /etc/init.d/unicorn_app: file does not exist\" in ubuntu 10.04",
      "P-task": "update-rc : etc init unicorn_app : file exist ubuntu 10 04",
      "F_verb": "update",
      "P-body": "I guess the \"red\" colour in LS means that unicorn_app is a broken symbolic link. Please try \"ls -l /etc/init.d/unicorn_app\", see if the file it points to exist or not. .  In addition, you may run \"file /etc/init.d/unicorn_app\" to see if it is a broken symbolic link or not. .  ",
      "P-tags": "nginx ruby-on-rails-3 ubuntu unicorn ruby-on-rail",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    }
  ],
  "10": [
    {
      "id": "ul_298421",
      "task": "Ignore 'cannot remove `dir`: Is a directory message",
      "P-task": "ignor remov dir : directori messag",
      "F_verb": "ignore",
      "P-body": "You can just throw away the error messages: .  That'll throw away all errors. If you want to see other potential errors then we can do something more complicated: .  In this way other errors will still be logged. .  ",
      "P-tags": "directori deleted-fil rm",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP"
    },
    {
      "id": "su_1069987",
      "task": "Unable to edit files and folders over Samba",
      "P-task": "unabl edit file folder samba",
      "F_verb": "edit",
      "P-body": "in your mount command, provide the Group with Write permission, and change the owner-group to Users, or alternately, allow the Other group write permissions.  .  Normally you would use the commands below: \"sudo chown -R root:users /media/ECHO; sudo chmod -R 775 /media/ECHO\" .  or .  \"sudo chmod o+w /media/ECHO\" .  but since you are using ex-fat, you will have to edit it in FSTAB instead. .  samba permissions stack atop filesystem permissions, so even if you tell samba to allow write, it won't unless the filesystem also provides that user the same write permissions. Based on your permissions (755), only the owner (root) could write.  .  Adding an umask to the fstab does this if you're using exfat-fuse. .  ",
      "P-tags": "linux debian samba",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP over NP"
    },
    {
      "id": "su_1373939",
      "task": "How can I use the linux terminal to access another file system on a network?",
      "P-task": "use linux termin access anoth file system network",
      "F_verb": "use",
      "P-body": "SCP When using scp, you have to have an openssh-server on the remote computer you're trying to access. You can check if it's installed with \"apt-cache policy openssh-server\" . Then scp is used to fetch a file like this:  .  \"scp user@remote-hostname:Documents/file.txt ~/Documents/\" .  or to send a file: .  \"scp ~/Documents/file.txt user@remote-hostname:Documents/\" .  which will prompt you to enter the remote-user's password. The path after the colon (:) assumes the user's home directory, which is why you can use Documents/file.txt instead of /home/user/Documents/file.txt .  .  NFS NFS is the linux-only Network File System. I've never used it but you can find some instructions at https://mxlinux.org/wiki/networking/nfs ... However those instructions do not show how to setup security on the shares so that a password is necessary to access the shares. .  SAMBA Samba (SMB/CIFS) is a file server that is compatible with Gnu/Linux and Windows computers. I use samba, but I don't use it to access Windows computers so I don't know if there are any quirks in that use-case (Linux to Windows). You can find good instructions for setting up samba on a debian-based system (Debian, Ubuntu, Linux-mint, etc) at https://wiki.debian.org/SambaServerSimple: .  ........................................................ .  Install Samba Server as root or using sudo .  Install Samba Client .  And the instructions go on to configuring samba's config file (/etc/samba/smb.conf) and setting up samba passwords (which are separate from your users system-login password but the same password can be used). .  ........................................................ .  If you run \"apt-cache show samba\" on your machine it shows information on the samba package. One sentence to note:  .   This package is not required for connecting to existing SMB/CIFS servers (see smbclient) or for mounting remote filesystems (see cifs-utils). .   To set up a share that doesn't require entering a password, a paragraph like the one that follows can be added to your /etc/samba/smb.conf : .  To access a samba share from the file-browser on my pc's, sometimes using the 'browse network' button or menu entry doesn't work. In that case I manually have to type in the samba address into 'pathbar' by clicking in the pathbar, or if you pathbar is in a 'button' view, you can revert it to a pathname by using the keyboard shortcut Ctrl-l (lower-case L). Then type in: \"smb://IP-address/sharename\" . For samba-shares that were set up without requiring a password, you can leave the password field empty and press the connect button. .  ",
      "P-tags": "termin linux remot",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP S_INF on NP"
    },
    {
      "id": "su_919318",
      "task": "Search for files created at specific time in folder OS X",
      "P-task": "search file creat specif time folder os x",
      "F_verb": "create",
      "P-body": "You can install ImageMagick utils and use \"identify\" command for that. .  You can install it via \"brew install ImageMagick\". .  Here is the suggestion how you can use this tool: .  It should print the files matching the criteria in format like: .  To search for all files recursively, use a new globbing option which is \"**/*.jpg\" (it's available in Bash 4.x, zsh and similar shells). .  ",
      "P-tags": "shell command-lin maco",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V at NP in NP"
    },
    {
      "id": "au_725280",
      "task": "Mount errors when trying to open a DVD - is the unit broken?",
      "P-task": "mount error tri open dvd - unit broken",
      "F_verb": "mount",
      "P-body": "I found How to fix it. .  add at the bottom .  reboot .  ",
      "P-tags": "mount dvd",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V"
    },
    {
      "id": "au_173329",
      "task": "What alternatives are available to replace the purple boot splash screen?",
      "P-task": "altern avail replac purpl boot splash screen",
      "F_verb": "replace",
      "P-body": "Ubuntu Sunrise (plymouth) I use an old favorite \"Ubuntu Sunrise\" in 12.04 (In fact I have been using it since 10.04 LTS). It's easy to install (instructions below) and it has never caused me any issues. However you should note that changing your Plymouth may cause resolution issues depending on your own resolution. .   .  INSTALLATION INSTRUCTIONS .  Step 1: .  Download the Plymouth Sunrise deb file from here. .  Step 2: .  Open the Terminal (Ctrl-Alt-T) and type .  Step 3 .   Copy \"ubuntu-sunrise\" folder to \"/lib/plymouth/themes\"  Copy the file splash into \"/etc/initramfs-tools/conf.d\" (Optional, for better buffer)  Step 4: .  Type in the terminal .  Step 5: .  Choose the number associated with \"ubuntu-sunrise\" in the options that pop up. .  Step 6 .  Type in the terminal .  Then .  That's it. .  Note: Some people have issues installing other Plymouth themes (I've never had any) and I would strongly advise you to take a look at these issues here at Ask Ubuntu to familiarise yourself. .  ",
      "P-tags": "plymouth",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP"
    },
    {
      "id": "ul_65902",
      "task": "Why does bash show 'Terminated' after killing a process?",
      "P-task": "bash show termin kill process",
      "F_verb": "terminate",
      "P-body": "Short answer In \"bash\" (and \"dash\") the various \"job status\" messages are not displayed from signal handlers, but require an explicit check. This check is performed only before a new prompt is provided, probably not to disturb the user while he/she is typing a new command. .  The message is not shown just before the prompt after the \"kill\" is displayed probably because the process is not dead yet - this is particularly probable condition since \"kill\" is an internal command of the shell, so it's very fast to execute and doesn't need forking. .  Doing the same experiment with \"killall\", instead, usually yields the \"killed\" message immediately, sign that the time/context switches/whatever required to execute an external command cause a delay long enough for the process to be killed before the control returns to the shell. .  Long answer \"dash\" First of all, I had a look at the \"dash\" sources, since \"dash\" exhibits the same behavior and the code is surely simpler than \"bash\". .  As said above, the point seems to be that job status messages are not emitted from a signal handler (which can interrupt the \"normal\" shell control flow), but they are the consequence of an explicit check (a \"showjobs(out2, SHOW_CHANGED)\" call in \"dash\") that is performed only before requesting new input from the user, in the REPL loop. .  Thus, if the shell is blocked waiting for user input no such message is emitted. .  Now, why doesn't the check performed just after the kill show that the process was actually terminated? As explained above, probably because it's too fast. \"kill\" is an internal command of the shell, so it's very fast to execute and doesn't need forking, thus, when immediately after the \"kill\" the check is performed, the process is still alive (or, at least, is still being killed). .   \"bash\" As expected, \"bash\", being a much more complex shell, was trickier and required some \"gdb\"-fu. .  The backtrace for when that message is emitted is something like .  The call that checks for dead jobs & co. is \"notify_of_job_status\" (it's more or less the equivalent of \"showjobs(..., SHOW_CHANGED)\" in \"dash\"); #0-#1 are related to its inner working; 6-8 is the yacc-generated parser code; 10-12 is the REPL loop. .  The interesting place here is #4, i.e. from where the \"notify_and_cleanup\" call comes. It seems that \"bash\", unlike \"dash\", may check for terminated jobs at each character read from the command line, but here's what I found: .  So, in interactive mode it's intentional to delay the check until a new prompt is provided, probably not to disturb the user entering commands. As for why the check doesn't spot the dead process when displaying the new prompt immediately after the \"kill\", the previous explanation holds (the process is not dead yet). .  ",
      "P-tags": "process kill bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V"
    },
    {
      "id": "so_61074627",
      "task": "find and replace string on a line",
      "P-task": "find replac string line",
      "F_verb": "replace",
      "P-body": " Demo :  .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP on NP"
    },
    {
      "id": "au_725579",
      "task": "How to find only 'permission granted' files",
      "P-task": "find permiss grant file",
      "F_verb": "find",
      "P-body": "One certainly could filter out the permission denied errors with \"2> /dev/null\" redirection, as it is an output from error stream. .  But also a good idea is to exclude those directories that give you problems with \"-path /some/dir/*pattern -prune -o -print\". .  It's also should be possible to exclude multiple directories with logical OR operator \"-o\" and grouping into \"\\( ... \\)\" brackets .  ",
      "P-tags": "permiss find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_21838",
      "task": "How to make tree output only directories?",
      "P-task": "make tree output directori",
      "F_verb": "make",
      "P-body": "\"tree\" man page says: .    So the output of \"tree -d YOUR_TARGET_FOLDER\" looks like: .  ",
      "P-tags": "directori opensource-project file",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "so_35840847",
      "task": "linux how to get process params with pid?",
      "P-task": "linux get process param pid",
      "F_verb": "get",
      "P-body": "From proc(5): .   The command-line arguments appear in this file as a set of strings separated by null bytes ('\\0'), with a further null byte after the last string. .   So, this code should work: .  ",
      "P-tags": "linux c",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "so_19446248",
      "task": "Cannot compile with Eigen Library",
      "P-task": "compil eigen librari",
      "F_verb": "compile",
      "P-body": " ^ Redefining an individual letter without respect for scope is a bad idea. .  Try \"static int const M = 10;\" instead. .  ",
      "P-tags": "c++ linux eigen",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V with NP"
    },
    {
      "id": "so_42669490",
      "task": "How to pass quoted arguments to elevated batch script via powershell Start-Process",
      "P-task": "pass quot argument elev batch script via powershel start-process",
      "F_verb": "pass",
      "P-body": "The \"runas\" verb doesn't work if you invoke it directly on a batch file. You need to invoke it on the actual executable (i.e. \"cmd.exe\") and pass the batch file as an argument. .  ",
      "P-tags": "parameter-pass powershel window double-quot",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP via NP"
    },
    {
      "id": "so_50664923",
      "task": "Executing JavaScript function with mongo shell has no output",
      "P-task": "execut javascript function mongo shell output",
      "F_verb": "execute",
      "P-body": "The problem is that you are expecting the same result as you see in the REPL when you type \"db.myFirstCollection.find()\", but that's not what happens here. As stated it's a REPL, which means that the statement is evaluated to the \"left\" unless otherwise assigned to a variable or in this case, \"inside a function\". .  So simply do something to actually \"print\" output: .  What you see in the shell \"db.myFirstCollection.find()\" is actually that \"left hand assignment\" of the \"Cursor\" which is then evaluated and the first 20 results are iterated. .  You can similarly stop that from immediately happening by doing: .  Which does not \"print\" those results until you \"evaluate\": .  Which will then print out the next 20, which is the default evaluation. .  So when you are \"scripting\", you actually need to do something with the returned \"Cursor\" result. In this case \"forEach()\" the results and \"printjson\" on each iteration. .  If you are going to \"play around\" with more of this, then I suggest you read Write Scripts for the \"mongo\" Shell and also Iterate a Cursor in the \"mongo\" Shell within the core documentation. These cover most of the differences you would encounter as you work with \"scripting\" as compared to the \"interactive\" form as you simply type things into the REPL which the \"mongo\" shell is. .   Quick Demo Create a file as \"test.js\" .  Then simply execute on the default \"test\" database namespace as: .  Returns: .  Note that in the same way the \"deleteMany()\" and \"insertMany()\" responses are also suppressed by being wrapped inside an inner function so their results are not \"left evaluated\". .  ",
      "P-tags": "mongodb mongo-shel javascript",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_378380",
      "task": "Gnome: See basic emacs commands in background image",
      "P-task": "gnome : see basic emac command background imag",
      "F_verb": "see",
      "P-body": " We can find our used images in \"/usr/share/desktop-base/softwaves-theme/wallpaper/contents/images\" (It's the default images I think). .  cd /usr/share/desktop-base/softwaves-theme/wallpaper/contents/images .  we can find which image we are using by command: .  gsettings get org.gnome.desktop.background picture-uri  .  We copy the one we need (or all if we don't know which to use) in a folder: Let's say in \"~/bg_images/\". .  mkdir ~/bg_images/ .  cp *.* ~/bg_images/ .  cd ~/bg_images .  We open the image we are going to use with GIMP and exporting as png. .  Gimp->export as->select png files->set compression to 0->enter .   Let's say it was the image 1280x720.svg and we created 1280x720.png. .   We open a file image1.tex (in the same folder) and add the code: .   We compile with pdflatex image1.tex and we get the file image1.pdf. .  pdflatex image1.tex .  Then we have an image1.pdf file and we convert it to svg with texlive convert command: .  convert image1.pdf image1.svg .   We can avoid the next steps until step 13 by just using the code in the script in our shortcut command creation .   We create a directory 'bin' in our home folder (if we don't already have one) .  mkdir ~/bin .  cd ~/bin .  We open a file 'change_background.sh' .  nano change_background.sh .  We copy paste the code: .  #!/bin/bash .  file_path=$1 .  if [ \"x$file_path\" != \"x\" ]; .  then gsettings set org.gnome.desktop.background picture-uri file://\"$file_path\" fi .  Save and close .  chmod +x change_background.sh .  Then we open settings from the top right corner: .  All Settings->keyboard->scroll down to bottom->press '+' .  We create a custom shortcut (Let's say it show_emacs_help) with the command .  bash /home/userName/bin/change_background.sh /home/userName/bg_images/image1.svg .  where \"userName\" is our username .  We chose our shortcut keys (Lets say Ctrl+Alt+H) .  We can add in the same way a new shortcut to reload the default backgroound image. .   PS: Source for the script: https://askubuntu.com/questions/858663/how-to-change-background-with-keyboard-shortcut Selected answer by @SergiyKolodyazhnyy. .  Result image: .   .  ",
      "P-tags": "script gnome",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_523520",
      "task": "Debian: The following packages have been kept back.... odbcinst AND odbcinst1debian2",
      "P-task": "debian : follow packag kept back odbcinst odbcinst1debian2",
      "F_verb": "follow",
      "P-body": "You\u2019ve added the Microsoft repositories, which contain newer versions of the \"odbcinst\" packages, and those conflict with KDE (they \u201cbreak\u201d \"libiodc2\", which KDE needs via \"soprano-daemon\" and \"libsoprano4\"). .  So you need to choose: either you keep KDE, or you upgrade to the new \"odbcinst\" packages; you can\u2019t have both. .  To get rid of the \u201cwarning\u201d, you can pin the Microsoft repositories to a priority strictly less than 100 like this: .  and insert: .  ",
      "P-tags": "apt aptitud package-manag debian",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V NP"
    },
    {
      "id": "au_723244",
      "task": "Cannot log in after upgrade: xcb plugin missing",
      "P-task": "log upgrad : xcb plugin miss",
      "F_verb": "log",
      "P-body": "Installing \"libqt5xcbqpa5\" helped me: .  Rant: looks to me this was semi-intentional -- J. Riddell must be happy now. .  ",
      "P-tags": "kubuntu kde5 kde",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V after NP"
    },
    {
      "id": "so_54693287",
      "task": "How to get 200 status code in PS after checking a redirected URL",
      "P-task": "get 200 statu code ps check redirect url",
      "F_verb": "get",
      "P-body": "Too long for a comment. Important: \"$res = $req.GetResponse()\" does not set any value into the \"$res\" variable in the \"catch\" case (the \"$res\" variable keeps unchanged). .  Output examples: .    ",
      "P-tags": "powershel url",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP after S"
    },
    {
      "id": "so_44403144",
      "task": "Powershell script not running on scheduled task",
      "P-task": "powershel script run schedul task",
      "F_verb": "run",
      "P-body": "Call the Powershell.exe in your schedulded task: .  Set this arguments: .  ",
      "P-tags": "powershel scheduled-task",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V on NP"
    },
    {
      "id": "so_16791374",
      "task": "work with parallel port interrupt",
      "P-task": "work parallel port interrupt",
      "F_verb": "interrupt",
      "P-body": "I got it. .   First make a thread put the Enable IRQ code in that thread so it will continuously execute it whenever i connect pins at my hardware then it will be interrupted. .   check this code for your ref. .  ",
      "P-tags": "parallel-port interrupt linux device-driv linux-device-driv",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V"
    },
    {
      "id": "so_33433088",
      "task": "\"The database cluster was initialized with CATALOG_VERSION_NO X, but the server was compiled with CATALOG_VERSION_NO Y.\" after aptitude upgrade",
      "P-task": "databas cluster initi catalog_version_no x server compil catalog_version_no aptitud upgrad",
      "F_verb": "initialize",
      "P-body": "You are/were using an alpha release of the database, which is explicitly documented as not remaining format-stable. It looks like it might've been a bit too easy to install without realising that, though; I've mailed the apt packaging team about that. .   Update: you must've explicitly done an \"aptitude install postgresql-9.5\" and either used \"--force\" when originally installing or added \"9.5\" to your \"sources.list\" entry manually. The 9.5 packages are not installed by default, and take extra steps to install. See: .   http://www.postgresql.org/message-id/20151031211657.GB24389@msg.df7cb.de https://wiki.postgresql.org/wiki/Apt/FAQ#I_want_to_try_the_beta_version_of_the_next_PostgreSQL_release  I updated the wiki with a warning note, in case you followed those instructions without realising about the format change. Though I'd think using a prerelease database with data you care about would be something that's obviously not a great idea, really. .   If you need to read the old data, you'll need to download the particular version you were running then, install that, and use it to dump the database(s). Then you can restore them to the new copy. .  I strongly advise you to dump your data, then restore it to PostgreSQL 9.4, and keep using that until 9.5.0 comes out or at least until a beta is released. After beta the PostgreSQL team tries hard to avoid changing the format. .   Update: You're running \"9.5~beta1-1.pgdg14.04+1\" now, so I'm pretty sure it's the 9.5alpha2 to 9.5beta1 update that broke things. Which makes sense. .  So what we need to do is find the 9.5alpha1 version, then force a downgrade. Note that this will stop you from being able to access your 9.5beta2 database until you upgrade again, so I suggest dumping it first. .  From the version it's clear it's a PGDG release, i.e. a release from apt.postgresql.org (run by the PostgreSQL Development Group). Examining \"http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/9.5/binary-amd64/Packages\" shows us the current package-list, and the alpha is not in it. That's to be expected, since it's no longer a current release, but it means you can't download it from that repo directly. However, it's also not in \"trusty-pgdg-testing\", and it's not in the package pool at \"http://apt.postgresql.org/pub/repos/apt/pool/main/p/postgresql-9.5/\" either. .  In other words, the alpha has been removed from the repository completely, and is no longer available for download from apt.postgresql.org. .  First, check if you still have the alpha in your \"/var/cache/apt/archives\". If you do, copy everything with \"alpha2\" in its name to a separate location now. .  If you don't, your options are to compile it yourself, or ask on the mailing list if anyone still has the packages. .  ",
      "P-tags": "upgrad postgresql aptitud ubuntu",
      "source": "qa",
      "cate": "initialize/reinitialize/prepare/refresh/reset/initiate/reposition/initialise/activate/reinitialise",
      "pat": "V with NP"
    },
    {
      "id": "so_39430357",
      "task": "Powershell - running a ps1 script on all ps1 files in a directory",
      "P-task": "powershel - run ps1 script ps1 file directori",
      "F_verb": "run",
      "P-body": "Is this what you're trying to do? .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP in NP"
    },
    {
      "id": "so_23389599",
      "task": "Remove excess information from string in Powershell",
      "P-task": "remov excess inform string powershel",
      "F_verb": "remove",
      "P-body": "In your code \"$strOwnerName\" is a \"PSCustomObject\". To convert it to a string change .  to  .  or .  ",
      "P-tags": "string powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "so_59142544",
      "task": "Docker + Kong: [PostgreSQL error] failed to retrieve PostgreSQL server_version_num: connection refused",
      "P-task": "docker + kong : postgresql error fail retriev postgresql server_version_num : connect refus",
      "F_verb": "retrieve",
      "P-body": "The article you're referring is a bit outdated  .   Note for Kong < 0.15: with Kong versions below 0.15 (up to 0.14), use the up sub-command instead of bootstrap. Also note that with Kong < 0.15, migrations should never be run concurrently; only one Kong node should be performing migrations at a time. This limitation is lifted for Kong 0.15, 1.0, and above. .   Reference https://hub.docker.com/_/kong .  Kong docs https://docs.konghq.com/install/docker .  The instructions below should work  .  Create a docker network .  Start a PostgreSQL container .  Prepare your database .  Start Kong .  ",
      "P-tags": "postgresql kong ubuntu-18 04 docker",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_54654118",
      "task": "get content from a list and run the Get-ADOrganizationalUnit for that list",
      "P-task": "get content list run get-adorganizationalunit list",
      "F_verb": "run",
      "P-body": "Your existing code should work, given some typos are corrected: .  ",
      "P-tags": "powershel list",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "so_50876405",
      "task": "Loop skipping first line of text file being read, working for second line, but also not reading third line",
      "P-task": "loop skip first line text file read work second line also read third line",
      "F_verb": "skip",
      "P-body": "In your while loop, you do two reads. The first is \"read -r line\" reads the first line then \"read CENTRIFY_USER\" which is the second line. You do not appear to be using \"$line\" in you script.  .  You appear to need: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP of NP"
    },
    {
      "id": "so_25072531",
      "task": "Escape character confusing in sed command",
      "P-task": "escap charact confus sed command",
      "F_verb": "escape",
      "P-body": "\"/\\\\\\. /\" .  search for the pattern \\. .  by default \\ is the sequence for escaping following char and dot mean \"any char\", so \\. is translate in regex format by escape slash (\\\\) followed by escape dot (\\.) .  \"/ \\\\\\\\\\\\\\\\./\" .  replace by \\\\. there are 8 slash and 1 dot. 4 escaped slash for same reason as for research pattern earlier but in replacement pattern dot mean dot so no need to escape it. .  another way to write it \"/[\\][.]/\\\\\\\\\\\\&/\" or for fun \"/\\([\\]\\)[.]/\\1\\1\\1&/\" take  .  ",
      "P-tags": "sed escap shell",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_387142",
      "task": "How can I run a script every time a certain GNU screen changes?",
      "P-task": "run script everi time certain gnu screen chang",
      "F_verb": "run",
      "P-body": "You could write a wrapper script: .  You can use the above script by piping the output from your program to the script .  For example if above script is called \"./wrapper.sh\" and your program is \"prog\": .  Note that if something is printed in standard error by \"prog\", it won't processed by the script unless you redirect it or handle stderr separately. .  ",
      "P-tags": "shell-script gnu-screen",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_33513515",
      "task": "How to do a loop with filenames in shellscript ordered by 'last modified'?",
      "P-task": "loop filenam shellscript order last modifi",
      "F_verb": "modify",
      "P-body": "try this : .  ls -lrth give's 9 coulmns in output, out of which you need only 9th column(file names), you can get that using awk .  If you have space seperated filenames, modify awk print to print all data after 9th column .  ",
      "P-tags": "imagemagick ls unix shell",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_12235776",
      "task": "converting bat file to script file containing java command",
      "P-task": "convert bat file script file contain java command",
      "F_verb": "convert",
      "P-body": "well I could run run.sh file finally. It looks like below: .  After that I run this command: \"\"dos2unix run.sh\"\" and then I run \"./run.sh\". and this way application gets executed. .  I thnak you all for your responses.. .  ",
      "P-tags": "classpath batch-fil jar shell java",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "ul_465968",
      "task": "How to wait for all files and copy into dir",
      "P-task": "wait file copi dir",
      "F_verb": "wait",
      "P-body": "You're so close, just switching your \"if\" statement with a \"while\" loop, or just adding a while loop as you suggest should do the trick for you. .  This would work, though it would hang should there ever be more than 3 files in that dir, or if one or more of the files never turn up. So I'd recommend adding a break to the while loop: .  ",
      "P-tags": "shell-script shell",
      "source": "qa",
      "cate": "wait/await/sleep",
      "pat": "V for NP"
    },
    {
      "id": "ul_82145",
      "task": "emacs-nox doesn't load the files I ask it to at command line",
      "P-task": "emacs-nox load file ask command line",
      "F_verb": "load",
      "P-body": "Following the comment by @EvanTeitelman , I looked at the output in the question's edit, deleted the non-existent but locked-down directory \"~/.emacs.d\", and now it works. .  This appears to be a common thing, at least on Xubuntu. I noticed another installation doing it today. So hopefully this will help someone. .  ",
      "P-tags": "configur emac",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "ul_166477",
      "task": "When I run `./command.sh &`, the background task is suspended. How can I keep it running?",
      "P-task": "run\ncommand sh background task suspend\nkeep run",
      "F_verb": "run",
      "P-body": "It stops because of the reason given: it tries to output to tty. You can try to redirect the output if \"./command.sh\" supports that, or run the command in a \"tmux\" or \"screen\" window of it's own. E.g. .  and then view the list of windows created with \"tmux list-windows\" and attach to \"tmux\" with \"tmux attach\". .  That way the program will still wait for input/output to happen, but you can easily provide input once you go to the appropriate window and the output will just be captured without any activity. .  ",
      "P-tags": "job-control background-process bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V"
    },
    {
      "id": "so_59019332",
      "task": "Cannot use Powershell intellisense in Sublime Text 3 with LSP",
      "P-task": "use powershel intellisens sublim text 3 lsp",
      "F_verb": "use",
      "P-body": "Any language needs to be added under the \"clients\" heading, as per below: .  ",
      "P-tags": "powershel intellisens sublimetext3",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_14739488",
      "task": "Powershell - How can I do a live Active directory search using a dropdown menu",
      "P-task": "powershel - live activ directori search use dropdown menu",
      "F_verb": "use",
      "P-body": "To do a live update you need to update the list when the text in the dropbox is modified. There are at least 2 events thats triggered when you write in it: \"TextUpdate\" and \"KeyPress\" . Choose ONE. I'd suggest \"TextUpdate\" since it reacts after the text is changed, while \"KeyPress\" reacts before. You can add a eventlistener using e.g.: .  In the scriptblock you need to run a function that queries the DC, but this question is not tagged with ADSI, AD, LDAP etc. so that's another question.  .  Be aware that this will run the query EVERY time you change a letter which is causing extra load on the DC. E.g. if you want to write \"Mark\", it will have searched minimum 4 times before you are done writing.  .  I'd suggest using a textbox with a search-button instead to minimize unecessary traffic. .  ",
      "P-tags": "powershel drop-down-menu powershell-2 0 winform",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_7052765",
      "task": "powershell : changing the culture of current session",
      "P-task": "powershel : chang cultur current session",
      "F_verb": "change",
      "P-body": "Have a look here: http://blogs.msdn.com/b/powershell/archive/2006/04/25/583235.aspx .  and here: http://poshcode.org/2226: .   Additional Info .  To find which values can be used for \"$culture\": .   This will give you a list of Culture Types: .   Selecting one of the above types (e.g. AllCultures) you can then list the available values of that type: .   You can then use the Name or Number of the culture you're interested in with the \"GetCultureInfo\" method to retrieve the value you're after: .    NB: Thanks to implicit conversion, you could just pass the culture name or number (i.e. as a string or integer) to the \"Set-Culture\" method which would automatically be converted to the expected CultureInfo value. .  ",
      "P-tags": "powershel windows-vista window powershell-2 0",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP"
    },
    {
      "id": "so_50084075",
      "task": "Rename files with same name and extension (usually .pdf) in the sub directories with incrementing number",
      "P-task": "renam file name extens usual pdf sub directori increment number",
      "F_verb": "rename",
      "P-body": "I just found the answer to my question through a very kind person. Anyway..here is the PS script that worked for me.. .  ",
      "P-tags": "powershell-2 0",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP in NP with NP"
    },
    {
      "id": "so_64236047",
      "task": "What is the last character of a line string (hexadecimal) in a file which is written using echo",
      "P-task": "last charact line string hexadecim file written use echo",
      "F_verb": "write",
      "P-body": "\"echo\" outputs its argument followed by a newline character (\"\\n\" aka LF aka 0x10). So that's the extra character you're seeing. To suppress this, use \"echo -n 0xfec6a2ea > test.txt\", but then of course all the text will be on the same line. .  ",
      "P-tags": "linux c shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V using NP"
    },
    {
      "id": "au_524242",
      "task": "How to find out which NVIDIA GPU I have",
      "P-task": "find nvidia gpu",
      "F_verb": "find",
      "P-body": "please update your PCI ID database with: .  And use the following command in your terminal: .  You will see the model name of your graphic card. If it's ambiguous, you could search the PCI ID (something like [10de:11bc]) on the Internet for the corrent model name. .  ",
      "P-tags": "nvidia gpu",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V which S"
    },
    {
      "id": "so_59056849",
      "task": "Remove blank line after a match",
      "P-task": "remov blank line match",
      "F_verb": "remove",
      "P-body": "This sed command would work: .  It does the following: .  This would fail for a few edge cases: does a line ending in \"blamet\" qualify? Does \"--\" have to be separated by blanks? Could there ever be input like this: .  as the solution presented would not remove the blank line here. For the presented input, though, it would work. .  ",
      "P-tags": "sed bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP after NP"
    },
    {
      "id": "au_410053",
      "task": "How do I install 3rd party programs and make them appear in the Dash Home menu?",
      "P-task": "instal 3rd parti program make appear dash home menu",
      "F_verb": "make",
      "P-body": "A much easier method is to try the public beta version, as it comes in both tarball form for any Linux version, and in a \".deb\" format specifically for Ubuntu. Download either 32- or 64-bit, depending on your version of Ubuntu (run \"uname -a\" at the command line, and look for either \"i386\" (32-bit) or \"x86_64\" (64-bit) in the output), then at the command line navigate to where you downloaded it and run .  where \"XXXX\" is the build number (currently 3059) and \"YYYY\" is either \"i386\" or \"amd64\". This will automatically install Sublime Text in \"/opt/sublime-text\", create a \"/usr/bin/subl\" command, and automatically create \"/usr/share/applications/sublime_text.desktop\" along with the associated icons. It should also create a launcher in your Unity taskbar. .  Sublime Text 3 is the future of the editor, and every day more and more plugins and extensions are released or revised on Package Control that are compatible with ST3. If you purchase a license, which is required for long-term use after evaluation, you will also have access to the bleeding edge development releases which are released more frequently than the public beta versions and so are more up-to-date as far as new features and bug fixes are concerned. Sublime Text 2 is basically a finished product as far as development is concerned, and while it is quite stable for most people, many plugins do not work with it, especially those under active development that depend on some of the advanced features that ST3 provides. .  It's worth noting that ST2 and ST3 can coexist peacefully on the same system, as the plugins and data are stored separately. You obviously can't have two \"subl\" commands, but you can rename one of them \"subl2\" or \"subl3\", for example. .   If you still need to create a \".desktop\" file for ST2, its contents should be as follows. Please note that it assumes you moved the \"Sublime Text 2\" directory from where you unpacked it to \"/opt/sublime_text_2\". If this is not the case, please update the directory paths accordingly. .  Save the file as \"sublime.desktop\", then use \"sudo\" to move it to \"/usr/share/applications\". You may have to log out and then back in, but it should now be available in Unity. .  Good luck, and if you have any questions please let me know. .  ",
      "P-tags": "sublime-text software-cent uniti unity-dash",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP in NP"
    },
    {
      "id": "so_29774557",
      "task": "Batchscript can't remove line from text file",
      "P-task": "batchscript remov line text file",
      "F_verb": "remove",
      "P-body": "You require \"&\" between commands on a single line, otherwise \"cmd\" will assume the second command is extra arguments to the first. .  should become .  or even easier .  or, easier still .  where the \"move\" command will overwrite the target file with the source. The \"/y\" means \"don't prompt for authority to overrite\" and the \"1 file(s) moved\" message is suppressed by being redirected to \"nul\" .  ",
      "P-tags": "batch-fil cmd window shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_44976815",
      "task": "Rename files, using text-file as source",
      "P-task": "renam file use text-fil sourc",
      "F_verb": "rename",
      "P-body": "Just loop through your file with \"read\", get the seperated columns with \"awk\" \"cut\" (Thank you, @Jack) and \"mv\" your file accordingly. In this very simple implementation I assume that your text file containing the new names is located at \"./filenames\" and your script is called from the directory containing your files. .  ",
      "P-tags": "batch-renam file-renam bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP using NP as NP"
    },
    {
      "id": "ul_676252",
      "task": "How to create a bash script that watches my local git repo and runs 'git log' every time I commit/checkout -b/push/status?",
      "P-task": "creat bash script watch local git repo run git log everi time commit checkout -b push statu",
      "F_verb": "create",
      "P-body": "Take look to the bottom right there is the \"(END)\" this comes from the pager used by git. .  There \"--no-pager\" to avoid this issue .  Then do \"while\" to react to each event around \"inotifywait\": .  ",
      "P-tags": "arch-linux git inotifi bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP that S"
    },
    {
      "id": "au_1207707",
      "task": "How to install gitslave on Ubuntu 16.04.6 LTS?",
      "P-task": "instal gitslav ubuntu 16 04 6 lt",
      "F_verb": "install",
      "P-body": "The main problem here is that the application is old (from 2012). .  You have to provide the name for the man-page which is generated by \"pod2man\" (see \"--name\" option). .  and then continue the installation as was planned: .  ",
      "P-tags": "git software-instal make",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_36401623",
      "task": "How to delete a string from a file in bash",
      "P-task": "delet string file bash",
      "F_verb": "delete",
      "P-body": "You can use: .  but make sure \"input\" doesn't contain any regex special character. .  \"awk\" with \"index\" function might be safer due to non-regex: .  ",
      "P-tags": "string shell bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP in NP"
    },
    {
      "id": "su_1551768",
      "task": "How to compare file permissions between two files?",
      "P-task": "compar file permiss two file",
      "F_verb": "compare",
      "P-body": "\"stat\", with the right options, seems to provide a way to compare this property, but not to an arbitrary permissions argument (e.g. \"777\" or \"+x\"). For that you'll want to choose the appropriate representation (e.g. \"%A\" or \"%a\"). See more in the man page. .  ",
      "P-tags": "chmod permiss bash",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP between NP"
    },
    {
      "id": "so_67449510",
      "task": "Powershell get values and create table",
      "P-task": "powershel get valu creat tabl",
      "F_verb": "create",
      "P-body": "Enumerate all the \"ANNOTATION\" nodes, then use the TS references to query the appropriate value in the \"TIME_ORDER\" node: .  Which, with your sample data, produces a table like: .  ",
      "P-tags": "powershel xml",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_23443083",
      "task": "awk find difference between second field in two files",
      "P-task": "awk find differ second field two file",
      "F_verb": "find",
      "P-body": " Output: .  It removes elements of the array that match \"file2\", then prints all remaining elements of the array. This does not save the order of lines, so I have piped it to \"sort -k1\". .  ",
      "P-tags": "awk unix",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP between NP in NP"
    },
    {
      "id": "so_22759554",
      "task": "Bash: remove all but last 10 log files",
      "P-task": "bash : remov last 10 log file",
      "F_verb": "remove",
      "P-body": " Check the output and if satisfied replace echo with rm. .  ",
      "P-tags": "file bash regex",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "au_1018569",
      "task": "Can't write to partion after creating it with GParted",
      "P-task": "write partion creat gpart",
      "F_verb": "write",
      "P-body": "As I can understand, your mount point is named \"BackUP\". .  So you should take ownership of the filesystem with: .  ",
      "P-tags": "partit gpart",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP after S"
    },
    {
      "id": "au_1035114",
      "task": "How can I set the shortcut for \"Redo\" from Ctrl+Shift+Z to Ctrl+Y?",
      "P-task": "set shortcut redo ctrl+shift+z ctrl+i",
      "F_verb": "set",
      "P-body": "Since you explicitly ask for a system- or at lease session-wide solution in the comments: this cannot be done in a way that doesn't break lots of other things. .  The Ctrl+Z, Ctrl+Y, and Ctrl+Shift+Z shortcuts that you mention are handled on the application level. Although it's possible to intercept and \u201ctranslate\u201d them before they ever reach an application it would interfere with many other things, e. g. applications that bind these to unrelated actions.1 .  Instead I recommend that you change the on the application level. Many applications without a distinct interface to change keyboard shortcuts still allow changes to them through their toolkit configuration, e. g. .   GTK+ applications and .  KDE applications. .    1 If you still want to try it please look at \"xmodmap\" or \"xdotool\". Relevant questions are: .   Make shortcut for navigational functions Create custom keyboard shortcut to send Super+2  ",
      "P-tags": "shortcut-key 16 04",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP from NP"
    },
    {
      "id": "so_67855188",
      "task": "how make a current directory as home directory in linux",
      "P-task": "make current directori home directori linux",
      "F_verb": "make",
      "P-body": "You can change variable \"HOME\" as you like (but i wont recommend that unless you know what things are gonna change) But simpler way is to mane soft links for the directories you like, which i personally do. .  You can make or edit \"user-dirs.dirs\" file under \"~/.config\" directory to this .  Here you can change default directories used by system. You can change your \"SECOND_HOME\" as you like .  Edit: If you want to change your default HOME then overwrite HOME variable on user login (it depends on which display manager you are using, but its easy) .  But before that move every thing (ie. .config, .local, etc) directories to the directory which you want to set as HOME (eg. /labs/professor) .  Or you can directly run .  Here -m (abbreviation for --move-home) will move the content from the user's current directory to the new directory. .  ",
      "P-tags": "linux slurm singularity-contain",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "so_12799047",
      "task": "Writing to /etc/networking/interfaces at boot using sed/awk?",
      "P-task": "write etc network interfac boot use sed awk",
      "F_verb": "write",
      "P-body": "You can do that with sed: .  You can group commands with braces. The commands in the braces will only execute on the third line. The \"i\" insert command will only execute on the third line and if the third line doesn't match the string between slashes (the \"!\" after it tells it to execute when it doesn't match). .  You can do the same to delete: .  Here we delete the third line only if it contains the string \"gateway\". You could probably be more generic and simply do: .  which will delete all lines that contain gateway, but maybe that's not what you want. .  As for deleting the last lines, the easiest solution would be: .  Where the \"d\" delete command is executed on the last line if it matches either \"auto lo\" or \"iface lo inet loopback\". Executing it twice will delete the last two lines if they match the patterns. .  If you want to add lines to the end of the file, you can do: .  Or maybe only add them if the last line isn't a specific line: .  Hope this helps a little =) .  ",
      "P-tags": "awk ubuntu sed bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V to NP at NP using NP"
    },
    {
      "id": "au_126496",
      "task": "Can I convert a 2D video to 3D?",
      "P-task": "convert 2d video 3d",
      "F_verb": "convert",
      "P-body": "I installed AviSynth with Wine 1.3.16 through PlayOnLinux, then I chose \"System\" version. I replaced \"DirectShowSource\" with \"AviSource\" in the script and I could open the script with VirtualDub. .  ",
      "P-tags": "3d wine convers",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP"
    },
    {
      "id": "so_52121388",
      "task": "trying to set status in bash function",
      "P-task": "tri set statu bash function",
      "F_verb": "set",
      "P-body": "you could run \"which mail\" which should give you the path of the package installed. For example: .  \"which bash\" \"/usr/local/bin/bash\"  .  so you could check if the return of \"which bash\" is 0 or not using \"$?\" If it is 0 then the package is installed .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_62093343",
      "task": "When using Yad, can a button be made the default?",
      "P-task": "use yad button made default",
      "F_verb": "use",
      "P-body": "Found out that $? for Yes=0, for No=1 and Close=252, so coding externally allowed to make the Yes button the default. :- .  ",
      "P-tags": "yad bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_45509231",
      "task": "Remove Custom Domain/Host from App Service via Powershell",
      "P-task": "remov custom domain host app servic via powershel",
      "F_verb": "remove",
      "P-body": "at a top level this is what you need to do: .   Get the websites resource Manipulate the hostnames collection Post the changes back to azure  Here is an example of how I did it: .  This will remove all custom hostnames and leave only the default one. .  If you want to remove a specific hostname for the collection you could use: .  NOTE If your hostname has SSL bindings you will need to remove those first and then delete the hostname. .  ",
      "P-tags": "azur powershel azure-powershel azure-web-app-servic",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP via NP"
    },
    {
      "id": "ul_513574",
      "task": "How to do vi edit on bash Linux?",
      "P-task": "vi edit bash linux",
      "F_verb": "edit",
      "P-body": "I'm not sure I understand you, but you may be looking for the \"fc\" shell builtin. .  will let you edit in \"vi\" your last command line. .  ",
      "P-tags": "vim bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V on NP"
    },
    {
      "id": "so_10611564",
      "task": "how to send a \"break\" when debuging embeded system?",
      "P-task": "send break debug embed system",
      "F_verb": "send",
      "P-body": "From the documentation, it looks like \"Control-\\ B\" will send a break in C-Kermit. .  Other ways... .   One way to send a break is to: .   Switch to a lower speed Send a Nul (0) or an @ (4016) -- a character with many contiguous 0 bits will produce the framing error called a BREAK. Switch back to the original speed  As you noted, the other way is to use the \"<termios.h>\" line control functions. .   ",
      "P-tags": "linux embed",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP when S"
    },
    {
      "id": "so_35568016",
      "task": "Install make 3.75 on ubuntu 15.10",
      "P-task": "instal make 3 75 ubuntu 15 10",
      "F_verb": "install",
      "P-body": " Why do you need this? As arved suggests: if your Makefiles are 20 years old and incompatible with current versions of \"make\", and can't be fixed, you probably have bigger problems elsewhere. Whatever those Makefiles try to do may require some tweaking to work on Ubuntu 15.10. .  ",
      "P-tags": "makefil ubuntu-15 10",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_70206408",
      "task": "Modify enviroment variable with putenv in C",
      "P-task": "modifi enviro variabl putenv c",
      "F_verb": "modify",
      "P-body": "Your program is working fine, and as intended. \"envp\" is a copy of \"environ\" at program start, and may be, unlike \"environ\", never updated afterwards. .  To run commands, shells (such as the one you are writing) use a combination of \"fork()\" + \"execv()\" -- and the manual on \"execv\" notes that .   For those forms not containing an envp pointer (execl(), execv(), execlp(), and execvp()), the environment for the new process image shall be taken from the external variable environ in the calling process. .   ... making no reference at all to relying on the \"envp\" that you received, as opposed to one that you may manufacture to pass whichever environment variables you choose to your child processes when using \"exec*\" variants that do take modified environment variables as arguments. .  As a side-note, using \"setenv()\" has two advantages over \"putenv\", and I would therefore recommend it: .   whatever you pass to \"putenv\" must persist in time; whatever you pass to \"setenv\" gets copied, so you need not manage its memory. Therefore, \"setenv(char *key, char *value, int replace)\" means less responsibility for you (and no need to malloc, strcat, and so on).  Both will modify \"environ\" for you. Note that you should not write \"environ\" directly (but reading it is fine, and needed because there is no \"lsenv\" function to list available environment variables); note this warning: .   Any application that directly modifies the pointers to which the environ variable points has undefined behavior .   ",
      "P-tags": "linux variabl c shell",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_185496",
      "task": "Run a Vim command from a bash script",
      "P-task": "run vim command bash script",
      "F_verb": "run",
      "P-body": "Ok it looks like the EOF was just a lot more sensitive than I excpected .  this doesn't work .  this does .  ",
      "P-tags": "script linux vim shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_141016",
      "task": "A layman's explanation for \"Everything is a file\" \u2014\u00a0what differs from Windows?",
      "P-task": "layman explan everyth file differ window",
      "F_verb": "differ",
      "P-body": "\"Everything is a file\" is a bit glib. \"Everything appears somewhere in the filesystem\" is closer to the mark, and even then, it's more an ideal than a law of system design. .  For example, Unix domain sockets are not files, but they do appear in the filesystem. You can \"ls -l\" a domain socket to display its attributes, modify its access control via \"chmod\", and on some Unix type systems (e.g. macOS, but not Linux) you can even \"cat\" data to/from one. .  But, even though regular TCP/IP network sockets are created and manipulated with the same BSD sockets system calls as Unix domain sockets, TCP/IP sockets do not show up in the filesystem,\u00b9 even though there is no especially good reason that this should be true. .  Another example of non-file objects appearing in the filesystem is Linux's \"/proc\" filesystem. This feature exposes a great amount of detail about the kernel's run-time operation to user space, mostly as virtual plain text files. Many \"/proc\" entries are read-only, but a lot of \"/proc\" is also writeable, so you can change the way the system runs using any program that can modify a file. Alas, here again we have a nonideality: BSD Unixes run without \"/proc\" by default, and the System V Unixes expose a lot less via \"/proc\" than Linux does. .   I can't contrast that to MS Windows .   First, much of the sentiment you can find online and in books about Unix being all about file I/O and Windows being \"broken\" in this regard is obsolete. Windows NT fixed a lot of this. .  Modern versions of Windows have a unified I/O system, just like Unix, so you can read network data from a TCP/IP socket via \"ReadFile()\" rather than the Windows Sockets specific API \"WSARecv()\", if you want to. This exactly parallels the Unix Way, where you can read from a network socket with either the generic \"read(2)\" Unix system call or the sockets-specific \"recv(2)\" call.\u00b2 .  Nevertheless, Windows still fails to take this concept to the same level as Unix, even here in 2021. There are many areas of the Windows architecture that cannot be accessed through the filesystem, or that can't be viewed as file-like. Some examples: .   Drivers. .  Windows' driver subsystem is easily as rich and powerful as Unix's, but to write programs to manipulate drivers, you generally have to use the Windows Driver Kit, which means writing C or .NET code. .  On Unix type OSes, you can do a lot to drivers from the command line. You've almost certainly already done this, if only by redirecting unwanted output to \"/dev/null\".\u00b3 .   Inter-program communication. .  Windows programs don't communicate easily with each other as Unix command line programs do, via text streams and pipes. Unix GUIs are often either built on top of command line programs or export a text command interface, so the same simple text-based communication mechanisms work with GUI programs, too. .   The registry. .  Unix has no direct equivalent of the Windows registry. The same information is scattered through the filesystem, largely in \"/etc\", \"/proc\" and \"/sys\". .    If you don't see that drivers, pipes, and Unix's answer to the Windows registry have anything to do with \"everything is a file,\" read on. .   How does the \"Everything is a file\" philosophy make a difference here? .   I will explain that by expanding on my three points above, in detail. .  Long answer, part 1: Drives vs Device Files .  Let's say your CF card reader appears as \"E:\" under Windows and \"/dev/sdc\" under Linux. What practical difference does it make? .  It is not just a minor syntax difference. .  On Linux, I can say \"dd if=/dev/zero of=/dev/sdc\" to overwrite the contents of \"/dev/sdc\" with zeroes. .  Think about what that means for a second. Here I have a normal user space program (\"dd(1)\") that I asked to read data in from a virtual device (\"/dev/zero\") and write what it read out to a real physical device (\"/dev/sdc\") via the unified Unix filesystem. \"dd\" doesn't know it is reading from and writing to special devices. It will work on regular files just as well, or on a mix of devices and files, as we will see below. .  There is no easy way to zero the \"E:\" drive on Windows, because Windows makes a distinction between files and drives, so you cannot use the same commands to manipulate them. The closest you can get is to do a disk format without the Quick Format option, which zeroes most of the drive contents, but then writes a new filesystem on top of it. What if I don't want a new filesystem? What if I really do want the disk to be filled with nothing but zeroes? .  Let's be generous and accept this requirement to put a fresh new filesystem on \"E:\". To do that in a program on Windows, I have to call a special formatting API.\u2074 On Linux, you don't need to write a program to access the OS's \"format disk\" functionality: you just run the appropriate user space program for the filesystem type you want to create, whether that's \"mkfs.ext4\", \"mkfs.xfs\", or what have you. These programs will write a filesystem onto whatever file or \"/dev\" node you pass. .  Because \"mkfs\" type programs on Unixy systems don't make artificial distinctions between devices and normal files, I can create an ext4 filesystem inside a normal file on my Linux box: .  That creates a 1 MiB disk image called \"myfs\" in the current directory. I can then mount it as if it were any other external filesystem: .  Now I have an ext4 disk image with a file called \"my-passwd-entry\" in it which contains my user's \"/etc/passwd\" entry. .  If I want, I can blast that image onto my CF card: .  Or, I can pack that disk image up, mail it to you, and let you write it to a medium of your choosing, such as a USB memory stick: .  All of this is possible on Linux\u2075 because there is no artificial distinction between files, filesystems, and devices. Many things on Unix systems either are files, or are accessed through the filesystem so they look like files, or in some other way look sufficiently file-like that they can be treated as such. .  Windows' concept of the filesystem is a hodgepodge; it makes distinctions between directories, drives, and network resources. There are three different syntaxes, all blended together in Windows: the Unix-like \"..\\FOO\\BAR\" path system, drive letters like \"C:\", and UNC paths like \"\\\\SERVER\\PATH\\FILE.TXT\". This is because it's an accretion of ideas from Unix, CP/M, MS-DOS, and LAN Manager, rather than a single coherent design. It is why there are so many illegal characters in Windows file names. .  Unix has a unified filesystem, with everything accessed by a single common scheme. To a program running on a Linux box, there is no functional difference between \"/etc/passwd\", \"/media/CF_CARD/etc/passwd\", and \"/mnt/server/etc/passwd\". Local files, external media, and network shares all get treated the same way.\u2076 .  Windows can achieve similar ends to my disk image example above, but you have to use special programs written by uncommonly talented programmers. This is why there are so many \"virtual DVD\" type programs on Windows. The lack of a core OS feature has created an artificial market for programs to fill the gap, which means you have a bunch of people competing to create the best virtual DVD type program. We don't need such programs on *ix systems, because we can just mount an ISO disk image using a loop device. .  The same goes for other tools like disk wiping programs, which we also don't need on Unix systems. Want your CF card's contents irretrievably scrambled instead of just zeroed? Okay, use \"/dev/random\" as the data source instead of \"/dev/zero\": .  On Linux, we don't keep reinventing such wheels because the core OS features not only work well enough, they work so well they're used pervasively. For just one example, a typical scheme for booting a Linux box involves a virtual disk image created using techniques like I show above.\u2077 .  I feel it's only fair to point out that if Unix had integrated TCP/IP I/O into the filesystem from the start, we wouldn't have the \"netcat\" vs \"socat\" vs \"Ncat\" vs \"nc\" mess, the cause of which was the same design weakness that lead to the disk imaging and wiping tool proliferation on Windows: lack of an acceptable OS facility. .  Long Answer, part 2: Pipes as Virtual Files .  Despite its roots in DOS, Windows never has had a rich command line tradition. .  This is not to say that Windows doesn't have a command line, or that it lacks many command line programs. Windows even has a very powerful command shell these days, appropriately called PowerShell. .  Yet, there are knock-on effects of this lack of a command-line tradition. You get tools like \"DISKPART\" which is almost unknown in the Windows world, because most people do disk partitioning and such through the Computer Management MMC snap-in. Then when you do need to script the creation of partitions, you find that \"DISKPART\" wasn't really made to be driven by another program. Yes, you can write a series of commands into a script file and run it via \"DISKPART /S scriptfile\", but it's all-or-nothing. What you really want in such a situation is something more like GNU \"parted\", which will accept single commands like \"parted /dev/sdb mklabel gpt\". That allows your script to do error handling on a step-by-step basis. .  What does all this have to do with \"everything is a file\"? Easy: pipes make command line program I/O into \"files,\" of a sort. Pipes are unidirectional streams, not random-access like a regular disk file, but in many cases the difference is of no consequence. The important thing is that you can attach two independently developed programs and make them communicate via simple text. In that sense, any two programs designed with the Unix Way in mind can communicate. .  In those cases where you really do need a file, it is easy to turn program output into a file: .  But why write the output to a temporary file when the \"everything is a file\" philosophy gives you a better way? If all you want to do is read the output of that command into a \"vi\" editor buffer, \"vi\" can do that for you directly. From the \"vi\" \"normal\" mode, say: .  That inserts that program's output into the active editor buffer at the current cursor position. Under the hood, \"vi\" is using pipes to connect the output of the program to a bit of code that uses the same OS calls it would use to read from a file instead. I wouldn't be surprised if the two cases of \":r\" \u2014 that is, with and without the \"!\" \u2014 both used the same generic data reading loop in all common implementations of \"vi\". I can't think of a good reason not to. .  This isn't a recent feature of \"vi\", either; it goes clear back to the ancient \"ed(1)\" text editor. .  This powerful idea pops up over and over in Unix. .  For a second example of this, recall my \"mutt\" email command above. The only reason I had to write that as two separate commands is that I wanted the temporary file to be named \"*.gz\", so that the email attachment would be correctly named. If I didn't care about the file's name, I could have used process substitution to avoid creating the temporary file: .  That avoids the temporary by turning the output of \"gzip -c\" into a FIFO (which is file-like) or a \"/dev/fd\" object (which is file-like).\u2078 .  For yet a third way this powerful idea appears in Unix, consider \"gdb\" on Linux systems. This is the debugger used for any software written in C and C++. Programmers coming to Unix from other systems look at \"gdb\" and almost invariably gripe about it, \"Yuck, it's so primitive!\" Then they go searching for a GUI debugger, find one of several that exist, and happily continue their work...often never realizing that the GUI just runs \"gdb\" underneath, providing a pretty shell on top of it. There aren't competing low-level debuggers on most Unix systems because there is no need for programs to compete at that level. All we need is one good low-level tool that we can all base our high-level tools on, if that low-level tool communicates easily via pipes. .  This means we now have a documented debugger interface which would allow drop-in replacement of \"gdb\". It's unfortunate that the primary competitor to \"gdb\" didn't take this low-friction path, but that quibble aside, \"lldb\" is just as scriptable as \"gdb\". .  To pull the same thing off on a Windows box, the creators of the replaceable tool would have had to define some kind of formal plugin or automation API. That means it doesn't happen except for the very most popular programs, because it's a lot of work to build both a normal command line user interface and a complete programming API. .  This magic happens through the grace of pervasive text-based IPC. .  Although Windows' kernel has Unix-style anonymous pipes, it's rare to see normal user programs use them for IPC outside of a command shell, because Windows lacks this tradition of creating all core services in a command line version first, then building the GUI on top of it separately. This leads to being unable to do some things without the GUI, which is one reason why there are so many remote desktop systems for Windows, as compared to Linux. This is doubtless part of the reason why Linux is the operating system of the cloud, where everything's done by remote management. Command line interfaces are easier to automate than GUIs in large part because \"everything is a file.\" .  Consider SSH. You may ask, how does it work? SSH connects a network socket (which is file-like) to a pseudo tty at \"/dev/pty*\" (which is file-like). Now your remote system is connected to your local one through a connection that so seamlessly matches the Unix Way that you can pipe data through the SSH connection, if you need to. .  Are you getting an idea of just how powerful this concept is now? .  A piped text stream is indistinguishable from a file from a program's perspective, except that it's unidirectional. A program reads from a pipe the same way it reads from a file: through a file descriptor. FDs are absolutely core to Unix; the fact that files and pipes use the same abstraction for I/O on both should tell you something.\u2079 .  The Windows world, lacking this tradition of simple text communications, makes do with heavyweight OOP interfaces via COM or .NET. If you need to automate such a program, you must also write a COM or .NET program. This is a fair bit more difficult than setting up a pipe on a Unix box. .  Windows programs lacking these complicated programming APIs can only communicate through impoverished interfaces like the clipboard or File/Save followed by File/Open. .  Long Answer, part 3: The Registry vs Configuration Files .  The practical difference between the Windows registry and the Unix Way of system configuration also illustrates the benefits of the \"everything is a file\" philosophy. .  On Unix type systems, I can look at system configuration information from the command line merely by examining files. I can change system behavior by modifying those same files. For the most part, these configuration files are just plain text files, which means I can use any tool on Unix to manipulate them that can work with plain text files. .  Scripting the registry is not nearly so easy on Windows. .  The easiest method is to make your changes through the Registry Editor GUI on one machine, then blindly apply those changes to other machines with \"regedit\" via \"*.reg\" files. That isn't really \"scripting,\" since it doesn't let you do anything conditionally: it's all or nothing. .  If your registry changes need any amount of logic, the next easiest option is to learn PowerShell, which amounts to learning .NET system programming. It would be like if Unix only had Perl, and you had to do all ad hoc system administration through it. Now, I'm a Perl fan, but not everyone is. Unix lets you use any tool you happen to like, as long as it can manipulate plain text files. .   Footnotes: .   Plan 9 fixed this design misstep, exposing network I/O via the \"/net\" virtual filesystem. .  Bash has a feature called \"/dev/tcp\" that allows network I/O via regular filesystem functions. Since it is a Bash feature, rather a kernel feature, it isn't visible outside of Bash or on systems that don't use Bash at all. This shows, by counterexample, why it is such a good idea to make all data resources visible through the filesystem. .   By \"modern Windows,\" I mean Windows NT and all of its direct descendants, which includes Windows 2000, all versions of Windows Server, and all desktop-oriented versions of Windows from XP onward. I use the term to exclude the DOS-based versions of Windows, being Windows 95 and its direct descendants, Windows 98 and Windows ME, plus their 16-bit predecessors. .  You can see the distinction by the lack of a unified I/O system in those latter OSes. You cannot pass a TCP/IP socket to \"ReadFile()\" on Windows 95; you can only pass sockets to the Windows Sockets APIs. See Andrew Schulman's seminal article, Windows 95: What It's Not for a deeper dive into this topic. .   Make no mistake, \"/dev/null\" is a real kernel device on Unix type systems, not just a special-cased file name, as is the superficially equivalent \"NUL\" in Windows. .  Although Windows tries to prevent you from creating a \"NUL\" file, it is possible to bypass this protection with mere trickery, fooling Windows' file name parsing logic. If you try to access that file with \"cmd.exe\" or Explorer, Windows will refuse to open it, but you can write to it via Cygwin, since it opens files using similar methods to the example program, and you can delete it via similar trickery. .  By contrast, Unix will happily let you \"rm /dev/null\", as long as you have write access to \"/dev\", and let you recreate a new file in its place, all without trickery, because that dev node is just another file. While that dev node is missing, the kernel's null device still exists; it's just inaccessible until you recreate the dev node via \"mknod\". .  You can even create additional null device dev nodes elsewhere: it doesn't matter if you call it \"/home/grandma/Recycle Bin\", as long as it's a dev node for the null device, it will work exactly the same as \"/dev/null\". .   There are actually two high-level \"format disk\" APIs in Windows: \"SHFormatDrive()\" and \"Win32_Volume.Format()\". .  There are two for a very...well...Windows sort of reason. The first one asks Windows Explorer to display its normal \"Format Disk\" dialog box, which means it works on any modern version of Windows, but only while a user is interactively logged in. The other you can call in the background without user input, but it wasn't added to Windows until Windows Server 2003. That's right, core OS behavior was hidden behind a GUI until 2003, in a world where Unix shipped \"mkfs\" from day 1. .  The \"/etc/mkfs\" in my copy of Unix V5 from 1974 is a 4136 byte statically-linked PDP-11 executable. Unix didn't get dynamic linkage until the late 1980s, so it's not like there's a big library somewhere else doing all the real work.) Its source code \u2014 included in the V5 system image as \"/usr/source/s2/mkfs.c\" \u2014 is an entirely self-contained 457-line C program. There aren't even any \"#include\" statements! .  This means you can not only examine what \"mkfs\" does at a high level, you can experiment with it using the same tool set Unix was created with, just like you're Ken Thompson, four decades ago. Try that with Windows. The closest you can come today is to download the DOS source code, first released in 2014, which you find amounts to just a pile of assembly sources. It will only build with obsolete tools you probably won't have on-hand, and in the end you get your very own copy of DOS 2.0, an OS far less powerful than 1974's Unix V5, despite its being released nearly a decade later. .  (Why talk about Unix V5? Because it is the earliest complete Unix system still available. Earlier versions are apparently lost to time. There was a project that pieced together a V1/V2 era Unix, but it appears to be missing \"mkfs\", despite the existence of the V1 manual page linked above proving it must have existed somewhere, somewhen. Either those putting this project together couldn't find an extant copy of \"mkfs\" to include, or I suck at finding files without \"find(1)\", which also doesn't exist in that system. \":)\") .  Now, you might be thinking, \"Can't I just call \"format.com\"? Isn't that the same on Windows as calling \"mkfs\" on Unix?\" Alas, no, it isn't the same, for a bunch of reasons: .   First, \"format.com\" wasn't designed to be scripted. It prompts you to \"press ENTER when ready\", which means you need to send an Enter key to its input, or it'll just hang. .   Then, if you want anything more than a success/failure status code, you have to open its standard output for reading, which is far more complicated on Windows than it has to be. On Unix, everything in that linked article can be accomplished with a simple \"popen(3)\" call.) .   Having gone through all this complication, the output of \"format.com\" is harder to parse for computer programs than the output of \"mkfs\", being intended primarily for human consumption. .   If you trace what \"format.com\" does, you find that it does a bunch of complicated calls to \"DeviceIoControl()\", \"ufat.dll\", and such. It is not simply opening a device file and writing a new filesystem onto that device. This is the sort of design you get from a company that employs 176000 people worldwide and needs to keep employing them. .     When talking about loop devices, I talk only about Linux rather than Unix in general because loop devices aren't portable between Unix type systems. There are similar mechanisms in macOS, BSD, etc., but the syntax varies somewhat. .   Back in the days when disk drives were the size of washing machines and cost more than the department head's luxury car, big computer labs would share a larger proportion of their collective disk space as compared to modern computing environments. The ability to transparently graft a remote disk into the local filesystem made such distributed systems far easier to use. This is where we get \"/usr/share\", for instance. .  Contrast Windows, where a remote disk is typically either mapped to a drive letter or must be accessed through a UNC path, rather than integrated transparently into the local filesystem. Drive letters offer you few choices for symbolic expression; does \"P:\" refer to the \"public\" space on BigServer, or to the \"packages\" directory on the software mirror server? UNC paths mean you have to remember which server your remote files are on, which gets difficult in a large organization with hundreds or thousands of file servers. .  Windows didn't get symlinks until Windows Vista, released in 2007, which introduced NTFS symbolic links, and they weren't made usable until a decade later. Windows' symbolic links are a bit more powerful than Unix's symbolic links \u2014 a feature of Unix since since 1977 \u2014 in that they can also point to a remote file share, not just to a local path. Unix did that differently, via NFS in 1984, which builds on top of Unix's preexisting mount point feature, which it has had since the beginning. .  So, depending on how you look at it, Windows trailed Unix by roughly 2, 3, or 4 decades. You may object, \"But it has Unix-style symlinks now!\" Yet this misses the point, since it means there is no decades-old tradition of using them on Windows, so most people are unaware of them in a world where Unix systems use them pervasively, so it is not possible to use a Unix system for very long without learning about them. .  It doesn't help that Windows' \"MKLINK\" program is backwards, and you still can't create them from Windows Explorer, whereas the Unix equivalents to Windows Explorer typically do let you create symlinks. .   Linux boxes don't always use a virtual disk image in the boot sequence. There are a bunch of different ways to do it. .   Bash chooses the method based on the system's capabilities, since \"/dev/fd\" isn't available everywhere. .   Network socket descriptors are FDs underneath, too, by the way. .    ",
      "P-tags": "architectur unix-philosophi window file",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V from NP"
    },
    {
      "id": "so_50945546",
      "task": "Do we need to unlocking a mutex after recived a signal from cond variable?",
      "P-task": "need unlock mutex reciv signal cond variabl",
      "F_verb": "unlock",
      "P-body": " Can you explain me, why after \"while\" statment (and recived signal from second thread) we need to unlock the mutex, when signal makes that mutex is locked? .   When \"pthread_cond_wait\" returns the mutex is locked so that you can examine the shared state protected by it safely: .   These functions atomically release mutex and cause the calling thread to block on the condition variable cond; atomically here means \"atomically with respect to access by another thread to the mutex and then the condition variable\". That is, if another thread is able to acquire the mutex after the about-to-block thread has released it, then a subsequent call to \"pthread_cond_broadcast()\" or \"pthread_cond_signal()\" in that thread shall behave as if it were issued after the about-to-block thread has blocked. .  Upon successful return, the mutex shall have been locked and shall be owned by the calling thread. If mutex is a robust mutex where an owner terminated while holding the lock and the state is recoverable, the mutex shall be acquired even though the function returns an error code. .   Generally, a mutex should be unlocked as soon as possible to reduce contention. .  In your case, you wait for shared state \"is_done\" to change. Once it changed and you are done accessing the shared state protected by the mutex, the mutex must be unlocked. .  ",
      "P-tags": "linux c mutex condit",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP after S"
    },
    {
      "id": "so_17110844",
      "task": "error while loading shared libraries: libevent-1.4.so.2: cannot open shared object file:",
      "P-task": "error load share librari : libevent-1 4 2 : open share object file :",
      "F_verb": "open",
      "P-body": "Your \"A\" system has a symlink from \"/usr/lib/libevent-1.4.so.2\" to \"/usr/local/lib/libevent-1.4.so.2\" but system \"B\" does not. Chances are, if you create it then everything will start working. .  The command should be as follows. .  As an alternative, you can add \"/usr/local/lib\" to your library path as a test by exporting \"LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\" as a temporary fix on system \"B\". .  ",
      "P-tags": "linux compiler-error libev shared-librari",
      "source": "qa",
      "cate": "open",
      "pat": "V NP"
    },
    {
      "id": "so_55746442",
      "task": "Is setitimer() call inherited by children",
      "P-task": "setitim call inherit children",
      "F_verb": "call",
      "P-body": "Not inherited. .  The POSIX spec for fork explicitly mentions that timers are not inherited and that XSI (\"timer_create\"/\"timer_settime\") timers are reset: .    [XSI] [Option Start] Interval timers shall be reset in the child process. [Option End] Per-process timers created by the parent shall not be inherited by the child process.   A test program like: .  shows the handler runs only in the parent\u2014it prints only one pid. .  ",
      "P-tags": "setitim timer linux fork c",
      "source": "qa",
      "cate": "call/invoke/indicate/occur",
      "pat": "V NP by NP"
    },
    {
      "id": "so_21523267",
      "task": "How to convert pptx files to jpg or png (for each slide) on linux?",
      "P-task": "convert pptx file jpg png slide linux",
      "F_verb": "convert",
      "P-body": "After Installing unoconv and LibreOffice you can use: .  to convert your presentation to a pdf. For further options look here. .  Afterwards you can - as already said above - use: .  to receive the images. .  ",
      "P-tags": "jpeg libreoffic linux convert powerpoint",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP to NP on NP"
    },
    {
      "id": "su_99692",
      "task": "How do I install commands on command line? - Windows 7",
      "P-task": "instal command command line\n- window 7",
      "F_verb": "install",
      "P-body": "You'll need to set the PATH. There are several paths, and in the end they (usually) get merged in to one. .  PATH entries are delimited by semicolon (;).  .  Two are managed by Windows: .   The system path. Affects all users on the computer. .  The user path. Affects all programs you run under your user account. .   Under Windows 7, the first two are easy to find: open the start menu and type PATH. .   .  Under older Windows version, you'll need to find the Environment Variables settings. There are several ways to get to them, and it varies by Windows version, but the other answers are valid. .   .  A third is process-specific: .   The current process path. Affects the current process and any new processes it creates.  If you're in a PowerShell session, the PATH is visible as \"$env:PATH\". To add something, use \"+=\". I'd recommend using env. vars. instead of hard paths where possible. .   .  Normally you'd do this in your profile. The path can be found at \"$profile\": .   .  ",
      "P-tags": "powershel window windows-7 command-lin",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1255650",
      "task": "Can not start visual studio",
      "P-task": "start visual studio",
      "F_verb": "start",
      "P-body": "here download a deb file from here and go to the directory where it's downloaded and type .  \"sudo apt install ./{nameofdebfile}\" .  ",
      "P-tags": "20 04 visual-studio-cod",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_35293503",
      "task": "Start Fedora Server MATE Desktop",
      "P-task": "start fedora server mate desktop",
      "F_verb": "start",
      "P-body": "This should cover most bases: .   \"yum -y update kernel\" and \"reboot\" \"yum -y install dkms kernel-devel kernel-headers\" \"yum -y install epel-release\" \"yum -y groups install \"MATE Desktop\"\" Install the Virtual Box Guest additions and \"reboot\"  It's important to install the VirtualBox Guest Additions after installing MATE so that they find the X Server installation. That way they arrange the necessary graphical drivers. Finally, to avoid having to setup a graphical default target; .   \"echo \"exec /usr/bin/mate-session\" >> ~/.xinitrc\" \"startx\"  If you still get that \"X Server is offline\" issue then try \"yum -y groupinstall \"X Window System\"\" and reinstall the VirtualBox Guest Additions.  .  As was commented above, this would have been better asked on Unix & Linux. Comprehensive instructions for installing various desktop environments can be found there. .  ",
      "P-tags": "mate-desktop linux fedora xserver",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "so_22695948",
      "task": "Renaming Files With Same Name, Different Extension in Linux:",
      "P-task": "renam file name differ extens linux :",
      "F_verb": "rename",
      "P-body": "You can use parameter expansion: .  There is an excellent write-up about it here .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "au_1161646",
      "task": "Is it possible to run Docker container and show its graphical application window on host?",
      "P-task": "possibl run docker contain show graphic applic window host",
      "F_verb": "run",
      "P-body": "We need to inform container about running X11 server on host with special syntax [1]: .   .  where [2]: .   -e, --env=[] Set environment variables -u, --user=\"\" Sets the username or UID used and optionally the groupname or GID for the specified command. -v|--volume[=[[HOST-DIR:]CONTAINER-DIR[:OPTIONS]]] Create a bind mount. If you specify, -v /HOST-DIR:/CONTAINER-DIR, Docker bind mounts /HOST-DIR in the host to /CONTAINER-DIR in the Docker container. If 'HOST-DIR' is omitted, Docker automatically creates the new volume on the host. The OPTIONS are a comma delimited list and can be: .    Reference: .   https://forums.docker.com/t/x11-forwarding-with-v-on-docker-run-not-working/17708/4 \"man docker-run\"   Complete reproducible solution: .  ",
      "P-tags": "docker contain x11-forward xorg",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_7656270",
      "task": "Bourne Shell Script to print out last argument",
      "P-task": "bourn shell script print last argument",
      "F_verb": "print",
      "P-body": " ",
      "P-tags": "unix shell",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V out NP"
    },
    {
      "id": "au_265708",
      "task": "Ubuntu doesn't want to turn off",
      "P-task": "ubuntu want turn",
      "F_verb": "turn",
      "P-body": "If you have already done \"sudo halt\", \"sudo shutdown -h now\", \"sudo shutdown now\" or even \"init 0\" and the system still does not actually shutdown, I suggest to first see in the logs which process is not shutting down correctly. I would start with \"syslog\": .  \"cat /var/log/syslog\" or better yet \"tail -n50 /var/log/syslog\" and see if there is anything in there mentioning the problem. .  As you mentioned, you have removed several apps that you thought were the issue, even removing \"postgresql\" because it was the one that was showing as shutting down too slow. .  Another very important part to check is your BIOS. Make sure, in the power management settings has the correct options enabled or set so that an OS can shutdown the computer. .  Lastly, you can check some kernel options to see if the problem is power management related. In the terminal type: .  \"sudo gedit /etc/default/grub\" .  and on the line that says: .  Add in the second line one of this options: .   noapic - Will turn off APIC. .  acpi=off or noacpi - Will turn off ACPI. .  acpi=force - Will Force use of ACPI. .   It should look like this after editing (Example showing noapic) .  More information about this 2 options in What are the F6 options during installation? .  After setting one of those, save the file and type in the terminal \"sudo update-grub\". then reboot and test to see if the system shuts down. .  If you still have a system that does not shutdown and has what you commented: .  You might be suffering from one of this bug reports .   https://bugs.launchpad.net/ubuntu/+source/unity-greeter/+bug/861171 .  https://bugs.launchpad.net/ubuntu/+source/rabbitmq-server/+bug/670289 (App Related, but might apply to another specific app) .  https://bugs.launchpad.net/ubuntu/+source/upstart/+bug/880240 .  https://bugs.launchpad.net/ubuntu/+source/netbase/+bug/903825 .   You will find there suggestions that go from editing \"/etc/default/halt\" to changing the order of some services in the \"rc\" folders (rc0.d...rc6.d). .  What I would suggest, at least until the bug is eliminated is to do a \"sudo kill -9 PROCESSID\" or \"sudo killall PROCESSNAME\" command on the process that is giving you a problem. .  ",
      "P-tags": "shutdown 12 04",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP"
    },
    {
      "id": "so_33519866",
      "task": "Ignore signal sent to my own process group",
      "P-task": "ignor signal sent process group",
      "F_verb": "ignore",
      "P-body": "Eventually, I just set a flag to ignore additional signals. The sample code above should be modified thus: .  ",
      "P-tags": "rubi signal unix",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP to NP"
    },
    {
      "id": "so_19200336",
      "task": "How to use array members as the search or replace pattern in bash?",
      "P-task": "use array member search replac pattern bash",
      "F_verb": "use",
      "P-body": "BASH supports associative arrays which would be a good fit for your use case: .  Output: .  ",
      "P-tags": "array script replac regex bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP in NP"
    },
    {
      "id": "so_46663446",
      "task": "Bash how to create a txt file of all file names in a directory",
      "P-task": "bash creat txt file file name directori",
      "F_verb": "create",
      "P-body": "Too much work. .  ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "au_817101",
      "task": "Cannot upgrade to 16.04 after failed attempt",
      "P-task": "upgrad 16 04 fail attempt",
      "F_verb": "upgrade",
      "P-body": "It appears that your upgrade was partially successful except for perhaps the latest kernel. Since you have now made room in /boot, you can try installing the metapackage \"linux-generic-lts-xenial\" which will get you the latest xenial kernel. .  If other portions of the upgrade didn't succeed, I do not know how to diagnose that. .  ",
      "P-tags": "14 04 upgrad 16 04",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V to NP after NP"
    },
    {
      "id": "ul_202011",
      "task": "Some of my applications are always started when I login to Linux Mint",
      "P-task": "applic alway start login linux mint",
      "F_verb": "start",
      "P-body": "I think you were very close.  .  Just go into \"Settings => Startup Programs\" and then click on the \"Options\" tab.  .  There, you will see a checkbox saying  .   Automatically remember running applications when logging out  .   Just uncheck it. .  ",
      "P-tags": "startup login linux-mint",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V when S"
    },
    {
      "id": "so_9160599",
      "task": "Use echo output as input into a script's stdin",
      "P-task": "use echo output input script stdin",
      "F_verb": "echo",
      "P-body": "Use process substitution: .  It basically allows you to redirect the input/output of a process to another process as if it were a file. .  ",
      "P-tags": "stdout stdin bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP as NP into NP"
    },
    {
      "id": "au_528267",
      "task": "Samba File Server hide folders for certain users",
      "P-task": "samba file server hide folder certain user",
      "F_verb": "hide",
      "P-body": "The easiest way would be to create a Linux user account for your 3 users and just have them to sign in to one big shared folder. To do so you will first have to install the gnome system tools with the following command  .  After you did this go to your \"user accounts\" and click the lock button and add your accounts.  .  Now open the gnome tool we just installed, it\u2019s called users and groups.  .  Click on an account, select \"advanced\" and enter your pass. Go straight to the \"advanced tab\" and change \"shell\" to \"/bin/false\". Also it\u2019s recommended to generate a random password for the samba accounts so you can\u2019t sign in to them on the Linux machine. .  You can also change the user ID to a number lower as \"1000\" This way it will hide the account on your Linux machine. I recommend you to do this after you are sure everything is working 100% .  Now do the same for the other account. .   .  After that you make 3 samba accounts and link them to the Linux user accounts. Like shown in the following image:  .   .  Now it\u2019s just a matter of changing permissions on the folders. I will use the student and school folder as an example.  .  Open an terminal and enter the following command  .  enter your password and click okay. Now browse to your shared folder and go to the folder school, right click on it and go to properties, select permissions.  .  Now you can set properties for users and groups to allow them to enter folders. In this example we want the owner to have full control and the student to only access the files and others get no access. So you would get this:  .   .  Now it is just a matter of repeating the previous steps to give the other accounts the wanted access and permissions.  .  I hope this answered your question.  .  ",
      "P-tags": "permiss server samba",
      "source": "qa",
      "cate": "hide/collapse",
      "pat": "V NP for NP"
    },
    {
      "id": "so_33910837",
      "task": "sed to search and replace in case of multiple spaces",
      "P-task": "sed search replac case multipl space",
      "F_verb": "search",
      "P-body": "There are multiple ways to do it. If you decide that portability is not an issue, you can use shorter notations than if portability is an issue. .  Portable The ghastly first line looks for zero or more space-like characters (blanks, tabs) at the start of the line, followed by \"enable-cache\", one or more space-like characters, the word \"passwd\", one or more space-like characters, the word \"no\", and zero or more space-like characters and the end of line. This matches the lines that are interesting. The second line contains a simpler pattern that replaces the \"no\" and any trailing space with just \"yes\" (deleting the trailing space if there was any \u2014 you didn't want it anyway). This can be simpler because the elaborate expression has ensured that only the interesting lines are found. The braces simply group things; it could all be done on one line without the braces if you don't mind long lines. .  GNU \"sed\" GNU \"sed\" and the \"-r\" option provides some shorthands, notably \"\\s\" to mean \"[[:space:]]\" and \"+\" to mean \"\\{1,\\}\", which allows that to be compressed to: .  ",
      "P-tags": "linux sed bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V for NP in NP of NP"
    },
    {
      "id": "so_17854431",
      "task": "Use awk to extract a row records not contain specific word",
      "P-task": "use awk extract row record contain specif word",
      "F_verb": "extract",
      "P-body": "You mean tab delimited right? You can do this in awk: .  That command will print all records where \"$0\" does not contain \"\"hello\"\". .  PS: If you want to match full word hello but avoid matching helloed then use: .  ",
      "P-tags": "awk shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_135807",
      "task": "Ubuntu 12.04 Update not working",
      "P-task": "ubuntu 12 04 updat work",
      "F_verb": "update",
      "P-body": "As mentioned in my comment, I had exactly the same problem. I solved it by doing the following: .   Boot into recovery mode. Login and hit CTRL + ALT + 1 Type \"sudo apt-get -f install\" Wait Type \"sudo shutdown -r now\" Wait Profit!  ",
      "P-tags": "12 04 instal",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V S_ING"
    },
    {
      "id": "ul_503126",
      "task": "Trouble setting up Raspbian network bridge",
      "P-task": "troubl set raspbian network bridg",
      "F_verb": "set",
      "P-body": "After looking at the linked tutorial ( https://pimylifeup.com/raspberry-pi-wifi-bridge/ ), I could conclude that this is not a bridge tutorial, but a NAT/router tutorial. Even a comment in it also states: .   Also, important to note that this setup is a wifi client NAT router, not technically a bridge. .   So to actually use a bridge, follow a bridge tutorial. Since it's Raspbian, Debian's BridgeNetworkConnections should be good enough. The bridge-utils package mentionned isn't really needed for its (obsolete) \"brctl\" command which could be completely replaced with modern iproute2's \"ip link\" and (if actually needed) \"bridge\", but for its \"bridge-utils-interfaces\" plugin for ifupdown's configuration. .  So in the end the configuration can be done with something similar to: .  Don't put any IP on the real interfaces, because they now become bridge ports and their layer 3 settings will be ignored. Also not vital but the bridge should inherit its first's interface MAC address. So if it really matters and you'd rather have eth1's MAC used, put it first in the \"bridge_ports\" command (this would probably also change the router's DHCP offer). .  Now change any reference to \"eth0\" in various settings that would state an interface into \"br0\" instead, but chances are you don't even need this, since for example you don't need anymore \"dnsmasq\". That's it. .  Some extra informations: .   If you ever use \"iptables\" instead or in addition of \"ebtables\" to try to do filtering between the two interfaces (hint: you should probably not, it's a bridge now, not a router, but it's needed for a stateful transparent firewalling bridge), please be aware, if activating br-netfilter of the special interactions between the bridge filtering and the IP filtering layers: ebtables/iptables interaction on a Linux-based bridge. This can lead to hard-to-debug results when not knowing about it. .  Many \"tc qdisc\" effects (like \"netem\") work on the outgoing direction (egress) only. Since you're between both interfaces \"eth0\" and \"eth1\" , you could ponder that you can always find an egress interface for a specific intended action, but if it's done on \"eth0\" then the RPi itself can be affected on the internet side, which is probably not what is wished. You can avoid this by attaching an Intermediate Functional Block device (\"ifb0\") to \"eth1\": this artificially inserts an interface between the ingress and the rest of the network code. This interface is thus now an egress interface from the point of view of \"eth1\"'s incoming data flow, and can happily accept egress features like \"netem\". For any other interpretation it's part of the ingress flow. You can now then apply TC to \"eth1\" and \"ifb0\" and leave \"eth0\" undisturbed. More informations in my answer there: Simulation of packet loss on bridged interface using netem .   ",
      "P-tags": "bridg raspbian dnsmasq iptabl dhcpcd",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP"
    },
    {
      "id": "au_537234",
      "task": "how to copy / install various data from a DVD drive to Hard disk in Ununtu 14.04",
      "P-task": "copi instal variou data dvd drive hard disk ununtu 14 04",
      "F_verb": "copy",
      "P-body": "use  .  to add these DVD to repository list .  and then use .  and then  .  ",
      "P-tags": "dvd software-instal",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP from NP to NP in NP"
    },
    {
      "id": "ul_185520",
      "task": "How to delete file called \"-C\"",
      "P-task": "delet file call -c",
      "F_verb": "delete",
      "P-body": "Use \"--\" to distinguish between options which start from \"-\" and filename or prepend file with \"./\". The safest is to use both: .  ",
      "P-tags": "solari file bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_2658572",
      "task": "How to log error queries in mysql?",
      "P-task": "log error queri mysql",
      "F_verb": "log",
      "P-body": "I know this is ancient now, but for anyone having the same issue that lands here from Google, here's my two cents.  .  If you're using the cli client, you can simply redirect your sterr to a file, and then parse through that.  .  ",
      "P-tags": "linux mysql log",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP in NP"
    },
    {
      "id": "so_17699161",
      "task": "How to prompt to the user while performing a find>replace in unix",
      "P-task": "prompt user perform find replac unix",
      "F_verb": "prompt",
      "P-body": " There's some tricky stuff going on here: .   the output from the find command is send to the while loop on file descriptor 3, and read uses that fd to grab filenames  this is necessary because there is a read command inside the loop to interact with the user that has to use stdin.  the while loop reads from a process substitution \"<(find -name ...)\" so that no subshell has to be created and to facilitate the use of a different file descriptor.  in bash, when you say \"cmd1 | cmd2\", new bash processes are created for each side of the pipe. This can cause problems in that variables assigned in a subshell are not present in the current shell, not the case here.  to properly handle files with weird names, I use the GNU find \"-print0\" feature which separates the filenames with a zero byte, and then use read's \"-d ''\" option. \"grep -c\" counts the number of lines with a match. \"grep -o pattern file | wc -l\" counts the number of actual matches. the crazy sed script adds protection in case the search or the replacement strings contain the \"s\" commands delimiter. I use \"|\" instead of \"/\" because the escaping got even more extreme.  ",
      "P-tags": "statu unix shell bash exit",
      "source": "qa",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V to NP while S"
    },
    {
      "id": "so_39457380",
      "task": "Retrieve email subject from file via bash",
      "P-task": "retriev email subject file via bash",
      "F_verb": "retrieve",
      "P-body": "The following is wrong but implements what you seem to be asking. .  The problem with this is that it succeeds in the trivial case, but fails when you have a MIME RFC2047-encoded \"Subject:\" header, and (more trivially) when the \"Subject:\" header spans more than a single line. .  I would approach this with a slightly more modern programming language. It's not quite a one-liner, but it's easy enough with Python. .  where \"emailsubj.py\" contains something more or less like .  (Remember to \"chmod +x emailsubj.py\", obviously.) .  This retrieves the entire \"Subject:\" header and seems like a good design for a modular tool. If you want to remove a prefix after extracting the header, the shell has simple facilities for parameter expansion which do exactly that. For example, .  displays the value of \"$subj\" with any prefix \"PD:\" removed from the front of the value. .   Here is a Python 3 version, contributed by Xlea in a proposed edit which however violated general Stack Overflow guidelines and thus was rejected before I could merge it into this answer. .  ",
      "P-tags": "email sed bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP from NP via NP"
    },
    {
      "id": "so_10088449",
      "task": "Skip line in text file which starts with '#' via KornShell (ksh)",
      "P-task": "skip line text file start via kornshel ksh",
      "F_verb": "skip",
      "P-body": "You should not leave skipping lines to \"ksh\". E.g. do this: .  And instead of the \"echo\" part do whatever you want. .  Or if \"ksh\" does not support this syntax: .  ",
      "P-tags": "ksh script unix shell",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP in NP which S"
    },
    {
      "id": "au_217380",
      "task": "How to remove wrong command ran earlier?",
      "P-task": "remov wrong command ran earlier",
      "F_verb": "remove",
      "P-body": "This should fix it: .  Otherwise, run \"sudoedit /etc/apt/sources.list.d/noobslab-themes-precise.list\" and fix the line manually. .  ",
      "P-tags": "error-handl command-lin",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_53529385",
      "task": "Get-ChildItem and wildcards and filtering",
      "P-task": "get-childitem wildcard filter",
      "F_verb": "get",
      "P-body": "The reason you're seeing different behavior is the - obscurely situational - stringification behavior of the objects output by \"Get-ChildItem\": .  This answer details when \"Get-ChildItem\" output happens to stringify to a mere filename vs. a full path, and it so happens that \"Get-ChildItem \"$ActivityLogDirectory\" -Filter *.csv\" stringifies to mere filenames. .  The workaround is to explicitly stringify the objects as their full paths via their \"FullName\" property (PSv3+ syntax): .  ",
      "P-tags": "powershel powershell-v5 1",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_19529999",
      "task": "Add Package Control in Sublime Text 3 through the command line",
      "P-task": "add packag control sublim text 3 command line",
      "F_verb": "add",
      "P-body": "The easiest way is to download https://packagecontrol.io/Package%20Control.sublime-package using \"wget\" or \"curl\", and store it in \"~/.config/sublime-text-3/Installed Packages\". It will then set itself up upon first starting the editor. As a bonus, if you create \"~/.config/sublime-text-3/Packages/User/Package Control.sublime-settings\" and populate it with the packages you want installed, everything should work more-or-less automatically to download and install everything. A restart is generally a good idea, but this is a good way to script the setup of a new development environment. As an example, a minimal ST3 \"Package Control.sublime-settings\" file is below, so you can get an idea of how it's set up: .  Good luck! .  ",
      "P-tags": "script linux instal sublimetext3",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP through NP"
    },
    {
      "id": "ul_200355",
      "task": "`ack` doesn't show line numbers on a single file",
      "P-task": "ack show line number singl file",
      "F_verb": "show",
      "P-body": "When you don't provide any file, \"ack\" will search for all files in current directory and subdirectories. If a file contains matching pattern, \"ack\" print that filename, the line number and the line which matched pattern.  .  This behaviour does not apply for one file (See ack documentation, search for \"-H\" option). .  Since when \"ack\" doesn't have \"-n\" option line \"grep\", which will print line matched with its relative line number, you have two choices to work around this issue. .  Forcing \"ack\" print filename with \"-H\": .  or passing \"/dev/null\" as the second file: .  ",
      "P-tags": "ack",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP on NP"
    },
    {
      "id": "au_456689",
      "task": "\"error: XDG_RUNTIME_DIR not set in the environment.\" when attempting to run nautilus as root",
      "P-task": "error : xdg_runtime_dir set environ\nattempt run nautilu root",
      "F_verb": "set",
      "P-body": "When you run software as another user you're in fact starting a new minimal isolated environment that doesn't carry on some \"excessive\" variables (among others variables responsible for injecting libraries or setting privileges). Replace your \"sudo nautilus\" call with the following - it will carry on user-specific X server settings from the current session: .  This is a one time low level solution but it will work on a misconfigured machine. If you want to permanently \"fix your \"sudo\"\" you need to find the issue with your environment configuration and correct it as described in other answers. .  ",
      "P-tags": "nautilu sudo",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V in NP when S"
    },
    {
      "id": "so_47802675",
      "task": "Combine file names with folders based on commn value in CSV",
      "P-task": "combin file name folder base commn valu csv",
      "F_verb": "combine",
      "P-body": "If you have folders for each kind of file all located in the same place and your files names are all formatted like that, like in your example, this is really easy. This answer uses the \".Split()\" method, and a calculated property. .  If things are not as simple as in your example we can work with that, we just need a more accurate example and explanation. .  Edit: Ok, looking at the updated CSV file I see that you have a list of potential paths in one column, and a list of files in the other. What I would suggest is to get the list of paths into another variable. Then build a hashtable with those paths as the key, and split the path on backslash and underscore (underscore because the files are underscore delimited). Now loop through the files, and for each one split on underscores. Compare that to the split paths, and take the path with the most matches. .  Here's the script that'll do that: .  And here's the output: .  I am assuming that your desired output has a mistake for the last 2 items, because there is nothing in the file name to indicate that the path should be ICO\\fdr_120 .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP with NP on NP in NP"
    },
    {
      "id": "so_34211944",
      "task": "Find and replace a portion of a string in a txt file",
      "P-task": "find replac portion string txt file",
      "F_verb": "replace",
      "P-body": "Simply replace that number with the content of the variables, then write the text back to the file: .  ",
      "P-tags": "string replac powershell-2 0",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "au_769329",
      "task": "Is there a way to restore a Linux system to a previous state Using BTRFS? as in Windows restore points",
      "P-task": "way restor linux system previou state use btrf\nwindow restor point",
      "F_verb": "restore",
      "P-body": "Yes, there is a very good way to make restore points using btrfs in Ubuntu. .  Standard Ubuntu installation with \"btrfs\" uses subvolumes \"@\" for \"/\" and \"@home\" for \"/home\". .  If you have installed Ubuntu in the default way with these subvolumes, then you can easily make restore points for \"/\" and \"/home\" separately. .  You can check if you have these subvolumes by running .  Let's assume that the partition with Ubuntu is \"/dev/sda1\". .  Make a snapshot of your \"/\" by running. .  Now you can safely amend your data on \"/\" (not including \"/home\"). You can install or delete any packages, or do whatever you want. .  To restore to the previous state you will need to boot from a LiveUSB and rename subvolumes. .  Now you can boot into the original system state. .  If you are sure that you do not need the \"broken\" subvolume any more, you can delete it this way: .  The same way you can make restore points for \"/home\". .  You can have some other subvolumes if you installed not a default way. But you can always make snapshots of any subvolumes the same way. .  A useful example: .  Before you upgrade Ubuntu to a newer release, make snapshots of \"/\" and probably \"/home\". The latter is not very important in most cases. .  If something goes wrong during or after the upgrade you can always return to the old release. .  You can keep old snapshots for any time if you have enough disk space. .  I upgraded this way some computers from 14.04 to 16.04 and keep the 14.04 snapshots in case there are some problems with 16.04. It takes a minute to boot into 14.04 this way. .  You can also setup grub a way that you can boot into one or another snapshot using grub menu. But it is probably a topic for another question. .  ",
      "P-tags": "schedul restor snapshot backup",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP"
    },
    {
      "id": "au_411914",
      "task": "How to restore python to its default on Ubuntu 13.10",
      "P-task": "restor python default ubuntu 13 10",
      "F_verb": "restore",
      "P-body": "This question has been answered here with \"update-alternatives\": .  https://stackoverflow.com/a/9140731/1041104 .  A detailed response is outlined here: .  http://codeghar.wordpress.com/2009/01/27/update-alternatives-in-debian/ .  As @Braiam asked, how did you install it? Python is Not always backward compatable, some projects Require One version. .  ",
      "P-tags": "python",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP to NP on NP"
    },
    {
      "id": "so_59155150",
      "task": "Obtaining allowed MTU range for specific device from bash-script",
      "P-task": "obtain allow mtu rang specif devic bash-script",
      "F_verb": "allow",
      "P-body": "Package iproute2 (since v4.19) parses min/max mtu details and prints it to console when \"--details\" option is provided by user .  example of script .  output: .  Debian 10 already has recent enough version of iproute2 package (v4.20) to display min/max mtu. Ubuntu 18.04.3 has a kernel which already provides this information to userspace but iproute2 package is not fresh enough(v4.15) to parse kernel's data (and display them to the user). .  You can build fresh iproute2 tools yourself in case you have outdated package. .  ",
      "P-tags": "linux network-program mtu bash linux-device-driv",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP for NP from NP"
    },
    {
      "id": "so_16527425",
      "task": "Unable to set second to last command line argument to variable",
      "P-task": "unabl set second last command line argument variabl",
      "F_verb": "set",
      "P-body": "You need a bit of math to get the number you want (\"$(($#-1))\"), then use indirection (\"${!n}\") to get the actual argument. .  Indirection (\"${!n}\") tells bash to use the value of \"n\" as the name of the variable to use (\"$2\", in this case). .  ",
      "P-tags": "command-lin shell bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP to NP"
    },
    {
      "id": "ul_622372",
      "task": "Getting name of logrotate file?",
      "P-task": "get name logrot file",
      "F_verb": "get",
      "P-body": "Yes, why not, you can directly write in postrotate block: .  in a worse situation where logrotation happened for example with today's date and postrotate posted to run in next day's date, so our \"cp\" command will not get that file to copy. for that you can get one day older file always instead of today's date rotated file: .  or of course you can copy those both files, meaning today's date and yesterday's date files. .  ",
      "P-tags": "logrot bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_27119071",
      "task": "How can I combine two ranges in a bash loop?",
      "P-task": "combin two rang bash loop",
      "F_verb": "combine",
      "P-body": "Try this: .  I feel that yours is a correct way too, but if you are facing any syntax error, try the above format. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP in NP"
    },
    {
      "id": "au_643441",
      "task": "How to create a separate home partition after installing Ubuntu under single / partition",
      "P-task": "creat separ home partit instal ubuntu singl partit",
      "F_verb": "create",
      "P-body": "If you don\u2019t create a separate home partition while installing Ubuntu, you don\u2019t have to reinstall Ubuntu from scratch. To migrate to a separate home partition after installation, you\u2019ll have to create a new partition (which may require resizing your existing partitions), copy the files from your existing home directory to that partition, and tell Ubuntu to mount the new partition at /home. .   Create a New Partition : use Gparted to shrink and create new partition. Here a tutorial for you. Copy Home Files to New Partition : copy your files from old home to the newly created partition .   Get your new Partition\u2019s UUID: use the command: .  Copy the UUID to add it later to the \"fstab\" .  Add to the fstab: .  Add the following text to the fstab file on a new line .   Move Home Directory & Restart .  Move your current home directory, and create a new, empty home directory which your new partition will be mounted at: .    Now restart and check your new configuration, If everything is just perfect then you can completely remove your old home. .  For details and more information refer to the Ubuntu wiki: https://help.ubuntu.com/community/Partitioning/Home/Moving .  ",
      "P-tags": "partit gpart",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP after S_ING under NP"
    },
    {
      "id": "so_45383944",
      "task": "match the string to find the braces & match another string with in the braces & replace it",
      "P-task": "match string find brace match anoth string brace replac",
      "F_verb": "match",
      "P-body": "I suppose that hostgroup value should be \"SERVER-DATABASE\" and not \"SERVER--DATABASE\" in your sample code. If so, you can try this sed: .  All lines between \"{\" and \"}\" are merged in the pattern space. If \"DataGuardDatadgSpace\" is found in the block, \"SERVER-DATABASE\" value in \"hostgroups\" is replaced with \"SERVER- NODE1-DATABASE\". .  Add the \"-i\" flag to edit the file in place: .  ",
      "P-tags": "awk perl sed bash",
      "source": "qa",
      "cate": "match",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_46254454",
      "task": "awk to compare two files and print formatted output",
      "P-task": "awk compar two file print format output",
      "F_verb": "compare",
      "P-body": "With GNU awk for true multi-dimensional arrays: .  . .  If the output order matters then there's various ways to handle it... .  ",
      "P-tags": "awk unix",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "so_4845733",
      "task": "Linux C creating custom printf function without header libraries",
      "P-task": "linux c creat custom printf function without header librari",
      "F_verb": "create",
      "P-body": "What architecture are you programming for?  .  If you are writing a boot loader for x86, then your boot loader will at first be in 16 bit mode. Thus when the compiler issues a push instruction, which is how I would guess it passes the arguments for the printf() function, it will by default push 16 bits of data. The long data type will be a specially issued instruction (or two) to push all 32 bits onto the stack, this is assuming an int is 16 bits and a long is 32 bits (which for a 16bit mode compiler, is not an unreasonable assumption, I don't think). .  So, lets assume x86 in 16 bit mode: .  It would appear you are using *ip to address the arguments as they are pushed on the stack. Since ip is a pointer to a long (a 32 bit data type) when you do ip++ you are incrementing the actual value held by the pointer by 4, as in if *ip = 0x1234 then *(ip+1) = 0x1238. Thus if you are using ip++ for the 16bit ints, then you are skipping an int every time you do ip++, since ints are only 2 bytes (16 bits). A possible solution is to use void * for ip and then add sizeof(data type) to ip; i.e if you print an int, so an: .  Or for an unsigned long: .  However, without more specific details about the exact architecture you are programming for and and what ABI your compiler is using, I can only wildly speculate. .  I hope this helps. .  Regards, Alex .  ",
      "P-tags": "linux c bcc-compil",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP without NP"
    },
    {
      "id": "so_58714843",
      "task": "Here-string not working if you indent in vscode",
      "P-task": "here-str work indent vscode",
      "F_verb": "indent",
      "P-body": "I'd love to be proven wrong (please!) but no, heredoc strings need to be formatted without indent in Powershell to be understood. .  ",
      "P-tags": "powershel visual-studio-cod",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V in NP"
    },
    {
      "id": "so_57201745",
      "task": "Check if linux client obtains IP via dhcp",
      "P-task": "check linux client obtain ip via dhcp",
      "F_verb": "obtain",
      "P-body": "Working with your 2nd code idea, .  I would use a \"case\" statement for the final block.  .  Note that we don't need \"[[ ... ]]\" pairings when we test the return value of the called program, hence the \"awk 'END{exit retVal}'\" sort of code. .  ------- Edit ------- .  And because we are relying just on the finding of a certain term in a certain file and are NOT parsing the output in any way, this can be futher simplified by replacing the \"awk\" scripts with a simple \"grep -q\", i.e. .  ----------- end edit --------- .  Untested as I don't have these OSes or the files and their contents available.  .  Hmm, I had one other comment to make, but got distracting cleaning up my code. When I think of it, I'll add it as a comment below. .  IHTH .  ",
      "P-tags": "if-stat redirect bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP via NP"
    },
    {
      "id": "ul_628492",
      "task": "Merge primary and clipboard X selections",
      "P-task": "merg primari clipboard x select",
      "F_verb": "merge",
      "P-body": "Shell script with Clipnotify It is a program that simply exits whenever an X selection changes. So put it in a while loop and when it exits, figure out if the clipboard or the primary changed, and stuff the contents of the changed selection in the other selection. .  Save it as \"mergexsel\", make it executable and let it run. .  The function contains a kludge to preserve trailing newline characters (\"abc\\n\" is different from \"abc\"); other than that the script is self-explanatory. .  Autocutsel It must be run for both primary and clipboard (as this answer on Super User shows). .  Diodon, a GUI clipboard manager Let it run in the background with \"diodon &\". Click the tray icon or issue another \"diodon\" command to pop up its GUI menu with the history of clipboard contents and the \"Preferences\" item. Select \"Preferences\" and in the window that opens, check the items .   Use clipboard (Ctrl+C) .   Use primary selection .   Synchronize clipboards .    Further reading: Clipboard \u2014 Arch Wiki for context and more clipboard managers. .  ",
      "P-tags": "clipboard x11",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP"
    },
    {
      "id": "so_8706958",
      "task": "Determine OS during runtime",
      "P-task": "determin os runtim",
      "F_verb": "determine",
      "P-body": "Actually, most systems have a \"uname\" command which shows the current kernel in use. On Mac OS, this is usually \"Darwin\", on Linux it's just plain \"Linux\", on Windows it's \"ERROR\" and FreeBSD will return \"FreeBSD\". .  More complete list of \"uname\" outputs .  I'm pretty sure that there's a C equivalent for \"uname\", so you won't need \"system()\" .  ",
      "P-tags": "linux bsd maco c window",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP during NP"
    },
    {
      "id": "so_65244260",
      "task": "Jmeter Encrypt AES 128 with CBC",
      "P-task": "jmeter encrypt ae 128 cbc",
      "F_verb": "encrypt",
      "P-body": "In order to get the human-readable error messages you need to put your code inside the try block like: .  Also be aware that since JMeter 3.1 it's recommended to use JSR223 Test Elements and Groovy language for scripting. Groovy has much better performance comparing to Beanshell especially when it comes to resource-intensive cryptographic operations. .  The only required change to your code would be removing static modifiers from the variables .  So given your \"xmlDeclaracion\", \"keybytes\" and \"iv\" variables have valid values your code should work fine. .  More information on Groovy scripting in JMeter: Apache Groovy - Why and How You Should Use It .  ",
      "P-tags": "encrypt beanshel java jmeter",
      "source": "qa",
      "cate": "package/encode/marshal/synthesize/wrap/compress/pack/compact/encrypt/escape/gzip/password/recompress/stream",
      "pat": "V NP with NP"
    },
    {
      "id": "au_764204",
      "task": "Can't disable turbo boost since Ubuntu 16.04",
      "P-task": "disabl turbo boost sinc ubuntu 16 04",
      "F_verb": "disable",
      "P-body": "I couldn't get my script to work with the latest version of msr-tools (probably discontinued as the github remains untouched since 2013). Perhaps Ubuntu 16.04 changed the way it stores settings for its CPUs drivers, and msr-tools fails to generate the proper file tree. .  The workaround I found is to (sudo) edit the file: .  Simply type \"1\" for no turbo and save... No reboot needed. .  You can easily check if it's working with  .  And see if any of the outputs goes above stock frequency .  I hope someone will find this useful! Regards .  ",
      "P-tags": "cpu turbo-boost 16 04",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "su_1352166",
      "task": "How to resolve \"ERROR: Specified cast is not valid.\" error during installation?",
      "P-task": "resolv error : specifi cast valid\nerror instal",
      "F_verb": "resolve",
      "P-body": "I just had this problem. I did: .  and it choked on \"HKLM:\\software\\microsoft\\windows\\currentversion\\uninstall\\nbi-nb-base-8.2.0.0.201609300101\", which is for Netbeans 8.2. I see in regedit that NoModify has \"(invalid DWORD (32-bit) value)\". \"get-itemproperty -erroraction continue\" has no effect. .  EDIT: The Netbeans people are finally fixing this currently. https://issues.apache.org/jira/browse/NETBEANS-2523 .  ",
      "P-tags": "chocolatey powershel",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP during NP"
    },
    {
      "id": "ul_364240",
      "task": "Would a reinstall keep my /home with all documents on the Desktop",
      "P-task": "would reinstal keep home document desktop",
      "F_verb": "keep",
      "P-body": "It's probably easier to repair the existing install, at least if the damage was caused by \"apt-get remove python\" or similar. But if you want to reinstall: .  FIRST. You really ought to take a backup. The easiest way (since you can't boot the system) is probably a Debian Live DVD/USB stick/etc. Copy all your important files to, e.g., a USB hard disk. The Live disc gives you a normal desktop environment, so you can do that with the familiar file manager interface. .  Do not proceed without a backup. It's far too easy to accidentally destroy your files. .  If you have \"/home\" on a separate partition and make sure not to reformat /home when reinstalling, then your files will be preserved. Whether to format or not is an option in the installer. .  Note that if you're running packages that manage their own data (for example, a database like MySQL or PostgreSQL, a mail server, a web or FTP server, etc.), that data may be stored in \"/var\" or \"/srv\". In addition, things like \"cron\" store your user crontab in \"/var\".  .  If everything is on one partition, then it's possible to tell the installer not to format it\u2014but the install will fail, unless you've already cleaned up (e.g., via \"rm -Rf\") all the system files. That'd basically be everything other than \"/home\", and the exceptions mentioned above. .  ",
      "P-tags": "home gnome debian",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "ul_40655",
      "task": "Applying changes to xorg.conf without restarting",
      "P-task": "appli chang xorg conf without restart",
      "F_verb": "apply",
      "P-body": "Try this from the command line: .  or alternatively .  I am not sure what will happen if you are already running X, but it should restart it, so better close out all windows first. .  See Restart X Server Ubuntu 12.04 Without Rebooting and How to kill and to start the X server? for more information. .  Always a good idea to keep a copy of any configuration file before you modify it so that you can easily restore it if something goes awry. .  ",
      "P-tags": "xorg",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP to NP without S_ING"
    },
    {
      "id": "au_741675",
      "task": "Failed to download repository information with Google Chrome installed on Ubuntu 14.04 64bit since beginning of March 2016",
      "P-task": "fail download repositori inform googl chrome instal ubuntu 14 04 64bit sinc begin march 2016",
      "F_verb": "download",
      "P-body": "Cause When you install Google Chrome, it adds its own repository to your system so that it can be updated via Software Updater. Around the beginning of March 2016, Google dropped their 32bit builds for Chrome. On 64bit Ubuntu, Software Updater expects to see both 32bit and 64bit versions of packages in a given repository. Since Google removed the 32bit version, Software Updater can't find that package anymore and produces an error that shows up as Failed to download repository information, Check your internet connection. .  Fix the repo In order to fix this, you have to tell the package manager that the Google repository is 64bit-only. To do this you have to edit the Google repository file to add \"[arch=amd64]\" after the \"deb\" at the beginning of the line. The following snippet will check if the error is indeed with the Google repository and make the change for you. Make sure you copy the whole snippet (it's one line) and paste it in your favorite terminal: .  Upgrade Chrome Close and re-run Software Updater and upgrade Chrome to the latest version - 49.0.2623.87-1 or later. .  ",
      "P-tags": "google-chrom updat update-manag",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP on NP since NP"
    },
    {
      "id": "au_681649",
      "task": "How to prevent grep from printing the same string multiple times?",
      "P-task": "prevent grep print string multipl time",
      "F_verb": "prevent",
      "P-body": "The Unix philosophy is to have tools that do one thing and do them well. In this case, \"grep\" is the tool that selects text from a file. To find out if there are duplicates, one sorts the text. To remove the duplicates, one uses the \"-u\" option to \"sort\". Thus: .  \"sort\" has many options: see \"man sort\". If you want to count duplicates or have a more complicated scheme for determining what is or is not a duplicate, then pipe the sort output to \"uniq\": \"grep These filename | sort | uniq\" and see \"man\"uniq` for options. .  ",
      "P-tags": "grep command-lin bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING"
    },
    {
      "id": "ul_312750",
      "task": "How to put three thin pages in a A4 page PDF?",
      "P-task": "put three thin page a4 page pdf",
      "F_verb": "put",
      "P-body": "Using the \"nup\" feature of \"pdfjam\" .  (tested with pdfjam version 2.08 on Ubuntu). Some systems may provide separate a \"pdfnup\" executable - AFAIK the command syntax is the same. .  PDFjam README .  ",
      "P-tags": "print pdf",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_643481",
      "task": "assign letters to jump forward and backward in bash",
      "P-task": "assign letter jump forward backward bash",
      "F_verb": "assign",
      "P-body": "In the \"tcsh\" shell, \"bindkey -v\" sets the command line editing mode to \"Vi mode\" (as opposed to \"Emacs mode\"). .  In the \"bash\" shell, the same effect can be had with \"set -o vi\". .  Putting the command line editor into \"Vi mode\" makes it behave a bit as if you were using the Vi editor, where \"w\" (in \"normal mode\", after pressing Esc) moves to the first character of the next word, \"b\" moves to the first character of the current or previous word, end \"e\" moves to the next end-of-word, etc. .  You may also switch the Readline library (which the \"bash\" bash is using for the command line editing) into \"Vi mode\" by adding the setting \"set editing-mode vi\" in your \"~/.inputrc\" file. Doing this would additionally affect any other program using the Readline library for command line editing (such as some interactive mode database clients). .  ",
      "P-tags": "vi-mod tcsh command-lin bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP S_INF using NP in NP"
    },
    {
      "id": "so_32254975",
      "task": "How to get only lines with a single quote using GNU sed in Bash shell?",
      "P-task": "get line singl quot use gnu sed bash shell",
      "F_verb": "get",
      "P-body": "As pointed by casimir-et-hippolyte using grep is simpler here: .  \"grep \"^[A-Z][a-z'][a-z ]\"\" .  or using sed: .  \"sed -n \"/^[A-Z][a-z'][a-z ]/p\"\" .  ",
      "P-tags": "linux regex quot bash sed",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP using NP in NP"
    },
    {
      "id": "so_22562992",
      "task": "Using mailutils-config to set askcc to False",
      "P-task": "use mailutils-config set askcc fals",
      "F_verb": "set",
      "P-body": "I installed mailutils just yesterday and today spent hours trying to set the mail variable \"savekeep\" to True. The mailutils documentation is poor but I got things to work after finding 2.4.7 Personal and System-wide Configuration Files. So then the task is to find out how to write the settings in a mailrc file. You can refer to .mailrc File Format on the ibm.com website. You need to create the file ~you/.mailrc for user configuration or /etc/mail.rc for system wide configuration. Here is what you need to write in the file to set \"savekeep\" and \"askcc\". .  ",
      "P-tags": "configur linux ubuntu sendmail email",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP to NP"
    },
    {
      "id": "au_721186",
      "task": "Cant get HD resolution working on second monitor, nvidia GT640 card, Ubuntu 14.04",
      "P-task": "cant get hd resolut work second monitor nvidia gt640 card ubuntu 14 04",
      "F_verb": "get",
      "P-body": "The answer here fixed it: http://ubuntuforums.org/showthread.php?t=1812872&page=2 .  specifically, .  ",
      "P-tags": "dvi nvidia multiple-monitor",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_ING on NP"
    },
    {
      "id": "au_66835",
      "task": "Where can I report a bug for apps.ubuntu.com?",
      "P-task": "report bug app ubuntu com",
      "F_verb": "report",
      "P-body": "Ubuntu web catalog Found it by searching google for \"\"apps.ubuntu.com\" site:launchpad.net -oneconf\" which shows bugs for \"apps.ubuntu.com\" in Ubuntu Web Catalog. .  ",
      "P-tags": "commun ubuntu-websit bug-report",
      "source": "qa",
      "cate": "report/notify/prompt/ring/remind/focus",
      "pat": "V NP for NP"
    },
    {
      "id": "ul_267578",
      "task": "Grep-like tool to show a specific region of a text relative to a pattern",
      "P-task": "grep-lik tool show specif region text rel pattern",
      "F_verb": "show",
      "P-body": " When line start with \"pose:\", \"s\" is set as \"NR+11\". if \"NR\" is greater than \"s\" and less than \"s+10\" lines are printed.  .  ",
      "P-tags": "text-format grep",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP to NP"
    },
    {
      "id": "so_48933691",
      "task": "Launch java processes upon docker run command",
      "P-task": "launch java process upon docker run command",
      "F_verb": "run",
      "P-body": "You can achieve this with: .  But you could also use the CMD statement inside the Dockerfile .  And than run \"docker run -it 6b23ccf3402c\" .  ",
      "P-tags": "linux selenium-grid docker",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_2833355",
      "task": "shell command to find a process id and attach to it?",
      "P-task": "shell command find process id attach",
      "F_verb": "attach",
      "P-body": "There is an easy way to get rid of the grep process: .  (as long as the process you're trying to find doesn't include the string \"\" grep \"\"). .  So something like this should work in a script (again, assuming there's only one copy running): .  If you call your script \"dddproc\", you can call it with: .  Although I'd add some sanity checks such as detecting if there's zero or more than one process returned from \"ps\" and ensuring the user supplies an argument. .  ",
      "P-tags": "domain-driven-design grep bash",
      "source": "qa",
      "cate": "bind/attach/rebind/reattach/subscribe/trace/catch/fork/follow/tail/daemonize",
      "pat": "V to NP"
    },
    {
      "id": "so_57016157",
      "task": "Stop git from writing non-errors to stderr",
      "P-task": "stop git write non-error stderr",
      "F_verb": "stop",
      "P-body": " write all those errors into a text file  .   Those are not always error, considering most Git commands outputs information message on stderr, as I mentioned here: .   stderr as it is just informative messages, not to be consumed by machines. .   If it better to test the exit status of the command and email both stdout and stderr if said exit status differs from 0 .  Plus, you are doing two redirections: \">\" followed by \">\": the second one would recreate \"/tmp/stderr-contents-sync_git_repositories.txt\": that second redirection should be \">>\", not \">\". .  So: .  Here I override a \"tmp\" file on each command (with their stdout/stderr), and if that command fails, I write to, or I append to \"/tmp/stderr-contents-sync_git_repositories.txt\". .  This is easier than your edit, where you redirect both commands to a file, even if one of them might have failed. .  That is why I do \"cmd1 || cat >> file\": the \">>\" part only runs if \"cmd1\" fails. .  ",
      "P-tags": "git stderr bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from S_ING to NP"
    },
    {
      "id": "ul_303312",
      "task": "something is restarting crond! How do I stop this?",
      "P-task": "someth restart crond\nstop",
      "F_verb": "restart",
      "P-body": "Your snippet does not show that anyone got into your system, only that there were attempts. This is, unfortunately, perfectly normal. Any machine visible on the internet with TCP/22 open will get numerous login attempts. You can reduce the chances of any of them being successful by .   not allowing root login. Use (or create) a normal user for connecting, and add (or modify) the line \"PermitRootLogin no\" in your \"sshd_config\". .  not using passwords. Setup publickey authentication for any system that is publicly visible, and disallow all password attempts with the configuration item \"PasswordAuthentication no\". .  specify which users (presumably only you) may login in with the \"AllowUsers\" directive (or, for a more complicated setup, an appropriate combination of \"DenyUsers\", \"AllowUsers\", \"DenyGroups\", and \"AllowGroups\"). .    As for cron, how you stop it will depend on which flavour of linux and which flavour of \"crond\" you are using. To disable the daemon (rather than individual users' crontabs), you might try something like .  or .  If it respawns after you have stopped it, check that \"/etc/inittab\" does not have a \"respawn\" entry for the daemon. .  ",
      "P-tags": "cron ssh",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP"
    },
    {
      "id": "ul_297944",
      "task": "Renaming using terminal and regexp to remove leading numbers from filenames",
      "P-task": "renam use termin regexp remov lead number filenam",
      "F_verb": "remove",
      "P-body": "I don't see why that error would occur. In fact, I am reasonably certain there were more lines to the error than you show; for one thing, there's no actual error message.  .  However, that regular expression won't actually match either of your example files. You are using \"[a-z]+\\.mp3\" which will only match lower case letters and, since you're matching all the way to the extension, it will only match files whose name consists of only lower case letters after the numbers and space you want to remove. You could instead match \"[a-zA-Z]\" or use \"s///i\" to make the match case insensitive, but it would be a better idea to not match the rest of the word at all. You just want to remove the digits and whitespace from the beginning, so just match those: .  ",
      "P-tags": "renam macintosh shell regular-express",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "au_1188381",
      "task": "How to get link of file to download with wget",
      "P-task": "get link file download wget",
      "F_verb": "get",
      "P-body": "You can find the link using the console. Open it with the right click -> examine element -> terminal (or console, don't know how it is in english), and just do like you had done in your gif. .  Here is your link : https://extensions.gnome.org/extension-data/user-themegnome-shell-extensions.gcampax.github.com.v38.shell-extension.zip .  and screenshot of Firefox terminal for this link : .   .  so your \"wget\" command would be : .  ",
      "P-tags": "wget",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP S_INF with NP"
    },
    {
      "id": "ul_93131",
      "task": "Pruning the package tree with apt-get and yum",
      "P-task": "prune packag tree apt-get yum",
      "F_verb": "prune",
      "P-body": "To show packages that were manually installed, use \"apt-mark showmanual\". To show packages that were automatically installed, use \"apt-mark showauto\".  .  Also, \"apt-get\" has \"autoremove\". From the man page .   autoremove .  autoremove is used to remove packages that were automatically installed to satisfy dependencies for other packages and are now no longer needed. .   So use \"apt-get autoremove\" for this. .  Generally \"apt\" will prompt you if packages are available to be autoremoved, so I would expect a user to become aware of this command quite quickly. .  Additionally, there are packages like \"debfoster\" and \"deborphan\" to help users to reduce package clutter. .  Also \"wajig\" has several commands that can be used to prune packages, including, but not limited to \"large\", and \"sizes\", which can be used to look at the large packages installed on the system. .  Also, it is worth mentioning the \"apt\" log files in \"/var/log/apt\", notably \"history.log\", which keep a log of the installations and removals performed by \"apt\". .  ",
      "P-tags": "depend apt package-manag yum",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_658522",
      "task": "Assign to associative array element indirectly",
      "P-task": "assign associ array element indirectli",
      "F_verb": "assign",
      "P-body": "You never declared \"foo\" as an associative array. Arrays and \"scalars\" (for want of a better word describing ordinary variables) never have to be declared, but associative arrays do. .  Since you did not declare \"foo\" as an associative array, your code sets \"foo[0]\" to \"baz\". It sets index zero because \"bar\" is being used in an arithmetic context (since it's an ordinary array assignment). Your \"bar\" variable, used as an index in an ordinary array, either has the value zero, or it is unset (does not exist). .  In short, there is nothing in the statement \"foo[bar]=baz\" that says \"foo\" is an associative array. By default, it would be an ordinary array and \"bar\" would be interpreted in an arithmetic context as some integer index (its value would be evaluated to zero if that variable did not exist). .  To get what you want, you will need to declare \"foo\" as an associative array. .  This would output .  ",
      "P-tags": "shell-script bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V to NP"
    },
    {
      "id": "so_5284246",
      "task": "Executing shell command and reading its output on a C program",
      "P-task": "execut shell command read output c program",
      "F_verb": "read",
      "P-body": "One bug in that code is that you assign to a variable \"pid\" that is not declared anywhere. And pid will always be 1 in the parent, because the code as written is equivalent to \"pid=(fork()==0)\" rather than \"(pid=fork())==0\". .  You should also close pfd[1] after the dup2 call. And for good measure, check for errors from dup2 and execlp. .  The answer to your real question is to use \"fdopen\". .  ",
      "P-tags": "linux c fork",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_436911",
      "task": "What is the 'Provided by' field of notification-daemon on Debian Stretch?",
      "P-task": "provid field notification-daemon debian stretch",
      "F_verb": "provide",
      "P-body": "Package A can provide package B even if B is not virtual. This is done when, for example, A provides equivalent functionality to B, but other packages depend on B. In this case \"cinnamon\", \"notify-osd\", etc. can be installed in place of \"notification-daemon\" to satisfy dependencies. .  ",
      "P-tags": "debian",
      "source": "qa",
      "cate": "provide/give/supply",
      "pat": "V NP of NP on NP"
    },
    {
      "id": "ul_624816",
      "task": "Find file(s) recursively and filter them by their path matching specific substring(s)",
      "P-task": "find file recurs filter path match specif substr",
      "F_verb": "find",
      "P-body": "Use the \"-path\" test with \"find\": .  The \"-path\" test works like \"-name\", but the pattern is tested against the complete pathname of whatever file \"find\" is currently considering. .  The way I'm using the test above will ensure that only files with the names \"someFile1.txt\" or \"someFile1.txt\" that are located somewhere beneath a directory called \"good\" is returned by \"find\". .  If the files are supposed to reside in the \"good\" directory, and not in a subdirctory beneath it, then use .  or something similar. .  Obviously, if you are looking for actual files called \"someFile1.txt\" and \"someFile2.txt\", you would be using the pattern \"someFile[12].txt\" rather than two separate tests. .  From comments, it's clear that you may want to use .  ",
      "P-tags": "find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_11947112",
      "task": "How to make git not ask for password at pull?",
      "P-task": "make git ask password pull",
      "F_verb": "make",
      "P-body": "There are a few options, depending on what your requirements are, in particular your security needs. For both HTTP and SSH, there is password-less, or password required access.  .  HTTP ============== .  Password-Less Useful for fetch only requirements, by default push is disabled. Perfect if anonymous cloning is the intention. You definitely shouldn't enable push for this type of configuration. The man page for git-http-backend contains good information, online copy at http://www.kernel.org/pub/software/scm/git/docs/git-http-backend.html. It provides an example of how to configure apache to provide this. .  User/password in .netrc or url embedded Where .netrc files are using in the form: .  And embedded urls would be in the form: .  Since git won't do auth for you, you will need to configure a webserver such as apache to perform the auth, before passing the request onto the git tools. Also keep in mind that using the embedded method is a security risk, even if you use https since it is part of the url being requested. .  If you want to be able to pull non-interactive, but prevent anonymous users from accessing the git repo, this should be a reasonably lightweight solution using apache for basic auth and preferably the .netrc file to store credentials. As a small gotcha, git will enable write access once authentication is being used, so either use anonymous http for read-only, or you'll need to perform some additional configuration if you want to prevent the non-interactive user from having write access. .  See: .   httpd.apache.org/docs/2.4/mod/mod_auth_basic.html for more on configuring basic auth www.kernel.org/pub/software/scm/git/docs/git-http-backend.html for some examples on the apache config needed.   SSH ============== .  Passphrase-Less Opens up for security issues, since anyone who can get a hold of the ssh private key can now update the remote git repo as this user. If you want to use this non-interactively, I'd recommend installing something like gitolite to make it a little easier to ensure that those with the ssh private key can only pull from the repo, and it requires a different ssh key pair to update the repo. .  See github.com/sitaramc/gitolite/ for more on gitolite. .  stromberg.dnsalias.org/~strombrg/ssh-keys.html - for creating password less ssh keys: May also want to cover managing multiple ssh keys: www.kelvinwong.ca/2011/03/30/multiple-ssh-private-keys-identityfile/ .  Passphase protected Can use ssh-agent to unlock on a per-session basis, only really useful for interactive fetching from git. Since you mention root and only talk about performing 'git pull', it sounds like your use case is non-interactive. This is something that might be better combined with gitolite (github.com/sitaramc/gitolite/). .  Summary ============== .  Using something like gitolite will abstract a lot of the configuration away for SSH type set ups, and is definitely recommended if you think you might have additional repositories or need to specify different levels of access. It's logging and auditing are also very useful. .  If you just want to be able to pull via http, the git-http-backend man page should contain enough information to configure apache to do the needful. .  You can always combine anonymous http(s) for clone/pull, with passphrase protected ssh access required for full access, in which case there is no need to set up gitolite, you'll just add the ssh public key to the ~/.ssh/authorized_keys file. .  ",
      "P-tags": "git linux",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF for NP"
    },
    {
      "id": "ul_268881",
      "task": "Cannot compile a linux kernel for an ARM board",
      "P-task": "compil linux kernel arm board",
      "F_verb": "compile",
      "P-body": "Finally it works, it seems that my kernel directory was not so clean, even after a \"make clean && make mrproper\".  .  After restarting from kernel sources extracted from the archive, i can do a \"make V=1\" without root privilege and there isn't any questions asked. And the directory \"/arch/arm/boot\" contains an image of the compressed kernel too (zImage). .  ",
      "P-tags": "kernel cross-compil linux-kernel x86 arm",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP for NP"
    },
    {
      "id": "so_44907775",
      "task": "How to create C# string object inside .ps1 file",
      "P-task": "creat c string object insid ps1 file",
      "F_verb": "create",
      "P-body": " produces .   Warning as Error: The variable 's' is declared but never used .   It will not allow you to declare unused variables. .  ",
      "P-tags": "powershel c powershell-4 0",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP inside NP"
    },
    {
      "id": "so_33770918",
      "task": "Is it possible to load multiple .dll's using powershell?",
      "P-task": "possibl load multipl dll use powershel",
      "F_verb": "load",
      "P-body": "I think you can load them all by doing the following, .  ",
      "P-tags": "powershel c",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP using NP"
    },
    {
      "id": "so_19807888",
      "task": "Cut the first and the last part of a string in bash",
      "P-task": "cut first last part string bash",
      "F_verb": "cut",
      "P-body": "when using \"bash\" you can use built-ins for this task: .  you might want to check the bash-manual (\"man bash\") for more information on this. search for Remove matching prefix pattern resp. Remove matching suffix pattern. .  ",
      "P-tags": "cut bash",
      "source": "qa",
      "cate": "cut/slash/separate/clip/crop",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_66268536",
      "task": "Why do I need to use dup for stdout redirection if the same can be achieved without it?",
      "P-task": "need use dup stdout redirect achiev without",
      "F_verb": "use",
      "P-body": "Both of these examples are buggy because they both rely on the same invalid assumption that closing 1 makes 1 the lowest available FD. .  You can trivially invalidate this assumption, causing the program to fail: .  The way to deal with this is to use \"dup2\" to explicitly pick the fd you want: .  ",
      "P-tags": "posix system-cal linux c operating-system",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP if S"
    },
    {
      "id": "so_40281490",
      "task": "How to connect to a linux server only support xterm terminal",
      "P-task": "connect linux server support xterm termin",
      "F_verb": "connect",
      "P-body": "According to this website, you'd need to set the \"TERM\" environment variable to 'xterm'. .  However, according to the paramiko documentation, you can tell \"invoke_shell\" to emulate a terminal type like so: .  ",
      "P-tags": "linux xterm paramiko python ssh",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V to NP"
    },
    {
      "id": "so_35352921",
      "task": "how to check if python script is being called remotely via ssh",
      "P-task": "check python script call remot via ssh",
      "F_verb": "check",
      "P-body": "You can tell if you're being invoked via SSH by checking your environment. If you're being invoked via an SSH connection, the environment variables \"SSH_CONNECTION\" and \"SSH_CLIENT\" will be set. You can test if they are set with, say: .  Another option, if you wanted to just stick with your original approach of \"sys.stdin.isatty()\", would be to to allocate a pseudo-tty for the SSH connection. Normally SSH does this by default if you just SSH in for an interactive session, but not if you supply a command. However, you can force it to do so when supplying a command by passing the \"-t\" flag: .  However, I would caution you against doing either of these. As you can see, trying to detect whether you should accept input from stdin based on whether it's a TTY can cause some surprising behavior. It could also cause frustration from users if they wanted a way to interactively provide input to your program when debugging something. .  The approach of adding an explicit \"-\" argument makes it a lot more explicit and less surprising which behavior you get. Some utilities also just use the lack of any file arguments to mean to read from stdin, so that would also be a less-surprising alternative. .  ",
      "P-tags": "linux python system ssh",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V if S"
    },
    {
      "id": "au_503796",
      "task": "How to make a portable Kubuntu on external drive (GPT) on UEFI computer?",
      "P-task": "make portabl kubuntu extern drive gpt uefi comput",
      "F_verb": "make",
      "P-body": "Your problem is that the EFI boot process stores data on the boot loader's location in NVRAM, so when you install on one computer and then move the disk to another computer, the second computer doesn't know where to look to find the boot loader. The usual way around this problem is to use the default/fallback boot loader filename, \"EFI/BOOT/bootx64.efi\", on the EFI System Partition (ESP; that's your FAT32 partition). The firmware looks for this filename on removable disks. The big caveat is that you may need to use the firmware's built-in boot manager to select that disk, and the details of how to access that boot manager vary from one computer to another. .  You can copy the boot loader to that location manually. The way that's most likely to work, from a working Ubuntu installation, is: .  Note that these commands will overwrite any existing \"EFI/BOOT/bootx64.efi\" boot loader. You probably don't have one on your external disk right now, but you might want to double-check this. Also, this assumes that the ESP on the external disk is mounted at \"/boot/efi\". You should definitely double-check that with \"df\" before you proceed. You don't want to overwrite the boot loader on your internal disk by accident! .  If you're sure that you'll be booting with Secure Boot disabled, you could copy \"EFI/ubuntu/grubx64.efi\" to \"EFI/BOOT/bootx64.efi\", but that won't work if the target computer has Secure Boot enabled. .  ",
      "P-tags": "dual-boot external-hdd boot uefi grub2",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP on NP on NP"
    },
    {
      "id": "so_42084298",
      "task": "Get columns header in Powershell from proc if returns 0 result",
      "P-task": "get column header powershel proc return 0 result",
      "F_verb": "get",
      "P-body": "UPDATE after OPs comment, where they want to export the header only to the csv, if the resultset is empty. .  ORIGINAL POST .  Nothing is returned because the \"DataTable\" is empty. The schema information is returned, though. Assuming you only have one table in your returned `DataSet', the PowerShell command below will show the columns returned within the metadata. .  ...or if you want a simple csv list of columns... .  Change [0] to another number, if your dataset returns more than one table. .  Is the consuming system or application expecting a resultset? .  ",
      "P-tags": "powershel sql-server",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "so_27956019",
      "task": "Cannot print a text with Gosu in Ruby",
      "P-task": "print text gosu rubi",
      "F_verb": "print",
      "P-body": "Use commas to separate function arguments, not dots: .  ",
      "P-tags": "rubi ubuntu libgosu syntax-error",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_26598218",
      "task": "Creating and Accessing Index Files in C++",
      "P-task": "creat access index file c++",
      "F_verb": "create",
      "P-body": "I will provide you with a possible naive draft for the first program, so that you can understand the general idea: .  Look at the example here if you don't know how to iterate within a \"std:map\". .  ",
      "P-tags": "file c++ linux index",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_585703",
      "task": "Foreman: ERF42-9666 [Foreman::Exception]: HTTP boot requires proxy with httpboot feature and http_port exposed setting",
      "P-task": "foreman : erf42-9666 foreman : :except : http boot requir proxi httpboot featur http_port expos set",
      "F_verb": "require",
      "P-body": "The solution is to enable http proxy: .  ",
      "P-tags": "foreman",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP with NP"
    },
    {
      "id": "so_37402289",
      "task": "Reading the output of a script in a particular way",
      "P-task": "read output script particular way",
      "F_verb": "read",
      "P-body": " This produces the output: .  The uses process substitution to feed the results of `` to the \"while\" loop. .  Aside: The command \"sortByDates < $(printf \"%s\\n\" \"${arr[@]}\")\" tells the shell to provide as input to \"sortByDates\" the contents of a file named \"$(printf \"%s\\n\" \"${arr[@]}\"\". That is note what you want.  .  Debugging Try running the script under \"bash -x\". Alternatively, try this script: .  For me, the above produces: .  ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_648474",
      "task": "How does mount know that it's a cifs mount without -t?",
      "P-task": "mount know cif mount without -t",
      "F_verb": "mount",
      "P-body": " Does \"mount\" assume cifs once it sees the double slashes(\"//\") or is there some other method? .   Yes, that's exactly how (lib)mount does it -- if source is not a block device it assumes it is a network location -- if it has \":\" it's NFS and with \"//\" it's assumed to be CIFS. You can check the mnt_context_guess_srcpath_fstype libmount function which is used when \"auto\" (or nothing) is specified as type. .  ",
      "P-tags": "mount cif",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP that S"
    },
    {
      "id": "ul_89538",
      "task": "How to tell which keyboard was used to press a key?",
      "P-task": "tell keyboard use press key",
      "F_verb": "tell",
      "P-body": "More digging revealed another solution using plain Bash and a normal user account. Script: .  ",
      "P-tags": "keyboard x11 xorg",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V which S"
    },
    {
      "id": "so_121318",
      "task": "Unix Script reading a specific line and position",
      "P-task": "unix script read specif line posit",
      "F_verb": "read",
      "P-body": " The \"sed\" command reads the first line of the file and the \"cut\" command chops out characters 27-34 of the one line, which is where you said the date is. .  Added later: .  For the more general case - where you need to read line 24, for example, instead of the first line, you need a slightly more complex \"sed\" command: .  The \"-n\" option means 'do not print lines by default'; the \"24p\" means print line 24; the \"24q\" means quit after processing line 24. You could leave that out, in which case \"sed\" would continue processing the input, effectively ignoring it. .  Finally, especially if you are going to validate the date, you might want to use Perl for the whole job (or Python, or Ruby, or Tcl, or any scripting language of your choice).  .  ",
      "P-tags": "unix",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_36909480",
      "task": "How to add a specific text to columns in a text file in Linux?",
      "P-task": "add specif text column text file linux",
      "F_verb": "add",
      "P-body": " ",
      "P-tags": "linux",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP in NP"
    },
    {
      "id": "so_42945675",
      "task": "Unix/bash/Shell: How to Find Files from a List and Merge Them into One File",
      "P-task": "unix bash shell : find file list merg one file",
      "F_verb": "find",
      "P-body": "You can use globbing to concatenate multiple files matching each line in \"list_NRPs.txt\" file: .  ",
      "P-tags": "unix shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP from NP into NP"
    },
    {
      "id": "au_1318387",
      "task": "I want to enable a beep sound on my laptop for my charger",
      "P-task": "want enabl beep sound laptop charger",
      "F_verb": "enable",
      "P-body": "Assuming you're running Ubuntu Desktop 20.04, it should beep when power is connected or disconnected. If it doesn't, then there are a few things you'll need to check: .  1 \u2014 Sound Settings .   Open \"Settings\" and click on the Sounds tab. Confirm that \"System Sounds\" is not muted and is loud enough to be heard   .  If everything there is correct, then ... .  2 \u2014 Gnome Power Panel .   Open \"dconf Editor\" and navigate to: org / gnome / desktop / notifications / application / gnome-power-panel Confirm that \"enabled\" is enabled Confirm that \"enable-sound-alerts\" is enabled   .  If you do not have dconf Editor on your system, you can install it like this: .  Hopefully this will help you get the audio confirmation for when power is connected and disconnected  .  ",
      "P-tags": "charg power-manag batteri sound",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP for NP"
    },
    {
      "id": "au_98180",
      "task": "Nautilus can't see files on a NTFS partitions, but 'ls' command shows them?",
      "P-task": "nautilu see file ntf partit ls command show",
      "F_verb": "see",
      "P-body": "When I've had this problem it turned out to be a permissions issue. Assuming your username on your system is satuon, you can change ownership of the files to your user with \"chown -R satuon /windows/Users/myuser/Desktop\" .  You may need to use sudo (\"sudo chown -R satuon /windows/Users/myuser/Desktop\") -- as with any command I'd encourage you to read \"man chown\" to understand what it does before you run it, especially as root. .  ",
      "P-tags": "nautilu ntf",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP on NP"
    },
    {
      "id": "so_58803542",
      "task": "Editing/Accessing Powershell objects using variables with dot notation",
      "P-task": "edit access powershel object use variabl dot notat",
      "F_verb": "edit",
      "P-body": "What you're trying to do there is not possible in PowerShell unless you use \"Invoke-Expression\" (which is strongly discouraged). .  What you could do is use a recursive function, e.g. like this: .  Note that this is just a very basic draft with no error handling whatsoever. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP using NP with NP"
    },
    {
      "id": "ul_63573",
      "task": "How is the path to search for 'man' pages set?",
      "P-task": "path search man page set",
      "F_verb": "search",
      "P-body": "The path for man is determined either by the env variable MANPATH or by constructing a MANPATH from PATH and /etc/manpath.config .  The reason your local git man pages are being picked up first is because the MANPATH generated is in the same order present in PATH, so your \"/usr/local/git/bin\" at the beginning of PATH means that manpath will (if it can find it) place the matching man path at the beginning of MANPATH (in this case, \"/usr/local/git/share/man\"). .  Paths that are earlier in your MANPATH are searched first and man(1) will display the first match. .  For more information on this see manpath(1) and for the configuration file see manpath(5) .  ",
      "P-tags": "man path",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V for NP"
    },
    {
      "id": "au_189811",
      "task": "Required plugin could not be found",
      "P-task": "requir plugin could found",
      "F_verb": "find",
      "P-body": "It seems the video is using GoToMeeting codec which is not supported on Linux. I searched the Internet and found this forum thread. .  There was a link to this page which was provided to be helpful. I read it, as far as I understand, you need to have Wine, mplayer, w32codecs and gotomeeting codec to play it via Wine .  I'm quoting the text below: .   If you want to watch a GoToMeeting video on Linux (g2m3 codec) You'll need to install mplayer, win32 codecs, wine, the gotomeeting codec (copy the G2M.dll codec to /usr/lib/codecs). Then run the video with WMV. You also might want to see this post on downloading the g2m3 codec. .   Apparently, The process is as follows: .   Install Wine with \"sudo apt-get install wine\" .   Install mplayer with \"sudo apt-get install mplayer\". You may want to install a front-end for mplayer. Try smplayer with \"sudo apt-get install smplayer\" .   Enable the medibuntu repository by going to this help page. .   After adding it, install w32codecs with \"sudo apt-get install w32codecs\". .   Then Download the free gotoMeeting codec from here. Install the downloaded .exe file with Wine. .   After installation, try to play the file using smplayer or mplayer. .  Don't forget to copy the \"G2M.dll\" file which is installed via Wine into \"/usr/lib/codecs\" directory. Most probably, you will find that file under \".wine\" directory which is hidden in your home directory. You can search for that file using nautilus search feature. .    For further info, you may want to visit these links: .   http://onlinemeeting.lefora.com/2009/12/08/guide-to-using-gotomeeting-on-linux/ http://onlinemeeting.lefora.com/2009/12/08/g2m3-codec-download/#post0 http://ubuntuforums.org/showthread.php?t=1806787 And another interesting thread on Ubuntu forum  Hope this answer will help. .  ",
      "P-tags": "codec 12 04 video",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "au_126660",
      "task": "Screen messed up when resumes from suspend",
      "P-task": "screen mess resum suspend",
      "F_verb": "resume",
      "P-body": "Suggested steps to get back to a working desktop when you have graphics issues regardless of driver.  .  The steps I usually try are first CtlAltF1 followed by CtlAltF7. In some cases this will get it working.  .  After that, if you're using unity-3d(the default) try \"unity --replace &\" in a terminal. Basically that means launch a new unity to replace the old one.  .  ",
      "P-tags": "12 04 nvidia uniti",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V from NP"
    },
    {
      "id": "so_40141415",
      "task": "Compiling project in Linux terminal doesn't work",
      "P-task": "compil project linux termin work",
      "F_verb": "compile",
      "P-body": "The working script has: .  And the other version has: .  So \"SharedTable.c\" must be in the \"bin\" directory, and the \"gcc\" command can't find it because it's no longer in the current directory. Try using a relative path instead: .  ",
      "P-tags": "linux java-native-interfac c java",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V NP in NP"
    },
    {
      "id": "so_31272586",
      "task": "combine two files -- one after another",
      "P-task": "combin two file -- one anoth",
      "F_verb": "combine",
      "P-body": "Normally I would use \"cat file1 file2\", but you could do it like: .  or  .  (Note: the \"'1'\" does the the same thing as \"print\") .  ",
      "P-tags": "awk unix",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP after NP"
    },
    {
      "id": "so_29119173",
      "task": "Compare two files and get only the differences - shell script",
      "P-task": "compar two file get differ - shell script",
      "F_verb": "compare",
      "P-body": "\"grep\" can read patterns from a file using the option \"-f\": .  \"-F\" tells \"grep\" that patterns aren't regex patterns - they are fixed length pattern. \"-v\" negates the match. .  ",
      "P-tags": "diff linux grep",
      "source": "qa",
      "cate": "compare",
      "pat": "V NP"
    },
    {
      "id": "so_8021874",
      "task": "How can I compile to assembly with gcc",
      "P-task": "compil assembl gcc",
      "F_verb": "compile",
      "P-body": "I suggest also using \"-fverbose-asm\" because then the generated assembler has some generated comments which \"explains\" the code. For example: .  would generate in \"foo.s\" (with some comments) the assembler code produced by compiling \"foo.c\"  .  And to understand what the GCC optimizations are doing one could even try \"-fdump-tree-all\" (but this produces hundreds of files!). .  ",
      "P-tags": "linux c gcc x86",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V to NP with NP"
    },
    {
      "id": "so_53283107",
      "task": "Bash script to run command when remote server is available",
      "P-task": "bash script run command remot server avail",
      "F_verb": "run",
      "P-body": "Try something like this: .  $? contains the return value of the last executed command (ping in this case). When ping return 0, it means no errors, so it will execute my-command.sh .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP when S"
    },
    {
      "id": "ul_14728",
      "task": "ls: how do I list directories sorted by timestamps of the files it contains",
      "P-task": "ls : list directori sort timestamp file contain",
      "F_verb": "contain",
      "P-body": "There are a couple of options that you can combine. .  The \"-c\" switch sorts by time modified [1]: .  -c with -lt: sort by, and show, ctime (time of last modification of file status information) with -l: show ctime and sort by name otherwise: sort by ctime The \"-u\" and \"-t\" switches can also be used: .  -t sort by modification time -u with -lt: sort by, and show, access time with -l: show access time and sort by name otherwise: sort by access time You could put it all together like so [2]: .  [1] http://unixhelp.ed.ac.uk/CGI/man-cgi?ls .  [2] \"-r\" reverses the order  .  ",
      "P-tags": "ls",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V"
    },
    {
      "id": "su_1301232",
      "task": "specific systemctl service is stopped after daily apt upgrades and clean activities",
      "P-task": "specif systemctl servic stop daili apt upgrad clean activ",
      "F_verb": "stop",
      "P-body": "You probably want to to use \"Wants=\" with your PostgreSQL service dependency instead of \"Requires=\".  .  With \"Wants=\", your app won't be stopped just because PostgreSQL was stop/started for a software upgrade. .  Read about the distinction more in \"man systemd.unit\". .  ",
      "P-tags": "acpi apt ubuntu systemd cron",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V after NP"
    },
    {
      "id": "so_66825845",
      "task": "Linux bash script: How to put command line into variable?",
      "P-task": "linux bash script : put command line variabl",
      "F_verb": "put",
      "P-body": "Yes, you can use arrays to build up commands with arbitrary arguments, for example: .  Also, Use More Quotes\u2122! .  ",
      "P-tags": "linux bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_39724735",
      "task": "Jmeter: Is it possible to run a particular thread group after all the other thread group gets completed",
      "P-task": "jmeter : possibl run particular thread group thread group get complet",
      "F_verb": "run",
      "P-body": "I can suggest 2 options: .   Use Inter-Thread Communication Plugin. See example test plan for details. If for some reason you are not in position to use JMeter Plugins you can achieve the same using JMeter Properties like: .   When Thread Group A finishes set a JMeter Property, i.e. \"ThreadGroupADone=true\" using __setProperty() function like  .   In Thread Group D: .   Add While Controller at the beginning of the Thread Group and use the following condition: .   Add Test Action sampler as a child of the While Controller and configure it to pause for a reasonable amount of seconds, i.e. 5 so each 5 seconds While Controller will check \"ThreadGroupADone\" property value and if it is still \"false\" - sleep for another 5 seconds. When property value will become \"true\" - Thread Group D will proceed.     ",
      "P-tags": "load-test performance-test beanshel blazemet jmeter",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP after S"
    },
    {
      "id": "so_35243565",
      "task": "How to generate random numbers between 0 and 1 in bash",
      "P-task": "gener random number 0 1 bash",
      "F_verb": "generate",
      "P-body": "As far as I can remember ${RANDOM} generates integers in the interval 0 - 32767. So, I guess, you might want to try something like this to generate random values in [0,1]: .  ",
      "P-tags": "random shell bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP between NP in NP"
    },
    {
      "id": "au_22952",
      "task": "How do I run VirtualBox on 2.6.38?",
      "P-task": "run virtualbox 2 6 38",
      "F_verb": "run",
      "P-body": "The new Kernel has moved \"linux/autoconf.h\" to \"generated/autoconf.h\" (hint). I don't really know the technical reasoning for this but anything that includes this in the VirtualBox host module source, needs editing. .  Thankfully fixing it is just a case of swapping out the strings: .  Of course this change might not be permanent in the Linux Kernel. Things could go back and that would squiffy your ability to compile in the future so if you need to do the opposite in the future, here it is: .  ",
      "P-tags": "virtualbox",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "so_56535075",
      "task": "How to fix count that doesn't work in while loop",
      "P-task": "fix count work loop",
      "F_verb": "fix",
      "P-body": "For conditional expression you need to use \"[[ expression ]]\", e.g. this will loop four times: .  To fetch the count from the command-line argument, you could replace the assignment \"count=4\" above with the following, parsing the command-line arguments: .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP that S"
    },
    {
      "id": "su_591407",
      "task": "starting network interface in debug mode",
      "P-task": "start network interfac debug mode",
      "F_verb": "start",
      "P-body": "A network interface cannot be \"started in debug mode\", however, if you want to inspect the network traffic specifically for one interface, the simplest and most commonly used solution is to use \"tcpdump(8)\". One example would be: .  Check the manpage for further options. .  ",
      "P-tags": "redhat-enterprise-linux debug network",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP in NP"
    },
    {
      "id": "au_141040",
      "task": "Xfce, Thunar: How to get file path in title bar?",
      "P-task": "xfce thunar : get file path titl bar",
      "F_verb": "get",
      "P-body": "The workaround is compiling Thunar yourself with this patch from the bug report. Since the patch is old, it may not apply automatically (with \"patch\")...sorry. .  ",
      "P-tags": "xfce",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_5078",
      "task": "Why is 'libgnomevfs' files under /usr/include/gnome-vfs-2.0?",
      "P-task": "libgnomevf file usr includ gnome-vfs-2 0",
      "F_verb": "include",
      "P-body": "The package is installed in \"/usr/include/gnome-vfs-2.0\" so that it can coexist with other versions of gnome-vfs (e.g. imagine also having \"/usr/include/gnome-vfs-1.0\" available). When a package needs to build against a version of gnome-vfs, it should query \"pkg-config\" to find the installation location. This is normally done during \"configure\" for the to-be-compiled software.) For example: .  Note the use of all the \"-I\" flags, including \"-I/usr/include/gnome-vfs-2.0\". The output of the \"pkg-config --cflags\" call would normally be added to the \"CFLAGS\" environment variable of the build. Given the \"-I\" part, the compiler will be able to find the full path to the headers, since it will start looking in \"/usr/include/gnome-vfs-2.0\" and then tack on the header path \"libgnomevfs/gnome-vfs-acl.h\", which will resolve the correct full file path: \"/usr/include/gnome-vfs-2.0/libgnomevfs/gnome-vfs-acl.h\". .  So, if the software does not already use \"pkg-config\", you can try to pass the variables (\"cflags\" and \"libs\") into the \"configure\" call: .  ",
      "P-tags": "path compil gnomevf",
      "source": "qa",
      "cate": "import/include",
      "pat": "V"
    },
    {
      "id": "au_196268",
      "task": "Migrate from Thunderbird to Mutt",
      "P-task": "migrat thunderbird mutt",
      "F_verb": "migrate",
      "P-body": "It is definitely possible to do all the things you want to do with \"Mutt\", and much more.  .  Multiple accounts are possible with \"Mutt\". Personally I have only used multiple gmail imap accounts, as described in this article here, but it is feasible to set them up and move between them. It is not necessary to repeat the information here, but it has a lot to do with how the 'account hooks' and 'folder hooks' are set up; the article explains it well. .  However, you can achieve it without \"folder-hooks\": see my answer here: .   How to manage multiple imap accounts with mutt  To navigate between folders, you can use macros, as these well known ones demonstrate:  .  More on how to move between folders and how messages can be moved across folders is explained here in great detail. .  Indeed, messages can be exported from \"Thunderbird\" in the \"mbox\" format and then read in \"Mutt\", as the Mutt wiki notes here. It will be necessary to install the \"Thunderbird\" import/export addon and then export the folders from Thunderbird in \"mbox\" format and then specify the folder in the \".muttrc\", by refering to these notes. .  Referring to your question in the comments: When you load up your inbox or when you switch between folders \"Mutt\" by default only loads the headers from the server, which I think is what you want. It only downloads the actual message when you click return to view the message. Hence, why we cache headers and messages for performance, and usually most people have standard entries like this in the \".muttrc\": .  For offline availability, you may need to pair \"Mutt\" with another program called \"offlineimap\", which is available in the repositories; a discussion is available here and here. .  I've put these hints together (from the wiki and my own personal rc) into a rough \"muttrc\" but you may have to test and modify it for your own purposes, and obviously add your own details, but it should be a useful starting point. .  ",
      "P-tags": "mutt thunderbird",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V from NP to NP"
    },
    {
      "id": "so_45403002",
      "task": "Installed libwnck-3-dev but still getting error about mising libwnck.h",
      "P-task": "instal libwnck-3-dev still get error mise libwnck h",
      "F_verb": "get",
      "P-body": "In my case I had to add \"${WNCK_CFLAGS}\" to \"add_definitions()\" and \"${WNCK_LIBRARIES}\" to \"link_libraries()\". .  ",
      "P-tags": "wnck linux vala cmake",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP about NP"
    },
    {
      "id": "au_553951",
      "task": "How to I check whether my installer is corrupt?",
      "P-task": "check whether instal corrupt",
      "F_verb": "check",
      "P-body": "You can only check the ISO itself, not the USB drive...  .  To check the validity of the downloaded ISO file: .  and then check the weird number in the front (the checksum) with the one you have to find on the web site you downloaded the file from. .  Use \"sha1sum\" if the web site provides these checksums. .  In your case, I suspect a problem on the USB (but that's just a hunch) Try .  to completely wipe it before formatting. .  ",
      "P-tags": "14 04 server system-instal",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V whether S"
    },
    {
      "id": "so_1098786",
      "task": "Run bash script from Windows PowerShell",
      "P-task": "run bash script window powershel",
      "F_verb": "run",
      "P-body": "You should put the script as argument for a *NIX shell you run, equivalent to the *NIXish .  ",
      "P-tags": "powershel bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP from NP"
    },
    {
      "id": "ul_340561",
      "task": "U-boot could not find a valid device tree",
      "P-task": "u-boot could find valid devic tree",
      "F_verb": "find",
      "P-body": "User error. .  I found that SAM-BA also has a verification method: .  Not good. It turns out that step 5 was missing a very essential step: first you need to erase the flash memory before writing it (I had no idea; I apparently have always used tools that took care of this for me): .  ",
      "P-tags": "u-boot arm device-tre",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_116606",
      "task": "How to enable someone to SSH to my server from Windows?",
      "P-task": "enabl someon ssh server window",
      "F_verb": "enable",
      "P-body": "(2) You may configure \"sshd\" to \"chroot()\" for this user. See \"man 5 sshd_config\", search for \"ChrootDirectory\" and \"ForceCommand\". .  (3) You must create a key pair. The public key is used on the server, the private key is used by the client. See \"ssh-keygen\". You may need \"ssh-keygen -e ...\" for converting the key so that it is usable by \"putty\" but maybe \"putty\" can do this conversion itself meanwhile. .  (4) This is basically adding a line to a text file: .  (5) Your user will have to download the Windows SSH program \"putty\" and configure it to use the private key you supplied. .  ",
      "P-tags": "ssh configur command-lin user",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP to NP of NP to NP"
    },
    {
      "id": "so_23187800",
      "task": "Not able to create a directory in linux",
      "P-task": "abl creat directori linux",
      "F_verb": "create",
      "P-body": "When you chmod a directories you dont change children directories. So, the command: .  will not change permissoins in: .  To do chmod recursively you need to use the -R flag .  It may not be a good idea to give all permissions to everybody in that directory, but it will acomplish what you tried to do. .  ",
      "P-tags": "linux ubuntu",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "so_25853098",
      "task": "How to copy a file located in different remote directories to a single local directory",
      "P-task": "copi file locat differ remot directori singl local directori",
      "F_verb": "copy",
      "P-body": "With \"rsync\" you can copy recursively only including the file you want: .  If you want to include \"a\" from any level below \"source*\" you can use double asterisks: .  ",
      "P-tags": "termin command-lin copi shell bash",
      "source": "qa",
      "cate": "copy/clone/paste/duplicate/burn",
      "pat": "V NP in NP to NP"
    },
    {
      "id": "so_48750382",
      "task": "Can not receive all the SIGCHLD",
      "P-task": "receiv sigchld",
      "F_verb": "receive",
      "P-body": "\"SIGCHLD\" is a standard signal, which means multiple occurrences of it get collapsed into one. Linux kernel maintains a bitset for standard signals, one bit per signal and supports queuing exactly one associated \"siginfo_t\". .  Fix: .  Also note, that you do not need to explicitly block the signal you handle because it is automatically blocked for you, unless \"SA_NODEFER\" flag is used. .  And, pedantically, only a limited number of async-signal safe functions (see \"man signal-safety\") can be used in a signal handler, \"printf\" is not one of those. .  ",
      "P-tags": "linux c operating-system unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_11229978",
      "task": "retrieve R output in PHP",
      "P-task": "retriev r output php",
      "F_verb": "retrieve",
      "P-body": "Found it, the answer is through Rscript. Rscript should be included in the latest install of R. .  Using my code as an example, I would enter this at the very top of r_script.R .  This should be the path to your Rscript executable. This can be found easily by typing  .  in the terminal. Where I have --options-you-need, place the options you would normally have when doing the CMD BATCH, such as --slave to remove extraneous output.  .  You should now be able to run your script like so: .  Important! If you get the error .  You need to include the \"methods\" package, like so: .  ",
      "P-tags": "php r consol stdout shell",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_438937",
      "task": "Sed to merge lines that are delimited with a token",
      "P-task": "sed merg line delimit token",
      "F_verb": "merge",
      "P-body": " If the blanks should be deleted: .  (if you want a single space to remain between the lines, replace \"//\" in the code by \"/ /\") .  If lines can be continued multiple times, as in .  then, .  This last \"sed\" script explained with annotations: .  ",
      "P-tags": "sed",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V NP that S"
    },
    {
      "id": "ul_581029",
      "task": "How do you grep two hyhpens only?",
      "P-task": "grep two hyhpen",
      "F_verb": "grep",
      "P-body": "At least if you have GNU grep, you could use PCRE lookarounds to match a pair of hyphens that are neither preceded nor followed by a hyphen: .  or .  ",
      "P-tags": "grep regular-express",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S"
    },
    {
      "id": "ul_179650",
      "task": "sh test two conditions gets [: missing `]'",
      "P-task": "sh test two condit get : miss",
      "F_verb": "get",
      "P-body": "Are you sure the error is for the first line? The last test is missing a space. Change .  to .  Also, since you are talking about sh, which may not be necessarily bash, you may change the first line to keep using \"[\" instead of \"[[\", which may not work on some shells: .  ",
      "P-tags": "shell-script bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_452028",
      "task": "Shell: Check line format file and loop over file lines",
      "P-task": "shell : check line format file loop file line",
      "F_verb": "check",
      "P-body": "With bash: .  outputs .  ",
      "P-tags": "shell-script text-process",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP over NP"
    },
    {
      "id": "su_737363",
      "task": "Send test message from one linux machine to another via command-line",
      "P-task": "send test messag one linux machin anoth via command-lin",
      "F_verb": "send",
      "P-body": "first, on the recieving host run: .  to make sure you have a process running on that port. .  then from the sending system, connect via telnet: .  a text prompt should appear. if you are able to connect via telnet, then the port is accessible.  .  you can type the text of your command in there. what you type will depend on the kind of service running on port 3000 of the other box. if you enter the text correctly, telnet will display the remote systems response to your input. .  ",
      "P-tags": "linux command-lin",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_12069809",
      "task": "Extract modified and added lines from two csv files using shell or diff command",
      "P-task": "extract modifi ad line two csv file use shell diff command",
      "F_verb": "add",
      "P-body": " ",
      "P-tags": "diff linux shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP from NP using NP"
    },
    {
      "id": "so_45623314",
      "task": "How to save a \"browser-initiated download\" file with Powershell System.Net.WebClient and custom user-agent string?",
      "P-task": "save browser-initi download file powershel system net webclient custom user-ag string",
      "F_verb": "save",
      "P-body": "The URL you are supplying is the HTTP page so that is why you are downloading that page and not the exe. To work around this you'll have to get a direct link to the file you want to download, usually the page handles this for you but the C# webclient isn't coded to do that. .  In this case you can get a directdownload link by: .   Click the \"Click here\" link the in \"If your download does not start after 30 seconds, Click here\" Copy the \"Click here\" download link to the product you wish to download, in this case \"https://download.microsoft.com/download/2/E/6/2E61CFA4-993B-4DD4-91DA-3737CD5CD6E3/vcredist_arm.exe\" Use that in place of \"https://www.microsoft.com/en- us/download/confirmation.aspx?id=40784\" for the webclient object.  ",
      "P-tags": "amazon-ec2 powershel amazon-web-servic script",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP with NP"
    },
    {
      "id": "so_36463615",
      "task": "Bash AWK, get first and second output (int)",
      "P-task": "bash awk get first second output int",
      "F_verb": "get",
      "P-body": "You can use a bash array: .  This puts the output of \"awk -F: '{print $2}' \"$file\"\" into the array \"$gameswon\" .  ",
      "P-tags": "awk shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "ul_500314",
      "task": "How do I add the bin subdirectory of the first directory in GOPATH to PATH?",
      "P-task": "add bin subdirectori first directori gopath path",
      "F_verb": "add",
      "P-body": "You can use: .  Or  .  Both will work because there can be at most one \":\". .  It will remove the part after \":\". So, in your first case, it will remove the second directory and in your second case, there will be no pattern like \":*\", so there will be no change in the directory name. .  ",
      "P-tags": "linux shell bash",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP of NP to NP"
    },
    {
      "id": "au_1219043",
      "task": "Can kernel modules/configurations fix the Intel 9560 Wi-Fi problem?",
      "P-task": "kernel modul configur fix intel 9560 wi-fi problem",
      "F_verb": "fix",
      "P-body": "While booted into -18, please do: .  If the latter is not installed so not removed, that's fine; just proceed. .  Reboot into -42 and show us: .  EDIT: Please also do: .   Failed to run INIT ucode: -110  .   Please be certain that you have the latest firmware: .  Next, please undertake the steps here: Dell Vostro 5490 no WIFI in Ubuntu 18.04 .  ",
      "P-tags": "iwlwifi kernel intel wireless",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_18344847",
      "task": "Checking/ moving files based on regex",
      "P-task": "check move file base regex",
      "F_verb": "move",
      "P-body": "The curly brackets are part of extended regular extension (ERE) syntax, not basic regular expression (BRE) syntax so we need to use \"egrep\". I also took the liberty of removing the brackets from your regex as I see that you are looking for files ending in \".EIP\" so this leaves us with: .  We will also need to change the \"$IFS\" variable, as it's used by the FOR loop to determine the field separator. By default the field separator is set to the space character, which does not work great for strings where the field separator can be part of the string(i.e. if the filenames contain spaces). We store the current value of IFS to a variable and we set the IFS: .  When we are done we are going to restore the IFS to its original value: .  Now we will pipe the filename to egrep and filter using our regex while redirecting both \"stdout\" and \"stderr\" to \"/dev/null\". The \"$?\" variable will let us know if our egrep returned a match. .  Here is how the complete script looks like (tested on mountain lion): .  Note you can check for compliance to N naming conventions by using multiple blocks of \"if\" statements and only one \"else\" condition at the very end as shown below: .  Note the use of \"continue\" as it resumes the iteration of the \"for\" loop, allowing for only a single action to be taken per file (think of filenames compliant to more than 1 naming convention) .  ",
      "P-tags": "osx-mountain-lion shell regex",
      "source": "qa",
      "cate": "move/scroll/offset/advance",
      "pat": "V NP on NP"
    },
    {
      "id": "so_26084582",
      "task": "Using find command in Bash script and excluding the subdirs",
      "P-task": "use find command bash script exclud subdir",
      "F_verb": "find",
      "P-body": "\"find -maxdepth 1 -name \"you_name\" -a type d\" .  ",
      "P-tags": "unix linux shell bash gnu-findutil",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "au_1359824",
      "task": "Snap applications - cannot create user data directory (home bind mounted)",
      "P-task": "snap applic - creat user data directori home bind mount",
      "F_verb": "create",
      "P-body": "You should not be using a file system that does not support linux symbolic links as your home directory. .  Your mounted drive where your home directory is, is formatted in the \"extfat\" file system. This is a rather simple file system mainly designed to be used on removable media. It does not support Linux links, nor Linux file permissions. Snap relies on symlinks and therefore cannot work on such a file system. .  Make sure your home folder is on a file system that supports symlinks and file system permissions. You still can keep the user files (document files, images, ...) on other media, and symlink - or mount bind - these to folders under your home directory. .  ",
      "P-tags": "symbolic-link snap permiss 20 04",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "so_24399907",
      "task": "Enable multiple webroot for apache2 on Ubuntu",
      "P-task": "enabl multipl webroot apache2 ubuntu",
      "F_verb": "enable",
      "P-body": "You can accomplish this easily with an alias directive. In \"/etc/apache2/sites-available/default\" just add an \"Alias\" for the URL. .  Now the contents of \"/home/paul/public_html\" should be available at www.example.com/paul .  ",
      "P-tags": "web-host ubuntu digital-ocean apach",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP for NP on NP"
    },
    {
      "id": "au_100698",
      "task": "Restrict access from another user to the NTFS partition",
      "P-task": "restrict access anoth user ntf partit",
      "F_verb": "restrict",
      "P-body": "Create a group called ntfs. Then edit the group to add all of the users that you want to be able to access the ntfs partition. .  Then .   To add a new user to a existing group you would do this: .   For More Detail plz have look .  https://help.ubuntu.com/community/AddUsersHowto .  http://ubuntuforums.org/showthread.php?t=1100120 .  ",
      "P-tags": "account ntf user",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from NP to NP"
    },
    {
      "id": "so_28517164",
      "task": "Oculus DK2 installation on Ubuntu 14.04 - cannot find ludev",
      "P-task": "oculu dk2 instal ubuntu 14 04 - find ludev",
      "F_verb": "find",
      "P-body": "You need to install the \"libudev\"and \"libudev-dev\" packages. .  ",
      "P-tags": "oculu linux ubuntu",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "ul_198003",
      "task": "Set default kernel in GRUB",
      "P-task": "set default kernel grub",
      "F_verb": "set",
      "P-body": "I think most distributions have moved additional kernels into the advanced options sub menu at this point, as TomTom found was the case with his Arch. .  I didn't want to alter my top level menu structure in order to select a previous kernel as the default. I found the answer here: .  http://www.humans-enabled.com/2014/08/how-to-set-default-grub-kernel-boot.html .  To summarize: .  1) Find the \"$menuentry_id_option\" for the submenu: .  2) Find the \"$menuentry_id_option\" for the menu entry for the kernel you want to use: .  3) Comment out your current default grub in \"/etc/default/grub\" and replace it with the sub-menu's \"$menuentry_id_option\" from step one, and the selected kernel's \"$menuentry_id_option\" from step two separated by \">\". .  In my case the modified \"GRUB_DEFAULT\" is: .  4) Update grub to make the changes. For Debian this is done like so: .  Done. Now when you boot, the advanced menu should have an asterisk and you should boot into the selected kernel. You can confirm this with \"uname\". .  Changing this back to the most recent kernel is as simple as commenting out the new line and uncommenting \"#GRUB_DEFAULT=0\": .  then rerunning \"update-grub\". .  ",
      "P-tags": "kernel linux boot grub",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP"
    },
    {
      "id": "so_47925653",
      "task": "Perl script does not output STDOUT to file when run from cron",
      "P-task": "perl script output stdout file run cron",
      "F_verb": "run",
      "P-body": "Reassigning \"*STDOUT\" is only affecting the Perl-internal \"STDOUT\" scalar's binding. The proper way to redirect standard output on the system level is something like .  You should similarly report errors from your other system calls which could fail (and \"use strict\" and etc). .  \"cron\" runs your job in your home directory, so if the path \"$HOME/log\" does not exist, the script will fail to open the log file handle (silently, because you are not logging \"open\" errors!) .  ",
      "P-tags": "cron linux perl stdout",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V from NP"
    },
    {
      "id": "au_303732",
      "task": "How to find out how many hours a drive has been used?",
      "P-task": "find mani hour drive use",
      "F_verb": "find",
      "P-body": "\"smartctl -A <device>\" as root from the command line will show you SMART parameter 9, \"Power_On_Hours\", if the drive supports it. .  ",
      "P-tags": "hard-driv smart",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V out S"
    },
    {
      "id": "su_1447873",
      "task": "What is starting this disabled service at boot? (Linux)",
      "P-task": "start disabl servic boot\nlinux",
      "F_verb": "start",
      "P-body": "In general, another service that has a \"Requires=yourservice\" might cause it to start even if it's disabled. .  Look for your service in the list generated by: .   systemctl list-dependencies .   If you find that bluetooth is linked to another service you can edit using: .   systemctl edit --full evilbluetoothstarting.service .  \"After=bluetooth.service\" .   That should create a seperate file that survives upgrades. .  Now as for disabling bluetooth, you might just need to change a parameter after disabling the service: .   vim /etc/bluetooth/main.conf .  \"AutoEnable=true\" .  => .  \"AutoEnable=false\" .   ",
      "P-tags": "bluetooth boot linux servic",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP at NP"
    },
    {
      "id": "ul_452689",
      "task": "Unable to mount 571 GB Volume",
      "P-task": "unabl mount 571 gb volum",
      "F_verb": "mount",
      "P-body": "How to mount NTFS drive on linux, and reset the dirty bit. .  Lets do this correctly. It is easy to inadvertently destroy the wrong data. .  1: Identify the HD partition. .  \"sudo fdisk -l\" .  You must be able to pick the drive and partition in question from the info supplied. .  Something like this: .  On my system \"/dev/sda5\" is the partition with the dirty bit set. .  Yours may be \"/dev/sda4\".  .  Note: .  The X in \"/dev/sdXn\" is the letter assigned to the physical hard-drive. .  The n in \"/dev/sdXn\" is the number assigned to the partition. .  The letters \"C:\" and \"D:\" are Microsoft assignments, and do not help here. .  Please be sure you are working on the correct drive and partition. .  Post the output of \"sudo fdisk -l\" for help identifying your disk / partition. .  2: Verify the partition is NOT mounted. .  \"mount | grep /dev/sda5\" .  If you get some output similar to this: .  The partition is mounted. .  Unmount with: .  \"sudo umount /dev/sda5\" .  Note: .  Yes you can unmount using the \"device file\" \"/dev/sda5\" OR the \"mount point\" \"/mnt/sda5\". .  3: Reset the dirty bit. .  Always check what will be done to your data before you modify the data. .  \"sudo ntfsfix --no-action /dev/sda5\" .  If you are content that everything looks okay, modify your data. .  \"sudo ntfsfix --clear-dirty /dev/sda5\" .  4: Mount the partition.  .  \"sudo mount /dev/sda5 /mnt/myData\" .  Note: .  The defaults that mount uses when a NTFS file system is auto-detected are usually fine. .  Adjust mount options if the defaults do not work for you. .  \"sudo mount -t ntfs -rw /dev/sda5\" .  Check the man page for exact switches for your mount version. .  \"man mount\" .  6: Add to \"/etc/fstab\" so partition will auto-mount on restart. .  After you mount the partition and have all of your switches fingered out, get the UUID of the partition you want to auto mount. .  \"sudo blkid\" .  Note the UUID number. .  \"sudo vi /etc/fstab\" .  Add an entry for your NTFS drive .  Note: .  Your UUID number will be unique and different from mine. Using the UUID number will prevent an oops if linux assigns the disk a different \"/dev\" number for some reason. .  Adjust the \"defaults\" to match your switches. .  ",
      "P-tags": "linux-mint",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "au_763335",
      "task": "How do I get the \"right\" LibreOffice Calc icon into the launcher?",
      "P-task": "get right libreoffic calc icon launcher",
      "F_verb": "get",
      "P-body": "Default directories for launchers The two default directories for \".desktop\" files (launchers) are: .  for gloablly installed applications, and .  for locally installed applications (\"~\" stands for your home directory, \"/home/yourname\") , or local versions of the launchers. .  About LibreOffice LibreOffice however is a bit of a stranger in our midst, if it comes to \".desktop\" files.  .  While the default (Ubuntu) version of LibreOffice stores its \".desktop\" files, as usual, in  .  the downloaded version stores them in .  That is, links to the launchers. The real launchers are in .  What happened There are two options: .   Somehow, you have a local copy of the \"Libreoffice\" launcher in \"~/.local/share/applications\". If so, it will overrule all other occurrences of the same launcher (as mentioned, \"~\" stands for your home directory, \"/home/yourname\"). If so, remove the file(s), log out and back in. the launcher in \"/usr/share/applications\" was left behind for some reason, by an error during uninstall. If the first option is not the case: .   Navigate to \"/usr/share/applications\" open a terminal window, type: .  and subsequently drag the \"LibreOffice Calc\" launcher over into the terminal window in order to insert the file-directory. Then press Enter. Of course, you can also do that by typing the command: .  and hitting Enter. .  Log out and back in and it should be fixed. .    ",
      "P-tags": "icon launcher libreoffic unity-dash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_11510323",
      "task": "A weird situation happened to my Terminal,relative to texlive",
      "P-task": "weird situat happen termin rel texliv",
      "F_verb": "happen",
      "P-body": "I solved this problem by myself. .  I found that some codes about texlive2012 in \"/etc/bash.bashrc\" are messed up. I mended them and now those messages disappears. .  The solution is to add those codes into \"/etc/bash.bashrc\" , which follows the guide from texlive manual.  .  \"PATH=/usr/local/texlive/2012/bin/i386-linux:$PATH; export PATH\" .  \"MANPATH=/usr/local/texlive/2012/texmf/doc/man:$MANPATH; export MANPATH\" .  \"INFOPATH=/usr/local/texlive/2012/texmf/doc/info:$INFOPATH; export INFOPATH\" .  ",
      "P-tags": "termin ubuntu latex",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V to NP"
    },
    {
      "id": "so_63140073",
      "task": "grep for x but exclude y and z",
      "P-task": "grep x exclud z",
      "F_verb": "exclude",
      "P-body": "If you use \"grep -r\" or \"grep ... filename\", then \"grep\" will ignore stdin and only produce independent, fresh results from the current dir or given filename. .  Here's what you should be doing: .  Here's what you're doing instead in most of your examples. Since the filters don't apply to the search, they're effectively dead, and it's equivalent to just \"search > output\". .  Additionally, you write to a file in the current directory, so \"grep -r\" will search through the results and add them to the results, which is obviously a bit chaotic. .  Given this, here's what you can do instead: .  ",
      "P-tags": "syntax grep unix bash",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "so_44023311",
      "task": "Python gtk3 filechooser restrict folder",
      "P-task": "python gtk3 filechoos restrict folder",
      "F_verb": "restrict",
      "P-body": "Limiting directory changes isn't directly available in \"FileChooser\", but there are a few ways: .   You can define file filters (\"Gtk.FileFilter\") but those basically filter on the file extension (or mime type). .  More interesting is that, when changing the folder, a signal is emitted called \"'current_folder_changed'\". So, you could bind a function to that signal and take action. Mind: if you programmatically change the folder as a result of this signal, the signal will probably be called again, so you have to temporarily block the signal while doing that. .   ",
      "P-tags": "gtk ubuntu gtk3 python",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP"
    },
    {
      "id": "ul_211607",
      "task": "How do I get size of (deb) file from download link/URL?",
      "P-task": "get size deb file download link url",
      "F_verb": "get",
      "P-body": "The typical way to get the file size without downloading it would be to issue a HTTP HEAD request and hope for the server to send the size back in the \"Content-Length\" header. For static files like \"deb\" files typically, servers are likely to send back that information though there's no guarantee. .  There are various tools that can send those HTTP HEAD request. Here's an example of a function that does it using the \"curl\" utility: .  Note that it will return that \"Content-Length\" regardless of whether the query is sucessful or returns with an error (like \"404 Not found\" where the \"Content-Length\" will be the size of the error message). .  Alternatives to \"curl\" include: .   GNU \"wget\": \"wget -qSO- --max-redirect=0 --method=HEAD \"$1\"\". That one will return with a non-success exit status if the query is not-successful (to be used in combination with \"set -o pipefail\" for instance). Perl LWP \"HEAD\" command: \"HEAD \"$1\"\". That one will also report query failures but follows the HTTP redirections and it doesn't seeem you can disable that.  If it's a human-friendly method you're after, you can also use \"lftp\" as in: .  ",
      "P-tags": "apt size wget url",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_45024565",
      "task": "Failed to create docker base image with Debootstrap",
      "P-task": "fail creat docker base imag debootstrap",
      "F_verb": "create",
      "P-body": "The documentation is out of date -- it's listing an old non-lts release of ubuntu (\"raring\", \"13.04\") -- I've submitted a pull request to update it to a more-recent LTS release (\"xenial\", \"16.04\"): https://github.com/docker/docker.github.io/pull/3859 .  The following commands work great though: .  ",
      "P-tags": "imag ubuntu docker",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_101995",
      "task": "Transpose several columns (of varying lengths) into rows",
      "P-task": "transpos sever column vari length row",
      "F_verb": "transpose",
      "P-body": "I would use Perl's paragraph mode for this: .  Use it like so: .  This code is tested and should work fine. As pointed out by @cjm in the comments though, it will probably take some time if your input file is large. The step most likely to take time is the final \"sort\" of the keys. .  ",
      "P-tags": "column",
      "source": "qa",
      "cate": "flip/rotate/permute/swap/transpose/reverse/shuffle",
      "pat": "V NP of NP into NP"
    },
    {
      "id": "au_605839",
      "task": "What will be effect of removing sh file in Ubuntu?",
      "P-task": "effect remov sh file ubuntu",
      "F_verb": "remove",
      "P-body": "The command to fix this is \"cd /bin && sudo ln -s dash /bin/sh\" .  ",
      "P-tags": "12 04 sh",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_210143",
      "task": "How can I execute and interrupt a script in a loop",
      "P-task": "execut interrupt script loop",
      "F_verb": "interrupt",
      "P-body": " Will first background \"python\", then start a backgrounded shell that \"sleep\"s for 120 seconds before sending \"python\" the \"-TSTP\" - or the suspend signal. This is not strictly identical to pressing \"CTRL+C\" - for that you'd want \"kill -INT \"$!\"\" - but I thought you might you like to be able to restore it again, as this is like doing \"CTRL+Z\" instead. .  Last it \"fg\" foregrounds job ID \"%1\" - which, if these are the only two processes in the \"jobs\" table, will be \"python\".  .  And so your \"demo\" runs, while a waiting \"kill\"er lurks in the shadows. .  Here it is w/ \"cat\" and a 5 second wait: .  To do it in a loop you can do: .  ",
      "P-tags": "shell-script",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP"
    },
    {
      "id": "au_999846",
      "task": "How to \"reverse\" cat -A?",
      "P-task": "revers cat -a",
      "F_verb": "reverse",
      "P-body": "Well, Python to the rescue! .  Check out this one-liner, which reads from STDIN and prints to STDOUT, handling all possible \"caret escapes\"/\"C0 codes\" (like \"^I\") and line-end indicators (\"$\"): .  Actually it's both compatible with \"python\" (2) and \"python3\". Here's a longer, more readable version doing basically the same: .  So, first we remove the line-end indicators \"$\".  .  Second we use the regular expression pattern \"\\^([A-Z?@[\\\\\\]^_])\" to find all valid characters following carets and replace both with the correct unescaped character, according to Wikipedia on Caret notation and C0 control codes. Note how only capital letters \"A\"-\"Z\" or one of \"?@[\\]^_\" have a special meaning. .  Now to unescape such a C0 code, we take the position in the alphabet of the character succeeding the caret (found in \"m.group(1)\"), e.g. \"A\" is 1, \"B\" is 2 and so on. This is equal to its ASCII value minus the ASCII code of \"A\" plus one, which makes up the -64, which also explains e.g. \"@\" (ASCII 64) being 0 or \"[\" (ASCII 91) being ESC (ASCII 27). We do a binary AND operation on this number with 127 to only consider the first 7 bits of information, so that e.g. \"?\" (ASCII 63 == 64-1) wraps around to 127, representing the DEL character.  .  Finally after all these highly complex computations are done, we simply print the resulting string to STDOUT again. .  ",
      "P-tags": "script command-lin text-process",
      "source": "qa",
      "cate": "flip/rotate/permute/swap/transpose/reverse/shuffle",
      "pat": "V NP"
    },
    {
      "id": "ul_5188",
      "task": "How to find the BSP sections in the Linux source code?",
      "P-task": "find bsp section linux sourc code",
      "F_verb": "find",
      "P-body": "A board support package may have pieces spread out in the kernel, but the typical parts are in \"arch/\", and if your board requires drivers that aren't already part of the kernel, there may be some pieces in \"drivers/\". .  Each \"arch/\" is set up a bit differently. Arm is an interesting one: look in \"arch/arm/\", you'll see several cpu types and platforms there. If you look inside a cpu type, like \"arch/arm/mach-at91/\", you'll see lots of files for the various specific cpus as well as \"board-*.c\" files, where board-specific peripherals are set up. .  ",
      "P-tags": "kernel linux",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_58311010",
      "task": "Get-Content | Measure-Object -Line to Variable",
      "P-task": "get-cont measure-object -line variabl",
      "F_verb": "get",
      "P-body": "You can use the \".\" operator like this: .  What you had earlier was basically an object with 4 properties: \"Lines\", \"Words\", \"Characters\", and \"Property\". Using \".\" is an easy way to access such properties. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_9289385",
      "task": "How to Send formatted mail body Unix Script",
      "P-task": "send format mail bodi unix script",
      "F_verb": "send",
      "P-body": "Use  .  Also you use a back-tick in the \"echo\" which invokes \"shell\". But it seems \"$TIMESTAMP_CMD\" holds a shell command. So you'd want something like this, .  ",
      "P-tags": "linux unix shell email",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP"
    },
    {
      "id": "so_66142980",
      "task": "gpg: no valid OpenPGP data found. while installing SQL Server in Ubuntu 18.04",
      "P-task": "gpg : valid openpgp data found\ninstal sql server ubuntu 18 04",
      "F_verb": "find",
      "P-body": "the problem was the internet connection, in my \"/etv/netplan/00-installer-config.yaml\" file, the network mask was wrong .  ",
      "P-tags": "ubuntu linux databas sql-server",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V"
    },
    {
      "id": "so_24212995",
      "task": "Is it possible to pass a variable to control precision in printf?",
      "P-task": "possibl pass variabl control precis printf",
      "F_verb": "pass",
      "P-body": "A cleaner way to do it is to use the * modifier, just like in C. .  ",
      "P-tags": "printf shell bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP S_INF using NP in NP"
    },
    {
      "id": "so_63739015",
      "task": "How to ask PowerShell to copy identify duplicate & put their answer as comma separated?",
      "P-task": "ask powershel copi identifi duplic put answer comma separ",
      "F_verb": "ask",
      "P-body": "I think you are over-complicating this. .  Just fix your template.xml so that the \"<SingleAction>\" node is closed with \"</SingleAction>\". .  Then read the data from the csv file, and use \"Group-Object\" to get all data belonging to whatever is under \"Data1\" column as collection. .  Output example NameA.xml .  Output example NameC.xml .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "request/ask/allow",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_26906972",
      "task": "Cannot run program \"mvn\" error=2, No such file or directory",
      "P-task": "run program mvn error 2 file directori",
      "F_verb": "run",
      "P-body": "There are multiple things here. .  You either didn't select Maven version in Job configuration. Or you didn't configure Jenkins to install a Maven version. Or you expected to use locally installed Maven on the Slave, but it's not configured for \"jenkins\" user. .  Since I don't know what you've configured (or didn't configure) and what you expected to use, I can't answer directly, but I can explain how it works. .  If you want to use locally installed Maven on master/slave  You must have Maven locally installed You must be able to launch it with \"jenkins\" user  Execute \"sudo jenkins\", and then execute \"mvn\" on your Slave to verify that \"jenkins\" user can run \"mvn\" If that fails, you need to properly install/configure Maven  In Job configuration, for Maven Version, you must select \"Default\". This is the setting that uses the version that's installed locally on the node  If you want to have Jenkins install Maven for you  You must go to Jenkins Global Tool Configuration, and configure a Maven version with automatic installer (from the web). In Job configuration, for Maven Version, you must select that particular version that you've just configured.  ",
      "P-tags": "continuous-integr ubuntu-14 04 linux jenkin java",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_53135169",
      "task": "CMake pkg_check_modules does not search the CMAKE_PREFIX_PATH",
      "P-task": "cmake pkg_check_modul search cmake_prefix_path",
      "F_verb": "search",
      "P-body": "Macro \"pkg_check_modules\" is a wrapper around pkg-config utility, which searches \".pc\" file and read it. The error .  means that you have no \".pc\" corresponded to the package, or CMake cannot find that file. .  ",
      "P-tags": "ubuntu pkg-config cmake",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_15348852",
      "task": "Bash: how to change first column of a file and only the first column",
      "P-task": "bash : chang first column file first column",
      "F_verb": "change",
      "P-body": "Using \"sed\". Remove all characters from the beginning of the line (\"^\") until first colon. .  ",
      "P-tags": "awk text-pars script linux bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP of NP"
    },
    {
      "id": "so_24543540",
      "task": "Create eternal history in TCSH",
      "P-task": "creat etern histori tcsh",
      "F_verb": "create",
      "P-body": "There's a mini-guide here. .  In short, you need to add this to your \".tcshrc\" file: .  and this to you \".logout\" file: .  ",
      "P-tags": "translat tcsh bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_308796",
      "task": "How to use Linux without any user and permissions",
      "P-task": "use linux without user permiss",
      "F_verb": "use",
      "P-body": "Theoretically: this is a difficult question to answer completely, and it starts with: \"what is your definition of Linux\" (e.g. \"Ubuntu vs. the Linux kernel\" is an apples vs. oranges type of question) and quickly expands into a scoping discussion about what sorts of applications you need and, if you need to use existing programs, how you plan to modify them. .  Practically: set your uid to 0 (in the \"/etc/passwd\" file) and you'll be the \"root\" user who can create, edit or remove any file. .  ",
      "P-tags": "linux ubuntu",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP without NP"
    },
    {
      "id": "so_14181798",
      "task": "Displaying output in categories like Get-ChildItem",
      "P-task": "display output categori like get-childitem",
      "F_verb": "get",
      "P-body": "You have to provide the \"GroupBy\" information in your view in a \"format.ps1xml\" file and update the format data to get the desired behaviour. There is no getting out of writing the \"ps1xml\" and loading it in your session. .  http://technet.microsoft.com/en-us/library/dd315396.aspx .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_23047047",
      "task": "Return value from file_operations.write is not respected",
      "P-task": "return valu file_oper write respect",
      "F_verb": "write",
      "P-body": "When testing kernel stuff, always use as low level user space api as possible. If you were using \"write()\" (the system call) everything would be fine (you will get your error code out). But you decided to go with the more complicated \"fwrite()\" function which does something different (http://linux.die.net/man/3/fwrite): .   On success, fread() and fwrite() return the number of items read or written. This number equals the number of bytes transferred only when size is 1. If an error occurs, or the end of the file is reached, the return value is a short item count (or zero). .  fread() does not distinguish between end-of-file and error, and callers must use feof(3) and ferror(3) to determine which occurred. .   In fact, \"fwrite()\" could not possibly return a negative value even if it wanted too (check out its signature). .  ",
      "P-tags": "linux c linux-device-driv linux-kernel",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "so_29295489",
      "task": "How to remove lines containing any matching text in bash",
      "P-task": "remov line contain match text bash",
      "F_verb": "remove",
      "P-body": "With awk you can do that: .  Where you test whether the first field is equal to the one from the previous line or not. If it's equal do nothing, just save it (\"k=$1\"), if it's not, print the line. .  This can be shortened to: .  (Thx to JID and glenn jackman) .  Alternatively, if you had fix number of column you could have done: .  where you reverse each line of your file and skip the 17 first column to apply uniq on the last one (in fact, the first ones), and reverse back. But here it's not very convenient as you don't have the same number of columns.  .  HTH .  ",
      "P-tags": "awk grep linux bash sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_94489",
      "task": "What happens when my internet dies out during the net installation of Debian?",
      "P-task": "happen internet die net instal debian",
      "F_verb": "happen",
      "P-body": "All the packages you've already downloaded are in \"/var/cache/apt/archives\". At worst you may have to restart the downloading of the one package that was only partially downloaded (and not even that if your server allows to resume downloads). You don't need to worry about this, it'll just happen automatically. .  If you ended up with partially-installed packages because of the incomplete download, run \"apt-get -f install\". Most likely you have no partially-installed packages, but you're missing many useful packages. \"apt-get -f install\" will also finish installing packages marked for installation. .  If after that you find that you're still missing some packages you want, run \"apt-get install gnome-desktop-environment\" or whatever packages you want. .  ",
      "P-tags": "debian system-instal",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V when S"
    },
    {
      "id": "so_36681031",
      "task": "can't make pipe operator function properly - linux",
      "P-task": "make pipe oper function properli - linux",
      "F_verb": "make",
      "P-body": "Well, it works correctly NM_000525 is before NM_001005850, and the later is before NM_00695. .  But if you need to sort the second part (after the \"_\") numerically, then you can do: .   \"-s\" is a stable sort  Assuming the format is the same in the whole file (two letters \"_\" numbers) .  EDIT: Even shorter version would be: .  Explanation: .   \"-t_\" use \"_\" as separator of fields (for selection on which field to sort) \"-k1,1\" sort alphabetically from first field (without \",1\" it would sort also the second field) \"-k2n\" sort numerically on the second field  So first it will sort by first field (using alphanumeric sorting) and then using the second field (using numeric, so it will convert string to a number and sort that) .  ",
      "P-tags": "linux sort",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_10341719",
      "task": "find -name with multiple filenames using shell variable",
      "P-task": "find -name multipl filenam use shell variabl",
      "F_verb": "find",
      "P-body": "Looks like \"find\" fails to match \"*\" in patterns from unquoted variables. This syntax works for me (using bash arrays): .  Your example would become the following: .  ",
      "P-tags": "find shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP using NP"
    },
    {
      "id": "so_49810487",
      "task": "Failed to resolve library symbol hostfxr_main_startupinfo on Amazon Linux 2 AMI",
      "P-task": "fail resolv librari symbol hostfxr_main_startupinfo amazon linux 2 ami",
      "F_verb": "resolve",
      "P-body": "The problem is the \"yum install dotnet-sdk-2.0.0\" pulls in \"dotnet-runtime-deps-2.1.0-preview2-26406-04\" (preview version instead of release). .  To fix it you need to add line \"exclude=*preview*\" into \"dotnetdev.repo\" file. Or just run the following command on the second step from instruction: .  \"sudo sh -c 'echo -e \"[packages-microsoft-com-prod]\\nname=packages-microsoft-com-prod \\nbaseurl=https://packages.microsoft.com/yumrepos/microsoft-rhel7.3-prod\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc\\nexclude=*preview*\" > /etc/yum.repos.d/dotnetdev.repo'\" .  The source: https://github.com/dotnet/core-setup/issues/4007#issuecomment-380685340 .  ",
      "P-tags": "amazon-linux net-cor",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP on NP"
    },
    {
      "id": "so_4145667",
      "task": "How to override the path of PHP to use the MAMP path?",
      "P-task": "overrid path php use mamp path",
      "F_verb": "override",
      "P-body": "Everytime you save MAMP config (PHP section), it saves the current version of PHP on \"~/.profile\" file and creates the alias for php, pear and pecl, to point to the current configured version. Note: you need to check \"Make this version available on the command line\" option in MAMP) .  However, you need to refresh your terminal (open another session) to get this file refreshed. You can also type \"source ~/.profile\" to refesh the aliases manually. .  If you want to extract this curerent version in a PHP_VERSION variable - as commented above - for further use, you can do: .  And then you'll have $PHP_VERSION available with the current version of MAMP. .  Finally, if you want to run your php using the current configured version on mamp, you just need to add to your \"~/.bash_profile\" the following: .  Now, even script that relies on \"/usr/bin/env php\" will read the correct version from Mamp config. .  ",
      "P-tags": "php mamp maco shell path",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP S_INF"
    },
    {
      "id": "so_35449573",
      "task": "Multiple declaration of a function make command UNIX",
      "P-task": "multipl declar function make command unix",
      "F_verb": "make",
      "P-body": "You are compiling both these files into singular output file but your \"pgm1.cpp\" already contains the function \"print2()\" by virtue of the line \"#include \"pgm2.cpp\"\"... .  Possible solutions can be: .  1) Remove the include file and instead add a function declaration. .  2) As already pointed out create a header file and use include it instead of a .cpp file. .  ",
      "P-tags": "c++ unix makefil",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP"
    },
    {
      "id": "su_1462062",
      "task": "Linux ext4 restore file and directory access rights after bad backup/restore",
      "P-task": "linux ext4 restor file directori access right bad backup restor",
      "F_verb": "restore",
      "P-body": "The standard recommended solution is straight-forward: .  This will append as many filenames as possible as arguments to a single command, up to the system's maximum command line length. If the line exceeds this length, the command will be called multiple times. .  If you want to call the command once per file, you can instead do: .  ",
      "P-tags": "ext4 linux filesystem",
      "source": "qa",
      "cate": "restore/recover/resume",
      "pat": "V NP after NP"
    },
    {
      "id": "au_62034",
      "task": "Is it possible to set the default behaviour of double clicking a folder to be \"Open in New Window\" with PCManFM?",
      "P-task": "possibl set default behaviour doubl click folder open new window pcmanfm",
      "F_verb": "set",
      "P-body": "You can try to recompile PCManFM , I am running Lubuntu 12.04 with PCManFM 0.9.10 and these steps worked for me. .  Follow these steps: .   Open a Terminal and install the necessary packages: .   Install the build dependencies: .   Create a folder to download the source code: .   Download the source: .   Edit the \"pcmanfm-0.9.10/src/pcmanfm.c\" file. .   In Leafpad, search for the line \"fm_main_win_open_in_last_active(fi->path);\" (should be somewhere around line 420 and change it to \"fm_main_win_add_win(NULL, fi->path);\". Save the changes and close the file. See the screenshots if it isn't clear: .  Before: .   .  After: .   .  Go to the \"pcmanfm-0.9.10/\" folder to build the deb packages: .   Now you can install the deb packages: .   Finally you can logout and Login to see the changes. .    Reference: This post by ogilvierothchild in ubuntu forums. .  ",
      "P-tags": "lxde pcmanfm",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP of NP S_INF with NP"
    },
    {
      "id": "so_18080148",
      "task": "Replace Text Between 2 Characters in Vim",
      "P-task": "replac text 2 charact vim",
      "F_verb": "replace",
      "P-body": "\"ca[\" would be the answer if you are doing it with vim. .  since you tagged the question with \"sed\" too, here is the way with sed: .  with your example,  .  this works too. .  ",
      "P-tags": "sed vim shell",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP"
    },
    {
      "id": "so_57694085",
      "task": "String join in select object or Export-Csv",
      "P-task": "string join select object export-csv",
      "F_verb": "join",
      "P-body": "To build on @Ansgar's suggestion, here is how you would integrate a calculated property into your present select statement and retrieve the properties you're looking for. .  ",
      "P-tags": "powershel powershell-2 0 powershell-3 0",
      "source": "qa",
      "cate": "connect/associate/join/combine/concatenate/merge/concat/group/reconnect/migrate/defragment",
      "pat": "V in NP"
    },
    {
      "id": "so_27927484",
      "task": "Get Powershell result into C# List",
      "P-task": "get powershel result c list",
      "F_verb": "get",
      "P-body": "I think you're doing too much in the PowerShell script part. Try this: .  In fact, you could probably even lose the Select-Object part of the pipeline. PowerShell will return the .NET objects to your program and you can select the properties you're interested in. .  BTW when you use \"Out-String\" the entire output is accumulated into a single string. If you want Out-String to produce an array of strings use the \"-Stream\" parameter. .  ",
      "P-tags": "powershel c",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP into NP"
    },
    {
      "id": "so_23097842",
      "task": "How to execute command inside vim?",
      "P-task": "execut command insid vim",
      "F_verb": "execute",
      "P-body": "There are multiple ways to do it. A primary question is \"Do you want the output from the script in the file?\" .   If you want the output in the file: .   If you don't want the output in the file: .   If you have the line \"./shell.sh\" in the file, you can include the output in the file with: .   If you've done it before, you have more options. .  If you save the command in a named buffer you have still more options. .  If you want the script to have a portion of the file (edit buffer) as its standard input, you have an enormous number of options you can use in conjunction with either of these mechanisms. .   ",
      "P-tags": "vim bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP inside NP"
    },
    {
      "id": "au_870746",
      "task": "Cannot start X on Ubuntu 14.04",
      "P-task": "start x ubuntu 14 04",
      "F_verb": "start",
      "P-body": "Using \"xinit\" did the trick ! .  Hope it will help. .  ",
      "P-tags": "14 04 xorg",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1011295",
      "task": "`--no-install-recommends` only specified packages",
      "P-task": "-- no-install-recommend specifi packag",
      "F_verb": "install",
      "P-body": "I think this is a confusion between the upstream XCFE.org pages which indicate Midori is one of the xfce4 goodies, and what is actually installed. .  The actual dependencies of the \"xfce4-goodies\" package that it installs don't even reference Midori anywhere. From \"apt-get install --dry-run xfce4-goodies\" on a standard Ubuntu 16.04 box: .  Nowhere in this is Midori referenced. .  Now, if you tried to install the full XFCE packagesets and not just the goodies package, Midori might be included. however it is not part of the standard packagesets anywhere, not even in the Xubuntu packagesets by default, unless it's pulled in as its own dependency) .  ",
      "P-tags": "apt package-manag",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V"
    },
    {
      "id": "so_8756522",
      "task": "How to use a for loop in make recipe",
      "P-task": "use loop make recip",
      "F_verb": "use",
      "P-body": "There are two main things you need to know when putting non-trivial shell fragments into make recipes: .   Commands in the recipe are (of course!) executed one at a time, where command means \"tab-prefixed line in the recipe\", possibly spread over several makefile lines with backslashes. .  So your shell fragment has to be written all on one (possibly backslashed) line. Moreover it's effectively presented to the shell as a single line (the backslashed-newlines are not plain newlines so are not used as command terminators by the shell), so must be syntactically correct as such. .  Both shell variables and make variables are introduced by dollar signs (\"$@\", \"$i\"), so you need to hide your shell variables from make by writing them as \"$$i\". More precisely, any dollar sign you want to be seen by the shell must be escaped from make by writing it as \"$$\".) .   Normally in a shell script you would write separate commands on separate lines, but here you effectively only get a single line so must separate the individual shell commands with semicolons instead. Putting all this together for your example produces: .  or equivalently: .  Notice that the latter, even though it's laid out readably on several lines, requires the same careful use of semicolons to keep the shell happy. .  ",
      "P-tags": "makefil recip shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP for NP in NP"
    },
    {
      "id": "so_65194730",
      "task": "AWK - Parsing SQL output",
      "P-task": "awk - pars sql output",
      "F_verb": "parse",
      "P-body": "Description: .  Command line switches... .   The delimiter is \"|\" surrounded by spaces. Note that we need to use a couple of \"\\\"'s to escape \"|\" if we feed the regex for the delimiter in from the command line.) In addition to input delimiter (input field separator) the output delimiter (output field separator) can also be set using a command line switch.  The awk script... .   If a header is encountered or a \"(\" is seen on a line, it's not a valid line; so, just ignore it. If the line now has any alphanumeric characters, it's now a valid line to operate on; so, and we strip the leading spaces off the line, and then print the columns we want.  Examining the data more closely... It looks as though the date-stamp (which always has a \":\" in it) might be present on all valid records... If so, the script can be reduced to something much more simple. .  ",
      "P-tags": "sql awk bash",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_39236544",
      "task": "How to view information about a newly loaded external Linux kernel module?",
      "P-task": "view inform newli load extern linux kernel modul",
      "F_verb": "view",
      "P-body": "From the man page: .   modinfo extracts information from the Linux Kernel modules given on the command line. If the module name is not a filename, then the /lib/modules/version directory is searched, as is also done by modprobe(8) when loading kernel modules. .   So it looks like this command just uses the kernel module files to get this information, so you can either run: .  or you could put your kernel module in the \"/lib/modules/version/\" directory .  ",
      "P-tags": "kernel-modul linux linux-kernel",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP about NP"
    },
    {
      "id": "so_50270949",
      "task": "Automatically deleting files without prompts with Powershell",
      "P-task": "automat delet file without prompt powershel",
      "F_verb": "delete",
      "P-body": "You can add -Recurse to remove items without prompt. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP without NP with NP"
    },
    {
      "id": "so_55494233",
      "task": "Problem in executing a shell script present on host using docker exec",
      "P-task": "problem execut shell script present host use docker exec",
      "F_verb": "execute",
      "P-body": "The \"docker exec\" command runs a command within the container's namespaces. One of those namespaces is the filesystem. So unless the command is part of the image, written into the container directly, or you have mounted a host volume to map a host directory into the container, you won't be able to execute it. A host volume could look like: .  That host volume could be the same path on both the host and the container. .  If it is a shell script, you could use I/O redirection, e.g.: .  but be aware that you cannot do interactive stuff this way since the script content has replaced your terminal as stdin. This works because the shell inside the container is just processing commands from stdin. .  Other than those scenarios, I don't know what to tell you other than the documentation from AWS appears to be wrong. .  ",
      "P-tags": "amazon-emr docker bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP using NP"
    },
    {
      "id": "so_41019020",
      "task": "IF Statement to Verify VLAN Exists in PowerCLI Script",
      "P-task": "statement verifi vlan exist powercli script",
      "F_verb": "verify",
      "P-body": "EDIT to work for vlan rather than vswitch .  You could use get-virtualportgroup for this and check if the names returned contain your vlanid. This won't work for distributed switches as that's a different set of cmdlets. .  ",
      "P-tags": "powercli powershel vmware autom",
      "source": "qa",
      "cate": "test/tell/determine/check/ascertain/invalidate/verify/identify/track/detect/decide/checkout/sniff/inspect/justify/probe/benchmark/debug",
      "pat": "V NP in NP"
    },
    {
      "id": "so_23414675",
      "task": "Stopping paste after any input is exhausted",
      "P-task": "stop past input exhaust",
      "F_verb": "stop",
      "P-body": "Here's one solution: .  This has the slightly annoying effect of ignoring the last line of an input file if it is not terminated with a newline (but such a file is not a valid text file). .  You can wrap this in a function, of course: .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP after S"
    },
    {
      "id": "so_17435056",
      "task": "Read Bash variables into a Python script",
      "P-task": "read bash variabl python script",
      "F_verb": "read",
      "P-body": "You need to export the variables in bash, or they will be local to bash: .  Then, in python .  ",
      "P-tags": "script python environment-vari bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP into NP"
    },
    {
      "id": "so_1055671",
      "task": "How can I get the behavior of GNU's readlink -f on a Mac?",
      "P-task": "get behavior gnu readlink -f mac",
      "F_verb": "get",
      "P-body": "\"readlink -f\" does two things: .   It iterates along a sequence of symlinks until it finds an actual file. It returns that file's canonicalized name\u2014i.e., its absolute pathname.  If you want to, you can just build a shell script that uses vanilla readlink behavior to achieve the same thing. Here's an example. Obviously you could insert this in your own script where you'd like to call \"readlink -f\"  .  Note that this doesn't include any error handling. Of particular importance, it doesn't detect symlink cycles. A simple way to do this would be to count the number of times you go around the loop and fail if you hit an improbably large number, such as 1,000. .  EDITED to use \"pwd -P\" instead of \"$PWD\". .  Note that this script expects to be called like \"./script_name filename\", no \"-f\", change \"$1\" to \"$2\" if you want to be able to use with \"-f filename\" like GNU readlink. .  ",
      "P-tags": "freebsd sh maco",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP on NP"
    },
    {
      "id": "so_7568126",
      "task": "Retrieving the last modified file in a directory over FTP using a bash script with curl",
      "P-task": "retriev last modifi file directori ftp use bash script curl",
      "F_verb": "retrieve",
      "P-body": "You can sort the filenames in one shot with a multi-key \"sort\" command and grab the last line with \"tail\" to get the latest file. .  You'll need to specify \"-t-\" to use a dash as sort's field separator, \"-n\" to get a numeric sort, and list each field in the order of its priority. The format for a field specifier is: .  So for the year, field 3, you'll need to list it with its 4-character width as \"-k3,4\". .  If you sort by the year, month, and day fields in that order, you'll end up with a list that has all the files in date order. .  So instead of the \"for\" loop above, you can use: .  ",
      "P-tags": "grep file curl shell bash",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP using NP with NP"
    },
    {
      "id": "so_39609297",
      "task": "Replace very near word to a number with another word",
      "P-task": "replac near word number anoth word",
      "F_verb": "replace",
      "P-body": "Following solution will search for any number and if found it will start polling backwards to search \"d\" in the string and if found replace it with \"b\".  .  Sample input: .  Solution using awk: .  ",
      "P-tags": "grep linux shell bash sed",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "ul_614728",
      "task": "increasing the size of root partition and reducing the size of home",
      "P-task": "increas size root partit reduc size home",
      "F_verb": "reduce",
      "P-body": "There's no need for \"gparted\" to generate a new \"/etc/fstab\" (it never does this anyway). You are not creating any new partitions or changing UUIDs, so you should be good to go. .  That being said, that warning is posted for a reason: PLEASE have a system backup in case \"gparted\" crashes. .  ",
      "P-tags": "partit gpart",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_533508",
      "task": "How to retrieve specific cpu, memory and interface statistics only",
      "P-task": "retriev specif cpu memori interfac statist",
      "F_verb": "retrieve",
      "P-body": "I think jq is the tool of choice.  .   \"jq\" is like \"sed\" for JSON data - you can use it to slice and filter and map and transform structured data with the same ease that \"sed\", \"awk\", \"grep\" and friends let you play with text. .   A brilliant tutorial on \"jq\" can be found at Github https://stedolan.github.io/jq/tutorial/ and a nice one here: https://programminghistorian.org/en/lessons/json-and-jq. .  For example, to get to the \"memfree\" part, pipe the output of your commands to \"jq\" like this: .  \"... | jq .[].hosts[].statistics[].memory.memfree\" .  which gives: .  \"3707764\" .  Or, to get the whole memory part in a JSON: .  \"... | | jq .[].hosts[].statistics[].memory\" .  which gives: .  ",
      "P-tags": "json statist sysstat sar",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP S"
    },
    {
      "id": "ul_332747",
      "task": "In systemd, what starts units generated by generator?",
      "P-task": "systemd start unit gener gener",
      "F_verb": "generate",
      "P-body": "Generated unit files are not automatically activated by systemd. There's nothing special about them as far as systemd is concerned. Each individual generator has to explicitly create symbolic links that connect a generated unit to a target, so that activating the target activates the generated unit via a dependency in the normal way.  .  This takes advantage of the fact that not all connections between units are expressed inside the unit files. Wants and Requires dependencies can be expressed with symbolic link farms in \"*.wants/\" and \"*.requires/\" subdirectories. And those symbolic link farms encompass subdirectories of \"/run/systemd/\" amongst other things. .  In other words: Rather than write out a unit with \"WantedBy=local-fs.target\" and then have to explicitly invoke \"sytemctl enable\" to make the symbolic link (which is what enabling does), the generator short-circuits the process and makes the symbolic link itself. And it makes it in an ephemeral place, which \"systemctl enable\" normally would not, thereby preventing the symbolic link from continuing to exist after the next shutdown and confusing the next startup. .  Specifically, you'll find on your system that \"/run/systemd/generator/boot.mount\" is symbolically linked from \"/run/systemd/generator/local-fs.target.wants/boot.mount\". \"systemd-fstab-generator\" created this symbolic link, and it makes \"boot.mount\" wanted by \"local-fs.target\". The generator is run early in the bootstrap before the system gets around to activating \"local-fs.target\", which means that when it does get around to activating \"local-fs.target\" the generated dependency is there to be followed. .  Further reading  https://unix.stackexchange.com/a/233581/5132 Jonathan de Boyne Pollard (2016). \"Missing system search paths from the \"systemd.unit\" manual page\". Errata for systemd doco. Frequently Given Answers.  ",
      "P-tags": "systemd",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V by NP"
    },
    {
      "id": "au_1229832",
      "task": "Ubuntu server 18.04 networking not getting dhcp or static not working",
      "P-task": "ubuntu server 18 04 network get dhcp static work",
      "F_verb": "get",
      "P-body": "I have this working now. Yesterday I had edited this file which I now no was a mistake: \"/run/systemd/network/10-netplan-eth0.network\" .  I removed all configs from that file. I then set the \"/etc/netplan/50-cloud-init.yaml\" file back to DHCP and removed all configuration I had set in that file. I ran sudo netplan generate. That worked. Then \"sudo netplan apply\". That also completed successfully. So I was working again. I decided one more time to put in a static IP. I was edited the \"50-cloud-init.yaml\" file again with the IP address and DNS that I wanted. I ran \"sudo netplan generate\", and \"sudo netplan apply\" and all is good! Thanks for the help! .  ",
      "P-tags": "network server",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_ING"
    },
    {
      "id": "ul_237258",
      "task": "how to get crtime of a file in an ext4 partition as a single number or string",
      "P-task": "get crtime file ext4 partit singl number string",
      "F_verb": "get",
      "P-body": "You can use \"grep\" with PCRE (\"-P\") to extract the desired portion and use it as input for \"date\": .  Or .  For example: .   You can also use \"sed\": .  Or .  For example: .  ",
      "P-tags": "ext4 timestamp filesystem bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP as NP"
    },
    {
      "id": "au_1295701",
      "task": "uninstall program compiled with make",
      "P-task": "uninstal program compil make",
      "F_verb": "compile",
      "P-body": "For ANY Makefile, do a \"cat Makefile\" and look at the very end of the listing. There you'll find what options \"make\" will understand (for that particular Makefile). .  Look at the following code snippet... and look for \"option:\"... and in this example, we can see \"all:\" and \"modules:\" and etc... all the way down to \"uninstall:\"... and even a few more after that. .  This typically means (in this case example), following your initial \"make\" command, and \"sudo make install\" to build and install the code, you can use \"sudo make uninstall\" to remove the installed code. .  ",
      "P-tags": "configur make",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V with NP"
    },
    {
      "id": "so_46174341",
      "task": "MySQL: Can I create a database with command `cp` on centos?",
      "P-task": "mysql : creat databas command cp cento",
      "F_verb": "create",
      "P-body": "No you can not create any database using cp command. the easiest way to do that is  .  1- dump new_york database without data.  .  2- create los_angeles, and import new_york database dump. .  Hope This helps .  ",
      "P-tags": "linux mysql",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP with NP on NP"
    },
    {
      "id": "so_4535183",
      "task": "How to calculate the number of lines in source code",
      "P-task": "calcul number line sourc code",
      "F_verb": "calculate",
      "P-body": "Use \"sloccount\" .  ",
      "P-tags": "lines-of-cod termin bash",
      "source": "qa",
      "cate": "compute/calculate/evaluate/solve/scale/measure/recalculate/multiply/count/figure/subtract/increase/estimate/increment/aggregate/double/halve",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_51053475",
      "task": "Why does if [ ...something... ]; then echo \"Exit status is $?\" always emit 0?",
      "P-task": "someth echo exit statu\nalway emit 0",
      "F_verb": "echo",
      "P-body": "In both of these cases, the last command executed was \"[\", which exited with 0 status (\"success\") to land you in the \"true\" block. .  Yes, you need to specify a non-zero exit code for the \"exit\" command.  .  Pedantically \"unix\" does not output the error code: it's the shell running your script that exits with the specified status. .  ",
      "P-tags": "exit-cod unix bash",
      "source": "qa",
      "cate": "write/record/log/print/output/archive/spell/rewrite/echo",
      "pat": "V NP"
    },
    {
      "id": "au_424322",
      "task": "How can I install pepper plugin into chromium that is running from compiled src/out/ directory?",
      "P-task": "instal pepper plugin chromium run compil src directori",
      "F_verb": "install",
      "P-body": "I found the answer here http://www.chromium.org/developers/design-documents/pepper-plugin-implementation .  did the trick.  .  ",
      "P-tags": "google-chrom chromium",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP that S"
    },
    {
      "id": "ul_287913",
      "task": "\"cc: Command not found\" when compiling a PAM module on Centos",
      "P-task": "cc : command found compil pam modul cento",
      "F_verb": "find",
      "P-body": "Your error message is: .   make: cc: Command not found .   which tells you that you are missing the C compiler. As @GAD3R suggests, installing the Development Tools group will correct this. You probably also need the \"pam-devel\" package. .  But, that said: there's really no reason to build pam_radius yourself, as it already exists in EPEL (\"Extra Packages for Enterprise Linux\"). Find instructions for configuring it here, and then just \"sudo yum install pam_radius\". .  ",
      "P-tags": "cento radiu compil",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V when S"
    },
    {
      "id": "so_20529169",
      "task": "use powershell to find scheduled tasks set to wake the computer",
      "P-task": "use powershel find schedul task set wake comput",
      "F_verb": "find",
      "P-body": "That information should be down in the xml. Edit: Graimer is correct that this is not using the same script that was linked. This uses Get-ScheduledTask from the TaskScheduler Module in the PowerShellPack, which can be downloade from here: http://archive.msdn.microsoft.com/PowerShellPack .   or simply .  ",
      "P-tags": "powershel window windows-8 1",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP S_INF"
    },
    {
      "id": "so_33998091",
      "task": "Images not showing up from localhost server",
      "P-task": "imag show localhost server",
      "F_verb": "show",
      "P-body": "The problem is that your file has too little file permissions, probably \"640\". Because your user is owner, you can see the images in the browser when accessing the .html in your browser with url \"file://...\". Because now your own linux user is opening the file. .  But; when you try to open the file with url \"http://localhost/...\", your linux user itself is trying to open the file, but the user apache is running from (probably \"apache\" or \"www-data\"). So this time, the file has too little permissions (the last \"0\" in the bitmask). .  If you run give the image more permissions you should be good; .  \"chmod 644 /var/www/html/path/to/the-image.jpg\" .  And if you don't want to do this everytime you save an image on your pc, open up \"$HOME/.profile\" (in a terminal: \"vim ~/.profile\", or the more easy editor \"pico -w ~/.profile\") and add the following line at the very end of the file: .  \"umask 0022\" .  That's it! Don't forget to logout and login again to have this line to have effect. .  Note: the instruction about adding the \"umask\" command to \"~/.profile\" only applies to (most) Debian systems (including Ubuntu). It might differ for your linux distribution, so please check the documentation for your distro, or ask our omniscient friend google. .  ",
      "P-tags": "localhost linux permiss php",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V from NP"
    },
    {
      "id": "ul_159614",
      "task": "What mechanism prevents any user from accessing any other user's files via root?",
      "P-task": "mechan prevent user access user file via root",
      "F_verb": "prevent",
      "P-body": "The major difference between \"sudo\" and \"su\" is the mechanism used to authenticate. With \"su\" the user must know the \"root\" password (which should be a closely guarded secret), while with \"sudo\" the user uses his/her own password. In order to stop all users causing mayhem, the priviliges discharged by the \"sudo\" command can, fortunately, be configured using the \"/etc/sudoers\" file. .  Both commands run a command as another user, quite often \"root\". .  \"sudo su -\" works in the example you gave because the user (or a group where the user is a member) is configured in the \"/etc/sudoers\" file. That is, they are allowed to use \"sudo\". Armed with this, they use the \"sudo\" to temporarily gain \"root\" privileges (which is default when no username is provided) and as \"root\" start another shell (\"su -\"). They now have \"root\" access without knowing \"root\"'s password. .  Conversely, if you don't allow the user to use \"sudo\" then they won't be able to \"sudo su -\". .  Distros generally have a group (often called \"wheel\") whose members are allowed to use \"sudo\" to run all commands. Removing them from this group will mean that they cannot use \"sudo\" at all by default.  .  The line in \"/etc/sudoers\" that does this is: .  While removing users from this group would make your system more secure, it would also result in you (or other system adminstrators) being required to carry out more administrative tasks on the system on behalf of your users. .  A more sensible compromise would configure \"sudo\" to give you more fine grained control of who is allowed to use \"sudo\" and who isn't, along with which commands they are allowed to use (instead of the default of all commands). For example, .  (only useful with the previous %wheel line commented out, or no users in the \"wheel\" group). .  Presumably, distros don't come with this finer grained configuration as standard as it's impossible to forecast what the admin's requirements are for his/her users and system. .  Bottom line is - learn the details of \"sudo\" and you can stop \"sudo su -\" while allowing other commands that don't give the user \"root\" shell access or access to commands that can change other users' files. You should give serious consideration to who you allow to use \"sudo\" and to what level. .  WARNING: Always use the \"visudo\" command to edit the \"sudoers\" file as it checks your edits for you and tries to save you from the embarrassing situation where a misconfigured file (due to a syntax error) stops you from using \"sudo\" to edit any errors. This is especially true on Debian/Ubuntu and variants where the \"root\" account is disabled by default. .  ",
      "P-tags": "sudo su permiss user",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP from NP via NP"
    },
    {
      "id": "so_29017285",
      "task": "Delete files with same md5sum in cshell",
      "P-task": "delet file md5sum cshell",
      "F_verb": "delete",
      "P-body": "I'll assume that your goal is to delete certain lines from your textual input, not actually to delete the files. .  Like this: .  This reads from standard input. If the input is in a file, you can do: .  Or, if it's the output of some command: .  Explanation: \"seen\" is an associative array. \"$1\" is the first whitespace-delimited field of the current line. \"awk\" processes input line-by-line. \"seen[$1]\" tells you whether first field of the current line has been seen before; the \"++\" increments that value, marking the current line as already seen for the next time you see it. Incrementing a nonexistent array element sets it to \"1\". .  This assumes you have \"awk\" installed on your system. You probably do. .  If you're looking for a solution in pure csh, without invoking an external command, that's going to be more difficult (and I can't think of a good reason to do that). .   Apparently you actually want to delete the files. Here's a solution for that: .  Again, you'll need to provide the desired input to this command. .  This prints, but does not execute, a series of \"rm\" commands. For example, given the input in the question the output is: .  You could modify the \"awk\" command to use \"system(\"rm \" file\")\" rather than just printing it, but for added safety I'd write the output to a file, check that it looks correct, and then \"source\" the file to remove the files. It's easy to shoot yourself in the foot with a script that removes files automatically based on arbitrary input. .  ",
      "P-tags": "md5sum duplic shell",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_72157",
      "task": "Delete XML node containing certain element",
      "P-task": "delet xml node contain certain element",
      "F_verb": "delete",
      "P-body": "With \"xmlstarlet\": .  And as \"kml\" uses namespaces, you have to define it first (see the xmlstarlet documentation) .  With \"perl\", you'd need to process the file as a whole (not line by line) and add the \"s\" flag to \"s///\". And even then, even with non-greedy match, it would still match from the first \"<Placemark>\" up the next \"</Placemark>\" that occurs after the next \"<tessellate>\". So you'd need to write it something like: .  ",
      "P-tags": "xml regular-express python perl sed",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP"
    },
    {
      "id": "ul_234629",
      "task": "Combination of find command and sed (stream editor)",
      "P-task": "combin find command sed stream editor",
      "F_verb": "find",
      "P-body": "This seems to work for me... .  That's a pretty handy search to run, actually. Thank you. .  You might want to tack a \"2>/dev/null\" on the end, though. \"find\" complains a lot about \"/proc\" for me. .  ",
      "P-tags": "shell-script file find",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP"
    },
    {
      "id": "so_68492755",
      "task": "how do you force apple script + aws vault to wait for mfa access",
      "P-task": "forc appl script + aw vault wait mfa access",
      "F_verb": "force",
      "P-body": "I don't think this is really possible, because Apple Script has no way of knowing that the \"aws\" command requires mfa information and if you are done typing that information. .  But there are 2 very hacky ways in which you could achieve this: .  Using \"delay\" This option is probably very unreliable, but it may do the job. You can use the \"delay\" command to make AppleScript wait X seconds until it runs \"write text \"start him\"\". Lets say it takes you around 10 seconds to type out the mfa information, then you would use \"delay 10\". Below is how the code would look like. .  Using \"display dialog\" I personally feel this may be the most reliable option for you. What you can do is have a dialog box open and once you have typed out the mfa information, click \"Ok\" so that the script resumes. So you'd have something like this: .  Just a small warning: I haven't tested the above code as I do not own a macOS computer. .  ",
      "P-tags": "osascript termin iterm2 bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP S_INF for NP"
    },
    {
      "id": "so_47886689",
      "task": "Add Multiline Values to single HTML Cell",
      "P-task": "add multilin valu singl html cell",
      "F_verb": "add",
      "P-body": "When rendering HTML consecutive whitespaces is usually mangled into a single space. Because of that adding newlines won't give you wrapped text in the rendered HTML. You need to encode line breaks as \"<br>\" (or \"<br/>\") to preserve them in the rendered HTML. However, you cannot join the list of team members with \"<br/>\" strings before the \"ConvertTo-Html\", because then the angular brackets would be escaped to \"&lt;br/&gt;\" and you'd get literal \"<br/>\" in the rendered HTML output. .  One way to retrofit line breaks into the prepared HTML is to replace spaces (or newlines) in a \"<td>\" using a regular expression replacement with a callback function: .  However, a more elegant approach would be a CSS format for \"<td>\" tags that defines whitespace handling as pre-formatted (similar to the \"<pre>\" tag). Adding something like this to your CSS file should suffice: .  ",
      "P-tags": "array powershel html",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "so_45963820",
      "task": "How to populate field based on groupings?",
      "P-task": "popul field base group",
      "F_verb": "populate",
      "P-body": "I vowed myself that SQL is strictly taboo for me. However, below's an example of pure PowerShell solution (and I'm pretty sure that it's convertible to SQL simply): .  Output: \"D:\\PShell\\SO\\45963820.ps1\" .    Note that Criterium 3 covers criteria 1 and 2 but does not suffice if more Sub Owners have the same highest sum of Sub Hours for a particular Parent ID (e.g in case of \"B||aA|Jane Doe|8\" instead of \"B||aA|Jane Doe|4\" in the above example, then Jane Doe has sum of Sub Hours =18 as well as Bob Smith in Parent ID=B). .  ",
      "P-tags": "sql powershel",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_157285",
      "task": "Why does \"ls | wc -l\" show the correct number of files in current directory?",
      "P-task": "ls wc -l show correct number file current directori",
      "F_verb": "show",
      "P-body": "From \"info ls\": .   '-1' '--format=single-column' .   List one file per line. This is the default for 'ls' when standard output is not a terminal. .    When you pipe the output of \"ls\", you get one filename per line. \"ls\" only outputs the files in columns when the output is destined for human eyes. .   Here's where \"ls\" decides what to do: .  source: http://git.savannah.gnu.org/cgit/coreutils.git/tree/src/ls.c .  ",
      "P-tags": "ls wc",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "ul_535655",
      "task": "Why does acpi_listen show different events for gnome-session vs i3?",
      "P-task": "acpi_listen show differ event gnome-sess vs i3",
      "F_verb": "show",
      "P-body": "I've discovered that \"gnome-session\" has its own power management daemon that runs in the background once the session has started, and performs actions separate from \"acpi\" (such as managing the backlight, sending the system to sleep on the lid switch changes, etc.) .  I've been unsuccessful in finding out how to intercept these events directly in i3, or finding a seperate utility to listen to them for me. However, I have found an acceptable solution for now in i3-gnome .  It starts the gnome services in the background while allowing i3wm to run as the window manager. This results in my backlight and lid switch being handled by the gnome power daemon, and my windows being managed by i3wm.  .  ",
      "P-tags": "acpi backlight ubuntu i3 gnome",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP for NP"
    },
    {
      "id": "so_32973449",
      "task": "Linux - compare system date with date in file and send e-mail to admin",
      "P-task": "linux - compar system date date file send e-mail admin",
      "F_verb": "send",
      "P-body": "@John1024 After following your advice, I came up with this: .  ",
      "P-tags": "cron linux email bash",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP to NP"
    },
    {
      "id": "so_47105794",
      "task": "SGX Enclave: Where the actual function that does the procession goes and how it gets compiled",
      "P-task": "sgx enclav : actual function process goe get compil",
      "F_verb": "compile",
      "P-body": "The autogenerated outputs of edger8r are only to provide interface between the enclave and the untrusted outside world. They are not supposed to contain your implementations. .  You should define \"myFirstMethod\" in another source file, say \"enclave.c\" or \"enclave.cpp\" and link it with the rest of your project. The signature of the function being exactly what you declared in your edl, except for the pointer qualifiers, which are for edger8r to consume. .  It will go like this: .  enclave.cpp: .  ",
      "P-tags": "bash intel linux sgx c",
      "source": "qa",
      "cate": "compile/assemble",
      "pat": "V"
    },
    {
      "id": "au_492852",
      "task": "sending email from cron with correct format",
      "P-task": "send email cron correct format",
      "F_verb": "send",
      "P-body": "For \"CentOs\" to install cron type .  In your php script put the header section of $header above assigning $msg to intercept it as \"html\" content before it really assign $msg with \"HTML\" so it will be .  opens \"VI\" .  press \"ESC\" then \"capsLock ON\" type \"ZZ\" from keyboard you are done .  ",
      "P-tags": "mysql php mail cron email",
      "source": "qa",
      "cate": "send/pass/dispatch/post/issue/propagate/forward/broadcast/transmit/emit/signal/raise/plan/bump/pipe",
      "pat": "V NP from NP with NP"
    },
    {
      "id": "ul_670766",
      "task": "How to list sub directories of a directory?",
      "P-task": "list sub directori directori",
      "F_verb": "list",
      "P-body": "Assuming that you are using GNU tools, you could use GNU \"basename\" to get the names of all subdirectories in a particular directory. You could then use \"paste\" to format this as a space-delimited list. .  The above command uses the fact that GNU \"basename\" has an \"-a\" option to return the filename portion of multiple pathnames given as operands on its command line. .  We use a file-globbing pattern ending in \"/\" to generate the pathnames for GNU \"basename\". Only directories can match such a pattern. .  In the end, the \"paste\" creates the space-separated list from the newline-separated list produced by GNU \"basename\". .  Note that it would be difficult to parse the generated list of filenames if any of the original names of directories contain space characters. .  Note that if the directory contains symbolic links, this method will try to follow those symbolic links. .   Restricting us from using any external tools, we could use an array in the \"bash\" shell to store and manipulate the directory paths. .  The above shell code expands the same globbing pattern as we used in the first part of this answer but stores the resulting directory paths in the array \"dirpaths\". It then deletes the known prefix \"$topdir/\" from each element of the array and the trailing \"/\" before printing the array as a single string of space-delimited names. The delimiter used between the names on the last line will be the first character from \"$IFS\", which by default is a space. .   Using \"find\", you could look for subdirectories in the particular top directory you're interested in while making sure not to return the top directory itself. You would also stop \"find\" from progressing into the subdirectories. .  The above command avoids the search starting point using a negated \"-name\" test, and it prunes the search tree with \"-prune\" so that \"find\" does not recurse down into any subdirectories. We call \"basename\" for each found directory which outputs the filename of the directories onto separate lines. As the last step, we're piping the result from \"find\" through \"paste\" to format the output into a space-separated list on a single line. .  With GNU \"find\", you could write this as .  Using \"find\" like this will list directories with hidden names, and you will not see any symbolically linked directories. .   In the \"zsh\" shell, you would be able to use a more advanced shell globbing pattern to pick out the filenames of only directories and print them in one go. .  This command uses a glob qualifier, \"/:t\", consisting of two parts, affecting the preceding globbing pattern \"/some/path/*\". The \"/\" makes the pattern only match directories (not symbolically linked ones; for that use \"-/\"), while \":t\" extracts the \"tail\" of each generated pathname, i.e., the filename component. .  The \"print -r\" command prints its arguments with spaces as delimiters while avoiding expanding escape sequences like \"\\n\" or \"\\t\" in the data. Using \"--\" to delimit the operands from the options (also works with \"-\" like in the \"ksh\" shell) makes sure directory names resulting from the glob expansion are not taken as options even if they start with \"-\". .  You could use this from within the \"bash\" shell to generate your list. .  ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "list/enumerate/renumber/number",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_205648",
      "task": "Can you uncompress a btrfs filesystem?",
      "P-task": "uncompress btrf filesystem",
      "F_verb": "uncompress",
      "P-body": "You could use the compress tool with the \"--decompress\" option. This will recursively remove the +c (compression) flag, then copy and then the delete the original files and folders. Easiest way is probably to boot using the Arch Linux install medium (CD, USB, etc.), mount the root directory you want to decompress and run the command. .  An alternative solution would be to simply re-install the Syslinux (I assume that's what you're using) files using \"syslinux-install_update -i\" from the Arch Linux install medium. Of course, make sure you've mounted the root partition without enabling compression.  .  ",
      "P-tags": "arch-linux boot syslinux btrf",
      "source": "qa",
      "cate": "parse/resolve/unwrap/analyze/uncompress/decode/flatten/unmarshal/decompress/unzip/analyse/decrypt/unpack/decompile/disassemble/summarise/rank",
      "pat": "V NP"
    },
    {
      "id": "so_61236936",
      "task": "Enable O365 MFA with no old phone number via PowerSehll",
      "P-task": "enabl o365 mfa old phone number via powersehl",
      "F_verb": "enable",
      "P-body": "I found the answer of myself .  This code only disable the MFA but do not remove the phone numbers etc .  I have to add this as well to remove the phone numbers .  So the code will looks like: .  ",
      "P-tags": "powershel multi-factor-authent",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP with NP via NP"
    },
    {
      "id": "so_37205961",
      "task": "Powershell read csv and get data that equals username",
      "P-task": "powershel read csv get data equal usernam",
      "F_verb": "read",
      "P-body": "If (after your comments) I understood you correctly, you merely need to figure out what row to use from the CSV file. In that case you can read the user name from the environment variable \"USERNAME\" and simply filter appropriately: .  ",
      "P-tags": "powershel csv signatur powershell-3 0",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP"
    },
    {
      "id": "so_19828663",
      "task": "Starting Mongod from within a Shell",
      "P-task": "start mongod within shell",
      "F_verb": "start",
      "P-body": "The issue arose because of an issue in the mapping of 'mongo' and 'mongod' commands. Because of this issue, these commands were unavailable from within the shell, meaning that the answer in the mentioned thread did not work. .  I was able to resolve the issue by setting the command to the absolute path where mongod was located, overcoming the difference in $PATH: .  ",
      "P-tags": "mongodb gruntj shell bash",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP from NP"
    },
    {
      "id": "so_10902612",
      "task": "How to apply two different sed commands on a line?",
      "P-task": "appli two differ sed command line",
      "F_verb": "apply",
      "P-body": "Golfing =) .  In reply to user1428900, this is some explanations : .  Extended mode isn't really needed there, consider the same following snippet in \"BRE\" (basic regex) mode : .  Edit to fit your new needs : .  If you want only email lines, you can do something like that : .  the \"/@/\" part means to only works on the lines containing the character \"@\" .  Edit2: .  if you want to keep the end lines like your new comments said : .  ",
      "P-tags": "sed shell",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP on NP"
    },
    {
      "id": "su_1511447",
      "task": "Retain ownership by uid0 and setuid bit setting while transferring binary",
      "P-task": "retain ownership uid0 setuid bit set transfer binari",
      "F_verb": "retain",
      "P-body": "No \u2013 if you perform the transfer with your own user account on the destination system, then the new copy will always be owned by you as well. .  Files aren't simply \"sent\", the transfer tool (on the receiving side) always has to create a new file and then manually set all parameters (permissions, ownership, etc.) to match what it knows about the original. So obviously the transfer tool needs to have privileges for all of this \u2013 and if it isn't running as root, it cannot change the new file's owner to anyone else except yourself. .   There are possible exceptions to that. For example, you can transfer a filesystem image (e.g. an Ext4 image disguised as .iso) and have the recipient mount it. This will exactly preserve ownership and file permissions. .  However, mounting a filesystem image requires root, so it still won't help you get root access on the destination system if you don't already have it. In GNOME, double-clicking a disk image will mount it without requiring privileges, but will also set the options to ignore setuid mode \u2013 i.e. the filesystem is mounted with \"nosuid\" to prevent exactly this kind of trickery.) .  ",
      "P-tags": "linux permiss",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP by NP"
    },
    {
      "id": "ul_521917",
      "task": "How to view contents of a sparse file?",
      "P-task": "view content spars file",
      "F_verb": "view",
      "P-body": "On newer linux systems, there are the \"SEEK_DATA\" and \"SEEK_HOLE\" extension of \"lseek(2)\" which allow an app to skip \"holes\" when reading a sparse file. .  On older systems, \"ioctl(FIBMAP)\" could be used and the data could be read directly from the underlying device (\"FIBMAP\" needs \"CAP_SYS_RAWIO\" capabilities, though). .  Unfortunately, I'm not aware of any coreutils / standard utility making use of either. .  Here is a small \"sparse_cat\" demo, which is using those in order to dump the data from very large sparse files in no time. .  Example: .  Note: to keep things simple, I've omitted any file opening code (it should always be used as \"sparse_cat < input\", not \"sparse_cat input\") and any work-arounds for the bad interactions between \"sendfile(2)\" and ttys opened with the \"O_APPEND\" flag (use \">/dev/tty\" explicitly). .  Also notice that the data/hole ranges have block granularity -- the \"1st\" string from the example above is actually followed by \"block size - 4\" nul bytes. .  sparse_cat.c .  ",
      "P-tags": "sparse-fil linux filesystem",
      "source": "qa",
      "cate": "play/unpause/display/show/present/bring/replay/preview/visualize/view/monitor/watch/see",
      "pat": "V NP of NP"
    },
    {
      "id": "so_54893014",
      "task": "Using awk to include file name with format in column",
      "P-task": "use awk includ file name format column",
      "F_verb": "include",
      "P-body": "This would handle one or multiple input files: .  ",
      "P-tags": "awk linux hive unix",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_48018965",
      "task": "How do I download a package from the command line with .NET Core from nuget?",
      "P-task": "download packag command line net core nuget",
      "F_verb": "download",
      "P-body": "\"dotnet add package --help\" .  \"dotnet add package Newtonsoft.Json\" .  Please refer to the github page https://github.com/dotnet/docs/blob/master/docs/core/tools/dotnet-add-package.md for more details. .  ",
      "P-tags": "net linux c net-core-2 0 net-cor",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V using NP from NP with NP"
    },
    {
      "id": "ul_627156",
      "task": "Trouble getting bash tests working in .xsessionrc that work fine on command line",
      "P-task": "troubl get bash test work xsessionrc work fine command line",
      "F_verb": "get",
      "P-body": "Use .  i.e., single square brackets and quoting the pathnames of the file. .  The double square brackets is a non-standard test syntax in the \"bash\" (and other) shells. It is not clear that it is actually \"bash\" that is reading your file, and it may well be \"/bin/sh\" which may not understand the double square bracket syntax for tests. .  See also: .   What is the difference between the Bash operators [[ vs [ vs ( vs ((? When is double-quoting necessary?  ",
      "P-tags": "script linux bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP S_ING in NP that S"
    },
    {
      "id": "so_60247305",
      "task": "How to use a conditional statement with regex in PowerShell?",
      "P-task": "use condit statement regex powershel",
      "F_verb": "use",
      "P-body": "You can use the following: .  \"\\d\" is a regex character matching a digit. A \"switch\" statement with \"-regex\" allows for regex expressions to be used for matching text. The \"default\" condition is picked when no other condition is met. \"$_\" is the current line being processed.  .  \"switch\" is generally faster than \"Get-Content\" for line by line processing. Since you do want to perform certain actions per line, you likely don\u2019t want to use the \"-Raw\" parameter because that will read in all file contents as one single string. .   ",
      "P-tags": "if-stat regex syntax powershel iter",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_35356440",
      "task": "Codeigntier: Unable to load the requested file: helpers/phpass_helper.php on Ubuntu 14.04",
      "P-task": "codeignti : unabl load request file : helper phpass_help php ubuntu 14 04",
      "F_verb": "load",
      "P-body": "As you can see in the Codeigniter Docs: .   Unlike most other systems in CodeIgniter, Helpers are not written in an Object Oriented format. They are simple, procedural functions. Each helper function performs one specific task, with no dependence on other functions. .   To load a helper, the name of the file has to be like \"phpass_helper.php\" and inside the controller, you load this way .  But in your case with the \"PasswordHash\" class I would suggest you convert that to a Library, which would be a better fit for your application and a correct way to apply too. .  Creating libraries in Codeigniter .  ",
      "P-tags": "phpass codeignit ubuntu php",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP on NP"
    },
    {
      "id": "so_46930040",
      "task": "How to quit the JShell and go back to the command-line?",
      "P-task": "quit jshell go back command-lin",
      "F_verb": "go",
      "P-body": "You can use the JShell command to exit as: .  Side note: Interestingly, with the use of command abbreviations for input shortcuts:- .  (of course \"/exi\") also, resolves into the same command. .   .  ",
      "P-tags": "jshell java-9 java",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP to NP"
    },
    {
      "id": "so_15066725",
      "task": "how to get the actual address of `func` from `callq func@PLT`",
      "P-task": "get actual address func callq func plt",
      "F_verb": "get",
      "P-body": "You can only find out about that at runtime, after the dynamic linker resolves the actual load address. Warning: What follows is slightly deeper magic ... .  To illustrate what's happening use a debugger: .  Compile it (\"gcc -O8 ...\"). \"objdump -d\" on the binary shows (the optimization of \"printf()\" being substituted with \"puts()\" for a plain string not withstanding ...): .  Now load it into \"gdb\". Then: .  Notice this value points back to the instruction directly following the first \"jmpq\"; this means the \"puts@plt\" slot, on first invocation, will simply \"fall through\" to: .  The function address and argument aren't initialized yet. This is the state just after program load, but before executing. Now start executing it: .  So this hasn't changed yet - but the targets (the \"GOT\" contents for the \"libc\" initialization) are different now: .  I.e. at program load time, the dynamic linker will resolve the \"\"init\"\" parts first. It substitutes the \"GOT\" references with pointers that redirect into the dynamic linking code.  .  Therefore, when first calling an external-to-the-binary function through the \".plt\" reference, it'll jump into the linker again. Let it do that, then inspect the program after that - the state has changed again: .  So there's your redirect right into \"libc\" now - the \"PLT\" reference to \"puts()\" finally got resolved. .  The instructions to the linker where to insert the actual function load addresses (that we've seen it do for \"_dl_runtime_resolve\" comes from special sections in the ELF binary: .  There's more to ELF than just the above, but these three pieces tell the kernel's binary format handler \"this ELF binary has an interpreter\" (which is the dynamic linker) that needs to be loaded / initialized first, that it requires \"libc.so.6\", and that offsets \"0x5008c0\" and \"0x5008c8\" in the program's writeable data section must be substituted by the load addresses for \"__libc_start_main\" and \"puts\", respectively, when the step of dynamic linking is actually performed. .  How exactly that happens, from ELF's point of view, is up to the details of the interpreter (aka, the dynamic linker implementation). .  ",
      "P-tags": "linux shared-librari function assembl",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP from NP"
    },
    {
      "id": "so_6514378",
      "task": "how do you get how long a process has been running?",
      "P-task": "get long process run",
      "F_verb": "get",
      "P-body": "Okay guys, so after reading the \"top\" command's source code, I figured out a non-hacky way of getting the start time of a process. The formula that they use is: .  (You have to divide by HZ because process_start_time is in jiffies) .  Obtaining these values: .   \"current_time\" - You can get this from the C command \"gettimeofday()\". \"boot_time\" - This value is located in \"/proc/uptime\". This file contains two numbers: the uptime of the system (seconds), and the amount of time spent in idle process (seconds). Take the first. \"process_start_time\" - This value is located in \"/proc/[PID]/stat\". The time difference (in jiffies) between system boot and when the process started. The 22nd value in the file if you split on whitespace).  The code (Sorry, I sometimes mix c and c++): .  Happy Coding! .  ",
      "P-tags": "linux c++ c process-manag",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V S"
    },
    {
      "id": "au_912646",
      "task": "How to kill tabs without closing the tabs or killing the browser itself in chromium 58",
      "P-task": "kill tab without close tab kill browser chromium 58",
      "F_verb": "kill",
      "P-body": "Okay so after your edits; I played around with the command you gave. You said that it destroys extensions as well so to exclude them you can do \"grep -v \"extension\"\" but then you take as input the whole process command. .  Anyways. First select the process name .  I'm using chrome, you can put \"chromium-browser\" instead. The \"-a\" flag here is important. .  then do .  to get all renderers. Then do  .  to exclude the extensions, then we need to do  .  to get only the process number (since we had to use the \"-a\" flag which gives extra data in the string). .  Feed that into your for loop .  And it should kill renderers without extensions .  So finally, here's the whole thing for you: .  I hope I didn't make mistakes .  ",
      "P-tags": "chromium process kill",
      "source": "qa",
      "cate": "stop/quit/terminate/interrupt/crash/intercept/abort/disconnect/shutdown/pause/freeze/block/kill/prevent/halt/shut/poweroff/restrict",
      "pat": "V NP in NP"
    },
    {
      "id": "so_25567157",
      "task": "problems with read in bash script",
      "P-task": "problem read bash script",
      "F_verb": "read",
      "P-body": "  \"$(...)\" executes the contents of the parentheses and returns the stdout. If you don't have a command named \"line\" you'll see a \"command not found\" error message, and \"$()\" will return an empty string. \"[...]\" does different actions based on the number of arguments given. Since you only give a single word, the \"[\" command merely checks if the string is empty or not. In this case, \"[\" will see \"\"\"=='OFF'\" which is not empty, therefore the success block will always be executed.  ",
      "P-tags": "while-loop bash",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V in NP"
    },
    {
      "id": "au_744128",
      "task": "What is `run-init` actually?",
      "P-task": "run-init actual",
      "F_verb": "run",
      "P-body": "\"run-init\" is a binary executable, it lives in /usr/lib/klibc/bin/run-init and in your initramfs and is provided by the \"klibc-utils\" package in Ubuntu. It isn't a script, so you cannot take a look inside directly, you can check out its source code via running \"apt source klibc-utils\" or browsing the upstream repository at https://git.kernel.org/cgit/libs/klibc/klibc.git. .  So the main function is in run-init.c , but it's just a wrapper for \"run_init\" function, which lives here in runinitlib.c .  \"run_init\" does a lot of work: .   It jumps into the new root file system Checks that this is the new root file system Checks if it on initramfs Cleans all directory (why waste the RAM?) Mounts the new root file system and runs init in the new root file system  I believe, it would be very complicated to do all this work by a script, because of dependencies, but binary executable file can do it very ease. .  ",
      "P-tags": "initramf",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "su_408585",
      "task": "Use msysgit/\"Git for Windows\" to navigate Windows shortcuts?",
      "P-task": "use msysgit git window navig window shortcut",
      "F_verb": "navigate",
      "P-body": "*ahem* First, compile the following AutoHotkey script: .   Place the \".EXE\" file in a %PATH% directory. I named mine \"follow.exe\". .  Now, you can effectively follow a Windows \".LNK\" file in your working directory by using the following syntax: .  where \"Shortcut.lnk\"'s target is a valid directory. .   Demonstration:  .   .   Once you've set up your \"follow.exe\", you can add the following shell function to your \"~/.bashrc\" file to simplify the syntax even further. Thanks, Daniel! .  Now, you can follow \".LNK\" files with just \"cd\"! .   Demonstration:  .  ",
      "P-tags": "msysgit window bash",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP"
    },
    {
      "id": "so_4400250",
      "task": "How to align 3 files based on first column value",
      "P-task": "align 3 file base first column valu",
      "F_verb": "align",
      "P-body": " Output ",
      "P-tags": "file linux sort bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP on NP"
    },
    {
      "id": "so_25667616",
      "task": "Running multiples query on Hbase shell without calling hbase shell again",
      "P-task": "run multipl queri hbase shell without call hbase shell",
      "F_verb": "run",
      "P-body": "There are 4 options I know of .  Option 1: semicolons  .  Option 2: newlines  .  Option 3: exec  .  Option 4: external file  .  Whether to include the \"-n\" argument is up to you and your use case. It instructs the shell to stop executing after the first failed command and exit with a non-zero exit code. It was added with HBASE-11658. .  I personally prefer option 3 since it's readable and without the need for a temp file. .  ",
      "P-tags": "awk hbase shell",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP without S_ING"
    },
    {
      "id": "so_19710223",
      "task": "Magento: Getting 500 internal server error when creating invoices",
      "P-task": "magento : get 500 intern server error creat invoic",
      "F_verb": "get",
      "P-body": "I looked into the wrong error_log file, as I'm using Plesk the correct error_log file was located in /var/www/vhosts/xxx.com/statistics/logs/ and not in /var/log/apache2/ .  The error in there was .  This lead me to the fcgid.conf (etc/apache2/mods-available/fcgid.conf) where I had to increase the following values: .  ",
      "P-tags": "php linux ubuntu magento apach",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP when S"
    },
    {
      "id": "au_1228911",
      "task": "How to find config files for snap apps?",
      "P-task": "find config file snap app",
      "F_verb": "find",
      "P-body": "All of the snap settings are stored in \"~/snap/\" then whatever app it is. Usually the settings are stored in a \"current\" sub folder that points to the version that is being ran. Ex. GIMP is stored in folder \"~/snap/gimp/current\" which actually points to \"~/snap/gimp/252\" as it is the current installed version. In that sub folder you should be able to find the \".config\" folder that you can drop in plugins, etc. .  One thing to remember is that the actual snaps are sandboxed and secured so you will not be able to add directly to the snap app itself.  .  ",
      "P-tags": "filesystem snap 16 04",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP for NP"
    },
    {
      "id": "su_16810",
      "task": "Finding folders that contain changed files since date",
      "P-task": "find folder contain chang file sinc date",
      "F_verb": "find",
      "P-body": " From the find man page: .  -newerXY file .  True if the current file has a more recent last access time (X=a), inode creation time (X=B), change time (X=c), or modification time (X=m) than the last access time (Y=a), inode creation time (Y=B), change time (Y=c), or modification time (Y=m) of file. In addition, if Y=t, then file is instead interpreted as a direct date specification of the form understood by cvs(1). Note that -newermm is equivalent to -newer. .  ",
      "P-tags": "applescript unix mac maco",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP that S"
    },
    {
      "id": "so_3207785",
      "task": "Using PowerShell to replace string that contains $ in the string",
      "P-task": "use powershel replac string contain string",
      "F_verb": "replace",
      "P-body": "Two things to get this to work: .   Use single quotes for your strings so that the \"$\" is not interpreted as the start of a variable to be expanded. Escape the \"$\" using a backslash \"\\\" so the regular expression parser takes it literally.  For example, .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP that S"
    },
    {
      "id": "so_67137339",
      "task": "Suppress just bash job control messages in scripts (Aborted, Broken pipe)",
      "P-task": "suppress bash job control messag script abort broken pipe",
      "F_verb": "suppress",
      "P-body": " How do I suppress the 'Broken pipe' and 'Aborted' job control lines output by bash in the second case? .   Redirect bash stderr to null except for you process. .  ",
      "P-tags": "job abort bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP in NP"
    },
    {
      "id": "so_4238910",
      "task": "How do I properly read a line of a file into an array?",
      "P-task": "properli read line file array",
      "F_verb": "read",
      "P-body": "If, as you say, the original data-file is in CSV format, then you're probably better off doing something simple like .  ",
      "P-tags": "script linux curl bash sed",
      "source": "qa",
      "cate": "read/load/reload/reread/mount/remount",
      "pat": "V NP of NP into NP"
    },
    {
      "id": "ul_614979",
      "task": "Specify rootfs mount options",
      "P-task": "specifi rootf mount option",
      "F_verb": "specify",
      "P-body": "For context I'm working on a Raspberry Pi 0. .  Using @A.B 's comment, I added \"rootflags=fastboot\" to \"cmdline.txt\" which is passed to the kernel on boot. This solved my issue. .  ",
      "P-tags": "imag embed buildroot",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_28133037",
      "task": "Files not getting deleted from remote servers",
      "P-task": "file get delet remot server",
      "F_verb": "delete",
      "P-body": "As already mentioned in the comments, you need to pass the parameters to use inside the scriptblock as arguments to the \"-ArgumentList\" parameter: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V from NP"
    },
    {
      "id": "su_1480152",
      "task": "setting a value in `about:config` page from bash (no gui available)",
      "P-task": "set valu : config page bash gui avail",
      "F_verb": "set",
      "P-body": "Search in your home directory file \"prefs.js\" (usually \"~/.mozilla/firefox/*.default/prefs.js\") and in this directory edit file \"user.js\" (the file may not yet exist) and add: .  ",
      "P-tags": "centos-7 firefox bash",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "so_66530768",
      "task": "How to use a variable's value as identifier in order to declare/modify an array in BASH?",
      "P-task": "use variabl valu identifi order declar modifi array bash",
      "F_verb": "use",
      "P-body": "Here is an answer for my own question for anyone who encounters the same problem: .  This solves my problem. Note that if you don't do the \"cast\" part at the end an just use \"VAR_ID\" directly, the resulting \"my_array\" doesn't provide things like \"${my_array[0]}\" to give only the first item or \"${#my_array[@]}\" to count the items. .  Also note: This method is limited as it does not distinguish between separator spaces and \"value spaces\" that may be stored in \"VAL\". .  ",
      "P-tags": "array declar bash variabl export",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP as NP in NP S_INF in NP"
    },
    {
      "id": "so_51305520",
      "task": "OPENCV :: Find all the points between two concentric circles",
      "P-task": "opencv : : find point two concentr circl",
      "F_verb": "find",
      "P-body": "The indices (\"x, y\") of the points between the two concentric circles (center (\"x_0, y_0\"), radii \"r_0, r_1\" with \"r_1 > r_0\") have to fulfill the following condition: .  So when looping over all point of an image you can figure out which points to process: .  ",
      "P-tags": "histogram c++ linux opencv",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP between NP"
    },
    {
      "id": "ul_28526",
      "task": "Add a user to the system *only if it doesn't exist*",
      "P-task": "add user system exist",
      "F_verb": "add",
      "P-body": "\"id -u somename\" returns a non-zero exit code when the user does not exist.  .  You can test it quite simply... \"&>/dev/null\" just supresses the normal output/warning)  .  ",
      "P-tags": "user",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP if S"
    },
    {
      "id": "au_889450",
      "task": "How to duplicate a terminal session at same directory and get root user by default",
      "P-task": "duplic termin session directori get root user default",
      "F_verb": "get",
      "P-body": "Just launch a new terminal. The default terminal on Ubuntu is \"gnome-terminal\". If you launch a new one, it will start as the user who launched it and in the directory it was launched from.  .  So, if you're already logged in as root and are visiting, for example, \"/etc\", you can run \"gnome-terminal &\" (the \"&\" is just to send it to the background) and a new terminal will appear, running as \"root\" and in \"/etc\". .  ",
      "P-tags": "root command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP by NP"
    },
    {
      "id": "so_62348973",
      "task": "Why can't I execute binary copied into a container?",
      "P-task": "execut binari copi contain",
      "F_verb": "execute",
      "P-body": "For a binary, this most likely indicates a missing dynamic library. You can run \"ldd /usr/local/bin/my_bin\" to see all the libraries that binary uses. With alpine, the most common library to be missing from an externally compiled program is libc. Alpine is built with musl instead of libc, and therefore you'll want to compile programs specifically for Alpine. .  For others that may encounter this error in docker containers, I cover various issues in my faq presentation and other questions on the site. .  ",
      "P-tags": "linux contain docker",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP into NP"
    },
    {
      "id": "so_12861604",
      "task": "Got the Phusion Passenger errors with rails",
      "P-task": "got phusion passeng error rail",
      "F_verb": "get",
      "P-body": "I have already got solution. When I have check \"which passenger\" , I found there are 2 place that may cause some conflict problem. Because of the previous command there: .   \"sudo gem install passenger\" \"gem install passenger\"  then i do .   \"sudo gem uninstall passenger\" \"gem uninstall passenger\"  and do .   \"gem install passenger\" \"passenger-install-apache2-module\"  and I got my application back . .  ",
      "P-tags": "ubuntu-12 04 passeng ruby-on-rail",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP with NP"
    },
    {
      "id": "ul_176693",
      "task": "Shell script not able to awk created file",
      "P-task": "shell script abl awk creat file",
      "F_verb": "create",
      "P-body": "Spaces are not allowed around \"=\"! .  So: .  Or even shorter: .  NOTE:  There is no need to assign the \"x\" variable; you can print \"$6\" directly. AWK itself can create new files with its output The backquote is used in the old-style command substitution, for example :  The \"foo=$(command)\" syntax is recommended instead. Backslash handling inside \"$()\" is less surprising, and \"$()\" is easier to nest. .  Check http://mywiki.wooledge.org/BashFAQ/082 .  Extra solution using Perl: ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP"
    },
    {
      "id": "au_51364",
      "task": "How to repair ods files",
      "P-task": "repair od file",
      "F_verb": "repair",
      "P-body": "ODS files, like all Open Document file types, are just \"ZIP\" files. You can try to repair the file using regular tools for repairing ZIPs. For example on the command line: .  Beware that you should always operate on a copy of the file. If extracting data works, you might be able to re-assemble the file as a ZIP archive and load it in OpenOffice.org. .  Before trying this, you should make sure the file is actually an ODS file. If you run .  It should look like this .  That is, it should start with \"PK\". .  Also perhaps you can open the file in a different version of OpenOffice.org, or using \"gnumeric\" or Google Docs. .  ",
      "P-tags": "openoffic org",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP"
    },
    {
      "id": "so_65896101",
      "task": "Copy-Item : The process cannot access the file 'dll' because it is being used by another process",
      "P-task": "copy-item : process access file dll use anoth process",
      "F_verb": "access",
      "P-body": "As comments of Bruce Zhang, I add stop app pool to my script. It works.  \"Stop-WebAppPool -Name $args[0];\" .  ",
      "P-tags": "powershel web-deploy ii net",
      "source": "qa",
      "cate": "visit/rescan/scan/walk/iterate/access/descend/traverse",
      "pat": "V NP by NP"
    },
    {
      "id": "au_288390",
      "task": "How to open many-tabbed Gnome terminal as one windown instead of many independent windows",
      "P-task": "open many-tab gnome termin one windown instead mani independ window",
      "F_verb": "open",
      "P-body": "I don't see \"--tab\" option in gnome-terminal man page. But for example: .  ",
      "P-tags": "gnome-termin 12 04 bash",
      "source": "qa",
      "cate": "open",
      "pat": "V NP as NP of NP"
    },
    {
      "id": "so_20231435",
      "task": "Run an executable on all the files in a folder (with subfolders)",
      "P-task": "run execut file folder subfold",
      "F_verb": "run",
      "P-body": " Note the output filename does not conform to your spec, this exercise is left to the reader ;-)  .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP with NP"
    },
    {
      "id": "so_18611426",
      "task": "run uniq on csv file ignoring column preserving highest in file",
      "P-task": "run uniq csv file ignor column preserv highest file",
      "F_verb": "run",
      "P-body": "What about this? .  Explanation We store the first column in an array. In case it is already in the array, we skip the record. .   \"-F,\" sets the field delimiter as comma \",\". \"{if (a[$1]) next}\" in case the first field is already in the array, skip. \"a[$1]=$0\" saves the first field as a key of the array \"a\" and prints the line (\"print $0\" is the default behaviour of awk, so it does not need to be written).   And how would I tweak it if it was the nth column that needed to be ignored? .   You can replace \"a[$1]\" for \"a[$n]\", where \"n\" is the column. .  ",
      "P-tags": "csv pars bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP in NP"
    },
    {
      "id": "so_50424282",
      "task": "how to make powershell shorten the long directory before \">\"",
      "P-task": "make powershel shorten long directori",
      "F_verb": "make",
      "P-body": "You can modify the prompt-function to do whatever you want. If you only want to check a single variable, you can do this: .  Output: .  If you need to support multiple variables, you can store the paths in a hashtable and check that or use \"Get-Variable\" to search through variables that contains a valid path. Remember to exclude ex \"$PWD\" which is always your current location. .  ",
      "P-tags": "directori powershel alia",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP before NP"
    },
    {
      "id": "so_3553951",
      "task": "BASH: how to construct php command by asking for arguments?",
      "P-task": "bash : construct php command ask argument",
      "F_verb": "construct",
      "P-body": "The \"read\" command will do the trick: .  For your specific purposes, you can use: .  Use \"man read\" for further details, though it will probably give you the massive \"bash\" manpage, so I'll duplicate the relevant section from mine here: .   ",
      "P-tags": "bash",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V NP by S_ING for NP"
    },
    {
      "id": "so_26488857",
      "task": "How do I get specific information out of Mediainfo",
      "P-task": "get specif inform mediainfo",
      "F_verb": "get",
      "P-body": "You can work with the Duration you get with the command you allready used like this:  .  (assuming $tmil holds the value) .  The duration you get is in milliseconds and can easily be reformatted to fit your needs .  ",
      "P-tags": "powershel mediainfo command-lin",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "ul_658650",
      "task": "How to find a file with a given string in several directories?",
      "P-task": "find file given string sever directori",
      "F_verb": "find",
      "P-body": "From \"grep\"'s man page: .  So \"grep -r ...\" will do the trick. When \"grep\"ping multiple files I find it useful to also add \"-H\" so that the name of the matching file(s) is also printed (this is the default on Linux, but not on other platforms). .  ",
      "P-tags": "file grep",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "ul_120988",
      "task": "How to get last crash log from ArchLInux",
      "P-task": "get last crash log archlinux",
      "F_verb": "get",
      "P-body": " Reference .  ",
      "P-tags": "arch-linux log crash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_5998630",
      "task": "Package manager command that returns 0 or 1 in Ubuntu/Debian if a package is installed or not",
      "P-task": "packag manag command return 0 1 ubuntu debian packag instal",
      "F_verb": "return",
      "P-body": "Maybe not ideal, but this works: .  Or just .  ",
      "P-tags": "ubuntu perl debian packag",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP in NP S_INF of NP"
    },
    {
      "id": "au_987732",
      "task": "Can't open terminal after using chmod",
      "P-task": "open termin use chmod",
      "F_verb": "open",
      "P-body": "Please don't change permissions in order to read root-owned files. In future, if you want to read a file you don't have access to, use \"sudo cat\" or \"sudo less\" or open a text editor with root permission. If you think you really need to change permissions for some reason, then first do research or ask a question about it. It's all too easy to break your system with \"chown\" and \"chmod\". .  Anyway, your user already had read permissions on that directory and all its contents. The \"/bin\" directory has permissions \"755\" or \"rwxr-xr-x\", as do the vast majority of its contents. They can be read and executed by any user. .  You removed the execution bits (\"644\" = \"rw-r--r--\"), making the files readable for all, writeable for root, and executable for no user. .  When you remove the execute bits from a directory, you make it impossible to enter the directory, except for root. .  When you remove the execute bits from a file, you make it impossible to execute the file, even for root. .  The Bash program is located at \"/bin/bash\". You have made the directory it is in inaccessible, and you have made the binary file itself non-executable, so not even root can run it. \"chown\" and \"chmod\" are also in \"/bin\", so you can't even use another shell to run them, if you happen to have one that isn't in \"/bin\". .  Reinstalling your system is the best way to be sure you've got everything right, but if you would like to try fixing it or you really want to avoid that, what you could do is boot from a live system (eg USB installation media or System Recovery), mount your root partition, and change the permissions from there. See terdon's answer here for the best method of doing this (replace \"/etc\" with \"/bin\" and use \"chmod\" instead of \"chown\"). .  ",
      "P-tags": "permiss command-lin chmod",
      "source": "qa",
      "cate": "open",
      "pat": "V NP after S_ING"
    },
    {
      "id": "au_1119804",
      "task": "How to install LKRG - Linux Kernel Runtime Guard on 18.04?",
      "P-task": "instal lkrg - linux kernel runtim guard 18 04",
      "F_verb": "install",
      "P-body": "First get the sources: .  Unpack: .  Build: .  Run: .  Install systemd service and run it: .  Done! .  ",
      "P-tags": "kernel secur",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_9988125",
      "task": "Shebang pointing to script (also having shebang) is effectively ignored",
      "P-task": "shebang point script also shebang effect ignor",
      "F_verb": "ignore",
      "P-body": "Looks like Mac OS X requires interpreter to be binary, not another script. To make it work, change the second script's interpreter to .  But you've got a second problem here: the contents of the second script will not go to \"stdin\" of its interpreter, but the script pathname will be passed as command line argument, i.e. .  You shall read the file by name \"sys.argv[1]\" rather than from \"sys.stdin\". .  ",
      "P-tags": "shell maco bash",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V"
    },
    {
      "id": "au_577711",
      "task": "How to install synapse in Ubuntu 14.04",
      "P-task": "instal synaps ubuntu 14 04",
      "F_verb": "install",
      "P-body": "\"synapse\" is not available for Ubuntu 14.04 . But you can install it by adding Synapse core team PPA. .  To install \"synapse\" in Ubuntu 14.04, open terminal and type  .  It should install \"synapse\" in your system. .   EDIT .  \"synapse\" is now available in Ubuntu Universe repository (See here). To install it you need to enable the universe repository . Enable it using  .  and then install \"synapse\" using .  However above PPA can be used to get the latest version of \"synapse\" .  ",
      "P-tags": "14 04 apt lxde",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "so_66936100",
      "task": "Segmentation fault when executed from linux command line",
      "P-task": "segment fault execut linux command line",
      "F_verb": "execute",
      "P-body": "We need more information. Please do the following: .   Recompile with \"-g\", for debugging information. Include \"-Wall -pedantic\" for additional compiler warnings .  EXAMPLE: \"gcc -g -Wall -pedantic -o myprog myprog.c\" .   Update your post with your \"gcc\" command, and the compiler warnings you get. .   Run your program. If it still crashes, use gdb to analyze further: .  EXAMPLE: \"gdb ./myprog\" Type \"r\" to execute. Type \"bt\" to get a stack trace after it crashes. Copy/paste the stack trace into your post. .    Here are several useful links: .   GNU Debugger Tutorial How to automatically generate a stacktrace when my program crashes Debugging Segmentation Faults and Pointer Problems  ",
      "P-tags": "linux clion c gcc",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V from NP"
    },
    {
      "id": "so_36365783",
      "task": "Code seems to require Powershell 4, however, can't see why",
      "P-task": "code seem requir powershel 4 howev see",
      "F_verb": "require",
      "P-body": "You mention in the comments that you assign the \"$messagechoice\" variable like this: .  The \".ForEach({})\" extension method is a PowerShell 4.0 feature, which explains why it doesn't work in PowerShell 3.0 .  Use the \"ForEach-Object\" cmdlet instead: .  ",
      "P-tags": "powershel powershell-3 0",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP"
    },
    {
      "id": "so_9005867",
      "task": "Calling script from shell script - getting command not found",
      "P-task": "call script shell script - get command found",
      "F_verb": "get",
      "P-body": "The script with the Problem seems to be \"/mnt/stor/backups/backup.sh\". Try setting the PATH to include all the usual directories with binaries, so the script can find its tools. Or, even better, change \"/mnt/stor/backups/backup.sh\" and use absolute paths in the commands like \"/bin/rm\" instead of just \"'rm'\". .  ",
      "P-tags": "linux perl shell",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "au_820162",
      "task": "The password for encrypted file system is not updated when I change the user password",
      "P-task": "password encrypt file system updat chang user password",
      "F_verb": "update",
      "P-body": "This line of action worked well in one computer of mine with Ubuntu 14.04. I name first password the previous one where all worked seamlessly, and second password the current one that gives you hassles with encryption. .  Note that Linux uses the word password whereas ecryptfs uses the word passphrase -- one difference is that a passphrase accepts spaces. Nowadays the difference between the two is blurred, since modern passwords accept spaces too, while the old naming persists. It's useful though to keep in check what you are talking with. .  An important difference within ecryptfs is that between the login passphrase and the mount passphrase. Here we are interested in the login passphrase. .  The starting point of this post is that first login passphrase = first login password. To view the mount passphrase after curiosity, launch \"ecryptfs-unwrap-passphrase\" -- you'll be asked the login passphrase to move on (and keep that mount passphrase safe elsewhere for good measure, if you haven't done so yet). .  Mount the encrypted home  go to terminal with CTRL+ALT+F1 login with the user whose encrypted home is not accessible (with second login password) launch \"ecyptfs-mount-private\", note without \"sudo\" (else I get a \"fopen\" error) type in the first encryption passphrase (the first login password, because they were the same) check that the home directory has been unencrypted (with a \"ls\"-type command). If not, there is some other problem at play.  Reverse the change of login password  make the login password the same as the first encryption passphrase with a plain \"passwd\" command. Crucially, no \"sudo\" again. At this point the login password becomes the first one again, and the login password and login passphrase are the same again.  Give the second value to the login password  use again a plain \"passwd\" command to set the second login password. Crucially, no \"sudo\" again. At this point, ecryptfs will have updated the passphrase with the value given to \"passwd\". This does not work if you use \"sudo passwd\". Step 6 was necessary because successive passwords must be different.  Expected outcome At next reboot the desktop environment should allow you to log in seamlessly by chaining the decryption into the accreditation process, since password and passphrase are the same (having the second value). .  Next time you want to change password and passphrase, log in as the user owning the encrypted home and use \"passwd\", rather than \"sudo passwd\" -- source: http://bodhizazen.com/Tutorials/Ecryptfs/ .  Another attempt to resorting to \"ecryptfs-rewrap-passphrase\" resulted in the deletion of encryption (data are preserved though), so I discourage that (issue https://unix.stackexchange.com/questions/329661, please be aware and help out if possible) .  ",
      "P-tags": "password ecryptf login lightdm",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V when S"
    },
    {
      "id": "au_79481",
      "task": "Is 100% CPU usage harmful while update-apt-xapi runs?",
      "P-task": "100 cpu usag harm update-apt-xapi run",
      "F_verb": "update",
      "P-body": "It is completely harmless. If it were to go on and on and on, you could run: .  \"sudo killall update-apt-xapian-index\" .  to save your CPU from frying :D, which is only likely to be a risk when your system has bad cooling. .  To answer your \"sub-question\", it is not really \"acceptable\", so much as it is not what is ideal, but it is \"acceptable\" in the sense that it does not stay going for long enough to cause damage :). .  Pro-tip: When this program is running, stop doing what ever it is you are doing on the computer at the time unless it is critical/important, and if you have the cpu-frequency indicator, set it to performance for the moment, and let the application run through its paces. This way, it will finish faster, and your system will be smoother to use when it's over (because of less of a lock on the resources). .  ",
      "P-tags": "apt",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_57425713",
      "task": "How to add a new audio (not mixing) into a videos using ffmpeg (Batch Processing)?",
      "P-task": "add new audio mix video use ffmpeg batch process",
      "F_verb": "add",
      "P-body": "Easy method is to navigate to \"videos\" directory then execute a simple for loop with parameter expansion: .  ",
      "P-tags": "ffmpeg linux debian codec",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP into NP using NP"
    },
    {
      "id": "ul_283099",
      "task": "How to set default personality for a kernel?",
      "P-task": "set default person kernel",
      "F_verb": "set",
      "P-body": "There is no such kernel option as far as I can tell. You can take a look yourself through the kernel source if you want; relevant things to search for are \"set_personality\" and \"current->personality\". The flag you want is \"PER_LINUX32\". .  Short of patching the kernel, your solution of overriding init is probably the simplest one. This isn't really out of the ordinary; it's quite similar to using an initramfs. If you're already using an initramfs, you could put your \"setarch\" in there. .  ",
      "P-tags": "linux 64bit search",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP for NP"
    },
    {
      "id": "so_1282465",
      "task": "Why cant I execute a commandlet with arguments from a string in powershell?",
      "P-task": "cant execut commandlet argument string powershel",
      "F_verb": "execute",
      "P-body": "From the help (about_Operators): .  You can use a script block instead of a string: .  Or you can use \"Invoke-Expression\": .  or .  In contrast to \"&\", \"Invoke-Expression\" does parse the string contents, so you can put anything in there, not just a single command. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP with NP from NP in NP"
    },
    {
      "id": "so_41624157",
      "task": "Get-ADUser is not using import text file",
      "P-task": "get-adus use import text file",
      "F_verb": "get",
      "P-body": "You can't use \"-Filter\" with \"-Identity\" (identity is the parameter you're binding to when you pipe). You'll have to filter after the fact: .  ",
      "P-tags": "pipelin powershel active-directori",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V"
    },
    {
      "id": "so_22393775",
      "task": "How to convert shell script in one line and execute it from Python subprocess?",
      "P-task": "convert shell script one line execut python subprocess",
      "F_verb": "convert",
      "P-body": "The error you are getting is from \"json.loads(jsonStr)\". \"json.loads\" require a \"str\" or \"unicode\" not a \"dict\". \"jsonStr\" is already a \"dict\" you don't need \"json.loads\" .  ",
      "P-tags": "subprocess python shell bash",
      "source": "qa",
      "cate": "convert/change/transfer/map/turn/transform/adapt/translate/force/cast/switch/reformat/recurse/align/mirror/colorize/tile/interpret/hash/eval/remux/mutate/indent/sparsify/center/randomize/transverse/invert/lint/transpile",
      "pat": "V NP in NP from NP"
    },
    {
      "id": "au_433895",
      "task": "gnome crashed on ubuntu while updating",
      "P-task": "gnome crash ubuntu updat",
      "F_verb": "update",
      "P-body": "You should be able to use this, .  If not, then I would try .  ",
      "P-tags": "updat gnome",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V"
    },
    {
      "id": "so_18450964",
      "task": "How can I revert my last choice on terminal if it shows > symbol?",
      "P-task": "revert last choic termin show symbol",
      "F_verb": "revert",
      "P-body": "Normally you'll see a \">\" prompt if you've entered a command that's syntactically incomplete, for example if there's a unterminated string literal: .  It means that the shell is waiting for you to type the rest of the command, or at least enough of it to make for something that's not a syntax error. .  In this example, the default prompt, \"$PS1\", is \"'$ '\", and the secondary prompt, \"$PS2\", is \"'> '\". Read the documentation for your shell (probably bash) for more information. .  You can cancel the current command and get back to your primary prompt for a new command by typing Control-C. .  This is all about the behavior of your shell; it has nothing to do with your terminal (almost certainly a terminal emulator), which merely provides a GUI for your shell to run in. .  ",
      "P-tags": "termin linux window shell",
      "source": "qa",
      "cate": "cancel/deregister/undo/deny/unset/unregister/unbind/unload/deselect/unlock/unblock/suppress/revert/rollback/logout/mask/ignore/mute/disown/leave",
      "pat": "V NP on NP if S"
    },
    {
      "id": "ul_623063",
      "task": "How to ensure that a package is correctly installed/updated after \"post-installation script: subprocess returned error exit status 1\"",
      "P-task": "ensur packag correctli instal updat post-instal script : subprocess return error exit statu 1",
      "F_verb": "ensure",
      "P-body": "When a package post installation script fails, the package remains in \u201chalf-configured\u201d state, and any subsequent operation which touches packages should run the post installation script again. .  You can check \"initramfs-tools\"\u2019 state by running .  If this shows .  then nothing further needs to be done. .  If the second column shows \"F\", then the package is half-configured, and configuration can be completed by running .  If you\u2019d rather re-install the package instead, run .  ",
      "P-tags": "dpkg apt initramf debian",
      "source": "qa",
      "cate": "confirm/ensure",
      "pat": "V that S"
    },
    {
      "id": "so_49781364",
      "task": "Error: cannot set up sessions without a secret or encryptionKey/signatureKey pair",
      "P-task": "error : set session without secret encryptionkey signaturekey pair",
      "F_verb": "set",
      "P-body": "To use \"client-sessions\" you must set either \"secret\" or both \"encryptionKey\" and \"signatureKey\", as recommended in the documentation .  https://www.npmjs.com/package/client-sessions#usage .  The code of \"lib/client-sessions.js\" checks that secrets or two keys are initialized in \"clientSessionFactory\" method: .  https://github.com/mozilla/node-client-sessions/blob/d0c20af3b0ed7750c68d3ae67819dfe203fa3d60/lib/client-sessions.js#L542 .  https://hacks.mozilla.org/2012/12/using-secure-client-side-sessions-to-build-simple-and-scalable-node-js-applications-a-node-js-holiday-season-part-3/ page says how to set \"secret\" - by using some long random string (for example, combine several strings from the site random.org):  .  ",
      "P-tags": "node js ubuntu",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V up NP without NP"
    },
    {
      "id": "au_1056167",
      "task": "How to install ATLAS on Kubuntu 18.04(Bionic)",
      "P-task": "instal atla kubuntu 18 04 bionic",
      "F_verb": "install",
      "P-body": "It seems that you do not have universe repository (for \"libatlas-base-dev\"). LAPACK and BLAS are in main. You should have both repositories enabled.  .  Try to add the repositories with .  And then install needed packages with .  ",
      "P-tags": "dpkg apt updat package-manag software-instal",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP on NP"
    },
    {
      "id": "ul_87704",
      "task": "How to automatically apply changes in a folder to another?",
      "P-task": "automat appli chang folder anoth",
      "F_verb": "apply",
      "P-body": "\"rsync\" syncs stuff between directories and even different servers. It has includes/excludes support, etc. If you want stuff to be really synchronized automatically, then, you could run rsync with whatever parameters needed. .  You can put the command and all its parameters in a script, and then... .  You can run that script in a scheduled job if you want it to do the copy at a given interval, or you can run the script manually when a sync needs to happen, and finally, you can listen on to filesystem events on your relevant directory, using \"inotify\", to run rsync when certain changes happen in the directory.  .  You can do that either by a while loop that blocks on inotify, or by using special programs/scripts designed to do stuff like that, for example: .  rsync-inotify: http://code.google.com/p/rsync-inotify/ .  lsyncd: http://code.google.com/p/lsyncd/ .  and so on... .  ",
      "P-tags": "file synchron",
      "source": "qa",
      "cate": "apply/reapply/accept/repeat",
      "pat": "V NP in NP to NP"
    },
    {
      "id": "so_10444806",
      "task": "svc_tli_create not found in Linux",
      "P-task": "svc_tli_creat found linux",
      "F_verb": "find",
      "P-body": "\"TI-RPC\" provides a SUN compatible RPC interface and used by recent glibc as well. .  ",
      "P-tags": "linux function linux-kernel",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V in NP"
    },
    {
      "id": "so_9984173",
      "task": "Is there a way to format the output of Select-String to include newlines between the results?",
      "P-task": "way format output select-str includ newlin result",
      "F_verb": "include",
      "P-body": "There's probably a pithier way than this, but it works: .  ",
      "P-tags": "powershel grep",
      "source": "qa",
      "cate": "import/include",
      "pat": "V NP between NP"
    },
    {
      "id": "au_26555",
      "task": "Running PHP-CLI server",
      "P-task": "run php-cli server",
      "F_verb": "run",
      "P-body": "To redirect both output and any errors to some_other_file: .  The >& redirects a stream to another file descriptor (in BASH shell): .   0 is stdin 1 is stdout 2 is stderr  Or, 2>&1 redirects 2 to 1. And then to watch that output in real time: .  Starting at boot time: you could call the script from /etc/rc.local. Or, a more advanced solution might be to write a script in the /etc/init.d/ directory. See /etc/init.d/README for how to do that. .  If you make the PHP file, server.php, executable, you can add a line to the top of the file (aka file magic/shebang/hashbang) to call it this way: \"server.php\" instead of \"php server.php\". You could even remove the php extension if for some reason you want to do that. Like this: .  Upstart is probably the way to go to make sure the service stays running. This method does not involve /etc/rc*. Upstart has five packages, all installed by default: .   Upstart init daemon and initctl utility upstart-logd provides the logd daemon and job definition file for logd service upstart-compat-sysv provides job definition files for the rc tasks and the reboot, runlevel, shutdown, and telinit tools that provide compatibility with SysVinit startup-tasks provides job definition files for system startup tasks system-services provides job definition files for tty services  The learning is very enjoyable and well worth it. Upstart has a website: http://upstart.ubuntu.com/ .  Other good posts: What's the difference between \"Service\" and \"/etc/init.d/\"? .  ",
      "P-tags": "php server servic",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "so_36720958",
      "task": "Bashrc alias for deleting non consecutive duplicate lines directly from file then save and close it",
      "P-task": "bashrc alia delet non consecut duplic line directli file save close",
      "F_verb": "close",
      "P-body": "In shell you cannot nest single quotes inside a pair of single quotes. .  You can either use: .  or better use a function instead of \"alias\" without worrying about quoting: .  ",
      "P-tags": "shell bash",
      "source": "qa",
      "cate": "close/end/release/free/dismiss/deactivate/disable",
      "pat": "V NP"
    },
    {
      "id": "au_530211",
      "task": "How to fix upgrade hang from saucy->trusty: \"Removing ___ from Mono\"",
      "P-task": "fix upgrad hang saucy- trusti : remov ___ mono",
      "F_verb": "fix",
      "P-body": "The previous answer has a typo where it said to run \"sudo sed -i -e 's/trusty/saucy/g; s/14.04.1/13.10/g; s/LTS//;'\" but didn't say what file to apply that edit to.  .  My guess is that they meant /etc/lsb-release and editing that file (as well as /etc/apt/sources.list as shown) worked for me. .  P.S. The website said I didn't have enough karma or whatever to post a \"comment\", so posting this \"Answer\" (really a comment) was the only choice... .  Also, here's a script which automates the repetive ps/run-by-hand/kill procedure described in the previous answer (run the script as many times as necessary to get past the hangs) .  ",
      "P-tags": "upgrad do-release-upgrad 13 10 14 04 mono",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP from NP"
    },
    {
      "id": "su_1008549",
      "task": "grep command returning 0 - match all characters that are not digits globally",
      "P-task": "grep command return 0 - match charact digit global",
      "F_verb": "match",
      "P-body": "You need to adapt your pattern as follow: .   We do not need the 'greedy' flag as grep already works with lines The quotes are not required here The star can be any number of results, including 0 (so using it will return true for every line)  If you need to use again some Pearl regular expressions (PCRE), you can have a look at the -P option of grep but the manual page says: .   -P, --perl-regexp Interpret PATTERN as a Perl regular expression (PCRE, see below). This is highly experimental and grep -P may warn of unimplemented features. .   ",
      "P-tags": "linux grep regex",
      "source": "qa",
      "cate": "match",
      "pat": "V NP that S"
    },
    {
      "id": "so_29450829",
      "task": "c execute doesn't work",
      "P-task": "c execut work",
      "F_verb": "execute",
      "P-body": "you can use system() function instead of execl() to execute shell command .  ",
      "P-tags": "c exec bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP"
    },
    {
      "id": "ul_381567",
      "task": "Getting \"This repository does not have a release file\" on freshly installed Debian 9.1 with KDE",
      "P-task": "get repositori releas file freshli instal debian 9 1 kde",
      "F_verb": "get",
      "P-body": "It works now after: .   Changing the sources file by duplicating the below lines with one of the pairs saying \"stretch-updates\" instead of \"stretch\"  running \"apt-get install firefox-esr\"   Prior I only commented out the CD sources and added a source in the same way as here, like: .  \"deb http://ftp.id.debian.org/debian/ stretch main contrib\" \"deb-src http://ftp.id.debian.org/debian/ stretch main contrib\" .  which I changed to stretch/updates which didn't help nor did changing the mirror. .  For the bluescreen and freezes I created a separate question here .  ",
      "P-tags": "secur apt debian package-manag kde",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP on NP"
    },
    {
      "id": "so_13396024",
      "task": "Fake directory containing png informations",
      "P-task": "fake directori contain png inform",
      "F_verb": "contain",
      "P-body": "If all you need is a place in the filesystem where some application can read some specific data, use \"mkfifo\" to create it. .  Then you can write a producer that writes whatever you need at whatever bitrate to it and have a consumer reading from it. If you output what the consumer expects, you might be able to get something that resembles a \"live stream\" of faked data. .  ",
      "P-tags": "directori c unix",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP"
    },
    {
      "id": "so_21199666",
      "task": "Terminal colors cause the prompt to jump back to the beginning of the line",
      "P-task": "termin color caus prompt jump back begin line",
      "F_verb": "cause",
      "P-body": "I think you need to write .  So you have \"\\[\" and \"\\]\" surrounding all the colour directives. .  ",
      "P-tags": "prompt termin command-lin color shell",
      "source": "qa",
      "cate": "make/cause/instruct",
      "pat": "V NP S_INF to NP of NP"
    },
    {
      "id": "so_35582765",
      "task": "How to get first and last element from a csv column",
      "P-task": "get first last element csv column",
      "F_verb": "get",
      "P-body": "You have a lot of alternatives. Here are some of them: .  Using \"head\", \"tail\" and \"cut\" .  Using \"awk\" .  One-Liner using \"awk\" (thanks to this answer) .  Another One-Liner using \"awk\" .  ",
      "P-tags": "unix csv pars shell bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP from NP"
    },
    {
      "id": "so_2430441",
      "task": "SVN: Recurisvely add files?",
      "P-task": "svn : recurisv add file",
      "F_verb": "add",
      "P-body": "The \"find\" command is the trick to dig out the files you want. .  And there's about a million ways to do it, all of which are educational in their own right. .  ",
      "P-tags": "svn shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP"
    },
    {
      "id": "au_971216",
      "task": "Adding execute permission in opt folder",
      "P-task": "ad execut permiss opt folder",
      "F_verb": "add",
      "P-body": "If you are not the owner of a file you can't modify its permission bits. Well, with richacls you can do that, but you are not going to find it in a basic Ubuntu installation .  The root user can do that. There are many ways to become root user in GNU/Linux. The recommended way to do this in Ubuntu is by using \"sudo\" .  ",
      "P-tags": "permiss command-lin",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP in NP"
    },
    {
      "id": "au_224556",
      "task": "How to install Xfce without xubuntu-desktop or ubuntustudio-desktop",
      "P-task": "instal xfce without xubuntu-desktop ubuntustudio-desktop",
      "F_verb": "install",
      "P-body": "To install Xfce 4.10 (the newest version of this desktop environment) on Ubuntu 12.04 LTS you should follow these steps: .  Add the ppa that will allow you to install the Xfce 4.10: .  Update the system: .  Install Xfce 4.10: .  ",
      "P-tags": "xfce 12 04 xubuntu uniti",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP without NP"
    },
    {
      "id": "ul_66451",
      "task": "Run a command on all subfolders",
      "P-task": "run command subfold",
      "F_verb": "run",
      "P-body": "Try doing this (using bash, brace expansion & globs): .  or  .  if your shell lack the brace expansion feature. .  Contrary to \"[a-z]\", \"{a..z}\" (also supported by ksh93) is not a \"glob\", it's brace expansion, it's expanded (before \"globs\") regardless of whether files exist or not. That's like \"rm -f a/*.pdf b/*.pdf\"..., regardless of whether a, b... exist or not. Also note that contrary to \"[a-z]\" where the range may be locale dependant (like may include \"\u00e9, \u015b\"...), \"{a..z}\" only works with byte ranges (and reliably only in the \"ASCII\" letter ranges, and number ranges) .  (Merci Stephane Chazelas for explanations) .  ",
      "P-tags": "directori wildcard file command-lin",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP on NP"
    },
    {
      "id": "au_1084550",
      "task": "Ubuntu 18.10 stuck on \"Started bpfilter\" while booting",
      "P-task": "ubuntu 18 10 stuck start bpfilter boot",
      "F_verb": "start",
      "P-body": "Actually, scratch that. Do this: edit /etc/gdm3/custom.conf and uncomment the line: .  #WaylandEnable=false .  The issue also doesn't seem to appear in a fresh install of Ubuntu 18.10. .  Go here and press the affects me button to raise awareness. Feel free to provide information/logs needed by the developers in the comments. Thank you. .  Removing the nvidia proprietary drivers seems to fix the issue. Go into recovery mode by pressing Shift during boot and run \"sudo apt-get remove --purge nvidia-*\" Say goodbye to gaming, though. I have filled a bug in Launchpad. You might want to press the \"affects me\" button. Thank you. .  ",
      "P-tags": "boot 18 10 firewal",
      "source": "qa",
      "cate": "start/wake/launch/happen/begin/enable/spawn/restart/unfreeze/continue/host/deploy/seed/resurrect/tunnel/proxy/serve/reboot/boot/power/login",
      "pat": "V NP while S_ING"
    },
    {
      "id": "so_36920897",
      "task": "I'm trying to understand how to use special characters in grep and wc",
      "P-task": "tri understand use special charact grep wc",
      "F_verb": "use",
      "P-body": " It reads the /etc/passwd file line-by-line and filters out all those lines that \"^\"=begin with the \"-w\"=complete word \"root\". So, for example the line .  To see all processes on a system, you could use \"ps aux\". and it will show lines like this .  As you can see, the lines start with a username. If you pipe the \"ps aux\" output through \"grep\", you can use the same RegEx from above, to filter out all lines that do not start with \"root\". .  Use \"-v\" to invert pattern matching, so that \"grep -vw '^root'\" finds all lines that don't begin with a complete word \"root\". .  Finally, \"wc -l\" counts the number of lines it receives. So that is the number of all lines from \"ps aux\" that do not begin with \"root\". .  ",
      "P-tags": "wc linux grep bash",
      "source": "qa",
      "cate": "perform/execute/run/enforce/fire/trigger/approve/emulate/ping/telnet/traceroute/loop/use",
      "pat": "V NP in NP"
    },
    {
      "id": "so_43989022",
      "task": "SSH server - Get pid of sshd process forwarding port #N",
      "P-task": "ssh server - get pid sshd process forward port n",
      "F_verb": "get",
      "P-body": "You can make use of \"lsof\" command since everything is a file on linux.  .  Something like \"lsof -Pan -i | grep :PORT\" will get you what you ask. It has an output like this when i run it for port 80 on my machine: .  More on \"lsof\" can be found here .  ",
      "P-tags": "pid linux server ssh-tunnel ssh",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP"
    },
    {
      "id": "so_45378619",
      "task": "Get logs of a function separately each time it is iterated in python",
      "P-task": "get log function separ time iter python",
      "F_verb": "get",
      "P-body": "You can create new file and write data into that for each iteration. .  This is a simple example: .  In you code if you implement same concept and pass the file object to mysql_spark function for every iteration it should work. .  ",
      "P-tags": "linux python pyspark bash",
      "source": "qa",
      "cate": "return/get/obtain/fetch/acquire/take/capture/represent/reclaim/receive/claim/extract/share/grab/grep/learn/recall/redeem/contain/pull/download/yank/recommend/digest/elaborate",
      "pat": "V NP of NP in NP"
    },
    {
      "id": "so_22533884",
      "task": "How to Configure Apache 2.2.14 on Ubuntu 10.04 to use SSL only (Redirect loop)",
      "P-task": "configur apach 2 2 14 ubuntu 10 04 use ssl redirect loop",
      "F_verb": "configure",
      "P-body": "You need to get rid of your first virtual host because this looks like it is your httpd.conf file, not .htaccess, then change \"*\" to your server's IP address and finally put .  at the top of the file. .  Finally restart Apache in a terminal: .  ",
      "P-tags": "ubuntu redirect-loop apach ssl",
      "source": "qa",
      "cate": "set/control/describe/define/specify/assign/configure/schedule/declare/reassign/designate/highlight/expose/grant/symlink/pair/link/act/hold/prefix/reference/manage/audit/whitelist/customise/suffix/require/answer/treat",
      "pat": "V NP on NP S_INF with NP"
    },
    {
      "id": "so_41576385",
      "task": "Powershell remove space from after command",
      "P-task": "powershel remov space command",
      "F_verb": "remove",
      "P-body": "It's less complicated to simply use string formatting or in-line expand into a single string. .  or .  An article on various formatting options: https://blogs.technet.microsoft.com/heyscriptingguy/2013/03/12/use-powershell-to-format-strings-with-composite-formatting/ .  The reason you're getting the extra newline is that your code sample omitted a Write-Host on the Width portion. The first items went to Write-Host, then an item on the output stream that didn't have a way to omit the newline. Simply correcting that flaw gives you the output you desired, but the approach is overly complicated. .  Fixed original sample: .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "remove/exclude/reduce/delete/pop/uninstall/detach/decrement/revoke/abandon/discard/peek/limit/exit/eject/overwrite/omit/truncate/prune/override/unstage/dereference/purge/drop/unmount/trash/reject/erase/deduplicate/wipe/decrease",
      "pat": "V NP from NP"
    },
    {
      "id": "so_33126250",
      "task": "Run echo and redirect it to cat with dash shell",
      "P-task": "run echo redirect cat dash shell",
      "F_verb": "redirect",
      "P-body": "No. dash doesn't support process substitution. .  But that's also a rather strange way to do what you want there. .  Two simpler (and dash compatible unless I'm sorely mistaken) ways are: .  and .  ",
      "P-tags": "makefil cat dash-shel bash echo",
      "source": "qa",
      "cate": "redirect/jump/skip/go/navigate/roll/expand",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "so_62472866",
      "task": "Powershell - replace line in .txt if condition is met",
      "P-task": "powershel - replac line txt condit met",
      "F_verb": "replace",
      "P-body": "You can use some conditional logic (\"if\" statements) to achieve the goal: .  Since we are piping the \"Get-Content\" result into \"Foreach-Object\", \"$_\" becomes the current line being processed (each line is processed one by one). If a line contains \"successfull\", then we mark \"$successful\" as \"$true\" and still output that line (\"$_\"). If the line contains \"error\", then we will only output it if \"$successful\" is \"$false\". Anytime we reach a line that does not contain \"succcesfull\", we mark \"$successful\" as \"$false\". .  No deletion is actually occurring as it is merely not displaying \"error\" lines when the conditions are met. .  ",
      "P-tags": "powershel",
      "source": "qa",
      "cate": "replace",
      "pat": "V NP in NP S_INF of NP"
    },
    {
      "id": "so_8274898",
      "task": "How to integrate Phonon with Qt in Linux?",
      "P-task": "integr phonon qt linux",
      "F_verb": "integrate",
      "P-body": "When you ran \"configure\" to install Qt, did you somehow disable Phonon support? .  \"-phonon\" and \"-phonon-backend\" are enabled by default. .  Qt documentation notes: .   Phonon is built if a decent C++ compiler is used. .   Are you using an up-to-date compiler? .  You might try clearing your current configuration and running \"configure\" again: .  ",
      "P-tags": "phonon linux media-play qt",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP with NP in NP"
    },
    {
      "id": "so_69172746",
      "task": "JQ: Add object to nested json with the same key names",
      "P-task": "jq : add object nest json key name",
      "F_verb": "add",
      "P-body": "You were close .  see https://stackoverflow.com/a/42248841/2235381 .  ",
      "P-tags": "json linux jq shell",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP with NP"
    },
    {
      "id": "so_33936043",
      "task": "Modify a JSON file with PowerShell without writing BOM",
      "P-task": "modifi json file powershel without write bom",
      "F_verb": "modify",
      "P-body": "This has nothing to do with \"ConvertTo-Json\" or \"ConvertFrom-Json\". The encoding is defined by the output cmdlet. \"Out-File\" defaults to Unicode, \"Set-Content\" to ASCII. With each of them the desired encoding can be defined explicitly: .  or .  That will still write a (UTF8) BOM to the output file, but I wouldn't consider UTF-8 encoding without BOM a good practice anyway. .  If you want ASCII-encoded output files (no BOM) replace \"UTF8\" with \"Ascii\": .  or .  ",
      "P-tags": "unicod powershel byte-order-mark",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP without NP"
    },
    {
      "id": "au_1347213",
      "task": "Intellij Idea not showing up in apps and cannot add it to Favorites",
      "P-task": "intellij idea show app add favorit",
      "F_verb": "add",
      "P-body": "Thanks to @Kulfy I found the problem: there was an old \".desktop\" file for IntelliJ IDEA in \"~/.local/share/applications\" which contained invalid path (pointing to old version). .  After deleting it and restarting GNOME shell using Alt+F2 and ruuning \"restart\", I was able to add it to Favorites. .  ",
      "P-tags": "intellij gnome 20 04",
      "source": "qa",
      "cate": "append/put/add/insert/push/interpolate/place/install/register/queue/enqueue/type/consume/integrate",
      "pat": "V NP to NP"
    },
    {
      "id": "au_383178",
      "task": "Update Manager in Ubuntu 12.04 freezes every time",
      "P-task": "updat manag ubuntu 12 04 freez everi time",
      "F_verb": "update",
      "P-body": "permissions in your python packages are possibly not working , change its permission by using-  .  -Replace USER with your login name, if this doesnt works check the output of - .  If it throw any error \"ImportError: No module named pkg_resources\" .  then the reason behind this could be setup tools package has been deleted in my Python environment .to solve this use the following script- .  hope it will work. .  ",
      "P-tags": "12 04 updat update-manag",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP in NP"
    },
    {
      "id": "ul_512877",
      "task": "opendkim.sock file not being created or does not exist",
      "P-task": "opendkim sock file creat exist",
      "F_verb": "create",
      "P-body": "I ended up solving my issues. There were a plethora of issues riddled throughout my \"/etc/default/opendkim.conf\" file. Mainly misspellings. Result of following a tutorial, as I wasn't careful) .  My main issue was that my opendkim service was not running. The service should still run even if your dkim is not signing your messages.  .  For those having similar issues, id like to recommend referring to ALL of your log files. Some issues may stem from parent issues, as well as some logs may give you a better idea for what the root problem is or even a better description. .  See these below logs... .  Some of these logs can be very length, so make sure you are looking at the newest entries, as well as testing your problem and verifying with a close timestamp. .  ",
      "P-tags": "postfix opendkim debian dovecot",
      "source": "qa",
      "cate": "create/build/produce/construct/generate/establish/compose/instantiate/implement/setup/rebuild/train/recompile/reinstall",
      "pat": "V"
    },
    {
      "id": "so_12789666",
      "task": "Bourne Shell Programming: find smallest/largest number in list",
      "P-task": "bourn shell program : find smallest largest number list",
      "F_verb": "find",
      "P-body": "We don't want to spoil all the fun, do we? You didn't ask for a solution, you just asked for tips. So here we go: .   Set \"min=\"\"\" Read the file line by line  Compare the obtained value \"x\" to \"min\" (What if \"min\" is empty?) If it is smaller, set \"min=x\"  Print \"min\"  All you have to do is translate this to sh, and also the opposite for \"max\". .  There may be easier ways, but this is the simplest pure-sh algorithm I can think of. .  ",
      "P-tags": "shell search",
      "source": "qa",
      "cate": "query/find/locate/retrieve/look/search/discover/seek/lookup/hunt/pick",
      "pat": "V NP in NP"
    },
    {
      "id": "so_58974687",
      "task": "Is there a way to keep the program running while waiting for input?",
      "P-task": "way keep program run wait input",
      "F_verb": "keep",
      "P-body": "The easiest thing to do is just to change stdin over to non blocking. This is done (on Linux and others) by using the \"fcntl()\" function to change the \"F_SETFL\" option on stdin. .  That will make \"fgetc()\" (or any other read) no longer block returning right away. If there wasn't any thing to read (no input) it will return an error. If there is something it will return that character. .  Here is the call you need to make to change stdin to non-blocking. .  \"fcntl(0, F_SETFL, FNDELAY);\" .  The first argument is the file handle. We pass in 0 which is stdin. The next argument is the option we want to change (in this case F_SETFL), and the 3rd argument is what to change it to (FNDELAY is non-blocking mode). .  Here is a simple example program: .  This is great. It no longer blocks, but it still echos the characters being typed and you need to press enter before you will get back any input from \"fgetc()\". .  If we want to make it more game like we need to tell the terminal to stop messing with our input. We need to switch the terminal into RAW mode. .  The following example turn the terminal to RAW mode and changes stdin to non-blocking. .  The downside to this is that if you Ctrl-C or your program crashes it will leave your terminal in a messed up state that is not easy to get back out of. You can help with this by adding an \"atexit()\" and/or signal handling. .  ",
      "P-tags": "linux input consol c anim",
      "source": "qa",
      "cate": "store/save/dump/retain/cache/stash/serialize/deserialize/persist/keep/stage/suspend/backup/preserve/buffer",
      "pat": "V NP S_ING while S"
    },
    {
      "id": "ul_137643",
      "task": "Editing INI-like files with a script",
      "P-task": "edit ini-lik file script",
      "F_verb": "edit",
      "P-body": "Here are a few script examples. These are bare minimum and don't bother with error checking, command line options, etc. I've indicated whether I've run the script myself to verify its correctness. .  Ruby Install the \"inifile\" rubygem for this script. This script is tested. .  Usage: .  Perl Install \"Config::IniFiles\" using \"cpan\" or your OS package manager (if there is a package available). This script is untested as I've stopped using \"perl\" on my system. It may need a little work, and corrections are welcome. .  Usage: .  awk This script is more Bash and *nix friendly and uses a common utility of *nix OS's, \"awk\". This script is tested. .  Usage: .  ",
      "P-tags": "shell-script configur text-process",
      "source": "qa",
      "cate": "update/modify/fill/edit/rename/populate/adjust/flush/trim/reconcile/resize/upgrade/optimize/sign/prepend/optimise/customize/shrink/patch/fit/index/rebase/fake/compensate/calibrate/correct/flood/fix/repair/delimit/maximize/minimize/differ/minimise",
      "pat": "V NP with NP"
    }
  ]
}